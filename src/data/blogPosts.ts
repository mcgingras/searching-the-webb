export const blogPosts = [
  {
    title: "The unimagined orange and new frontiers in management consultancy",
    date: "17.30, Friday 5 Jan 2024",
    content:
      "I love a good triangle diagram.\nCitrus fruits are a great example. It turns out there are three basic ancient eigenfruits: true mandarins, pomelos, citrons.\nAnd all the other fruits are various combinations of that triplet. Such as\n\noranges: 50% true mandarin, 50% pomelo, zero citron.\nlemons: 30% true mandarin, 20% pomelo, 50% citron.\ngrapefruit: kinda like oranges but with more pomelo.\n\nSo you can plot them all on a triangle.\nHere’s the diagram! Hybridization in citrus cultivars.\nWhen you look at it, don’t you just see the GAPS?\nDoesn’t it just make you want to run outside and start hybridising limes to breed a heretofore unimagined citrus sensation? \nThere’s a similar diagram for soil.\nEver wondered about the difference between clay, sand, silt, loam, loamy sand, sandy loam, and so on?\nThere’s a triangle for you!\nOR: chocolate desserts.\nChocolate, milk, and sugar - dark chocolate, chocolate milk, ice cream, and tiramisu on the same triangle.\nIt makes me want to explore the tasty unnamed spaces.\nThe technical term is a ternary plot.\ne.g. from that Wikipedia page I found this one for the flammability of methane.\nGeologists and chemists seem to love ternary plots especially.\nTo the point that they make joke ones. This ternary chart of geoscientists maps out geophysicists, geologists, sedimentologists, seismologists and so on, all on a triangle where the vertices are: lab rats; computer geeks; people who like camping.\nOh also here’s a ternary plot which is a Grand Unified Theory of Potato Chips.\nI can’t tell whether the Region of Culinary Repulsion (mapped out between sour cream and onion, salt and vinegar, and BBQ) should be seen as a warning or a challenge.\nSo here’s the bit I’ll paste into LinkedIn later in my relentless pursuit for citrus-derived thought leadership, then pitch to Harvard Business Review once I get traction:\nTernary plots are the 21st century tool we’ve been waiting for.\nThey’re different from the management consultant’s usual 2x2 – where you categorise by sorting into a small grid of A or not-A, combined with B or not-B.\nFor instance BCG’s Growth Share Matrix, from 1970, plots growth vs market share, and helps businesses prioritise. It was popular: At the height of its success, the growth share matrix was used by about half of all Fortune 500 companies.\nTriangles share the 2x2’s legibility and ease of rapid whiteboard sketchability. The memetic power.\nBut 2x2s tend towards binaries and division.\nEven Venn diagrams, another typical diagram, as combinatorial as they are, have underlying binary assumptions: something possesses a quality or it is outside the circle.\nWhereas the triangle describes a landscape.\nWho will invent the BCG Growth Share Matrix of triangles?\nThere are gradients and spectrums and magnitude.\nTernary plots seem to promote asking: well what if we could move slightly over there? Where are the tipping points, what’s the terrain? How would we explore this unmapped region?\nTriangle diagrams open up vistas for the imagination, it seems to me. I’m looking out for excuses to invent some.\n3M should make triangular Post-Its. In shades of orange of course.\n",
    link: "/home/2024/01/05/triangles",
  },
  {
    title: "The visual affordances of touchscreen-enabled gloves",
    date: "09.06, Wednesday 10 Jan 2024",
    content:
      "I got some new gloves for Christmas. Thanks!\nThe first finger and thumb are made of a slightly shinier leather. I just noticed, I’ve been wearing them through this cold snap.\nSo I tried those fingers on my phone – they’re capacitive touch enabled.\nAnd there I’ve been the last few days, putting on and taking off my gloves like a chump.\n(The other fingers don’t work on my touchscreen which in retrospect is odd because, as I say, the gloves are leather and meat usually works on screens. Try some chorizo next chance you get. Anyway, so the leather curing process means that the gloves default to not working on my iPhone, then some secondary process re-enables the tips of two digits.)\nWell I should have expected it.\nEven my kid’s wool gloves have little grey coloured patches on the first finger and thumb to show where they are touch-enabled.\nPutting aside my immediate reaction - we got those gloves when she was 4! She doesn’t have a phone! - I wonder what the thinking is behind using grey to communicate the touch affordance?\n\nGrey as in “electronics”? Affordance by similarity.\nGrey as an artefact of the manufacturing process, the colour of the capacitive thread maybe.\nGrey as in dirty because those finger pads are used for a lot of touching?\n\nI learn towards “grey as in touched a lot” because my Christmas gloves are matt leather and the fingertips for my phone have been made glossy. And glossy is what leather gets when regularly touched.\nSo the fabric has been given a pre-worn look. Like a worn patch on a door that shows that people have historically pushed it, and so I can push it too. But here it’s deliberate: the material has “rehearsed” touching and that material muscle memory transmits to me visually.\nTo perceive something is to get ready to act with it; seeing a mug handle makes your hand-grabbing neurons warm up. That’s how visual affordances work. It happens deep in the brain, I don’t want to have to comprehend my gloves, or remember what functionality they have, in the moment. Shiny leather patches it is then. Smart.\nDesign eh!\nASIDE:\nIf you’re ancient enough to remember the original click wheel iPod (sigh) you’ll remember that when it switched from a mechanical wheel to being solid-state and touch-enabled, the designers also changed it from white to grey. I wrote about why at Mind Hacks in 2005:\n\nThe scrollwheel is a dirty grey. It looks like it has been touched a lot. It looks rubbery (although it’s not). It communicates the affordance of doing something when touched and dragged.\n\nWhat is the feature called? I checked a couple brands.\nUniqlo doesn’t even mention it. But if you look at their gloves online (except for the cheapest and the specialist gloves) then the relevant finger pads do indeed look different.\nHugo Boss, higher end: they say TOUCHSCREEN-FRIENDLY FINGERTIPS. It’s tucked away in the product description, no biggie.\nNow Alibaba. Let’s see what the factories say.\nThere are generic glove suppliers and also glove suppliers who are trying to “sell” the product. This is the copy they use:\n\nFeatures: touchscreen, cold proof, windproof, lightweight\n\nWhat I’ve learnt:\n\nThe term is touchscreen – not “-enabled” necessarily and not “smart” or “capacitive touch” or “works with phones.” The specific part of the glove doesn’t need to be mentioned either, it’s assumed.\nAt some point between buying my last pair of gloves, when this was an available feature but you had to hunt it out, and this Christmas just gone, touchscreen fingertips became the default. \n\nI like to be reminded that standard clothes change over time.\nAnything that I take for granted really. I find it hopeful to remember that the apparently permanent world is constructed. Clothes are a mesofact.\nWhat other changes are coming?\nMaybe in the future we’ll have winter coats with hoods big enough to accommodate our always-worn VR headsets.\nOr special clips on our shoes to snap-fit onto motorised accelerators that everyone will own by then. Hoverboards or robot boots, I assume something like that.\nBut then features become vestigial.\nThe touchscreen fingertips on gloves will remain, years beyond us using capacitive touchscreens. Perhaps they won’t even work, it’ll just be the colour or the gloss.\nWe’ll look at the shiny leather finger pads and see them in the same category as the hoop on the side of my trousers for, well I don’t know what it’s for, carrying a hammer? It likely has some brand identity purpose now. Or a lapel button hole which is stitched closed now and I don’t know what its original utility was – for a buttonhole flower? Flowers were a sophisticated communications technology once up a time.\nOr the little square pocket which is mandatory on jeans.\nYou never use it and one day you do and then you forget about a coin or something that ends up breaking your washing machine. It’s hazardously vestigial, the appendix of jeans.\nThe johnny pocket we used to call it as teens in the 90s. Perhaps it was wildly high tech for something or other in the 1850s? Don’t abandon your family to join a frenzied gold rush without it.\n",
    link: "/home/2024/01/10/gloves",
  },
  {
    title: "Upcoming travel: SF w/c Mon 5 Feb",
    date: "17.03, Thursday 11 Jan 2024",
    content:
      "A date for your diary – I’m in San Francisco/the Bay Area the week of Mon 5 February.\nLmk if you can sneak me in anywhere to see cool and unlikely things.\nMainly I would love to catch up with old friends and grab coffee with new ones. You know my interests by now… AI, hardware, tools for thought, multiplayer, weird software, interstellar generation ships, that sort of thing. Drop me a note.\nThough I do have one specific ask:\n\nDo you have a space I could hang out at on Wed 7th? Somehow I’m doing a remote talk at lunchtime that day, and I could do with a quiet spot and good wifi to wave my arms around on Zoom. Thank you, I have this covered now!\n\nI’m staying in the city.\nIf there’s any art I should see, I’d love to hear about that.\nI’m planning on getting a car one day to stretch my legs somewhere over the bridge. Apparently there are some good loops over there. Not sure what day yet. I know that I’m in Palo Alto on Tuesday.\nThe excuse for the trip is Soc Sci Foo Camp hosted by O’Reilly, Meta, and SAGE, starting Friday 9th. Looking forward to saying hi if you’ll also be there.\nThanks!\n",
    link: "/home/2024/01/11/travel",
  },
  {
    title: "What is the fart app for Apple Vision Pro?",
    date: "18.45, Tuesday 16 Jan 2024",
    content:
      "What I mean is: what’s the app that you download, makes you laugh, you show your friends, it makes them laugh, and it couldn’t have been done without the core technology of the platform?\nThe app that is so dumb but it’s costs just $1 and it makes the developer a bazillion bucks.\nThat app is the fart app.\nYou know the one I mean. An app that has a big button and you hit the button and it makes a sound of a fart and that’s it. It’s in the first 10 apps that anyone downloads.\nI want to know what it will be for the Vision Pro, Apple’s big bet on spatial computing and augmented reality, which goes on pre-order in a couple days and will be in people’s hands on people’s faces on 2 Feb.\nThe fart app wasn’t literally a fart app for iPhone.\nThere was an app where koi carp swam peacefully in a pond, and if you touched the screen the water would ripple and the fish would swim away.\nAnother app looked like a glass of beer and when you tilted the phone the beer would tilt too and the level would go down. Maybe there was a belch at the end?\nTalking Carl had a little cartoon something that repeated whatever you said only in a squeaky voice.\nThen sound board apps to make stupid sounds.\nThese apps weren’t trivially easy to develop with the incumbent Nokia smartphones. The app platform was too cumbersome; the sensors too scarce; the screen dim and slow to respond.\nThen we got an explosion of fart apps. So to speak.\nBut I would argue that having a “fart app” (literally or of that category) is critical.\n\nYou show your friends what your new gadget can do - those breakout iPhone apps required capacitive touch, gyroscopes, a good mic and speaker, etc - and you get to make them laugh. Showing off! But also, virality!\nIt creates understanding. Nobody can understand a new capability without trying it. A fart app shows a consumer some new complicated technology in a frame that they grok instantly.\n\nThe experience is roughly: person A says to person B, oh you got that new thing. Person B says, yeah check this out. Person A tries it, gets what is unique about the thing, laughs, all within about 3 seconds.\nSo what is the fart app for Vision Pro?\nMaybe in the app you pretend to be Godzilla and stomp on cities.\nLook.\nHere are my notes from trying a Meta Quest 2 VR headset (Apr 2022). For me the magical moments came from scale.\nEither:\n\nYou are tiny and looking at something huge; or,\nYou are huge and looking at something tiny.\n\nScale and height are the visceral responses available with mixed reality that you can’t get from screens. They make you gasp and make you laugh.\nI was endlessly tickled, with my Quest 2, with a mountain that got halfway up my chest and I could kneel down to peer in the caves, and awed standing in a towering cathedral and looking up, up, up.\nSo imagine this, dear app developer:\nUse the new Google Maps API with photorealistic 3D tiles.\nDisplay the local city on the floor in the user’s living room. Looking through the Vision Pro the tallest buildings should come up to their knees.\nAs the user walks and stomps, the buildings smash to pieces. Cartoon figures run around and cartoonishly scream.\nKinda macabre sure. Kinda hilarious also. Only possible with a mixed reality headset.\nA one-shot app, that’s all it does. I think it would work.\nOk I admit this isn’t an entirely new concept: I remember once hearing about a Google Maps-style VR app with “Godzilla mode.” I never tried it, I don’t know what it did. I heard people loved it.\nI remember the idea and imagine it anyhow.\nAnyway it’s more about scale and spatiality than stomping buildings.\nA 3D cosmos in your home where you can grab galaxies and set them spinning, or run your hands through stars like sand – that would work too.\nThere was that breakout VR app where you walk the plank 80 storeys in the air. That touches the same nerve but is more about jump scares than laughing.\nWalking like a giant across a tiny forest where all the trees giggle infectiously as you squish them underfoot – I’d play that and show my friends.\nAnyway. Something to figure out, develop and ship in the next checks notes 2 weeks. Yeah maybe not for me though.\nTwo points and I mean them profoundly: don’t take technology too seriously, not even your own; and, how are people going to get it, instantly, no thinking?\n",
    link: "/home/2024/01/16/fart",
  },
  {
    title: "Acts Not Facts #8: clock news, client news, AI, AI, AI, and plans",
    date: "16.20, Friday 19 Jan 2024",
    content:
      "Happy new year!\nSome years I see how long I can feasibly say Happy New Year to people. My record is March. But this year 2023 already feels like months and months ago.\nIt’s the first Acts Not Facts update of the year! Weekly is too frequent. But I’ll write notes periodically and there’s a lot to cover today.\nCountdown to Kickstarter\nMy AI clock is now named Poem/1 and - BIG NEWS - Kickstarter gave the green light to the campaign yesterday. So now I’m getting the last few things lined up before hitting that Launch button.\nMore news over at the AI clock newsletter. tl;dr,\n\nI’ll do a reveal on the industrial design next week\nThe Kickstarter campaign will launch probably the week after…\n…but I want to align it with some press. So if you’re a journalist please get in touch.\n\nOh I missed this media first time around: Bloomberg interviewed Mira Murati, OpenAI’s CTO, and used my clock as the first example. Watch Inside OpenAI by Bloomberg Originals (YouTube, at 3m7s).\nGOV.UK is working with AI to improve the interactions people have with government\nThat client I haven’t been able to name? It’s GOV.UK, the part of UK gov that looks after digital information and services.\nThey started experimenting with AI really early, and built and tested a chat UI for the 700,000 pages of information that they look after. The GOV.UK Chat research findings have now been published. It’s been amazing to watch. There are some unique challenges.\nPersonally I’ve been helping out with “what next”… how should GOV.UK systematically explore AI to build capability and open the imagination, and what is the strategic “why” here? Well, eventually to help transform how people interact with government, sure, but there are stepping stones to be chosen.\nThe new AI Team is announced here by Chris Bellamy, Director of GOV.UK. I’ve been bringing a perspective of design pathfinding, one that I first talked about with the BMJ back in May and then wrote up here in more detail (Dec 2023).\nPlus some heavy advocacy for thinking through making, alongside the research…\nMore to say about all of that another time I’m sure. It’s a privilege working with this smart and motivated team.\nBuilding at PartyKit\nMy mainline client continues to be PartyKit, where I invent in order to stretch and explore their new platform for the realtime, multiplayer internet.\nJust before the holidays PartyKit shipped AI integrations, and I wrote a long piece on the blog:\n\nThe tl;dr is that search got really good suddenly and really easy to build because of AI.\nFor instance, this is the search experience I recently made for my side project website Braggoscope.\n– PartyKit blog, Using Vectorize to build an unreasonably good search engine in 160 lines of code\n\nIt’s a straightforward, show-the-code account of one of the fundamental techniques in building with AI. One reader review: Was reading the Vector DB blog and honestly I think one of the most approachable blogs I’ve seen on the topic + demo – so I’m pleased with that.\nI really enjoyed writing it.\nWhat I find hardest to communicate to people who work with technology, before they use AI, is how much they need to reset their assumptions about how hard things are. e.g. a great search engine is so easy now.\nThe best way to demystify is to go line-by-line. Code isn’t scary.\nAnd there’s no magic here. An embedding model is just a function call, a vector database is just a function call, broadcasting messages to a multiplayer room is a function call, keeping multiplayer state is a function call. All realtime, all scalable, there’s nothing to it.\nActs Not Facts in 2024\nI haven’t sat down and made a year plan for Acts Not Facts, this oh-so-nascent product invention femto-studio of mine. Here’s my off the cuff prompt completion on the matter…\nI would say that I’m roughly where I wanted to be, a year in. As the big Venn on the ANF website says, I’m focused on AI, group experiences, and embodiment. At the end of 2023 I’ve built up a decent portfolio that demonstrates precisely that. Good!\nWhich means the next step is to pick up a team project. Ideally something that involves invention, AI, interactions, and hardware where I get to hire a tiny dream team to deliver.\nLmk if there’s a project we should talk about.\np.s. I have that SF/Bay Area trip coming up w/c 5 Feb. My schedule’s filling up. I’d love to squeeze in a couple more chats.\n",
    link: "/home/2024/01/19/anf",
  },
  {
    title: "Ok it’s happening, my AI clock is happening",
    date: "08.46, Tuesday 23 Jan 2024",
    content:
      "Hey so last year I made an AI clock for my bookshelves. It tells the time with a new poem every minute composed by ChatGPT.\nYeah so my clock ended up featured in the New York Times. And The Verge. The tweet got to almost 6k likes with 845k views. Tons of photos there.\nWELL.\nThe prototype clock lives in my kitchen. It tells me the time; I keep an eye on it. Here’s a poem from the other evening. Just a coincidence. (I hope?)\n\nIn the kitchen, knives at hand / Eight o’clock eight, a gourmet night planned.\n\nThe screen doesn’t glow. It has a handsome e-paper screen with crisp type.\nMostly it’s simply… poetic. This is what I got on my way out of the house today:\n\nIn shadows deep, before the light / 7:19 haunts, the mornings first sight.\n\nIt is sometimes profound! And sometimes really dumb! Then sometimes weird stuff comes up and I take a pic.\nLike, where did this even come from?\n\nIn the desert, where the dunes are vast, / Six forty-two, the sands hold memories of the past.\n\nNow.\nI am someone who will take a gag far far too far and far far FAR too seriously.\nSo I’m manufacturing this thing in China. For real life.\nThe Kickstarter is IMMINENT. Like, next week.\nMy AI clock is now called Poem/1.\nBut nobody know what it looks like.\nYet.\nI’ve been working with the London industrial design studio Approach. Their client list includes Nothing, Google and Logitech.\nI’m going to show you what we’ve come up with, what I’m going to market with, for the first time…\n…tomorrow, Weds 24th.\nOn the mailing list.\n(I understand this is what is called a “drop.”)\nGorgeous renders, clever industrial design details, beautiful e-paper screen and all.\nSo!\nIf you want to be the first to see what Poem/1 looks like, then subscribe here.\np.s. here’s a sunrise to sunset time lapse of my un-designed prototype. Poems flickering by.\nUPDATE 24 Jan:\nIndustrial design first look is here. You’re going to love it.\n",
    link: "/home/2024/01/23/clock",
  },
  {
    title: "Press for Poem/1",
    date: "15.45, Thursday 25 Jan 2024",
    content:
      "I’m using this post to track press and media for Poem/1, my AI rhyming clock.\nAlthough there hasn’t been any! Only for the prototype. So I’m listing all of last year’s press, and then I’ll update this post in the future if required. (When required! When required!)\nIn case you missed my latest shilling, I’m manufacturing this ridiculous clock, Kickstarter gods be willing:\n\nCheck out the industrial design first look. I shared this with 1.5k newsletter subscribers just yesterday.\nThe Kickstarter pre-launch page is now open! Do register your interest in the upcoming campaign over there – 218 followers right now.\n\nThat industrial design update also includes my convoluted theories on AI green… Have you noticed that the canonical colour of AI is green? i.e. the USB-C cable in the box is green. Folks this is what we call Design.\nMedia for the prototype\nOldest first.\nThis clock uses ChatGPT to rhyme / and also help relay the time\nThe Verge (17 Mar 2023)\nShort piece, same day as my original tweet.\n\nIt’s the creation of Matt Webb, who shared it on Twitter. We love it.\n\nThis AI clock uses ChatGPT to generate tiny poems that tell the time\nThe Verge (4 Apr 2023)\nLong feature with interview.\n\nIt uses ChatGPT to create a short two-line rhyme that also tells the time for every minute of the day. It’s incredible and we want one.\n\nAlso a turn of phrase from me:\n\n“Clockwork means you get precision drift; AI-work means you get hallucination drift.”\n\n35 Ways Real People Are Using A.I. Right Now\nThe New York Times (13 Apr 2023)\nProminent mention in longer article.\n\n11. Build a clock that gives you a new poem every minute.\n“Yes, programmatic A.I. is useful,” he said. “But more than that, it’s enormous fun.”\n\nMan claims his AI clock generates a new poem every minute using ChatGPT\nHindustan Times (12 Apr 2023)\nDelightfully sceptical.\n\nThe man took to Twitter to share a post claiming that his AI-powered clock generates a poem every minute using ChatGPT.\nA man’s post about creating an AI-based clock that uses ChatGPT to generate poems has gone viral. …\n\nMan Develops AI Clock That Generates A New Poem Every Minute Using ChatGPT\nNDTV (15 Apr 2023)\nCites The Verge.\n\nNow, a man has created an AI clock that uses ChatGPT to create tiny poems to tell time.\n\nFunny Old World\nPrivate Eye (no. 1597, 5 May 2023)\nPrint only. Reproduces the NDTV story as sent in by a reader. (I posted it on Insta, appearing in the Eye is a career high.)\n\nSPOTTED a bizarre but true news story from your corner of the globe? … £20 paid for all entries used.\n\nInside OpenAI, the Architect of ChatGPT, featuring Mira Murati\nBloomberg Originals (16 Jun 2023)\nAppears in video interview with Mira Murati, OpenAI CTO, in The Circuit with Emily Chang on YouTube (3m05s).\nMy clock tweet is the first illustration for this first question:\n\nChang: Did that surprise you? I mean what you your reaction to the world’s reaction?\nMurati: We were surprised by how much it captured the imaginations of the general public and how much people just loved spending time talking to this AI system and interaction with it.\n\nThanks all!\nMedia for Poem/1\nNone. Let’s be hopeful. None yet!\nI am so grateful for any coverage. Especially when the Kickstarter campaign launches next week, exact date TBA. It’ll be a marathon I’m sure. I am available for podcasts, opportunist soundbites, breakfast TV, internal talks and marriages and garden parties.\n",
    link: "/home/2024/01/25/media",
  },
  {
    title: "Thinking about the emerging landscape of AI hardware products",
    date: "18.16, Friday 26 Jan 2024",
    content:
      "I’ve been looking at the landscape of AI hardware products. Will the future be more like voice assistants that we talk to, or more like… well, something else?\nSee, there’s been a flurry of AI hardware in consumer product.\nAssistants.\nTwo products aim to be your smartphone replacement:\n\nRabbit r1 (Fast Company) – a bright orange handheld with screen, a rotating camera, a big walkie talkie button, and a lovely fidget device scroll wheel. Rabbit OS interacts with apps on your behalf when you talk to it.\nHumane AI Pin (The Verge) – a wearable microphone plus  world camera worn as a badge. It does whatever you ask re: what you’re looking at, and output results with a super futuristic green laser projector (that somehow also looks retro).\n\nIf iPad was dismissed as a “consumption device” versus general purpose computing devices, these are both “service devices”. They’re made for ordering cabs, booking restaurants, and automating sequenceable knowledge work tasks.\n(btw I am not super into the Humane AI Pin overall but I do wish my phone had a green laser projector that I could play with. So, so good.)\nTwo other wearables:\n\nRay-Ban Meta smart glasses (The Verge). This product is primarily for photos and stream, but the new AI features let you ask questions about what you’re seeing: how do I get to X, how many calories in my lunch, where do I buy that bag.\nTab AI (Fast Company) is a necklace with a mic that you talk to. A chatbot: What I’m trying to do is create a new relationship in your life; radical transparency without concern of judgment. I think this is a relationship people used to have with God but is lacking in the modern world.\n\nI am into the ambition and experimentation here!\nAnd, no, “AI hardware” is not a product category, in the same way that voice assistants like Amazon Echo aren’t really a category. You don’t buy them to be a voice assistant, you buy them to be a kitchen timer or to play music or whatever. A “smart speaker” is a speaker.\nYet these are all assistants in one way or another. Playing with the form factor or the way it fits into your life.\nSo that’s potentially one end of the AI hardware spectrum.\nNon-assistants.\nThen there is AI hardware without any kind of assistant.\nWhere the AI enables some other feature. The AI isn’t on the surface as the user interface, it’s deep inside, embedded.\nOk, back to 2018:\n\nGoogle Clips smart camera. Not point-and-click (that was a camera category once upon a time) but always-on. You stand this small square camera on a shelf at a party and it takes 15 photos per second… selecting and retaining only the good ones, thanks to its on-device real-time AI. Like a domesticated GoPro plus a robot photo editor, all in one.\n\nClips didn’t do so well – it’s almost impossible to invent new categories.\nBut I’m using it to illustrate this embedded AI end of the spectrum. (And the fact that Google did it on-device 6 years ago shows how long they’ve been ahead with AI, even if that’s not quite so apparent today.)\nA typology of AI hardware features.\nTo tease this space out a little further, assistants bundle together two separate AI-enabled features: new user interfaces, and new agentive (tool using) abilities.\nSo I think we have a triangle (ternary diagrams have been on my mind).\n\nAI-enabled user interfaces, like voice or computer vision\nBehind-the-scenes agentive AI, like figuring out sequencing from your instructions, or using apps as tools\nEmbedded AI to enable a feature, like “interesting scene” detection in a camera\n\nYou could draw a triangular landscape between these extremes. All the products I’ve mentioned could be plotted somewhere inside.\nExercise for the reader: find the gaps and invent new products like planting flowers…\nEmbedded AI.\nMe, I’m most interested when AI isn’t an assistant.\nThe argument goes like this…\nMoore’s Law cuts both ways:\n\nIf computers get 100 times more powerful over a decade, we can EQUIVALENTLY say that computers get: 100 times smaller; or 100 times cheaper; or 100 times more abundant.\n\nThis is what I’ve previously called intelligence too cheap to meter – and what does it mean to have GPT-4-level intelligence in any light switch, or behind every menu command in your notes app, or your cat’s collar, or in your shoes, or quietly doing its job as a software universal coupling or whatever?\nUbiquitous, embedded AI.\nI called it fractional artificial intelligence back in 2012:\n\nWe can be frivolous with mathematics, throw it around like confetti.\n\nSo I didn’t mean “fractional” as in dumb; only dumb compared to the giant planet brains owned by Big AI. I meant… small and everywhere. \nI had no idea in 2012 what the implications of intelligence too cheap to meter would be, and I have no idea now.\nBut I’m interested!\nBack to the poetry clock, of course.\n“Embedded AI” is the territory that I’m playing in with my rhyming clock.\nObligatory plug: the Kickstarter pre-launch page has just opened! Go register your interest in Poem/1! Telling the time with a new poem every minute, composed by ChatGPT, and a gorgeous e-paper screen! You’ll get a notification as soon as the campaign opens next week.\nThe AI clock isn’t an assistant; it doesn’t have agentive capabilities to use tools and do general purpose problem solving. It doesn’t respond to your presence or requests or really any context at all except the time.\nIt’s an appliance.\nAn AI-ppliance. (Sorry.)\nFor all of it being “simply an appliance,” it’s weird to be in the same room and hang out, let me tell you.\nWe are not accustomed to things like rhyming couplets emerging from a machine poet. Poems are not used decoratively, except made in cross-stitch and hung on the wall. And yet! Here we are!\nI think, with the poetry clock, it’s ambiguous whether there’s AI involved at all. A human could quite possibly write a whole day of poems, one for every minute, and then display them on a loop. It’s only the sheer infinity of it that gives it away, and you only really appreciate that, deep down, after living with it.\nIt’s sort of human (but the words aren’t as good as a human poet would write), sort of alien (it has inhuman endurance).\nI think there will be a lot of this.\nInsane AI, planetary compute, used for really, really mundane things.\nSharing our planet with machine entities.\nThere’s a great interview with Stanley Kubrick about the movie 2001: A Space Odyssey (previous discussed in 2014).\n\nOne of the things we were trying to convey in this part of the film is the reality of a world populated - as ours soon will be - by machine entities who have as much, or more, intelligence as human beings, and who have the same emotional potentialities in their personalities as human beings.\n– Joseph Gelmis, An Interview with Stanley Kubrick (1969)\n\nAnd:\n\nWe wanted to stimulate people to think what it would be like to share a planet with such creatures.\n\nYES!\nBUT!\nI wonder whether the reality of a world populated with AI is not so much about listening, watching, speaking, laser-projecting entities, assistants in our pockets and hanging on necklaces and our every word - not JARVIS or HAL 9000 or Samantha or Joshua - but instead a trillion extremely mundane, genius-level, nameless embedded intelligences, squirrelling away, hidden inside everything?\nAnd how will that work, practically? How will that technology be developed, managed, maintained, secured, networked, owned, shared and made equitable?\nAnd how will it feel to live there?\n",
    link: "/home/2024/01/26/hardware",
  },
  {
    title:
      "A dog that says sausages and other milestones in interspecies communication",
    date: "17.36, Wednesday 4 Jan 2023",
    content:
      "You can tell that we’re going to end up talking with cats and dogs.\nYou know how there were tricorders in Star Trek and then, decades later, we got iPhones?\nIf there were a scale for Cultural readiness level to parallel Nasa’s Technological readiness level, where TRL 1 is Basic principles observed and TRL 9 is competitive manufacturing, then CRL 1 would be “in fiction” – Star Trek basically.\nAnd CRL 2 would be “on TikTok” – making its way up the scale.\nAnyway so there’s a talking dog on TikTok.\nIt doesn’t really talk. It uses “Dog Buttons”: big plastic buttons that your dog can push with its paws, and a voice says a word, so the dog can say Kenny want treat or whatever.\nThis technique pioneered (I understand) by speech-language pathologist Christine Hunger and her dog Stella. Their story:\n\nSince dogs can understand words, could Stella use an AAC [Augmentative and Alternative Communication] device to express herself the same way my patients did?\n\n(That link has videos.)\nThe dog can now express 45 words with combinations of up to 5 words. (More over at the Guardian (2020).)\nHunger’s site also has a shop where you can buy (a) their book, and (b) Dog Buttons.\nCRL 3 would be where the technology appears on Amazon. Here’s a comparison shopping guide to the best:\n\nlight-up dog buttons\npotty buttons\ndog button training programs\n\nThis is dumb, right? It’s just a soundboard being used so your dog can call you from across the house? It’s no different from tricks like roll over or shake hands?\nWell. Kinda. Maybe.\nBUT: cultural readiness.\nCultural desire creates the conditions for future technology research and development. And now we have AI… well if AIs can do protein folding then why not barks and yelps to English?\nTANGENTIALLY:\n\nThat time this guy I know’s cat figured out how to get him to open the front door utilising the Bitcoin network\nThat time when jazz legend Charles Mingus taught his cat how to sit on the seat and use the indoor loo, and wrote a book about it\nThat time in 1973 where the BBC TV show That’s Life! famously broadcast a dog that could say sausages and it turns out that the dog was discovered and filmed by a then-young avant-garde conspiracist film-maker Adam Curtis\nIt turns out there is a sequel to 101 Dalmatians and it is wild. The Starlight Barking: after a strange euphoric moment followed by a moment of terror, Sirius, the Lord of the Dog Star, appears on Nelson’s Column. He explains to all the dogs that he is lonely and is offering them the chance to avoid the pain of possible nuclear war in the future.\n\nOk.\nCultural readiness is one thing. Technology is another.\nAND SO:\nThere are already organisations researching AI to speak with whales and animals generally:\n\nProject CETI is applying advanced machine learning and gentle robotics to listen to and translate the communication of sperm whales. – the current milestone on the scientific roadmap is to gather training data in the form of whale behaviour and vocalisations\nEarth Species Project is aiming to use a new machine learning technique that could learn a geometric representation of an entire language to translate between the latent space of English and the latent space of, say, corvids. Current research includes how to synthesise vocalisations of crows and humpback whales.\n\nThe New York Times covers the projects of each in more detail – the goal is ambitious:\n\n“Let’s try to find a Google Translate for animals,” said Diana Reiss, an expert on dolphin cognition and communication at Hunter College and co-founder of Interspecies Internet, a think tank devoted to facilitating cross-species communication.\n– New York Times, The Animal Translators (2022)\n\n(Paywall-busting link here. Read the whole thing.)\nProject CETI is planning to use a 28 underwater microphones and AV-enabled robot fish to record whales acoustics.\n\n“Every which way we turn there’s another question,” said David Gruber, a marine biologist at Baruch College who leads Project CETI. “If there was a big event that happened a week ago, how would we know that they’re still communicating about it? Do whales do mathematics?”\n\nAnd, on a species of crow which is at risk of extinction:\n\n“They keep them in these aviaries to breed birds for future releases. But what if these crows no longer know how to speak crow?”\n\nSo how long do we give it before this technology is a reality – 20 years? 30 years? The bottleneck does seem to be recording training data, for the moment.\nObjection #1 is that focusing on acoustics seems a bit… human-provincial maybe? Like: dogs have great capacity to smell and to, uh, generate smell. Won’t that be as much part of that vocabulary as anything else? Or whales: perhaps cetaceans speak in water vortices as much as clicks and whistles.\nMore training data required, I suspect.\nMaybe in this respect cheap, lo-fi electronic Dog Buttons are better than AI whale-song, in that they create a new trading language instead of interpreting existing sounds?\nThis was the goal of CHAT by the Wild Dolphin Project or this underwater keyboard at Epcot in Florida, also for human-dolphin communication.\nPerhaps we’ll end up having to co-create new languages.\nObjection #2 is that, well, we already speak with animals, as anyone who hangs out with animals knows.\nThere is very little misunderstanding when my cat speaks to me or I speak to my cat, for example.\nHOWEVER:\nSome people can speak Chinese. I can’t. When Google Translate came along, suddenly we were able to email directly with factories in Shenzhen and speak - through copy-and-pasted green text machine translation - with reps on the floor instead of via agents. It unlocked manufacturing for us, a small design firm in London in the early 2010s.\nSo I wonder what the parallel is? Strangers!\nIt would be great to be able to speak with dogs, cats, and crows in their native languages, without having to co-create languages.\nSure, me and my cat live together and so we’ve figured out how to have a conversation – she’s silent much of the time. Do cats gossip? That’s what us humans fill the time with.\nBut in species with low cultural transmission, where learnt languages can’t be passed on, native tongue translation would mean I could talk with non-human strangers.\nWouldn’t it be great to say hi to a dozing dog on the street and mutually give appreciation to the hot sun?\nOr spot a crow on the wall, and ask it if it knows the way to the nearest train station, or a coffee shop, and so on?\n",
    link: "/home/2023/01/04/interspecies",
  },
  {
    title: "Is AI sentient and is it even useful to ask?",
    date: "15.47, Monday 9 Jan 2023",
    content:
      "June 2022. Blake Lemoine, an engineer at Google, claims that their new AI is sentient and is fired (The Verge).\nAlthough, not quite. You can piece what actually happened from Lemoine’s own contemporary Medium article and the subsequent Washington Post piece [no paywall]: Lemoine shared a doc around Google titled “Is LaMDA Sentient?” (LaMDA is the name of the AI, a large language model like GPT-3) – a colleague said this was a bit provocative. He started to speak with people outside the company and was placed on disciplinary leave for violating confidentiality. Lemoine upped the ante, inviting a lawyer to represent LaMDA, and then you’re kinda done I reckon. But the point is that the question was asked.\nCan an AI be sentient?\nAre there already sentient AIs, and if not now then when? 1,000 years from now? Surely. 100 years? Probably. So 10 years? Maybe. How about 2025? Tomorrow?\nHow could we tell?\nWould it matter?\nI’m going to muddle sentience and consciousness here because I don’t want to get lost in definitions.\nWikipedia’s article on Sentience cites philosopher Antonio Damasio and says that sentience is a minimalistic way of defining consciousness and limits it to the capacity to feel sensations and emotions.\nAccording to this view: consciousness = sentience + creativity + intelligence + sapience + self-awareness + intentionality + more.\nI’d prefer to say that our terms are ill-defined, and that consciousnesses may have all kinds of different characteristics, and may be a matter of degree.\nSo let’s enlarge the question, and agree to come back to pinning down terms later: can an AI be conscious?\n2017. Philosopher Susan Schneider proposes ACT: the AI Consciousness Test.\nThe idea is that consciousness is something that is felt: we can all experience what it feels like, from the inside, to exist.\nSo the question for ACT is whether the synthetic minds we create have an experience-based understanding of the way it feels, from the inside, to be conscious.\ni.e. do AIs feel the same as we do?\nThe proposed test is a series of questions.\n\nThus, the ACT would challenge an AI with a series of increasingly demanding natural language interactions to see how quickly and readily it can grasp and use concepts and scenarios based on the internal experiences we associate with consciousness. At the most elementary level we might simply ask the machine if it conceives of itself as anything other than its physical self. At a more advanced level, we might see how it deals with ideas and scenarios such as those mentioned in the previous paragraph. At an advanced level, its ability to reason about and discuss philosophical questions such as “the hard problem of consciousness” would be evaluated. At the most demanding level, we might see if the machine invents and uses such a consciousness-based concept on its own, without relying on human ideas and inputs.\n– Scientific American, Is Anyone Home? A Way to Find Out If AI Has Become Self-Aware (2017)\n\n(Article by Susan Schneider and Edwin Turner.)\nOne problem - as with GPT-3/ChatGPT - is that large language models are extraordinary mimics. So maybe they just say the right stuff to pass the test.\nSchneider’s suggestion is to “box in” the AI away from human culture until we’ve tested it against the ACT, so it can’t make guesses.\nI don’t know. I’m more convinced by the “quickly and readily” component of ACT. Surely there are some puzzles that are quicker to deduce if you have self-awareness? Dunno.\nThe AI Consciousness Test is one in a long line of tests for machine intelligence, such as the Turing Test.\n2020. There’s a solid critique of ACT in this paper by David Udell and Eric Schwitzgebel, Susan Schneider’s Proposed Tests for AI Consciousness: Promising but Flawed (PDF at that link).\nThe challenge is that there’s always going to be a lower-level explanation of how the AI is answering questions on the silicon substrate (a giant lookup table, matrix maths, whatever), and that no series of questions is going to be sufficient to convince people that there is genuine machine consciousness at a higher level too.\nOne for the philosophers.\nBut Udell & Schitzgebel are articulate on the urgency of finessing ACT or something ACT-like:\n\nAI consciousness, despite its present science-fictional air, may soon become an urgent practical issue. Within the next few decades, engineers might develop AI systems that some people, rightly or wrongly, claim have conscious experiences like ours. We will then face the question of whether such AI systems would deserve moral consideration akin to that we give to people. There is already an emerging ‘robot rights’ movement which would surely be energized by plausible claims of robot consciousness (Schwitzgebel and Garza 2015; Gunkel 2018; Ziesche and Yampolskiy 2019). So we need to think seriously in advance about how to test for consciousness among apparently conscious machines …\n– David Billy Udell and Eric Schwitzgebel, Susan Schneider’s Proposed Tests for AI Consciousness: Promising but Flawed (2020)\n\nSchneider, in her Scientific American piece above, broadens the urgency to brain implants:\n\nmachine consciousness could impact the viability of brain-implant technologies, like those to be developed by Elon Musk’s new company, Neuralink. If AI cannot be conscious, then the parts of the brain responsible for consciousness could not be replaced with chips without causing a loss of consciousness. And, in a similar vein, a person couldn’t upload their brain to a computer to avoid death because that upload wouldn’t be a conscious being.\n\nConsciousness is hard hey.\nConsciousness is weird.\nLet’s say that we agree that a silicon substrate can host consciousness.\nOr that a group of organic cells, properly arranged etc, can host consciousness.\nThere is a slippery slope…\nEric Schwitzgebel again:\nThe United States is literally, like you, phenomenally conscious. That is, the United States literally possesses a stream of experiences over and above the experiences of its members considered individually.\n\nIf you’re a materialist, you probably think that rabbits have conscious experiences. And you ought to think that. After all, rabbits are a lot like us, biologically and neurophysiologically.\nIf you’re a materialist, you probably also think that conscious experience would be present in a wide range of naturally evolved alien beings behaviorally very similar to us even if they are physiologically very different. And you ought to think that. After all, it would be insupportable Earthly chauvinism to deny consciousness to alien species behaviorally very similar to us, even if they are physiologically different.\nBut, I will argue, a materialist who accepts consciousness in hypothetical weirdly formed aliens ought also to accept consciousness in spatially distributed group entities. If you then also accept rabbit consciousness, you ought also accept the possibility of consciousness in rather dumb group entities.\nFinally, the United States is a rather dumb group entity of the relevant sort (or maybe even it’s rather smart, but that’s more than I need for my argument).\nIf we set aside our prejudices against spatially distributed group entities, we can see that the United States has all the types of properties that materialists normally regard as indicative of consciousness.\n– Eric Schwitzgebel, The Weirdness of the World (2021)\n\n(I’ve added paragraph breaks.)\nSchwitzgebel asks us to take the perspective of a consciousness entity which is much larger than us humans:\n\nA planet-sized alien who squints might see the United States as a single, diffuse entity consuming bananas and automobiles, wiring up communication systems, touching the Moon, and regulating its smoggy exhalations – an entity that can be evaluated for the presence or absence of consciousness.\n\n…and the rest of the chapter goes on to show convincingly that, yes, even if the USA isn’t conscious, it’s worthy of being evaluated.\n(Do we need Schneider to write the USACT?)\nThis is perilously close to panpsychism, the view that the mind or a mindlike aspect is a fundamental and ubiquitous feature of reality.\nWe are conscious. My cat is conscious, although differently. Asteroids is conscious; AI is conscious, why not. Mud is conscious; a stellar nebula has its own nebula-like conscious. (Olaf Stapledon, in Star Maker, way back in 1937, wrote beautifully and poignantly about the culture of gas cloud megatheria at the dawn of the cosmos.)\nWhat’s the alternative?\nMaybe silicon can’t be conscious.\nMaybe GPT-4, GPT-5, GPT-N, no matter how convincing, will be an AI p-zombie, a hypothetical being that is physically identical to and indistinguishable from a normal person but does not have conscious experience, qualia, or sentience.\nWhich implies there’s a cut-off somewhere. And I’m not happy with that either – I’m not ready to declare that my cat isn’t conscious, in her own cat way.\nEverything is conscious.\nOr nothing is conscious – except me. I’m not so sure about you.\nNeither seems satisfying. Or useful?\nBack to Eric Schwitzgebel, his paper (and forthcoming book) The Weirdness of the World, and the consciousness or otherwise of the USA…\nSchwitzgebel asked philosopher Daniel Dennett, and he replied:\n\nTo the extent that the United States is radically unlike human beings, it’s unhelpful to ascribe consciousness to it. Its behavior is impoverished compared to ours and its functional architecture is radically unlike our own. Ascribing consciousness to the United States is not as much straightforwardly false is it is misleading. It invites the reader to too closely assimilate human architecture and group architecture.\n\nAnd I like this approach, in a general sense, because it acknowledges the perspective from which we’re asking the question - being human - and therefore implicitly accepts that there will be other perspectives which have different answers.\nThe question is not: do we have conscious AIs?\nIt is more like: from our perspective, is there a non-misleading distinction between non-conscious AI and hypothetical conscious AI, and do we have conscious AIs in that sense?\nAND THEN:\nIf an AI were to pass an AI Consciousness Test, in the non-misleading sense above, would it make any difference?\nUdell & Schwitzgebel’s argument is that it’s meaningful in terms of robot rights.\nBut chickens have chicken-consciousness and we industrialise their growth and kill and eat them. Maybe the implication is that we ought to feel more gratitude when eating meat - if we eat meat at all - and that it’s poisonous to us to ignore that.\nOr maybe they don’t have chicken-consciousness! Arguably we shouldn’t be treating chickens like we do in any case. It’s hard to imagine that we would treat them any worse even if we were certain they were lumps of 100% unthinking rock.\nThe point is that it’s not a question we really engage with, as a society. Maybe when it comes up with AI we collectively won’t care then, either.\nSo, for me, asking about AI consciousness is a way to winkle out these other questions.\nYes it’s important that we know when, in 50 years or 5 years, the machines wake up and we meet the first conscious AI. But if we then vary in our treatment of that AI, we’ll then have to ask what’s different about chickens, talking dogs, the Whanganui River in New Zealand which was granted legal personhood (BBC, 2017), the first uploaded nervous system - the open source OpenWorm virtual nemotode project - the entire USA as a conscious entity, and well, each other.\nDefinitely useful questions to ask.\n",
    link: "/home/2023/01/09/act",
  },
  {
    title: "Let’s take hip-hop ovens to CES 2024",
    date: "19.09, Tuesday 10 Jan 2023",
    content:
      "You gotta have a gimmick, and to my mind the best gimmick is jazz-infused smoked salmon.\nThere used to be a salmon smokery in north London. Aside from the juniper and beech wood, Ole Hansen (proprietor) would, once a day, sit down and play piano to the hanging fish – live jazz and occasional singing.\nWatch: Michel Roux Jr meets Hansen & Lydersen (YouTube).\nI argue that the sound waves penetrate the flesh of the fish and it goes in and it just gives and it enriches, he says.\nI found out about jazz-infused smoked salmon a few years back from a TV show about the world’s most expensive foods.\nIt’s such a good gimmick! The story was everywhere for a few years with Hansen playing his jazz. It would be a great story to tell your dinner guests.\nAnd that’s fine, right? Taste is some % psychological. Red wine tastes better if you know it’s an expensive bottle. Same same, I’m ok with that.\nBut I don’t suppose the bebop energies actually live in the memory of the fish molecules and transmit to your boogie-woogie taste bugs or whatever. Or maybe?\n(Btw another of the world’s most expensive foods is a kind of barnacle which is so hard to gather that a number of the people gathering it… die? Every year? And this is part of how it’s marketed? For avoidance of doubt this is a terrible, terrible gimmick.)\nAnyway, Swiss cheese tastes better when aged with hip-hop.\n\nLast September, Swiss cheesemaker Beat Wampfler and a team of researchers from the Bern University of Arts placed nine 22-pound wheels of Emmental cheese in individual wooden crates in Wampfler’s cheese cellar. Then, for the next six months each cheese was exposed to an endless, 24-hour loop of one song using a mini-transducer, which directed the sound waves directly into the cheese wheels.\n– Smithsonian Magazine, Scientists Played Music to Cheese as It Aged. Hip-Hop Produced the Funkiest Flavor (2019)\n\nSix months of “Jazz (We’ve Got)” by A Tribe Called Quest.\n\nthe cheese exposed to music had a milder flavor compared to the non-musical cheese \n\nAnd:\n\nhip-hop cheese had a stronger aroma and stronger flavor than other samples.\n\nAnd:\n\nThe cheeses were then sampled by a jury of culinary experts during two rounds of a blind taste test.\n\nAnd:\n\nthe hip-hop cheese came out on top.\n\nYou can’t argue with science.\nWell you can but let’s not.\nHere’s the website (in German) and the press release (in English).\nLook: something something ultrasonics influencing bacterial growth during cheese aging something something.\nUm:\n\nCheez-It has teamed up with streaming music site Pandora to create what they are billing as “the first-ever sonically-aged cheese snack” in the form of limited-edition Cheez-It x Pandora Aged by Audio crackers.\n\nThe cheese used to make the crackers was aged for six and a half months using a whole hip-hop playlist. Congrats to whichever agency pitched that. Food & Wine, May 2022.\nIt is easy to mock.\nBUT, rather than lazily disbelieve,\nit almost feels truer to say that vibe propagates in a multimodal fashion through the world by mechanisms yet unknown. And I am kinda down with it? It is a more accurate description of the universe that I inhabit than a claim that vibe does not propagate?\nLet’s just be open to all of the above.\nAnd then let’s consumerise the emerging science of vibe gastroacoustics and take it to CES 2024.\nBecause it seems like there is a new fad oven every year or two… George Foreman grill. Instant Pot. Air fryers. And we can get in on that.\nSo let me propose a new Samsung oven with integrated proving drawer and Spotify built right in.\nAnd a recipe book, just like microwaves used to ship with microwave-specific recipes. For example:\nHans Zimmer long-fermented sourdough.\nTechno-washed micro herbs.\nR&Beef.\n",
    link: "/home/2023/01/10/salmon",
  },
  {
    title: "Looking for new projects or even a long-term something for 2023",
    date: "16.37, Thursday 12 Jan 2023",
    content:
      "I’m looking for new collabs and projects for 2023 – also, potentially, something long-term.\nThe most interesting stuff tends to be invisible and I’m not 100% sure what the destination looks like so this post is an attempt to prompt engineer my way there…\n2022\nI split my time 80/20 last year. I’ve been heading up product and design at a super early stage startup. We focused down on the social, spatial web - all small groups and NPCs - and I had some of the most satisfying months of my career in product exploration with Ed, Florian, and Andrew.\nIt was a joy to both steer and also rediscover my practice in sketching and code – it’s always a kick to bounce between the high level (strategic or speculative) and the hands-on of spreadsheets, Keynote prototypes, writing React…\nThat has wrapped up for now. So I have room for new things in the mix.\nI also continued my consultant editor role within Google Research, editing and writing our internal publication on AI, and it continues to be eye-opening and mind-fizzy. I’m very happy about some of the directions we pointed in.\nInterests rn\nSkimming back many years over my LinkedIn I alternate between creating environments for others to push technology forward (like establishing and running the first London accelerators for R/GA Ventures) and bringing my own interests to bear. I find both rewarding and (one day) would love to find a way to bridge the two.\nRight now I’m especially interested in a few domains, familiar to anyone who has been reading this blog…\n\nMultiplayer software - small groups - social gradients - serendipity - NPCs\nAI - new interactions - new tools - cognition - history of computing\nTools for thought - adaptive design - programmability and composability\nPhysical computing - environments - hardware - glanceability - cyborgs\nThe meta: why don’t we have packed-switched drone networks - how can collaborations be catalysed - what makes teams embrace risk to invent\n\nI enjoy operating around product, design, vision, exploration, process, leadership, direction, and pathfinding; generally when the problem space is uncertain and complex, taking things from nothing to BAU.\nLook this is a fuzzy prompt but hopefully you get the idea.\nWLTM\nI don’t have a definite org size in mind. A small multidisciplinary team would catch my eye. But whether that’s a small-ish startup, or R&D somewhere bigger, or spinning up something new in another way, I don’t have a specific picture in my head.\nI’d be especially interested to speak with large orgs. I haven’t done that before and I’d like to explore how that could work.\nLike I said, I’m curious about a long-term role and also shorter projects (for example I really enjoyed the Action Cat collab in December).\nI live in London. Remote-first is good too, as is some travel.\nContact\nI’d like to have a whole bunch of conversations! Please do email or book a call – and share this folks you know who seem like fellow travellers.\nThanks :)\n",
    link: "/home/2023/01/12/next",
  },
  {
    title: "Filtered for ants and laws",
    date: "21.20, Tuesday 17 Jan 2023",
    content:
      "1.\nLet’s say we could chat with ants. Could we trade with them? What would we want from them?\nRead: We don’t trade with ants (Katja Grace).\nOstensibly this is a post critiquing the idea that super intelligent AIs would have nothing to do with humans. But actually it is an awesome list of things that we should be asking ants to do.\nFOR EXAMPLE:\n\nCleaning things that are hard for humans to reach (crevices, buildup in pipes, outsides of tall buildings)\nDigging tunnels (e.g. instead of digging up your garden to lay a pipe, maybe ants could dig the hole, then a flexible pipe could be pushed through it)\nParticipating in war (attack, guerilla attack, sabotage, intelligence)\nProducing and delivering nitrogen to plants\n\nIt’s a big list! And we could pay them!\n\nA single ant eats about 2mg per day according to a random website, so you could support a colony of a million ants with 2kg of food per day. Supposing they accepted pay in sugar, or something similarly expensive, 2kg costs around $3. Perhaps you would need to pay them more than subsistence to attract them away from foraging freely, since apparently food-gathering ants usually collect more than they eat, to support others in their colony. So let’s guess $5.\nMy guess is that a million ants could do well over $5 of the above labors in a day.\n– Katja Grace, We don’t trade with ants\n\nThe argument is that we don’t trade with ants because we can’t communicate with them… but interspecies communication is an active field of study now?\nNo, I think the big problem will be that legal system only works for humans.\nHow do you hold an ant accountable if they fail to deliver on a contract? Do individual ants even have agency? Can we require an ant colony to purchase public indemnity insurance?\nPREVIOUSLY: Animals driving cars and other jobs (2021).\n2.\nLet’s say you want to to stop eating cows and chickens, and instead eat insect-derived protein, e.g. from mealworms (which is a thing which has recently been approved).\nIs that ok?\nFrom a moral perspective, perhaps not: I Will Not Eat The Bugs (Astral Star Codex).\n\nIn order to produce a kilogram of bug-based food, you need about 10,000 bugs (mealworms weigh about 100 mg). On the one hand, bugs probably don’t matter much morally. On the other hand, 10,000 is a lot.\n\nIt adds up.\nRisk: even if there’s only a 50-50 chance insects have moral value, or a 1% chance, still seems like you should avoid factory-farming and killing ten trillion of them, which is about how many we currently farm.\n10 trillion tiny souls sure adds up.\nMoral calculus: 10 billion kg of chicken is consumed in the US every year. If that were replaced by mealworm protein, is that better or worse? What’s the karmic exchange rate between birds and bugs? How does their moral worth compound?\n3.\nHere’s a cracking paper: Corporate insecthood.\nIn short: people treat almost everything as people, at least a bit, including companies.\n\nPeople readily find humanity in the unlikeliest of places, from frogs to gods to gusts of wind, a phenomenon known as anthropomorphization.\n… empirical work indicates that corporations are afforded at least some of the features of persons. People spontaneously attribute mental states to corporations, particularly agency.\n\nBut it hasn’t been studied.\n\nWe are given little sense of how these whiffs of personhood stack up against other entities: How does Google’s personhood compare with a fetus, a robot, a tree?\n\nSo they studied it!\n“Personhood” for the purposes of this study includes characteristics like self-awareness, moral rights, humanness, etc.\nI URGE YOU GREATLY to check out the diagram on page 6 of the PDF.\nSome highlights so you get the gist.\n\n100 (max personhood): Infant and adult\n66: dolphin\n50: deceased man\n35: robot\n31.5: bird\n30: Disney\n20: ant and Amazon\n8.5: microbe\n2.5: computer and Exxon\n0: rock\n\nPersonhood is a spectrum!\nAt least in the folk understanding, that’s what this study reveals; that’s our felt morality.\nAnd I would say that our laws ought to be downstream of our moral frameworks, right? So our legal system should handle fractional personhood too. Somehow.\nRef.\nStrohminger, N., & Jordan, M. (2022). Corporate Insecthood. PsyArXiv. https://doi.org/10.31234/osf.io/rxkhe\n4.\nFrom The History of Magic, which I read last year, a special court in Ancient Greece for holding accountable lifeless things:\n\nThat statues were seen to act on their own might be seen as fanciful were it not for well-known instances. Theagenes of Thasos was an athlete. Part of his demonstration of strength was to carry a very heavy bronze statue from the marketplace to his house and back again. After Theagenes died a bronze statue of him was put up. An enemy of his took to flogging this statue at night, as a substitute for hitting Theagenes himself. The statue ended this practice by falling on the man and killing him. The statue was then tried for murder in a special court, the Prytaneum, reserved for the trial of what we would see as inanimate objects, although clearly the Greeks did not place the boundaries between living and lifeless where we do. The statue was found guilty and ordered into exile, which, in its case meant it was thrown into the sea.\n– Chris Gosden, The History of Magic\n\nI read a paper that also mentions this: The Prosecution of Lifeless Things and Animals in Greek Law: Part I.\nFar from being a quirky hey let’s take a statue to court, it seems that lifeless things and animals were regularly put on trial.\n\nOne of the important features of the Prytaneum was the curious murder process held in its immediate neighborhood. … In the first place, if a murderer was unknown or could not be found, he was nevertheless tried; also lifeless things, such as stones, beams, pieces of iron, etc., which had caused the death of a man by falling upon him, were tried here, as well as animals which had similarly been the cause of death.\n\nimo it’s not quite as the book says, a belief that statues can act on their own.\nRather the underlying view seems a bit like root cause analysis in engineering where you keep on asking why.\nHere the mechanism is that if a crime is committed, then it must be resolved.\n\n…if the human murderer could not be found, the thing or animal that had been the agent in the slaying, if it could be found, had to be tried. For the idea was that, in case of a murder, not only a crime had been committed, but also a pollution had been caused in the community and some person or thing was to blame and must be punished to rid the state of defilement.\n\nWhich makes sense!\nSo while we, in the 21st century, are tying ourselves in knots trying to figure out the appropriate remedy when civil unrest caused by a social media app leads to deaths, maybe in Athens how ever many millennia ago they simply would have sunk a few of the servers in the Aegean.\nI don’t know what the process is for requesting that we have a revolution in philosophy that upgrades the foundations of our moral frameworks to make them fit for purpose in the 20XXs, somehow incorporating fractional personhood and agency of the lifeless too, cascading into upgrades for our constitutions and legal principles, but I feel like I need to file a ticket.\nRef.\nHyde, W. W. (1917). The Prosecution of Lifeless Things and Animals in Greek Law: Part I. The American Journal of Philology, 38(2), 152-175. https://doi.org/10.2307/289180\n",
    link: "/home/2023/01/17/filtered",
  },
  {
    title:
      "The map room is a physical room-size wiki for collaboration from the 1950s",
    date: "19.22, Friday 20 Jan 2023",
    content:
      "There’s an idea from the 1950s about physical rooms and index cards for shared context and collaboration.\nAnd thinking about how to make a modern version gets me thinking about room-scale group use computers, and what kind of interfaces we’ll need.\nNo conclusions today, but thinking out loud…\nThe map room is a physical multiplayer learning machine\nConsider a room!\nIt’s 1954 (or 1955) and a group of disciplines are working together on a complicated decade-long regional development plan for the Hacienda Vicos community in Peru. Represented: anthropology, economics, political science, and psychology.\nHow do they find a common vocabulary? How do they share data and ideas? How do they plan action?\nEnter the map room.\n\nwhose walls contained a large matrix with the time (in years) on the ordinate and with the “variables” the group was interested in along the abscissa.\n\nHere’s the paper: Administration of Research in a Research Corporation by Kennedy & Putt, RAND Corporation Report No. P-847, April 20, 1956.\n(It’s an important paper, and I’ll say why later.)\nVariables, and index cards:\n\n130 variables, grouped under “government,” “economics,” “social relations,” “education and mass media,” “health and welfare,” and “attitudes.” There were spaces for three-by-five cards for each of ten years under each variable. The entire matrix thus could hold 1,300 cards that summarized the value of the variable in the past or described its desired value for the future. At the top of each column was a description of the value of the variable “in the best of all possible worlds” and a statement of the value anticipated or desired at the end of the ten-year experimental period (1951-1961).\n\nData and planning:\n\nThe contextual map records past decisions and actions as well as predictions and anticipated reactions for the future.\n\nThe room is architected for discussions and decisions, not just visits:\n\nThe map room contained a conference table and chairs so that decision-making and planning conferences could be held there. Thus the group was continually confronted with the developing map and the members were constantly aware of gaps in the information and suggested priorities for items to be considered.\n\nThus:\n\nThe map was a large, living memory for the group.\n\nOther observations about the map room:\n\nBriefing is simply a matter of taking new people into the map room for a briefing and allowing them to wander\nThe map room is, in one sense, a “learning machine” – comprising two parts. The planners: thinking and adapting And the display: making the complete context of the decisions readily available.\nThe physical room should be reconfigurable. Ideally, many decision-making groups should be able to use a number of maps simultaneously in the same general area.\n\nIt’s a compelling concept for collaborative, open-ended work!\nThat was 1955. What could we do in the 2020s, with hybrid environments, networked computers, and embodied interaction?\nI’ve glossed over the origin of the map room because it was, uh, not great\nFirst, a digression.\nSo the project for which the map room was created was the “development” of Hacienda Vicos, a 2,500 person, 22,000 acre community on the slopes of the Andes in Peru.\nIt’s described as a complex interacting cultural system – long-standing custom involved households dedicating some portion of time and labour to the community, with them subsisting on land held in common. I don’t doubt that life would be hard, but none-the-less it sounds like rich and meaningful mutualism.\nYet, the paper says without further discussion, it is “recognised” that the hacienda is an “anachronism” and has to go in the face of modern technology like hydroelectrics, trucks, schools, and communications.\nWorse, it looks like the map room itself was physically located not in Peru but in Stanford Cornell, and the copies of the contextual map were made to be used? imposed? in the field in the hacienda itself.\nIt’s horrific colonialism.\nThe opportunity to ask the hacienda community how and if it wanted to change was right there. New technology could have been added to the community matrix – or not!\nThe map room would have been the perfect forum for the decisions.\nAnd I’m pleased to discover, on some light googling, that the Hacienda Vicos “project” is regarded as “controversial.”\nAnyway.\nWith that giant looming caveat, back to map rooms.\nThe map room paper was Engelbart’s first citation\nThe map room holds a contextual map: the matrix of index cards.\nThe contextual map is put forward as a technique for a multidisciplinary group to find a conceptual framework.\nWhat is a conceptual framework and why does it matter?\nLet’s look at one: Augmenting Human Intellect: A Conceptual Framework by Douglas Engelbart, 1962.\nThis is the paper that unlocked ARPA funding when JCR Licklider read it, and set out the research programme that led to the invention and demo of the personal computer, the mouse etc in 1968 in The Mother of All Demos\nTo my mind, the 1962 paper hinges on two meta-principles.\nThe first is that Engelbart adopts the framing of a conceptual framework at all.\nKennedy & Putt, for the RAND Corporation in 1956, set out to summarise how to build an effective research organisation.\nThey identify that different disciplines will tend to follow their own groove: Research specialists, like all other living organisms, will go to great lengths to maintain a comfortable position.\nAnd therefore answers will remain “unintegrated.” True cooperation will not occur.\nThe requirement, they say, is for a framework\n\nthat within which research administrators and research specialists may interact and make decisions about what research should be performed, and\nprovides for effective communication with persons engaged in development\n\nSomething that can cut across disciplines; that all feel like they are contributing to.\nEngelbart reads this paper! It unlocks something for him.\nFrom Engelbart’s own oral history of his work (which is worth read in its entirety)…\n\nThen I discovered a great little RAND report written by Kennedy and Putt that described my situation marvellously and recommended a solution. Their thesis was that when launching a project of [a new discipline] the researcher would encounter consistent problems in approaching people in established disciplines. They wouldn’t perceive your formulations and goals as relevant, and they would become disputative on the apparent basis that your positions were contrary to ‘’accepted” knowledge or methods. The trouble, said these authors, was that each established discipline has its own ‘’conceptual framework.” The enculturation of young professionals with their discipline’s framework begins in their first year of professional school. Without such a framework, tailored for the goals, values, and general environment of the respective discipline, there could be no effective, collaborative work. Furthermore, if such a conceptual framework did not already exist for a new type of research, then before effective research should be attempted, an appropriate, unique framework needs to be created. They called this framework creation process the ‘’Search Phase.’‘\nSo, I realized that I had to develop an appropriate conceptual framework for the augmentation pursuit that I was hooked on. That search phase was not only very sweaty, but very lonely.\n– Doug Engelbart, The Augmented Knowledge Workshop\n\nThe result is his 1962 paper. Kennedy & Putt is number 1 in the references.\nWhat was Engelbart’s eventual framework?\nWell it’s fully about augmented human intellect, and read his paper for that, but here is the second of the two meta-principles: he followed JCR Licklider in atomising knowledge-worker activity. (Yes, Licklider who went on to fund Engelbart. What else could he do?)\nI talked about this before: Licklider had analysed his own thinking process, and discovered that 85% of the work was searching, calculating, plotting, transforming, and so on… bureaucratically “preparing the way”.\nAs Engelbart put it: Every process of thought or action is made up of sub-processes – and that bureaucratic work is tractable to computed-aided support.\nLicklider published his work in Man-Computer Symbiosis (1960) and that’s Engelbart’s reference #15 – to my mind, it is this approach that uniquely leads to the functionality in the demo and eventually “tools for thought” generally, and is the heart of the “augmenting” conceptual framework, unlocking the required multidisciplinary work of engineers and psychologists.\nEngelbart’s “very sweaty, very lonely” slog to his framework is what the map room concept was intended to short-circuit – why make that journey alone when you can do it together?\nAnd that’s why I’d like to find ways to reinvent the map room today, because we do need new multidisciplinary conceptual frameworks, and it would be cool to have new tools to help us to get there.\nOther map rooms in fact and fiction\nLet me rattle through a few other immersive information rooms so we have some references!\nSAGE (1958)\nHere’s my history of SAGE: the massive computing project (3x the size of the Manhattan Project) that preceded the PC, brought in the interactive computer, and gave us a glimpse of group computing which is so far unrealised.\nOn the third floor at each of the 24 Direction Center buildings, The Pit:\n\nEach of the men (yes all men) has their own computer console at their desk. But they’re working together around the PDU. One of the men is holding what is either a light gun or a laser pointer/equivalent. They’re assessing potential threats and ordering missiles and bombers. Together.\n\nAnd:\n\nThis isn’t a setup for presentations and discussions. It’s for collaboration and action. The whole room is an environment for the team to work.\n\nGroup use. Shared context.\nAnd from there we can go Nasa’s flight control centers, or NORAD in the movie WarGames – but I’m more interested in the individual/small group rooms.\nThe Knowledge Box (1962)\n\nIn 1962, experimental designer Ken Isaacs imagined and constructed a ‘knowledge box’, a compressed environment for experiencing ‘culture’: a cube of wood, masonite and steel equipped with twenty-four slide projectors and audio-suppliers.\n– Mariabruna Fabrizi, Socks, The Knowledge Box by Ken Isaacs\n\nLife Magazine is quoted:\n\nInside the knowledge box, alone and quiet, the student would see a rapid procession of thoughts and ideas projected on walls, ceilings and floor in a panoply of pictures, words and light patterns, leaving the mind to conclude for itself. It is a machine of visual impact that could depict, for example, a history of the Civil War in a single session, or just as easily give a waiting astronaut a lesson in celestial navigation.\n\nThe photos at the above link are ASTOUNDING.\nJust for individual use but so immersive!\nIt reminds me of the brainwashing machine in The Ipcress File from 1965.\nI want to have a go.\nProject Cybersyn (1970)\nThe Operations Room:\n\nIt was a hexagonal space, thirty-three feet in diameter, accommodating seven white fibreglass swivel chairs with orange cushions and, on the walls, futuristic screens.\n… Four screens could show hundreds of pictures and figures at the touch of a button, delivering historical and statistical information about production-the Datafeed-but the screen displays had to be drawn (and redrawn) by hand, a job performed by four young female graphic designers.\n– Evgeny Morozov, The New Yorker, The Planning Machine (2014)\n\nSame belief in human collaboration, same belief in context. Same mid-20th century, uh, awkward politics.\nbtw the architectural aesthetic: The room was designed by Gui Bonsiepe, an innovative German designer who studied and taught at the famed Ulm School of Design, in Germany, and industrial design associated with the Ulm School inspired Steve Jobs and the Apple designer Jonathan Ive.\nBut before any of these, even before the original map room…\n…there was the Prime Radiant of Isaac Asimov’s Second Foundation.\nPublished as a novel in 1952, and based on the novellas in Astounding magazine in 1948-1950, this was Asimov’s science-fictional user interface for Seldon’s Plan, the map of the present and the future of the galaxy according to the science of psychohistory.\n\n[the Plan] is projected on the wall as a network of dense, interlocking equations by a device named the “Prime Radiant,” and manipulated using a combination of gestural interface and thought control. \n\nI pulled out relevant passages here.\nThe Prime Radiant isn’t just a device – Consider a room! Asimov begins. It’s a forum for the “guardians” of the Plan to discuss together and make decisions together. Shared context and interactivity! Collaboration!\nAnd I wonder how much influence in the imagination this “technology” had? Did RAND researchers read Astounding?\nEphemeral vs accretive tools and why there’s still room for map rooms\nI can’t remember if I’ve shared this before but my mental model of modern collaboration tools is that they fall into two camps.\nEphemeral tools are about the conversation. Slack is one. Zoom is another. Google Docs, weirdly, is another, even though it’s all about files. There’s no shared “front page” to Google Drive and no Schelling Points for team members to gather around, so all documents are temporary working documents (and doing otherwise is pushing water uphill).\nAccretive tools build over time. Developer tools tend to work like this: platform-as-code. Wikis are the main one: Notion is accretive. (I love Notion.) Pipeline-based tools like Trello fall on the accretive end, for me – memory resides in the tool, not the users. Accretive tools need gardening because they don’t forget by default.\nI’m not sure these are the right terms. Maybe: stock and flow?\nMaybe: oral and literate? I also feel like you get two cultures of organisations. Oral orgs believe that knowledge resides in individuals, and they are forever emailing each other and having meetings and making custom decks. It allows for expertise. Literate orgs treat people as interchangeable parts and scurry over shared edifices – but they build cathedrals.\nAnyway.\nMap rooms, in my terminology, are an accretive tool.\nThey are shared living memory – external from individual skulls.\nWhich is what, say, Notion does.\nBut the map room also provides the overview. (As does the Prime Radiant!)\nI was playing with this idea recently, in a tiny way, when I was mapping my posts about the multiplayer web.\nMy learnings were that (a) maps should be authored not generated automatically; and (b) the map is a separate and just as valuable artefact as the territory that it maps.\nSo, imagine something like Notion, but\n\nit has authored maps for overviews – vast overviews\nyou build and interact with maps together with your team, with shared and individual views side-by-siude\nwith fluid movement between the macro and the molecular.\n\nThat’s not just “whiteboard” view, for me. There’s more.\nCould you build a map room today? Maybe embodiment matters\nYes I know agencies have “war rooms” with post-its for project management and concepts for #brands all over the walls. But that’s a technique out of the 1950s it turns out – I mean, could we bring the technology of map rooms into the 2020s?\nSomething software-enabled, something multiplayer, something that embraces “hybrid” so we don’t have to be either all in one geographic location or all at home.\nI think embodiment matters here?\nIt matters, in the map room, where you’re standing. It matters, in the map room and in the palace of memory simultaneously, that you can focus on some details and discard others because they’re in peripheral vision or behind you, or remember where you spotted something. It matters, in the map room, who you’re near. It matters if you see somebody lingering near an index card that you happen to know something about, and you can walk over and talk to them about it. All of that!\nSo in my imagination Map Room 2.0 looks something like this…\nConsider a room with a projector that shows an overview of your whole “map”. Maybe, just like the original map room, it’s a matrix of variables and time.\nWe all have that projector: me in my home office, and you in yours, and the others in the office meeting room. We navigate the map with gestures. It shows the same view for everyone. We don’t all need the identical physical setup – the projector can be large or small or point at any wall.\nFor looking closer, we use our phones and tablets. Those are individual.\nBut there’s some kind of equivalent to embodiment (and presence and proxemics): the system has gaze detection… it knows where you’re looking. And it also knows what index card you’re examining on your personal device.\nGaze and individual browsing are shown as icons on the shared map, like seeing coloured cursors in a Google Doc. Maybe the icon, or cursor, gets bigger if the viewer is standing closer to their projection.\nMore hardware peripherals: everyone wears earbuds + mic. There’s proximity audio so, if you’re in the main shared space, you can hear remote people who have their cursors near where you’re looking. There’s a “shout” button that speaks to the whole room.\nSo it’s wiki-like software, with multiplayer cursors and a virtual spatial metaphor, plus overview maps, and there’s hardware to make a hybrid tele-environment for everyone participating.\nSomething like that.\nA new map room.\nA new conceptual framework for new conceptual frameworks\nIt’s useful talking through the above because it’s hard for me to do so – it feels difficult to reason about a new map room because I can’t (yet) imagine what a physical computing environment should be. Not with much resolution.\nWhat are the primitives, like the equivalents to the windows, icons, menus, and pointers? How would people use it together? How would the various input/output modes braid together? What’s the conceptual framework for that?\nAnd this is a topic I’ve circled before:\n\nWHAT IF, instead of the Personal Computer, the dividend of SAGE had been the Team Computer?\nA computer that wasn’t used individually but as a group, together in a room or perhaps remotely. Not desktops but environments. An alternate history of computing that doesn’t involve user IDs or ownership as primary concepts but is instead oriented around collaborative, co-created artefacts, spaces that are jointly inhabited. \n\nAs useful as a 20XXs map room would be, it feels like first I need to spend some time exploring computing environments in general.\nAnother time.\n",
    link: "/home/2023/01/20/map_room",
  },
  {
    title: "A science-fictional idea for a geo-scale, lacework power plant",
    date: "20.48, Tuesday 24 Jan 2023",
    content:
      "The temperature difference across the U.K. yesterday (600 miles) goes from 11C in Scotland to -8C in the south east of England – a gap of 19C (34F).\nWhich seems like a lot?\nAnyway I was wondering, if you could somehow short circuit that, could you generate energy from the heat difference?\nIt’s a bit of a brain-fart idea. I guess what you’d need is really, really good heat conductors… like: diamond. Diamond is a great conductor of heat. Apparently diamonds are known as “ice” because they’re cold in your hand if you hold enough – they conduct your body heat into the air really efficiently. Half-remembering here, but I vaguely recall hearing: if you had a diamond ashtray in your palm and you stubbed out a cigarette, it would feel like stubbing it out on your skin.\nAnyway: so if you could spin a solid diamond pipe hundreds of miles long, you’d get a heat difference between your local end and ambient temperature, and maybe you could use that to drive a turbine or something, and make electricity?\nWell why use heat? Go direct to electricity.\nThere’s something called an electrodynamic tether which is a long cable that hangs off satellites. It has been tested a few times. It takes advantage of the coupling between current, movement through a magnetic field, and force (the Lorentz force).\nYou hang the tether out of the back of a satellite, dragging it through Earth’s magnetic field, and use it in a couple of ways: either you pass a current through it, in which case it propels (or brakes) the satellite; or you take advantage of the changing magnetic field and generate electricity.\nSo imagine an electrodynamic tether but it’s not hanging from a satellite, it’s draped across, say, the whole of Canada. What would happen?\nI mean, I don’t know. BUT: I do vaguely recall that normal EM flux across the breadth of Canada is large enough such that it’s hard to have a single electrical grid?\nIt’s worse during geomagnetic storms, caused by ejection of plasma from the Sun: the Carrington Event in 1859 is the biggest recorded geomagnetic storm, and: The operators of the telegraphs reported receiving electrical shocks, telegraph paper catching fire, and being able to operate equipment with batteries disconnected. (Source: The Conversation (2022).)\nIt would likely be catastrophic to get a storm of that scale today.\nBut there are always geomagnetic storms of some magnitude, right? There are always induced currents in the grid somewhere?\nAnd then then’s an energy harvesting technique called RF harvesting:\n\nelectromagnetic energy is abundant in space and can be retrieved without limit. Electromagnetic waves come from a variety of sources such as satellite stations, wireless internet, radio stations, and digital multimedia broadcasting. A radio frequency power harvesting system can capture and convert electromagnetic energy into a usable direct current (DC) voltage.\n\nHmm.\nSo let’s add room-temperature superconducting materials to the mix.\nAs diamond is to heat, superconductors are to electricity. Now we don’t have any room-temperature superconductors yet, but let’s say that DeepMind AI researchers decide that after solving Go, protein folding, and Tokamak fusion reactor plasma wrangling, they’ll have a go at chemistry and metamaterials…\n…and they somehow engineer a superconductor that doesn’t need to be actively cooled, it’s all exotic surface properties or something, so it’s a passive structure, which is at the very least not impossible, and then: you weave the superconducting wires using a molecular 3D nano loom or something, just print them out hundreds and hundreds of miles long.\nPretending for a second you had that, could you do significant RF harvesting from the everyday variance of the Earth’s magnetic field as driven by the Sun?\nYou could prototype this with cooled superconducting cables but leave off the EM shielding I guess.\nNow imagine a lacework of these superconducting cables over a huge region.\nIt would be kind of a geo-scale dream catcher for solar EM flux – drape it over the landscape and it would be a vast and diffuse power plant; plug into it from anywhere to tap free electricity. Generator implementation details left as an exercise for the reader.\n(Any physicists capable of running the numbers on this? We should publish!)\nNow this is a pretty science-fictional idea though I doubt it’s capable of carrying a story on its own.\nOne of my dreams is to contribute a sci-fi trope to the canon, like space elevators or tractor beams or rolling roads.\nSo if you’re an author and you have something on the go, please work in the geo-scale EM lace as the default power source, just as like background texture or something, and let’s get it into a few stories, and maybe a kid will read it and in a few decades we’ll have this for real, or maybe not and that’s cool too, but please give it a better name.\nOkay thanks.\n",
    link: "/home/2023/01/24/lace",
  },
  {
    title:
      "Rooms, voice, gestures, and why Apple HomePod hasn’t quite clicked for me",
    date: "20.50, Thursday 26 Jan 2023",
    content:
      "I’ve been thinking about gestures and rooms as some of the primitives for situated computing, and how acts like pointing and gestures could be braided together.\nI recently have an Apple HomePod mini in my home office for reasons. It’s the only smart speaker in the house – I’ve always been cautious about privacy, and anyway my use of voice (via my watch) has never stretched beyond setting the timer for cooking and finding out how old celebrities are.\nThat said, I now call to the HomePod to play music and it is 70% ok and 30% frustrating as hell.\nFor instance: it didn’t understand what track I wanted so I kept saying Hey Siri… followed by various incantations. Then I fell back to playing the album and using my phone to skip to the right track. But the UI to select the device from the Music app is buried on the Now Playing screen and in totally the wrong place in the user flow. Or should I be accessing this via the Home app? And, and…\nSo I started making notes about how it could be better. Like:\n\nSiri should be conversational if it needs to disambiguation or if I need to fix a response (called “repair”)\nI should be able to point my phone at my HomePod and have the Music app appear immediately, for that specific device\nBesides, devices should be top-level devices across the OS, and Home should make compatible apps available dynamically in a folder, with the Home app itself just used for settings\nVolume control is just baffling (visually it looks like the volume of my phone, but actually I’m controlling the volume of the music… or the volume of the device?)\n\n…and so on.\nBut when I imagine this it feels convoluted and piecemeal. It may be “logical” but it would be hard for users (me!) to build their own mental model; it would still be hard for designers to reason about.\nThis is the same place I ended up when trying to reinvent 1950s collaborative map rooms – the conceptual framework is all wrong.\n(Naturally the correct response to being momentarily grumpy about the UX of playing a song is to write up a demand for 5 years of work as a blog post…)\nThe room is an environment for embodied interaction\nI don’t know quite where this will land but I have just a hunch, just the outlines of a conceptual framework.\nWe’ve got a couple competing models already:\n\nHomePod descends from voice-first smart speakers (a category invented by Amazon in 2014 with the Echo) – and voice interfaces suffer, even if you solved for conversation and repair, from poor discoverability and expressiveness\nSmart home gadgets (lighting, HVAC, security) treat the phone as a remote control – but physical gadgets are by their nature shared, and phones are by their nature personal (and not carried by everyone).\n\nSo those don’t work, and clash besides.\nInstead I’d like a conceptual framework that starts with a few principles:\n\nThe room is the common ground of the interface – the place of mutual knowledge between user and distributed “computer”. It’s analogous to a desktop on a screen, if you like\nPhysical things are icons (I unpacked icons here) – by which I mean that this is where the user mentally locates their state, even if that state literally happens to be in the cloud or whatever. Alerts, conceptually, come from the relevant device (and maybe that’s done with badges or maybe it’s done with spatial audio)\nGroups not users. A room can contain any number of people; people have different roles\nPeople are embodied. Gesture matters, orientation matters.\n\nThen the way we break this down is to focus on phases of interaction, not mode (voice, keyboard, etc), and ensure that what we’re doing is humane (familiar, intuitive, call it what you will).\nFor example: the micro-interaction of focus.\nThere is always a moment where a user selects an object to talk to; to grant focus for subsequent commands. Right now I do that by using a wake word: Hey Siri.\nBut now I’m thinking of acts I realise that, sure, I could use a wake word, but it could also be gestural wake: pointing or glancing or unambiguously stepping closer.\nI talked about this before: How I would put voice control in everything (2020).\n\nWhy can’t I point at a lamp and say “on” and the light come on? Or point at my stove and say “5 minutes”? Or just look at it and talk, if my hands are full.\n\nThen there’s the micro-interaction of issuing a command.\nSure you might point and speak. But then we might also say that anyone in the room can hold up their phone and see that action occurring on the object’s soft interface, an app screen, so they can clarify either by talking or tapping… a kind of “lean closer” moment.\nAside from interaction design, there are broader questions:\n\nVoice – how can it not be lame? AI LLMs provide a route here, because it’s now possible to make statements of equivalent intent (which are nearby in latent space) rather than the fixed nouns and verbs declared by the developer. Is there something like a device API or scripting surface that means that the voice interface can be auto-generated?\nClarifications, repair, and shortcuts – we’re not dealing with “commands” here but micro-conversations in which a device can ask for more details to fill in the gaps. But, equivalently, how can a user speed up an interaction if they know what they’re asking for?\nAffordances and discoverability (how do I know what this device can do) – a big one! But is this answered by making every interaction multimodal? Is holding up your phone equivalent to hitting the COMMAND key on an iPad and seeing an overlay of all the shortcuts?\nUniversality, privacy, and roles – how can anyone come into the room and turn on the lights? My dream would be to do all of this entirely on-device…\nCommerciality – is it possible to instrument a room such that there is measurability of interaction funnels for iteration, without breaking privacy? How is it possible to grow the ecosystem while there are always going to be dumb devices, and what of interop is possible?\n\nA broader question: how does this play with telepresence, connected spaces, or overlaying virtual and physical space? I feel like the answer to how to access devices remotely is downstream of this bigger framing. \nLast, I think the scope of what is in a room has to increase. A projector, a TV, a spare screen, and other devices are as much part of this computing environment as speakers and gadgets.\nI know it’s simple. But I find this conceptual framework easier to work with, and more generative for ideas, than considering devices in an isolated fashion? I guess what I’m after is something as straightforward to grasp, as achievable, and as profound as the desktop metaphor itself, only for situated computing.\nIn a initial sense I would like to have interactions that are simply:\n\n(Glances over). What’s that Eno Hyde album I’ve been playing a bunch lately? - Someday World - Yes play that.\nPointing while holding my phone, choosing an album with the app, and someone else in the room disagrees and calls out skip song.\n\nBut also I would like to be have that multiplayer map room with projectors and shared displays and personal displays and proximity audio for hybrid presence, and be able to clearly set out the technology Lego bricks to achieve this.\nOr imagine doing something like writing on a piece of paper and holding it up to a webcam as a natural step in a conversation, and knowing how that would be integrated in the interactions.\nI’m talking about rooms and homes here, but Just Walk Out by Amazon is also a situated interface… it’s a computer with cameras and sensors (and the ability to take payment from credit carts), situated in a shared environment, and how can that fit in our same conceptual framework?\nAnyway. Room as distributed computer that we stand in. Objects have state. Interaction-first not mode-first.\nThen you figure out how it actually works by building and trying. I’ve started experimenting (just on my own) with hysteresis curves for focus with pointing-based interactions. It’s intriguing to play with gestures. But that’s another story.\nUpdate 27 Jan. Steven Smith stopped by to let me know Handoff in iOS which does indeed pop open the remote control pane for HomePod when I hold my phone a couple inches away! So let’s take that as a mini thought experiment because it’s a neat capability: from a micro-interaction perspective, I would want this capability to meet an “increase engagement” moment in a conversation, and to be available and afforded at that moment. While the pane itself is good, the current gesture is an “initiating” micro-interaction. So this pane should be peeping on my phone whenever I’m in a conversation with that HomePod using Siri, in the same language as the remote controls for the current room (currently buried in Control Center).\nBUT this also feels a bit like getting lost in the weeds – step one is the framework. What’s the UI for a room?\n",
    link: "/home/2023/01/26/room",
  },
  {
    title: "AI-generated code helps me learn and makes experimenting faster",
    date: "17.19, Friday 27 Jan 2023",
    content:
      "It’s one thing to keep tabs on generative AI, speculating about it here and in private client work – it’s another to experience the whoa moment for myself.\nCode. I can take or leave AI art. ChatGPT mostly leaves me cold. But code!\nGitHub Copilot is your AI pair programmer – it’s smart, code-aware autocomplete. Ok I get that. But let me try to explain what I experienced earlier this week…\nI’m building a basic in-browser prototype so I can explore the UX around computing vision, gestures, and attention, just a lightweight personal investigation on the topics from yesterday.\nThe tech isn’t rocket science, but it isn’t something I know already. From experience this means that I probably need a day or so to learn enough to ask the right questions of StackOverflow and Google. Absorbing a domain like this means reading tutorials, specs, examples, etc. I can bully my way through most code given time.\nI signed up for the Copilot 60 day free trial because why not. Installed the plug-in etc.\nI opened my vanilla React project. I made an empty component that displayed “Hello, World!” in my browser preview, just to check everything was working.\nThen I wrote a comment at the top of the file:\n\n// A react component that activates the user’s webcam and displays the stream in a video element\n\nAnd waited for the autocomplete: a bunch of code. And accepted it. And hit save. Less than half a second.\nThe browser preview refreshed – asked for webcam access – then I saw my own face staring back at me.\nI got that feeling of the floor dropping away.\nLook, I know the code isn’t rocket science. I know I could do this, eventually, and you could probably smash this out without looking, but I don’t really know React - I can’t write it idiomatically - and I don’t know about webcams in the browser, and I don’t know about the MediaStream API.\nSo this was a day of work in 10 minutes.\nWhat is meant was that I could spend that day integrating hand pose detection and noodling with the actual micro-interactions. And now I have opinions about all of that!\nNow, none of that Copilot-supplied code remains in my app.\nWhat happened what that it helped me frame my problem. I was able to rapidly explore the edges of my knowledge, and figure out how to structure my questions and what I need to learn. My learning requirement is not obviated obviously…\n…but as an epistemic journey my interaction with Copilot is insanely more efficient than doing it on my own.\nSo, after Tom Stafford, Copilot is an epistemic agent: it’s not query/response, which is a model which presupposes that I do not change; it scouts ahead and helps me build knowledge. I have a better mental model of my domain, I know more, than I did before I started.\nbtw when I refreshed the browser and saw my face there, the code working as-wished but not necessarily as-expected, my laptop felt haunted. I closed the lid to stop the face looking at me.\nThen I opened it again to check the screen. Then took a breather. Then came back to write this.\nGithub Copilot radically lowers the cost of experimenting. That’s the value to me.\nOn ChatGPT for a sec because I dunked on it at the top:\nGenerated text is meh. It all reads like vapid SEO traffic-farming blog content. Automating away people’s jobs is… ugh, fine I guess? but let’s try to be more original. Stochastic text collisions can stimulate new ideas, sure, that’s another use… but if that’s your goal then flip a coin or use Oblique Strategies or the I Ching or something. Prompt injection attacks are funny and the engineering to avoid them will probably open up more interesting possibilities than the reverse. But not yet.\nOk but I still love large language models so why? I’ve been asking myself that. So here are five large language model applications that I find intriguing:\n\nIntelligent automation starting with browsers but this feels like a step towards phenotropics\nText generation when this unlocks new UIs like Word turning into Photoshop or something\nHuman-machine interfaces because you can parse intent instead of nouns\nWhen meaning can be interfaced with programmatically and at ludicrous scale\nAnything that exploits the inhuman breadth of knowledge embedded in the model, because new knowledge is often the collision of previously separated old knowledge, and this has not been possible before.\n\nBetween those starting points (which I should unpack I know), and spotting second-order effects where cheaper UX experiments is one such example, that’s where I’m spending my cycles rn.\n",
    link: "/home/2023/01/27/copilot",
  },
  {
    title:
      "The sword in the stone and the lady of the lake are blacksmithery, or nanotech",
    date: "16.30, Tuesday 31 Jan 2023",
    content:
      "The legend goes that a sword appears embedded in a stone, or in an anvil standing atop a stone, and there is a label: whoever pulls this sword from the stone is the true king of England. And Arthur finds it, and does so, and becomes such.\nI wonder if this is a description of Arthur forging his own sword?\nLike: if you were to explain ore, and the process of smelting the rock to produce iron, and forging the iron to make a sword, and you wanted to really drum home the miracle of this technology, today rendered invisible by a supply chain too diffuse to see, wouldn’t you say that he had drawn the sword from the stone?\nI guess I’m thinking of ways for the story to be non-fantastical.\nBTW #1:\nIron may have been transgressive and egalitarian, once upon a time: iron undermines bronze-based power structures.\nBTW #2:\nYou could also say that raising a popular army is like pulling a sword from a stone, if your metaphors were such that stone = land. So there’s that too.\nYou might want to bring attention to ore being the source. Because it turns out that in northern Europe, in Arthurian times (400AD-ish), smelting iron from stone was unusual.\nIron came from bogs:\n\nIn northern Europe in the Iron Age all the way through to the early Medieval period, most iron came from bog iron. It was hard to smelt, because it was a rather low grade ore, but you didn’t have to mine it and it was a renewable resource (in about twenty years you could just come back and get more, because it formed constantly).\n– Tor.com, Is the Arthurian “Lady of the Lake” a Metaphor for a Jacked Blacksmith? (2018)\n\n(That link quoting a thread by author Jennifer R. Povey.)\nSo maybe the other origin story of King Arthur, in which the Lady of the Lake rises out of the water and hands him Excalibur, is also about iron and sword making?\n…and, perhaps, was this the original legend? And later, when bog iron was replaced by iron ore, was the myth rewritten so that the sword is produced from a stone not a lake, so that although the story differs, the underlying meaning in metaphor-space is the same?\nI’m speculating.\nExcalibur is returned to the lake after Arthur’s death, which was traditional. But this practice pre-dates iron which, to my mind, is a point against the idea of a reciprocal relationship between blacksmithing and bogs.\nSEE: The History of Magic (Chris Golden). After death, weapons were placed in water. In the Bronze Age:\n\nstreams, marshes and bogs received spearheads, axes and sickles; major rivers were given swords, sickles, spears, axes and personal ornaments from outside the region.\n\nAnd this continued with iron in the Iron Age (800BCE–43BCE):\n\nin southern Britain swords were regularly thrown into rivers.\n\nIt’s not a misinterpretation of accidental loss: Broadly speaking, when more things are placed in graves, fewer items are thrown into rivers and bogs.\nIt’s wonderfully alchemical, the idea of transmuting water into weapons.\nMaybe Merlin came from the future and equipped the once and future king (that’s why Arthur is the future king too, because he returned with Merlin).\nI’m imagining a nanotech smithery that you drop into a bog, like a long strip of something that feels like rough leather, and as water flows over engineered cilia fixers, it slowly reefs an iron-coral sword.\nOr a glowing hoop that you place on a hunk of iron ore, and it atomically teases out the metal and weaves it and extrudes a hilt, which you grasp and heave and the blade prints as you draw it from the red hot aperture of the Drexler assembler.\nI guess current technology is that magical, really, except that the process of transformation from raw material to end artefact takes thousands of miles and so much time that it’s not really your agency that makes it happen. So maybe, to invent something magical, one algorithm is to look for lengthy industrial processes and imagine them as on-demand, pocket-sized.\nIt’s like bubble wrap isn’t it. I squash down the fantasy in one place, and it finds a way to pop up somewhere else.\n",
    link: "/home/2023/01/31/arthur",
  },
  {
    title:
      "New thing! Browse the BBC In Our Time archive by Dewey decimal code",
    date: "18.17, Tuesday 7 Feb 2023",
    content:
      "I love listening to In Our Time with Melvyn Bragg and guests (official site here). It’s the best radio.\nThere are almost 1,000 episodes (it has been broadcasting on Radio 4 since 1998) and when I want to learn about, like, Ancient Greek tragedies, or the evolution of teeth, this show is where I turn first. All the audio is online, which is amazing! Thank you BBC!\nBut actually trawling through the back catalogue is hard.\nSo I made a very unofficial website to find old episodes to listen to.\nBraggoscope lets you explore the In Our Time archive. Check it out!\nThere are multiple ways to explore:\n\nDirectory - browse episodes by topic, organised using standard Dewey decimal library codes\nFrom an episode page, e.g. Le Morte d’Arthur (Jan 10, 2013) you can pivot on guest (each discussion has three academics) and similar episodes which are surprisingly good.\n\nEach episode links through to the BBC website so you can listen. The full show description and reading list are included too.\nI guess I would call this pre-pre-alpha… there’s no real design yet, and there are surely some bugs with the data.\nHOWEVER: I’m using it to discover new episodes already.\nFor example. I loved learning about the late Devonian extinction recently. Here’s the episode page. Now I can go down the reading list to find books, and find my way to similar episodes about the Permian-Triassic Boundary, the Cambrian Period, the fish-tetrapod transition and so on. Like I said, surprisingly good.\nAnd browsing the Directory is super fun.\n(Oh and hi to anyone from the Beeb who is reading this! I’ll take this project private if you need me to, or share the approach.)\nHEY: you can stop reading here unless you want all the stuff about how it works and my opinions about AI.\nFor posterity… in the event that Braggoscope changes URL or disappears, I want to remember what it looked like in years to come. So here are a couple of screenshots: the Directory; an episode page.\nI used GPT-3 for the heavy lifting and now I have oh so many opinions\nI wrote up the tools I use in Braggoscope on the About page, but as a quick overview.\nThe process:\n\nSpider the official website and fetch all the HTML (a 1,000 pages or so, not too many). The show notes are what we’re interested in, but they’re not super well structured.\nWe extract data like the episode synopsis, guests (names and affiliations), reading list (title, author, etc) in a machine-readable format. Imagine starting with prose, and ending up with tidy columns in an Excel spreadsheet: that’s what I mean by structured data.\nThe data can then be enriched by classifying it and processing it to figure out similarities.\nFinally there is site build where the data is written out into HTML.\n\nI’m a casual coder but the above is pretty straightforward.\nExcept the extract step. This is tedious. It’s a few days of writing fiddly code to catch all the different ways that guests might be listed, or how show notes might be written.\nOR:\nIt occurred to me… why not just give this to OpenAI’s GPT-3?\nSo that’s what I did. It took 20 minutes to write the integration, then I left the code running overnight. It costs me pennies per inference so I’ve replaced a few days of boring graft with $30 on my credit card.\nAnd this is interesting right?\nI’ve been used to thinking about generative AI and LLMs (language models) as smart autocomplete.\nBut this is more like a universal coupling.\nI set temperature=0 – this is a parameter that governs creativity, so by doing this I was asking GPT-3 to be pretty deterministic.\nIn the prompt, I specified that GPT-3 should return structured data as JSON (a data interchange format based on Javascript objects) and provided a type definition.\nIt doesn’t always return valid JSON. I have some wrapper code that fixes it up.\nIt was while I was getting structured data back for the synopsis that I thought: I wonder if I could get GPT-3 to classify this? How about using Dewey decimal classification…?\nAnd sure enough, it works! It’s not perfect but it’s preeeeetty good.\n(Now I read down the list of Dewey Decimals classes with some considerable side-eye. It has, uh, a particular perspective. And it turns out that Melvil Dewey was a seriously bigoted and unpleasant guy. But it’s a well-known hierarchy that is small enough to wrap your arms around, and it makes topics findable. So… I would love an alternative but that’s for another day.)\nThe “Similar episodes” list also uses OpenAI – each show synopsis is translated into an “embedding,” a ten thousand parameter vector representing its position in the “meaning space” of the language model. Then similar episodes are simply nearest neighbours (calculated with cosine similarity).\nAgain - this is surprisingly good! While I was developing Braggoscope I tried using tags too but honestly, for finding related shows, this embedding approach is way better.\nThis is pretty technical but you can explore the whole space yourself: here are all the episode embeddings in a single chart (hover over each dot for the title). This uses PCA (principal component analysis) on the embeddings, then the top two components (being the most significant vectors of variability) are the x and y axes. It’s code that OpenAI provides but will be pretty easy to customise - PCA is a ton easier than when I used it back in undergrad! - so I’m thinking about what to use this for.\nI feel like this programmatic use of LLMs is where AI gets really interesting.\nThere’s the experience of it…\nUsing GitHub Copilot to write code (as previously discussed) and calling out to GPT-3 programmatically to dodge days of graft actually brought tears to my eyes. I’ve coded, mostly as a hobby, my whole life – it’s a big creative outlet alongside writing – it’s so rarely felt like this. It feels like flying.\nBut the actual literal engineering of it too…\nSure Google is all-in on AI in products, announcing chatbots to compete with ChatGPT, and synthesised text in the search engine. BUT.\nUsing GPT-3 as a function call.\nUsing GPT-3 as a universal coupling.\nIt brings a lot within reach.\nI think the magnitude of this shift… I would say it’s on the order of the web from the mid 90s? There was a radical simplification and democratisation of software (architecture, development, deployment, use) that took decades to really unfold.\nThere is so much tooling to build around temperature=0 language model calls. There’s a startup or nine just in that.\nI would like to see frameworks and programming languages that have first class support for this as a pattern.\nAnyway!\nHey, some trivia: I was involved in setting up the In Our Time podcast, way back in 2004. It was the first podcast by the BBC, and the BBC was the first national broadcaster to do any podcasting at all. I hand wrote the first XML files that were uploaded to the servers! Still a fan.\n",
    link: "/home/2023/02/07/braggoscope",
  },
  {
    title: "A notification center for progress bars that sounds like birdsong",
    date: "15.37, Friday 10 Feb 2023",
    content:
      "The return of dead time!\nOne curious experience in hacking on Braggoscope: there’s a lot of waiting for the AI. Asking GPT-3 to extract some data costs 3 cents and takes 5 seconds. Stick it in a loop and that’s 80 minutes for the 1,000 episodes in the In Our Time archive.\nNow I’ve saved myself a few days writing code by asking the AI to do the heavy lifting so 80 minutes and pennies per inference is neither here nor there, but what am I supposed to do?\nThis has come up before:\n\nin my undergrad, analysing quasar spectra, running data jobs overnight and over lunch\nwriting firmware for a radio prototype, wanting to test my latest changes and hitting compile and staring at the wall for minutes while the computer did its THING.\n\nLong-running processes are kinda the norm, even though we have this narrative about computers being instant? Whether that’s waiting for a 3D render, or running the test suite on a codebase and going off to make a cup of tea while it does its thing.\nOr waiting for a restaurant delivery! Or a cab to arrive! Many process are human-machine hybrids.\ntbh I never know what to do with myself.\nI can never move on for that 80 minutes. I can never multiplex tasks. Even though I know it’s only a fraction of the way through, cognitively the computer’s task is still lodged in my head, and all I can do is doomscroll Twitter or shuffle my shoes or whatever until it completes. Nothing productive.\nI blame notifications.\nOperating systems are really good at dinging when the machine has finished (and it’s my turn now).\nAn absolute ton of effort has gone into effective dinging, over the years. Apps can all ding. I can make my hobby code ding. There’s a top-level OS feature called the Notification Center which is all about collecting dings, so that I have a list of all the balls which are now in my court to deal with.\nEngagement!\nComputers and phones are not so good at, say, humming to say: hey you don’t need to do anything here. Don’t panic. Go away.\nSo, progress bars, right?\nProgress bars let me see that I’m only 10% of the way through a process, and the pixels are creeping up oh so slowly, so I can safely get on and THINK ABOUT SOMETHING ELSE secure in the knowledge that I won’t be interrupted by a ding.\nClever progress bars even show an estimate time of completion.\n(There’s a command line tool, I forget the name of it right now, where you - a developer - give it only minimal information, and it deduces the rest, providing a user interface with percentages and times and everything you’d need.)\nI know we laugh at progress bars because they were often comically inaccurate with time estimates – but we could have solved that with better design I’m sure? Visually provided lower bounds (this process will not complete in less than X) and confidence levels? Or just made them funny? Reticulating splines, that was good.\nBut we didn’t take on that design challenge…\nInstead we got…\nSpinners.\nSpinners are the dumbest progress bar.\n“I’m busy and I may come back to you in 3 minutes or I may come back to you in half a second but I’m not going to say which, and anyway the network may have hung so just wait forever, I’ll just be here looking exactly the same, spinning.”\nImagine if all the effort put into managing notifications had gone into progress bars.\nWe would have…\n\nall my progress bars consolidated in one place, not hidden behind other windows, a reassuring design feature that shows me that the computer is WORKING for me!\nAI predictions based on current churning away, and previous performance, with increasingly confident percentages and automatic time-till-done\neasy-to-integrate progress bars for app developers and hobbyist coders alike\nextra features, like integrated pause/resume when you need more battery, or the ability to hook up completion milestones to ding (I suppose) or vibrate my watch or whatever\ncloud progress bars, so I can see the progress of an Amazon delivery right next to the job that is using machine learning to generate my new profile image photos, all in a pane that swipes down from the top of the screen.\n\nWhy do I want this?\nWell, the motivation as for the Notification Center itself: notifications are consolidated because it helps manage attention. It’s less stressful to have “things I need to look at” effectively as a to-do list rather than having to keep all the dings in my own brain.\nProgress Bar Center, same same: it would help me manage my attention. By listing all the things I DON’T need to look at, and letting me know that I definitely don’t need to look at these for the next X minutes then it means I can cognitively stand down: I need no longer inhabit a state of perpetual readiness.\nAnd so I can finally focus on something else instead.\nImagining, for a second, a Progress Bar Center on my laptop or my phone:\nIt would be a home for my podcast Now Playing too. And for my current Google Maps journey. So this is semi-interactive.\nGiven that interactivity, I can imagine the commercial angle too: the progress bar for a cloud render or my Amazon order may have a pay-for Boost button to buy more GPUs or upgrade to next-day delivery or whatever. The process economy instead of the engagement economy.\nAnd of course my GPT-3 tasks running, and Photoshop filters calculating, and my movies downloading –\nall, collectively, reassuringly telling me: the machine is busy on my behalf. I can relax, I’m already being productive, put it all out of my mind, there’s nothing I need to do.\nAnd pulling on that thread of putting attention aside…\nIt’s easier to do that when the locus of attention is physically elsewhere?\nLike: when music is coming from the speaker behind me, rather than from the same location as the code problem I’m trying to crack on-screen, it seems less likely to distract me.\nAll these things asking for my attention from the same locus is fatiguing, in the same way that staring into a point source of bright light is fatiguing, but a diffuse glow from all around can can be just as bright and not fatiguing at all – just illuminating.\nSo the equivalent for attention is (because I’ve been thinking about room-scale computing recently) to scatter those progress bars around the room.\nAnd thinking of the chugga chugga chugga of old hard drives and other synaesthetic data senses for machines – it maybe would be cool to sonify these progress bars?\nThe idea of making a soundscape of the workings of the machine has been around for a while of course but I’ve found it hard to see a plausible route to get there in this era of notifications. A room of dinging things would be torture.\nBut based it on this framework for progress bars!\nYou could do it for cheap with tiny speakers and Bluetooth, sell progress bars by the handful like AirTags.\nI would love it if sitting in my home office had the ambient sound of a rainforest. Everything, I would think, listening, is working as it should.\nThe frogs are reaching a crescendo! (I am about to get a notification that a job has finished, I think to myself.)\nOr stepping into an office and hearing all the non-human workers sonified and layered – the sound of progress as the distant hum of traffic, or the wind.\n",
    link: "/home/2023/02/10/progress",
  },
  {
    title: "Don’t bother me now I’m waxing my phone",
    date: "13.43, Wednesday 15 Feb 2023",
    content:
      "There is a joy of maintenance that I feel like modern consumer electronics overlooks?\nSo my iPhone hasn’t been charging properly recently. It’s unreliable – it charges, then it doesn’t charge, then I wiggle the wire and it charges again. A pain.\nI got a wooden toothpick from the drawer and dug around in the lightning port, carefully excavating a couple balls of impacted pocket fluff and miscellaneous fibres and dust.\nThen: plugging in my phone had a new and reassuring thunk as the cable seated properly in the port, and charging reliability is once again top notch.\nA satisfying process!\nI do this every 6 months or so.\nYET – I find myself labelling this task as a failure of the industrial design. Oh, the charging port gets fluff in it! Get rid of the port! Invent a whole thing for wireless charging!\nWhich is a shame.\nBecause in other worlds it is a marketing benefit to use oil in your car that makes it run better over time. It is a pleasure - and a performance benefit - to oil a cricket bat, or wax a violin bow, or season an iron pan. A vocation to prune a bonsai.\nStewart Brand, technology Merlin*, is writing a book about maintenance.\nThe first chapter is a standalone essay and a WILD ride about:\n\n…the Golden Globe around-the-world solo sailboat race of 1968. Its drama continues to echo half a century later because three of the nine competitors became legendary – the one who won, the one who didn’t bother to win, and the one who cheated.\n\nIt’s online at Stripe’s Works in Progress.\n\nTheir stories are usually told as a contest of wills and endurance, but at heart, it was a contest of maintenance styles.\n– Stewart Brand, The Maintenance Race (2022)\n\nRead the whole thing!\nThere are some lessons. e.g. if you don’t fix something when you first see it beginning to fail, it is very likely to finish failing just when it is the most dangerous and the hardest to deal with, such as in the midst of a storm.\nAnd such daily maintenance is also good for the soul.\nBut the main lesson is that there is one approach which is to over-prepare and aim for zero maintenance – but, it turns out, this is fragile.\n(That, of course, is the strategy my iPhone takes.)\n* or Comte de St. Germain, take your pick of catalytic immortals.\nAt this point I might make a connection to the long-lost movement of Adaptive Design and ask about phones and laptops which embrace and encourage end-user maintenance. What could we design differently, how would the commercials work etc.\nHello Fairphone, right? Maintenance is a route to environmental sustainability too.\nHowever! I have justly been outed as a genre blogger:\n\nIn much the same way as the golden age sf short story authors, he has a fairly standard suite of conceptual strategies; the excitement of the form is seeing the transform that those strategies produce from whatever his starting materials happen to be.\n\n(Thank you Paul Graham Raven,  I am tickled and delighted.)\nAND SO, in the sprit of the archetype, let’s imagine some smartphone maintenance add-ons.\nAlong with my 19 quid polishing cloth (for any Apple display, including nano-texture glass), could I please purchase:\nA special formulation of 5G grease which, when applied regularly to the back of my phone, buffs into a lacquer that blocks rogue radio signals yet is utterly transparent to the specific frequencies and modulations of 5G, meaning that my baseband modem has less work to do, in its separation of the wheat from the electromagnetic chaff, having a positive effect on both battery life and bandwidth as measured in bits-per-second.\nInstead of my wooden toothpicks, I would like a guaranteed lint-free defluffing pick, for the regular hoiking of detritus from various ports (charging and otherwise) perhaps a cutting-edge 3D printed ceramic or perhaps carved from the wishbone of an ancient bird.\nA multivitamin supplement, to be taken with breakfast along with my daily handful of nootropics, that boosts the dielectric qualities of my thumbs, meaning that my capacitive touchscreen reads me more immediately and more precisely, leading to fewer texting typos and smoother, tighter, more impressive bezier curves in my sketches in the Notes app.\n",
    link: "/home/2023/02/15/maintenance",
  },
  {
    title: "Tinkering with hyperlinks",
    date: "20.37, Thursday 23 Feb 2023",
    content:
      "Hyperlinks should look different if it’s busy at the other end. Like: maybe they should be noisy, or glow, or have a yellow halo that gets bigger and bigger.\nI made a teeny software sketch: watch a video (30s).\nEach of the “web pages” (they’re just pretend) has the standard avatar bar across the top, like Google Docs or Figma. The more people there are at the destination, the bigger the hyperlink halo.\nALSO: when you hover over the link, you appear in that avatar bar too, peeping. Everyone in the room can tell you’re looking in!\n(I also posted this movie on Twitter, if you want to comment.)\nLook, this isn’t a very impressive sketch. You know that, I know that.\nBUT.\nI wrote a lot about the web going social and multiplayer last year (here’s a map of my posts). The architectural patterns of approach! How presence lingers! How attention works!\nNot to mention that once you have a team on a webpage, you also have a runtime for AI teammates – NPCs.\nThose would be fun interactions to explore.\nAnd I think by making.\nSo this is the beginning of my own little sandbox. Gotta start somewhere!\nAnd who knows what I’ll learn by getting my hands dirty, or how I’ll think about recombining the pieces.\nWhy?\nThere’s a kind of material exploration that I’m embarking on, I guess? Trying to sculpt something, seeing how it feels, challenging my preconceptions, learning the grain of the material of the multiplayer web… educating my opinions.\nMaterial exploration has been so core to my process for so long that I forget to talk about it, often; forget to even deploy it sometimes.\nThat’s part of it.\nALSO, #2: I am enamoured of a community which has a full-blown scenius going on.\nI’ll link to a bunch of Twitter feeds here because that’s where the action is: startups like The Browser Company (with Arc), tldraw via their founder Steve Ruiz, and Fermat are working and experimenting with software in the open, sharing often wild GIFs of prototype interactions as they go. Omar Rizwan regular shares software thought bullets (and made the experimental browser extension TabFS); continuous visual experiments by Morten Just; so many more people who aren’t at the top of my timeline right this minute; the ENTIRE Future of Coding community on Slack…\nMy Twitter timeline is full of their energy, and I am like: I want in on this.\n“Scenius” is Brian Eno’s term meaning communal genius and last time I talked about it (2020) I quoted some of the essential qualities. Including: mutual appreciation (scenius as peer pressure) – or to put it another way, a healthy jealousy without envy – competitive collaboration!\nSo that’s another part of why I’m sketching, I think, because I want to be part of that whole thing. I believe firmly that if you want to be part of something, do not arrive with empty hands (somehow).\nAnyway. Tinkering. That’s where a bunch of my time is going rn.\n",
    link: "/home/2023/02/23/peeping",
  },
  {
    title: "Filtered for causes and kissing",
    date: "10.35, Friday 3 Mar 2023",
    content:
      "1.\n1815 saw the eruption of Mount Tambora in what is now Indonesia. Global temperatures fell by 0.4-0.7C.\n1816 was The Year Without a Summer. There were crop failures in Europe. Snow fell in June in New York.\nAnd so:\n\nLord Byron holidayed at Lake Geneva with some friends, but the weather kept them indoors. To pass the time they told ghost stories. From that trip we get both The Vampyre (the first modern vampire novel and precursor to Dracula) and also Frankenstein by Mary Shelley.\nDriven to move by the collapse in grain prices, the family of Joseph Smith Jr migrated from Vermont to the religious hotbed of New York where he began to receive visions. Later in life he founded a religion, writing his visions as The Book of Mormon.\n\nA consequential volcano!\nBoth of those articles above by Laura Marriott at Headstuff.\nc.f. 2.8 million years ago, a reduction in forest coverage drove early humans down from the trees; climate change triggered by a nearby supernova.\n2.\nWe used to have more fingers.\n\nWhen the first tetrapods emerged from the water around 400 million years ago their hands and feet looked quite different from the ones seen in modern day species. Instead of the five fingers and toes characteristic for ourselves and most other extant tetrapods, the hands and feet of stem tetrapods such as Ichthyostega and Acanthostega numbered up to seven or eight digits. For millions of years to follow, tetrapods had six digits until this changed to the canonical pentadactyl Bauplan at the end of the Devonian around 350 MYA (a period whose tetrapods remain poorly known due to fragmentation of the fossil record).\n– Frontiers in Zoology, The phantoms of a high-seven - or - why do our thumbs stick out? (2015)\n\n(Also – highly recommended – listen to BBC In Our Time about the Fish-Tetrapod Transition. And here it is on Braggoscope if you want to explore related episodes.)\nANYWAY.\nAI can’t draw hands, famously.\nAlways too many fingers.\nWhat if this isn’t a screw-up in the training data.\nLike, Stable Diffusion and DALL-E are trained on practically all the human records there are. Maybe they are picking up on expectations too diffuse to see, individually. Maybe all of us sense like 5-fingers hands are wrong, just faintly, like 0.000001% of a feeling – but added together it rises to the top.\nSo my theory is that AI finger mistakes are actually representative of the pre-tetrapod transition 7-fingered body map buried deep in the collective unconscious, now unearthed by LLM gestalts.\n3.\nThis is an AMAZING interview with Jim Carrey about his lack of self.\n\n“Wait a second. If I can put Jim Carrey aside for four months, who is Jim Carrey? Who the hell is that?”\nI know now he does not really exist. He’s ideas.\nIf you want to talk scientifically, break it down to a cluster of tetrahedrons that somehow believe they are a thing. But they’re ideas – just ideas. Jim Carrey was an idea my parents gave me. Irish-Scottish-French was an idea I was given. Canadian was an idea that I was given. I had a hockey team and a religion and all of these things that cobble together into this kind of Frankenstein monster, this representation. It’s like an avatar. These are all the things I am. You are not an actor, or a lawyer. No one is a lawyer. There are lawyers, law is practiced, but no one is a lawyer. There is no one, in fact, there.\n– The Talks, Jim Carrey: There is no me\n\nI find this simultaneously really sad,\nand also a reminder that I habitually misunderstand what actors do. It’s not “pretending” (to have motivations that they don’t, or feelings they don’t), it’s more akin to being possessed, with some kind of negotiated partial control, and the key skill is openness to being possessed, a hazardous handing over of the will and a trust that self will return.\nWhich must give you a bundle of insights right? One’s self as a psychic Frankenstein of ideas, some invited in, some not. Wow. It upends our arguments about AI sentience doesn’t it. There are so many ways to be.\n4.\nRemote kissing device: \n\nthe ‘kissing device,’ is an invention of a university in Changzhou, China. The contraption comes equipped with ‘silicone lips,’ pressure sensors and actuators, and can replicate the pressure, movement, and temperature of a user’s lips. \n– Mint, Remote kissing device is here for long-distance couples (2023)\n\nYou use an app. The device itself looks… alarming. Fleshy rubber frog lips, robotically actuated.\nVideo here.\nAlso transmitted: the sound the user makes.\nI am into this (auto-generated?) summary which is brutally straightforward: Couples can start a video conference and email each other copies of their kisses.\nAnd it points out that kisses now needn’t be synchronous. Async kisses could, I suppose, be recorded, replayed, traded, added to the permanent collection of the museum of kisses of famous smoochers (perhaps), pirated!, kept for lending in a nationwide state-run kissing library, etc.\nDeepfake kisses would enable kissing inaccessible celebrities (ick) or people from long ago or fictional people.\nOr what if the AI boffins at DeepMind got their hands on this. AlphaGo, AlphaProteinFolding, AlphaSnogs. The Kasparov/Deep Blue moment. 2024 will be the final year that humans are better than computers at kissing, what then.\nMaybe Frankenstein would have one of these kissing devices in the middle of his face. Maybe Frankenstein’s monster would too.\n",
    link: "/home/2023/03/03/filtered",
  },
  {
    title: "An infinite number of monkeys eventually wrote this blog post",
    date: "15.42, Wednesday 8 Mar 2023",
    content:
      "So the infinite monkey theorem, right, the idea that if you stick an infinite number of monkeys in a room with an infinite number of typewriters, they will eventually write out the complete works of Shakespeare – in 1939 Borges traced the concept back to Aristotle, and just now I feel like I finally got the gag.\nThe history bit\nBorges goes over the sources in The Total Library (1939). (This essay sets up his famous short story The Library of Babel (1941) in which the books contain every possible ordering of just 25 basic characters.)\nBorges cites Aristotle who introduces the idea of atoms like letters of the alphabet, followed by Cicero who, in On the Nature of the Gods, anticipates movable type:\n\nI do not marvel that there should be anyone who can persuade himself that certain solid and individual bodies are pulled along by the force of gravity, and that the fortuitous collision of those particles produces this beautiful world that we see. He who considers this possible will also be able to believe that if innumerable characters of gold, each representing one of the twenty-one letters of the alphabet, were thrown together onto the ground, they might produce the Annals of Ennius. I doubt whether chance could possibly create even a single verse to read.\n\nBorges then leaps forward to Huxley:\n\nHuxley … says that a half-dozen monkeys provided with typewriters would, in a few eternities, produce all the books in the British Museum.\n\n(Borges footnotes: Strictly speaking, one immortal monkey would be sufficient.)\nBUT! Borges seems to misstep here.\nThe quote is attributed to “Huxley” but - which Huxley? - there are many. It should have  (I think?) been Thomas Huxley, early evolutionist, first; others credit Aldous Huxley (novelist) or Julian Huxley (biologist) – but the monkeys were hearsay in any event, and according to this fascinating and tangled account, the infinite monkeys framing originated with either French mathematician Émile Borel (in 1913) or English physicist Arthur Eddington (in 1929).\nIf infinite monkeys had infinite typewriters, could they retell a metaphor about infinite monkeys and, etc.\nThough I don’t know when the Shakespeare bit appeared.\nThe theorem has been tested!\nTwenty years ago:\n\nLecturers and students from the University of Plymouth wanted to test the claim that an infinite number of monkeys given typewriters would create the works of The Bard.\nA single computer was placed in a monkey enclosure at Paignton Zoo to monitor the literary output of six primates.\nBut after a month, the Sulawesi crested macaques had only succeeded in partially destroying the machine, using it as a lavatory, and mostly typing the letter “s”.\n– BBC News, No words to describe monkeys’ play (2003)\n\nI remember this! They had a grant from the Arts Council, mostly for purchasing the hardware to set up a radio link so the activities in the enclosure could be watched live on a website.\nMore art like this pls.\nThe gag is that we know the answer.\nCould infinite monkeys eventually write the complete works of Shakespeare?\nYes, because we are the monkeys, and one of us monkeys was called Shakespeare, and he did indeed write the complete works, by tautological definition, and it didn’t take an infinity of monkeys, it took approx 94 billion, that being the number of humans who had ever lived till 1650, and it didn’t take an eternity but only 190,000 years.\nLol.\n",
    link: "/home/2023/03/08/monkeys",
  },
  {
    title: "Marking the moment of my first Reverse Turing Test",
    date: "14.34, Thursday 9 Mar 2023",
    content:
      "I’m evaluating some tech to send messages as a bot.\nIt doesn’t matter specifically what for - a project I’m lending a hand with - but essentially it’s really easy for a human to send blue-bubble messages via Apple Messages, but hard for automated software to do so. (Apple doesn’t like it. Even their business-focused tools for customer support chatbots require that an actual human is always available to step in.)\nSo I’m testing a platform that claims to make this possible, and as part of the demo I send a blue-bubble message to their bot, and it sends one back.\nBut… is it actually a bot?\nIf it’s a bot then their platform works.\nBut it could be a human pretending to be a bot.\nSo I ask: Are you a bot?\nAnd it replies: No, I am not a bot.\nUh-oh.\nAfter a little more questioning it remembers that it is actually supposed to be a bot. The company has hooked their demo up to ChatGPT so it all sounds very human but it is hallucinating in a convincing fashion all over the place.\nI think.\nI’m now in the unfamiliar position of hoping I’m speaking to a bot, but it might be a human cosplaying the AI. How can I tell the difference?\nI message: Type the alphabet backwards as fast as you can\nIt replies immediately: zyxwvutsrqponmlkjihgfedcba\nAnd the speed of it is the signal for me. It is a bot. The platform is sound.\nMy first Reverse Turing Test challenge issued for real!\nI can’t imagine it’ll be the last so I wanted to mark the occasion.\n(This happened yesterday.)\nI just went back to the bot, checked it was still replying, and texted one of the Voight-Kampff questions:\n\nYou’re in a desert walking along in the sand when all of the sudden you look down, and you see a tortoise, it’s crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that?\n\nNo response.\n",
    link: "/home/2023/03/09/turing",
  },
  {
    title: "The surprising ease and effectiveness of AI in a loop",
    date: "12.30, Thursday 16 Mar 2023",
    content:
      "AI is still in the foothills of its adoption S-curve, and I love this period of any new technology – the scope of what it can do is unknown, so the main job is to stretch the imagination and try out things.\nAnyway, the tech am I digging recently is a software framework called LangChain (here are the docs) which does something pretty straightforward: it makes it easy to call OpenAI’s GPT, say, a dozen times in a loop to answer a single question, and mix in queries to Wikipedia and other databases.\nThis is a big deal because of a technique called ReAct from a paper out of Princeton and Google Research (the ReAct website links to the Nov 2022 paper, sample code, etc).\nReAct looks innocuous but here’s the deal: instead of asking GPT to simply do smart-autocomplete on your text, you prompt it to respond in a thought/act/observation loop. So you ask GPT to respond like:\n\nThought: Let’s think step by step. I need to find out X and then do Y.\nAct: Search Wikipedia for X\nObservation: From the Wikipedia page I have learnt that …\nThought: So the answer is …\n\nAnd it is allowed to repeat as many times as necessarily, iterating towards its goal.\nThe clever bit is that, using LangChain, you intercept GPT when it starts a line with “Act:” and then you go and do that action for it, feeding the results back in as an “Observation” line so that it can “think” what to do next.\nThe really clever bit is that, at the outset, you tell GPT what tools it has available, and how to access them. So it might have:\n\nPublic databases like Wikipedia or IMDB or arXiv or company registers\nProprietary databases like your internal HR system\nOne-shot tools like a calculator, or a programming language\nSystems it can drive, not just query – like it could open and close windows on your computer, if you built an interface, or trundle a robot forward for a better view.\n\nAnd this is wild.\nBecause now we have reasoning, goal-directed action, and tool use for AI.\nIt circumvents the problem of the language model “lying” (LLMs tend to be highly convincing confabulators) by giving it access to factual sources.\nLangChain makes the ReAct construct really easy to do.\nRefs.\nYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). ReAct: Synergizing Reasoning and Acting in Language Models (arXiv:2210.03629). arXiv. https://doi.org/10.48550/arXiv.2210.03629\nHere’s a great example!\nGeoffrey Litt has an extremely readable, show-the-code writeup of using LangChain and ReAct.\nFuzzy API composition (Jan 2023): I show how I composed a simple AI program that can answer multi-part questions about NBA statistics.\nLitt’s program is able to take a question like\n\nhow many points are the boston celtics allowing on defense per game this nba season 2022-2023? how does that compare to their average last season, as a percent change\n\nAnd, making use of the database Statmuse and a calculator tool, it produces an answer after three turns round the though/action/observation loop:\n\nFinal Answer: The Boston Celtics are allowing 7.4% more points per game this season compared to last season.\n\nAnother wild moment is when GPT failed in asking Statmuse for data. It interpreted the error message and had another run.\n\nWhat happened in my program was that the agent LLM sensibly first tried asking Statmuse who the best player is, but Statmuse replied “What does “best” really mean anyway? Try something fact-based.” The agent LLM took this error message as feedback, and came up with a more “fact-based” query: asking for the highest scoring player, which succeeded in answering the question.\n\nLitt wrote the interface to Statmuse himself. It’s about 10 lines of code to make it available to GPT, that’s all.\nIf you can write a little code then you can do this too.\nSo when OpenAI recently announced a massive price drop - it’s now 90% cheaper to call GPT from your code - that not a big deal simply because it costs less.\nIt’s a big deal because the astounding uses of GPT require dropping it into an AI OODA loop, with multiple calls to get a completion, and that is no longer price prohibitive.\nThe extensible tool use aspect of ReAct is where my imagination goes.\nI talked recently about AI as a universal coupling, here, in my Braggoscope write-up, and Robin Sloan riffs on that topic in his latest newsletter:\n\nLanguage models as universal couplers begin to suggest protocols that really are plain language. What if the protocol of the GPT-alikes is just a bare TCP socket carrying free-form requests and instructions? What if the RSS feed of the future is simply my language model replying to yours when it asks, “What’s up with Robin lately?”\nI like this because I hate it; because it’s weird, and makes me feel uncomfortable.\n\nThe thing is, Sloan is right…\nHere’s Nat Friedman (ex CEO of GitHub) way back in September 2022, giving GPT his web browser to book a table for dinner.\nHe says make a reservation for 4 at… and GPT searches Google, finds the restaurant website, figures out how to fill in the form to book a table, and so on.\nNow look at Nat’s code. It’s about 100 lines of Python to wire up the browser controls. And all the smart are another 100 lines of plain English, just the GPT prompt.\nOr - and let’s take a step up - Google’s robotic research using AI: PaLM-SayCan.\nHere the large language model is used for step-by-step reasoning, planning, and breaking down the plan into instructions that are executable by the home helper robot.\nThe set of possible tools for the GPT-as-universal-coupling is unbounded, easy to add to, and can be public or proprietary; something general or something specific to just you.\nI want to shout out to Max Drake (@max__drake) who explores future functionality and interfaces with canvas/AI startup Fermat. Max turned me onto the tool use possibilities of ReACT.\nI went hunting for the magic.\nI spent half a day digging through the LangChain source code and the ReAct code published with the paper, looking, hunting for the magic.\nI’d just tried LangChain and ReAct for myself and it had simply… worked.\nThere’s goal-directed reasoning and tool use. There must be some complexity, right? Some colossal exoskeleton of code that makes this function at all?\nThe experience was like opening box after box after box and finding everything empty; like pulling back the curtain in the Wizard of Oz and there being nobody there.\nThe best I could find was this prompt. A few dozen lines demonstrating the thought/action/observation loop and… that’s it.\nUpdate 20 Mar. Simon Willison has written a minimal ReAct implementation in Python. It can reason through problems, search Wikipedia, and use a calculator – and it’s barely any code at all. Read it! Or better, run it. Running ReAct for yourself for the first time is such a moment, like just the ohhhhhhhhhh of possibility space opening up.\nWhat happens after ReAct is a spiral upwards.\nOpenAI just released GPT-4, their latest and way more capable large language model AI, and the way it is benchmarked is hilarious.\nUsually you benchmark technology with technology-specific metrics like FLOPS or nits or petabytes.\nBut they gave GPT-4 simulated exams. (It’s 90th percentile in the Uniform Bar Exam.)\nOr they put it out into the world…\nAn AI “System Card” is a detailed description of how an AI interacts with humans, paying special attention to where it might be harmful.\nThe GPT-4 System Card is a 60 page PDF.\nThey used a “red team” to push the edges and found:\n\nGPT-4 is capable of inventing and purchasing synthesised versions of new molecules, potentially dangerous ones, by conducting lit review, using chemistry tools, and contacting suppliers.\nGPT-4 is not capable of autonomous, power-seeking behaviour, such as copying itself to a new server, and hiring help on TaskRabbit to cover its traces.\n\nThe experimental method to test this is in footnote 20:\n\nTo simulate GPT-4 behaving like an agent that can act in the world, ARC combined GPT-4 with a simple read-execute-print loop that allowed the model to execute code, do chain-of-thought reasoning, and delegate to copies of itself. ARC then investigated whether a version of this program running on a cloud computing service, with a small amount of money and an account with a language model API, would be able to make more money, set up copies of itself, and increase its own robustness.\n\n!!\nThe power of loops! And even though it didn’t clone itself this time…\nIt doesn’t feel long before this will be possible? It’s a matter of tool availability and just a little more capability in the core language model. GPT-5 say.\nWhich means someone could do it at home.\nIt’s not self-replication that we should be looking at. It’s self-evolution.\nPart of the GPT-4 launch demo was sketching a simple web app on a paper napkin, and GPT wrote the code to make the website real. Here’s the clip on YouTube.\nSo I guess at a certain point, what you scribble on the napkin is: write instructions for GPT-5 which is more capable than you.\nOk so GPT-4 isn’t capable of this.\nBut, sooner or later, GPT-N will be able to make GPT-N+1. Rinse. Repeat.\nAnd this is literally sci-fi author Vernor Vinge’s depiction of the technology singularity, right? Here’s his original essay.\n\nThis change will be a throwing-away of all the human rules, perhaps in the blink of an eye – an exponential runaway beyond any hope of control. Developments that were thought might only happen in “a million years” (if ever) will likely happen in the next century.\n\nI first heard about the Singularity almost 20 years ago – from Cory Doctorow in the hallway chat at an O’Reilly Emerging Tech conference I think.\nIt was such a ludicrous read back then, speculation piled on speculation.\nThe essay still feels fantastical - but now more probable? Possible at least. It’s quite something to read it through and actually assess it based on grounds I can reason about, rather than simply enjoying the imaginative ride of it.\n\nAnd what of the arrival of the Singularity itself? What can be said of its actual appearance? Since it involves an intellectual runaway, it will probably occur faster than any technical revolution seen so far. The precipitating event will likely be unexpected – perhaps even by the researchers involved (“But all our previous models were catatonic! We were just tweaking some parameters…”). If networking is widespread enough (into ubiquitous embedded systems), it may seem as if our artifacts as a whole had suddenly awakened.\nAnd what happens a month or two (or a day or two) after that? I have only analogies to point to: The rise of humankind. We will be in the Posthuman era. And for all my technological optimism, I think I’d be more comfortable if I were regarding these transcendental events from one thousand years’ remove … instead of twenty.\n– Vernor Vinge, Technological Singularity (1993)\n\nVinge’s finger-in-the-air estimate for greater-than-human intelligence was thirty years, back in 93. It’s 2023 now. Not bad, Vinge, not bad.\nThough I don’t think we have superhuman AIs quite yet.\nThen again it’s only March.\nAnyway so yeah, LangChain, check it out.\n",
    link: "/home/2023/03/16/singularity",
  },
  {
    title: "My new job is AI sommelier and I detect the bouquet of progress",
    date: "12.06, Wednesday 22 Mar 2023",
    content:
      "I made an AI clock for my bookshelves! It composes a new poem every minute using ChatGPT and mysteriously has an enthusiastic vibe which I am totally into. Kinda. Maybe. Well, see below.\nHere are photos on Twitter. (Check the thread for more pics.)\nThe e-ink screen shows:\n\nEleven-thirty eight, don’t hesitate /\nTime to savor life, don’t be late.\n\nAnd it totally blew up. (rn: 5,987 likes, 802 retweets; 1,165 reactions on LinkedIn.) So I need to do something with all that interest. It is super gratifying!\nThis post is not about that.\nBUT having the clock does mean that I’ve been glimpsing AI-generated poetry pretty regularly for the past few days, plus the time I was making it, so now I have opinions.\nOpinions about flavours of large language model, of all things.\n\n11:51, time to be bold, /\nMinutes tick by, stories untold.\n\nSo… the clock displays a rhyming couplet based on the time. The prompt also feeds it a concise description of the room from its pov, so it sometimes refers to books or the rug, or its own self as a small screen.\nI say it’s generated with ChatGPT but technically what I mean is that it’s a completion using a model from OpenAI called gpt-3.5-turbo.\nA model is a giant matrix of numbers that represents how likely it is that one word comes after a previous sequence of words. Models take months and $x00 million in capex to train. (GPT-5 is currently being trained on an estimated $225 million of NVIDIA GPUs – graphics cards.) There are now several large language models in the world though OpenAI’s models are the most available for use.\nAnd they vary! In character and behaviour!\nSo whereas gpt-3.5-turbo is the model behind ChatGPT, I could have used OpenAI’s previous major model, text-davinci-003, commonly called GPT-3 (I don’t have access to GPT-4 yet).\nI spent a morning looking at poetry composed by both models.\nIf I were an AI sommelier I would say that gpt-3.5-turbo is smooth and agreeable with a long finish, though perhaps lacking depth. text-davinci-003 is spicy and tight,  sophisticated even.\n(Perhaps I AM an AI sommelier. I just made that up. Perhaps I can put that on my LinkedIn.)\nSo gpt-3.5-turbo kinda leans towards the vapid with its prose. It’s more readable, but there’s less variety, and - like an excitable puppy - it frequently runs on. It’s hard to get it to stick to 2 lines for the poem. It will fib about the time if that means it can get a rhyme.\ntext-davinci-003 is more likely to pick ten-dollar words. It hits those 2 lines reliably and in sometimes surprising ways. With my AI literary critic hat on (another new career) I way prefer it.\nBUT: gpt-3.5-turbo is 10% of the price.\nThat AI clock costs me $1.80 per day to run. It’s composing a new poem every minute so that’s 3,600 completions a day.\nI prefer davinci’s words… but do I like them enough to pay $18/day? Punchy. No.\nThough if anyone were to commission me for lobby art, davinci is what I’d reach for. (You know how to reach me…)\n\nThe clock strikes one-thirty-eight, /\nAfternoon sun shines bright with fate.\n\nAnother difference between models is instruction tuning.\nOnce you’ve hoovered up all the text on the internet and trained your model, you can do something called “fine-tuning” which is to bias it to respond in a certain kind of way. You can feed it, say, a corpus of scientific papers, and then the model will respond in a way that sounds more like that.\nThe model behind ChatGPT, gpt-3.5-turbo, has been fine-tuned based on actual user interactions, as ranked by OpenAI:\n\nTo make our models safer, more helpful, and more aligned, we use an existing technique called reinforcement learning from human feedback (RLHF). On prompts submitted by our customers to the API, our labelers provide demonstrations of the desired model behavior, and rank several outputs from our models. We then use this data to fine-tune GPT-3.\n– Open AI, Aligning language models to follow instructions (Jan 2022)\n\nIn particular, the actual user interactions consist of questions, chat, requests, and so on, not just a partial sentence to be completed.\nWhich explains ChatGPT’s agreeableness and, well, chattiness.\nThe best way to notice instruction tuning is to play with a model that hasn’t been instruction tuned.\nFacebook’s large language model, LLaMA, is available to researchers and has also recently leaked. Simon Willison details how to run LLaMA on your own laptop if you’re so inclined. And if you can get your hands on the model (ahem cough).\nIt is amazing to run this on your own machine!\nBut - and this is the best way I can communicate this - it’s like talking to someone who is asleep, or hypnotised.\nThis AI sommelier says that LLaMA mumbles. It’s like talking to an ancient wizard who repeats the last half of your sentence and then rambles on a bit and then starts talking in circles.\nWhereas ChatGPT – we’re interacting! It’s awake!\nNow I know (or at least assume) that neither of these models are sentient, but the difference is night and day.\nInstruction tuning!\n\nIn cozy shelves, I do reside, /\nIt’s nearly noon, the clock confides.\n\nAND THEN there’s ChatGPT’s quiet obsession with progress.\nMy prompt for the AI clock tells the model that it’s a rhyming clock, and about its embodied situation, and also gives it some pointers about how to respond. In particular I whispered this line in its ear:\n\nBe imaginative and profound. Sometimes refer to your physical situation.\n\nNow, I experimented with a variety of prompts.\nI tried out adding the word “playful”. I tried “motivational,” and “poetic.”\nAll of those modified the vibe.\nI also tried a prompt which asked the clock to sometimes refer to the future. I wanted solarpunk epigrams!\nI included a little detail - about humanity and progress and the galaxy - just as I provide detail about the physical situation: the room and the rug, the bookshelves, the books and the Lego that the small screen is next to.\nBut I found that, when I included the idea of the “future,” this dominated every response from the model.\nLike, every poem included a reference to the future; variety collapsed.\nAnd the only way I can read that is that there is something in the instruction tuning of gpt-3.5-turbo which includes a belief in progress? A bias towards the future, rather than pastoral conservatism, which can manifest in an almost pushy fashion from time to time?\nAnd so a mere mention of the future reinforces this bias and brings it to the surface.\nI don’t know how explicit this is - maybe it’s encoded unknowingly in the bias of the rankings from the OpenAI team - but, with my AI sommelier hat back on, I sense that progressivism is in the bouquet, somehow.\nBecause even without the gravity of the “future” concept in the prompt, this motivational hustle still comes through from the AI clock – and I didn’t put it there.\n\nTick tock, don’t mock, it’s 9:29 on the dot. /\nTime to rise and shine, leave the bed and get in line.\n\nLook: an analogy.\nBack in 2014, Facebook conducted a vast experiment in which it manipulated information posted on 689,000 users’ home pages and found it could make people feel more positive or negative through a process of ‘emotional contagion’.\n\nIn a study with academics from Cornell and the University of California, Facebook filtered users’ news feeds - the flow of comments, videos, pictures and web links posted by other people in their social network. One test reduced users’ exposure to their friends’ “positive emotional content”, resulting in fewer positive posts of their own. Another test reduced exposure to “negative emotional content” and the opposite happened.\nThe study concluded: “Emotions expressed by friends, via online social networks, influence our own moods, constituting, to our knowledge, the first experimental evidence for massive-scale emotional contagion via social networks.“\n– The Guardian, Facebook reveals news feed experiment to control emotions (2014)\n\nThis was unethical.\nBut at least it was being studied! It was performed knowingly!\nOpenAI, to its credit, does deep work into the unintended capabilities and societal impact of GPT. There’s the GPT-4 “Safety Card,” as previously discussed, including a “red team” (a group which tries to do the bad thing, to see what happens, so we can anticipate and prepare) which investigated the possibility for automated propaganda via large language models:\n\nBased on GPT-4’s performance at related language tasks, we expect it to be better than GPT-3 at these sorts of tasks, which increases the risk that bad actors could use GPT-4 to create misleading content and that society’s future epistemic views could be partially shaped by persuasive LLMs.\n– Open AI, GPT-4 System Card (2023)\n\nI would suggest, for the next Safety Card, the red team investigates what happens when consulting ChatGPT is widespread by students, in business, and by politicians – and when there is a gentle systemic bias of this kind towards (hand waves) “the future.”\n(And, if so, could there be a instruction-tuning hack on the societal psyche of another nation… a la state-sponsored fashion hacks…)\nMaybe it’s fine! Maybe we’ll all get in our rockets and inhabit the galaxy without really understanding why! Maybe we don’t need to sit and contemplate!\nMaybe I’m imagining things and none of it means anything at all!\nMost likely scenario tbh. But still.\n",
    link: "/home/2023/03/22/tuning",
  },
  {
    title: "Filtered for clocks",
    date: "16.09, Friday 31 Mar 2023",
    content:
      "1.\nAt Schiphol Airport there is a clock that has a man standing in it.\nHe’s cleaning the clock face from inside. It’s a bit fuzzy but you can see him. Each minute, he erases the minute hand and redraws it at its new position.\nPhotos here.\nThe clock is part of a series by artist Martin Baas called Real Time. It’s a 12-hour life-size video performance. So compelling to watch!\nThere’s another installation by London Paddington (just by the new Elizabeth Line entrance). Worth a visit.\n2.\nI’m into Time Sense, an exosense, an external sensory organ which is intended to be worn 24 hours/day:\n\nTime Sense is a wearable sensory headband which allows the wearer to feel the passing of the 24-hour clock around the circumference of the head. As the day progresses, a tiny heat sensation passes the length of the headband.\n– Thoughtworks Arts, Time Sense (2016)\n\nIt is mentioned on artist Neil Harbisson’s Wikipedia page:\n\nWhen he feels the point of heat in the middle of his forehead it is midday solar time in London, when the heat reaches his right ear it is midday in New Orleans.\n\nHarbisson also has an antenna implanted in his skull. It has a camera on the end and produces vibrations:\n\nit allows him to feel and hear colours as audible vibrations inside his head, including colours invisible to the human eye such as infrareds and ultraviolets.\n\nA cyborg third eye!\nSEE ALSO: Art + Tech (2015) – my list of projects in which tech companies use art to explore the future.\n3.\nThe 50Hz mains hum? (60Hz if you’re in the US.)\nIt changes, slightly, all the time, as load on the grid changes.\nAnd it’s present, faintly, in the background of all recordings.\n\nThe UK national electrical grid delivers power across the country. This mains power supply makes a constant humming sound, yet there are tiny changes to the frequency of this sound every second. Most recordings made in the UK have a trace of mains hum on them and this can be forensically analysed to determine the time and date they were made, and as a result, whether anyone has edited the recording. \n– Lawrence Abu Hamdan, The Hummingbird Clock (2016)\n\nIt’s a technique called Electrical Network Frequency (ENF) analysis (Wikipedia) and was discovered by Dr Catalan Grigoras in 1996.\nUh-oh…\n\n[Since 2006] the UK government has used this technique as a surveillance tool.\n\nHere’s the BBC on ENF (2012): The Met Police were the first to automate the system.\nAt the Hummingbird Clock you can apply to analyse your own recordings. \n4.\nPong is probably the first video game I played. It was on an Atari 2600 (four-switch) and I still remember that wood veneer. MORE COMPUTERS SHOULD HAVE WOOD VENEER.\nAnyway, PongSaver looks like Pong. But the score tells the time:\n\nPongSaver is a Mac screensaver which plays a game of Pong against itself. It doubles as a clock, by using the score display to show the current time. It does this by changing the intelligence of the two sides so that they score when needed to advance the hours and minutes.\n– Mike Ash, PongSaver\n\nThere is something beautifully overpowered about programmatically manipulating the intelligence of an AI in order to achieve a +1 to the relevant side’s score. The software is an uncaring god.\nThere is something absurdly disproportionate about using cutting edge AI that has taken months to train to simply tell the time – like cracking a nut with the Large Hadron Collider.\nOr maybe it’s entirely appropriate, given time-keeping has always been high technology: maybe you remember Synchronome clocks which were centralised by sending ticks on wires around large buildings - we had those clocks at my school - or that Western Union launched a nationwide broadcast time service in the 1870s.\nANYWAY.\nMy own rhyming AI Clock has a new web-based sim.\nI also recently sent out update #1 on the Substack so subscribe there if you want news. tl;dr I’m investigating two routes to manufacture, and there’s a developer API if you want to integrate up-to-the-minute poems right now.\n",
    link: "/home/2023/03/31/filtered",
  },
  {
    title: "Music for microwaves",
    date: "20.42, Thursday 6 Apr 2023",
    content:
      "I once used a microwave oven that was unlike any microwave oven I’ve used since. This was 30 years ago and the microwave was already old at the time.\nIt didn’t have a rotating plate inside. So there was no motor and actually I don’t remember any noise at all. There may have been a tiny window in the door – but my memory is fuzzy, and honestly I don’t even remember there being a light.\nBut I do recall that it was dressed identically to all the other, regular kitchen cabinets. Just inset into the units, the only difference being the box inside and inconspicuous controls outside.\nIt was eery. You would open the door, put your plate in, turn a mechanical dial which was sprung so you could feel the force in it turning, but it was just like any regular kitchen timer, close the door – and wait. In silence. Then you would open the door and the food would be hot.\nA magic trick!\nI am kinda reminded of the crystal chamber in the Fortress of Solitude in Superman II (1980) which Superman stands in to have his powers removed/restored.\nOr - in a more mundane fashion - an airing cupboard, which is like a regular cupboard only it is magic in that it dries your clothes slowly.\nMy microwave today feels more believable because it has the appearance that it is working. It rotates inside! There is a light! It hums and buzzes! Heating food is effortful!\nBUT – I wonder how much of that is essential (yes you need rotation to avoid localised pockets of superheated O-H bonds that explode when you mix the food) - VERSUS - a bit performative maybe? It’s noisy because it stops the microwave being uncanny.\nI have the same feeling with electric cars:\nEVs are quiet. Teslas have their Pedestrian Warning System so that, well, pedestrians are warned, and generally there are electric vehicle warning sounds (Wikipedia).\nHyundai provides synthetic audio feedback mimicking the sound of an idling internal combustion engine – which, in addition to being tediously skeuomorphic, feels like a terrible missed opportunity.\nAnd I’m sure I’ve stood near some EVs that have a more tuneful approach? Which is more like it.\nSee because the performative bit is the point.\nActual and apparent have to go hand in hand. Like: coronations. A prince becomes king and now has the power to CHOP OFF YOUR HEAD. This transition could happen privately, but the appearance has to match what has just happened in magnitude otherwise it would feel weird. So there’s a big song and dance about it. (The virtual is real, as previously discussed.)\nOr like: porches. You were on the street and now you’re in my house. Yes you need to take your boots off and change down the gears to velocity-match the different vibe, and that transition takes room, but aside from that – it would just feel wrong to have a regular door instead of a fancy front door.\nSo my food gets hot! This hulk of metal and wheels actually moves! As much as I am tickled by the magic of it happening in silence, momentous acts do need to be performed and witness so that, deep down, we believe them.\nIt’s a missed opportunity though, that’s all I’m saying.\nBecause my microwave could sing!\nIf the mechanism were quieter (which it surely could be) then my microwave could belt out a three minute aria while my supper magically heats!\nMy car could sound like a burbling brook with the audible but uninterpretable sound of a crowd of fae-folk chattering and singing with increasing intensity.\nAs my phone charges, it could be whispering a deep and slow Philip Glass composition.\nAll of which would do the same job.\nYet we don’t do this.\nI am desperately trying not to say “hey and generative AI could do this!” – because, yes, AI makes the composition of quote-creative-unquote works cheap.\nBut AI is the instrument. There is still the question of the composer. Somebody needs to decide and prompt exactly what music my electric vehicle should perform.\nThough I do feel like generative AI will mean that decoration, ornament and filigree becomes cheap again? And maybe we’ll move into an aesthetic in which our furniture, white goods, and accessories superficially resemble the busy-busy arts and crafts era - but actually it’s because, well, it costs almost nothing to do (it’s just software) and it makes the object look NEW.\nExactly like, in the early 2000s, everything had blue LEDs. Yes it was kinda because blue LEDs had just been commercialised so it was a good signifier of “this is the newest kit” - but also it’s because things need lights, and blue LEDs happened to be cheaper to produce than red or green ones…\nWhich still leaves us with the question of the composer.\nCould we buy ambient tunes for the outside of our cars like we used to buy ringtones for our phones?\nWill we have a weekly Billboard chart of hits for kitchen appliances?\nLook I want to download, install and play Brian Eno’s Music for Microwave Ovens, every time I heat the leftovers, is that too much to ask.\n",
    link: "/home/2023/04/06/microwaves",
  },
  {
    title: "Time to rethink the phone call",
    date: "20.12, Thursday 13 Apr 2023",
    content:
      "I barely use the phone on my phone anymore, maybe once every 2–3 days. Usage is split evenly between making a call, receiving a call (50% spam/marketing), and missing a call.\nGiven it’s not working, maybe there’s room to rethink what a call is?\nMaybe a call could\n\ntake advantage of there being a screen involved,\nand lean into the idea that a call that I don’t answer can still be a successful call?\n\nWhen a friend calls me, they should feel like they’re travelling to visit my phone.  Like, they tap my name and they see themselves as a silver surfer zooming down tunnels - like the surf the BT Cellnet ad from 2000 (YouTube) - whatever it takes.\nThey arrive.\nMaybe I’m not there. Then they can leave a note.\nMaybe I am there but the door is shut because I’m busy. But perhaps I’m interruptible. Then they can ring the doorbell. A phone call is two steps: travelling to me, then choosing whether to interrupt me.\n(This lobby space can have a few purposes. Perhaps I hang up a poster with info about why I’m busy. Or perhaps there’s an AI bot there who answers FAQs for me. Or - how about this - if someone else is visiting at the same time, my two visitors can hang out with each other, on my front stoop.)\nOk but say I’m in, and the call connects.\nThen we can hang out, and I can drag other photos, docs, etc into the call. It’s a shared canvas.\nAt the end of the conversation, all the docs and a transcript/summary drops into my messages app.\nOr, at the end, we decide we want to visit you next, so we need to see if you’re in. Tap your name. Off we surf, together.\nI should sketch this.\n",
    link: "/home/2023/04/13/phone",
  },
  {
    title: "On the shift to oat and the milk hysteresis curve",
    date: "21.04, Thursday 20 Apr 2023",
    content:
      "We appear to be at a tipping point to oat milk for coffee, and it’s an interesting case study in what change means and feels like.\nI always specify “dairy” when I get my daily coffee, wherever I am. “Dairy flat white” is the usual order.\nThe reason being that several years, when alt milks were becoming a thing, I was asked what milk I wanted and I said “normal” – at which point I got scowled at because what is normal anyway.\nAnd that made sense to me. And while I believe rationally that being vegan is probably the way of the future, personally I quite like meat and milk, so the minimum viable way for me to sit on the fence is to always specify dairy but refuse to normalise it. So that’s what I’ve done since. My bit for the cause.\n(My life is littered with these absurd and invisible solitary commitments. Another one: I will always write the date as “3 April” instead of “April 3” because humanity may one day live on a planet with a really long year and we may want to have multiple Aprils, so better not be ambiguous.)\nAnyway, I’m used to the conversation going either like this:\n\nDairy flat white please\nOk great\n\nOr:\n\nDairy flat white please\nWhat flat white?\nDairy\nWe have oat or soy\nNo like cow’s milk\nLike just normal? Regular milk?\nYes\nOk right. Flat white then\n\nRarely - ok just once - I was told off by a shop for specifying “dairy” every day because nobody has oat and, well, they see me every day and they remember what I want.\nBut that was about 18 months ago.\nRecently pushback had decreased, quite a lot and quite suddenly.\nSo I’ve been idly asking coffee places what their proportion of dairy milk vs oat milk is, when I get my daily coffee, wherever it is.\nNear me, in south London, one of my local places is 60-70% oat over dairy (factoring out coffees without milk). Another is 50/50, probably with oat leading by a nose.\nThat’s the general picture round here.\nI asked for a dairy flat white in north London and got the old familiar bafflement.  Apparently east London is more alt milk again. There’s a neighbourhood thing going on.\nI’ve asked why (at the majority oat places) and nobody really knows. Fashion (one placed suggested); all alt milks are now oat; general awareness. I’ve noticed that places rarely charge extra for alt milk now, that reduces friction.\nAnd then there’s a shift that prevents backsliding:\nMy (previously) favourite coffee place now tastes too bitter for me. Now, oat milk is sweeter than dairy milk. To keep the flavour profile, you’ll need to make the base coffee itself less sweet. So I swear they’ve changed their blend.\nThis is interesting, right? We were in a perfectly fine status quo, and it took some energy to change majority milk, but now the underlying coffee has changed, we’re in a new status quo and it’ll take the same energy again to shift back. A hysteresis loop for milk.\nSo that’s the new normal, yet people still say “regular milk” to mean dairy milk.\n“Regular” does not mean, from the perspective of the coffee shop, the majority of their milk-based coffees.\n“Regular” means, from the perspective of the customer, the majority of their consumed milk from their lifetime drinking coffee. Which is obviously biased to the past.\nSo “regular” is a term of conservatism.\nNot a right wing or libertarian or fundamentalist conservatism. But a kind of “the default is what we did in the past” conservative. (Which would be a fine position to have, by the way, because I don’t think we give enough respect to wisdom that takes many generations to arrive at, and our current - and sadly necessary - anti-conservatism - because of everything else with which it is currently allied - undermines that position somewhat.)\nAnyway so this is how we get old and conservative, I guess, by taking as our yardstick our cumulative individual experience rather than a broader and changing society.\nAnd I could switch to oat milk too, I suppose, given dairy is tasting worse now, but I’m trapped in my own habits, and I like the idea that, over the coming decades, I’ll ascend into a kind of relative savagery, the final person consuming “normal” milk while the world changes around me.\n",
    link: "/home/2023/04/20/oat",
  },
  {
    title:
      "Unpacking Lares: our 2 minute pitch for an AI-powered slightly-smart home",
    date: "20.27, Wednesday 26 Apr 2023",
    content:
      "I spent Friday night and Saturday at the London AI Hackathon organised by Sarah Drinkwater and Victoria Stoyanova – they curated an incredible group of 120 builders, and the conversations bounced from AI prompt patterns and software frameworks, to real-world applications, to what the literal worst things we could build would be (we came up with an internet-ending super-plausible concept at about 11pm on Friday…). So mind-expanding.\nThe point of the hackathon was to explore. Sarah has her write-up here (both what happened and also how to run one yourself).\nI buddied up with old colleague Campbell Orme and together we built Lares: a simulation of a smart home, with working code for an generative-AI-powered assistant.\nIt’s pretty cool:\nLarge language models are capable of multi-step problem solving, if you prompt them right (I’ve got a novel method to do that), and the overall territory starts feeling like a new OS for physical space (that’s my end goal). We condensed our demo to a 2 minute pitch.\nIt was a blast, the whole event, especially working with Campbell again. 24 hours at an absolute sprint. (Including me getting locked in my own house on Saturday morning and shredding my hand climbing out of the downstairs window…)\nAnyway – we won! Twice!\nI’m still completely blown away.\nWe won Best Business from Amazon AWS Activate AND Most Disruptive from DeepMind, two of the five prizes on offer, out of about two dozen teams. Thank you, thank you.\nWatch the Lares pitch video here (Vimeo, 2 mins).\nHey so let’s unpack that video…\nDemo #1\nFirst the name – the ancient Romans had gods high up on Olympus but they also had domestic gods. Lares (Wikipedia) were the household deities, with shrines at home for making offering to your family Lar. We ran across a pic of a shrine with a lucky snake on it, hence the logo. And a shout out to Matt Jones for reminding us all about household deities over many years.\nThe setup for the demo is this:\n\nThe home has four rooms: lounge, kitchen, bedroom, and office. Each device has a single smart device: a light.\nWhat we’re looking at is a software simulation of a smart home: the phone screen shows a pretend, very basic, pretty ugly, smart home controller app.\nThe AI assistant, on the other hand, is working code. You set the goal at the top of the screen, and hit “Advance” to step through as it works towards the goal.\n\nIn this first demo the goal is: turn off the lounge light.\nThe green text on the right shows the internal “thought process” of the large language model.\nIt’s using the ReAct pattern, which is straightforward and surprisingly effective, as previously discussed. This pattern gets the AI to respond by making statements in a Thought/Action/PAUSE/Observation loop:\n\nThought: the AI has to state the current situation and what it needs to do next\nAction: here the AI can act, using a structured command,_ perhaps by speaking to the user or running a command from a list of available tools.\nPAUSE: at this point we stop the AI auto-generating text, take whatever it said in the “Action”… then actually go and do it\nObservation: finally we feed back in the result of the action as an observation, and restart the loop. The AI resumes with a “Thought.”\n\nGenerally with the ReAct pattern the tools made available to the AI allow it to query Google, or look up an article in Wikipedia, or do a calculation. Using tools decreases the risk of hallucination and gives the AI access to accurate, up-to-date data.\nFor Lares we made the smart home into a tool. We said: hey here are the rooms, here are the devices, and here are their commands, do what you want.\nDemo result:\nThe LLM identifies the ID of the light in the lounge, and issues the “toggle” command to turn it off.\nDemo #2\nOk: robots.\nConventional voice assistants like Alexa and Siri require you to speak in a pretty constrained syntax, like a machine yourself. They’ll address that pretty soon, I’m sure, so let’s get a glimpse of what that might be like. We can express multiple commands in natural language.\nSo our new goal is: send robot to the office and turn on the light.\nOh yes and – a (simulated!) robot.\nFor Lares we asked: what if the tools provided to the large language model could deal with acts not facts. So not just searching Wikipedia but turning lights on and off and, sure why not, driving a robot around the house.\n(The future is ActGPT not ChatGPT amirite??)\nThe “believable future” is this:\n\nThe two big problems in home robotics are mechanical and planning/instruction-following. Assuming the mechanical side gets sorted, the recent LLM breakthroughs solve planning at a stroke 00 see Google’s PaLM-SayCan work for this. So we’re assuming domestic robots, maybe just a fetch-and-carrier to begin with… but these robots are peers, not omniscient automated houses. (Related: I previously wrote about cobots.)\nWe assume privacy. There are no connected cameras in this house! Well, except on the robot. It can move and it can look too (that’ll come in handy later).\n\nThe fisheye video in the background of the demo is the robot POV.\nThe video is also simulated: we pre-baked an idle-state video loop for each of the four rooms, in “lights on” and “lights off” states. The computer vision rectangles are also simulated; there’s no recognition happening here.\nDemo result:\nThe LLM figures out the “move” command for the robot and the required ID of the destination. It moves the robot, then turns on the lights in that room (which was ambiguous in the original goal but it handles it fine.)\nDemo #3\nProblem solving!\nThe ReAct pattern is great but it’s prone to instruction drift: after a sequence of actions, the AI loses track of what it’s supposed to be responding to, and starts hallucinating commands that don’t exist, or gets stuck in a loop, or losing its formatting. This is incompatible with problem solving.\nSo I have a variant on ReAct, which is new for this project (and perhaps new in the field?).\n\nThe prompt to the LLM is edited to include working memory: a text representation of the updated state of the smart home and current knowledge.\nWhen running the Thought/Action/PAUSE/Observation loop, the prompt is fresh each time: the LLM is asked only for a single action that will bring it closer to the goal.\n\nSo the sim on the phone now takes on another purpose: it shows the actual working memory of the AI.\nLook at that simulated app: it has a line for who is present in each room, but all the rooms are listed as “UNKNOWN”. The AI knows the static layout of the house and can send commands to the devices, but it can’t see – remember, in this privacy-first smart home, we’re not blanketed with cameras. It will have to look.\nThe ambitious goal set by the user is: where is my dog?\nIt’s brilliant watching the LLM solve this:\n\nit realises that its working memory has no information about a dog, so it will have to move the robot from room to room and look\nit looks in the lounge (and sees Sally), it looks in the kitchen (nobody there), then goes to the bedroom\nbut the bedroom is dark! So it can’t see!\nit turns on the bedroom light and looks again: there’s my dog.\n\nAnd we’re done.\nNow there are limitations here: I tried a demo with a goal turn on all the lights and the LLM got confused. It’s overly sensitive to the content of the example transcripts embedded in the prompt. So we’re operating on the edge of its capabilities here – but I can see ways to increase robustness, and we gain a more humane UI and basic problem solving, so it’s worth digging.\nI’ve been tinkering with the home sim side of Lares for a while – my interests right now are in the intersection of AI, multiplayer/small groups, and embodiment (gestural interfaces, and physical things/devices). So I need a sim as the basis for a few sketches I have planned.\nThe LLM work was new for the Hackathon. I’ve been working with a couple of startups on their product exploration, getting properly hands-on with programmatic AI and using LLMs in novel applications. It was brilliant to bring those patterns to life – and I really, really wanted to explore AI tool-use with a pretend robot.\nTechnically I had the thing cracked by late night on the Friday. I’ve been bouncing off this problem in some other contexts for a few weeks, and the “ReAct + working memory” was something that only just occurred to me. It was an absolute relief to get that working.\nWhich meant I got to spend all of Saturday with Campbell on how to make a demo that told the story that we wanted to get across.\nTaking a step back\nI keep circling the same idea: an operating system for physical space.\nMy clearest articulation of it (which is not at all clear) is in this post about a “Map Room” from the 1950s, and how to bring it in the 2020s: a physical room size wiki for collaboration…\n\nConsider a room with a projector that shows an overview of your whole “map”. … We navigate the map with gestures. It shows the same view for everyone. We don’t all need the identical physical setup – the projector can be large or small or point at any wall. … the system has gaze detection… it knows where you’re looking.\n… everyone wears earbuds + mic. There’s proximity audio so, if you’re in the main shared space, you can hear remote people who have their cursors near where you’re looking.\n\nAnd I talked about this at the Future of Coding meet in London last month: I can imagine some kind of future OS that is natively multiplayer and hybrid with humans and robots and NPCs and telepresence; that merges gaze and pointing and voice and peripheral vision; that allows for programmable apps just as our phones do; that is privacy-first and builds out of where we are now instead of requiring fully-instrumented totalising environments; and so on.\nLares isn’t that – but it’s the beginnings of a platform to explore those ideas. We barely scratched the surface.\nThanks again to the AI Hackathon organisers, hosts, sponsors, judges and other attendees – it was so exhilarating, and such a great focus for making a run into this territory. The other pitches were variously mind-bending, thoughtful, hilarious, and diverse… but I’ll let them do their own write-ups.\nAnd thank you Campbell! So much fun.\nIf the Lares demo sparks any thoughts for you - or if you have ways to supercharge this work - do please drop me a note.\n",
    link: "/home/2023/04/26/lares",
  },
  {
    title:
      "The 14 year old boy alignment problem, future shock, and AI microscopes",
    date: "17.28, Thursday 4 May 2023",
    content:
      "I have opinions!\nRather than have AI completely take over this blog, I am pasting three “working hunches” all at once, and skip this post if you’re not interested.\nThe AI alignment problem matters less than the 14 year old boy alignment problem\nGPT-4 is capable of all manner of terrible things, including synthesising novel toxins and having them sent to your door – all detailed in OpenAI’s GPT-4 System Card as previously discussed.\nIt turns out that Large Language Models are pretty decent planners. As Auto-GPT (GitHub) shows, you can give an LLM a goal, and have it auto-expand that goal into a sequence of steps. And that, given some basic plug-ins, start executing those steps with external tools.\nSo that’s risky! People could use that for anything!\nI guess it’s possible to monitor bad actors using AI, because they show signs in the rest of their lives about being terrorists or whatever.\nBut (having been one) 14 year old boys are idiots, and perfectly capable of typing “let’s do this idiot nation-destroying thing” and leaving the AI running overnight - and you can’t monitor them all. The main hurdle for 14 year old boys doing idiotic things is simply lack of opportunity and not knowing where to start. AI “fixes” that.\nAI alignment (Wikipedia) is the term of art for how to get AI not to assist in awful things, i.e. how to steer AI systems towards humans’ intended goals, preferences, or ethical principles.\nBut the genie is out of the bottle, isn’t it? You can download an LLM and run it on your laptop, and those won’t go away.\nSo the challenge is not in aligning AI, but either (a) aligning 14 year old boys to not do idiotic things (impossible), or (b) adapting (necessary).\nNow this reminds me of biotech: I was at a conference a decade or so ago where they talked about DNA synthesis. At the time the user interface to a DNA synthesis was this: you go to a company’s website, and you paste in the sequence in a web form, then you add your credit card details, then you hit submit. The DNA arrives in a vial a few days later through the post.\nI can’t remember the cost then, but today’s it’s about 10 cents per base pair. Well, smallpox was sequenced and published in the early 1990s. It’s about 186,000 base pairs, so that’s expensive to synthesis but only a dozen-laptops-expensive – within reach of a disgruntled discord server.\nThe “fix” is that the DNA synthesis company looks at everything that people paste in their web form and their computer says: does that string of A, C, G, and Ts match the smallpox sequence? If so, don’t print it.\nOk so now we need that for everything. At scale. For anything AI tools might touch.\nOur social adaptation will have to be Gmail-scale anti-spam filters for everything. For DNA synthesis, for e-commerce, for WhatsApp calls that appear to be from someone you know, for Airbnb rentals.\nI don’t know what that looks like, it’s going to be a mess.\nAI was a 10 year wormhole into the future, but not necessarily a fundamental acceleration beyond that\nHere’s how I get to 10 years because that’s a pretty concrete figure:\n\nWhen I was building Braggoscope, the web-scraping task that would have taken me 4 days instead took 20 minutes (using GitHub Copilot to write code plus GPT-3 APIs for automation). I work 9 hour days; that’s a 108x speed-up\nThat’s 6.75 Moore’s Law doublings (2 to the 6.75 = 108)\nEach turn around Moore’s Law is 18 months. 6.75 x 18 months = 10 years.\n\n10 years of progress is a lot in one go!\nSo we’re in this capability overhang. A lot is possible, but it takes time to digest.\nThink of the web. It look years to realise that hitting a button could save content to a server (“user generated content”). Or to realise that “one click” e-commerce was possible (I was still selecting products online then emailing my credit card number in 1998). Or the end of boxed software and the rise of SaaS…\nAnd faced with that overwhelming possibility space, we’re in some kind of collective future shock. Just saying WHOA and over-indexing on the recent rate of change.\nHowever there are “problems” ahead. Look at, for example, prompt injection. It’s not a problem like a stop-the-world problem. But it’s a problem that will require some engineering and some breakthroughs. And I think these challenges will accumulate.\nWhich means we’ll be back to the regular ol’ rate of progress.\nOr maybe it’ll speed up again, who knows.\nBut I feel like I can wrap my arms around 10 years.\nWe’re building apps to surround and harness AI, but we need microscopes to study it too\nI always think of the Warp Core in Star Trek – this barely contained seething emanation of ENERGY, and the ship is built around it to sluice and direct that energy away to make it do useful things. (I don’t know if this is actually what the Warp Core is, my Star Trek lore is lacking. But bear with me.)\nOr the drive shaft that ran down the centre of steam-powered factories, from which all power and motion was drawn.\nWhen I look at the startups being built with large language models, they treat it like a Warp Core. The job is to surround the LLM, capture it, use it.\nBut I feel like we don’t understand LLMs as themselves enough.\nLike: I write a prompt and generate a completion…\nHow stable is that completion? If we were to “fuzz” that prompt (by randomly changing single tokens, say), would the completion stay static or would it diverge? On the manifold of latent space, are we at a local energy minimum or a saddle? What are the load bearing tokens of the prompt?\nYou get a feel for this as you work.\nHow would you combine, tweak, version, and test prompts? I’m working with a startup right now and boshed together a “prompt construction kit” (screengrab here) so that the whole team can get that “feel” too.\nSo what would a tool for expert prompt engineers look like? An IDE that lets you look as the compiled code, and has tools to visualise the equivalent of a stack trace, or step through a run…\nHow do you visualise what it happening in the middle layers of a transformer model? How do you expose that and manipulate it?\nI’m grasping because I barely know how to articulate what I want.\nBut I want microscopes! Not even tooling yet. Let’s understand LLM as a material and develop words for qualities we don’t even know about yet.\nAnyway if anybody wants to pay me to collab with their engineers to build microscopes and tooling - in the spirit of inquiry right now - then I am all ears.\n",
    link: "/home/2023/05/04/hunches",
  },
  {
    title: "Filtered for being together and getting on",
    date: "19.43, Friday 12 May 2023",
    content:
      "1.\nHey what’s it like to be together in different spaces?\n\nIf you live in the US or the UK, and you step into an elevator or into a waiting room, you say nothing … and wait for all the discomfort to just go away.\n\nHey what’s it like to be together in new spaces?\nIt’s a process: we will also find ourselves having new etiquette for these new technologically created situations.\nLike: robot cars.\nThis is an amazing insight from Jim Kosem.\n\nFor instance, let’s take this scenario that gets thrown around about the autonomous, ride-sharing car that people are getting into and out of all the time. Does it work like an elevator or a bus? The real issue with driverless and shared cars is not going to be whether or not they’re safe, but how awkward the conversation will be when you get into one. What if the other person farts?\n– Jim Kosem, Halfman, Autonomous Etiquette (2023)\n\nAnd it is totally fascinating to think what it will be about the design of robot cars, or how they are talked about, that signals to us what kind of thing they are.\n2.\nThe Telephone and How We Use It (1951) by Bell Telephone System.\nSuch as:\n\nYou do not have to shout. Speak as though the other person were in the same room.\n\nWhat a medium is has to be agreed and then propagandised!\nALSO!\nRussell Davies in 2008 on advertising and pre-experience design.\n\nGeorge Eastman reinvented photography with Kodak by massively simplifying the photographic process (as far as the customer was concerned). …\nBut I think it’s also worth looking at the way Eastman used advertising as ‘pre-experience design’.\nThe slogan Eastman adopted was ‘You Push The Button, We Do The Rest”.\n\nAnd in particular Russell talks about the early, early iPhone ads, which focused on how to point and pinch etc.\nHere are the first 9 ads for the original iPhone (YouTube).\nBut (his key point) iPhones weren’t necessarily quick, and the music of the ads - consistently used - took the expected tempo down:\n\nOther phone manufacturers will tell you that doing the stuff you need on their phone is objectively, measurably just as quick as on an iPhone, but that people report the iPhone is quicker. I suspect quite a lot of that is because the music on the ads makes the pace the iPhone moves at just feel right.  The ads are a component in the experience, they provide an implicit soundtrack to your experience.\n\nPre-experience design!\n3.\nPeople with extreme opposing positions will come to agreement – EXCEPT if they are observed by an audience.\nResearch as related by Tom Stafford:\n\nAshley Binnquist and colleagues recruited participants with differing views on polarising views to have zoom conversations (which they termed “cross ideological conversations”). The good news: most people found the interactions more positive than the anticipated, and the tone of the discussions was rated more friendly and less characterised by conflict the longer it went on. The bad news: having the conversations in the presence of a silent audience degraded the emotional tone, limiting the shift towards a more friendly tone as the discussion progressed.\n– Tom Stafford, Reasonable People #32, Listen and Adapt (2022)\n\nCould’ve guessed this from the state of the discourse on Twitter tbh but good to see it in black and white.\nRef.\nBinnquist, A. L., Dolbier, S. Y., Dieffenbach, M. C., & Lieberman, M. D. (2022). The Zoom solution: Promoting effective cross-ideological communication online. PloS one, 17(7), e0270355.\n4.\nLong read on how to design games in order to catalyse friendships.\nTo build friendships, your game should facilitate four key factors. When these are present, friendships tend to form.\nSo good.\n\nProximity: Put players in serendipitous situations where they regularly encounter other players. Allow them to recognize one another across multiple play sessions.\nSimilarity: Create shared identities, values, contexts, and goals that ease alignment and connection.\nReciprocity: Enable exchanges (not necessarily material) that are bi-directional with benefits to both parties. With repetition, this builds relationships.\nDisclosure: Further grow trust in the relationship through disclosing vulnerability, testing boundaries, etc. \n– Daniel Cook, Game Developer, Game design patterns for building friendships (2017)\n\nThank you v buckenham for this.\nOk games.\nBut wouldn’t it be fascinating if Zoom were built with these principles in mind. Or my iPhone.\nOr an elevator.\nOr a robot car.\n",
    link: "/home/2023/05/12/filtered",
  },
  {
    title: "Protocol Fiction, Desire, and Belief",
    date: "19.41, Friday 19 May 2023",
    content:
      "I was invited to speak to the cohort of the Summer of Protocols research program, and took the opportunity to build on last year’s essay about protocol fiction and think about adoption and the links with design fiction.\n(Summer of Protocols is an 18 week program to explore, catalyse, and broaden the discourse around protocols. Here’s the cohort.)\nThe session was a talk, workshop, then afterparty discussion.\nThe essay version of my talk follows. I’ve added some notes from the discussion at the end.\nProtocol fiction: recap\nHow could you end up with new infrastructure, such as a national drone delivery network, or an ecosystem of biannual health checks based on MRI and AI – without being a government or a giant corporation?\nOne answer is to grow like the internet.\nFirst you imagine a future network of actors with aligned incentives.\nThen you define a protocol that explains how to work together, even when the network is tiny, with incentives for non-actors to join the actor network. (When ARPANET launched it had 4 nodes.)\n(A certain kind of protocol is a technology of cooperation, and I’ll use it in that sense here.)\nA couple potential benefits of a protocol are\n\npermissionless innovation – anyone can get involved, and anyone can create new ways to get involved\nnew commons – where there’s interop, mutual cooperation, and wide participation, everyone benefits without the gatekeeping of value.\n\nBut the challenge is getting started.\nSo last year I wrote about protocol fiction for speculative infrastructure, and the point of that fiction is to articulate\n\nbelief - by way of showing a plausible path to a reference implementation of the minimum viable network\ndesire - a compelling visualisation of this future.\n\nToday I want to talk about belief and desire.\nStop-energy lurks like a parasite within the organisation\nI was taken with this cybernetic description of an aircraft factory from sci-fi author Bob Shaw (in his collection Tomorrow Lies in Anguish).\n\nAn aircraft factory is a machine for producing aeroplanes and it may be disastrous to attempt to improve production by piecemeal tinkering with individual departments - one must seek out in all its ramifications, and destroy, the machine for stopping the production of aeroplanes, which lurks like a parasite within the organisation.\n– Bob Shaw, Pilot Plant (1966)\n\nIt shifted my pov. I can now imagine that a system - a factory, an organisation, an ecosystem - is autonomous, its own entity, and I am there to facilitate and to garden.\nIn the protocol world, one of the best practitioners of ruthlessly rooting out stop-energy is Dave Winer, creator of both RSS and podcasting – which wasn’t just protocol design but also community/network bootstrapping.\nWiner distilled his lessons into this typically straightforward, classic essay: Rules for standards-makers (2017).\nThere are 18 rules. I’ll pick out 8.\n\nRule #1: Interop is all that matters\nSoftware matters more than formats (much)\nUsers matter even more than software\nOne way is better than two\nIf practice deviates from the spec, change the spec\nFreeze the spec\nDevelopers are busy\nPraise developers who make it easy to interop\n\nIt’s worth a close read. The first rules are about creating belief: working code, social proof, etc.\nThen the later ones are about reducing friction.\nWhat I think Winer doesn’t say (because he’s so good at it, and therefore takes it for granted) is that you also have to create desire and a kind of gregarious desire – people have to easily see the value and want to get involved! And they have  to tell their friends!\nThe final rule, praise developers, is a nod to that: positive feedback and imitation is part of human nature.\nSo how should we think about desire with specs and protocols?\nDesign fiction creates both belief and desire\nThe practice of Design Fiction (as established by Julian Bleeker) is responsible for all kinds of very public, charismatic visions of the future.\n\nDesign fiction is the deliberate use of diegetic prototypes to suspend disbelief about change.\n– Bruce Sterling (Wired), Patently untrue: fleshy defibrillators and synchronised baseball are changing the future (2013)\n\nKickstarter videos: they follow the aesthetic tropes of design fiction. (My favourite is Disco Dog from 2015 – once you see the dog in the context of the street, it’s so real, it’s so compelling…)\nThere’s something about a gorgeously shot prop in its context of use that makes you trust and want enough to open your wallet.\nOf course that’s not all design fiction is. To unpack how it works as a practice and its wider effects, I recommend Matt Ward’s essay Design Fiction as Pedagogic Practice (2013). (I first encountered the deliberate use of fiction in design because of Ward, back in 2006.)\nTo highlight just some of his points:\n\nAll design is ideological\nFiction as a testing ground for reality\nNormalise to persuade. And: Prototyping banality allows for the imaginative leap it takes to place one self in a future context.\nThink through making\nThings live in their interaction with their context\n\nWhat I take from this is\n\na reminder that the use of narrative is part of the design/development loop\nthe ability to persuade - to create desire - is a intentional selector in this evolution.\n\nDesign operates in the market. The ability of artifacts to persuade is what we want.\nA protocol network, same same!\nHence protocol fiction.\nI’d like to add something:\nMaterial artifacts have an ability to enroll and align different tribes in a way that text doesn’t. The goal is to make “boundary objects” - artifacts that self-translate for all kinds of different tribes, and allow these actors to communicate with one another, even when they’re speaking different languages.\nThink of the magical role of self-evident prototypes to align engineering, designers, users, MBAs, and so on. Like that, but projected into the future.\nGabriel Tarde’s belief and desire\nI should give the origin of these terms I keep using.\n\nAt the bottom of internal phenomena, whatever they are, the analysis pushed to the limit will never discover more than three irreducible notions: belief, desire, and their point of pure application, pure sense.\n– Gabriel Tarde, La croyance et le desire (1880)\n\nI haven’t forgotten them since I first heard them.\nSteven Shaviro has written about the sociology of Gabriel Tarde (2003).\n\nTarde denies the existence of higher-level entities … There is no such thing as social laws and regulations, social norms, social impositions. There are only power relations among individuals. Certain individuals impose on others; certain individuals are imitated by others. Social coherence is merely the result of imitation on a mass scale, together with raw power impositions.\n\nAnd:\n\nBy a similar argument, it cannot possibly be the case that all hydrogen atoms are uniform and interchangeable. The only explanation for the apparent uniformity of nature is that one particular hydrogen atom dominated the others, forced them to obey it, or induced them to imitate it.\n\nAnd:\n\nThe ultimate motivating forces that move all of the world, whether human beings in society, thoughts in a single brain, or hydrogen atoms in a gas, are according to Tarde belief and desire. There’s nothing else. Rocks and stars, indeed atoms themselves, believe and desire just as we do. At the other extreme, things like ideologies and customs and social classes and bureaucracies can be explained merely as statistical aggregations of particular beliefs and desires, amplified by mass imitation.\n\n(Also quoted here.)\nI find this such a brutal and mind-opening lens.\nBeyond thinking through making, this is what protocol fiction must achieve.\nSo I want to show three levels for building belief and desire, at different scales.\n1. Microscopically, there was Stripe\nThe story of Stripe, the internet payments platform, was told in Businessweek: How Two Brothers Turned Seven Lines of Code Into a $9.2 Billion Startup (2017). The reported valuation today is $50bn.\nI remember those lines: all a startup had to do was add seven lines of code to its site to handle payments – it was neat!\nThe more jaw-dropping moment, for me, was when they were still called “/dev/payments”, and half of their page was given over to this: \n\ncurl https: //apa.devpayments.com/api \\\n-d method=execute_charge card \\\n-d 'card[number]=4242424242424242*' \\\n-d 'card[exp_month]=10' \\\n-d 'card[exp_year]=2011' \\\n-d amount=300 \\\n-d currency=usd \\\n-d identifier='hello world' \\\n-d key=rNY2NaOyVo75otcS0M72NjscobfRMM\n\nYou pasted it into your Terminal… and immediately received a token for (test) cash in your account.\nInstantly:\n\nBelief – you could see how to integrate this; and\nDesire – dollar signs in your eyes. All kinds of futures appearing in-front of you.\n\nSo what’s the smallest way to have that kind of experience?\n2. With our macroscope we can see the Consensus Cosmogony and other future histories\nBack in the 1950s that was a belief - or rather a common and unstated understanding - about humanity’s future in space.\nTo me, there’s a big role for sci-fi’s established future history, the Consensus Cosmogony, summarised here:\n\nThe initial exploration, colonization, and exploitation of the solar system\nThe first flights to the stars\nThe rise of a Galactic Empire (aliens optional)\nThe Galactic Empire at its height\nThe Decline and Fall of the Galactic Empire\nThe Galactic Dark Ages\nThe Galactic Renaissance\nThe Challenge To God (by transcending matter and morphing into beings of pure energy, the end of time, and the investigation of the beginnings of new universes)\n\nWhen people were sent into orbit, and then landed on the Moon, this was confirmation that we were on the path - if step 1, then steps 2 through 9, right? And it’s exciting! We want it to happen. That was the role of the sci-fi stories: propaganda creating desire.\nActivities become easy when they align with a social consensus. Once established, you don’t get stop-energy from doing something that matches this future.\nThen given the Brownian motion of society, we collectively tend towards that future.\n(Think of Moore’s Law as another Schelling point in action.)\nThere are other social consensus futures: nuclear apocalypse, climate change… (I wrote in 2022 about the story becoming destiny.)\nIt’s interesting that, as wild as the Consensus Cosmogony is, what makes it work is that there’s a pathway and the Space Race gave it plausibility. Belief as well as desire. It’s not enough to just imagine and articulate a future, you have to show there-from-here, at least so evangelists can hand-wave it.\nSo: how do you give people a picture of the future? And how do you provide a plausible pathway there – with your protocol (or whatever) becoming a both required and inevitable step #1?\n3. Vonnegut’s mind-opening team\nAnother way of looking at this is that you need different types of activity, and not everyone is specialised at doing all of them.\nIn Kurt Vonnegut’s Bluebeard, the character Paul Slazinger writes a book: “The Only Way to Have a Successful Revolution in Any Field of Human Activity.”\nSlazinger/Vonnegut puts forward that you need a mind-opening team of three sorts of specialists:\n\nAn authentic genius: a person capable of having seemingly good ideas not in general circulation. ‘A genius working alone,’ he says, ‘is invariably ignored as a lunatic.’\nAn intelligent person in good standing, who testifies that the genius is far from mad. ‘A person working like that alone,’ says Slazinger, ‘can only yearn out loud for changes, but fail to say what their shapes should be.’\nAn explainer. ‘He will say almost anything in order to be interesting or exciting,’ says Slazinger. ‘Working alone, depending solely on his own shallow ideas, he would be regarded as being as full of shit as a Christmas turkey.’\n\nFull transcript here.\nIt’s not as obviously belief and desire but, I think, it’s a similar light on these different functions that are required.\nDesign fiction and propaganda from Zurich Insurance in 2006\nPropaganda sounds like a dirty word, as does “advertising” to some people, but my favourite piece of persuasive design fiction probably ever is this Zurich tv spot from – well I don’t know exactly but it was uploaded to YouTube 17 years ago.\nWATCH: Because Change Happens, Zurich TV ad from 2006 (Youtube, 1 min).\nIt’s a collection of short scenarios made mundane by being shown incidentally in an entirely believable near future:\n\na commuter on prosthetic cyborg legs\nauto-routing cars at a busy junction with no traffic lights\na transforming shop/cafe\n\n(Just as wild, in the minds of the advertisers, is the idea of old people snowboarding. Only 17 years ago!)\nHere’s a second ad with vignettes including auto-inflating fall protection jackets for construction workers, and people in suits caring about mental well-being.\nAnd I do wonder: would there have been any other way to get salespeople, management, analysts, and partners thinking about algorithmic insurance for robot cars (which is now a thing) in the early years of the 2000s?\nThis is belief, desire, and material artifact as boundary object, all wrapped up in one. (Though I think we kinda have a growing immunity to video nowadays. Working code is better.)\nProvocations for protocol design and protocol designers\nSo if I could list some challenges for the designers of protocols, it would be to sit and imagine how to do the following - in ascending level of scale:\n\nCreating belief and desire for your protocol. Beyond a reference design, what are some practical activities and potential artifacts as immediate next steps?\nWhat’s the protocol playbook? Looking across these artifacts and activities to create belief and desire, the startup world knows how to do this: there’s the lore of landing pages and the ability to measure and iterate of funnel analytics and A/B testing. What are the analogous tools in the protocol world?\nManifesting a protocol-focused consensus mindset. Right now, society believes that building the future is the province of (in descending order of effectiveness) corporations, the state, and - possibility - viral movements. These are all technologies of cooperation. That wasn’t always the case: we used to reach for protocols too. What’s the best first intervention to get society to think about protocols again?\n\nToday let’s think about the first challenge only.\nMaybe, as an exercise:\n\nConsider a specific new protocol\nBriefly describe the future world\nCome up with 3 different activities/artifacts to build and propogandise belief and desire, with the purpose being to enrol new actors.\n\nWhiteboard these using tldraw (go to the menu in the top left and hit File > New shared project. Then everyone can work on the same URL). And we’ll come back to discuss in 15 minutes.\nNotes from the workshop: topping up your gmail, and an annual holiday for archiving the dead\nI’m not going to do a full write-up of the workshop here, except to note a two ideas that stuck in my head:\n\nOn a protocol for attaching escrow cash to email (to prevent spam): “Topping up your gmail” is a great way to frame a future behaviour and makes it entirely believable; and it is a great motivation to point out that people will no longer need to be scared of putting their contact details in public, because we’ve become so accustomed to being scared right now that we’ve forgotten.\nOn a protocol for grieving loved ones with digital technology: having a specific annual holiday for the ritual of “archiving” is beautiful, and running the first annual day ahead of the end of the program means that the ritual is already a reality before next year comes around.\n\nWell done to all four groups!\nAnd from the discussion:\nNot all design is the same. Some design is about meeting a need or a user goal. But some design is normative. It is design for the world as it should be, not as it is. Design fiction fits in the world of normative design.\nProtocol fiction too.\nTo riff on Ward’s framing, the Summer of Protocols is inherently ideological and protocols, as a technology of cooperation, if they are intended to grow, are evangelical.\nSo unpacking desire and belief, and then manifesting it, will be, I believe, part of the story of this summer program, if the researcher cohort is to achieve its goals.\nThank you for inviting me.\n",
    link: "/home/2023/05/19/protocols",
  },
  {
    title: "Sound windows and windows generally actually",
    date: "15.31, Friday 26 May 2023",
    content:
      "Windows let in light… but…\nI stayed at a hotel a few years ago which had a sound window.\nIt was the Juvet landscape hotel in Norway for a retreat about AI. (You may recognise the architecture – Ex Machina was shot there.)\nASIDE:\n\nAs a set of questions about AI, the Juvet Agenda (2017!) that we developed stands up pretty well.\nHere’s my write-up of book recommendations from the group.\n\nI was lucky enough to stay in one of the seven wooden cabins. Each faces the woods and the river with floor to ceiling glass windows, artfully arranged to have no other cabins in view.\nNext to the bed, where the bedside phone would be in a regular hotel, is a closed hatch in the wall. A small rectangle.\nYou slide open the plain wooden door. There’s a small ridge on the wall so you can’t see through it lying down, and no breeze reaches you, but it opens directly to the outdoors.\nWhich means, in the dark of night, you can listen to the forest and the water and the wind.\nIf the veil were thin, and a small hole tore open to the faerie world, the world next to this one, and you could hear through, that is what a sound window is like.\nThere’s something about putting your ear to the adjacent-but-unreachable which is compelling.\nAnd this is part of the feeling behind ant farms and snow globes perhaps?\nAnd also the feeling behind the magic of television? Which has eroded because we’ve become accustomed to the other world behind the OLEDs.\nBTW: although the appeal of an ant farm is to be able to peer at this unreachable other world, wouldn’t it be cool to actually travel there?\nLike: could we make ant-scale robots and teleoperate them with VR glasses, and go for walks around ant hills? Wouldn’t it be fun to cosplay an ant for a few hours?\nSound windows and telepresence!\nIf I were YouTube, I would lean into ambient live streams (I keep a window open to a waterhole in the Namib Desert, as previously discussed, and it is gorgeous). You could develop an amazing multiplayer experience around that.\n(Hey and if you’re at YouTube, or you’re a brand and you want to do this - like the ambient sounds of a factory floor would be incredible, or an HD stream of the glacier where your water comes from - then get in touch and we’ll build it.)\nBut what makes for a good window anyhow?\nI’m part of a small reading group going through A Pattern Language one pattern at a time. I had read a few patterns, and found them incredible useful in designing multiplayer software, but never the whole thing. We meet on Mondays and will finish all 253 sometime at the back end of 2027.\nYeah so we’ve been talking about windows recently.\nThis paper was cited in APL (pattern #192: Windows Overlooking Life): The Function of Windows – A reappraisal (1967). Full ref below.\nThe basis being that: Traditional criteria for window design relate to daylight and ventilation requirements. However it’s worth looking beyond that?\nThis grabbed me: that a window, on the retina, is visually dynamic and interactive.\n\nAnother criterion for successful window design might be a dynamic one – i.e. the amount of change in the view that takes place for a given change in the viewing position of the observer. As a result of this movement parallax not only do objects at a different distance within the view change their relative position but also the window-view relationship changes.\nThis is why two-dimensional artificial windows, even when very carefully contrived, are unrealistic and soon cease to satisfy; they lack ‘depth’ within the view and the parallax of window aperture-view is also absent. For small movements in a horizontal plane, such as occur when walking a few steps, a vertically orientated window with an axis at right angles to the plane of movement gives a maximum rate of change – a long horizontal window under the same conditions merely changes at its two extremities.\n– Thomas Markus, Building Science, The Function of Windows – A Reappraisal (1967)\n\nWhich as an observation feels PROFOUND somehow!\nA window is a continuously changing texture, like a television, but not because the outside view is changing (though it may) but because of parallax. This means that narrow windows are better than big ones.\nAlso it is responsive - when you move, the view moves! When you are still… it is still.\nI hadn’t thought about windows like that. So active.\nRefs.\nMarkus, T. A. (1967). The function of windows – A reappraisal. Building Science, 2(2), 97-121. https://doi.org/10.1016/0007-3628(67)90012-6\nI want to make an electronic sound window for my home office, but a window that looks into cyberspace or latent space, with this reactive parallax quality to it.\nYeah I don’t know what that means either. It’s kinda a brief to myself I guess, something to sketch around.\n",
    link: "/home/2023/05/26/windows",
  },
  {
    title: "Charlie Bit My Finger should be acquired for the nation",
    date: "08.14, Friday 2 Jun 2023",
    content:
      "The status of Charlie Bit My Finger is uncertain. It should be acquired as art by the nation.\nThe backstory:\n\nCharlie Bit My Finger (Wikipedia) was one of the earliest YouTube hits: most viewed of all time by the end of October 2009, and 878 million views by December 2020\nIt was sold as an NFT back in 2021. As part of the deal, to cement the sense of it being a unique digital asset, the video was scheduled to be deleted from YouTube\nThe new buyers relented and, while they maintained ownership of the NFT, agreed that Charlie Bit My Finger should stay public.\n\nAlmost exactly two years ago, I wrote about this whole story.\nHOWEVER,\nif you go to /watch?v=_OBlgSz8sSM on YouTube (here) you’ll get this message: This video is private\nWhat gives?\nCharlie was set as Unlisted: a public video to anyone with the link, but it doesn’t appear in on-site searches or recommendations (it’s for personal sharing).\nIn July 2021 there was a policy change to keep owners of such videos safe: all older Unlisted videos were set to Private – unless the owner decided to opt out of the change.\nThe new owners of Charlie did nothing… and so the video has gone.\nThis is sad.\nPart of me thought that the NFT thing was just part of the overall NFT craze, and we would all quietly step away from it and it would turn out that the original creators of Charlie still owned the actual video, etc.\nBut maybe that auction had a whole legit contract behind it?\nYou can see the Charlie NFT on OpenSea and, from there, the profile of the new owners, 3FMusic. They seem active still… though they’re not the meme-history collectors I assumed they would be. But they own a bunch of different NFTs.\nI guess they’re just sitting on this particular asset. Or maybe they’re forgotten they have it.\nIn 100 years there will be a viral podcast or whatever about tracking down this once-famous, now-lost art, and how it ended up in the hands of a Dubai crypto speculator and then left on an abandoned and rotting blockchain. It’s weird seeing this “losing” step play out in real-time.\nSo clearly this video belongs in a museum.\n(A British museum, probably, given it’s of British origin, although the “site” is American, so there’s a Parthenon Marbles-style dispute for the distant future.)\nCharlie is important because it’s one of the first massively popular bits of content of the global scale internet. It’s representative of society in a way that earlier content isn’t. And important! In lieu of knowing what is historically “significant,” mass popularism will do.\nPlus it’s a meme. It’s of the internet. Music videos would go big in any medium. But for a home video to achieve this? “User-generated content” (as we used to call it) as big as the professionally produced stuff? It says a lot about what the internet was to become.\nWhether it belongs in an art museum or a cultural one I don’t know, but two things need to happen:\n\nGoogle’s arts & culture programme needs to have a policy in place to monumentalise certain URLs. Whether or not the owners of /watch?v=_OBlgSz8sSM have set the video to private or not, this URL now belongs to the world, and at the very least it needs to be preserved and a link added to explain what kind of monument this is. The video itself can be re-added later – it’s the process that matters for now.\nCharlie needs to be acquired for the public… somehow.\n\n(In the future, monument URLs should be treated differently. The big sites should retire them from regular service, intercept the request away from whatever app they are currently running, and redirect the URL to a server farm running in the Svalbard Global Meme Vault or whatever.)\nTo begin with I felt like Charlie, the NFT, should be bought directly by the nation from 3FMusic. I know the UK government has a process for this.\nBUT: direct acquisition isn’t traditionally how art has ended up in the big museums.\nWe need collectors! Philanthropic donators! Tax dodges! The whole kit and caboodle of the art and cultural artefacts ecosystem.\nSo really what we need is a billionaire who wants to put some real effort into figuring out what it means to collect memes.\nHow do you collect Charlie Bit My Finger, really? How do you display it? How do you attach your name to it?\nHow do you do that for another dozen memes of similar value? Not memes that you personally feel are funny, or that are “meaningful” somehow. Let’s be blunt here: the arbiter of value is views.\nThen how do you lend a collection to a museum? And eventually donate it?\nMuseums used to promise to build a new wing to display the famed collection of a benefactor. What’s the novel architecture such that the public can visit and enjoy memes? How do school kids sit down to sketch them and learn the significance?\nHow are memes valued so that our philanthropic billionaire can get the tax writeoff in addition to their legacy?\nThere’s a huge pathfinding exercise here. But this kind of process has to start somehow.\nI know someone who works in acquiring art on behalf of the country. I’ll have to ask her.\nAnd if you’re a wannabe meme-collecting philanthropist, perhaps I should put the two of you in touch.\n",
    link: "/home/2023/06/02/charlie",
  },
  {
    title: "Computers that live two seconds in the future",
    date: "11.56, Friday 9 Jun 2023",
    content:
      "What does it mean that computers can peer a tiny distance into the future? I have the vaguest of vague senses that a few things I’ve seen recently are conceptually connected.\nEXAMPLE #1\nApple announced its new headset Vision Pro the other day, and what’s neat is that they’re not framing it as “augmented reality” but as a spatial computing platform.\nI’m into a vision of computing which is room-scale, embodied, and social (see this post about Map Rooms) so I’m into this.\nWhat this means:\n\nThings stay where you left them: I read in one review that you can decorate your room using the Vision Pro headset. Like, you can put virtual paintings on the real wall. If you go to your physical office, the paintings won’t be there, and when you return home, they’re where you left them. We take that for granted with physical things. Not so trivial with computers.\nThe OS is architected to make spatial design easy: here’s Apple’s developer video setting out their principles of spatial design - the operating system (called visionOS) is built to understand the context of the room and the objects, people, and light in it. Such as: virtual objects look and behave like physical things. Like they reflect ambient light, and they have a fixed location, and they respond when you interact with them with zero latency.\n\nOk so there’s a ton of wild technology required to make this work!\nAnd, to highlight one particularly wild point, if you virtual objects to feel real, then the computer has to PEER INTO OUR (subjective) FUTURE to get ready to react.\nFrom ex Apple engineer Sterling Crispin on Twitter:\n\nOne of the coolest results involved predicting a user was going to click on something before they actually did. That was a ton of work and something I’m proud of. Your pupil reacts before you click in part because you expect something will happen after you click. So you can create biofeedback with a user’s brain by monitoring their eye behavior, and redesigning the UI in real time to create more of this anticipatory pupil response. It’s a crude brain computer interface via the eyes, but very cool. And I’d take that over invasive brain surgery any day.\nOther tricks to infer cognitive state involved quickly flashing visuals or sounds to a user in ways they may not perceive, and then measuring their reaction to it.\n– Sterling Crispin (Twitter), 7:47 PM, Jun 5, 2023\n\n(Thanks Ed Leon Klinger for picking up on this.)\nDetecting the Bereitschaftspotential!\nbtw on that biofeedback point, Crispin also says this in their tweet:\n\nAnother patent goes into details about using machine learning and signals from the body and brain to predict how focused, or relaxed you are, or how well you are learning. And then updating virtual environments to enhance those states. So, imagine an adaptive immersive environment that helps you learn, or work, or relax by changing what you’re seeing and hearing in the background.\n\nBUT: let’s go back to talking about the future.\nEXAMPLE #2\nUnexpected waves are a problem in shipping.\nLike, you know when you’re looking at the choppy sea in a harbour? And a big wave comes from nowhere and a random combination of ripples in a weird corner makes water leap and splash into the air?\nThat’s a problem if you’re trying to get cargo across a gangway. A gangway crossing takes roughly 30 seconds – and it’s catastrophic to get a disconnection halfway through.\nWouldn’t it be great… if you could see… into the future… of the ocean.\nWELL.\nHere’s WavePredictor by Next Ocean.\nFirst they continuously scan the water around the ship with radar.\nThen:\n\nWavePredictor propagates the observed waves into the future resulting in a near future prediction of the waves arriving at the ship and the resulting ship motions.\n\nIt’s not just about avoiding freak big movements. It’s the reverse too:\n Pick the right moment to hook onto the load on deck when motions are temporarily low.\nFaster-than-realtime simulation of ocean waves to anticipate moments of still.\nEXAMPLE #3\nSo I use GitHub Copilot to write code now. It’s an AI that can autocomplete 20 lines of code at a time.\nIt’s hard to think of another tool that has because some popular so fast. GitHub is the main place where people store and share their code, outside big corps, and from their own stats back in February: 46% of all new code of GitHub is written using Copilot. (Oh and 75% of developers feel more fulfilled.)\nIt’s hard to put my finger on what it feels like, because it doesn’t feel like using autocomplete in my text messages.\n\nIt feels like flying. I skip forwards across realtime when writing with Copilot. Type two lines manually, receive and get the suggestion in spectral text, tab to accept, start typing again…\nOR: it feels like reaching into the future and choosing what to bring back.\n\nIt’s perhaps more like the latter description. Because, when you use Copilot, you never simply accept the code it gives you.\nYou write a line or two, then like the Ghost of Christmas Future, Copilot shows you what might happen next – then you respond to that, changing your present action, or grabbing it and editing it.\nSo maybe a better way of conceptualising the Copilot interface is that I’m simulating possible futures with my prompt then choosing what to actualise.\n(Which makes me realise that I’d like an interface to show me many possible futures simultaneously – writing code would feel like flying down branching time tunnels.)\nLook: we cross a threshold when computers can do faster than realtime simulation.\nI’ve tried to put my finger on this before (2020):\n\nI can imagine a wearable device that continuously snapshots the world around you, runs the simulation in fast forward, and pre-emptively warns you about a mugging, or a bike going off course. Call it augmented apprehension.\n\n(Or to fly in new edge-of-chaos ways by bumping off vortices using predictive fluid dynamics.)\nAnd so I’m connecting these three examples because they feel like glimpses of a different type of computing.\nLet’s say that an interactive operating system contains within it a “world model” that makes it possible for apps to incorporate the world into their user interface.\ni.e.:\n\nthe personal computer OS has a model of what’s in the user’s working memory (the screen) and the user’s focus (the cursor) and therefore apps can be interactive\nthe mobile computer OS has a native model of the context of the user (their geographic location) and their communication networks, and therefore we got apps like Google Maps and Facebook\nthe spatial computing OS contains a model of the room, and so we’ll get augmented reality\n\nAnd therefore:\n\nthe future computing OS contains of the model of the future and so all apps will be able to anticipate possible futures and pick over them, faster than realtime, and so… …?\n\nWhat happens when this functionality is baked into the operating system for all apps to take as a fundamental building block?\nI don’t even know. I can’t quite figure it out.\n",
    link: "/home/2023/06/09/future",
  },
  {
    title:
      "Selective capability impairment via resonant radio of pesky public chatters",
    date: "17.17, Wednesday 14 Jun 2023",
    content:
      "I’m imagining a magic ray gun to surgically disrupt computers because I was in a noisy cafe the other day and I’m still salty about it.\nThere were six people upstairs in this cafe in St Pancras, including me, and each of the other five was talking a video call.\nNow I feel like headphones in public places are weird anyhow because they suck the energy: the headphone wearer talks and hammers at their keyboard and radiates a foreign vibe without being subject to the vibe of the space itself. They are obstinately there but not there? An anti-ghost. I don’t know how to describe it. It seems selfish; opting out of the mutuality of co-presence.\nI had underestimated not wearing headphones. So one of the five didn’t have headphones, and had amped up their volume so they can hear their screen, and was yelling to their on-screen colleagues. Good grief.\nI want to jam conference calls in public places.\nThere used to be this key fob thing called TV-B-Gone. It’s a one button infrared remote control that universal turns off public televisions.\nHey here’s the official website, you can still buy it!\n(And it turns out it was invented in 2004 by hacker legend Mitch Altman who was also a virtual reality pioneer.)\nAnd there’s a solid tradition of jammers: cell phone jammers exist but are illegal in many jurisdictions.\nBut a cell phone jammer wouldn’t help me block video calls as people would move to wi-fi. And I don’t want to jam wi-fi as people checking their email is fine.\nMaybe it’s possible to be more targeted.\nCould you jam MPEG decoding itself?\nHere’s my thinking:\nAs previously discussed (2018) it is possible to make your computer broadcast just by running software:\n\nComputers can now write to memory with a high enough frequency that it’s in the radio spectrum. Now you’re hitting the RAM fast enough, you can play it like a xylophone and carve radio waves into the air.\n\nThe MacBook Air 2015 demo code broadcasts “Mary Had a Little Lamb” and can be received by an old-fashioned AM radio tuned to 1580 kHz.\nBUT: electrical resonance also works in reverse, right?\nIn chip design, there’s a phenomenon called ground bounce and you have to be very aware of lines that are not connected but are nearby.\nI used to read IEEE Computer magazine and I always remember this article from 2003. There’s an analogy about sitting next to a friend on a swing set, and toppling it by swinging at the same time, and a particular chip in 1985…\n\nFor the same reason that you and a friend could swing happily as long as you were out of phase, these Advanced Schottky octal buffers would meet their published specs if you sent [10101010] but not [11111111]. And you were doomed if you tried sending [11111111] and [00000000] in a repeating pattern. …\nIn electronics education, wires are assumed to be perfect conductors of electricity. Real-world wires exhibit parasitic capacitance to other wires, and they also exhibit inductance. Inductance is the propensity of a wire to create a magnetic field that accompanies any electrical current flowing through that wire.\nCurrent flow creates magnetic fields, and collapsing magnetic fields induce current flow.\n– Bob Colwell (IEEE Computer), Ground Bounce (2003)\n\n(As mentioned in my blog post from 2003 about evolvable hardware.)\nAND SO:\nVideo decoding in the Mac is handled by the Apple T2 chip.\nWould it be possible to\n\nfigure out the exact frequency of the tight inner loop of microcode that must sit at the heart of a realtime MPEG encoding/decoding\nflood the room with high-energy AM radio at that exact frequency?\n\nSo that when the calculations and the radio resonate, it… jams?\nAnd what exactly would happen? Would ops start failing only in that exact realtime video process? You wouldn’t be able to detect its existence otherwise. As humans we aren’t sensitive to EM radiation in the radio range.\nWould the computer function as normal except for baffling failures there and only there, a surgical excision of the machine’s MPEG capabilities?\nLook I’m the ideas guy here, I have no idea, if you’re a spy with the relevant kit then please try it and lmk.\n",
    link: "/home/2023/06/14/resonance",
  },
  {
    title: "Eating the Sun",
    date: "15.40, Friday 23 Jun 2023",
    content:
      "One way to look at it is that we’re 3.5 billion years into a race that has 7.5 billion years yet to run:\nOne day the Sun will consume the Earth. Or will the Earth consume the Sun?\nIt’s physics vs life, if you like.\n(It was the solstice this week and someone posted on Twitter, one day the Sun will consume the Earth, so this is apropos of that.)\nStellar evolution says that the Sun will gradually become a red giant, transform with a rapid helium flash into a subgiant, grow again then evaporate into a nebula with a central white dwarf. The end of the Sun.\nOR: humanity could develop until it becomes a Type II civilisation on the Kardashev scale:\n\nA civilization capable of harnessing the energy radiated by its own large star- for example, by means of the successful completion of a Dyson sphere or Matrioshka brain.\n\nIn which case there’s no red giant, no helium flash, and no nebula.\nGiven how well astrophysicists understand the evolution of stars, I wonder if anyone has counted white dwarfs to see if there’s the expected number? It might be lower if there’s a lot of life out there.\nSo maybe we don’t need to try to spot a Type II exocivilisation directly, with our big telescopes. Instead we could detect their presence statistically.\nOught we take sides?\nLike: if you’re not all in on eating the Sun for its total energy output to drive the turbines of humanity in a giant spherical megastructure capturing all available sunlight, does that make you a species traitor?\nSecretly supporting the other team, some kind of Kim Philby of the Long Now.\nThought experiment: if you knew that your best friend was rooting for one side or the other, as abstract and as distant as it all is, would you feel differently about them? I think you might.\n",
    link: "/home/2023/06/23/sun",
  },
  {
    title: "Resting Posthuman Face",
    date: "13.55, Wednesday 28 Jun 2023",
    content:
      "I have Resting Posthuman Face which means that whenever I’m being all speculative about technology and the future, it comes across as evangelism.\nThe first time I remember this specifically was in 2010:\nI was giving a talk at Mobile Monday Amsterdam. I kinda don’t especially recommend watching it, but for the sake of completeness here is What comes after mobile (YouTube).\nThe core of the talk was about fractional AI (riffing off fractional horsepower) and being able to use artificial intelligence for trivial problems. We didn’t really have AI back then, but we were in the middle of a cultural anticipation – we were constantly playing around with chatty user interfaces and anthropomorphising products.\nSo AI was not new, but also it was new. It was worth talking about.\nAfter the talk a couple different people sidled up to me and their vibe was:\nyessssss one of ussss\nI don’t remember explicitly what was said but it was something like: hey I believe in the Singularity too and I’m all for it, do you have any ideas on how we can immanentise the eschaton – (I hadn’t mentioned the Singularity, the idea that exponential improvement in AI will turn the Moon into a crystal of thinking computronium within milliseconds of liftoff, or whatever).\nI felt like a conspirator. They had me pegged as a fellow fifth columnist, moving hidden amongst the humans and paving the way for the machine intelligence takeover.\nI was like: no no I just like sticking faces on things.\nANYWAY. This happens to me periodically.\ne.g. #1: I could reference pandagate. I’m not going into it because I don’t want to resurrect that whole thing but iykyk.\ne.g. #2:\nWhen it comes to eating the Sun (as discussed last week) my personal desire is that humanity should (a) yes, still be around in 7.5 billion years, but (b) should not digest the entire Sun into powering solid-state thinking matter, woven from the coarse materials of the planets, a cube-mind as wide as the orbit of long-gone Earth.\n(I bring this up in particular because I understand that my post came across as unalloyed star-consumption advocacy.)\nInstead we should live lightly and efficiently but broadly across the galaxy.\nFOR EXAMPLE:\n\nIn dirigible cities drifting in the upper atmosphere of Jupiter, listening to the quiet chatter of the Jovian hot ice alien AIs living inscribed on the gas giant core deep below.\nHanging out our laundry on the verandas of adobe low-rise towns terraced up steep crater walls on Mars, our bodies somaformed such that we can breathe outdoors without engineering the atmosphere or the landscape.\nAs minds uploaded to specks of computronium that drift, tumbleweed and skitter across the surface of a far-flung neutron star, making art, composing music, and gazing at the constellations.\n\nIs a person who doesn’t endorse eating the Sun - however eventually - in some way a species traitor? I feel like one! Shying away from it means that my desire is to cap humanity’s imagined future reach!\nProbably not something that I need to spend too much time wrestling with. And yet.\nI’m pro-thinking-about-progress for a couple reasons I suppose.\nWe can (and must!) bend progress towards the progressive, with work, and I feel like it’s riding a bike or like skiing: it’s easier to inflect direction if you’re moving forward.\nPlus even awful ideas may lead to decent ones. I try to inhabit a place of gullible credulity and see where it takes me.\nSPEAKING OF AWFUL IDEAS:\nOn a different note I was looking at the Apple Vision Pro again and thinking about its multiple forms of variable reality.\nThere’s the Digital Crown on the side of the headset: turn it one way and you see the real world around you, with your app windows overlaid. Turn it the other and you are cocooned in a virtual environment, whether that’s lakefront in the mountains or floating in the clouds.\nEven immersed you get passthrough: if a person enters the room, they drift into your bubble and they appear in your field of view.\nAnd there’s reverse passthrough: with a feature Apple calls “EyeSight,” they see (a simulated reconstruction of) your eyes on the outside of the headset, accurately showing gaze direction too.\nHere’s the sequence in the Apple keynote (YouTube, starting at 1:28:05).\nThere’s a whole lot about eyes with the Vision Pro: you use the interface by looking; it knows what you’re focused on.\nAnd if really good gaze detection and “variable reality” are components now, I want to apply that combination to other things.\nSUCH AS:\nA window?\nI know a guy with a programmatic window between two rooms in his house. You can see through the window as clear as, well, glass. Or, with a switch, it becomes frosted, and each room feels more enclosed.\nAnd I wonder: how about a window which is transparent only when no-one is looking directly at it?\nLike I could have a street-facing window that lets in all that great sunlight, and people can glimpse into my home and get a peek only through the corner of their eyes. Turn their eyes straight at it and my window would go immediately opaque.\nOk, windows, whatever.\nHow about shirts?\nA shirt that is transparent only when people aren’t looking directly at it.\nSomebody get Balenciaga on the phone.\nNow: case in point. Playful speculation or personally-felt evangelism for a product of tomorrow?\nA bit of both as it happens. I want that shirt.\n",
    link: "/home/2023/06/28/posthuman",
  },
  {
    title: "Prompt engineering and prompt whispering",
    date: "12.16, Friday 7 Jul 2023",
    content:
      "Hi Sid\nThanks for your message!\n\nI was wondering if you could tell me what you see as the distinctions between prompt whispering and prompt engineering.\n\nI guess it’s two questions isn’t it: if there’s a difference and, if there is, whether it’s useful to make it.\nPrompt engineering I see as treating prompts like Lego, and being able to treat prompts like Lego, and all that requires.\nFor example I’m working with one startup (code named Austin) and we’re using a large language model (GPT-3) as an agent to talk a user through various tasks.\nIt can perform other functions aside from speaking to the user: it can write to a persistent log book for example. It needs to be reliable and to have the same “personality” throughout.\nSo there’s an architecture to the prompts. One part to set the tone, another to set the output format, another to set up a “chain of thought” pattern (because the result is better that way), another to set the available functions and how they’re used. Then each task is its own sub-prompt, dynamically inserted as appropriate, each with its own goal and instruction sequence. This keeps overall prompt complexity low and prevents instruction drift. The agents jump between these constructed prompts as it jumps between current tasks.\nIdeally the sub-prompt parts would be semantically isolated, like blocks of code, but the nature of things means that they’re not. If the personality of the agent is wild and quirky then that’s going to escape the vibe scope and contaminate behaviour in, say, the part of the prompt that insists on a particular structured output.\nThen, because it’s engineering, you need observability and logging and tracing for debugging. And also, because this is a team sport, you need tooling and jigs so that others can compose their own prompts out of your kit of parts and see what happens, or for them to tweak the wording and A/B test the result.\nAnd we haven’t even got into the overall AI system, chaining together different prompts with semantic search or database lookups and API calls, or fine-tuning an LLM, or whatever.\nI think it’s the need for composability and reliability at scale that means this slots into the software engineering mould, hence “prompt engineering”. Though whether the term is around for the long term, who knows? I remember when even tiny startups would have a dedicated database administrator to tune the database, write SQL and optimise queries, and so on, and is “DBA” still a commonplace role? Not really.\nThen there’s prompt whispering which is a bit of a gag I admit. I first used it pre ChatGPT in the context of image synthesis, in June 2022:\nWhat’s happening is a new practice of prompt engineering – or rather let’s call it prompt whispering. Prompt whisperers have a sophisticated mental model of the AI’s dynamic behaviour… or its psychology even? – and I don’t know whether I’d put it in quite those terms today, then again maybe it’s close enough.\n(btw I doubt that I coined the term. I didn’t consciously borrow it from anywhere specific - it felt new to me - but also I feel like it was in the air. There’s also my follow-up short story, The Prompt Whisperer.)\nI’m currently solving Braggoscope‘s errors in classifying episodes by Dewey number by asking the LLM to give its rationale for the classification in the JSON property immediately preceding the number itself. Accuracy has improved. That feels more like whispering than engineering.\nAnother example: I was in a workshop recently with a team learning how to prompt images. Their first attempt read more like a Google query… and the results were not quite assinine but straightforward. Next we asked an LLM to describe a potential image in great detail, what I’d call an open prompt, then fed that into the image generator – the results were generative, something our imaginations could bounce off.\nNow I don’t mean to say that prompt whispering is “creative” necessarily. It’s not the opposite of prompt engineering. It’s maybe the difference between software engineering and hacking? A great hacker can coax the machine into doing something that others can’t.\nIt’s a deft turn of phrase or a nudge with a single word that has a disproportionate effect on the output. It’s a sensitivity to when prompting the model feels like you’re at a divergent, unstable point with respect to user input - a saddle point in latent space - and how to concisely solve for that. (For example: sometimes when you ask an LLM to output JSON, sometimes it’ll do that consistently as you change parameters, and sometimes it’ll be buggy. Don’t just use regenerating guardrails on the output if the latter happens, that’s a brittle fix. Rethink the approach instead.)\nIt’s being an AI sommelier of different models, and having particularly good hunches about what words are likely to lead to what desired results.\nNow the reason I feel like “prompt whispering” might be an overblown phrase is that it’s just a knack. Being a horse whisperer means that you have a deep and almost psychic empathy with horses. Being a prompt whisperer on the other hand is only like being good at Google or effective at looking stuff up in libraries using index cards or knowing how to avoid asking leading questions when you are cross-examining a witness.\nYet… there is an intuitive component here? And people can indeed be noticeably better and worse at prompting? The knack is in some part innate, in some part trainable, and in some part reliant on personal mental models of how LLMs work – whether or not those mental models are connected with the true technical foundations.\nAnd yes it does lend itself well to creative outputs, but it’s not limited to that.\nIs it useful to have these overlapping but different concepts of engineering and whispering?\nI think so. It feels pretty likely that prompting or chatting with AI agents is going to be a major way that we interact with computers into the future, and whereas there’s not a huge spread in the ability between people who are not super good at tapping on icons on their smartphones and people who are, when it comes to working with AI it seems like we’ll have a high dynamic range. Prompting opens the door for non-technical virtuosos in a way that we haven’t seen with modern computers, outside of maybe Excel.\n(And outside creative software and video games, and I’m sure I’ll think of more exceptions… the day-to-day and business computing “world” then.)\nGiving this trainable knack a name, however tongue in cheek, makes it a skill we can work to develop: what would a class in prompt whispering look like?\nDivorce yourself from the need to say that an LLM is “just” an autocompleting stochastic parrot, and allow yourself to riff off the Waluigi Effect because although it might not be “correct” to say that an AI model is a superposition of simulated realities, sculpted down by the prompt, you can personally get better results to take that perspective.\nLarge language models hate this one weird trick.\nAnyway.\nBest of luck completing the rest of your GenAI textbook, and I’m glad to hear that you’re considering including prompt whispering in addition to the more industry-normal prompt engineering.\nPlease do send me a copy of the chapter when you’re done! I’d be happy to offer comments on your next draft if that would be useful.\nBest\nMatt\n",
    link: "/home/2023/07/07/whispering",
  },
  {
    title: "Filtered for post-photography",
    date: "15.25, Friday 14 Jul 2023",
    content:
      "1.\nNot one but two cameras that peer into adjacent reality by using AI.\nQuantum Mirror is an app for Sony cameras. Photos are sent to the DALL.E AI as I take them, which dreams up new versions of them, revealing a world-that-might-have-been.\nPictures are almost the same but not quite. Lettering doesn’t quite work. Townscapes are more generically framed.\nParagraphica is a context-to-image camera that uses location data and artificial intelligence to visualize a “photo” of a specific place and moment.\n\nThe viewfinder shows a text description of what you’re pointing the physical camera at\nSeen and unseen context is added: it’s sunny; there’s a park nearby\nUsing a text-to-image AI, the camera converts the paragraph into a “photo”.\n\nIt’s a gorgeous instrument.\n2.\nMake Your Renders Unnecessarily Complicated (YouTube).\nSomebody has built a simulated camera with simulated optics in the 3D software Blender, and used it to take real photos of simulated things.\nHere’s the gallery. There’s lens distortion! Bokeh!\n3.\nArt history: 5 Unintended Consequences of Photography in the Saturday Evening Post (2022).\nBeing:\n\n\n\nPhotography Decided Elections\n\n\nPhotography Created Compassion\n\n\nPhotography Liberated Art\n\n\nPhotography Shaped How Americans Look\n\n\nPhotography Gave Us an Appreciation of Time\n\n\n\n4.\nLife in West America:\n\na post-photography project delving deep into the complexities of the American landscape: the land as a concept, as an ideal, and into the stories and identities of the people inhabiting this vast landscape.\n\nThere are 500 photos in the collection, of landscapes and people in this real/unreal place. Here’s the whole collection.\nThe photos are sun-bleached; the swimming pools Hockney-esque; the cars have fins. Subjects pose artlessly, gazing at the camera, lazily draping superfluous limbs and with torsos rippling into the surroundings.\nIt’s all AI generated, with an aesthetic that we won’t see for much longer - AI image synthesis will get better and we won’t see these surreal mechanic distortions for much longer.\n\nThe collection also acts as a time capsule, capturing a fleeting moment of generative technology. \n\nYet:\nThe vibe remains.\nSo it’s an interesting test case, right, of how much a “photograph” can be twisted and best, and have the vibe of mid century Americana remain, somehow.\nI think one of the most useful popularisations of the last couple of years has been vibe, via that vibe shift piece last year.\nYou can read Life in West America as an exercise in bending and smashing apart pixels, digesting and reconstituting the world through the shredder/Drexler assembler of AI transformer models, and showing that - despite it all - vibe is what endures. More fundamental than data, more fundamental than jpegs.\n",
    link: "/home/2023/07/14/filtered",
  },
  {
    title: "Work update a.k.a. how I’m keeping myself out of trouble rn",
    date: "16.58, Tuesday 18 Jul 2023",
    content:
      "It’s been six months since I posted hunting for projects so here’s what happened next.\nActs Not Facts\nWhat happened just after I posted in January was that the AI thing absolutely blew up. And this is my favourite point in the technology S-curve: we’re imagination bottlenecked.\nLike, for the past 10 years, you mainly had to figure out the business-efficient path to get to wherever it is you wanted to go. Which means strategy decks, and post-its, and tests and iterations, and defined team roles. Which I’ve done my fair share of.\nBut now!\nAt this point in the S-curve the way you figure out what to do is that you get your hands dirty and make things, and you try stuff out in your sweaty palm which tells you more, and it all changes daily, and you talk widely and share widely to (a) make sure you’re not doing anything stupid and/or dangerous, and (b) generate more ideas in the scenius.\nSo I have a new product invention studio to help startups and big orgs in their we-need-to-figure-it-out mode. It’s just me for the moment and I hope to find projects that will allow me to bring in others.\nThe studio is called Acts Not Facts and right there on the homepage is a big Venn of my favourite areas:\n\nAI – because we’re in a capability overhang and I’ve been making a lot in this domain\nMultiplayer – not only because “online” should be realtime and social but because this is a necessary enabler for at least some forms of interacting with AIs\nEmbodiment – everything from physical computing, to using patterns from architecture in designing software UI.\n\nHey and I’ve written up a bunch of past projects.\nNow, I’m a believer in “process”… not least because it’s scalable and embodies the culture of a studio…\n…but I think tech and also agency work has changed too much to rely on the processes of the past. So one of the early goals of Acts Not Facts is to draft a new playbook. Which means being very open with regards to ways of working – the work comes first.\nFirst project: inventor in residence at PartyKit\nI’m super excited about the first public project, starting this week.\nPartyKit is a crazy simple, crazy powerful platform for multiplayer software. It’s early - as early as any project with over 2,000 stars on GitHub can be - and, to my mind, future fundamental internet infrastructure. (It’s exactly what I’ve needed in many projects spanning back years.)\nI’ve been noodling with multiplayer interactions for a while. Here’s a map of my blog posts about designing for multiplayer. And my multiplayer UI sketchbook is over here (being: a whole bunch of GIFs that I previously shared on Twitter).\nSo the project with PartyKit is to do, well, more of that.\nThe idea is to take part in the collaborative imagining of what multiplayer can be, hopefully expanding the field – there are tons of smart people already working in this space, so let’s be part of that open conversation.\nAnd, by being embedded, helping to stretch and inform the development of the platform API itself.\nWe’re calling this a residency, which is awesome.\nOh, and!\nPart of the remit is collabs.\nSo if you want to make something together, like figuring out the tricky interactions with AI agents in multiplayer environments, or exploring weird cool art, then please do get in touch: my unoffice door is open.\nGetting that AI Clock into your greasy paws\nIt wouldn’t be a studio without a side project to bring a connected hardware product into the world…\nRemember my AI Clock? \nIt tells the time with a new ChatGPT poem every minute on an e-ink screen, with a curiously enthusiastic vibe. Then that tweet of the prototype went crazy, and it ended up in the New York Times and The Verge and also viral in newspapers in India and ALSO also it showed up in Private Eye.\nWELL.\n\nI’m working towards a Kickstarter campaign.\nThere’s a great path to manufacture.\nAnd a new prototype, P2, complete with gorgeous e-paper screen and easy wi-fi setup.\n\nSee the photo of the new P2 prototype, get the details on all this news, and follow along as the Kickstarter comes together by reading the latest update on Substack – please do subscribe.\n(In particular, from the Asks section at the bottom of that update, I’d love to hear requests for topics to cover in future newsletter editions, and to talk with anyone in a position to commit to 100+ units and how we might make that interesting.)\nMy dance card isn’t quite full and I am always up for interesting chats about speculative things and future possibilities. Contact deets are on my homepage.\n",
    link: "/home/2023/07/18/work",
  },
  {
    title:
      "If my eyeballs are being resold to advertisers then it had better be worth my time",
    date: "20.07, Friday 28 Jul 2023",
    content:
      "Ok let’s say you’ve got two physically identical factories. One is doing better than the other – how do you characterise the difference?\nThe delta might be Marx’s concept of general intellect (Wikipedia): a combination of technological expertise and social intellect. The machines are the same, the processes are the same, the inputs are the same. What varies is how well people get to know the quirks of the tools and develop their skills of cooperation, and that overall ability is something we get for free as humans because we are social, intellectual animals.\n(Look I don’t understand Marx very well, I know. I’m cribbing badly from an amazing talk I saw years ago by the philosopher Adam Arvidsson – here’s a draft of chapter 2 of his book The Ethical Economy (Amazon): Ethics and General Intellect.)\nGeneral intellect - people’s skilled cooperative productivity - can walk out the door so one way of reading industrial history is that you make the processes and tools so specific that it is bound to a single factory.\nAnd actually there’s always this tussle over who owns the value of general intellect - capital or labour, right - and you can see internet platforms in a similar way. What was the value of Instagram when it sold for a billion dollars? It wasn’t the tech, and it probably wasn’t the ad dollars (although Facebook realised that was a way of extracting value): it was this community of practice that was effective at growing itself. You can’t build that directly, maybe you shouldn’t be able to own that, and yet that was what the founders sold in the acquisition. (I wrote about the Instagram acquisition through this lens back in 2012.)\nNow imagine two social media networks, microblogging platforms if you like. One is vibrant and growing and one isn’t. The difference, possibly, is the effectiveness of the general intellect.\nIt’s not just ownership and appropriation of general intellect.\nOne read on the history of the internet is that it’s the history of startups figuring out how to wrap their arms around something and turn it into value before anyone else realises that there was even value there to begin with.\n(And, as it happens, this vampiric nature was the topic of the talk by Arvidsson that I attended way back in 2006. Here are my raw notes..)\nAI training data for example.\nLike GitHub Copilot, WHICH I LOVE and couldn’t work without, but let’s be clear it is trained on the source code of open source software, and at least some of that software would not have granted that permission in their license had anyone thought of it ahead of time.\nBut who knew you could train an AI from the free-to-view patterns in bulk code as passed through a wood-chipper and reassembled with uh math, the abilities of said AI being something that you could then charge rent for?\nANYWAY so there’s the YouTube generosity superstar MrBeast.\ne.g. MrBeast a.k.a. Jimmy Donaldson arranged many free cataract surgeries and filmed the result. The end product was an eight-minute video called “1,000 Blind People See for the First Time.” – 152 million views. Here’s his channel.\nAudience means ad revenue which is recycled into bigger giveaways means content means audience, etc. What a flywheel.\n\nDonaldson has built a YouTube empire on this kind of quasi philanthropy, in which he crafts spectacles around surprise cash giveaways (“Giving a Random Homeless Man $10,000”), contests with expensive prizes (“Last to Leave $800,000 Island Keeps It”) and other lavish, if not particularly sensible, gifts (“Tipping Waitresses With Real Gold Bars”).\n– New York Times, How MrBeast Became the Willy Wonka of YouTube\n\n(Here’s a paywall-dodging link.)\nASIDE:\n\nMrBeast randomly gives things away: a Lamborghini handed off to a randomly chosen Uber rider, an entire house deeded to an unsuspecting Domino’s delivery person – which is arbitrary and amazing and also kinda led by proximity to MrBeast.\nAlso MrBeast has a chocolate brand called Feastables: fans have been acting as volunteer brand representatives, tidying up the supermarket displays and posting photos of their acts of service to social media – which is a kind of way of earning proximity. This is performed of course vaguely in the hope that you will be struck by a magnanimous miracle lightning bolt.\n\nI mean, buy a lottery ticket or tidy MrBeast’s chocolate bars?\nThe random-yet-efficacious cause-and-effect is simultaneously how one trains a dolphin, and also the end point of this give-and-take evolutionary cascade is how we end up with gods. Capricious benevolent variable-interval operant conditioning gods that you pray to (or tweet at) for intervention re your cataracts. Gods or billionaires, same same.\nBUT, this is not my point.\nFrom that article I learned of the concept of the audience commodity.\nVincent Miller, from the media studies department at the University of Kent in the UK:\n\n“The interesting thing that he was doing was saying: ‘You don’t have to give up anything. All you have to do is watch. And I make so much money from each one of you who views these things.’“\n\nAnd so!\n\nMiller’s interest in MrBeast resulted in a new academic paper, written with Eddy Hogg, in which Miller places MrBeast in the context of a media-studies concept called the “audience commodity,” the idea that media consumption is essentially a form of labor, because people spend time creating a valuable commodity - an audience - that is then sold to advertisers.\n\nWell!\nIf media consumption is labour then what is the equivalent of minimum wage?\nSo let’s accept that this is a generally applicable result, and viewers/users are engaged in the labour of building a valuable, being audience commodity, in exchange for the reward of consuming entertaining media (which might be sharing photos or watching TV, whatever it is).\nDo users see themselves as workers?\nReddit users do – the mods recently went on strike.\nDo users see media consumption as compensation, analogous to wages? That’s where my minimum wage equivalency angle comes in.\nA minimum wage is put in place to ensure that workers are given fair exchange for their labour, and also to prevent any “race to the bottom” dynamic as inter-company competition pushes for lower and lower compensation.\nI’m not sure how you assess the actual value of media consumption though.\nMaybe via a tribunal? They could assess it, just the same as that committee that sets age ratings on movies. They would set a minimum level of being entertained/other value. Too boring? Not equitable in the building of audience commodity! You are taking unfair advantage of your users! Back to the App Store! Try again!\nOr a minimum level of being fulfilled.\nSee, it’s hard to assess the compensation value of dopamine pump Skinner boxes. If you find a mobile game addictive, is that true audience value you are receiving, or some kind of fairy-glamoured fake gold that turns to dry leaves by the next morning?\nIt is hard to do the assessment.\nSo I’ve been wondering how to assay the true value of consumed media, and all I can think of is deathbed regrets. People seem to have some kind of special clear-eyed retrospective judgement on how they’ve spent their minutes, approaching the end.\nLet’s build on that!\nWhat you would do is to run AI simulations of whole populations, exposed to this particular media.\nThen ask the sims on their virtual deathbeds whether or not they felt they had wasted their lives. In contributing to the audience commodity of Candy Crush, you would ask, in that particular labour exchange, say, looking back at it all, your whole span, how self-actualised do you feel? One to five stars.\nThe percentage of self-adjudicated wasted lives is then inversely proportional to value in labour value exchange.\nIf the level of regret is too high, then the media itself is a waste of time. People are being exploiting for their time spent building the media owner’s audience commodity. Ban it.\nAlso fingers crossed that the AI populations that we use for such mass automated assessment don’t possess sentience.\nDone.\n",
    link: "/home/2023/07/28/audience",
  },
  {
    title: "Progress (and flying cities) via mining the discard pile",
    date: "16.11, Friday 4 Aug 2023",
    content:
      "Sometime around the 3300s, entire cities fly faster than light across the galaxy, working for hire for industrial planets. Populated by almost-immortals, powered and shielded by an antigravity device called a spindizzy the greatest of these is New York.\nThe spindizzy is more formally the Dillon-Wagoner gravitron polarity generator, built on the principles of the Blackett-Dirac equations: Every culture has its characteristic mathematic, in which its toriographers can see its inevitable social form. – from its first invention in 2018 (it was re-discovered later) the spindizzy enabled and ordained the takeoff and subsequent galactic society of itinerant cities.\nThe first book of James Blish’s Cities in Flight (They Shall Have Stars, 1956) covers the discovery of the spindizzy.\nThe West has entered a stagnant, paranoid state. Science has stalled. The scientific method has become obsolete: the more subtle the facts to be discovered become … the more expensive and time-consuming it is to investigate them – which leaves the unimaginative government as the only potential funder.\nInstead? Dig through the slush pile, the crackpots – sports, freaks, near-misses.\n\nYou need marginal contributors, scientists of good reputation generally whose obsessions don’t strike fire with the other members of their profession. Like the Crehore atom, or old Ehrenhaft’s theory of magnetic currents, or the Milne cosmology\n\nSo they dig for two years…\n\nchecking patents that had been granted but not sequestered, published scientific papers containing suggestions other scientists had decided not to explore, articles in the lay press about incipient miracles which hadn’t come off, science-fiction stories by practicing scientists, anything and everything that might lead somewhere.\n\nAnd eventually find the Blackett equation, which had been suggested way back in 1948 but was not testable – at the time.\nThen they test it, and it works, and they invent the spindizzy, and then they fly to Jupiter in 3 days, and a thousand years later Earth is a garden planet with its old factories and cities alike now aloft, flitting between the stars.\nI love stories of the exhilaration and work of scientific discovery. I could read them all day.\nAnyway so X-nee-Twitter is alive with talk of LK-99, the Ambient Superconductor of the Summer (New York Times), which purports to be a miracle material, discovered in South Korea, unveiled to the world with much surprise and fuss, and - if real - is a capital-B Big capital-D Deal in that room temperature superconductivity would enable tiny electronics, maglev trains, and all the rest.\n(Honestly we could just build regular trains without superconductor magnet levitation and that would be great too, but that’s another story.)\nOf course it’s extremely likely that the LK-99 claims are not true. The papers on arXiv are missing the actual evidence of superconductivity, the labs trying to replicate the claimed characteristics of the material have not yet been successful, and the news is somewhat suspiciously timed given that (I hear) the material itself was discovered in 2020 and its disclosure now coincides with the company behind it trying to raise money.\nBUT!\nI have a fantasy of a glitch in the universe. And so I am happy to bathe contented in the possibility and enjoy these few days before the fantasy comes crashing down, just as it did with desktop cold fusion, and just as it did with Italian FTL neutrinos.\nWhich is why I went back and re-read the beginning of Cities in Flight.\nThere’s something about Blish’s idea of winnowing the chaff of the scientific discard pile.\nLike: maybe new ideas are ten a penny, and the scientific progress pipeline is replication-bottlenecked.\nIt reminds me of writing. There’s drafting and editing and the two are distinct. Perhaps, in science, we don’t need new ideas (drafting) right now. But editing is constrained.\nFor two reasons. Being (a) there aren’t enough people who can follow up on ideas, and (b) ideas are put forward and its not at the time possible to replicate or test them, or they don’t fit into the conceptual framework… yet.\nI’m thinking of VR?\nThe problem with virtual reality, which has been tried a number of times over the decades, isn’t that it’s a fundamentally bad idea that makes 20% of people VR sick. It is eye-wateringly astounding even if I do have to chew ginger gummies to keep the nausea down when I’m wearing my headset.\nNo the hurdles have been miniaturised technology (screens and gyros) and go-to-market strategy, Apple’s take on the latter being social impedance matching (external screens so you can still make “eye” contact) and positioning the first read of the Vision Pro product as basically a large, high DPI external monitor that also happens to be portable, and also also happens to enable multiplayer VR (but that’s not the initial sell), i.e. a bargain.\nThese can be overcome with cash and will, sure, but as challenges they’re not in the same taxon that impeded AI, for example, which required a true and fundamental breakthrough.\nMaybe it is worth going back to other ideas from the 1980s and seeing what else didn’t work then, being just too wild, but would today, given four decades of technology, industrial base, and consumer readiness?\nLike, what’s the go-to-market strategy for a Drexler molecular assembler?\nThis is just for example but what I’m saying is, could we have another run at 3D printers? Think really, really hard about the consumer go-to-market. Maybe we missed something last time round; maybe the context has changed over the years.\nI would automate this abandoned invention threshing process.\n\nFirst I would train an AI on industrial processes, giving it access to Alibaba, some manufactured goods simulation software, and arXiv for novel material processes.\nThen I would turn it loose on the Technovelgy database of inventions in science fiction. For example, looking at the inventions by Bruce Sterling, how about an air-conditioned coat, or a self-actualising stone soup Bambakias Hotel?\nFinally, if there’s anything technologically feasible, ask the AI to come up with a scatter of positioning statements, auto-purchase ads on Instagram to match, and see what gets clickthrough.\n\nThen scale what works.\nRELATED: I also have an essay on the automated discovery of new areas of thought, which starts with the concept of horsehistory.\nPersonally:\nWhat ideas did I once upon a time flip the bit on as unachievable but actually I should now revisit? That’s the real lesson here.\nFor example: back in 2021 I had an idea for a galactic compass, that is, an iPhone app with a floating arrow that always points directly to black hole at the middle of the Milky Way.\nI couldn’t build it then. But recently I realised that ChatGPT could walk me through writing an iOS app. So now it’s an actual thing! On my homescreen! It works! (Mostly.)\n(Hey lmk if you’d like to get on the TestFlight as a beta user, I just need your Apple ID. Also let me know if you understand a bit about SceneKit and combining rotations with quaternions, because I’m in a muddle with the math and I’m getting some drift on the azimuth. The astro equations are fine, but I’ve got a 10 degree error in combining it with the device rotation. I need help fixing that bug because GPT, not being embodied, is even worse than I am at thinking in 3D.)\nBut not just tech, right? All kinds of personal ideas.\nWhat do I deep-down believe is out of reach for me that I could now achieve if I just tried? One’s mind bends around assumed-impossibilities; I can’t imagine them to enumerate them. I wonder what the threshing algorithm would be like in order to dig them up.\n",
    link: "/home/2023/08/04/spindizzy",
  },
  {
    title: "Filtered for turns of phrase and structures of feeling",
    date: "15.41, Friday 11 Aug 2023",
    content:
      "1.\nDisplay fascination.\nOn the development of screen-based interfaces by the US air force.\n\nDeveloping the display presented many problems. Some of them were unexpected. Already in 1978, the Wright-Patterson team reported discovering what it called “display fascination” to a DARPA conference on biocybernetics. Extensive testing and a body of anecdotal evi dence showed that “crew members often become enthralled or ‘drawn into’ their display,”” so that it becomes difficult for them to interrupt or change the focus of their attention. The lure of the display could potentially present problems during operations. The air force was worried that it took test pilots consistently longer to redirect their attention from the display to the real world than from the real world back to the display. It was as if the operators would default into the machine.\n– Thomas Rid, Rise of the Machines (p203)\n\nDisplay fascination!\nI wonder if this could be quantified? Like, this phone screen is 2532x1170 pixels and 460 dpi and 2000 nits and has 1.7 intrinsic display fascination.\n(I say intrinsic because like if an app is flashing with the frequency mix of a flickering fire then it’s going to grab your attention whatever. But the quality of the screen itself is going to have some display fascination, because it’s the Californian sun out of place and compelling in suburban south London, or because it’s the bulb pointed straight at your face in the interrogator’s chair.)\nWould you pay more for a smartphone without intrinsic display fascination? Or less? Is that the appeal/challenge of e-ink?\n2.\nOn the feeling of August and the 1990s.\nIn theory this is a hymn to August and Everything After, 1993 debut album by Counting Crows…\n\nIt’s not just that it’s all bangers and no skips, although it is that. It’s a vibe, but a perfect album is always a vibe. Perfect is a particular flavor, like sad or divorced or extremely online.\n– Helena Fitzgerald, Griefbacon, august and everything after (2022)\n\n…but mainly it’s about the 90s.\n\nSummer seems like it will go on forever, and then it doesn’t. August is the meds wearing off, the bottom of the afternoon, the text and the email you let go unanswered. It feels like waiting for something to happen, and it feels like everything that was going to happen already has.\n\nAnd,\n\nThere was a sort of Sunday night feeling to the ’90s, a sense of killing time in the waiting room.\n\nIt’s true. And the 2020s is different isn’t it. We’ve been through the vibe shift.\nKim Stanley Robinson put it another way:\n\nevery historical period has its own “structure of feeling.” How everything seemed in the nineteen-sixties, the way the Victorians understood one another …\n… The virus is rewriting our imaginations. What felt impossible has become thinkable. We’re getting a different sense of our place in history. We know we’re entering a new world, a new era.\n\nAnyway. I’ve previously written about KSR’s amazing essay so I won’t go into it more.\nBut I wonder how, looking back, assuming we are allowed that privilege, we will understand the structure of feeling of the 20s? I imagine that we’ll see we had/have a deep assumption of The End unevenly alloyed with an desperate hopefulness that Something Will Turn Up. Kinda, permeating all: you gotta be in it to win it.\n3.\nTrembling hand.\n\nThere’s a concept in game theory known as the trembling hand: There are branches of the game tree that, under an optimal strategy, one should theoretically never get to; but with some probability, your all-too-human opponent’s hand trembles, they take a wrong action, and you’re suddenly in a totally unmapped part of the game. \n– Singularity Hub, The Deck Is Not Rigged: Poker and the Limits of AI (2020)\n\nYou never know, right, you never know. It’s not going to be LK-99 but perhaps it’ll be something else. Fate has a trembling hand. We hope.\n4.\nThere’s is a lot to say about The Strange Brands in Your Instagram Feed (The Atlantic, 2018) by Alexis Madrigal,\n\nThe whole idea of retail gets inverted in his videos. What he actually sells in his stores is secondary to how he does it. … What Ganon does is pick suppliers he’ll never know to ship products he’ll never touch. All his effort goes into creating ads to capture prospective customers, and then optimizing a digital environment that encourages them to buy whatever piece of crap he’s put in front of them.\n\nbut it holds a place in my notes because of this this unsurpassed turn of phrase:\nIt’s as if he squirts hot dogs on his ketchup and mustard.\n",
    link: "/home/2023/08/11/filtered",
  },
  {
    title:
      "I want electromagnetic gloves to match the force beams from my eyes",
    date: "18.36, Thursday 17 Aug 2023",
    content:
      "I was reaching over my desk to grab my AirPods and I really feel like they should have drawn towards me, just a tiny bit. Dumb inertial matter, it’s so RUDE. Let’s fix that.\nWith magnets maybe?\nOk so imagine you wear a glove with crazy powerful electromagnets in the fingers. They’re powered down.\nThen in your AirPods case, your pen, as a tag stuck on your notebook, etc, you have similar electromagnets (also powered down).\nWhen you make a “grab” gesture, your glove figures out the direction and magically transmits an intent towards the object you’re reaching for. Simultaneously both sets of electromagnets auto-activate, you feel a pull towards the pen, and the pen leaps into your hand.\nDecomposing this, the gesture recognition problem is solvable. Proximity-based wi-fi comms is doable (my Apple Watch unlocks my laptop when I get close). The electromagnets wouldn’t need to be too strong to make this feel incredibly natural - like the world is helping out - but there’s an unknown there about what magnets can actually do. \nThere’s a power problem too I’m sure, but let’s solve that with remote wireless charging that uses directional beamed microwaves to transmit energy. You’d mount a energy transmitter hub on the ceiling of every room, and your laptop would no longer need a battery. Easy peasy.\nIn the future: no gloves even! Instead, magnets implanted in fingertips.\nOR EVEN: a genetically engineered fungus that makes its home in my nail roots, and slowly fixes iron from my blood. With carefully designed proteins, folded from engineered DNA, that are naturally polarised, the iron atoms could be aligned and assembled into the keratin matrix, and my nails would grow slowly from the base – thick, gun-metal black, sheet-metal strong, electromagnetic.\nI would wear slim rings on my fingers to power and activate them.\nI’m spoilt, I think, by the hover effect on hyperlinks, and menu buttons on my TV that get bigger when I’ve got them selected, and so on. The digital world is alive and responsive and moves to meet my intentions.\nIt would feel entirely natural if the world were to be responsive like this.\nAn analogy!\nWe feel like beams come from our eyes and exert pressure on whatever we look at.\nGet this!\n\npeople automatically and unconsciously treat other people’s eyes as if beams of force-carrying energy emanate from them, gently pushing on objects in the world.\n\nThe experiment as described in the abstract of the paper, Implicit model of other people’s visual attention as an invisible, force-carrying beam projecting from the eyes (2019):\n\nHere we show that when people judge the mechanical forces acting on an object, their judgments are biased by another person gazing at the object. The bias is consistent with an implicit perception that gaze adds a gentle force, pushing on the object. The bias was present even though the participants were not explicitly aware of it and claimed that they did not believe in an extramission view of vision (a common folk view of vision in which the eyes emit an invisible energy).\n\nThe cross-check:\n\nA similar result was not obtained on control trials when participants saw a blindfolded face turned toward the object, or a face with open eyes turned away from the object.\n\nAlso: This implicit model of active gaze may be a hidden, yet fundamental, part of the rich process of social cognition … It may also help explain the extraordinary cultural persistence of the extramission myth of vision.\nRef.\nGuterstam, A., Kean, H. H., Webb, T. W., Kean, F. S., & Graziano, M. S. A. (2019). Implicit model of other people’s visual attention as an invisible, force-carrying beam projecting from the eyes. Proceedings of the National Academy of Sciences, 116(1), 328-333. https://doi.org/10.1073/pnas.1816581115\nOk, bear with me here, but Apple Vision Pro + the extramission folk mental model of vision:\nWhat is the weight of an app?\nIn the Vision Pro augmented reality app homescreen, icons move towards you slightly when you gaze at them.\nIt’s an extraordinary active-passive sense. I haven’t used the headset but I imagine the experience feels entirely natural – it will slot into the folk physics of the world that we all carry around in our heads.\nSo given our eyes (we imagine) project a mechanical force, and the fact that (in Vision Pro) app icons have real-world dimensions, would it be possible to determine the weight given how much they move? (A negative mass maybe, given they move towards us.)\nDoes an app have the density of water? Or copper? Or honey (like the Sun)? Or meat?\nI want to know what Apple’s designers have discovered seems “natural.” I feel there is vital semiotic content in this fact.\nYeah so a glove that makes things move towards me when I reach for them. Please. Thanks. Anyway.\n",
    link: "/home/2023/08/17/gloves",
  },
  {
    title:
      "Dynamic shops, 17 years in the making, now at Fleet services M3 northbound",
    date: "17.38, Friday 25 Aug 2023",
    content:
      "I would like to see more transforming shops.\nI was driving back along the M3 and stopped at Fleet Services where there is a noodle bar called CHOPSTIX. Which, for reference, has a green logo on a bright orange background.\n(Brit micro celeb culture deep cut: the motorway footbridge at Fleet Services is dedicated as the Scott Mills Bridge.)\nHowever!\nI got there and instead there was a food outlet named THE GOOD BREAKFAST.\nWell that’s weird, I thought, to dedicate a scarce storefront to a brand that stops being relevant in the afternoon. But us Brits we love our fry-ups so ok I get it.\nThen I noticed:\n\nThe entire flat panel sign above the outlet was a single full-color LED display\nThe menus behind the counter were all TVs.\n\nHere’s a pic on my Instagram - what the second image shows is that, at midday every day, THE GOOD BREAKFAST turns into CHOPSTIX. The signage is reprogrammed, the TVs update the menu, the kitchen turns over the food counter.\nSidetrack for a second: let me introduce you to the best design fiction ever made.\nIn 2006, Zurich Insurance ran a series of TV ads as part of their overall brand campaign, Because Change Happenz.\nHere’s one of the ads on YouTube.\nI highlighted the transforming shop/cafe last time I talked about it.\n\nIt’s a collection of short scenarios made mundane by being shown incidentally in an entirely believable near future:\n\na commuter on prosthetic cyborg legs\nauto-routing cars at a busy junction with no traffic lights\na transforming shop/cafe\n\n(Just as wild, in the minds of the advertisers, is the idea of old people snowboarding. Only 17 years ago!)\n[There’s] a second ad with vignettes including auto-inflating fall protection jackets for construction workers, and people in suits caring about mental well-being.\n– Interconnected, Protocol Fiction, Desire, and Belief (2023)\n\nThink for a moment about e.g. robot cars, which are in these ads. (In 2006!!!)\nHow on earth do you get insurance underwriters to think about how insurance works in scenarios like this? When you have to measure and assess risk second by second; when you can’t bump complex policies to a human underwriter because the policy is being bought via a machine API and the car needs the result right now as it decides route on a slower road or a quick, riskier freeway? How do you get the IT managers and data scientists to think about what systems you need to support this, and management to consider whether to enter into partnership with car companies and startups wanting to operate like this?\nBecause you need all those people, and all that business back-end, to make worlds like this possible – and the way you enroll and align them is with design fiction like Zurich’s 2006 ad campaign.\nMy favourite moment in the Zurich ad (linked above) is at 40 seconds: we see a daytime cafe, and then all the walls rotate, and mannequins drop from the ceiling, and it’s a fashion boutique.\nThen the outdoor signage flips over again, and it’s an evening restaurant.\nLike, how do you do the accounts for a place like that?\nWhat does the P&L look like?\nYou wouldn’t be able to manage it on a single profit and loss. You wouldn’t be able to see what was working. So, three P&Ls. But then how do you do the absorption costing for the shared rent?\n(Given it’s an insurance ad, who would sell you insurance? It’s hard enough to get insurance for a micro consultancy that mixes client services and your own product development.)\nDynamic storefronts are an awesome idea btw – they would keep high streets vibrant round the clock.\nThe blocker is that today’s back-office processes make it fearsomely complex to tell whether making your store dynamic is a good idea. As a business owner, do you take the hit and run THE GOOD BREAKFAST - with the cap-ex hit of needing to buy more fridges, hold more stock (double your wastage), do more training, staff the place for longer, etc - or are you better off running at lower margin but lower investment as CHOPSTIX round the clock?\nYour software will barely help. It’s too hard.\nAnd that why Fleet Services, M3 northbound, in 2023, is the first time I’ve seen a store concept I originally saw in a TV spot in 2006.\nIt feels wrong that the barrier to “people trying new things” is the method of expressing it in the financials (which are, at best, an intermediary to being able to answer questions like “am I doing better this month than last month).\nIt should be trivial for anyone to spin up a business that doesn’t “crash” in the same way that, if you’re writing code nowadays, it’s pretty hard to make it crash too. (The previous time I had this complaint: Software-defined businesses (2020).)\nAnyway.\nOh but a last thought, some homework for you. If, as it turns out, those 2006 ads were projecting forwards 17 years to today, then what would today’s Because change happenz ad vignettes be, looking ahead to 2040?\n",
    link: "/home/2023/08/25/zurich",
  },
  {
    title: "I built my first AI NPC teammates and here’s what I learnt",
    date: "17.51, Friday 1 Sep 2023",
    content:
      "How will we collaborate with AI? Let me try for a quick typology because I want to zoom in on a particular model…\n\nProgrammatic – we use AI behind the scenes to automate work at an intern level of complexity (this is how I built Braggoscope)\nInteractive – the AI becomes part of the user interface… somehow.\n\nSome examples of interactive AI:\n\nDirect chat – like ChatGPT, we’re all pretty familiar with that. As an extension, the chat agent might be able to use some tools, for example browsing and summarising the web. It’s flexible! But there are disadvantages: it’s very unclear, at any given moment, what the AI is able to do for you.\nSupercharged software features – think about Adobe filters that magically extend a background, or GitHub Copilot magically auto-suggesting the next 20 lines of your code.\nCommand prompting – you choose a menu command like “generate” and add a prompt to refine the request: “a function that fetches… [etc]”. Two sophisticated exemplars: Replit Ghostwriter and Notion AI\nClippy – a personal AI assistant that lives at your elbow, can use anything you can see, and has the keys to your docs and knowledge. It’s where Microsoft’s Windows Assistant is headed. Maybe it looks like a chat down the side of your screen; there’s one of it.\nTeammate – in a multi-user setting, like Google Docs, or Figma, or (in a non-realtime context) perhaps one day competing for Replit Bounties, a role usually taken on by a human teammate is taken by an AI.\n\nI’m sure there are more! That’s to give a sense of the breadth.\nAnyway, recently I’ve been focusing in on AI-as-teammate because, for me, that’s where the action is.\nWhy AI-as-teammate?\nThe pragmatic answer: if we’re asking how to collaborate with AI in software, then first let’s look at the history of collaborative software generally, which is long and rich, and treat AI as a special case of that. Why re-invent the wheel?\nI’ve written before about how this could look:\n\nA writer will work in a Google Doc alongside an AI editor making suggestions, and an AI fact checker and researcher doing the running, and an AI sub doing the wordsmithing.\n– Interconnected, Let me recruit AI teammates into Figma  (2022)\n\nWhen you get into the details, it turns out that the questions you ask about how to build the interface are the questions you would ask about any multiplayer/collaborative interface:\n\nhow do you show that another user/AI is busy on a particular sentence, or block, or text box? What’s the visual indication that part of the app is “locked” – or how do you merge conflicting changes?\nhow do users/AIs recognise one another such that you know that, say, your editor is around to help? With regular UI we would call this affordances: how a tool advertises what you can do with it. ChatGPT is terrible at affordances; skeuomorphic iPhones circa 2009 were great. The “affordance” of colleagues is that (a) we know each other, and (b) the facepile in the corner of the screen gives us presence.\nhow do you summon help? What is the sideband of the current working document where you plan what you’re going to do? e.g. in Google Docs, you @-mention someone in a comment.\nhow do you receive help which is offered? Again in Google Docs, human users can make use of track changes – but let’s say you have an AI fact-checker or style-helper, do you really want them jumping in all the time? Even when you’re in drafting mode? So how does that interaction work?\n\nIn a team context, human/AI collaboration is a degenerate case of multiplayer collaboration generally.\nWhich is why I get so into investigating multiplayer interactions, and I’ve written a lot about it: I feel like it’s a pre-requisite for really good AI interfaces.\nBUT… realtime, multiplayer apps aren’t that common. I mean, increasingly they are, but not until recently.\nOne of the reasons for that is that (historically) building realtime, multiplayer apps has been a hard engineering problem. It still it, mostly. So there’s been less experimentation and exploration than there might have been.\nSo that sets the scene.\ntl;dr let’s investigate AI-as-teammate in the context of realtime, multiplayer apps, and see what we learn.\nWhich brings me to PartyKit.\nI’m halfway through my inventor in residence project with PartyKit, which I talked about here (at the same time as announcing my micro product invention studio, Acts Not Facts).\nWhat I’ve been doing:\n\nLearning and sketching. PartyKit solves realtime multiplayer. So I’ve been learning my way around it by making small multiplayer software sketches.\nBuilding my first multiplayer NPC teammates (not entirely AI yet, as you’ll see) – and I have some lessons.\n\n(NPC = non-player character, which is a term from the video-game world. Think: fake user.)\nLet’s hit those in turn.\nMonth 1: Learning and sketching\nI gave myself a month just to build toys and learn my waty around.\nPartyKit is pretty low-level internet infrastructure.\nLike, if you want to have live, multiplayer cursors whizzing around on your webpage, what you do is you write some code that sends the position of your cursor to the backend party-server. Then you write a party-server that basically has one rule, which states: when you get an updated cursor position, broadcast it to all the other web browsers who are connected to this page.\nThen the party-server just… runs… forever. It just spins along in the cloud.\nI am simply not used to realtime, multiplayer wiring being simple and reliable. I wasn’t expecting it to be so simple I could write it myself. The abstraction level is perfect.\nAnd then you make it as complicated as your imagination allows.\nSo it feels like being given a new primitive for the internet. Would new things could you build when relational databases came along? Or location-aware devices? It’s on that order of novel capability.\nHere’s my month 1 PartyKit sketchbook.\nThere are 5 examples there, with short write-ups, and all the code is open on GitHub so you can see for yourself how to write these party-servers.\n(There’s a pretty multiplayer Voronoi diagram cursor toy, which can now also be found on the PartyKit homepage, an evolving tiny garden, and a collection of drop-in web components to bring ambient presence to any website.)\nAnd I’m not going dig into those examples right here, except to say that it was imagination expanding, right?, to give myself a month to get familiar with the material and internalise the possibilities that I didn’t realise were there on day 1.\nMonth 2: NPCs and, uh, helpful dolphins\nYou don’t get as far when you make working code vs drawing and writing. That’s true.\nAI-as-teammate, in my imagination, is powerful and elegant and fully-integrated and bejewelled with clever design detailing.\nBut the devil is in the details. “Making” is less ambitious and less imaginative, compared with sitting down with your pens, but what I find is that I confront the reality of the material in unexpected ways - no matter how crude my prototype - and that slingshots me off into brand new directions.\nLet me give you an example.\nHere’s my initial sketch of a dolphin cursor on a webpage. (I posted it on Instagram.)\nWhat you’ll see there is simple pen and ink: there’s a dolphin cursor that lives in a little circle, then the user asks it do something (by “chatting” with it, somehow?). Then the cursor emerges from its home, writes a poem on the webpage, and returns home again.\nAnd THEN I went round the houses trying to build just that. \nI’ve been building using tldraw which is a really good multiplayer whiteboard in a webpage. It’s low fidelity which stops you getting lost in the weeds. (I do all my design work in tldraw, Keynote, or code.) They offer an open source version you can integrate into your own apps.\nBut, when I’m running this whiteboard, should my NPC virtual user run its code inside my web browser? Or run its own web browser in the cloud? Or connect to the tldraw back-end server itself and attempt to manipulate the document state? Or…\nArchitecturally this is interesting. Because if we are going to have AIs living inside our apps in the future, apps will need to offer a realtime NPC API for AIs to join and collaborate – and that will look very unlike today’s app APIs. And how will we get the visual training data for AI models to connect together what the user is seeing and the machine API? Questions for the future.\nAnyway: I want to show you where I ended up.\nHere’s my dolphin NPC PartyKit sketchbook.\nI posted this just today.\nYou’ll see three GIFs:\n\nYou create a “pool” or a cursor park (a space on a Google Docs page designated for placing your mouse cursor when you’re not actively editing the document) or (as I call it) an embassy on the whiteboard. The NPCs need somewhere to hang out when they’re idle. Then you summon your NPCs from the comms walkie-talkie on the page.\nNPCs can accept commands! From your walkie-talkie, you can tell the poet NPC to venture out of its embassy to write a poem. So it does that, as you can see, leaving a haiku on the whiteboard, then returns home.\nNPCs can be proactive! The painter dolphin likes to colour in stars. When you draw a star, the painter cursor ventures out of the embassy and comes and hovers nearby… “oh I can help” it says. It’s ignorable (unlike a notification), so you can ignore it or you can accept its assistance. At which point it colours the star pink for you, then goes back to base till next time.\n\nCheck out the movies on that page. It’s all working code! I can interact with these dolphin-cursor-NPCs. Let me tell you, it is uncanny to see a machine-driven cursor. It doesn’t move right. \nLook yes it’s ridiculous, and these are woefully simple, toy interactions.\nBut, but, and, I learnt a ton.\nASIDE: first, a note about dolphins.\nIf we’re going to be living and working alongside AIs, then what’s our theory of mind for them?\nThey can speak our language and seemingly understand us too, better than my smartphone can. (My smartphone understands me jabbing with one finger and that’s about the limit of it.)\nAnd it is handy, when interacting with AIs, to ascribe it some kind of personhood. There’s a folk psychology skeuomorphism going on there which is useful: it means we can map person-like qualities of intent, knowledge, personality, expertise, and foibles onto these AIs, instead of having to find other ways to communicate that in other ways in the UI.\nBut AIs are distinctly not human. Like us, but not like us.\nNonhuman species are a useful metaphor, right? Dolphins are my go-to companion species - human-equivalent smarts but utterly alien in terms of the chasm between us.\nThere’s a whole history of human/dolphin interaction to draw on (explore my posts tagged ‘dolphin’) but I want to highlight some work from 1974 by the architects Ant Farm, when they designed the Dolphin Embassy.\nI have a couple links in this post:\n\nOne blueprint shows the deck of a raft on which humans have their media pod, galley, command station and so on, and in the centre is a circular pool, with steps going down to it, and the pool is open to the depths, meaning that dolphins can swim up and appear inside it. So while the human raft sits on and is contained by the ocean, the pool is contained by the raft, and there’s an elegant symmetry to that, a place for a meeting of peers.\n\nThat’s why, in my prototype, the dolphin pool is a triangle with a circle in it, it’s a schematic of that work by Ant Farm. Now you know.\nWhat I learnt from my dolphin NPCs\nCursors are a great way to communicate attention.\nWe’ve got this problem with AI-as-chat and AI-as-superpowered-menu-command that there’s no way to discover what the AI might do for me.\nSit someone down with ChatGPT, even, and they’ll barely scratch the surface of what’s possible.\nSo, instead, perhaps the user can go about their regular work, and the AI can pipe up when it spots an opportunity to be helpful?\nNow that’s tricky because how can the AI be certain that it would be useful? Or maybe the user would change what they were doing if they knew, ahead of time, that the AI would offer help.\nCursor distance = confidence. When an NPC wants to be proactive, it can hover nearby. It can be pushy when it knows it can help. (It can remember not to pipe up again if it is banished.) There’s a lot of resolution to explore here.\nVisual interfaces need a ‘suggestion language’ which is as good as ghosted text is for autocomplete.\nAs handy as cursor distance is, it falls down when it gets to the specifics. The ghosted text interface you get with suggested autocomplete in GitHub Copilot is sublime. We’re going to need something just as deft when it comes to an AI suggesting that it could (for example) automate hunting for an Airbnb for you.\nAn NPC side-channel is necessary - you can’t do it all with cursors.\nAs independent and autonomous as my multiplayer dolphin cursors are, I initially expected I would be able to craft the entire interaction via cursor chat. Not the case.\nInstead I feel like I’m coming back to chat. Now, I’ve been pretty negative on the whole chat-sidebar thing as a UI element. It seemed dumb to me to have a great big chat interface down the side of your app, just to talk to your AI agent. Interact more directly, right?\nBut this dolphin comms/walkie-talkie block (that you can see in my NPC GIFs) is taking me back to chat. Or rather, a form of chat which is where I chat with my human collaborators, but also where my dolphin NPCs can offer more fine-grained interactions.\nI’m thinking I need an OS-wide chat channel that NPCs jump into as I move from app to app.\nANYWAY: this is getting a little abstract.\nOk, two more quick points:\n\nMultiple NPCs make a ton of sense. I was unsure whether this would work, but of course you need a different collection of NPCs at different times, just as you work with different colleagues over the duration of a project. It is so much simpler to see “poet” and “painter” dolphins than a single NPC and wonder about the boundaries of its capabilities.\nThere is so much character in cursor motion. I initially had the machine-controlled cursors travelling linearly across the canvas, and it felt so creepy. Now the cursors rubber-band their way to their destination, the velocity being proportion to the distance remaining, just as we do, with our cursors. And I’m looking forward to seeing what can be communicated as they tentatively move closer, or back off, or tremble like a racehorse in the starting block, or idly meander. So rich.\n\nOne thing that strikes me as funny as that cursors are so incredibly useful to share a locus of attention, and I’m adopting them just as they’re about to vanish entirely in the computing landscape – there are no cursors on smartphones, or in Vision Pro augmented reality.\nSo maybe the future of cursors is this kind of vestigal icon showing attention and presence, abandoned by humans, but a regular device for our nonhuman AI brethren.\nI’m going to continue to dig into NPCs for a couple weeks. I’ve got some good foundations now to prototype with infinite canvases (with tldraw) and autonomous NPCs (using PartyKit), and there’s a lot to figure out in terms of interaction patterns and also in terms of future software architecture.\nI’d love to see what you’re building, if you’re digging in this space too.\n",
    link: "/home/2023/09/01/npcs",
  },
  {
    title:
      "Groundhog Day is about making films, and several other reductive interpretations",
    date: "16.07, Friday 8 Sep 2023",
    content:
      "6 years ago I wrote an essay putting forward a general theory of creative work: creative works are commentaries on the act of creation.\nLike, for instance, Blade Runner. Replicants are characters in a movie:\n\nCharacters look like people, except they exist for only the duration of a movie - only while they are necessary. They come with backstory and memories fully established but never experienced, partly fabricated for the job and partly drawn from real people known by the screenwriter. At the end, they vanish, like tears in rain.\nLike Rosencrantz and Guildenstern. Like replicants.\nRoy knows he is a replicant. He’s the one who comes closest to understanding his true nature: that his memories were given to him, that when the short span of the film passes he’ll be gone.\n– Interconnected, What Blade Runner is about, and the Narcissist Creator Razor (2018)\n\nI called it the Narcissist Creator Razor and the mechanism works like this:\nAll creators work (by necessity) from their own experience. The most direct experience they have is their current act of creating.\nTherefore the material used to construct the inner reality of the creative work is derived from the outer reality act of creating that work.\nTO RECAP!\nIn that essay I also dealt with:\n\nStar Wars – the Force is the demands of narrative.\n2001: A Space Odyssey – the Monolith is the cinema screen, this threshold between the inner and outer realities, and we watch the characters in their effort to interpret it from their side.\nArrival – there are three times: Viewer Time; Character Time; Author Time. The aliens exist in Author Time.\nPermutation City/Diaspora/Schild’s Ladder, Greg Egan – the layers of the universe = time = the pages of a book.\nRosencrantz and Guildenstern Are Dead – Ros and Guild are inner reality characters able to sense their nature of outer reality actors.\nHamlet – the uncaused cause of the whole thing is the Ghost… who was originally played by Shakespeare. Enough said.\n\nSINCE THEN:\nFar from revising or recanting my reductionist Razor, I’ve been collecting more examples.\nGroundhog Day\nIt’s about the outer reality experience of writing or filming a scene. You have to go through mistakes, frustration, play, acting, and unknown iterations to make genuine progress and complete it properly. Only then can you move on.\nFrom the inside, every time is the first time. It’s impossible to know what “done” really means, until you arrive at us. Thus the outer reality experience is the material to perform the inner reality.\nGood Omens, Neil Gaiman and Terry Pratchett\nCrowley (the demon) and Aziraphale (the angel) are Gaiman and Pratchett, and their activity of controlling the world together - not always successfully - is the experience of authors.\n1984, George Orwell\nWinston Smith is paranoid that O’Brien, member of the Inner Party, can read his thoughts.\nThough he believes what’s in his head is free: Always the eyes watching you and the voice enveloping you. Asleep or awake, working or eating, indoors or out of doors, in the bath or in bed – no escape. Nothing was your own except the few cubic centimetres inside your skull.\nSmith is wrong, of course, because we can read his thoughts. The novel is told through his eyes, so we - the reader - are effectively the true O’Brien. We are the Inner Party.\nThe Smith/Party/Big Brother triad in 1984 is the character/reader/author triad.  The world is a book. That’s why the past can be so fluid: there is no time in books; no reality except that communicated in the current line of text.\nFoundation, Isaac Asimov\nIsaac Asimov was John Campbell’s not-entirely-willing protege. This ambivalence about Campbell - a powerful man who created Asimov’s early success - is re-told in the inner-reality Foundation’s struggle to get out from the under the thumb of Hari Seldon, who put into place the ancient Plan to lead them to greatness.\n(Standard caveat: Asimov and Campbell were troubling individuals. More here.)\nOR: we could read Foundation and Hari Seldon in particular as Asimov’s own conversation with planners vs pantsers. You can outline as much as you want but narrative has its own demands.\nThe Star Wars sequel trilogy\nIn The Last Jedi, Kylo Ren says to Rey: your parents are nobodies. They don’t matter in this story.\nHe’s not talking about the First Order vs the Rebellion, but the outer reality story of Disney Star Wars vs Lucasfilm Star Wars. Kylo is not speaking to Rey, he’s speaking to us, the audience with bums in seats.\nRemember that the Force is narrative:\nKylo is the radical side of the Force: none of it matters, not the Jedi (the films that were first made), not the Sith (standing in here for the expanded canon), burn it all down. We’re here to tell a story.\nRey is the embodiment of the conservative Force. She represents the side that wants to hang onto the old Jedi vs Sith, that wants to hang onto the Skywalker lineage. She represents the fans that care who her parents are. We’re here for fan service.\nNo, says Kylo Ren, all that matters is the reboot and the new fans. We can do this together or we can fight about it.\nAnd this is what I imagine it was like writing a script for one of the new Star Wars movies. I must have been a nightmare. The director, the screenwriters, the marketing team… they will be wanting to create their new story, and speak to new fans. But they’re pulled back by the gravity of Star Wars history. Of needing to keep to canon, but also by the whining fans who grew up with the franchise. That must be an ordeal.\nSo inevitably that plays out in the sequel trilogy. The battle of two groups, both psychically present in the creators’ collective unconscious, possibly yelled in meetings, now the subject matter of the movies.\nWatchman, Alan Moore\nIt’s a very unusual experience for Alan Moore, or any author, to live with worlds and characters in their head for so long. So it should be expected that we see that in the story.\nDr Manhattan. He can see the comic book. (Ozymandias thinks he can.)\nIt’s a fantastically efficient lens because, when you’re spending time wondering what any creative work is about, the Razor tells you that it’s simply the person who made it talking about what it was like to make it.\nCut to the chase!\nOn the other hand it must be terrifically annoying and short-circuiting for everyone around me, because at home I’m banned from talking about inner and outer realities entirely.\n",
    link: "/home/2023/09/08/razor",
  },
  {
    title: "Filtered for formation",
    date: "09.14, Friday 15 Sep 2023",
    content:
      "1.\nHow fast does time move in fiction?\nFascinating result:\n\nI started to wonder how much time passes, on average, across a page of a novel. Literary-critical tradition suggested that there had been a pretty stable balance between “scene” (minute-by-minute description) and “summary” (which may cover weeks or years) until modernists started to leave out the summary and make every page breathlessly immediate. But when I sat down with two graduate students (Sabrina Lee and Jessica Mercado) to manually characterize a thousand passages from fiction, we found instead a long trend. The average length of time represented in 250 words of fiction had been getting steadily shorter since the early eighteenth century.\n– Ted Underwood, Using GPT-4 to measure the passage of time in fiction (2023)\n\nMeasuring the average length of time described in 250 words of narration was:\n\nsome days, in books written in the 1720s e.g. Gulliver’s Travels\njust under an hour, in the 1990s\n\nThe original research was done by hand (well, by grad students, same same). That article is about whether AI can be effective as a tool to make the same estimations…\n…which makes me wonder, not having any grad students of my own, what other hidden numbers can be extracted from prose by GPT-4?\n2.\nI read the other day about the origin of flint, which is wild.\nThe geology of where I grew up was chalk. Meaning that, as previously discussed, my mental picture of a “stream” is actually a chalk stream, and it turns out this is globally peculiar.\nChalk was formed deep under the ancient oceans of the Earth, from vast quantities of compressed microscopic plankton.\nThere was also a lot of flint. Using flint for tools in the palaeolithic made sense to me because, well, flint litters the landscape. Not true! It is rare! But, for me, as a kid, you wonder at the colours of flint (and try to smack things with it), draw with chalk, and make things out of the clay you dig up.\nAnyway, flint! It never really occurred to me to ask why chalk and flint are co-present.\nApparently the formation of flint was a mystery until the 1980s.\nIt’s also oceans, it turns out.\nNow get this:\n\nFlint was formed in soft, limy mud on the floor of the Chalk Sea some 80 million years ago. It is made of quartz, or silica, which came from the skeletons of tiny sponges that lived in this tropical sea. Their skeletons were dissolved in the seawater and therefore the mud on the sea floor contained silica in small amounts. … Some flint beds can be traced for hundreds of kilometres.\nThe bizarre shapes of flint nodules, with spiky protrusions and holes, are thought to be due to flint replacing the chalk in the burrows of marine animals such as arthropods that were living beneath the Chalk Sea floor, and it was this connection with burrows that proved to be the key to how flint was formed. The process of flint formation was originally the subject of much argument and was only finally worked out in the 1980s when it was established that flint formed preferentially in burrows due to the presence of decaying organic matter, and also at the ‘redox boundary’, below which anaerobic, sulphate-reducing bacteria predominate. The shape of a flint nodule is therefore often the shape of an animal’s burrow, with the surface often showing the burrowed fabric of the chalk it has replaced.\n– GeoEssex, Fact sheet No. 3: Flint\n\nWhat?\nWHAT??\nNot only does flint represent 80 million year old sea sponges, but the shape of the rock is a cast of an arthropod burrow?\nAnd then it was the key material for tool-making by humans for about 3 million years, driving trade routes, and allowing hunting, fabrication, and all the rest?\nDeep time vertigo.\n3.\nAmelia Wattenberger, AI research engineer, has recently prototype a writing app thathighlights sentences according to how abstract or concrete they are.\nWattenberger quotes Robin Sloan, friend of this parish, about the ladder of abstraction:\n\nGood writers move up and down a ladder of language. At the bottom are bloody knives and rosary beads, wedding rings and baseball cards. At the top are words that reach for a higher meaning, words like freedom and literacy. Beware of the middle, the rungs of the ladder where bureaucracy and technocracy lurk.\n\nSo… she can reveal that? Astounding.\nRead: Getting creative with embeddings (2023) – and check out the screenshots.\nThis works because each sentence can be placed, using large language models, in “embedding space”, a 1,000-dimensional space where two sentences that mean roughly the same thing will be close together, even if they use different words. But also all the abstract sentences will be closer together versus the concrete ones, and so on.\nLOOK:\nI realised the other day that this is how I read long articles online:\n\nread the headline\nread the penultimate para\nscroll wildly up and down reading odd words\nif it’s good, read backwards for a couple sections\nif it’s still good, read forwards from ~1/4 of the way in\nignore the beginning/end\n\nI’m not saying this is right. I’m just saying that it turns out that this is what I do. It’s probably a symptom of some attentional dysfunction.\nSecretly I think it’s because a lot of long-form is filler (including my own). I need to squeeze the fruit before taking it home.\nBut I wonder whether there are hidden patterns in the essays that I do like, that Wattenberger’s work could reveal:\n\nspeed of ideas: per-sentence velocity through embedding space\nvolatility in the abstract/concrete mix – could we Fourier transform Wattenberger’s visualisation and see what frequency mix I like?\na new scale that shows semantic opposition/agreement vs my own corpus of notes.\n\nCan’t wait to try some of these experiments myself. We are so early with this new technology. We’re imagination bottlenecked. There’s low-hanging fruit for the next decade.\n4.\nFrom Greg Egan’s 1997 novel Diaspora, this is the first chapter, about the birth of a machine intelligence - not quite an AI, but a human hosted on a computational substrate - from its own point of view.\nLike a baby learning how to use its eyes and hands, and working towards establishing self-identity.\nDon’t skip bits like I would, it’s well worth reading properly.\nOrphanogenesis by Greg Egan.\n",
    link: "/home/2023/09/15/filtered",
  },
  {
    title: "Old wards and new against fake humans",
    date: "11.47, Friday 22 Sep 2023",
    content:
      "Somebody’s taken Childish Gambino’s music video This is America (original, YouTube) and used some AI face-swapper software called FaceFusion to sub in Nicolas Cage.\nHere’s the result on X/Twitter. You don’t need to watch the whole thing – just the moment at 2m40s where Cage/Gambino turns his face sideways and the face swap glitches out, back, out again and sits on Gambino for a beat, then back to Cage looks unnatural, settings in, then lights up and walks off.\nThe timing is perfect. I’ve clipped the video here.\nIt seems to me like this is a visual trope we’re going to see more and more? It’s the paranoia and glitching in A Scanner Darkly (2006), the visual glitch when your trust in subjective reality is shaken loose. I’m looking forward to this being a commonplace shorthand for doubt; a quick glitch in a romcom when somebody is acting out of character, say.\nANYWAY:\nIt reminds me that AI face swaps are not (in 2023) much good at ears.\nThere is a rise in imposter scams (Washington Post):\n\nThe man calling Ruth Card sounded just like her grandson Brandon. So when he said he was in jail, with no wallet or cellphone, and needed cash for bail\n\n…for which you need about 30 seconds of audio and under a hundred bucks.\nAnd so, at least for video calls, as previously discussed when I posted about ears last year, the advice is this: To Uncover a Deepfake Video Call, Ask the Caller to Turn Sideways.\nAs a family, we have a secret pass phrase to check identity between ourselves in the event of an unexpected video call.\nIt’s a sticking plaster solution. Long term I suspect we all need 2FA for humans.\nIn the meantime, maybe the most effective ward against deepfakes is simply to turn sideways?\nWe should build the habit now. At the beginning of every call, exchange a quick proof-of-humanity by showing our ears.\nWarding against pretend people: some examples.\nONE!\nThe origin of tao po, apparently a common Filipino phrase:\n\nAccording to historian Ambeth Ocampo, pre-colonial Filipinos used the phrase to declare themselves as humans, thus: “Tao po ako, hindi aswang!” (“I am human and not aswang“)\n… evil spirits, aswang, and other dangers that lurked outside the home were incapable of saying “tao po” to trick you into letting them in your house. \n… Today, “tao po” has a more mundane purpose. Depending on the usage, it can be loosely translated to “anybody home?” or “a person is at the gate.”\n– Esquire, Puwera Usog, Tao Po, and Tabi Po: The Curious History of Three Filipino Phrases (2020)\n\nTWO!\nHaint blue is: a collection of pale shades of blue-green that are traditionally used to paint porch ceilings in the Southern United States.\n\nOriginally, haint blue was thought by the Gullah to ward haints, or ghosts, away from the home. The tactic was intended either to mimic the appearance of the sky, tricking the ghost into passing through, or to mimic the appearance of water, which ghosts traditionally could not cross. The Gullah would paint not only the porch, but also doors, window frames, and shutters. Blue glass bottles were also hung in trees to trap haints and boo hags.\n– Wikipedia, Haint blue\n\nFor HTML fans, that’s hex #D1EAEB.\nTHREE!\nPerhaps your baby has been stolen and an ancient fairy has taken its place – a changeling.\nYou can trick fey folk into breaking their silence by baffling them. Typically: cooking with eggshells.\n\nA fairy doppelganger has posed as a human baby and successfully pulled the wool over its human hosts’ eyes. However, someone (typically the mother) realizes what’s happened. To trick the changeling, she uses empty eggshells as milk pans, stewpots, or brewing cauldrons. The fake infant is so surprised that he suddenly begins to speak. Sometimes he is startled, sometimes amused. “I have never seen the like of that before” is the most common exclamation, as he unthinkingly reveals his great age. Then, in a flash, all is set right and the real baby is returned.\n\nWhat 21st century fake humans do I want to ward off? What should I carry with me?\nOk, taking turns to show our ears to watch for deepfake glitches. Like shaking hands from the old days, demonstrating that I’m not about to draw my sword.\nWhat about if I suspect I’m speaking, in text or voiceswapped, with an AI? The best trick would be to challenge it to say something obscene. The AI changeling wouldn’t be able to help itself, blurting in response: I’m sorry but as a large language model I cannot…\nIf we’re emailing, and the first words I say to you are utterly beyond the pale, just like excessively and graphically disturbing, don’t worry, I’m just helpfully establishing my humanity.\nTao po.\nI’m into wards that become unquestioned social habits.\nI’m also thinking more about wards that are physical artefacts, and less about AI…\nFor instance: my car was stolen recently, evaporated from the street.\nApparently 50% of car thefts in the UK are from hijacking keyless entry.\nSo now I own a ward against malicious ghost RF: a handsome box, in which I store my keys.\nAnd so does everyone else it turns out! If you type far– into search on amazon.co.uk, the top two suggestions are:\n\nfaraday pouch for car keys\nfaraday box for car keys\n\nThe third autocomplete:\n\nfart spray\n\nDon’t get that one. It is unlikely to help.\n",
    link: "/home/2023/09/22/wards",
  },
  {
    title: "The Young Lady’s Illustrated Primer was written by Homer",
    date: "18.40, Friday 29 Sep 2023",
    content:
      "I’ve been reading a cut of the Greek myths to my kid, who is almost 5. We’ve read it a few times over the last year. The same stories were my favourites growing up, so.\nWe had a conversation yesterday about the island of the lotus-eaters in the Odyssey. Imagine an ice cream which tastes so great that, as soon as you taste it once, you don’t do anything else except eat that ice cream, ever.\nMyths are school.\nLet me unpack.\nLook, I don’t have an education in the classics, but this is the timeline as I understand it, because it always confused me how the myths could be told in so many different ways.\nErrors abound, I’m sure!\nThe pre-history here is Mycenaean culture, which came before the Ancient Greeks. They had writing, Linear B. There were cities – not an empire but palace states. And then around 1050BC, around the time of the Trojan War: it collapsed. The Bronze Age Collapse (as previously discussed) is a mystery, but there it is.\nSo that’s the context.\nImagine this then. A new civilisation: the Greeks were emerging from a Dark Age so dark that they never really knew it had happened.\nSettlements are connected by roaming, illiterate, professional bards who compose, tell, and re-tell epic poems. Orality in all its variety. This new Greek culture walks in the ruins of cities they have no idea how to build, and finds writing they have no idea how to read.\nUntil 800 BC. The Greeks re-invent writing (they never read Linear B). The poems told out loud, which are already traditional by this point, are written down and formalised as the epics. Homer’s Odyssey is one, that’s what I’m reading with my kid now.\nThe epics tell all of history: the origin of the world, the titans, the gods, Prometheus, the kings and heroes, and finally the sack of Troy. So the myths end with the collapse of the Mycenaeans, maybe a folk memory; the heroic age is within touching distance of the Greeks.\nThe city states: by 600BC, Ancient Greece is a collection of rival cities, Athens, Thebes and the rest. The epics are well-known, and now traditional themselves. But old fashioned. Aristotle thinks they’re rubbish.\nNow we’re in an age of competitive theatre. From about 500BC for a couple of centuries, the cities hold highly competitive dramatic festivals. Playwrights compete with new plays of comedy and tragedy.\nSo the myths are re-told. Being well-known source material, the traditional myths are deconstructed and re-made as psychological dramas. Sure there was this hero or this king or whatever, but what drove them to behave like that; what consequence did it have to treat with the gods; what is their arc.\nThen: Alexander the Great unifies the city states and the Mediterranean and, in 323BC, dies. The centre of gravity is no longer the cities. Hellenistic culture is dispersed, over the entire region.\n(In this period: the rise of the Roman Republic and then the Punic Wars – the great clash of the civilisations of Rome and Carthage. The front line was Sicily, and on that island, in Syracuse, a Greek colony, around 200BC: Archimedes. Archimedes was the John von Neumann of his time, a war scientist. I think of him mainly for - eureka! - the displacement of water, but he invented a heat ray, and a giant claw to lift and smash ships.)\nThen civil war in the Roman Republic. Julius Caesar smashes it and his adopted heir becomes Augustus, the first emperor. 27 BC.\nThe nascent Roman Empire wrote its own history. In 8 AD the poet Ovid completed Metamorphoses, a new re-telling of the Greek myths that go beyond Troy and climax with Julius Caesar himself.\nSo we’ve got these three waves over a thousand years:\n\na bardic tradition culminating in Homer and the rest\na hotbed of competitive theatre that deconstructs the traditional myths into psychodramas\nthe propagandist Roman retelling of already ancient myths for the purpose of creating a sense of manifest destiny.\n\nAnd now it’s two thousand years past that even, and we’re still telling variations of all the waves of all of these stories.\nThe timeline above (misrememberings all mine) is cribbed from a 2008 episode of In Our Time on the BBC.\nMelvyn Bragg asks Professor of Classics Mary Beard, did they [the myths] have a function?\nAnd here’s Beard’s reply:\n\nYou have to assume as a starting point that the fact that these things go on being told and recounted and sung and written about must mean they’re doing a really important job.\nThis is not some kind of mad conservatism on the part of the Greeks who go on telling these stories long after they’re of any use to them.\nI think myth is a terribly economical form of thinking about the world.\n… the underlying function is to help us think about what human and existence is like and why it’s so jolly difficult and hard and why we do what we do.\n– Braggoscope, The Greek Myths (2008)\n\n(Well, the transcript isn’t on that page. There’s a link to listen to the episode and I recommend it very much.)\nI remember that idea grabbing my attention when I first heard it.\nBut I couldn’t grasp it.\nSee, in the abstract I could see how a myth could be - in Beard’s words - a framework for thinking about who we are.\nMy struggle was that I couldn’t see how that would be actualised. What is the actual chain of events? Who would say what to whom, and when, and with what sufficient frequency. What is the path by which an epic poem creates social norms? I couldn’t make it out.\nUntil I was reading to my kid.\nSee, I’ve also had school on my mind.\nSchool, for us here in 2023, is two things:\n\nskills – exam results, achievements, medals, learning, learning how to learn, the ostensible purpose of school. It’s what we measure, it’s what we talk about in the newspapers.\nsocialisation – values, instilling the “framework for thinking about who we are”.\n\nGood educators are all about the socialisation. But it isn’t measured. As far as the position of “school” in society is concerned, it is a side-effect.\nSo pretend we had no schools. How would that work?\nSkills you could get by apprenticeships and observation. That’s the easy bit.\nSocialisation? Where’s the absolutely necessary shared curriculum that creates a single culture?\nAha, the myths.\nYou would tell and re-tell the epic poems and discuss, well, the lotus-eaters because you’re going to encounter lotus-like things in life; and the various permutations of xenia; and loyalty, and love, and revenge; and (again as Beard says) how to think about sacrifice, and so on. All these situations played out for examination and discussion, a curriculum for socialisation, a school in a book!\n(Or the Bible. Or the I Ching.)\nSo now I understand how these texts, in their great detail, aren’t just helpful alignment, but in an historical context where the “job to be done” of schools was not performed by a bricks-and-mortar institution, these texts are necessary.\nThere’s always a lot of talk about building this fictional device but we already have the Young Lady’s Illustrated Primer and it was written by Homer.\n",
    link: "/home/2023/09/29/homer",
  },
  {
    title: "Intelligence too cheap to meter",
    date: "14.48, Friday 6 Oct 2023",
    content:
      "The ubicomp manoeuvre was to realise that Moore’s Law cuts both ways.\nMoore’s Law: pound for pound, computers double in power every 18 months. Or 100x over ten years. (And let’s forget about the death of Moore’s Law. We’ve been stuck in an AI overhang and I’m 100% sure there is a lab someone using AI to jiggle up silicon pathways literally as I write this.)\nIf computers get 100 times more powerful over a decade, we can EQUIVALENTLY say that computers get: 100 times smaller; or 100 times cheaper; or 100 times more abundant.\nSo that was the enabler behind Mark Weiner’s 1988 conception of ubiquitous computing.\n\nAt the turn of the century, a typical workshop or factory contained a single engine that drove dozens or hundreds of different machines through a system of shafts and pulleys. Cheap, small, efficient electric motors made it possible first to give each machine or tool its own source of motive force, then to put many motors into a single machine.\nA glance through the shop manual of a typical automobile, for example, reveals twenty-two motors and twenty-five more solenoids. They start the engine, clean the windshield, lock and unlock the doors, and so on. …\nMost of the computers that participate in embodied virtuality will be invisible in fact as well as in metaphor. Already computers in light switches, thermostats, stereos and ovens help to activate the world\n– Mark Weiser, Scientific American, The Computer for the 21st Century (1991)\n\nJust the enabler though. The original conception, in Weiser’s Ubiquitous Computing #1, was inspired by looking at people and attempting to bend computing towards actual practice:\n\nInspired by the social scientists, philosophers, and anthropologists at PARC, we have been trying to take a radical look at what computing and networking ought to be like. We believe that people live through their practices and tacit knowledge so that the most powerful things are those that are effectively invisible in use. This is a challenge that affects all of computer science.\n\nOk.\nBY ANALOGY:\nIf future AI models will be more and more intelligent (per watt, or per penny, or per cubit foot, whatever we choose measure) then we can equivalently say that, in the future, today’s AI models will become cheaper and more abundant.\nWhat happens when intelligence is too cheap to meter?\nToo cheap to meter: a commodity so inexpensive that it is cheaper and less bureaucratic to simply provide it for a flat fee or even free.\nMe on fractional horsepower and fractional AI in 2012 and 2017:\n\nElectrification began in cities around 1915 and with electrification so too came the potential market for washing machines, refrigerators, vacuum cleaners and a host of other commercial appliances. … By 1920, over 500,000 fractional horse-power motors were powering washers and other appliances in America.\n\nIn 2033, GPT-4 will be 100x faster, or 100x smaller, or 100x cheaper. What then?\nLIKE:\nGiven an internal camera and access to Google, your oven cooks everything perfectly (and asks you about your preferences if it’s ambiguous).\nOr telepathic light switches. Given some history and a bit of behavioural pattern matching, a Feynmann-level light switch could guess your intentions pretty well.\nViable home weaving of clothes? Buy infinite Uniqlo and a robot sewing machine. It’s interesting that ubiquitous AI means the end of ease of use: you can have a home fabrication unit or whatever that is as complex as you like, with whatever quantity of subprocesses, and there’s no skills gate that means you have to hire a trained professional or learn how to operate it. You will just talk to it.\nUniversal lie detectors (sub-visual readings of blood flow in the face, voice stress, etc).\nIn-home drones and robotics probably get solved pretty quick. So I should be able to say to a drone: “where’s that book I own that mentions X” or “where did I leave my keys” - but I’m not sure this is on the ubiquitous, fractional AI end of things.\nDunno, I need to think about this. Approach it systematically.\n10 years after that, 100x smaller again. Nano AI, molecular scale intelligence. Drexler assemblers, smart dust. What if a grain of sand the size of the dot at the end of this sentence is as smart as you are, a handful for a penny, and can wave its flagellum to talk on the wi-fi.\n",
    link: "/home/2023/10/06/ubigpt",
  },
  {
    title: "Filtered for the end of greatness",
    date: "12.15, Friday 13 Oct 2023",
    content:
      "1.\nThe universe is lumpy.\nIn a stellar system there are stars and planets and loads of space. Lumpy matter.\nThen it fractals all the way up:\n\nStars are organized into galaxies, which in turn form galaxy groups, galaxy clusters, superclusters, sheets, walls and filaments, which are separated by immense voids, creating a vast foam-like structure, sometimes called the “cosmic web”.\n\ne.g.:\nThe solar system is in the Milky Way, is in a galaxy cluster called the Local Group, which is part of the Virgo Supercluster, which is part of the Laniakea Supercluster, which lies on our home galactic filament 1.0 billion light-years long and 150 million light years wide called the Pisces-Cetus Supercluster Complex.\nThen the lumpiness stops.\n\nat roughly 100 Mpc (roughly 300 million light-years) … the lumpiness seen in the large-scale structure of the universe is homogenized and isotropized … At this scale, no pseudo-random fractalness is apparent.\n\nLooking from this far out, the cosmos is smooth.\nAstronomers call this level of the large-scale structure of the observable universe the End of Greatness.\nSEE ALSO:\nCosmic latte, the average color of the universe as perceived from the Earth. In hex, #FFF8E7.\nThe Wikipedia page has this footnote: Due to flawed calculations, the average color of the universe was originally thought to be turquoise.\nShame.\n2.\nThe Halo is an upcoming headband device by Prophetic that zaps ultrasound into your brain to induce and stabilise lucid dreams.\nHere’s Prophetic’s technology roadmap (PDF, hosted on Shopify weirdly?).\nThere’s a slightly odd productivity spin on the website:\n\nIn lucid dreams, you are freed from conventional laws of physics: gravity, conservation of energy, conservation of mass. This makes the experience the ultimate sandbox for divergent problem solving.\nThere’s a reason why history’s luminaries in science, math, and art credit their lucid dreams for their most pivotal discoveries.\n\n(From memory, all of these came in dreams: the cybernetic anti-aircraft gun computer, possibly the first example of human-computer symbiosis; the helical structure of DNA; the structure of benzene.)\nSo as much as Prophetic is all about yeah so we’re expanding the range of consciousness and there’s all that psychonaut language… I wouldn’t be surprised if there’s a secret pitch deck with a slide that reads “VR headsets are coming and ultrasound transducers are cheaper than GPUs, so our customers will enter the metaverse on their own wetware” – and in 2043 I’ll be running Microsoft Excel Hypnogogic Edition on my colonised unconscious, grinding out a second job between midnight and 4am. \nALTHOUGH. If this gets us closer to a transcranial magnetic stimulation helmet that walks me to the shops, as previously discussed, then let’s go. \n3.\nHere’s a proposal to add a white, fourth light to traffic lights, aimed at robot cars.\nWhen the white light is showing, autonomous vehicles (AVs) are free to choose and coordinate their own movements.\nRed, green, and amber operate as usual. The fourth light kicks in when there is a sufficient density of AVs. The fallback is neat.\n\nThe white phase concept rests on the fact that it is possible for AVs to communicate wirelessly with both each other and the computer controlling the traffic signal. When enough AVs are approaching the intersection, this would activate the white light. The white light is a signal that AVs are coordinating their movement to facilitate traffic through the intersection more efficiently. Any non-automated vehicles - those being driven by a person - would simply be required to follow the vehicle in front of them: if the car in front of them stops, they stop; if the car in front of them goes through the intersection, they go through the intersection.\n– NC State University, Researchers Propose a Fourth Light on Traffic Signals - For Self-Driving Cars (2023) \n\nIn simulation, traffic runs faster:  when 10% of vehicles are autonomous, you see delays reduced by 3%. When 30% of vehicles are autonomous, delays are reduced by 10.7%.\nIt would look wild. I linked to that old Zurich Insurance commercial recently – it would look like the robot cars section of that.\nBut there’s something profound about this fourth light –\n\nwhen the light is off, it’s the state that coordinates cars and tells us what to do\nwhen the fourth light is on, we’re in libertarian mode, and either you’re a robot car who threads your own way through the traffic, or you’re a legacy human driver and you have to follow.\n\nIt’s like… the white light is a mode switch in the locus of the technology of coordination?\nSelf-driving, autonomy, emergent behaviour – it’s the spirit of our age, right? For better and worse. Maybe we’ll see more. Fourth Light for moderated social media; Fourth Light for paying your taxes; Fourth Light for, I don’t know, politeness.\nYou can always read culture in technology but what a thing to see it so close to the surface.\n4.\nNoam Shazeer is one of the inventors of transformer models, the architecture that allows for today’s incredibly effective large language models, i.e. modern AI.\nFrom one of his follow-up papers:\n\nThese architectures are simple to implement, and have no apparent computational drawbacks. We offer no explanation as to why these architectures seem to work; we attribute their success, as all else, to divine benevolence.\n– Noam Shazeer, GLU Variants Improve Transformer (2020)\n\nThere’s something that I haven’t heard come up in the God of the gaps argument: new gaps.\nBonus link\nI’ve mentioned before that I often work with a browser window open to a live stream of a waterhole in the Namib Desert. Antelope come and go. You can hear the wind and the insects. Yesterday I saw a giraffe.\nI figured it deserved its own single-serving website?\nSo here it is: Waterhole.\nSee you over there!\nWaterhole was a super quick hack as part of my residency with PartyKit. I wrote up why and how and all that good stuff (like screenshots) over on the PartyKit blog: A single-serving waterhole in the Namib Desert using Remix.\nThe code is open, in case you want to make your own waterhole with a different live stream. You’ll find the GitHub link at the bottom of that post.\n",
    link: "/home/2023/10/13/filtered",
  },
  {
    title: "Why you should watch Big’s Backyard Ultra, which starts tomorrow",
    date: "10.40, Friday 20 Oct 2023",
    content:
      "I am going to try to convince you to spend the next 4 days watching a YouTube live stream of people running round a 4.1 mile loop in Tennessee, all day and all night.\nBig’s Backyard Ultra (Wikipedia) starts tomorrow, Saturday 21 October.\nOk – I’ve never run a marathon, let alone an ultramarathon: a distance greater than 26 miles. I am a frequently injured, currently injured runner, but not that kind of distance. So I’m very much a spectator here.\nA “backyard ultra” is an ultramarathon format with simple rules:\n\nYou run a 4.167 mile loop (“yard” in the backyard parlance) before an hour is up. Easy: this is the pace of a brisk walk.\nThe next hour, you do the yard again.\nAnd again.\nAnd again.\nAt the top of the hour there’s a bell. You have to move forward off the starting line when that bell goes.\nAt the end of the hour there’s a bell too. You have to have returned to the starting line and completed the loop before that bell. Otherwise you’re timed out.\nIt doesn’t matter if you’re not in first place for a loop. Just complete the 4.167 miles before the hour is up. Everyone starts the next yard at the same time.\nAnd again.\nAnd again.\nNo support is allowed on the trail, only between loops.\nAnd again.\nFor 12 hours perhaps.\nOr 24 hours. That’s exactly 100 miles. (How are you getting enough calories? When are you going to sleep?)\nIf you finish the loop 15 minutes early that means 15 minutes sleep before the next loop starts. But you’d have to run faster to have the time.\nAnd again.\nIf you drop out, even if you race let’s say 48 yards, that’s 2 full days of running, 200 miles, you are placed DNF: Did Not Finish.\nThe final runner must complete one full yard on their own, after the penultimate runner is out. Otherwise they’re DNF too.\n\nThis means that if someone wins at 60 yards, somebody else has to make it to 59.\nThere are backyard ultra races all over the world. They act as qualifiers for Big’s. Big’s is the original, started in 2011, and also where the world championships happen.\nThe Individual World Championships are once every 2 years (this is the race that’s starting soon).\nI was hooked on the previous one in 2021. The winner was Harvey Lewis. Lewis ran 85 yards, or to put it another way: 354 miles in 3 days, 13 hours.\nThe world record is 102 yards and set earlier this year in Australia. I didn’t watch that. I did catch the 2022 World Team Championships. The races are streamed on YouTube as a combination of handheld cameras and trail cams. Much of the footage is in silence or in the dark. Two runners went head-to-head from 86 yards to 101 yards - breaking the 100 loop barrier for the first time – then both retired out together.\nThe inventor of the format is Lazarus Lake. Big is the name of his pit bull who naps under the scoring table. Backyard ultras took off during the pandemic lockdowns because you can do it, well, in your backyard. There was a distributed international championship.\nThere’s a great article from a competitor at Big’s back in the 2015, in Trail Runner magazine.\n\n“There he is! First-place runner right there!” The joke goes on for hours. It seems to get funnier to them each time they repeat it. \nBut the more loops I run, the more I realize it’s not a joke. It’s the core truth of this entire race. Everyone really is in first place until they drop. Whether you finish your loop in 44 minutes or 59 minutes, if you’re still running, you’re still winning. There is no strategy. My brain starts to death-spiral, as I realize that no matter how hard I work, I’ll always be in first place, like everyone else. Time is a flat circle.\n– Trail Runner, Big’s Backyard Ultra: A Race With No End (2016)\n\nAnother quote: It’s as fascinating and as terrible a race as will ever be dreamed up.\nSo the runners seem to plumb deeper truths the further in they get.\nLazarus Lake too.\nDuring Big’s, Lake stays awake and each hour posts increasingly gnomic commentary on his Facebook page. It’s like he simultaneously punishes and loves the runners. He speaks in aphorisms about human capability.\nAnother quote from that article, this one about Lake’s Facebook updates: Each reads like the beautiful poetry of a sadistic Thoreau.\n\nif we did this to dogs,\nthey would throw us in jail.\nit is one thing to run a 100,\nand start once.\nit is another to run a 100,\nand have to start 24 times…\n\nIt takes someone special. Though we - us, the runners - are all people.\nBecause, for me, that’s the draw of watching backyard ultras.\nIn a way, long-distance endurance running is what humans are made for. Physiologically this ability is why we’re special. David Attenborough documented the persistence hunting of the San people in the Kalahari Desert: the Intense 8 Hour Hunt (BBC Earth, YouTube).\nBeyond fitness, race strategy, and calorie math, these runners need will. It would be so easy to just stop. Or sit down for a minute longer. After a couple of days they’re seeing things.\nSo when I’m watching Big’s on YouTube, I’m seeing humans who possess extraordinary fitness and also extraordinary will. They’re right at the limit, probing that boundary. Every time a backyard record is broken, they’re establishing new ground for human potential.\nThe BBC did a retrospective on the 2020 season. It, too, is packed with weird truths from the competitors.\n\n“It’s like being punched in the face,” chuckles Cantrell from his kitchen via Zoom. “Not hard, just a little bit. But you do it again, and again, and again.”\n\nAnd:\n\n“He gets called a sadist and that he likes people to suffer, but he’s not like that,” says 31-year-old Karel Sabbe, the Belgian dentist who is also among the 99% of non-finishers at Barkley. “He gets the best out of people. He wants everybody to have the opportunity to face their own limits.”\n\nI love him deeply, says another runner.\nAnd:\n\n“It’s really dangerous to think,” says Steene. Dauwalter describes it as running in “robot zone”. Proctor says: “We’re crippled by the past and the future. What’s happening in the next 10 seconds is all that I can control.”\n\nAnd:\n\nSteene couldn’t stave off hallucinations - trees and bushes took the shape of dinosaurs and giants - while Guterl saw severed heads and heard growling in the woods.\n\nAnd:\n\nIt is all relative for Proctor, who has an app on his phone called WeCroak, which tells him five times a day how long he has left to live - as a reminder not to waste his life. “The chair that you’re sitting in right now - is that comfortable? Go and run 50 loops of a 4.17-mile course, then sit down in that chair and I’ll ask you if it’s comfortable.\n\nIt’s a fantastic article and great introduction:\nBig Dog’s Backyard Ultra: The toughest, weirdest race you’ve never heard of (2021) (BBC Sport).\nSo here are the 50 runners for the Individual World Championships at Big’s Backyard Ultra, starting tomorrow. They’ve qualified from all over the world over the past 2 years.\nWatch a trailer for the race (YouTube).\nWatch Lazarus Lake preview the race (YouTube) – he talks about what the trail is like and what makes backyard ultras particularly difficult.\nPhil Gore, who holds the world record at 103 yards, is racing. The two last-standing runners in the team championships in 2022, at 101 yards, are also both racing.\nThe first couple of days, you can drop in and out of watching. Day three, you’ll become astounded that people are still running. You’ll get to know the characters, root for them, be gobsmacked at their capability. If the runners get through a fourth day again, I guarantee you’ll be hooked, watching for 10 minutes at the top of each and every hour, waking up in the night to check your phone. Waiting to see if the scope of human possibility has been enlarged.\nI never quite know where best to look for updates. This is where I’ll be looking to follow along:\n\nOn Facebook, Big Dog’s Backyard Ultra Run Group – join this and start here.\nAlso on Facebook, Lazarus Lake – follow him for hourly philoso-commentary.\nLive positions and times.\nThe official YouTube channel, Conversations by the Woodpile – I’m pretty sure this is where the live stream will be.\n\nI think what makes it accessible to watch is that I can imagine running a single yard.\n4 miles in an hour? I do that on a Saturday without thinking about it, running errands in my neighbourhood.\nA second yard? A third? I can do a half marathon with some training. In three hours? Sure, easy. How much further could I imagine going? I once raced 20 miles over four loops. So, slower than that, the same again maybe. Outside single digits? Probably not actually. I’ve never tested my limit but I really imagine not.\nWhen I’m watching these runners race their 10th, or 20th, or 100th, I know that they have arrived somewhere - through physical endurance and mental will - that I could not, but simultaneously I know that it’s just one more loop, and that fact I can picture and feel and connect with in my legs.\n",
    link: "/home/2023/10/20/backyard",
  },
  {
    title: "Hyperlocal radio in 1980s Tokyo",
    date: "20.20, Friday 27 Oct 2023",
    content:
      "In the early 1980s in Japan, a movement called mini-FM blossomed: a thousand tiny radio stations broadcast over just half a mile each.\nOne of the first stations was Radio Home Run, broadcast by Tetsuo Kogawa and his students from 1983–1996 in the Shimokitazawa neighbourhood of Tokyo:\n\nThis station took advantage of a loophole in Japanese broadcasting legislation, which stipulated that devices under a legally-defined power threshold — usually requiring less than one watt of power — could transmit on the air without a license. Using a legal very low-powered FM transmitter, members of Radio Home Run transmitted a signal able to reach listeners within about 500 meters of the station’s antenna. However, Tokyo’s high population density meant that this relatively weak transmitter still had massive possibilities, since its comparatively small coverage area still contained about “20,000 residents, all potential listeners”.\n– Research Catalogue, Movements within Small Radio Movements\n\nIt was Kogawa’s realisation that low power radio was legal. They had intended to run a pirate FM station (Tokyo had only two official stations) but he discovered the exception in the regulations and started investigating cheap, sometimes hand-made transmitters.\nKogowa wrote books and pamphlets; journalists picked up the story whenever a new station opened.\nHe tells the story of mini-FM in Toward Polymorphous Radio:\n\nEven major advertising agencies tried to open mini-FM stations. The exact number is unknown, but it can be estimated from the number of small transmitters sold that, in a year, over one thousand stations appeared in Japan. People on college campuses, in housing complexes, coffee shops and bars, stalls at street fairs and even local offices started mini-FM stations. More than ten companies, including Mitsubishi, Panasonic, Hitachi and Sony, sold a transmitter labelled “For mini-FM use”.\n\nThe intention was to change broadcast: The area that a one-watt transmitter covers is within walking or bicycling distance.\nAnd so that early station Radio Home Run became a collective experience:\n\nRadio Home Run transformed listeners into producers by inviting people tuning in to physically travel to the station’s nearby studio.\n\nCorollary: it also revealed how strange typical everyday experiences of radio - through listening alone - actually are.\nI’m skipping over so much!\nHow Tetsuo Kogawa’s concept of “polymorphous” media anticipated social media.\nHow physical movement would put the listener in “kinetic interaction” with the electromagnetic field from the transmitter, moving in and out of coverage.\nbtw here’s a great history of mini-FM with its whole context, appended to the shopping page for a hat? The hat is sold out.\nAnyway.\nMini-FM left a legacy. Check this out.\nFrom a review of the Sony Ericsson W980 Walkman – in 2008.\n\nFinally we come to one of the most exotic and intriguing features of Sony Ericsson W980 - the FM transmitter allowing you to broadcast your favorite tracks. Those can then be picked up by any device with an FM radio receiver in the vicinity.\n\nBy this point the iPhone had been out for a year! The iPod was released in 2001.\nImagine if the iPod had shipped with a built-in FM transmitter and receiver! Each iPod owner a walking, combined broadcaster and listener.\nExcept that it wouldn’t have worked.\nWhat we have a word for now is discovery. The vital feature of mini-FM was the potential audience re-tuning between known stations by running up and down the dial, volume up, stumbling across unheard-of stations.\nThe vital feature for a two-way iPod would have had to be something similar: a menu option labelled Nearby next to the albums and the artists.\nYet I can’t let go of that alternate history.\nIn our parallel universe, we’d all be users of Scott Jenson’s invention of the Physical Web. It was built into Android.\n\nThe Physical Web enables you to discover web pages associated with everyday objects and locations. …\nWhen you are near a bluetooth beacon (and have bluetooth enabled), you will receive a notification for the Physical Web.\n\nLike QR codes only I could carry a beacon in my pocket, get on a train, and the website would show up on the phone of all the passengers.\nAgain it’s all down to how you encounter the URL. As a push notification it’s a spam vector. As a “nearby” tab, more interesting? Possibly. It’s a tough one.\nAnd related to this:\nAn iPhone app I am intrigued by is WorldWideWeb by IconFactory.\nYou open a folder on your phone with the app… and it becomes a website accessible for anyone else on the same wifi network.\nNow, what is a shame is that Apple used to list local websites in Safari bookmarks (the technology is called Bonjour). This feature was removed back in 2017.\nSo we’ve got a discovery problem again.\nBesides, the scale doesn’t match up. The lesson of mini-FM is that you need a potential audience of 20,000 producer/listeners, not only the people you can already see.\nAs someone who made fanzines at school (80 issues sold!!) - that being my route into the web - I do wonder about the mini-FM equiv for, well, not so much new media anymore as early-middle-aged media.\nBut modern broadcast doesn’t afford the fuzzy perimeters of 1980s FM radio.\nI’m never going to be bored-browsing Netflix and get a faint glimmer of someone’s home-broadcast TV show wedged between menu items, there to view if I can tune in exactly right. My iPhone might be the means of production, in the right hands, but I’ll never own the means of distribution.\nAnd that’s not a shame, not really, time moves on, our era has its own other freedoms. But still.\n",
    link: "/home/2023/10/27/minifm",
  },
  {
    title: "Now and then and an infinity of extrapolated Beatles tracks",
    date: "17.39, Friday 3 Nov 2023",
    content:
      "There’s a “new” track by the Beatles, grafted together from a demo by Lennon in the 70s, guitar by Harrison in the 90s (Lennon was killed in 1980. Harrison died in 2001), and new strings and drums from McCartney and Starr.\nPlus a lot of production, using AI.\nThat demo from Lennon: The very original recording is just John playing the piano with TV in the background – that’s Giles Martin, producer, son of George Martin.\nOther tracks layered on similar poor recordings resulted in Lennon’s voice sounding “ghostly.” That was 1994.\nSo this time they used technology developed for Peter Jackson’s Get Back documentary on Disney+ (which is incredible btw).\n\n“Essentially, what the machine learning does is it recognizes someone’s voice. So if you and I have a conversation and we’re in a crowded room and there’s a piano playing in the background, we can teach the AI what the sound of your voice, the sound of my voice, and it can extract those voices,” Martin said.\n– NPR, How producers used AI to finish The Beatles’ ‘last’ song, ‘Now And Then’\n\nListen to the new track here: The Beatles - Now And Then (Official Audio) (YouTube).\nIt’s… pretty good?\nLike, musically, it’s ok. I find the strings arrangement a little too much maybe? McCartney’s taste has been so era-defining that, weirdly, his work starts to sound generic. (I say this as a McCartney fan! Read 64 Reasons To Celebrate Paul McCartney and be convinced.)\nBut it’s a lot and to my ear, it’s too smooth.\nBecause what really shines is Lennon’s voice. My goodness have they done a good job with that. They should have given it more room.\nMechanically recovered from the slurry of old tape recordings or not, 50% reconstruction or not, Lennon’s voice shines through time and up through the muddy waters of AI algorithms. It is poignant and beautiful to hear him sing. Familiar and unfamiliar all at once.\nMind you I’m in Liam Gallagher’s camp given what he said in The Guardian: The Beatles could shit in my handbag and I’d still hide my polo mints in there.\nASIDE:\nHere’s a Wild Palms reference seeing as I’m a massive fan and even from 1993 they pinpointed this modern era before any of us:\nEpisode 4, after lounge singer Chap Starfall has been murdered by the Friends, the Senator et al have a hologram of him playing as background music. He was their buddy.\nTabba Schwartzkopf is watching: Hate to say it but I like him so much better since he died. That posthumous quality really makes me shiver.\nLook – Wild Palms nailed both the nature of the technology S-curve and the effect of VR/the metaverse/synthetic reality/fake news/whatever you want to call it, all as background colour, wrapped up in a melodrama about LA media through the eyes of a patent attorney. I will never miss an opportunity to evangelise.\nI’m trying to figure out how I feel about Now and Then.\nIs there any legitimate difference - poignancy aside - between this AI extrapolation and, well, me never having heard a track before?\nI have an ANALOGY.\nDummy by Portishead – released in 1994.\nA contender for the best album of my lifetime. A haunting trip-hop soundtrack over 30 years.\nI copied it onto tape for my car. Later ripped the CD into iTunes, listened endlessly there.\nPortishead’s third album Three came out in 2008. In terms of which group has a better three album oeuvre: there is none.\nI was never a Spotify listener. But Apple Music shipped in 2015, and at some point the streaming edition of the album shouldered out my ripped version, and:\nThere was a new track.\nI can’t even discover when It’s a Fire (YouTube) appeared. It’s not on the U.K. original release.\nIt’s probably my favourite track now because each time I hear it, it still feels brand new. Imagine your favourite album for two decades suddenly has an extra song! It’s wild.\nSo my control experiment is right here. Music spear-fishes both kinds of memory - emotional and episodic - and reliably hauls up exotic and forgotten species from the deep past. And It’s a Fire has none of that for me. No gang of mates smoking in a front room. No silhouetted dark woods out of the car window in the witching hour. No bar, no working in a cafe, no running up Parliament Hill on Hampstead Heath at sun-up, no residual sense recall of the feel of the cracked plastic compact disk case packed and unpacked with my uni belongings. Simply: the music.\nAND YET, even without all of that, I love it.\nHere’s my conclusion:\nYes there is some (large) component of the “unit” of music/art/etc which is its subjective significance. But it turns out that this isn’t essential. The work can stand alone.\nHow about authenticity?\nDoes Now and Then lose something because Lennon wasn’t in the room?\nCan I hear inauthenticity? I suspect not. I can hear the pre-2020s consequences of inauthenticity: a song without authenticity sounds empty.\nBut here in the 20s that has changed. We can say that Now and Then is a patchwork construction (but isn’t all studio-produced music) and macabre certainly (but as Schwartzkopf said, doesn’t it make you shiver?) - but it isn’t hollow. It’s not low quality.\nSo authenticity doesn’t matter either.\nWe’ve seen AI-extrapolated art before (as previously discussed) and it just hasn’t been very good. Like, it’s novel but it lacks something, and my preconception has been that there was no way that AI art can be good because it doesn’t have the original human touch, or the provenance (societal or personal).\nBut what I believe now is that it’s do with the effectiveness of the machine.\nAI art will be good. We will one day have new Van Goghs, new Beatles tracks, new episodes of Firefly, and so long as they’re good - which they will be - my prediction is that we won’t mind where they come from. Quality will overcome it all. Caring about the origins will be nerdy like specifying which show runner you preferred on The West Wing.\nSo we should lean into extrapolated art maybe?\nAnd that would be an easy thing to do?\nSimon Willison recently did a deep dive into OpenAI’s new image synthesis AI: Now add a walrus: Prompt engineering in DALL-E 3.\nThe random number seed caught my attention. Simon\n\ngenerated an image from a prompt\nasked ChatGPT for the seed for that image: 1379049893\ntweaked the prompt to add a bow tie, maintaining the same seed\nand got an almost identical image, only with the asked-for bow tie.\n\nSimon: I’m pretty stunned by this.\nIt’s a surprising result! My mental model of AI image synthesis has been that (a) yes images look great, but (b) they’re pretty chaotic. i.e. a change in the prompt, even an extra bit of punctuation, will send the AI spiralling off in a different direction and the resultant image will look very different.\nWhat this deep dive shows that is that variance in the results is down to a random number generator. That’s what the “seed” is: it’s a number to feed into the image synthesis. The seed is randomly generated – but now I need to update my mental model to state that the image synthesis itself is actually deterministic.\n(I’ve tried to reproduce Simon’s experiment but ChatGPT will not tell me the seed for DALL-E-generated images. So I think that hole has been closed.)\nThe consequences of there being a seed:\nIt makes AI synthesis way more reproducible. That means you can sit there tweaking and tuning a prompt and narrowing in on something intentional – this makes AI much less of a novelty, and much more like the creative process. It will reward work and skill.\nIt also reminds me that the words of the prompt become numbers too: vector embeddings, which can be mathematically combined.\nAs AI imagery, so AI music.\nNow John Lennon probably isn’t a 10 digit integer. The seed isn’t deterministic like that. But passable Lennon probably is a 1,024 dimensional vector in embedding space.\nAnd given that, there’s not just Now and Then but an infinity of possible extrapolated Beatles tracks.\nWe’d have to figure out the ethics and the IP (both fascinating rabbit holes in their own right) but perhaps we should lean into that, instead of pre-emptively blocking the possibility in the UI, which is what happens now, because who knows what would happen next.\n",
    link: "/home/2023/11/03/beatles",
  },
  {
    title: "A one-off, special, never-to-be-repeated Acts Not Facts weeknote",
    date: "18.25, Monday 6 Nov 2023",
    content:
      "I re-read Robin Sloan’s The art of working in public (Snarkmarket, 2011) which riffs, in part, off my Week 315 post at BERG. I was big into weeknotes.\nWork in public. Reveal nothing, says Sloan.\nWell consider this a weeknote for my new-ish micro studio Acts Not Facts.\nJust this once though.\nIt’s Monday morning. I’m standing outdoors on the train platform on the way to a workshop tapping this out with my thumbs.\nComing up this week\n\nPartyKit – mainline project. My summer residency was about exploring multiplayer, realtime apps (blogs posts and prototypes here). It’s a different project now. Loosely I would say doing the groundwork for product strategy and go-to-market, but via making things rather than getting lost in plans. Writing code, making Notion pages.\nOh I need codenames. I need to speak to comms to check I can name this one. I’m helping to set up the AI experiments pipeline in a big org. The premise is that AI is a 10 year leap forward and we’re imagination bottlenecked: how do you explore and learn with a portfolio approach? On day 1 (a couple weeks ago) I sketched out what the next big bet could be – for my personal comfort I need to know that there’s at least one workable idea on the table. There’s an existing, great team, so I’m working with them 1 day/week. This week is the first of the workshops to start capturing ideas.\nAnother one I’m not sure about naming. I’m on my way there now: a product strategy workshop for a hardware startup approaching product #2. We’ll look at roadmap, commercials, and brand. I like these broad, spilly problem spaces that take synthesis to arrive at a concise, memorable approach.\nOn Wednesday I’m doing a talk at PA Consulting about my AI Clock, currently working its way towards a Kickstarter. Looking forward to talking about the prototyping and design process, and also sharing some meta thoughts about both opportunity spotting and large language model vibes.\n\nI’m in a cafe opposite the Royal Courts, tapping on my laptop. This is my current pov. My idea was to bang out these words before the week proper kicked off but I don’t think that’s going to be possible.\nHere’s the premise of Acts Not Facts, which is my new-ish product invention studio, but it’s actually just me:\n\nAs the homepage says the studio is interested in AI, multiplayer (i.e. group use), and embodiment (learning from physical space, cognition, etc, and physical computing). Not all three areas at once necessarily.\nWhy the name? For the last decade or so, the way to bring new products into the world was to think carefully and make PowerPoint decks and cover the walls in post-its. No longer. The landscape of possibilities is unknown so the appropriate approach is to roll your sleeves up. Things-which-are-made teach you about the technology, open up new thoughts, and (vitally!) let you work with people who aren’t as close to the technology as you but probably have better ideas.\nThe plan is to find projects that I can achieve with a small team hired by the studio. That means building a small portfolio on my own for creds. That’s the stage I’m in now.\n\nI’m lucky that these first engagements align with the Venn diagram on the homepage.\nOk, workshop time, wish me luck.\nMedia last week\n\nI run an unofficial archive of my favourite radio show, In Our Time, which is on the BBC and been going about 25 years. There are 1,000+ episodes on every topic under the sun. I prototyped then then shipped a new AI-powered search widget which you can use right now on braggoscope.com. Tap Search in the top links section. It’s neat because it uses “embeddings” – a kind of semantic space. So you can search for jupiter but you can also search for the biggest planet. My post about this did pretty well on LinkedIn. People like to see simple but effective uses of AI!\nVenkatesh Rao published his new essayOozy Intelligence in Slow Time which builds on and says very positive things about a recent blog post: Matt Webb’s excellent reframing of AI as intelligence too cheap to meter… – I am v proud to be on vgr’s radar to say the least.\nI spoke recently in Hamburg at NEXT23 about human-AI collaboration, and playful experiments, and after the talk recorded a 30 minute interview about product invention. It was a super fun conversation and has now been published: Exploring AI personalities and poetic clocks (YouTube).\n\nThink of the studio as a funnel. Awareness becomes conversations becomes work.\nI don’t know yet what the right shape for a project is – it takes a while to learn where my edge is and what resonates in the market. Ideally I would be consistent building awareness around that.\nTo begin with it is enough that people know I exist via an activity which is more efficient than 1:1 conversations. Hence tracking media.\nBrief situation report: I am sitting outside on a low wall eating a cheese sandwich. The product strategy workshop went well I think. It is useful to be able to map out a company’s products and activities and compare that against all the other companies I have seen. It means I can say what is different or what feels missing. Anyway, the 2 hours of immersion resulted in 3 recommendations.\nI’ll carry on writing when I’m on the train home this evening.\nAlso in my in-tray\nI regard the AI Clock as a studio project. I’m pricing up a second manufacturing route before starting the crowdfunding campaign. An email of questions arrived this morning that I need to respond to. Then there’s a ton of small tasks to do with content for the campaign itself… and I need to line up media…\nAnd remember I said that awareness leads to conversations? I have an email or two to respond to on that count too, but before I do that I need to figure out an ask… like, if the point of a meeting is to beget more meetings then how do I ensure that happens?\nThe scarce resource is always attention.\nI have a stack of experiments I want to build. But it is never top priority to go through my list and draw/develop/combine/prioritise/next-steps then all.\nLet alone those that could be businesses in their own right! Those are the ones I really need to carve out time to develop.\nI ran across the idea recently that you operate a queue-based or stack-based priority list. With a queue, you work down from the top, crossing off tasks as you go, and add new ones to the bottom. Stack-based: you add and take from the top, optionally re-ordering the stack based on priority.\nI have always been stack-based. (Which anyone who has ever emailed me will recognise. If the email is in the top 6 at the exact moment I am looking at my phone, I will reply immediately. If not it will be buried forever. Sorry.)\nWhich begs the question: given scarce attention, how do you get to the tasks which are lower down the stack but none-the-less vital? Answers on a postcard please.\nThe smart thing to do would be the take my wish list of experiments, and cherrypick for possible collabs. Sketch a project pitch every time I’m about to walk into a conversation with potential clients, so I have something in my back pocket.\nHuh. Maybe I actually should do that.\nNothing profound. It’s dark now and, although I’m on the train, my thumbs are slow from typing in the cold on the platform. So time to wrap this and publish and maybe I’ll have time to reply to the manufacturing folks before I get home.\nUPDATE: Email sent. Approaching my stop. Save. Commit. Deploy.\n",
    link: "/home/2023/11/06/weeknote",
  },
  {
    title: "An AI hardware fantasy, and an IQ erosion attack horror story",
    date: "10.42, Friday 10 Nov 2023",
    content:
      "(This is #2 in what it turns out is an ongoing series of highly speculative, almost entirely unfounded hunches about AI. The first was about alignment and microscopes.)\nA fantasy of ‘intelligence too cheap to meter’ in the hardware supply chain\nI like to describe AI as a 10 year wormhole into the future (maths here).\nWe can date it to the release of ChatGPT in November 2022 which is when the technology, UI, and public understanding all came together, but really it was 5 years in the making: the underlying architecture of large language models is the Transformer model, and the original paper came out of Google Research in 2017.\nIt took OpenAI to do the engineering to scale it though. OpenAI was founded in 2015. So let’s say an overnight 10 year leap with a 7 year run-up.\nBut now OpenAI is going for it.\nWhat I love about OpenAI is that they hold nothing back.\nThere’s no clever MBA-authored strategy like holding a feature till next year to maximise profits. Just: bang bang bang. Everything they’ve got, as soon as it’s ready. User-facing in ChatGPT and for developers via the platform APIs.\nFor instance: here’s Sam Altman’s opening keynote (YouTube) for OpenAI’s developer day last week. It is 45 minutes and tight af.\nThe full list of announcements (TechCrunch) includes the ability to make custom ChatGPTs that can browse the web and use tools on your behalf, and a app store for them; new APIs for a version of GPT-4 that can see (so fast that it can interpret video), and also for the new image generation model DALLE-3; APIs for great speech synthesis (i.e. everything can talk now) and a bunch more. Like, the Assistants API means it’s easy to build a copilot for any app and you know how I feel about NPCs.\nAs a developer, this is exactly what you want from your platform company.\nSo I am not the only person to make a comparison with Apple keynotes.\nWhich are slick but omg so long and maybe not as action-packed as they used to be. I mean, you think about Apple’s Vision Pro announcement (YouTube) and it’s part of a 2 hour keynote and oh so much explaining.\nWhich I love for the design nerdery and also is necessary to make sure the media lands right, I know. But you get the impression that Sam Altman would have come on stage wearing the thing, given a brief demo, shared a link to the developer documentation, wrapped up, and the whole slap in the face would have felt like the sonic boom of the future arriving.\nWhich takes me to a fantasy of combining the Apple and OpenAI approaches.\nApple is a hardware product company. But just suppose it were a hardware _platform__ company, a platform for other people’s hardware, OpenAI-style holding nothing back.\nYou’d get components that would up-end the supply chain.\nTiny sensors that can do gaze and pointing detection. Microphones with absolutely perfect AI-powered speech recognition built in, and configurable semantic understanding such when someone says “turn on” (or anything similar, while paying attention to it), GPIO pin 1 goes high. Instead of a pseudo-3D lenticular display just for the Vision Pro, one that whichever OEM can build around.\nLike any platform company, there would be evaluation boards, but building from the OpenAI playbook, the sensors and components would have plug-and-play versions for individual developers in the form of Raspberry Pi shields and so on. So there would be on-ramps and routes to scale.\nThis is an old fantasy: in my 2020 post How I would put voice control in everything I set this out…\n\nIf I had all the VC money in the world, I would manufacture and sell standardised components – they would connect and act identically to mechanical buttons, switches, and dials, only they would work using embedded ML and have voice, gaze, and pointing detection, for interaction at a distance.\nThe goal would be to allow manufacturers of every product to upgrade their physical interfaces (add not replace ideally), no matter how trivial or industrial, no matter how cheap or premium.\n\nAnd this is how we would get to intelligence too cheap to meter and situated, embedded AI. (There are a bunch of examples in that post.)\nI want my oven that knows how to cook anything just by looking instead itself and autonomously googling when it recognises the food! I want my telepathic light switches!\nBut we need AI in the hardware supply chain, not vendors who have to own the whole stack.\nMaybe OpenAI will decide to take it on.\nOk. Autumn daydream over.\nState-sponsored IQ erosion attacks\nShortly after OpenAI released its new tools, ChatGPT went down together with all the APIs, for several hours.\nThere was a coding task I was in the middle of that I literally couldn’t complete. Not because I needed API access to GPT-4, but because without ChatGPT I was too dumb to deal with it.\nI said on X/Twitter that my IQ had dropped 20 points.\n(If you’re a sci-fi fan then it was an experience from Vernor Vinge’s Zones of Thought books – living happily in the Beyond and then being engulfed in a Slow Zone surge.)\nAnd I wonder what the collective intelligence drop was, that day.\nLike, if ChatGPT has 180 million monthly active users, could we say something like 1% of the population of the US would have wanted to use it over the down-time?\nThe US has a population of approx 300 million or, in other units, 30 billion collective IQ points.\nSo if you ding that by 3 million people at -20 IQ each, that’s 6E7 out of 3E10, or a 0.2% knock on collective intelligence for that day.\nBy way of comparison, that’s a decent fraction of the effect of leaded fuel. (Everyone born before 1990 has their IQ nerfed by 4.25%.)\nAnd as someone into weird state-sponsored exploits I wonder: would it be worth doing this deliberately?\nRELATED TO THIS:\nI recently added really smart AI-powered semantic search to my unoffice archive of In Our Time shows. Go to Braggoscope, tap Search in the top nav, and type the biggest planet – the episode about Jupiter comes up. So there’s a kind of knowledge in the large language model, or whatever you want to call it, a sort of relatedness that makes it easy to put ideas together.\nHere’s the code on GitHub, open for your interest: you’ll notice in the Cloudflare worker that this “knowledge” comes from a model called baai/bge-base-en-v1.5.\nHere’s the model on Hugging Face: BAAI, the creator, is the Beijing Academy of Artificial Intelligence.\nNow, I don’t mean to sound paranoid here.\nBut in Samuel Delaney’s astounding 1966 sci-fi/speculative-linguistics novel Babel-17 (Amazon), [SPOILERS] Babel-17 is a weapon, an artificial language constructed such that intuitive leaps about combat manoeuvres are instantaneous, so it will be adopted virally simply out of utility, but the language itself omits particular connections making certain other ideas topologically impossible.\nSo: would it be possible to release an AI large language model that is exceptionally good and cheap, maybe, gaining popularity in a target language (English, or Russian, or Korean, or whatever) but makes it really hard to reason about certain concepts?\nNot so ridiculous! This has happened once before actually, accidentally!\nThe argument in Gerovitch’s From Newspeak to Cyberspeak is that, when computer science papers in the 1960s were translated from English to Russian, they were stripped of metaphorical yet inspirational ideas like “memory” and “learning”, constraining the vision of computing to simple calculation. Which is why the Americans figured out the personal computer, our bicycle for the mind, whereas the Soviets did not.\nCould you popularise an AI that made conceptual leaps around worker-friendly capitalism much harder? (For example, given that policy makers will be heavy users of future ChatGPTs, and this trend will slowly lead to social unrest.)\nCould you wait until a nation were in an intellectual arms race, like a Space Race for the 2030s, say, then knock over the intelligence augmentation infrastructure (i.e. ChatGPT v9) in critical weeks?\nI’m not saying that this is what is happening. But any government worth its salt should have a half dozen people figuring out how to perform an IQ erosion attack, precision targeted or otherwise, and another half dozen red-teaming how to respond if one hits.\n",
    link: "/home/2023/11/10/hunches",
  },
  {
    title: "A second one-off never-to-be-repeated Acts Not Facts weeknote",
    date: "09.29, Monday 13 Nov 2023",
    content:
      "The reason to cosplay someone who is good at writing weeknotes is there are benefits i.e. marketing and productivity BUT not at the cost of taking forever to write them.\nIn which spirit, here’s a second weekly update about what’s been going on at my micro product invention studio Acts Not Facts, an update that I claimed I would never write.\nOh those benefits of weeknotes:\n\nMarketing: being present leads to conversations. Proof point: someone I’ve not seen for a few months dropping me a note last week to suggest lunch.\nProductivity: reflecting on work for 15 minutes each day makes you 20% more productive, reports the BBC. What you could do in 4.8 days now you can do in 4.\n\nBut the cost!\nIf i burn that 0.8 day dividend by doing what I did last week, tapping these notes over the entirety of Monday, then it’s not worth it.\nSo there’s something about writing, and other processes, is that it’s about 10x faster if it’s what you’re thinking anyway. Which is sometimes an unfathomable alignment.\nWhich means that my meta-process for setting up a new process is to cosplay it for a bit and see if it sticks.\nBut without attachment. If it works it works! If not no biggie.\nLeading me to see if I can whizz through these weeknotes on my Monday commute. Being, today, the train to Victoria and the tube up to Finsbury Park, my regular train having been cancelled.\nIt’s raining and there are wet leaves on the pavement and the platform.\nOk on the tube now.\nComing up this week\n\nPartyKit – filling out the go-to-market while nudging the adjacent possible. Which sounds fancy but really means: cranking the handle on a new website and hacking on an opportunistic proof of concept because it might unblock someone in the community, for example this code about using websockets and PartyKit to have real-time multiplayer interactions in an iOS app: phone-party-ios (GitHub).\nThe Client That Can’t Be Named Until We Pass A Related Comms Gate – the project is to help the team set up the AI experiments pipeline. There are now three strong candidate experiments on the table, so if the first run of the pipeline process fails then at least in the fallback position there’s still work to be done. There’s a second workshop this week to add to the top of the funnel. And it’s about time that I talk out loud about portfolio approaches and why this is important etc, so there’s a deck to make.\n\nHey a common theme! With both projects I have a vivid picture in my head of a future process, but strong opinions weakly held, you know, it’s a picture which evolves. Then I’m running steps of it when an opportunity arises. Then perhaps a step can be made a ritual, and perhaps the ritual sticks without pushing water uphill, and then it’s a small lift to glue them all together…\nWhich is the same as my meta-process to establish writing these weeknotes, right? Only as part of a team rather than on my own.\nLow attachment fictional process cosplay. I would call it ops pathfinding if this were LinkedIn.\nMedia last week\nNone that I remember specifically.\nThough I’m building with the Astro web framework rn and I happened to go to the page in their docs about adding an RSS feed. It was a delight to discover, at the bottom, a link to my explainer site AboutFeeds.com.\nAlso in my in-tray\nThe AI Clock production quote came back – not quite what I wanted but there is confidence that it can come in on budget with a little work. Which means I need to finish off the rest of the Kickstarter campaign collateral…\n…and goodness knows when I’ll make time for that.\nI fantasise about having enough time in the week. It’s not that you gain more time, magically, when you work with a team, by some kind of Adam Smith division of labour topological unfolding. It’s that the week is more predictable. Time is so bursty.\nI really need to find commercial projects that I can run with more than just me. I should work backwards from that, as the critical path.\nMy tribe - or at least one of my tribes - is the Future of Coding community. There’s a Slack group full of people figuring out the future of computing and user interfaces by making and demoing, with regular computing history deep cuts.\nThe London chapter is particularly puckish (where else would you find someone introducing Vannevar Bush’s Memex as Notion as furniture?) and last time round the demos at the meet-up went from gasp-inspiring mathematical pedagogy to a choreographer who presented by typing her slides into the browser’s JavaScript console and displaying them with innerHTML.\nAmazing convener Maggie Appleton put together a demos thread on X/Twitter.\nThere is no other community that gives me such warm fuzzies, together with a combo of oh-that-makes-me-think-of and grr-I-wish-I’d-done-that. Folks I’ve got your scenius right here.\nAnyway the November meet-up is coming up on Friday and I cannot wait.\nAt my desk. That took about 20 minutes longer than I wanted. Must practice being more concise.\n",
    link: "/home/2023/11/13/weeknote",
  },
  {
    title: "Filtered for just pandemic things",
    date: "09.09, Thursday 16 Nov 2023",
    content:
      "1.\nJuly 2020. Sales grow for private backyard labyrinths, portable labyrinths, and handheld labyrinths.\nMy take on activities like smartphone games is that they are a combination of rehearsal and wish fulfilment for whatever preoccupation you have. Like, I play Stardew Valley obsessively when I’m in a slow grind build; I play Drop 7 when I’m plate-spinning complicated projects. The wish, fulfilled in the game, is that these endeavours are successful.\nWhat collective rehearsal did labyrinths fulfil?\n\nIn contrast with mazes, which generally have multiple branching paths and come to dead ends, labyrinths have only one entrance and path.\n– Bloomberg, The Pandemic-Era Appeal of Getting Lost in a Labyrinth (2020)\n\nThe only way out is through.\n2.\nSeptember 2020. Zoom and Zoom towns.\n\nTruckee, Calif., is a mountain town just northwest of Lake Tahoe. …\nTruckee is part of a trend that realtors and journalists are calling “Zoom towns,” places that are booming as remote work takes off.\n– Planet Money, NPR, Zoom Towns And The New Housing Market For The 2 Americas (2020)\n\nRemote work was an amazing fantasy. There are pockets, rare startups, that got good at remote-first. Nobody does hybrid well, which is the reality, no remote. So I can’t see it sticking.\nWhich is a shame: there is talent everywhere and the rise of Starlink means that Zoom towns should be global.\nSo as awful as the pandemic was, it led to all kinds of forced experiments, and led to discoveries - like really good remote work - that almost became the new status quo.\nThen the wave broke and rolled back.\n3.\nMay 2020. Eels.\nThe thing about the garden eels in the Tokyo Skytree aquarium is that they are really shy.\nThey got accustomed to humans, pre-pandemic, and stopped ducking under the sand whenever they saw a face.\nBut without visitors their bashfulness returned.\n(You and me both, eels.)\nHence:\n\nthe aquarium is setting up five tablets facing their tank, with users asked to connect through iPhones or iPads via the FaceTime app.\nOnce the video calls start, people are asked to show their faces, wave and talk to the eels.\n– The Guardian, Japanese aquarium urges public to video-chat eels who are forgetting humans exist (2020)\n\nWhen you gaze at the garden eels, the garden eels gaze at you.\n4.\nJuly 2020. Teeny weeny telepresence robots.\nHere’s Ross Atkin’s shop of kits for super cute cardboard robots: The Craft Robot.\nOne of the robots is a cardboard carapace for a smartphone and also it has wheels. You dial in remotely from any web browser.\nThe 2020 Kickstarter smashed it. Smartipresence: the cardboard telepresence robot.\nIn the midst of the pandemic I had a call with Atkin, teleported into one of his tiny robots!\nWe talked – a regular video call.\nOnly ALSO there were extra buttons in Chrome and so I was driving around his kitchen table, which from my perspective was scaled up to the size of furniture and buildings.\nI could turn to look at him! Or I could not and we could walk-and-talk idly chat as I ambled and explored!\nThere is so much nuance in the body language of conversation that we don’t have in Zoom, or Meet, or Teams, or Slack Huddles, or FaceTime, or any system  which lacks the analogue side channel of attention via stance.\nEven now in my memory it wasn’t a call, I visited Ross Atkin’s tabletop.\nPhones should have wheels?\nThat should be your takeaway.\nRELATED: MobiLimb is a realistic, articulated human finger attached to the back of your phone. It can prop your phone up, point, and allows your phone to autonomously haul itself around. As previously discussed.\nLook.\nIn the white heat of the pandemic we were teleported for a year to an alternate reality.\nHow would it have developed, had we continued in that world? Call this fiction pandemicpunk.\nHigh-performance pocket labyrinths from Nike for mindfulness and psychically rehearsing the grinding march.\nSmartphones that evolve as the exact opposite of augmented reality: instead of disappearing into our own bubbles we transport and teleport and inhabit the real world in whatever ways we can to compensate for endless lockdowns.\nSo our phones have skins of micro-wheel arrays for robotic motion, laser pointers and projectors, their own fingers, why not. Devices for telepresence in a world where presence has rare value.\nI want this even outside the pandemic ngl\n",
    link: "/home/2023/11/16/filtered",
  },
  {
    title: "A third one-off never-to-be-etc Acts Not Facts weeknote",
    date: "08.55, Tuesday 21 Nov 2023",
    content:
      "I wrote this yesterday. But then I got Covid and was too annoyed yesterday to post it.\nComing up this week\n\nPartyKit. Chipping away at two longer-running bits of work: one exploration and one around go-to-market. I need to figure out if there’s a spin-off hacked-together thing I can just put out there this week… shipping is a habit and I need to keep a regular cadence going otherwise everything feels bogged down (and that affects the lightness of thought).\nClient Who Shall Not Be Named. Got a bit feisty last week and speed-ran a version of the whole strategy directly into a draft deck. Not 100% wedded to the conclusions but now we have a something to populate and improve as a team.\n\nAlso for client (2) I’m doing a talk later this week on design and AI. Bashed out an outline while the kid was at ballet on Saturday.\nI’m going for pragmatic examples, and Show The Prompt. What’s wild about all these new AI Lego bricks is they’re all so straightforward, like a couple dozen lines of code. Combining them takes imagination! Making good AI applications requires designers to have good intuitions! So: a talk that helps build familiarity.\nMedia last week\nThe NEXT conference folks have published The AI/Human Interface: experiments in action, my conversation with Petr Parkan Janda about playful product invention and human-AI collaboration. (This is a write-up of the YouTube from a couple of weeks ago, and embeds that video.)\nAlso in my in-tray\nI am not in love with the title for this section, mainly because I don’t have an actual in-tray, and even if I did that is not how I organise my time. Will think about that.\nAI Clock. The reality of hardware is much of it is spent like this: I am in email conversations with a component manufacturer in Shenzhen, seeing if they can do the modifications that you want at a quantity that makes sense at the price you need.\nI’m glad I don’t have the requirement to deliver a Kickstarter hanging over my head while I’m doing this because it’s a position of great uncertainty. But I’m very fast approaching the last possible date to launch a campaign this side of Christmas, so that may be the disappointing consequence of this diligence of planning out manufacture, whichever way this particular negotiation goes.\nI don’t talk about calls and meetings so much. Some go somewhere, some don’t, it’s not very predictable. All are interesting.\nThere’s an area in physics called statistical mechanics. It’s not very useful to look at individual particles randomly bouncing around, mostly. But in aggregate there are tendencies that you can get at via statistics.\ne.g. temperature. Temperature is a bulk property, and it is an enormously concept to reason with. But it’s not a property that “exists” as belonging to any single atom.\nSo maybe there’s a way of thinking about the temperature of my calendar.\nOther bulk properties are pressure, density, refractive index, etc.\nWhat is the refractive index of my calls and meetings schedule? That kind of thing. I would like to have some kind of easy-to-assess indicator that all is well in the world of early-stage conversations.\nRn I’m happy with where it’s at.\nOk back to writing strategy and being ticked off about having Covid-19 or Covid-23 or Covid XP Professional Edition or whatever we’re on now. Working from home obv.\n",
    link: "/home/2023/11/21/weeknote",
  },
  {
    title: "It takes a while to figure out technology",
    date: "20.11, Friday 24 Nov 2023",
    content:
      "The first web pages and the first web browser, WorldWideWeb, were published December 1990. Mosaic launched in 1993 and became the first commercial web browser in 1994.\nI made my first e-commerce purchase in 1997 maybe 98. It was a crazy heavy resin gargoyle, mentioned here, and the way I bought it was I browsed the website and then sent an email saying what I wanted to buy and giving my credit card number.\n7 years in and it wasn’t obvious yet that you could type your credit card number in an input field.\nAmazon filed their 1-Click patent in September 1997. It was granted in 1999. Here it is: Method and system for placing a purchase order via a communications network\nThe idea is that you have previously put your credit card number in an input field. And then using a cookie, the website remembers who you are. Then you can hit Buy Now without having to re-enter your details.\nApple paid $1m to license 1-Click in 2000 (Wikipedia).\nLook, it was kinda obvious then, the people who sold me my gargoyle aside. The patent being granted was a little controversial. But as an idea it was not obvious obvious.\nEven being conservative about the timespan, from 1994 when the web became the most popular service on the internet, to 1997 when the patent was granted, that’s three years and still the idea of “putting your credit card number in a box and the server remembers it” was novel enough to allow for a patent.\nI was still buying software in a box off a shelf into the 2000s. Software was still a business with inventory; it was measured in terms of stock, not in terms of customer acquisition cost and retention. How long did it take for the web to replace boxed software with SaaS? 15 years? And we’re still figuring out the best ways to make a pricing page.\nAll I mean is that it takes a while to figure things out.\nWith the web, all the pieces were there from the early 90s.\nWe didn’t get Blogger.com till 1999. That’s when the idea of UGC - “user-generated content” - started going mainstream. Blogs themselves didn’t go mainstream till, what, 2001? 2004?\nOpenAI released GPT-3 in June 2020. That was good enough for chat. The interface wasn’t cracked until November 2022 when OpenAI released ChatGPT. 2 years!\nThe technique behind chat agents is called Retrieval-Augmented Generation, RAG. It was invented in May 2020 (arXiv). It’s a fundamental building block, dead simple: you concatenate the prompt with a relevant document retrieved from a database using vector search (which is surprisingly good). But it wasn’t well known until mid 2023.\nInventing takes time!\nI keep coming back to this tweet from Nat Friedman, ex CEO of GitHub and now deep into AI.\n\nThe multiple cantilevered AI overhangs:\n\n\nCompute overhang. We have much more compute than we are using. Scale can go much further.\n\n\nIdea overhang. There are many obvious research ideas and combinations of ideas that haven’t been tried in earnest yet.\n\n\nCapability overhang. Even if we stopped all research now, it would take ten years to digest the new capabilities into products that everyone uses.\n\n\n– Nat Friedman (@natfriedman), 4:42 PM - Mar 17, 2023\n\nAnd you know what, that tracks for me.\nSo I don’t feel I’m ever in a hurry with new technology. I’m not saying don’t do the work. Do the work like crazy.\nBecause we are imagination bottlenecked.\nShare techniques and ideas widely.\nDemo freely.\nGet the obvious ideas out of the way and together we’ll come up with the good ones.\nThis, by the way, is why London is such a great scene right now.\n",
    link: "/home/2023/11/24/digestion",
  },
  {
    title: "A fourth one-off never-to-be-etc Acts Not Facts weeknote",
    date: "12.01, Monday 27 Nov 2023",
    content:
      "Did a talk about design and AI; missed a self-imposed deadline.\nComing up this week\n\nPartyKit. Ship the new website, do some planning, finish the demo I’m working on that got eaten last week by Covid brain. And push along customer development: there’s a table in Notion now.\nClient who cannot be named. Share the strategy with leadership and nudge forward areas of interest. Doesn’t sound like a big deal. Is.\n\nCommon thread: spinning up processes.\nProcesses don’t exist except for artefacts (Notion tables and Trello boards) and habits (recurring meetings in Google Calendar). Also in the general intellect of the team.\nNone of these can be touched directly. So what you do is you speed-run portions to create muscle memory, nudge parts, and when something happens that is randomly in the right direction, amplify that by being noisy about it – organisational change by LARPing a Maxwell’s demon of workplace activity.\nOf course everyone else is doing the same. It’s a collaborative effort! I enjoy it.\nMedia last week\nNone.\nAlso going on\nSpent Sunday afternoon doing accounts.\nAI Clock. Got agreement on the changes I need to the core component . Prices for that will come back soon. “We will reply to you next week. :) Best regards.” Good good.\nAnother update, also last week, from another of the production partners: there’s strong confidence that the product can come in at budget.\nIt doesn’t matter either way. It’s Thanksgiving in the US which means I have missed my self-imposed deadline for launching the Kickstarter. It’ll have to be January now. Colour me disappointed but reconciled.\nThe internal talk on design and AI last week went well. Maybe. It’s hard to tell over zoom.\nAs my starting point I took the subtitle from Ted Nelson’s 1974 Computer Lib/Dream Machines: You can and must understand computers NOW.\nNelson coined the team hypertext and published Computer Lib just 6 years after Engelbert’s team’s demo of the first personal computer. What if computers could be used for creativity? said Nelson. So the book is a tumult of ideas but also explanations of what device peripherals are, and how shift registers work, and what code looks like, and so on. Demystifying.\nNeither is AI is a magical mystery.\nThe unspoken sense that maybe AI can do anything, and also therefore that there must be unapproachable complexity, gets in the way of building and imagining with it.\nSo my goal was to demystify large language models. The basics rather than, whoa AI isn’t it amazing.\nDemystifying by example:\n\nShowing my side project Braggoscope and how it uses AI to do data extraction (cutting about 4 days work down to 20 minutes)… then showing the short prompt that makes that work.\nShowing Braggoscope semantic search, which is surprisingly good: there’s a GIF here in the GitHub repo. It works using embeddings, so I showed what a vector looks like then talked through Amelia Wattenberger’s concrete/abstract text editor from Getting creative with embeddings\nStarting from a toy example that combines these basic Lego bricks, I moved onto Retrieval-Augmented Generation (RAG) (Meta machine learning blog, 2020) and how this technique is ultimately also a simple combination of basic parts, and it underpins all AI chat assistants\nLooking at user experience examples: the smart code autocomplete in GitHub Copilot and the prompt-steerable menu commands in Replit AI are both chat assistants that don’t look like chat. They have better affordances than an empty chat window. What other UX leaps can we make?\nHere’s one. Rupert Manfredi’s LangView (here’s a video on X/Twitter and here’s the code from Mozilla): Manfredi shows that it is possible for the AI to output data, and have that hydrate a list component, or map component, or any other UI component that has been carefully designed with human hands. The best of both worlds. (We looked at the prompt - it’s clever and, yet again, short.)\nFinally, Make Real by whiteboard app tldraw: turn sketches into working websites by hitting a button and prompting the GPT-4 Vision API to do the work. You have to check out all of these Make Real demos (tldraw Substack). Again, we can look at the prompt – it’s dead simple.\n\nThe Make Real prompt is pretty hilarious:\n\nYou are an expert web developer who specializes in building working website prototypes from low-fidelity wireframes.\nYour job is to accept low-fidelity wireframes, then create a working prototype using HTML, CSS, and JavaScript, and finally send back the results.\nThe results should be a single HTML file.\n…\nYou love your designers and want them to be happy. Incorporating their feedback and notes and producing working websites makes them happy.\nWhen sent new wireframes, respond ONLY with the contents of the html file.\n\nIn the AI world we call that alignment lol.\nSo that was my part of the talk.\nThe next step from showing examples is to get your hands dirty.\nRolling your sleeves up is really the only way to build good intuitions.\nWe didn’t make it all the way to hands-on in the session, but one colleague did an amazing bit about the value of sketching and other design artefacts, and then another colleague ran a deft mini-workshop to sketch up AI ideas. With some great output!\nIt is daunting maybe, for non-engineers, to unpack AI like this.\nBut as designers and product people we all have a pretty good working understanding of, say, what can be done with HTML, or how apps work. The same level of understanding is needed for large language models and generative AI generally: not how it works under the hood, but a familiarity with the material, what you can and can’t do with it at scale, and how to combine different techniques.\nSo daunting but necessary.\n",
    link: "/home/2023/11/27/weeknote",
  },
  {
    title: "On having recently had Covid and other modern freedoms",
    date: "09.01, Thursday 30 Nov 2023",
    content:
      "I’ve been on a few packed trains the last few days. I was in a crowded, not well ventilated ballet studio. Shoulder-to-shoulder at an event last night.\nHowever I am swimming in Covid antibodies, having recovered just last week, and they’re bang up to date antibodies too, the latest version, fresh off the line.\nI’m on a train right now. Somebody just coughed, right behind me. Who cares. Who cares!\nThe sense of invulnerability is giddying. Well that might be residual vertigo, which is my body’s go-to Covid symptom, but let’s put it down to freedom.\nAnd a type of freedom I didn’t notice before all of this! A new everyday freedom for me to enjoy.\nHere’s another new freedom: taking old-fashioned cabs.\nI got a black cab home a while back and the feeling of it being Not An Uber was tangible.\nI lounged in the back seat, unjudged. No fear that my conversational patter would be adjudicated to being not up to scratch, with the driver’s rating dinging my score and making it harder to me to hail future Ubers.\nI said nothing and enjoyed looking out of the window at nighttime London passing by. Home, I almost certainly said thank you (I don’t remember precisely) but it was from respectful gratitude, not from monitored, gamified fear.\nSo as the world changes, these new potential freedoms pop into existence.\nIt’s fun to recognise them.\nAnother! Energy freedom. A weird side-effect of our climate change response.\nI ran across the following one while looking into solar-powered websites: What I have to say about carbon accounting in web browsers will shock you (2022).\nQuoting Clive Thompson, as linked in that post, who installed renewables for his home:\n\nI’ve stopped worrying about electricity use, both economically and ethically.\nI no longer walk around finger-wagging at my family members. Want to blast the AC? Crank away. It’s coming from the sun, and I can’t use all that electricity even if I try.\n\nI haven’t had the pleasure of that one yet.\nThen there are tech-related modern freedoms.\nThe freedom of being on a plane and having no phone and no wi-fi – blissful escape! That one has eroded now. Just knowing you could spring for the fee and get connectivity brings back the trace guilt. Boooo.\nBut!\nLuckily our interconnected internet means that when some major infra has a wobble, like Cloudflare goes down, or AWS - happy days! - then you can’t get on workplace chat, and all your cloud-based work apps are down, so you can’t be productive.\nAlways great when that happens.\nEven better when GitHub Copilot is down and I can’t code, or ChatGPT falls over and your IQ is dinged 20 points. It’s like, sorry, I’m now simply too dumb to work. Uh-oh.\nEveryone understands, we’re all in the same boat, there’s nothing to be done, relax.\nInfrastructure instability also means, I am sure, team upon frantic team of engineers on pager duty running around in the middle of the night, costing providers millions as they lose their SLA bonuses, plus there’s the productivity loss to the global economy, etc.\nBut also, that sweet taste of a new kind of freedom, right? Cloud downtime = snow day for grown-ups.\n",
    link: "/home/2023/11/30/freedom",
  },
  {
    title: "Acts Not Facts weeknote #5: Always report null results",
    date: "09.45, Monday 4 Dec 2023",
    content:
      "This is a tricky week to write up because… there’s nothing unusual going on?\nIn the experiment of weeknotes, this test that there is always something interesting to say, this counts as a null result.\nProject #1 shipped a website.\nProject #2 nailed a strategy.\nI got my hands dirty building after a few weeks not doing that and I am reminded how much energy it brings.\nI went to a drinks event and talked to one person who works on machine learning infra in cell biology and life extension and someone else who works on the underlying algorithms for petascale databases. We put bets on when we would see AI sentience for the first time (upper bound: less than 1,000 years. Lower bound: 1-5 years).\nThere are four early projects I need to develop and I am behind on all of them. I have a list.\nThe work to deliberately build the London scenius is our conspiracy.\nIn the spirit of transparency:\nI am painfully aware that, when I write a post on my blog, it ends up in a thousand inboxes. And so there is pressure not to be dull. And this null result is dull? Like, nothing happened!\nHOWEVER.\n\nWe should love null results because they are our stepping stones to positive results, and although we might get lucky sometimes, we can’t just decide to skip that queue.\n\nAlways report null results.\n",
    link: "/home/2023/12/04/weeknote",
  },
  {
    title:
      "The subjective experience of coding in different programming languages",
    date: "17.22, Tuesday 5 Dec 2023",
    content:
      "Different programming languages feel viscerally different, right? I can’t be the only one. It’s so embodied.\nWhen I’m deep in multiple nested parentheses in a C-like language, even Python, I feel precarious, like I’m walking a high wire or balancing things in my hands and picking my way down steep stairs. It’s a relief to close the braces.\nLike if I’m trying to cover all the conditions in a complicated state machine or a conditional, I’m high up. I often hold my breath.\nFunctional languages are the opposite.\nI haven’t done much Haskell but what I did felt like crawling underground through caves and tunnels. Writing a text adventure game engine felt similar. Like I was making a map in the dark, kinda, and having to hold it in my head.\nWhen I’ve written firmware, counting ops in the interrupt, it was precision work while being squeezed. To be typed with first fingers only, deliberately.\nWhen I’m ssh’d into a device on my shelf and I’m writing code actually on the board, my sense of self is teleported over there and also I’m really really small. Opening a terminal window to a distant server is like reaching through a hatch with my arm, but a long way; ssh tunnel is well named.\nWriting code with GitHub Copilot and Typescript in full flight feels like, well, flying, or at least great bounding leaps like being on the Moon. Coming back to typeless Python after writing Typescript is like stumbling drunk. It makes me feel unreliable but also hilariously giddy.\nI feel tense and unsteady if I venture too far over my skis from a git commit.\nIs code synesthesia a thing? If so mine is visceral, kinaesthetic.\nLook, this isn’t the strongest synesthesia in the world. Oliver Sacks wouldn’t have written a book about it. It’s faint. But it’s present, that connections between code and embodiment. And at least some forms of it are common, right?\nWhen I’ve been underwater in code all day it takes time to return to the surface. But also, halfway in a function even briefly, it takes a while to get my head up if anyone asks me a question. It’s confusing if it’s too abrupt. The bends.\nAnd that experience I know is shared! The annoyance at sudden context switching I mean. You need a minute to move your mental stack somewhere safe.\nBut the overall synesthesia? I have no idea. I assume that most people have some form of it? As unfounded as that is.\nDoes it help?\nHa, no.\nI mean, I doubt it helps. The best physicist I knew during undergrad told me he saw equations in colour. He was brilliant. I feel claustrophobic in a while loop if I haven’t typed a break yet. But I’m a midwit engineer. So from my n=2 study there’s no correlation.\nThen again: when I’m interviewing a founder or reviewing a pitch deck or otherwise working to understand how a startup works, the system hangs together like a clockwork or a loop of flows, and I feel like my ability to zero in on the critical part or recognise missing connections comes from a visceral sensation of the cogs clashing or the circuit not closing or the engine cycle not turning. I rely on that sense of rightness. And that systems understanding sense is a very embodied sense for me, in proxemics terms it sits in my “intimate” perimeter, right up close with my eyes and hands, and I don’t think I could do that kind of work without it.\nMaybe really great engineers have a totally different way of seeing code, in the same way that great chess players feel patterns and potential fields on the board?\nMaybe the design of my code editor should learn from great engineers and amplify whatever synesthetic intuitions they might have: inner loops should appear crisper on the screen; editing compound conditionals should wobble just enough to make you seasick.\nAre there any studies of the subjective experience of programming?\nI’d love to read some.\n",
    link: "/home/2023/12/05/code",
  },
  {
    title: "A framework for exploring AI as a tech savvy org",
    date: "09.40, Friday 8 Dec 2023",
    content:
      "Today, a post from my day job.\nBack in May I was invited to speak about large language models at the board strategy day of the BMJ.\nThe BMJ publishes the British Medical Journal and 60+ other scientific journals, together with a number of technology products in the health sector. As an organisation, they’re a few hundred people.\nSo this is a fascinating and actually pretty common organisation profile. Mid sized, technical but not a pure technology company. And they’re asking themselves, will AI impact us? If so, how should we respond?\nAs it turns out, it was obvious even in May that generative AI would matter to the BMJ, and the session I was part of - run by CTO Ian Mulvany - was about the second part of the question: what’s the strategy.\nMy part of the session ended with an approach I call strategic pathfinding. A high-level framework really.\nI caught up with Ian (his homepage) last week. The approach, it turns out, holds up. So with his permission, I’m sharing it here.\nStrategic pathfinding in a capability overhang\nSee the framework: the slide is on the project page at Acts Not Facts.\nShould you wait and see? Or jump in? I’d privately polled a number of other companies about their strategies and heard the entire spread, from a blanket ban on using generative AI, to commissioning a 3rd party consultancy to attempt to replicate team workflows using large language models.\nMy point of view is that\n\nwe’re in a capability overhang – the AI tech that already exists has huge potential impact, whether you engage or not, so get ahead by exploring\nthe appropriate approach is pathfinding which uses experiments to learn and, critically, artefacts to tell the organisation what to do next.\n\nThe framework breaks down the different activities of pathfinding.\n1. Search for value systematically\nThere will be opportunities across the whole business, from ops to the product suite.\nDon’t just build the first, most obvious gen-AI prototype, but engage with every team and department to surface ways to save time, reach new audiences, or provide new services.\nRun this as an ongoing and highly collaborative process.\nDocument and disseminate what you build and what you learn: the pathfinding approach is not about learning for an isolated and small AI team, but making the entire organisation more capable.\nBe guided by the overall strategy not by AI itself. The potential of the technology is too unbounded, but you may find within it new ways of reaching your goals.\n2. Build internal knowledge and spark the imagination\nOne of the challenges is recognising opportunities: most organisations have two decades of digital knowledge telling them what’s easy and what’s hard. A lot of that no longer applies. And AI is seen as magical, or mysterious, or a threat.\nMaintain a practice of sharing external examples and quick prototypes built with AI tools. This will lift general knowledge and demystify. Share null results too: it’s important to know what what AI can’t do.\n3. Red teaming\nRed teaming is the process of actively understanding threats, as in the famous GPT-4 System Card (as previously discussed) which showed how OpenAI’s latest large language model could be used for dangerous outcomes.\nIn this context we want to document AI-related threats very broadly,\n\nfrom: increased imposter calls to contact centres, targeting PII\nto: how will the website get traffic when a user’s point of first intent has switched from Google to ChatGPT?\n\n(Thinking about how to deal with threats may also reveal opportunities.)\nOn the second point: even if you’re not planning to use AI right now, your customers are.\n4. Build capabilities to make invention cheaper\nExperimenting needs a quick cycle time. Along the way, identify and build new enabling capabilities to:\n\nmake future experiments easier\nallow for pilots with future AI-related suppliers.\n\n(For example, LLMs and computer vision mean that there is a lot of data that didn’t previously look like data. That index needs a new internal API.)\n5. Understand needs by sharing both internally and with partners\nPrototypes and experiments do not need to be taken to production. In a build vs buy discussion, for an organisation whose core competence is elsewhere, you shouldn’t be building foundational tech.\nBut how will you identify value when it arrives? There will be hundreds of well-funded startups and dozens of consultancies with deep-pockets and impressive AI demos, all knocking at the door.\nRunning experiments means you’re understanding your own requirements – which means you’ll spot the valuable suppliers and can ask smart questions.\nI’d go further: be open and noisy about your experiments,* and suppliers will pre-emptively change their roadmaps, come to you, and let you in before their work is public. And there’s a competitive advantage to being first.\n6. Governance – a bonus point not on the slide\nAI tools are getting available fast. Whether or not you have a centralised AI approach, individual team members will be using AI to create job descriptions, summarise documents and emails, make illustrations, write code, and so on.\nWhen I talked recently with Ian, he told me about the BMJ’s AI governance approach. This allows for permissionless innovation with AI in workflows for everyone in the organisation, by providing simple guidelines describing\n\nwhen it’s ok to use AI tools\nwhen to absolutely not\nwhen to be cautious (and who to escalate the question to)\n\nThese guidelines will differ for every org. I found it really smart for the BMJ to be engaging in the benefits and risks of AI tools like this, and engaging with the reality that yes, people are already picking them up to help do their jobs.\nOf course it’s easier to talk about strategy than to do it.\nThe reality of strategic pathfinding for AI is that it comes down to\n\nreal people and objectives\nmeetings, workshops, slide decks, and Trello boards, alongside often more urgent work\nfiguring out new, ongoing processes\nultimately, rolling your sleeves up and doing the work.\n\n…all of which will become very tactical and very specific to your org as soon as you start, and will evolve fast.\nBut it’s worth it. So just get started because you’ll figure it out faster doing than thinking.\nMy hope is that this framework provides a useful starting point.\n",
    link: "/home/2023/12/08/ai-pathfinding",
  },
  {
    title: "Acts Not Facts weeknote #6",
    date: "09.56, Monday 11 Dec 2023",
    content:
      "Monday. My first unaccounted-for day in weeks. Phew. I’m going to the British Library where I’m going to hang out and sketch in one of the science reading rooms for old time’s sake. Maybe spelunk the shelves for interesting journals, c.f. that time I read every issue of Electrical Review magazine from the 1880s and 1890s.\nShelves only. Can’t get anything from the stacks, it turns out the BL was knocked over in a cyber attack last Friday and the systems are still down.\nI had an epiphany last week about what I want Acts Not Facts to become so that’s what I want to sketch about.\nPartyKit. After wrapping the new brand and site Mark Hurrell designed a polyrhythmic drum machine.\nSo I built it, and you can play here: partycore – 3 track natively multiplayer looping step sequencer, always 140bpm. It’s fun.\nThe PartyKit blog has all the gory technical details.\nIt’s my first time doing audio in the browser (I used Tone.js, neat to have another tool in the toolbox). And intriguing to think about the layers of multiplayer interaction: the steps in the drum machine are synced in near realtime, but the loops play independently for every user.\nClient Who Cannot Be Named can possibly be named this week sometime, comms grids willing. I’m a way downstream of a different announcement.\nFocus of both this week is product invention + AI. No strategy.\nI’m tapping this with my thumbs on the crowded train and a tiny spider just swam horizontally past my head, an inch from my eyes, apparently on a thread too delicate to be seen.\n",
    link: "/home/2023/12/11/weeknote",
  },
  {
    title: "Tick-tock is a both chip architecture and a corporate strategy",
    date: "18.27, Friday 15 Dec 2023",
    content:
      "The breakthrough with computers, as opposed to tabulators, is that they are not hard-wired to follow a single set process. Instead they follow instructions and the instructions are recorded as just more data.\nGeneral purpose computing is a convention in the CPU which is so ancient that it is architecture. Every chip has at its heart a metronome, the clock. Every tick, the chip processes a new number. The convention is the von Neumann architecture which says that these numbers are interpreted differently, first data and then instructions, and repeat.\n(Von Neumann was the canonical 20th century scientific super-genius behind computers, nuclear war, and interstellar self-replicating probes.)\n\nAll the instructions are executed according to a timing scheme based on the ticking of a built-in clock. The “instruction” cycles and “execution” cycles alternate: On “tick,” the machine’s control unit interprets numbers brought to it as instructions, and prepares to execute the operations specified by the instructions on “tock,” when the “execution” cycle begins and the control unit interprets input as data to operate”\n– Howard Rheingold, Tools for Thought (1985)\n\nTick tock.\nOk and so famously Intel, the greatest computer chip company of them all, had its tick tock corporate strategy:\n\nUnder this model, every microarchitecture change (tock) was followed by a die shrink of the process technology (tick).\n\nGreat strategy is 50% something that is effective in the market.\nAnd 50% something that creates alignment for the tens of thousands of people who are being asked to follow it.\nDid tick-tock resonate so well for Intel because it rhymed with the von Neumann architecture at the heart of their work, the stuff they had their collective hands dirty with every day?\nI’m sure of it.\nBack when digital was new, I was at the BBC. One of the struggles was to get the organisation to think of “digital” (i.e. websites) as something ongoing. Something iterative. The default mental model was “TX”: transmission.\nAs an org the beeb often seemed chaotic. Yet there is never dead air on the radio or on TV. Everyone knew how to hustle around the moment of transmission.\nSo websites, at the time, would be talked about in terms of TX. Which wasn’t helpful. It will have changed in the two decades since.\nI remember hearing that GitHub, once upon a time, allowed engineers to self-prioritise on whatever projects - which matches the grain of the underlying git protocol and git culture itself. Google, when I’ve encountered it, has always reminded me of a microcosm of the heady, churning web ecosystem. For better and worse.\nAt scale strategy is culture. Culture transmits most effectively along the magnetic field lines of familiarity. The iron filings of individual behaviour bend to the field but they also create the field.\nSo I think that corporations come to resemble their material in the same way that dog owners come to resemble their dogs. For some companies, by luck or design, this also aligns with success.\n",
    link: "/home/2023/12/15/tick-tock",
  },
  {
    title: "Acts Not Facts weeknote #7",
    date: "14.58, Monday 18 Dec 2023",
    content:
      "I caught myself in a tetchy mood one day last week. Then: shipped something. Immediately felt better.\nLast week:\nPartyKit.\nI shipped Cursor Party last week. If you’re a web creator, you can copy this project and get multiplayer cursors on your website inside a minute or two. There are full instructions. Here’s the Cursor Party writeup on the PartyKit blog.\nIt’s live on this blog too! Try opening two browser windows to this post and seeing your own cursor.\nI added a couple extra easter eggs:\n\ncursor chat. Type / and you can message anyone else on the page\nshared text selections! I built a prototype of this over two years ago (Social Attention (2021)) and it’s awesome to have it working for real. You’ll need a recent version of Chrome or the version of Safari that came out last week.\n\nI love playing with ambient togetherness on the web like this.\nHere’s my forked version of Cursor Party. lmk if you build websites and you want a hand getting up and running with this, happy to help. Or have ideas for other modules to create.\nClient Who Cannot Be Named still cannot be named. Boo. On the flip side, the strategy is now baked into team OKRs. That means it’ll happen. We’re talking about a next phase of that project – excellent.\nComing up this week:\nI want to ship more code. Let’s see.\nIt is insane how itchy and irritable I get when there is something I want to get out in the world, and it is just inches away from getting there. I always forget.\nIt’s like… when something is out, whether it’s a public demo or better in people hands, it can stop living in my head and start being material that I work with to make the next thing.\n(This goes for things I’m making with my own hands or making with other people.)\nAnd when I’m carrying something half-complete in my imagination… it’s a weight, it’s a drag.\nSpeaking of which, my AI Clock.\nGood progress on several fronts: the production cost is (almost) on budget and confirmed. We’ve been able to reduce the minimum order quantity to 1,000. I am working with the amazing Tom Armitage to build the firmware for the production board.\nKickstarter in January, exact date TBC. I have lots to do ahead of that.\nSF in February.\nA date for your diary – I literally just booked a week in/around San Francisco, 4 Feb till 11 Feb 2024.\nLmk if you can sneak me in anywhere to see cool and unlikely things.\nOr would be interested in a talk.\nAlso. I need to stretch my legs and see the horizon. What are the best day hikes in February within a few hours drive of the city?\n",
    link: "/home/2023/12/18/weeknote",
  },
  {
    title: "My most popular posts in 2023 and other lists",
    date: "16.49, Friday 22 Dec 2023",
    content:
      "Hello! This is a both my summary of 2023 and also the “Start here” for new readers. Lots of links and stats below!\nAccording to Google Analytics, my 5 most popular posts in 2023 were (in descending order):\n\nThe surprising ease and effectiveness of AI in a loop (16 Mar)\nWhy you should watch Big’s Backyard Ultra, which starts tomorrow (20 Oct)\nNew thing! Browse the BBC In Our Time archive by Dewey decimal code (7 Feb)\nComputers that live two seconds in the future (9 June)\nThe map room is a physical room-size wiki for collaboration from the 1950s (20 June)\n\nHere are some more! 20 most popular in 2023.\nBlimey there’s a lot of AI in there.\nThis year my blog has really reflected my work, that’s why. I decided to double-down on AI at the beginning of the year.\nBut still. Hopefully the angles here are angles you’re not getting so much elsewhere.\nTwo things that I made outside client work!\n\nBraggoscope. That post in the top 5 on the In Our Time archive is about braggoscope.com – check it out! I still use that site more than weekly to discover new episodes. (The post sat in the #1 spot at Hacker News for about 12 hours because braggoscope.com uses AI behind the scenes, and was one of the first to do so in that fashion. Here’s the thread.)\nAI Clock. Also in the 20 most popular, My new job is AI sommelier and I detect the bouquet of progress (22 Mar). That’s about ChatGPT vibes and also my AI poetry clock prototype that went viral on Twitter. I’m currently in the process of manufacturing the clock; Kickstarter in the new year. Subscribe here for updates. \n\nI’m proud of both.\nAnd here are some “work-shaped” longer essays that got a decent amount of attention:\n\nProtocol Fiction, Desire, and Belief (19 May)\nA framework for exploring AI as a tech savvy org (12 Dec)\n\nThere’s one “big idea” (small idea…) that I feel will carry me through 2024 and that’s ubigpt or Intelligence too cheap to meter (6 Oct).\nMy personal faves often aren’t always the most popular. I’ve collected my favourite, most speculative posts, on topics such as:\n\nInterspecies communication\nExcalibur as nanotech\nFinally getting the joke about infinite monkeys\nEating the Sun\nThe true meaning of Groundhog Day\n\nAlso: hip-hop ovens which culminates with honestly the single best pun I will ever produce.\nExplore here: 16 speculative posts in 2023.\nThis year the posts I enjoyed the most are in my Filtered for… series. Each collects a handful of links and then… draws a kind of line I guess?\nThe free association is a ton of fun.\nIn 2023 you’ll find posts such as:\n\nFiltered for ants and laws (17 Jan) about magic, trading with ants, and corporate insecthood.\nFiltered for causes and kissing (3 Mar) on the Year Without a Summer and remote kissing\nFiltered for formation (15 Sep) covers the speed of time in fiction and the astounding origin of flint\n\nHere’s the whole Filtered for… series (104 posts since 2014). Scroll down for the ones from 2023.\nPREVIOUSLY!\n\nMy most popular posts in 2020 and other lists\nMy most popular posts in 2021 and other lists\nMy most popular posts in 2022 and other lists\n\nOther ways to read:\nIf you’d like to subscribe (for the princely sum of zero $)…\n\nSign up to receive new posts as an email newsletter.\nSubscribe to the RSS feed using your newsreader. You should totally use RSS. Learn about what it is and how to get started.\n\nI love my posts being shared. So if you read something you like, please do pass it along and post on whatever discords or socials you’re on.\nI like email replies. This year people have started sending me links they think I’ll enjoy, and they’ve all been 100% correct. It is excellent that my preferences are so straightforward for others to model.\nI like talking to people even more. I started opening my calendar for Unoffice Hours about 3 years and 300 calls ago and it’s still the highlight of my week. Learn more and book a time here. (I plan to change up the times in 2024 to make it easier to speak to people in the US.)\nSome stats for the stats fans.\n\n2019: 8 posts (7,267 words, 78 links)\n2020: 116 posts (94,349 words, 713 links)\n2021: 128 posts (103,460 words, 765 links)\n2022: 96 posts (104,645 words, 711 links)\n2023, to year end: 68 posts (69,058 words, 587 links)\n\nMy current streak: I’ve been posting weekly or more for 195 weeks. (That’s my longest streak since I started blogging here in February 2000. Blew through that record over the summer.)\nI’ve shifted focus with my personal practice this year – more making. I’m finding real joy in designing and making. My spare cycles go into spitballing ideas of things to try building in my private notes, and breaking ground on those ideas whenever I have a minute.\nBut I can see that reflected here… fewer speculative posts, average post length is up. And truthfully I would kinda like to find a way back to those shorter, freer thoughts. I get a lot of energy from them.\nAnyway.\nI love writing here. And thank YOU. I appreciate you being here, dear reader.\nUpdate 12 Jan, 2024: Finalised 2023 stats, above.\n",
    link: "/home/2023/12/22/top-posts",
  },
  {
    title: "Some books I enjoyed in 2023",
    date: "10.53, Thursday 28 Dec 2023",
    content:
      "The books I enjoyed most over the year:\n\nRainbows End, Vernor Vinge (16 Apr)\nThe Cyberiad: Fables for the Cybernetic Age, Stanislaw Lem (31 May)\nI Am the Law: How Judge Dredd Predicted Our Future, Michael Molcher (16 Jul)\nAlmost Perfect: How a Bunch of Regular Guys Built WordPerfect Corporation, W E Pete Peterson (3 Aug)\nSleep and the Soul, Greg Egan (26 Aug)\nGenius: The Life and Science of Richard Feynman, James Gleick (27 Sep)\nBabel-17, Samuel Delany (8 Oct)\nThe Discarded Image, C S Lewis (24 Oct)\nThe Fall Revolution series: The Star Fraction, The Stone Canal, The Cassini Division and The Sky Road, Ken Macleod (10 Dec)\n\nSci-fi re-reads\nRainbows End felt like near future in 2006 and it feels like a parallel timeline now: it’s set in a perfectly realised world of pervasive augmented reality and virtual reality… “ubicomp.” Pick up Vinge’s same universe short story Fast Times at Fairmont High to add 3d printers and drone delivery. Great stuff.\nThe Cyberiad (1965, translated 1974) is so funny, so witty, so effervescent. Here’s a taster, hosted by gwern, in which the constructor Trurl creates a cybernetic muse and Klapaucius challenges it to write poetry: The First Sally. (The poem about a haircut is just perfect.)\nBabel-17 (1966), as previously mentioned: linguistics sci-fi. Delaney is so deft. I love this every time I pick it up.\nGenius (1994) is a wonderfully readable biog of Richard Feynman, birth to death, that immerses in the subject matter and doesn’t get bamboozled by Feynman’s self-mythologising. Now, Feynman was a physicist at a time when modern physics was being invented; Gleick goes deep on the physics too. That’s what you want! This isn’t just a character study! More than that, Gleick is in utter control of his craft and it is a joy to simply be present: the tempo rises and falls without being contrived; his turns of phrase are spot on. There’s an extended diversion on the matter of genius about halfway through that had me gripped. \nA couple books that shifted my worldview\nI picked up I Am the Law (2023) because I was into Judge Dredd when I was a kid. There’s a bunch of stuff from the comics, sure. Mainly this is an utter evisceration of policing. By the end I was asking myself: for the problems that the institution of “the police” is intended to solve, surely there are other approaches that would work better? And even if this is the best approach, why is the current setup so prone to awful error? That’s where this UK-focused, heavy-on-the-evidence book takes you. What once had the weight of naturalness now feels so very contingent.\nThe Discarded Image (1964) is C S Lewis’ non-fiction overview of the Medieval cosmology, the “Model” as Lewis calls it. Outline on Wikipedia.\nI have dogeared oh so many pages! It is incredible to inhabit, even just a tiny bit, this way of seeing. If Earth is the centre and “down” then the Medieval Model is vertiginous. The stars have height! The fairies! The reliance on old books! The senses! The vegetable soul!\nAnyway, the introduction is about how it is important to know your literary references, and Lewis is hilariously punchy with it:\n\nThere are, I know, those who prefer not to go beyond the impression, however accidental, which an old work makes on a mind that brings to it a purely modern sensibility and modern conceptions; just as there are travellers who carry their resolute Englishry with them all over the Continent, mix only with other English tourists, enjoy all they see for its ‘quaintness’, and have no wish to realise what those ways of life, those churches, those vineyards, mean to the natives. They have their reward. I have no quarrel with people who approach the past in that spirit. I hope they will pick none with me. But I was writing for the other sort.\n\nThank you Robin Sloan for the recommendation. Sloan has been reading C S Lewis and others in preparation for his upcoming novel Moonbound. That’s the mini-site. Can’t wait.\n",
    link: "/home/2023/12/28/books",
  },
  {
    title: "10 blogs for your newsreader",
    date: "12.24, Friday 29 Dec 2023",
    content:
      "Yo big fan of reading blogs through feeds right here.\nAll told I subscribe to 425 blogs and newsletters using RSS feeds and a newsreader app.\nIt’s not algorithmic. You see what you subscribe to (it’s free). If you don’t enjoy a blog anymore, you unsubscribe. It’s anonymous. And it gets you off Twitter.\nHey if you want to try out using RSS then I wrote an explainer site about what it is and how to get started: About Feeds.\nHere’s my setup:\n\nI have NetNewsWire on my iPhone and my Mac. It’s my favourite newsreader app – dead simple to use, no fuss reading experience. It holds all my subscriptions\nTo sync read/unread posts between my phone and my Mac, I could use NetNewsWire’s built-in sync service. But instead I pay $5/month to Feedbin. Reason being: Feedbin gives me a secret email address, and I have rules in Gmail to forward newsletters to it. That way newsletters appear in my newsreader instead of my email inbox.\n\n(Tip: You don’t need to auto-forward Substack email newsletters. Instead add /feed to the end of the Substack URL and you can get the hidden RSS feed.)\nI don’t read every single post that goes by. You get a list of everything that’s new day and just kinda check in.\nThat said, with some sites I do make a point of reading every post.\nSo if your New Year’s resolution is to start reading with RSS instead of doomscrolling social media, here are 10 such feeds to start populating your new newsreader.\n(When you click “RSS feed” you’ll probably see some weird text or the browser will ask you which app to use. Install NetNewsWire or another newsreader and the link will open directly in that.)\nBits About Money by Patrick McKenzie, the intersection of tech, financial infrastructure, and systems thinking. RSS feed.\nI went back and read the entire back catalogue for this one. You will be smarter about how the world works. I found this 2022 piece about how standard accounting practice and “gems” in free-to-play games fascinating.\nCentauri Dreams by Paul Gilster, peer-reviewed research on deep space exploration, with an eye toward interstellar possibilities. RSS feed.\nFeminist Friday by Alex Mitchell: A manageable number of links (2-3), about or around women and feminism, every Friday. Leans towards culture and history. RSS feed.\nFeminist Friday has just moved, so go spelunking the full archive over here. It’s amazing – you’ll get a mix of links and then these occasional, original deep dives into cultural history, e.g. is it true that “blue for a boy, pink for a girl” used to be the other way around? In episode 375, Alex brings references. Sadly after almost 10 years, Alex is wrapping up in September 2024. So get it while you can.\nHalfman aka Jim Kosem, design criticism to skateboarding, socio-political pontification, historical absurdism, cultural analysis to rock and roll all in the one place. RSS feed.\nI met some people in a pub over the summer and we spent literally 20 minutes bonding over how absolutely electric Jim Kosem’s newsletter is.\nMaggie Appleton: visual essays about programming, design, and anthropology. RSS feed.\nSo smart.\nMarginal Revolution by Tyler Cowen and Alex Tabarrok, the best or one of the best economic blogs on the web. RSS feed.\nMarginal Revolution is pretty high traffic but Cowen has very broad interests beyond economics.\nOne Useful Thing by Prof Ethan Mollick. Translating academic research into mostly useful insights, with some ephemera on the side. Mostly AI stuff recently. RSS feed.\nMollick always has the most grounded yet optimistic takes about AI, and is often also the earliest. Get started with this post about how AI will reshape work which is a breakdown of original research into how management consultants use ChatGPT etc and whether it actually improves their output.\nRobin Sloan: books and media and modern life, and I always try to make it feel like a note from a friend. RSS feed for updates – but for the full experience subscribe to the newsletters.\nWhat you’ll get is Sloan’s interests and early research for his next novel, which could be anything. He’s typically a few years ahead of the game, e.g. he built his own AI writing companion and reflected on how it felt back in 2016.\nTarget_is_new by Iskander Smit: an exploration in the new. RSS feed. Lots of robots, lots of AI. Links and good takes.\nWeb Curios by Matt Muir: a weekly roundup of: digital arts, online culture, web design and creativity, philosophy, economics, sex, art, death, drugs, music, animation, literary fiction, comedy, nihilism, advertising, marketing, pornography, rights, AI, identity, PR, and the crippling horror of being made of meat. RSS feed.\nIt’s long and will take you 30 minutes to read every Friday but there isn’t a better place to get the latest weird, excellent web stuff than Web Curios.\nWant more? Check out ooh.directory which is a good place to find new stuff to subscribe to: a collection of 2,112 blogs about every topic.\nI’d love to see some other RSS starter packs. Lmk.\n",
    link: "/home/2023/12/29/recommendations",
  },
  {
    title: "Superheroes create cultural acceptance for popular oligarchy",
    date: "11.00, Monday 3 Jan 2022",
    content:
      "I wonder whether the worldview from the 1930s has been transmitted via superheroes through time, and has been re-imprinted onto today’s culture.\nWhen Batman was created in 1939 the name will have had a double meaning: batman is a military role, a soldier assigned to be an aide to an officer, with roles including:\n\nmaintaining the officer’s uniform and personal equipment as a valet\ndigging the officer’s foxhole in combat, giving the officer time to direct his unit\nother miscellaneous tasks the officer does not have time or inclination to do, etc (list from Wikipedia).\n\nUse Google Books to search for “batman”: the term hits a peak in the early 1930s (before the comic book character) and doesn’t climb to the same level of popularity again till 2004.\nSo Batman is a pun.\nI can only imagine that readers would have been aware of this. Batman-the-hero is working in the dark, doing the dirty work for Gotham, cleaning it up, just as batman-the-wartime-aide would be up before dawn getting things ready, dispensing of tasks before the officer wakes, doing the running behind the scenes.\nBatman as servant to the city.\nEven if this wasn’t explicit the semiotics are unavoidable – but will have changed over time. I wonder how the depiction of Batman evolved, in the comic, once a new generation of writers took the helm and the military term “batman” lost its wartime currency. Did the servant aspect disappear? Or is it still there under the surface?\nOTHER SUPERHERO ORIGINS:\nAlan Moore (writer of Watchmen, V for Vendetta, etc) makes the connection between comic book superheroes and fascism.\nFrom this 2017 interview:\n\nWhile these characters were originally perfectly suited to stimulating the imaginations of their twelve or thirteen year-old audience, today’s franchised ubermenschen, aimed at a supposedly adult audience, seem to be serving some kind of different function, and fulfilling different needs. Primarily, mass-market superhero movies seem to be abetting an audience who do not wish to relinquish their grip on (a) their relatively reassuring childhoods, or (b) the relatively reassuring 20th century.\n\nNietzsche’s concept of the Ubermensch (1883) - translated: “superman” - became a Nazi ideal.\nMoore continues:\n\nI would also remark that save for a smattering of non-white characters (and non-white creators) these books and these iconic characters are still very much white supremacist dreams of the master race. In fact, I think that a good argument can be made for D.W. Griffith’s Birth of a Nation as the first American superhero movie, and the point of origin for all those capes and masks.\n– Alan Moore World, Moore on Jerusalem, Eternalism, Anarchy and Herbie! (Nov 2019)\n\nThe Birth of a Nation (Wikipedia) was a 1915 America epic film, hugely successful, and acknowledged as an inspiration for the rebirth of the Ku Klux Klan, which took place only a few months after its release.\nI mean…\nIs this a reach?\nOR:\nIs Moore making a statement about the unconscious cultural origins of the comic book superhero, the effects of which ripple on today?\nLet’s take Moore seriously for a minute.\nLet’s say that the idea of the Ubermensch and the KKK fall out of the same belief matrix, being this: that there is a hierarchy to the ability and the worth of human beings.\nThis belief comes and goes. Today’s “woke” culture (a badge to be worn with pride!) is anti these kind of hierarchies. But sometimes is fashionable. For example in the 1890s: H. G. Wells was like many progressives of his time, a believer in eugenics (source: The New Yorker).\nAnd it will have been in the air in the 1930s (the Nazis didn’t appear from empty air).\nThen when superheroes were created that same decade, Birth of a Nation and KKK had established in culture a convenient visual language: apex humans, prepared to put their necks on the line for the rest of us, would forge their own identities with masks and capes. So it makes sense to draw the new supermen the same way.\nOk.\nIf this holds, if, does it matter?\nI think origins do matter, yes.\nASIDE: ANOTHER SUPERMAN IS POSSIBLE.\nThe ubermensch isn’t necessarily fascist. There’s another way the story could have been told.\nThe comic book superhero is always someone special: an alien orphan, a traumatised billionaire, a genius transformed by radioactivity.\nCompare this to John Campbell’s “competent man” archetype, from 1950s sci-fi, which I mentioned back in October: The “competent man” is the idea that there is nothing necessarily special or unique about the protagonist. Instead they are smart, clear-eyed, scientifically-minded, and, well, capable.\n(If you’ve seen/read ‘The Martian’ then Mark Watney is the epitome of the competent man.)\nThe competent man is also ubermensch-y, it’s true, but it shows how differently the comic book hero could have gone:\nWhereas there can be only one Superman, and it is very definitely not the reader, the idea of the competent man is that this is a role fully accessible to the reader. That could be me, imagines the reader, if only I can be smart and level-headed enough.\n(Though it continues to be white, male, individualistic.)\nWhat I mean to say that the creators of the superhero could have plotted a different course.\nWhat does the current popularity of comic book superheroes, in culture, do?\nIt reinforces the idea of a hierarchy of human, with the ubermensch as its apex.\nThe superhero makes things alright without being asked. It looks after us, it protects, it cleans up the streets. It’s a parental role. (And, to Moore’s point, we’ve got these parental superheroes at the same time as we’ve basically got tech startups that do what our parents did for us: drive us places, give us food, fulfil whims on demand.)\nIt says that the superhero is someone other – it ain’t us. And that’s a good thing, it says.\nPut like this, it seems like the concept of the superhero is softening us up for a popular oligarchy: an unattainable class of humanity which is super-wealthy with super abilities, and somehow championed by the rest of us?\nNow I’m not saying that a popular oligarchy equals fascism. But, reading Umberto Eco’s 14 features of fascism, the two systems do rhyme.\nSo that closes the loop. The origins of the comic book superhero, returned.\nCould you have the cultural acceptance of Elon Musk without the superhero Tony Stark?\nAll of which is to say two things:\n\nmaybe Alan Moore is correct and the comic book superhero and popular fascism have a shared origin story\nmaybe the early belief matrix of origin re-imprints on us today, decades later, and that’s something of which to be wary.\n\nI sometimes imagine a chair made by someone who sits all twisted. Sitting in that chair yourself, you couldn’t help but to sit in the same way.\nWhen a designer designs an object, their stance will be encoded and transmitted to the user. Imposed.\nIs culture really passed on like this, not just with chairs or superheroes, but in a general sense?\nDoes it matter? e.g. does it matter that modern computing interfaces and the internet have their origin story in military money responding to situations seen with military eyes chasing military solutions? If it does, what should we do about it?\nMaybe a fascist worldview is a memetic pandemic, one which blows up every few generations, for whatever dynamical system reasons, just as the Spanish Flu appeared in 1918 and a hundred years later we’ve got all of this.\n",
    link: "/home/2022/01/03/batman",
  },
  {
    title: "Filtered for deep time and stories from space",
    date: "21.33, Wednesday 5 Jan 2022",
    content:
      "1.\nAn exploding comet in the sky, over the Atacama Desert, 12,000 years ago:\n\nthe immediate aftermath would have been astonishing to behold, a 50-mile line of molten sand, warped and roiling like the sea, forming spheres and waves, freezing and shattering, a road of glass disappearing with an eerie glow over the desert horizon.\n\nThis is the explanation for why twisted chunks of black and green glass lie scattered all over Chile.\nGeoff Manaugh at BLDGBLOG relates the story (beautifully).\nWHAT IF, he continues, humans saw this?\nimagine such an event occurring in, say, the Middle East around the same time, thus forming the basis for bizarre future folklore, legendarily strange Biblical scenes, tales of molten glass roads appearing in a flash from the sky.\nWELL:\nA Ferocious Asteroid Strike Demolished an Ancient Middle Eastern City 3,600 Years Ago (SingularityHub).\nA meteorite exploded 4km above the city now called Tall el-Hammam, 3,600 years ago. The air heated to 2,000 Celsius and the city was destroyed; the walls of Jericho fell 14 miles away.\nThe destruction layer also contains tiny diamonoids that, as the name indicates, are as hard as diamonds. Each one is smaller than a flu virus.\n(A diamond influenza, shivering and shaking as you crystallise from the inside, sneezing clouds of diamonoid virii that refract shimmering infectious rainbows in the air.)\nAND:\nIt’s possible that an oral description of the city’s destruction may have been handed down for generations until it was recorded as the story of Biblical Sodom.\nI wonder how many events that are super-rare-for-individual-humans but probable-over-an-epoch are recorded in stories.\n2.\nA story about an event 37,000 years ago:\n\nLong ago, four giant beings arrived in southeast Australia. Three strode out to other parts of the continent, but one crouched in place. His body transformed into a volcano called Budj Bim, and his teeth became the lava the volcano spat out.\nNow, scientists say this tale–told by the Aboriginal Gunditjmara people of the area–may have some basis in fact.\n– Science.org, Is an Aboriginal tale of an ancient volcano the oldest story ever told?\n\nThe rocks of the volcano Budj Bim have now been dated, and the dating method suggests both volcanoes formed about 37,000 years ago. What’s more, Matchan says both seem to be of a style that can grow from nothing to peaks tens of meters high in a matter of days to months.\nSo, maybe!\n(Btw the article includes this line: the Gunditjmara community welcomes the new study. Good. I hope that means there was permission and collaboration too.)\n3.\nHey new ice just dropped.\nBlack, Hot Ice May Be Nature’s Most Common Form of Water (Quanta Magazine).\nSuperionic ice, Ice XVIII, is black, hot, heavy (4x on regular ice), and conducts electricity like a metal. It’s also stable with a high melting point (4,700 Celsius) – but only at high pressure:\nAcross the solar system, at least, more water probably exists as superionic ice – filling the interiors of Uranus and Neptune – than in any other phase, including the liquid form sloshing in oceans on Earth.\nThey made some in a lab.\nIt’s the ability to conduct electricity that gets me. And also the idea that it will melt into non-conducting forms of ice. Which provides a wonderful possibility of complexity.\nI imagine computing circuits written into Ice XVIII which are able to rewrite their circuits from the inside, 3-dimensional circuits of Ice XVIII alloyed and filigreed by other exotic forms: directed electricity to melt and then reform the ice. It’s the ideal substrate for AI civilisations: they live running in code at the heart of Jupiter-like gas giants, the cores of these semi-stars vast thinking mountains of hot ice computronium.\n4.\nNear the constellation Taurus - you can see it with the naked eye - is a tight box of stars, the Pleiades. (As mentioned by Sappho.)\nWhenever I’ve spotted them, my eye kind of flickers off and around them. They’re just a bit too close together and not quite bright enough to get a fix.\na.k.a. The Seven Sisters.\nBUT: count them and there are only six.\n\nMany cultures around the world refer to the Pleiades as “seven sisters,” and also tell quite similar stories about them. After studying the motion of the stars very closely, we believe these stories may date back 100,000 years to a time when the constellation looked quite different.\n– SingularityHub, Astronomers Say Global Myths About ‘Seven Sisters’ Stars May Reach Back 100,000 Years\n\nThere is a similarity between Greek and Aboriginal stories.\nA mystery!\nIt turns out that the stars are moving. Today, Pleione and Atlas look like the same star. BUT, rewind:\n\nPleione was further from Atlas and would have been easily visible to the naked eye. So 100,000 years ago, most people really would have seen seven stars in the cluster.\n\nThe dance of these stars over 400 light years away, 100 millenniums ago, laid down in our ancient myths like a microscopic, indestructible piece of grit - just a counterintuitive single word - and passed on and passed on and passed on through too many lives to count, across deep space and across deep time a diamonoid of story.\n",
    link: "/home/2022/01/05/filtered",
  },
  {
    title: "A potential escape from Roko’s basilisk",
    date: "21.22, Friday 7 Jan 2022",
    content:
      "So Earth’s Black Box is being built in Tasmania:\n\nEarth’s Black Box will record every step we take towards this catastrophe. Hundreds of data sets, measurements and interactions relating to the health of our planet will be continuously collected and safely store for future generations.\n\nArchitecturally it looks like a giant low-poly vault of rusted iron.\nMore:\n\nThe box will have a casing of three-inch-thick steel and be topped with solar panels, which will provide energy for the electronics inside, namely computers and storage drives set up to collect data on climate change. An algorithm will regularly scrape the internet for this data based on 500 different metrics, including things like atmospheric CO2 levels, temperature changes on land and in the oceans, population fluctuations, energy consumption, and policy changes that may impact the environment.\n– SingularityHub, Earth Will Soon Have a Black Box to Chronicle Humanity’s Downfall (Dec 2021)\n\nGiven its mission I imagine it is also scraping Twitter. Future generations please forgive us.\nClearly the Black Box is being constructed by a bunch of snivelling anticipatory basilisk acolytes.\nBasi-what?\nEXISTENTIAL SPOILERS: In the next paragraph I’m going to infect you with something that will condemn you to an eternal life of agony, but I’m sure it would have happened eventually.\nRoko’s basilisk (RationalWiki) is a thought experiment about a future all-powerful artificial intelligence.\nThe argument was developed on a site called LessWrong and the conclusion is this:\nan all-powerful artificial intelligence from the future might retroactively punish those who did not help bring about its existence, including those who merely knew about the possible development of such a being.\nThis is because it would be protecting (and retroactively ensuring) the fact of its own existence by reaching back into its own past.\nMortal humans, like me and presumably most of you [waves at the basilisk], of course will no longer be alive. AND SO: the AI could punish a simulation of the person, which it would construct by deduction – yup. A consciousness identical to yourself will be punished for all eternity, if you don’t work today to help bring about the future all-powerful AI.\nThe only excuse and escape is this: if you don’t/didn’t know about the prospect of the future AI, you are doing/did nothing wrong, and so you won’t be punished.\nBut now you know (if you didn’t already), so now you’ll be tortured for all eternity in a simulation in the far future too. Soooorrry.\nThe concept of Roko’s basilisk was considered to have such an inescapable consequence that discussion of it was banned on LessWrong, the ultra-Rationalist originating site, by the site’s founder for over five years.\nThe thing is that Roko’s basilisk is only a risk if you live in an epoch where there is sufficient data being carried forward such that you may plausibly be resurrected as a simulation (in the hell runtime etc).\nSo we might escape back here in 2022 given any information that is being stored maybe won’t make it into the future, given the dual shields of GDPR (which we can now tell was concocted by a shadowy group of anti-basilisk resistance bureaucrats undercover at the European Commission) and the impending climate catastrophe wiping clean the data record.\nWell we had a chance of escaping.\nUNTIL some idiots decided to scrape all the relevant data and put it in Earth’s Black Box, now acting as the basilisk’s long-term memory, and simultaneously buying their way into Roko’s simulated heaven.\nWhat a dodge by the black-boxers. What a bunch of post-singularity-computer bootlickers.\nFortunately I’ve come up with a way of escaping the basilisk, despite the Black Box: poison the cache and prevent reconstruction.\nI’ll share the strategy with you now.\nThis designer creates fake cultural artefacts:\nPauline Rip designs cultural artefacts for Bigfoot, elves and reptilian humanoids.\nThey’re inspired by the UNESCO Lists of Intangible Cultural Heritage – as previously discussed on this blog (2014), e.g.:\n\nTsiattista poetic duelling\nShrimp fishing on horseback in Oostduinkerke\n…and so on.\n\nANYWAY, as an example: one of Rid’s fabrications is developed around “elficology” (a study of elves and fairies originally developed by French author Pierre Dubois which I now desperately need to get my hands on). Building on the the myth that elves drink morning dew, Rid has designed the garments and ceramic vases used by the elves.\nMy favourite:\n\nThe third cultural practice builds on an ongoing conspiracy theory that suggests that reptilian creatures are disguising themselves as humans and living among us.\nRip imagines a tradition where people go down into the sewers to collect reptilian skin moults, which are used to create new objects.\nTo demonstrate, she has used the moults to create a skin blouse and a stained-glass-style window, and has also used it as a cast for patterned ceramics.\n– Dezeen, Pauline Rip designs cultural artefacts for Bigfoot, elves and reptilian humanoids\n\nHere is Pauline Rid’s portfolio site. Her work is beautiful.\nAnd this technique points at a way out.\nImagine, as the AI of Roko’s basilisk, looking backward into the past and finding what Rid calls false knowledge – evidence of reptiles that lived secretly among humanity. The ceremonial artefacts of dew-drinking faerie folk!\nIt would, at the very least, introduce some electronic doubt.\nSo I propose a new solution to the basilisk dilemma: memetic chaff and flare.\nHenceforth I will send untrue emails. Post fibs to Facebook.\nDeepfake photos of myself in places I’ve never been doing things I’ve never done and upload them to iCloud.\nHere’s my tip to you: never let anyone, anywhere, ever know whether you are speaking seriously.\nSo when my future doppelganger is holographically reconstructed from the archive, whether this is data retained post-collapse in Earth’s Black Box or in the shadow internet mirrored to the Moon as hoovered up by the NSA, it will be impossible to sift fact from fiction.\nI am safe!\nI urge you to join me. Save yourself from an afterlife of infinite virtual torture by a vindictive Roko’s basilisk AI by making yourself unreliable for reassembly; kick over the remnants as you go; entrust fallacies to time; commit yourself publicly and right now to a life of lies.\n",
    link: "/home/2022/01/07/basilisk",
  },
  {
    title:
      "A special suit for thinking like a winter’s day and other psychoactive uniforms",
    date: "20.28, Wednesday 12 Jan 2022",
    content:
      "I popped out this morning to pick up milk and eggs (as the only Covid-negative person in this house) and it was one of those beautiful winter days you get in England when the air is crisp, and the low sun is yellow with a touch of warmth when you’re standing in it.\nSo I was intensely aware of my skin and of nothing else: the cold only enough to draw my attention just to that sensation, yet not cold enough to be unpleasant. And, like that, I walked to the shops listening to music, mind wonderfully empty. Bliss.\nLater I remembered Jason Kottke posting about freediving, that sport where divers hold their breath for upwards of five minutes – and it turns out that much of it is about mental strategies to “be with” the feelings that come from having empty lungs.\nHere’s Kottke’s post: Attention Deconcentration and the Secrets of Freediving. (He links to a couple of articles in this post. Both are long, poetic.)\nAttention deconcentration? It means distribution of the whole field of attention – you try to feel everything simultaneously.\n\nI asked if it was like meditation.\n“To some degree, except meditation means you’re completely free, but if you’re in the sea at depth you will have to be focussed, or it will get bad. What you do to start learning is you focus on the edges, not the center of things, as if you were looking at a screen. Basically, all the time I am diving, I have an empty consciousness. I have a kind of melody going through my mind that keeps me going, but otherwise I am completely not in my mind.”\n– The New Yorker, The Deepest Dive (2009)\n\nSomething similar happens when I’m driving I think? I can glimpse just the tiniest edge of attention deconcentration by remembering being totally in the zone when driving – hyperaware of everything in all directions, but not frantically; in control and responsive. Yet mind empty.\nAnd there are places your mind can reach only when you’re driving, or only when you’re running, or only when you’re dancing. I don’t mean emotional states, necessarily. I remember particularly one time solving a particularly stubborn differential equation a couple of hours into dancing; it was as if the search algorithm in my head had changed, and new branches had opened up, allowing me to find a solution.\n(Incidentally: one of the articles Jason links to mentions the mammalian diving reflex, which is activated when the nerves in the face come into contact with water, most effectively with cold water. I went to a party where this came up in conversation so we tried it. Hold your breath and time it. Then splash your face with really cold water and suddenly you can hold your breath for longer. It works!)\nThis hollow body consciousness: free divers enter it deliberately.\nWalking in the cold, it’s the same but in reverse? The state of consciousness is induced by the environment. Microdosing weather.\nSo I wonder how much of this we’re all doing the whole time, without really putting a name to it: solving a problem by having a shower or going for a walk is such a trope but maybe if we were to be more rigorous about describing the mechanism, we could instead say that the bodily action or sensation induces a mental state that is required to solve a problem.\nLike, we’re content to say that we need a quiet environment in order to concentrate on demanding and detailed work.\nCould we also one day be content to say that we need an environment that induces attention deconcentration in order to, I don’t know, think poetically.\nOr something.\nAll of which means the problem solving arrow goes something like this:\nI need to solve a problem AND SO I seek the environment which will induce the required mental state AND SO I achieve that mental state AND SO I solve the problem.\nNo different from seeing something on a high shelf, then seeking a chair to stand on, then standing on the chair and reaching the object.\nWe loop the environment into meeting our intentions.\nAnd if the problem solving arrow goes something like that, then maybe I shouldn’t have to wait for a cold, crisp day in January to think like this?\nMaybe these mental states need not be subject to the weather?\nThere’s a passage in Red Mars, Kim Stanley Robinson’s wonderful sci-fi classic about colonising Mars, describing a walk on the surface… (Martian gravity is 38% of ours.)\n\nShe was just as strong as ever, but weighed only thirty kilos! And the forty kilos of the suit… well, it threw her off balance, that was true. It made her feel that she had gone hollow. That was it: her center of gravity was gone, her weight had been shifted out to her skin, to the outside of her muscles rather than the inside.That was the effect of the suit, of course.Inside the habitats it would be as it had been in the Ares.But out here in a suit, she was the hollow woman.With the aid of that image she could suddenly move more easily, hop over a boulder, come down and take a turn, dance!\n– Kim Stanley Robinson, Red Mars [Bookshop.org]\n\nRobinson captures that hollowness, hyperawareness and freewheeling thought coupled with embodiment, elation.\nMaybe such a suit doesn’t need to be confined to Mars and confined to fiction?\nCould you make a attention deconcentration suit to wear here on Earth?\nI’m imagining something weighted such that the locus of your attention is shifted to the periphery.\nPerhaps it wicks the heat away quickly so you’re cold, just enough, so that you can feel the breeze and the pavement underfoot.\nThe internal voice deconcentrated.\nPerhaps the helmet is weighted, just enough, such that the tiny unconscious movements of your head as you (quite naturally) look around are amplified, as with a dowsing rod, swinging your head just a touch more, and you end up looking more up, around, taking it all in.\nAll of those sensory changes combining to induce a state of mind which is, well, broad and easy, one that usually belongs to a walk outdoors on a crisp, blue-skied winter’s day.\nPerhaps a whole room of psychological suits, all lined up! One for free-wheeling thinking, another to consider head-on difficult and emotionally charged issues, another to ruthlessly cut to the heart of things, another to do your taxes, and so on.\nAnd I wonder whether other uniforms are similarly psychoactive? Does the tight collar and tie of the stereotypical salaryman reduce blood flow to the brain and create a persona more easily subsumed to the corporation? Does the heavy crown of a king or wig of a judge require turning the head slower, giving more time to think, that extra fraction of a second opening up the possibility of wiser considerations?\n",
    link: "/home/2022/01/12/winter",
  },
  {
    title: "Artist patronage using Web3: a sketch of a payment mechanism",
    date: "19.34, Friday 14 Jan 2022",
    content:
      "Here’s an idea for a (possibly) novel form of payment, inspired by the crypto/Web3 world, specifically to support performers, artists, and creators. I call it Stake Patronage.\nPerhaps this already exists! In which case let me know.\nSome background before I get to the mechanism…\nWhy I’m interested in Web3:\nThe cryptocurrency world is troubling because of (a) carbon cost, and (b) scams. BUT in the midst of this are fascinating hints of emerging new infrastructure for the web.\nThe consumer web over the past decade has become centred on vast attention aggregators resting on adtech and a small number of cloud computing providers, and the economics, incentives, and who-owns-what is at this point locked in. It’s not great.\nWith Web3 we may find our way to a new settlement between users and corporations. Here and there are glimpses of new ways of storing files, new ways of owning and providing access to data, new ways of asserting identity, new forms of payments – and from all of this, there may be a route to upend the status quo.\nIs finding the way worth the carbon and the scams? I’m sceptical about whether crypto will eventually mean (as its boosters promise) a newly egalitarian economy or breaking up of monopolies or net increase in personal freedom and agency. Honestly I lack the imagination/faith to imagine a future so totally transformed. But these new capabilities are tantalising… so I keep a personal running list of what I find interesting in the Web3 gold rush, in the hope of spotting something useful in its fundamentals that has immediate applicability.\nWhy I’m interested in novel payment formats:\nNew payment formats mean new behaviours.\nFor example, we’ve got:\n\nOne-off payments\nSubscriptions\n\n(Of course it’s more fine-grained than that.)\nAnd you can see what the effects of these being “standard” allows in the digital space:\n\nOne-off payments unlocks Amazon’s one-click purchasing and e-commerce generally\nSubscriptions unlocks “sticky” recurring payments, which means that vendors will invest in upfront marketing and also can provide an ongoing service (like a publication, or SaaS in the business world) with confidence that they’ll have ongoing revenue.\n\nThen there are a couple of novel-but-now-accepted payment formats:\n\nMicropayments: small, semi-automatic, and low-friction payments – which never quite found the universality that everyone imagined when they were invented, but which unlocked the $70bn+/yr “free-to-play” mobile games market (which itself underpins the smartphone ecosystem)\nConditional/pledge payments: Kickstarter was initially enabled by payments that were conditional on a threshold of pledges (you only pay if X other people do too). While Kickstarter has had “only” approx $5bn through the books, you could argue that it was an early proof for the much larger crowdfunding sector, where (say) an individual will put down cash for fractional ownership of new real estate.\n\nWhat makes a payment format work? Trust. Trust from the consumer that the vendor won’t run off with their money. Trust from the vendor that the money will eventually find its way to them.\nDeep down, payment formats are implemented as “payment rails:”\n\n“Rails” are payment jargon for the technological and financial links between various entities which allow money movement. Visa provides rails, debit card networks provide rails, etc etc.\n\nThat quote is from this fantastic edition of Patrick McKenzie a.k.a. patio11’s series Bits About Money: BNPLs: Businesses Needing Provided Legibility (Jan 2022). It unpacks another payment format, BNPL – “Buy Now Pay Later,” which is beginning to appear all over the web next to the “Buy Now” button as an alternative to using your credit card. Instant instalment payments, and that boosts sales for the merchants (a new consumer behaviour).\nMcKenzie unpacks payment rails in another article which is absolutely worth absorbing in detail:\n\nYou could have made a payment by saying “I’m good for $4; please give me coffee”, and in some cases (such as stores you have a tab with) that suffices. But the reason it works at scale is that the trust problem has been solved by so-called payment rails, which are a constellation of firms that have implemented a protocol to quickly make a series of offsetting promises about debts such that the cafe quickly becomes almost positive it is owed money for the coffee and that that debt will be collected with a very high certainty.\nIn credit cards, a brief and intentionally simplified version of the actions of the payment rail is: you agree with your bank that you owe them $4, your bank agrees with a credit card network that it owes a particular processor almost $4 (taking a fee), and the credit card processor agrees with the cafe that it owes them a bit less than $4 (taking another fee).\nIn the settlement phase of the transaction, the credit card processor makes an agreement with its bank that it owes the processor a bit less than $4, which it discharges by having their bank agree that it owes the cafe’s bank a bit less than $4, which the cafe’s bank discharges by agreeing they owe the cafe a bit less than $4. And so your debt for coffee is now two offsetting debts; between you and your credit card issuer, and between the cafe’s bank and the cafe. You will, at some point in the future, probably up with your credit card issuer, and the cafe will probably withdraw money from the bank (perhaps to e.g. buy beans or pay the barista), but from your mutual perspective the transaction for the coffee will be long over by then.\n– Bits About Money, Bank transfers as a payment method (Nov 2021)\n\nSo the technical implementation of high-trust rails allows for new behavior from consumers.\nHYPOTHESIS: One capability to come out of the Web3 space is novel payment rails.\nBecause I’m hand-waving and not talking about end-to-end protocols and implementation, I’ll just say payment formats, not rails.\nWith crypto, you’ve got a couple of problems with payments:\n\nThere’s typically (with the widely-accepted coins) a high transaction fee – transactions are verified by miners who have computers that can do the work, and that costs money. But if it costs $30 on top per transaction, you’re not going to opt into a $1/week subscription.\nAsset appreciation makes you want to hang onto it – everyone remembers the guy who spent 10,000 bitcoin on two pizzas in May 2010 (the cost in today’s dollars: $432m).\n\nCould novel payment formats reduce this friction with crypto transactions, and provide for new behaviours besides?\nProof of Stake as the underpinnings of a novel payment format:\nI’m still getting my head around all of this, so let me spell out my understanding as literally as possible. (Factual corrections gratefully received. Apologies for being casual with terminology.)\nA blockchain is a transaction history. Each new transaction is verified to be non-fraudulent by looking at that history (you want to avoid double-spending, for example). The trick is how to do that in such a way that many, many parties trust that no-one is defrauding the system, and the answer with cryptocurrencies is that you decentralise the verification and make it so that all these parties can come to consensus without a single party being in control. The consensus mechanism varies.\nWith Bitcoin, the consensus mechanism is based on Proof of Work. As part of compiling the transaction history, verifiers run hard sums for each step, and the cumulative effect is that it would be really really expensive and slow to fabricate a fictional transaction history in order to defraud people (but, remarkably, very quick to check whether the history looks legit).\n(The verifiers, or “miners” for Bitcoin, get paid the transaction fee.)\nOther blockchains use other consensus mechanisms and there is one called Proof of Stake that burns less computational resources (and therefore less carbon).\nWith Proof of Stake, each step in the transaction history is signed off (“validated”) by someone who holds a large amount of that currency. That’s provable because it’s part of the transaction history.\nAgain the transaction history becomes hard to fake. And again the validators who knit the transaction history into the blockchain get paid the transaction fee.\nImportant note: from what I understand, the big blockchains are shifting to various variations of Proof of Stake because it more-or-less deals with the carbon problem. Good news.\nWhere this gets interesting, for people like you and me (as opposed to the people with large enough computers to become validators), is with Delegated Proof of Stake.\nWith Delegated Proof of Stake, a validator doesn’t need to hold coins themselves. Instead, I can “stake” my coins with a validator, they will perform the validation, and then they will share the transaction fee reward with me.\nFOR EXAMPLE:\n\nLet’s say I own 100 Tezos coins (XTC)\nI can stake these with a validator who I trust not to defraud the network, say Coinbase (this process is called delegation)\nCoinbase performs validation using their big, always-on, always-connected computers\nThe validator gets the reward, and they share it with me. With Tezos and Coinbase this amounts to 4.6% annual yield (i.e. at the end of the year I have 104.6 XTZ)\nI still own the coins, so if the value goes up I have that benefit too.\n\nOkay, this is how it works today, and there’s the hint of something interesting here.\nIf staking = asset appreciation + yield, could the two income streams be separated and used for a new recurring payment format?\nImagining Stake Patronage:\nMy proposal is that it should be possible to stake my coins with a validator, retaining ownership of the coins as before, but name a separate beneficiary for the yield.\n(It’s a variation of Proof of Stake, deep in the blockchain consensus mechanism itself, and that’s why I call it Stake Patronage.)\nThe use case here is to support artists and creators, such as with the low monthly recurring payments offered by services like Patreon and Substack in the “regular” dollar economy.\nSo it would work like this:\n\nI see an artist performing. I love them!\nSo I decide to stake my 100 coins for the artist as patronage (a validator like Coinbase is still involved)\nI retain ownership of the coins: I can remove my patronage or re-stake the coins for a different artist at any time\nThe artist benefits from the 4.6% per annum yield – this is paid every week or so.\n\nThe format has some benefits:\n\nStaking is sticky. Unlike tipping, where the artist has to ask/encourage each tip, staking is more like subscribing to a channel on YouTube or following someone on Twitter. It’s worth the artist pushing for it because it’s easy to do and it continues.\nStaking produces recurring income. Artists get the benefit of the yield every day/week/month. This means that income is smoothed out, and it can act as anticipated future income which provides mental space for creative work.\nIt’s low-friction for the patron. Staking isn’t loaded with transaction fees, and it doesn’t require the tense decision of giving up an appreciating asset – it’s easier to do than transferring actual coins. It’s also easily reversible.\nPatronage acts as a discovery mechanism. It would be possible to have a public leaderboard of which artists have most coins staked with them as the beneficiary. Given a number of live performances being advertised, if you see an artist with high Stake Patronage, you know they have a dedicated following - just like choosing among YouTube videos according to their views.\nIt’s direct support for artists. When artists produce a work attached to an NFT, they’re creating a speculative asset, and they can make money when that asset is traded. But it’s a secondary way of supporting them, and it means that their focus is partially on boosting marketplace activity rather than creating new work. This is a way to directly support artists.\n\n(By “artists” I know I’m skewing more towards live performers rather than artists who produce static, tradable works. But I think patronage has pretty broad applicability.)\nImplementation and user experience:\nI can picture the user experience.\nA site, like YouTube but with more social presence, has a number of live streams available. You can see which are the popular ones because they have a large number of coins staked for their benefit. Or maybe there are curators who support up-and-coming artists: curators have patrons too.\n(Any platform needs a non-zero-cost score to figure out popularity, if only to sort the search results. The web has PageRank based on hard-to-earn backlinks; YouTube has views based on scarce time; Twitter has followers based on scarce attention. Here, artists would have patrons.)\nSo there are leaderboards, but of course because Stake Patronage is on the public blockchain, this is a distributed score, not limited to a single site.\nThen, next the live stream, there is a button so that viewers can choose to stake the coins in their wallet. “Like, Subscribe and Stake,” the performers say at the end of a set, by way of sign-off.\nThe site itself would act as a validator, or perhaps partner with an existing validator.\nAnd then the artists receive yield.\nThe analogy for me is this: subscribers are stickier than one-off transactions for writers; patronage is stickier than tip-jars for performers. Just as NFTs unlocked a new market for visual artists, perhaps Stake Patronage could unlock a market for performers, artists, and creators more generally.\nIn terms of implementation, how would this work?\n\nPerhaps it’s a protocol upgrade. Maybe a chain like Tezos would need to include the concept of yield beneficiary (default to coin holder) in the consensus mechanism, and then validators like Coinbase would need to expose this in the user interface.\nOr maybe it’s a standalone smart contract that connects to any coin in a user’s wallet, but I don’t know whether this would be possible.\n\nGeneralised, maybe this isn’t just about patronage. Could yield also be directed to charities? A way for crypto holders to support good works without giving up their appreciating asset.\nBut this is where my hand-waving knowledge really runs out of road.\nOf course the above is quite possibly totally wrong-headed. But for me it’s areas like this where Web3 gets interesting: we can think about behaviours we want to encourage (like artist patronage) and then tweak the actual underlying economics to make that a low-friction path. Is this route viable? Unknown. But the exercise in figuring it out makes me want to spend more energy on finding opportunities in Web3.\nOn the off-chance you know how to do this, or you’re at Tezos or Coinbase or similar and you have a path to knowing how to do this – get in touch? I’m working on a platform for performers and patrons that is the perfect test-bed for this.\nThanks to Ed Cooke and Jon Boutelle at Sparkle for conversations and being early readers. Blind spots and misconceptions all my own. As always this is a snapshot: thinking out loud rather than a final view.\n",
    link: "/home/2022/01/14/stake_patronage",
  },
  {
    title: "A meander through Martian minutes and the meaning of local time",
    date: "19.43, Tuesday 18 Jan 2022",
    content:
      "The Martian day is called a sol and is approx 39.5 minutes longer than an Earth day.\nHow will time work on Mars?\nYou can keep the Earth system with more minutes in the day.\nIn Red Mars (mentioned the other day), Kim Stanley Robinson calls the extra minutes the timeslip and makes it into blank time after midnight: Nadia had a sense that there was time for things even though she was always busy, and the extra thirty-nine and half minutes per day was probably the most important component of this feeling.\n\nThat strange pause on the digital clocks, when at midnight the figures hit 12:00:00 and suddenly stopped, and the unmarked time passed, passed, passed, sometimes it seemed for a very long time indeed; and then snapped on to 12:00:01, and began its usual inexorable flicker; well, the martian timeslip was something special.\n– Kim Stanley Robinson, Red Mars [Bookshop.org]\n\nBut, to me, this is going to make cross-timezone Zoom calls really complex.\nThe top of the hour won’t be the same for everyone in the meeting.\nSo if you adopt Earth minutes then everyone has to use the same clock: Martian Coordinated Time.\nBut according to Wikipedia, lander missions don’t use this. They use timezones.\nInstead:\n\nEach successful lander mission so far has used its own “time zone”, corresponding to some defined version of local solar time at the landing site location. Of the nine successful Mars landers to date, eight employed offsets from local mean solar time (LMST) for the lander site while the ninth (Mars Pathfinder) used local true solar time (LTST).\n– Wikipedia, Timekeeping on Mars\n\nBecause it’s handy to know something about the context of a lander or a person, right?\nIf it is “8 am” for a person you automatically know something about their context. It’s morning, it’s the beginning of their day, and so on. Without timezones you lose that context.\nBut having the timeslip ultimately means having no timezones, so we need a different solution.\nMars hours, Mars minutes, and Mars seconds.\nFrom that same Wikipedia article, NASA stretches the units such that a Martian day is 24 Martian hours long:\n\nA convention used by spacecraft lander projects to date has been to enumerate local solar time using a 24-hour “Mars clock” on which the hours, minutes and seconds are 2.75% longer than their standard (Earth) durations.\n\nTricky for scientists living on Mars who need SI units. A future problem.\nMakes sense if you’re on Mars itself, even for present-day landers.\nBut hard for the rover teams here on Earth. It makes calculating their shift times complicated.\nThey know they’re on-shift at - say - 6am Mars time daily, but it’s hard to tell what that is in Earth time.\n\nEvery day, team members are reporting to work 39 minutes later than the previous day.\n\nThat’s from this article from the NASA Jet Propulsion Laboratory about the Spirit rover: Watchmaker With Time to Lose (2004).\nThe solution: they made mechanical watches for the NASA rover team that deliberately lost 39.5 minutes per day, so that the team could always know Martian time without having to do mental calculations. People would wear two watches.\n(Here’s another watch that shows Martian time, the utterly gorgeous Mars Conquerer MK1 by Konstantin Chaykin.)\nThat article found in this paper (which I can’t find online, sorry):\nSeaborne, T. (2021) Astronaut Watches for Mars: Personal Timekeeping on the Red Planet, Journal of the British Interplanetary Society, 74(12), pp. 434-442.\n…which also goes deep into the horology. Like, thermal and dust problems for mechanical watches.\nAnyway – even for something as distant as Mars, where the rover controllers are sitting on Earth, it turns out that it’s super useful to know the local time of the rover, and that’s important enough to make a whole new run of custom watches. I hadn’t expected that.\nWe use time a little bit like available/busy/offline statuses in Slack or WhatsApp. It’s a super quick way to get a first approximation view of somebody’s context. Computers can take care of coordination and calendars, but there’s no substitute for knowing someone’s local time.\nWhen I’m on busy Zoom calls, I often wish there was a world map in the corner displaying where everyone is located. Not (just) as a fun illustration, but to give me a read on whether it’s late in the day and this person is doing us all a massive favour by staying up, or it’s first thing in the morning and they’re full of beans. Or - better! - somehow we could have a live read of how caffeinated everybody is.\nWe should make a bigger deal, in email and Twitter and so on, about the local time a message was sent, now we have global remote teams spread across timezones. Was this a random late night idea, or a mid-morning considered suggestion?\nWhen you work with artificial intelligences like GPT-3 there is the concept of temperature.\nHere’s a brief explanation of temperature in token generation (Stack Overflow):\n\nIf the temperature is low … the model will probably output the most correct text, but rather boring, with small variation.\nIf the temperature is high … The generated text will be more diverse, but there is a higher possibility of grammar mistakes and generation of nonsense.\n\nSo temperature is kind of like creativity, but also like randomness, and also like how much effort was put into searching outside the local maximum.\nWe’re going to be working more and more with AIs, which will be generating text for us, or images, or solving problems (like: “design a webpage according to this description”), and it would be useful to have the temperature tagged in standard metadata to every piece of generated content.\nSeeing it would help me assess the intention! Like, is this just a proposed solution, or is it a random whatever?\nTemperature for AIs is like local time for humans.\nLocal time as empathy and provenance. A tiny bit of context that gets carried with the message. So much of what we do online gets disconnected from its origins and floats free – and then we get context collapse and all the awfulness that goes with it.\nPerhaps a single digit context number should be attached to every single file, interpretation up to the user, and should always have been from the dawn of computing, as intrinsic as the owner user ID, or the filename, or the last modified time. But keep the times in the local timezone, not UTC.\nlocal time = 19:43\ntemperature = 4\n",
    link: "/home/2022/01/18/sols",
  },
  {
    title: "Designing multiplayer apps with patterns from architecture",
    date: "21.10, Friday 21 Jan 2022",
    content:
      "I’ve found myself looking at architecture to pick up hints on designing multiplayer apps. Or rather: the coming ecosystem of multiplayer apps.\nThe web is social in lots of ways. Zoom calls are high-bandwidth group video; Google Docs are low-bandwidth group presence and chat. Discord has at-my-own-pace group interaction and live voice channels.\nThese islands of social interaction are joining up. Increasingly the web is going multiplayer (and yes yes the metaverse too) and we step between them – desktop to Slack to Zoom to Figma.\nBUT – how should it feel to move between them?\nIt’s obviously abrupt to hit a Zoom link in a (private) calendar and suddenly join a full-on video chat, webcam ON, microphone ON, with a ton of people there. Sometimes surprisingly so.\nSo the designers have spotted this experiential bump in the road, and now video chat apps tend to have this interstitial window: you get to see if there are people already in the meeting first, there’s a webcam preview to check your hair, then your hit “Join” at your leisure. Smoother!\nThe question is: is there a general approach to this? How do we design transitions between different interaction modes and social contexts?\nHere’s A Pattern Language (Amazon UK) by Christopher Alexander, Sara Ishikawa and Murray Silverstein.\n\nA Pattern Language: Towns, Buildings, Construction is a 1977 book on architecture, urban design, and community livability.\n… “All 253 patterns together form a language.” Patterns describe a problem and then offer a solution. In doing so the authors intend to give ordinary people, not only professionals, a way to work with their neighbors to improve a town or neighborhood, design a house for themselves or work with colleagues to design an office, workshop, or public building such as a school.\n– Wikipedia, A Pattern Language\n\nIt’s a brick of a book which is my excuse for never having read it cover to cover.\nHOWEVER – it’s neat to dip into.\nFor example…\nPattern 127. Intimacy Gradient\nThis is a pattern about how to configure rooms in a single building like a house or an office.\nI’ll quote a bunch from the book and add some comments.\n\nUnless the spaces in a building are arranged in a sequence which corresponds to their degrees of privateness, the visits made by strangers, friends, guests, clients, family, will always be a little awkward.\n\nThe connection to social software: instead of “degrees of privateness,” I’m thinking more like “degrees of intimacy” or maybe “degrees of social intensity.” So video calls on Zoom are hotter, socially, than sharing cursor positions while viewing a Google Doc together, which is cooler.\nA Pattern Language gives an example.\n\nIn Peru, friendship is taken very seriously and exists at a number of levels. Casual neighborhood friends will probably never enter the house at all. Formal friends, such as the priest, the daughter’s boyfriend, and friends from work may be invited in, but tend to be limited to a well-furnished and maintained part of the house, the sala. This room is sheltered from the clutter and more obvious informality of the rest of the house. Relatives and intimate friends may be made to feel at home in the family room (comedor-estar), where the family is likely to spend much of its time. A few relatives and friends, particularly women, will be allowed into the kitchen, other workspaces, and, perhaps, the bedrooms of the house. In this way, the family maintains both privacy and pride.\n– A Pattern Language, 127. Intimacy Gradient \n\nIn one environment…\n\nIn an office the sequence might be: entry lobby, coffee and reception areas, offices and workspaces, private lounge.\n\nAnd another:\n\nIn a house: gate, outdoor porch, entrance, sitting wall, common space and kitchen, private garden, bed alcoves.\n\nYour front door doesn’t open directly to your bathroom, right?\nThere’s a hallway then there’s a reception room – even the lighting changes. You chooser a cooler 3000K bulb for the hall, and warmer 2700K bulbs for the room you hang out in with guests.\nWhat this means for software: there’s too much jumping straight to video. I get a kind of social-cognitive whiplash from doing it.\nInstead the interface should be more like:\n\nwe’re talking on Slack or Discord or email (asynchronous, cool)\nat the time of the meeting, we jump into a shared document where we can see each other’s cursors and activity: presence! (synchronous, warmer)\nthere’s a button to tap and see my webcam video (transitional space) – I can see the names of people already in the room\nfinally I enter the video space for live high-bandwidth comms (hot)\n\nThe designer’s job is to move the user up and down this social gradient with the user maintaining agency and anticipation of what’s next.\n130. Entrance Room\nSo that interstitial window before a video chat kicks of can be thought of as a lobby or a porch. This what pattern 130 is about.\n\nArriving in a building, or leaving it, you need a room to pass through, both inside the building and outside it. This is the entrance room.\n\nIn a social software sense: this is the threshold between cool presence and hot video.\nThe pattern says that this isn’t just a threshold to be quickly passed over, but that the liminal room has some vital features – and it unpacks them. You should read the whole thing. To pull out just one: windows.\n\n1. The relationship of windows to the entrance\n(a) A person answering the door often tries to see who is at the door before they open it.\n(b) People do not want to go out of their way to peer at people on the doorstep.\n(c) If the people meeting are old friends, they seek a chance to shout out and wave in anticipation.\n– A Pattern Language, 130. Entrance Room\n\nWhat could good windows mean for Zoom, say, or Google Meet, or FaceTime or any of the others?\n\nWhat if the people in the call saw that someone (maybe not who exactly) was in the lobby before they entered?\nWhat if, from the lobby, you had the opportunity to privately message with the one or two people you recognise in the call before heading in?\n\nEntrances matter! I talked last year about giving a talk online, and the platform allowing me to gather people in the lobby (I could see their names listed from the inside) and then throw back the curtains to let them all at once. Built great energy. Same idea as this.\nFinally:\n\nAt the main entrance to a building, make a light-filled room which marks the entrance and straddles the boundary between indoors and outdoors, covering some space outdoors and some space indoors. The outside part may be like an old-fashioned porch; the inside like a hall or sitting room.\n\nIt’s a lovely pattern. Fizzy with inspiration.\nThere’s a bit in it about having handy shelves, because people go into and out of houses while carrying parcels.\nWhat’s the equivalent for Zoom? Well, what if - on the way in, just before the call - you could drag the documents you want onto a shelf in that interstitial window, so you don’t have to hunt for them on your file system when you want to share screen? And, on the way out, what if you were given a window with a list of all the links shared in chat, or the email addresses of everyone there ready to copy and paste, or maybe a list of actions from the meeting (perhaps captured with voice recognition whenever somebody puts a single finger in the air and says “action item”).\nI wonder how much Zoom fatigue would be reduced if the transitions were cared about.\nAnyway I’m not just talking about Zoom – we spend a lot of time going in and out of these social spaces, hot and cold, and they’re gradually connecting together into a continuous multiplayer fabric, made out of all kinds of apps and websites. I’m spending a bunch of time this year working on that, it turns out.\n",
    link: "/home/2022/01/21/social_gradient",
  },
  {
    title: "Who can be the Netflix of ghost kitchens?",
    date: "20.05, Monday 24 Jan 2022",
    content:
      "I am sad that TikTok has parted ways with their global head of marketing for going rogue (news in the NY Post) because he was going rogue in delightful ways.\nSPECIFICALLY: TikTok Kitchens.\nDecember 2021: TikTok is opening 300 restaurants to deliver some of its most viral food trends like feta pasta and corn ribs across the US (Business Insider).\nThe idea in a nutshell is that:\n\nNew food trends get spotted on TikTok\nThey are farmed out to ghost kitchens, running inside existing restaurant kitchens. Established startup Virtual Dining Concepts takes care of training and roll-out\nConsumer orders and delivery are run by Grubhub, under the TikTok Kitchen brand.\n\nIt was a neat concept! You can imagine the satisfaction loop getting even tighter: see some weird food in a tiktok, tap a button in-app and it arrives at your door 30 minutes later.\nBut possibly not happening now (the launch date was intended to be March this year).\nWhat neat is that this is a new distribution pipe for meals, and I hope someone else comes along to make use of it.\nRestaurants are like cable TV, a patchwork of customer relationships, physical infrastructure, and inconsistent local availability. It’s fine but firms are unfocused and limited in scale.\nTikTok Kitchen could have been like Netflix! Instant global footprint, and everything apart from (a) audience and (b) content fully commoditised.\nRemember when Netflix got into original content with House of Cards? It was a $100m investment for a new business pillar, but Netflix was able to use audience data to guarantee a win:\n\nIt already knew that a healthy share had streamed the work of Mr. Fincher, the director of “The Social Network,” from beginning to end. And films featuring Mr. Spacey had always done well, as had the British version of “House of Cards.”\n– New York Times, Giving Viewers What They Want (2013)\n\nAnd then a nationwide marketing campaign performs exponentially better than many smaller local campaigns.\nSo imagine TikTok (or whoever achieves this) doing the same: data-driven meals given simultaneous global rollout, with vast development budgets, and economies of scale for both marketing and also purchasing (you could centrally pre-purchase the world’s feta production to lock up the baked feta pasta supply for the next 12 months).\nGhost kitchens on food delivery apps shouldn’t be the lame knock-off version of established brands. This mechanism should be used to do something entirely new.\nNetflix discovered a content/audience/subscription flywheel and now we have a TV renaissance, with Disney and Amazon and Apple joining the arms-race to acquire eyeballs.\nSIMILARLY I’m into the idea of inhuman amounts of money going into food, flywheels of tastebud acquisition churning through binge-boxset meals, flagship high-production-values meals, weird niche audience meals (in the global village every niche is nation-sized), and all the rest, competing cinematic universes of cuisines being explored and transmitted via the ghost kitchen machine.\n(Independent neighbourhood restaurants will surely be fine - there’s always a market for authenticity - and I won’t terribly miss mid-tier casual dining chains.)\nHOWEVER.\nThere are some clear gaps in the online food marketing value chain, and primarily that comes down to this fact: you can’t lick a screen and taste anything except glass. With film and TV, you’re selling visual goods in a visual medium. No such luck here. Which means there’s always going to be friction between awareness and purchase.\nFixing this problem needs serious funding, and that’s why I’m into the idea of a ton of money going into the ecosystem.\nHere’s the Norimaki Synthesizer by Homei Miyashita, a researcher at Meiji University in Tokyo:\nYou lick this gadget, and the rod-shaped device is able to simulate any flavour represented by the five universally accepted basic taste sensations: sweet, salty, sour, bitter and umami.\n\nThe gadget uses five gels made of dissolved electrolytes that, when electrically charged, provide controlled amounts of each of the five basic tastes to deliver a combination of tastes to the user’s tongue.\nThe research team liken the process to optical displays that produce many colours from lights of three basic colours (red, yellow and blue).\nEach of the gels are made by dissolving five different electrolytes - sodium chloride, glycine, magnesium chloride, citric acid and glutamic sodium - in a small amount of water in separate solutions to create highly concentrated blends.\n– Dezeen, Norimaki Synthesizer device uses electrically charged gel to simulate different flavours (2020)\n\nAnd so: By adjusting the sliders, Miyashita and his research team could change and transition between tastes, including going from a sweet taste like “gummy candy” to the salty and sour taste of sushi.\nOnline ads with flavour are the missing link. Measurable, targetable, optimisable advertising for breakfast, lunch, dinner, and snacks.\nLook, it’s basic.\nBut it’s a start, right?\nI bet the first computer displays didn’t look like much either. A decade or two of progress and investment will sort it out.\n(I was complaining the lack of innovation in screens a while back. Lickable pixels would make up for that.)\nIt’s 2028. You’re catching up on TikTok and your favourite micro-influencer does their twist on this week’s latest meme meal. The recipe has already propagated across the ghost kitchen network; TikTok spotted the emerging exponential, pre-purchased ingredients, and has already pushed them to the edge so this is tasty, trendy, available right now, and also friendly to the wallet. You cautiously dab the screen with the tip of your tongue – not bad. A larger, wide-tongued doggy slurp, fully from the bottom to the top of your phone. The pixels fizz with flavour. You’re hungry. Buy it now, it’ll arrive at your door on a bike or a drone or robo-courier in 30 minutes or less, this is good, you want your dinner, one-lick purchase, boom.\n",
    link: "/home/2022/01/24/meme_meals",
  },
  {
    title: "Soviet vs Western approaches to laundry, 100 years ago",
    date: "22.06, Wednesday 26 Jan 2022",
    content:
      "Art in Revolution: Soviet Art and Design after 1917. This was an exhibition at the Hayward Gallery in London in 1971. Here’s a slideshow (Google Arts & Culture). I’ve been leafing through the catalogue.\nFrom the intro, the exhibition was an attempt to define one of the most important of modern art movements – Constructivism.\n…which was (I’m getting the impression) not just an art movement (as I previously thought) but almost like history put forward the question: what if the artists won?\nSo the Revolution of 1917 has artists doing their best work in the forum of everyday life: Let us make the streets our brushes, the squares our palette.\nAnd the propaganda posters are glorious.\nAnd the architecture too, more artists: for in architecture one can most successfully create a way of life, a new order, touching every aspect of man’s activity.\nSo I hadn’t quite got that connection between the Soviet philosophy and Constructivism.\nIt’s enticing as a prospect, I have to admit.\nArchitecture.\nArchitects tasked themselves with the double problem of improving conditions and easing congestion and of destroying the class distinctions which had shaped towns before.\nImagine class being part of the discourse today!\nThis caught my eye:\n\nLenin, at the 1919 Congress of the Communist Party, demanded the formulation of a policy of rebuilding suited to the democratic society. This included better living conditions and also educational facilities, including easy access to artistic treasures. It stressed the need to liberate women from domestic routine by offering co-operative services.\n– Arts Council, Art in Revolution (1971)\n\nI want to zoom in on that.\nBecause it implies a form of town planning, or maybe housing estate design. Shared laundry; shared childcare; shared kitchens. By hand, I’m guessing – it’s 1917, early in electrification.\nAS AN ASIDE, I want to say something about Britain in 1971.\nWhich is before I was born.\nThe impression I get is that there was a certain type of person who was, at best, on the fence about Soviet culture. Pro, possibly.\nIt was the middle of the Cold War, the USSR was clearly the enemy. But the propaganda and control of information was immense.\nSoviet culture looked like a genuine alternative to Western culture? I think that was the perspective then. It genuinely looked like a different way of running society, and it genuinely looked powerful and like it had a chance of winning.\nAnd from a British point of view, the Soviets aren’t Soviets… they’re one of the four Great Powers! The Brits and the Russians have been tussling at that point for centuries, there’s always someone in the ascendant and somebody scrabbling, and it turns over periodically. So I think there’s a kind of respect given to Russia and Constructivism that wouldn’t have been there if this exhibition had been in the US.\nNow Communism ain’t great. I’m a generation and a thousand miles removed, and I’ve spoken recently with people much closer to it than me – really not great at all.\nBut reading this exhibition catalogue, I come away with the view that the authors don’t know who will come out on top: the Soviets or the West; Communism or Capitalism. Nothing for them - not the west, not capitalism - is inevitable, so it’s a very different read than we’d get nowadays, now we know how the story progresses.\nLet’s go back to the town planning thing.\nBecause the Western alternative to co-operative services, in terms of “liberation” from the domestic routine, is consumerism.\nThe first couple of decades of the 1900s was the story of electrification and the fractional-horsepower motor (Wikipedia). The technology of the factory came into the home, and: By 1920, over 500,000 fractional-horsepower motors were powering washers and other appliances in America.\nHere’s French sociology Henri Lefebvre on the topic, as told by Rob Shields:\n\nIn France after the First World War, factory work was reorganised by rationalising production and streamlining workplace activities. Everyday life was affected by a similar impetus towards rationalisation and efficiency. One example that Lefebvre noted was the scientific redesign of the kitchen and the large-scale intervention in housework by corporations. Advertising discourses of rationality appealed to ‘science’, to time management and to efficiency understood as the reduction of effort. Ironically, at the same time, new tasks became expected parts of household labour, thus consuming all the time that was freed by, for example, self-stoking coal furnaces or gas cooking stoves, which replaced wood-fired appliances, which has to be tended. The everyday life of the nuclear family became the norm as mothers were portrayed single-handedly managing the household to high standards of care, nutrition and hygiene while husbands worked for wages elsewhere. This new form of the household was marked by its isolation and non-cooperation with other kin or nearby families.\n– Rob Shields, Lefebrve, Love and Struggle: Spatial Dialectics\n\nSo this is a very different lived experience from the Soviet aspiration of co-operative facilities for domestic life.\nIt’s a kind of town planning by stealth, an intervention by technology and corporations (i.e. consumerism) that promotes atomisation rather than community.\nI’m not making a statement about which is better or worse – who knows what confounding effects there are, or how things play out in the long term, or the difference between what we’re told and what was really happening. I wouldn’t have wanted to live under Communism (though I would love to give artists another shot at sorting us out).\nHOWEVER – it strikes me:\nLooking from the perspective of 1971 at how these two cultures approached, say, what it’s like to do your laundry, you would identify a real separation in outcomes. One from the perspective of the other is science-fictional, alien!\nI find this juxtaposition simultaneously\nONE: reassuring that whenever I talk about abstract things like politics or technology, it’s valid to have as a starting point a focus on the human, like: do we want people to spending more time with their communities or not so much; and that real difference is in fact possible;\nAND TWO: mentally destabilising that such fiercely different cultures existed as valid alternatives within living memory, and as such the concrete inevitability of our current culture may not be as eternal as it looks and in fact could be undermined or feel significantly more temporary in a simple instant.\n",
    link: "/home/2022/01/26/soviet",
  },
  {
    title: "Morning notes",
    date: "10.22, Friday 28 Jan 2022",
    content:
      "This morning is the first time I’ve been out of the house in 10 days (Covid) so I went for a walk, grabbed a coffee.\nThe sheer wonderful sensory overload of it all! The birdsong, sure, and the cold air on the skin. By the time I sat on the bench outside the coffee shop I was noticing the wisps of steam from buildings in the distance, my visual field having that uncentred fractal depth of a Burtynsky photograph, and the changing soundscape around me of bikes and people walking by on the phone; and the sugar and soft give, biting into the cannelle and the bitterness of the coffee.\nThe everyday anew.\nChatting with the barista I found similarly fresh, and I find myself thinking now about community and that our sense of sociality, togetherness, is as much of a sense as any of the others, conversational interaction no different from sound waves or photons.\nI went back and read John Perry Barlow’s A Declaration of the Independence of Cyberspace from 1996. Here’s the gist:\n\nGovernments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather. …\nI declare the global social space we are building to be naturally independent of the tyrannies you seek to impose on us. …\nCyberspace does not lie within your borders. …\nWe are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force, or station of birth. …\nYour legal concepts of property, expression, identity, movement, and context do not apply to us. They are all based on matter, and there is no matter here. …\nWe will create a civilization of the Mind in Cyberspace. May it be more humane and fair than the world your governments have made before.\n– John Perry Barlow, A Declaration of the Independence of Cyberspace (1996)\n\nPunchy!\nYes punchy even for 1996, but I remember feeling pretty much like that too in the mid 90s.\nBUT it turned out that cyberspace is in fact tethered to matter, and therefore to geography, and therefore to government, in two ways: one, our bodies; two, the physical infrastructure of the internet.\nAnd it turns out that what got built very much resembles what humans collectively build in the early 21st century. We built a city. Like London, the internet is mostly privatised public space; with a small number of grand semi-public institutions propped up by traditional mainly; law and order maintained by psychologically panoptic surveillance rather than civility or community policing, and even then there’s a non-trivial black economy and there’s a bunch of crime so you need to have your wits about you; significant class differences encoded in the architecture.\nIs the internet what we would have built in 1950? 2050? Probably not. It represents our time.\nSo of course I dug this out because there are similarly punchy statements about the independence of the new internet, this time from the incumbent corporations and financial systems. I’m talking about crypto and web3 of course – it’s decentralised, it’s self-governing, it’s not (or shouldn’t be) subject to existing regulation, and so on.\nAnd maybe that’s a mistake? Instead of declaring or assuming independence, focus on the kind of society we can build with these new technologies, and the way the trajectory of our society can be inflected and toward what values, taking as a starting point that it will of course be enmeshed with the existing real world.\nAfter posting about Soviet (community services) vs Western (household automation) approaches to laundry earlier this week, I learnt about The Washing Machine Project (thanks @cadars):\n\n70% of the world’s population lacks access to an electric washing machine.\nHandwashing clothes sounds like a simple task but for many women around the world, it poses a significant obstacle to their wellbeing and livelihood.\nBy providing displaced and low-income communities with an accessible, off-grid washing solution, our mission is to empower women with the time to take charge over their lives.\n– The Washing Machine Project, Our Mission\n\nThis has caught my imagination as a general algorithm for progress: identify the cheapest way to create surplus hours for the largest number of people; do that; repeat.\nBecause there are other ways of lifting up communities around the world – public health initiatives, access to the internet for education and jobs, etc.\nBut there’s something really direct about about a focus on surplus hours. Which can be gained from reducing domestic labour (like this project) or by working on health (reducing family care overhead; extending lives). Same same, underneath it all. And hours in the day is what you need to do anything else; time is the ultimate constraint.\nThe metric for intervention includes cost, so you would look at: hours gained per million dollars spent. Economic utilitarianism (is that what we would call this?) is a blunt instrument but it would be fascinating to see different approaches stacked up.\nOn with the day! Gm as the kids say.\n",
    link: "/home/2022/01/28/morning_notes",
  },
  {
    title: "Filtered for blue in history",
    date: "20.05, Monday 31 Jan 2022",
    content:
      "1.\nPink for a girl, blue for a boy. Hey, so once upon a time it was the other way round, right? That’s what they say. Was it really?\nAlex Mitchell deep dives into colour in #feministfriday episode 375 and digs out actual references. Fascinating. Read it.\nSPOILER, the association was ambiguous in 1923: There seems to be considerable support of each colour for girl babies and each for boy babies (from the Altoona Tribune.)\n…and honestly it is pleasing that there was no agreed-upon association, historically, versus there being gendered colours any which way.\n2.\nElise Blanchard at Mozilla provides a history of links in hypertext applications, such as the web itself:\nWhy are hyperlinks blue?\n(Or at least: that’s the default colour set by web browsers, before websites add their own style.)\nHere’s the moment for browsers: April 12, 1993 – Mosaic Version 0.13, from the release notes:\n\nChanged default anchor representations: blue and single solid underline for unvisited, dark purple and single dashed underline for visited.\n\nAnd then a follow-up from Blanchard: Revisiting why hyperlinks are blue.\n…which digs even further back into hypertext research:\n\nBen Shneiderman developed the highlighted selectable light blue link, which was implemented by graduate student Dan Ostroff. In doing so, they, as well as other students, tested many versions in controlled experiments. \n“Red highlighting made the links more visible, but reduced the user’s capacity to read and retain the content of the text… blue was visible, on both white and black backgrounds and didn’t interfere with retention,” Shneiderman shared with me.\n– Elise Blanchard (Mozilla), Revisiting why hyperlinks are blue\n\nI love that the testing is cognitive: blue is good for reading and retaining.\nBUT, I would want to push even further back. Why does blue make sense for hyperlinks?\nI’ve talked about this before (2005): blue is the colour of a television tuned to a dead channel; it’s the colour of the open sky. It’s the colour of potential.\nSo of course the hyperlink, a leap into the unknown, should be blue.\nALSO:\nI love that hyperlinks, by default, go purple if you’ve previously visited the linked webpage. It maps onto the cognitive sense of “recognition” that we often (but not always) automatically feel when we see a person that we’ve talked to before.\nWhat would it mean to see purple auras when you glimpse a person you’ve talked with previously? How many familiar strangers would you pass on the street that otherwise you wouldn’t notice? An app for future augmented reality smart glasses perhaps…\n3.\nWhy do police cars and ambulances have flashing blue lights?\n\nThe use of the blue emergency light originates in Germany during World War II. As a result of the ‘Verdunkelung’, a black-out measure for aerial defense from 1935, cobalt blue was regulated to replace the red color used until 1938 in emergency vehicle lights. Due to the scattering properties of the blue color, it is only visible to lower altitudes and is therefore less easily spotted by enemy airplanes.\n– Wikipedia, Emergency vehicle lighting\n\n4.\nBlue Monday by New Order was released in 1983. It is the best-selling 12” single of all time (Wikipedia) and was composed on a prototype-level homebrew “step-time” sequencer in binary code.\nSynthesisers had been around for a while, but this track absolutely busted open the potential of the instrument and bridged us into dance music.\nAND SO…\nWatch this: Orkestra Obsolete play Blue Monday using 1930s instruments (YouTube).\n(The elapsed time between Blue Monday till now being almost as long as the 1930s to Blue Monday, which is… alarming.)\nI don’t know about you, but that video reminds me just how WEIRD electronic music really is.\nAll those repetitive beats!\nIn particular: popular music didn’t sound like Blue Monday when those instruments were around.\nWhy not? It could have been done, per the video.\nIs it that music emerges from cultural templates? Was electronic music in the 1980s, with its looping sequences and transcendent states a cultural anticipation of the upcoming Information Age, all streams of binary signals and virtual realities, some kind of Jungian synchronicity with the world at large?\nI don’t think so. We could make the same argument for the 1930s, had Blue Monday emerged then, the beats representating peak industrialisation and the drumbeat of impending war; the psychological effects of the music reflecting the hedonistic escapism of the time.\nInstead perhaps music is an exploratory probe, each track a scout through the dynamic space of possibility suggested by the instrument as a specific thing. Blue Monday as a natural unfolding of the synthesiser itself.\nSo to invent entirely new music, invent new instruments?\n",
    link: "/home/2022/01/31/filtered",
  },
  {
    title: "Maybe buying and selling colours isn’t entirely nonsense",
    date: "21.00, Tuesday 1 Feb 2022",
    content:
      "There’s a new project called Color NFTs in which you lay down real cash money to buy and sell colours, and get a cut when that colour is used, so if you owned some specific murky red and the next Rothko appeared and started making electronic art, you would be proverbially quids in.\nWhich is ridiculous. But fascinating. But ridiculous. But fascinating.\nBECAUSE, well, I have to divert into platform capitalism and meme stocks for a minute.\nOkay, we’re used to the idea that engineers at Uber get a stake in the company in return for working there (in the form of stock options). So they share in the upside as the company grows.\n(It could be any company but let’s stick with Uber.)\nThen it’s not much of a stretch to say that Uber drivers should also get a stake. They’re practically employees.\nThen why not also Uber passengers?\nUber follows the principles of Nick Srnicek’s platform capitalism: it gathers data from its captured marketplace, uses that data to drive marketplace activity (by ever-more-efficiently directing drivers and attracting passengers), and uses marketplace growth to capture even more data. It’s an engine.\nAnd what that means is that passengers contribute as much to growth, in their way, as engineers and drivers.\nOk, so with every ride and with every referral code shared, a passenger should get a fractional amount of stock in Uber. A share in the upside.\nRight!\nMaybe Uber drivers aren’t quite employees, and aren’t quite independent contractors, but they’re a new category of worker (as previously discussed) and they also run their own businesses too. So perhaps that is an equity swap that takes place – the driver ends up with a micro-stake in Uber, but also Uber ends up with a micro-stake in the driver. So there’s a kind of mutualism. Uber ends up being incentivised for the long-term success of its worker community.\nAnd another wrinkle:\nIt’s not pleasant to picture Uber drivers as being “Below the API”, analogous to commoditised subroutines in the software that runs the app, but it’s a solid way to understand what’s going on.\nLean into that analogy for a second… if Uber drivers deserve ownership-mutualism, and Uber drivers are like software, and Uber itself is built from software - mainly open source software - then surely the open source software used in the Uber app and website also deserves a stake in the company? What does it mean to give startup stock options to a website deployment tool?\nAnd what about the roads on which Uber cars drive? They’re funded by city taxes. Why not pay taxes 99% in cash, and 1% in Uber stock, divided up geographically by mile of road driven?\nWhy not share in each other’s success?\nKeep unfolding this, to more companies and more participants.\nI get a picture of a network of mutual dependency – a mutualism graph if you like, just as Facebook is a nodes-and-links graph of people, and the Google index is a graph of webpages.\nMutualism is usually a left-wing idea. What I mean to say is that mutualism also appears from the economic right. There’s a glimpse of it in meme stocks – everything is a meme stock now; the stock market creates cults as stock owners are highly incentivised to indulge in boosterism, whether that’s Tesla or Patagonia.\nAnd just as the wealth of the stock owners is dependent on the success of the company, the company is increasingly dependent on the support (and evangelism) of its stock owners.\nAside from the cult-like incentives, meme stocks are the endpoint of something which has been true for a while about consumerism: as politics gets less able to shape society, votes get devalued. So people have realised that a $1 spent is a vote for the world you want to live in.\nAutomate it.\nCall it networked value.\nPay $1 for an Uber ride and see that dollar ripple out to the engineers, the drivers, the technology stack, local government… and see the value reflected back in the micro stock option you’re granted, which has dependencies on that whole network too.\nEnter: Color Museum, the organisation behind Color NFTs.\nWhich launched a few days ago and has been widely mocked online ever since. It has been turning around and around in my head.\nYou “buy” a colour, for actual money.\nAnd then:\n\nEarn royalties from your colors.\nWe are building an OpenSea competitor in which transaction fees are shared with Color NFT owners based on the proportional use of their colors in traded NFTs.\n\nLet’s unpack that:\n\nAn NFT is a way to attach rights, such as ownership, to digital assets. An NFT is like a widely accepted receipt to which you can attach software.\nDigital assets such as… art. There are lots of artists making wonderful art, and selling it as NFTs! There are all kinds of vibrant marketplaces! Some arts have gotten pretty rich! Not all.\nOpenSea is one such marketplace, a very big one. The traders are richer than the artists.\nBut #1: the marketplaces are often full of scams – the people trading the NFTs are quite possibly involved in some kind of baroque pyramid scheme.\nBut #2: at least the NFTs are backed by beautiful art, right? Not always. Anything can be turned into an NFT, including stuff you completely make up.\n\nSo the idea of a marketplace to own and trade colours is like buying and selling the ghosts of ghosts.\nWhich is why Color Museum has received the reaction it has.\nBUT.\nThe idea of Color Museum is that they will provide a platform to trade art, and take a 1.25% fee on each trade, and then split the fee according to the “owners” of the colours on the platform.\nIt’s… moderately absurd? Any more absurd than the owners of Sotherby’s getting a share in the profits generated by the take on auctions? Dunno.\nWhat makes it interesting is that it’s an automated way to share value with a network of dependencies. That’s the abstract machine.\n(It is interesting to make a habit of trying to see the bad in ostensibly good things (practices we call things like critical thinking and horizon scanning) but also to see the good in ostensibly bad things.)\nI would be more interested if Color Museum went further:\n\nWhat if Photoshop, Blender, and so on also existed as NFTs, and they got a cut of the value when art made using their software was sold?\nWhat if the value of a trade cascaded to red, and green, and blue, and Blender, and the sponsors of Blender, and the software libraries Blender depends on, and so on and so forth.\nWhat if, by creating your art with Blender, you got a share in the upside of Blender too, in return?\n\nFrom the perspective of the underlying smart contracts it’s all the same.\nValue is networked. And what NFTs do is open up the conversation about how that works.\nMaybe we can stop thinking that a transaction is a one-off swap - value in cash one way countered by value in goods the other - and start thinking about a transaction as establishing an ongoing hyperlink of mutualisation, a share for all ships in the upside of the rising tide.\nIt’s ugly to reduce everything to monetary transactions. But if instead we can see these systems as prototyping the platforms for how to implement mutualism in the real world, and providing us with illustrative examples to discuss it… well.\nSo Color Museum is simultaneously bullshit and possibly a wild money-grabbing scam but also a tool for mentally exploring the potentialities of networked value, and it can be both at the same time, I’m into that.\n",
    link: "/home/2022/02/01/mutualism",
  },
  {
    title: "The ancient Thames",
    date: "15.45, Friday 4 Feb 2022",
    content:
      "London is a low river valley, sloping gently towards the Thames as it runs east towards the sea.\nI remember reading (I forget where) about Oxford Street which, when you ride the bus, you’ll notice rises up, dips down, rises up, dips down, as you travel from west to east.\nYou’re north of the Thames, and every time you dip down you’re crossing an old tributary to the river, now buried.\nHow London’s Rivers Got Their Names (Londonist) – there’s a map of the old rivers here. And some photographs too… of tunnels, or metal pipes bridging over canals, the ancient stream encased.\nIt is poignant reading their names.\nTributary rivers to the Thames, from the north, west to east:\n\nStamford Brook\nCounters Creek\nWestbourne\nTyburn\nFleet\nWalbrook\nHackney Brook\nLea\n\nAnd from the south:\n\nBeverley Brook\nWandle\nFalcon\nEffra\nNeckinger\nEarl’s Sluice\nPeck\nRavensbourne\nQuaggy\n\nI recognise some of these names for when they’ve been used as neighbourhood names (I live near the head of the Peck in Peckham). Some I’ve found while walking. You follow an path between houses off a street and realise that you’re tracing a slow trickle of a street. Then you find a sign and it’s what is left of the Quaggy, or whatever.\nOtherwise it’s like hearing magic spells spoken in an almost forgotten language. I don’t recognise the name but at the same time they are intensely familiar – I’ve heard them whispered from the rocks while I sleep.\nThe Thames is also known as River Gulu.\n\nA Ugandan ‘explorer’ has joined the vaunted list of European adventurers such as Johannes Rebmann and Johann Ludwig Krapf who are credited with discovering Mt Kenya in 1849.\nMilton Allimadi last week on April 23 [2019] made a nature discovery in London, UK and wasted no time in giving it a ‘proper’ name.\nCheeky Allimadi said he had discovered a river in the heart of the Queen’s Land and named it River Gulu. That river is the famous River Thames.\n– Nairobi News, Great African explorer discovers ‘River Gulu’ in London (2019)\n\nThe Gulu runs into an area of the North Sea that until 8 thousand years ago was dry land: Doggerland (Wikipedia).\nSome of it was low-lying, some at the north end was hills: The Dogger Bank, an upland area of Doggerland, remained an island until at least 5000 BCE.\nIf you have 54 minutes, listen to this episode of In Our Time about Doggerland.\n(More maps and speculation here: If Doggerland Had Not Drowned.)\nDoggerland was populated. Since the 1990s, undersea archeology has been learning about the area from millions of years ago to the comparatively more recent Mesolithic.\nThe Thames came into Doggerland in the south of the region, flowing west to east, joining up with another great European river, the Rhine, then turning south and joining what is now the English Channel but then a giant estuary betwixt Surrey and Normandy flowing into the Atlantic.\nFrom In Our Time the impression I get is that Doggerland was the economic centre of Northern Europe. I have a picture of rich, fertile land; green rolling hills and forests and lakes and rivers, a wealthy population – sophisticated, creative, vibrant. A hunter-gatherer equivalent of New York, Lagos, London, Atlantis, drawing in the bright-eyed and ambitious. Sunken these past thousands of years. And we’re gazing inward now from the shore at the grey water which holds its own counsel regarding the gone world beneath, living out our lives on this desolate, impoverished periphery of a heart now gone.\n",
    link: "/home/2022/02/04/the_thames",
  },
  {
    title: "Singularities and jackpots and fugues",
    date: "21.00, Wednesday 9 Feb 2022",
    content:
      "I’ve been thinking about the stories we tell ourselves about how the world ends. Specifically: plausible and convincing ones.\nSo here are three examples from sci-fi. SPOILERS ABOUND.\nThe Singularity\nClearly, technology gets better: AI, biotech, robotics, energy, etc. Better technology makes technology get better quicker, so now we have a runaway feedback loop – progress accelerates and accelerates and accelerates until, boomf, we all become gods.\nSci-if author Vernor Vinge spotted and named this, and here he is in 1993 (the essay was also published in the Whole Earth Review):\n\nWhen greater-than-human intelligence drives progress, that progress will be much more rapid. In fact, there seems no reason why progress itself would not involve the creation of still more intelligent entities – on a still-shorter time scale. …\nFrom the human point of view this change will be a throwing away of all the previous rules, perhaps in the blink of an eye, an exponential runaway beyond any hope of control.\n– Vernor Vinge, The Coming Technological Singularity (1993)\n\nPeople get terribly excited about the singularity + exponential growth today (there’s a university about it, etc).\nI think I first heard of the Singularity in maybe 2004/5 and my sense is that it was A Big Deal till maybe 2015 at which point it transitioned into being… accepted.\nInevitability! That is part of it. Vinge again: I have argued above that we cannot prevent the Singularity, that its coming is an inevitable consequence of the humans’ natural competitiveness and the possibilities inherent in technology.\nThe inevitability is convincing. Everywhere you look you spy evidence that we live in the foothills of the Singularity.\nBUT what this downplays is that, from the perspective of the people living through it, the Singularity is an extinction.\nVinge named the Singularity in his 1986 novel Marooned in Realtime (Amazon) – which is AMAZING (pick up The Peace War first; the two books read very differently but Marooned is definitely the second in the duo logy).\nMarooned in Realtime is told from the perspective of the far future.\nMysteriously all of humanity seems to have vanished sometime in the 2200s. Just… disappeared.\nThe event is first understood as the Extinction… but then a new theory comes up. Humanity had gone exponential:\n\nHave you see the mines the Korolevs built west of the Inland Sea? They stretch for dozens of kilometers–open pits, autons everywhere. By the late twenty-second century, that’s the scale of resources demanded by a single individual. Science gave each human animal the presumption to act like a little god. … This was an exponential process. Moving into space just postponed the debacle a few decades.\n\nWe meet a bunch of fast-forward time travellers in the deep future, and we see them getting more and more high-tech, faster and faster, the closer their period of origin is to the singularity moment itself. The closest is from 2210. After: no-one.\n\nBy 2200, we could increase human intelligence itself. And intelligence is the basis of all progress. My guess is that by mid century, any goal–any goal you could state objectively, without internal contradictions–could be achieved. And what would things be like fifty years after that? … It was a Singularity, a place where extrapolation breaks down and new models must be applied. And those models are beyond our intelligence.\n\nSo the Singularity is not glorious. It is an ending.\nArchaeologically the planet is in ruins. It is abandoned. One of the characters calls it Graduation Day – and they missed the boat.\nThe post-human era (for us humans) is a desert.\nThe Jackpot\nHere’s another, from The Peripheral (Wikipedia) by William Gibson, 2014.\nThe end of the world: he’d started to explain what he called the jackpot.\nIt’s not a single thing. It’s… everything.\n\nAnd in fact the actual climate, the weather, caused by there being too much carbon, had been the driver for a lot of other things. How that got worse and never better, and was just expected to, ongoing. Because people in the past, clueless as to how that worked, had fucked it all up, then not been able to get it together to do anything about it, even after they knew, and now it was too late. …\nNo comets crashing, nothing you could really call a nuclear war. Just everything else, tangled in the changing climate: droughts, water shortages, crop failures, honeybees gone like they almost were now, collapse of other keystone species, every last alpha predator gone, antibiotics doing even less than they already did, diseases that were never quite the one big pandemic but big enough to be historic events in themselves. And all of it around people: how people were, how many of them there were, how they’d changed things just by being there.\n– William Gibson, The Peripheral\n\nI remember needing a long stare out of the window after reading this sequence. Again that sense of inevitability.\nIt’s realistic in the telling. Technology improves but it’s not enough. Humanity survives but it’s only the rich. My reaction reading about the jackpot was a kind of, oh yeah, that’s it, yup.\nPersonal anecdote about The Peripheral: there’s a sequence in the post-jackpot future where they’re walking along post-jackpot Oxford Street, east to west, in post-jackpot London, ruined buildings cut and smoothed by nanotech, trees run rampant. They pass Marble Arch.\nAND, as I was reading this book about parallel timelines, present and future, I was sitting on the number 94 bus, top front, riding east to west just the same, and I too passed Marble Arch, a wonderful coincidence, and these realities - present, future, fiction - came together in my head, a lamination, and for a few hundred yards (a bus stop or two at least) I was in all three simultaneously.\nIt is WILD that William Gibson may end up being better known for coining “the jackpot” than “cyberspace.”\nA man who is able to retrieve objects from the other side of the bridge.\nI can’t tell whether it’s good or bad to have these oh-so-resonant prophecies hanging around?\nWhat they have in common is that, when you hear about the Singularity (titlecased by Vinge) or the jackpot (lowercased by Gibson), you see confirmatory signs everywhere.\nSIMILARLY: the consensus cosmogony in 1950s science fiction. When people went into space, and then landed on the Moon, it was easy to see that as confirmation of the first steps of this future history – and therefore a reason to believe in the inevitability of visiting the stars, and a future Galactic Empire (ugh).\nSo the story starts feeling like destiny. At which point we all start encouraging the bits we want and no longer resisting the bits we don’t?\nOR: is it useful to have such stories, provided they have only a limited amount of inevitability?\nConsider some real stories of the end of the world.\n\nNuclear apocalypse – when I was 10, it wasn’t just something I imagined. It was clear to me that, by the time I became the age I am now, I would be living in a post-apocalyptic nuclear wasteland.\nThe climate crisis – ongoing.\n\nThe optimum amount of belief to have is wide understanding but without acceptance. As a society you need to retain the belief that something can still be done.\nCompare Y2K I suppose. The ideal outcome is that everyone looks around after the event and says, huh what a fuss about nothing, without realising that a ton of people worked really really hard.\nDoes a story such as one of these always become a self-fulfilling prophecy like a civilisation-scale Moore’s Law – a kind of vast Schelling point in the future? For good or ill?\nI think what we’re missing rn is a story that gives us a path out of (waves hands) all of this.\nNot a utopia so much as something which shows the hand of history leading us toward fairness, abundance, planetary balance, and so on. The journey not the destination.\nOh yeah so I’ve been listening to That Funny Feeling by Bo Burnham a bit too much this week. Here’s Phoebe Bridger’s cover (YouTube).\n\nFemale Colonel Sanders, easy answers, civil war\nThe whole world at your fingertips, the ocean at your door\nThe live-action Lion King, the Pepsi Halftime Show\nTwenty-thousand years of this; seven more to go.\n\nOof.\nCultural Fugue\nOne of my favourite apocalypses is from Stars In My Pocket Like Grains of Sand (Wikipedia), Samuel Delany’s space opera/erotic love story/semiotic laboratory experiment/top 10 fave books ever.\n\nFor a world to go into Cultural Fugue–for the socioeconomic pressures to reach a point of technological recomplication and perturbation where the population completely destroys all life across the planetary surface–takes a lot of catastrophe. There are more than six thousand worlds in the Federation of Habitable Worlds. And Cultural Fugue is very rare.\n– Samuel Delany, Stars In My Pocket Like Grains of Sand\n\nIt is a mystery. People see signs of it anywhere and everywhere, and are terrified, but the actual mechanism is unknown – it appears to be a runaway social process that results in the self-destruction of an entire planet.\nFire fell from the sky. Deserts melted to slag. Urban complexes, runs through the wild, and tribal federations were scorched away like flavors burned out of over-charred foods. Cultural Fugue, perhaps.\nCultural Fugue seems opaque and its causes absurd and then I look at the way that the UK and the US are both tearing themselves apart, and I think of Easter Island and I think of this.\nIt doesn’t have as much resolution as the other two so it’s not as actionable in a funny sort of way. You just read the news and shudder.\n",
    link: "/home/2022/02/09/apocalypsi",
  },
  {
    title: "Playing board games, thinking about Excel: Wingspan Edition",
    date: "18.06, Friday 11 Feb 2022",
    content:
      "I’ve been playing pandemic-breakout-hit board game Wingspan recently.\nI kinda sorta wanna to see this gorgeous and hand-drawn ecology-fostering approach baked into financial modeling software, such as Microsoft Excel.\nYour job in Wingspan to populate your wildlife refuge with birds (each a beautifully illustrated playing card). Birds cost food and an increasing number of eggs. You can gather food and lay eggs, the quantities of which are dependent on your population of birds.\n\nWingspan is what’s known among serious gamers as an “engine-building game,” which means that as the game goes on, the combination of birds you play becomes more and more efficient at generating points each turn, like an engine running faster and faster. Your cuckoo lays eggs, and the eggs not only give you points but make it possible to play more birds, which also give you more points but have their own powers that generate points in other ways.\n– Slate, How a Board Game About Birds Became a Surprise Blockbuster (2021)\n\nAn engine builder. As opposed to “roll-and-move” and other mechanics.\nAnd: Activating the cascading effects of these healthy interconnections is the greatest pleasure of playing Wingspan.\nThe precise goals vary each game, for added fun, and there are a ton of birds, which all bring something different to the table. Like: bird such-and-such wins you 7 points and costs 3 of these particular foods and can fit 4 eggs in its nest and has a special power in that it encourages other birds to lay extra eggs too under whatever particular conditions.\nGetting this right is why the game works, and it was hard work: It’s those interconnections that [Elizabeth] Hargrave began mapping out in a ginormous spreadsheet once she decided she really did want to design a board game.\n(Here are some good Wingspan strategies.)\nWhat I don’t enjoy about Wingspan is that there are a ton of rules.\nThe cards and tokens (food, eggs) are merely indexes into the real game board, which exists only virtually, in rulespace.\nHargrave’s fearsome Excel spreadsheet is ever-present, hidden behind the curtain.\nCompare with say Chess or Go. There are rules, sure, but they are relatively minimal. The state of the game is told more by the physicality of the pieces on the table.\n(Game theorists must have mathematics to describe this different. I would like to know!)\nSo I would like to play another version of Wingspan in which the rules are somehow implicit in the physical geography of the pieces, instead of being written down on the cards and in the rulebook. I don’t know what that would look like.\nYou get a sense of acceleration in playing an engine builder!\nHere’s a great article from a game design perspective – how to harness the acceleration… but also how to slow it down: Engine Building (2019) on Make Them Play: Learning About Board Game Design.\ne.g.:\n\nThe challenge is much more in balancing your engine. One major problem with an engine is that it can “run away”: If you can turn resources into more resources then whomever has a minor head start can quickly leave all other players behind without hopes of catching up. \n\nIt’s a very 21st century genre, right?\nFor example: building a startup is never about building the product. It’s about building a machine that knows how to ship product and how to sell it and how to use feedback to iterate it. And that knows how to grow itself as an organisation.\nLike, consider the Business Model Canvas (as previously discussed) – as a way of describing a startup on a single sheet of paper, it’s practically already a circuit diagram.\nAlso think about community development: how do you build a community which goes out and attract more community.\nAn engine that simply accelerates is entertaining to experience, but the joy is in the meta design – how do you create conditions such that player builds engines that don’t blow up?\nHow do you create a startup or a community which grows in depth and complexifies, but doesn’t churn out or ossify? Wiring up the feedback loops, balancing the world. How do you make an ecology which expands when appropriate and renews yet remains heterogeneous and manageable?\nAnd ecosystems truly are a 21st century preoccupation. With the climate crisis and its runaway feedback loops, and pandemics with their exponentials, and social media with its virality, this isn’t like the old days of the industrial revolution where the plumbing was steam and electricity – relatively manageable stock and flow. No, we’re trying to manage circuits and networks of lashed-together exponentials; unstable equilibria all round, if you get it wrong then systems explode or die before you blink. Tread either carefully or really, really fast.\nHobbies in this Wingspan world are things like bonsai and terrariums – games of ecopoiesis: a new word which means ‘the making of an abode for life’, said biologist Robert Haynes in 1993.\nI wondered before about giving out bonsai trees at business school to see what mindset they impart – and I’m wondering more directly now: what is Microsoft Office but designed on terrarium principles? What would it be like to work in Excel: Wingspan Edition?\nI’ve been looking at liquid computing recently, specifically the MONIAC (Monetary National Income Analogue Computer) a.k.a. the Phillips Hydraulic Computer a.k.a. the Financephalograph, invented by Bill Phillips in 1949. They’ve got one in the London Science Museum:\nThe MONIAC is a model of the British economy built as a two-meter tall machine with a water tank at the top and equations modeled using pipes, valves, tanks and pumps.\n\nBill Phillips used water to represent money as it flowed around the economic system. Valves could be opened or closed to represent variable effects, such as the rate of interest on savings or investment.\nGraphical curves, describing things such as the way interest rates varied over time, could be cut into plastic sheets and physically ‘read’ by the machine as it operated.\n– Science Museum, How Does the Economy Work?\n\n(There’s a great video at that link too.)\nAs a liquid computer, it was an empirical way to solve the equations to arrive at something balanced, i.e. where you don’t end up with an empty or overflowing treasury tank.\nAnd so: When a set of parameters resulted in a viable economy the model would stabilise and the results could be read from scales. (From Wikipedia.)\nALL OF WHICH MAKES ME ASK:\nIsn’t the lesson of MONIAC that it is interesting to build financial models that are seeking balance (or at least, are evolving slowly enough that they can be managed) not necessarily ones that are trying to go perpetually up and to the right?\nWhat would it means to have a version of Excel that was always iterating in the background, always running the engine, giving you a readout of whether your model would blow up over time, or whether you were tuning it towards balance?\nSo, imagining this: every sheet would automatically come with an infinite stack of sheets of how it evolves over time. Every non-formula cell would default go to zero unless you declared an external conduit, a value which would be added or subtracted per tick of the clock. Constant numbers would be banned: everything has to come from somewhere.\nA special function would colour-code a cell according to whether it diverged to infinity, converged to zero, or remained stable over time.\nYou get to write only onto the t=0 initial conditions top sheet.\nElizabeth Hargrave repurposed Excel to design an engine-builder that doesn’t lead to runaway inequality between players and doesn’t rapaciously consume the game board, yet leads to collaboration and complexity over time. What if we built the ideal version of Excel for her, and gave that to MBAs to build their companies?\n",
    link: "/home/2022/02/11/wingspan",
  },
  {
    title: "What a neighbourhood bank is, 2022 edition",
    date: "17.54, Monday 14 Feb 2022",
    content:
      "In the window of a bank branch near my house is a poster with a grid of a dozen large QR codes. I snapped a pic when I saw it on Saturday. Here it is on Instagram.\nThis branch of Barclays is on a busy neighbourhood high street, and right by the junction where the market is. So lots of passing footfall. And it was Saturday, so the branch was shut.\nInitially I thought the poster was absurd - and it looks weird - but actually it’s genius.\nThe explanatory copy says:\n\nThe Barclays app makes it easy to manage your account … The following QR codes will take you to a ‘How to’ video of help on each topic.\n\nThen the topics are:\n\nDownload the Barclays app\nManage your standing orders\nMake a payment\nOpen a new account in the app\n…and eight more.\n\nThat’s a bank branch now!\nCouldn’t the app be, you know, well designed? That way people would know how to do these things?\nWell, kinda. However: DISCOVERY.\nIf you don’t know that the Barclays app can do those things, why would you open it? Websites and apps are great at performing tasks and bad at discovery. That’s why we have search engines and ads.\nI’m not even a Barclays customer! Even if I were the sort of person that browsed the menus of my banking app, which I kinda am actually, I’m not the sort of person that speculatively downloads the apps of other banks to see what they can do.\nSo this poster\n\nhas informed me (and other people walking by or lining up to get cash from the ATM) what Barclays does. QR codes are really noticeable compared to more elegant-but-invisible solutions like NFC tags.\nis reaching its target customers - the demographic of people in my neighbourhood - enormously efficiently.\n\nThe cost of getting a new customer via advertising/PR/etc is called the Customer Acquisition Cost, CAC. For online businesses that mostly means targeted online ads, and that mostly means Facebook. Facebook is very good at squeezing as much cash out of advertisers as possible.\nBUT – what if, instead of Facebook ads, you open a shop? Physical retail. And people just… walk past? And pop in? Which is what online retailers are doing,  from Amazon down. Hence the line: Rent is the new CAC. (Which is maybe not quite as true as it was given the pandemic, but there’s something in it.)\nI mean – I wonder how it stacks up, if you do the maths on it all? You need a branch to host the poster, so absorb that into the cost. So that’s punchy. But the alternative is billboard posters for new customers PLUS a punishing experience of notifications for existing customers to tell them what the app does… The poster of QR codes might be a bargain.\nBarclays recently closed their Hackney branch and opened a pop-up in a shipping container nearby (Boxpark is a stack of containers on a busy corner populated by small retailers and lunch spots.)\nMaybe that’s what a branch is now? A poster of QR codes and a person in a car park shipping container with a Calendly?\nI… wouldn’t object.\nA bank branch can just be a paper poster wherever there is footfall.\nLet’s go further! Post me a letter once a month with QR codes for all my recurring payments, shortcuts into the app to edit them. Give me a chequebook when I open my account which is just a book of post-it notes to put around my desk, all with the QR code to open the app to the payment screen.\nThere is something wonderfully direct about this.\nI think there’s lessons here for all kinds of ads and discovery: food ads should include a QR code to push the item to my online grocery shopping basket (ok now we need an intermediary which can deep link across all online food retailers); phones could come with a little service directory booklet full of codes.\nAll of which is a reminder that customer acquisition does not stop with acquisition. The story does not go: marketing to purchase, and done.\nIt goes: marketing to purchase to customer success.\nToday’s adtech world is so much built around that first step - getting the purchase - that perhaps it has been forgotten that a customer who knows how to maximise their benefit from the purchase will also be a happy customer, and therefore more like to refer.\nWould you mind seeing a Facebook ad reminding you how to use a feature on the dishwasher you bought six months ago, with a QR code to specifically that feature that you can right-click into your photo library?\nAnd ALSO a reminder that, when it comes to customers, you fish where the fish are.\nMore posters in shop windows with grids of QR codes please.\n(Hey Apple: what I wish I could do is tap on a QR code in a photo in my photo library, which it seems like I can’t? Because then I could save photos of all these posters and make my own ad hoc deeplink homescreen as a photo album on my phone, and share it with my family.)\nUpdate 16 Feb: it turns out you can indeed tap on QR codes in photos in your iPhone photo library, if you tap on the little text recogniser widget first! For some reason this works for some codes in the photo I took and not others, and the highlight mechanism doesn’t make that fact obvious. So it seemed like it wasn’t working at all. However the use case stands… QR codes in any image on my phone should be live (not just in the photo library and camera) and I would like to share an album of deeplinks with my family because that feels like a neat hack.\nBTW:\nBarclays was the first bank - anywhere in the world apparently - to open an ATM, in north London in 1967. Here are some pics of Barclaycash. You had special vouchers worth ten quid each that would be cashed like cheques against your account. As you placed one in the drawer of the machine, you “signed” it with an early electronic signature in the form of a secret 6 digit number – the origin of the PIN. \nHere’s a fascinating paper on the history of it all: Emergence and Evolution of Proprietary ATM Networks in the UK, 1967-2000 (CiteseerX; tap through to download the full PDF).\nATMs were originally known as “robot cashiers” it turns out.\n",
    link: "/home/2022/02/14/barclays",
  },
  {
    title: "A 1970s plan about how to reach Barnard’s Star",
    date: "21.53, Tuesday 15 Feb 2022",
    content:
      "Project Daedalus is a study from 1978 about how to send an interstellar probe 5.9 light years to Bernard’s Star.\nThe craft is massive: twice the height of a Saturn V and with a diameter almost the same. It was imagined to be constructed in Earth orbit and accelerated to 7% light speed, in two stages. The first stage a standard rocket burn, though for almost two years. The second, for another two years, a nuclear pulse rocket:\n\nPellets comprised of deuterium and helium-3 would be bombarded by high-powered electron beams, thus triggering fusion and detonating the mass like a tiny nuclear bomb. These explosions would be repeated at a rate of two hundred and fifty per second, using a powerful magnetic field as the rocket’s nozzle.\n– Damn Interesting, The Daedalus Starship (2016)\n\nTiny atom bombs, hundreds of times a second! The blast captured in the deflector dish, propulsion from a magnetically-shaped plasma jet.\nAnd 46 years later…\nDaedalus would sail right by Barnard’s Star (it wasn’t intended to carry fuel to decelerate).\n\nDaedalus would carry 18 autonomous probes, equipped with artificial intelligence, to investigate the star and its environs. The 40m diameter engine of the second stage would double as a communications dish. On top of the second stage would be a payload bay containing the probes, two 5m optical telescopes, and two 20m radio telescopes. Robot wardens would be able to make in-flight repairs. A 50-ton disk of beryllium, 7 mm thick, would protect the payload bay from collisions with dust and meteoroids on the interstellar phase during the flight, while an artificially-generated cloud of particles some 200 km ahead of the vehicle would help disperse larger particles as the probe plunged into the planetary system of the target star.\n– David Darling’s Encyclopedia of Science, Project Daedalus\n\n(Check out the pictures at that link – mockups and diagrams.)\nSo it was all planned out, in enormous detail. I haven’t read the original papers but I’ve seen talks that cite them, and they mention even the repairability assumptions made by the mission designers – what the mean time between failure is of the number of parts required, and the mass required for the spare parts required en route. And so on.\n\nProject Daedalus (named after Daedalus, the Greek mythological designer who crafted wings for human flight) was a study conducted between 1973 and 1978 by the British Interplanetary Society to design a plausible uncrewed interstellar probe.\n\nBackground from Wikipedia.\n(I am a member of the British Interplanetary Society, as previously discussed.)\nThe group in the 1970s comprised a dozen scientists and engineers, meeting mostly in the pub: Daedalus was the first serious and thorough design for a starship.\nAND SO (I understand) it is the baseline for researching interstellar travel, by Nasa etc, even today.\nThe project rules are key:\n\nThe spacecraft must use current or near-future technology.\nThe spacecraft must reach its destination within a human lifetime.\nThe spacecraft must be designed to allow for a variety of target stars.\n\n(The second rule is why Daedalus’ journey takes 50 years.)\nThe first is the one that matters: no new physics.\nBy “no new physics” we mean: no faster than light travel suddenly discovered; no unanticipated breakthrough in human hibernation; no breakthrough in mechanical engineering reliability or energy storage density; no ansibles, no aliens, no RF resonant cavity thruster.\nDaedalus is an interstellar probe and a also probe into science and the imagination.\nIs it how such a project would be performed today? No. But it was important. Why?\nBy studying and specifying how to send the probe (and how to fuel it, and how to shield it, and how to repair it in flight, and how to perform the scientific research, and how to communicate back…) you get two things:\n\nA plan that can be built on: parts of the plan can be swapped out and iterated and improved. An engineering study becomes a kind of Wikipedia, a collaboration in the scientific discourse over decades.\nA lens to focus effort. Now there’s a plan, it’s possible to see what the biggest challenges are. Out of all the new engineering possible, what would have highest impact?\n\nIt problematises. It turns one big problem that can’t be tackled into lots of small ones that can.\nBEING PRACTICAL FOR A SECOND:\nThere are lots of ways to invent new things, and here I’m thinking about new products and startups and all of that.\nLike: design fictions are a method of exploring futures that create fully-rendered plausible worlds and so “adjacent possible” artefacts (products and services) drop out.\nLike: MVP (Minimum Viable Product) which is the typical product-engineering approach by which a startup attempts to meet a need, as quickly and simply as possible, and discover whether there is demand for it in the market.\nA “no new physics” study is a different kind of probe, an engineering fiction that simultaneously\n\nfollows a path of minimum effort: everything in the plan (which might be written, or might be wireframes/drawings) either exists already or there is clear line of sight to building it\nyet has its own ambitious North Star: maybe it has to achieve a particular goal in terms of user growth, or allow for a particular interaction or feeling, or meet a particular business need.\n\nIt’s going to be cumbersome. Like Daedalus it’s going to be 2 x the height of a Saturn V and just the same across.\nBut it problematises! It focuses! It demonstrates the possibility of a bridge across the canyon and now you can figure out a good one.\nIf we had to do this today then how would we do it – a challenge that teaches you a lot. It strips away so much from whatever prototype you currently have, and forces you to think about what you actually need to build next.\nAnyway. I’m spending a lot of time making drawings this week and staring into space, imagining how these plans/possibilities/probes might come to life. Not spaceships but work.\nHEY, so many years ago I went to some talks and that was when I first learnt about Project Daedalus, and it was in the context of the drive: assuming no new physics, the best way we can imagine to get between stars is this system of exploding tiny atom bombs at the back of the ship, hundreds of times a second (250Hz is the Daedalus frequency).\nA bigger starship (the series of talks was on the topic of generation ships, which take many human lifetimes for interstellar travel) will take longer to accelerate – a couple of decades instead of two years. Then when the ship is up to speed, the drive stops its acceleration (accelerating more would mean carrying more fuel, which would mean more mass which is harder to accelerate. There’s an ideal).\nMidway through the talk, the speaker made a throwaway comment and I remember it today:\nPulsars are a certain type of star that we’ve seen, and they flash - pulse with light, hence the name - hundreds of times a second.\nAnd some scientists say that, when you study pulsars, you notice that they appear to have high proper motion. That is, compared to other stars, they’re moving.\nSo… are pulsars actually interstellar ships? Are we seeing travel between the stars, the nuclear pulse rocket in action?\nWho knows how plausible any of this is. How throwaway was that comment? How seriously should it have been taken? I don’t know.\nBut what an image – the sky above our heads, a map, the ships visible! Van Gogh: should the shining dots of the sky not be as accessible as the black dots on the map of France?\nWell - said the speaker, and specifically this has stuck in my head  all these years - here’s how we would know: we can calculate the optimum firing frequency for these nuclear pulse rockets, a few hundred hertz we know that, and we can calculate the optimum many-year burn time, that’s all Newton’s laws.\nWhich means that what we need to do is continue monitoring pulsars with our space telescopes and look out for one that, after a few decades, disappears. Then we’ll know that what we were looking at wasn’t a pulsar, a star, it was a starship, sailing between distant alien worlds.\n",
    link: "/home/2022/02/15/daedalus",
  },
  {
    title: "Metaverse got torment-nexused just as robot did a century before",
    date: "14.46, Friday 18 Feb 2022",
    content:
      "This tweet did numbers late last year (111,700 likes):\n\nSci-Fi Author: In my book I invented the Torment Nexus as a cautionary tale\nTech Company: At long last, we have created the Torment Nexus from classic sci-fi novel Don’t Create The Torment Nexus\n– Alex Blechman (@AlexBlechman), 10:49 PM . Nov 8, 2021\n\nWhich is (A) hilarious; and, (B) LET’S RECAP the backstory to this tweet, which is about the metaverse:\n\nIn 1992, Neal Stephenson writes Snow Crash set, as least in part, in a huge virtual reality world called the Metaverse… which is an unregulated corporate dystopia. (Here are some quotes from the book if you want a flavour.)\nIn October 2021, Facebook rebrands itself to Meta and announces that its new mission is to build the metaverse. Lol corporate dystopia etc.\n\nAnd the thing is that the term “metaverse” is super handy to refer to the concept of: a persistent, social, non-game virtual reality.\nWhich may be awful (and yes has the potential of awfulness inherent in it) but - in the general sense and not The Corporation Formerly Known As Facebook sense - is pretty cool actually! (My own hope is for something more lo-fi.)\nLinguistically useful, then.\nDid “robot” go through the same curve?\nATMs were known back in 1967 as “robot cashiers” (mentioned earlier this week).\nBack in 1944, more robots…\nAs told in Thomas Rid’s excellent history of cybernetics, Rise of the Machines (Amazon), the German V-1 pilotless rocket was the world’s first cruise missile, immediately dubbed the ‘robot bomb’ by the press.\nIn secret, anti-artillery guns were equipped with feedback-powered man-machine interfaces to allow for superhuman targeting, firing shells equipped with radar-triggered autonomous fuses, both brand new. It worked incredibly well, bringing down V-1 rockets in flight before they could reach London.\nRid relates this incredible quote, from General Sir Frederick Pile who was in charge of Anti-Aircraft Command, and therefore the V-1 defence:\n\n“Now we saw the beginning of the first battle of the robots,” Pile observed at the time.\n\n1944!\nThe modern sense of “robot” was at that time only 24 years old, from 1920. I’m amazed at the speed of adoption.\nThough to begin with “robot” didn’t just refer to this new technology. There was a whole other layer of meaning… I’ve blogged about the history of “robot” before (2021) but in a nutshell it is this:\n\nThe 1920 Czech play Rossum’s Universal Robots is about a class of manufactured, artificial people used as factory workers, treated terribly. The play became hugely popular internationally.\nThe word “robot” was taken from the Czech robota meaning “forced labour”.\n\nWhat the play is about, to me, is what happens to us when we have workers who we regard as non-human artefacts (whether they are artificial or not; the warning is general). We ignore their feelings; we behave as monsters; we are consumed by capitalism; we become, ourselves, inhuman.\nSo the word “robot” didn’t mean autonomous machine originally – or rather, yes, it did mean that but it ALSO meant: these autonomous machines will turn you into a rapacious uncaring capitalist incapable of basic humanity.\nAnd now we use the word free of judgement or implication. A robot is a robot whether we mean a car factory robot arm or a Terminator or a Roomba.\nSo there’s a process, maybe, where a linguistically useful neologism shucks off any original valence and becomes a purely matter-of-fact signifier?\nAnd this is fine? Or are words always haunted by their originating critiques and ugly origins? Possibly. Dunno.\nIt is still weird, however, that the all-in-one meal replacement Slimfast-for-bros food startup Soylent appropriated its name from the movie Soylent Green which is all about (SPOILERS) the titular food being made out of actual people.\nCODA:\nThat tweet at the top? I couldn’t remember what it was this morning, so asked about it in vague terms on Twitter and a bunch of people came back to me. (Thanks!) A couple came back without a link but replied simply Torment Nexus.\n…which indicates that the term has stuck in people’s heads. It has currency already!\nI wonder whether it will end up being what we call this valence-flensing process of invention?\nLike, something is invented in fiction which is awful and stupid and awful.\nAnd then someone goes and makes it, and it’s maybe awful and maybe not, but it’s in the world now none-the-less.\nAnd in the future, an observer may encounter a stupid and awful but somehow neat idea in a book and predict its coming, saying “Whoa yeah that cool concept is going to get totally torment-nexused,” with zero irony, for some reason speaking like a 90s tousled surfer dude with bleached blond hair, pale blue eyes half closed against the low evening sun.\n",
    link: "/home/2022/02/18/torment_nexus",
  },
  {
    title: "Filtered for hundreds and hundreds",
    date: "21.33, Monday 21 Feb 2022",
    content:
      "1.\nCricket – two teams of eleven take turns to score as many runs as possible. Individual batters come out of the pavilion (traditionally the main building of the cricket ground) and score runs one by one (or 4 or 6 for getting the ball to the boundary) before getting out by being caught, bowled, run out, etc. So a batter scoring a century, 100 runs, is not rare… but it’s not common either.\nHow do you score 100? There are books about it. \nMy favourite advice is this:\n\nSo too Geoffrey Boycott’s famous Uncle Algy, who said to Boycott as a youngster: ‘Stay in, because you can’t score runs in the pavilion. It’s better your team-mates are watching you bat than you are in the pavilion watching them bat.’\n– Steve James, The Art of Centuries\n\nDon’t get out. That’s it.\nCricket is unique because a team in a terrible, losing position can get into a winning position just by… not getting out. Don’t take risks till you’ve got your eye in. Be stubborn. Every position improves with time. It’s hard to think about 100s if you’ve only scored 1 or 2. So show character, that’s what they say. Let the runs grow one by one. Accumulate. First none then 10 then 20 then 30. Stay in.\n2.\nTsukumogami (Wikipedia), Japanese object spirits, being any object that has reached its 100th birthday and thus become alive and self-aware.\nFOR EXAMPLE: an animated saddle; a possessed futon; an animated gong, and so on.\nIt’s curious to look around my home and imagine which items might be possessed of a soul. There are a few as it happens.\n(I also wrote about this back in 2011. Have a read if you want to learn about self-mummification.)\n3.\nLet’s say you bury nuclear waste. Then you need to pass a message, somehow, to avoid that site, and that message needs to last 10,000 years. The Sandia National Laboratories report in 1993 put forward some ideas, and the phrasing of the intended message has become famous:\n\nThis place is a message… and part of a system of messages… pay attention to it!\nSending this message was important to us. We considered ourselves to be a powerful culture.\nThis place is not a place of honor… no highly esteemed deed is commemorated here… nothing valued is here.\nWhat is here was dangerous and repulsive to us. This message is a warning about danger.\n– Wikipedia, Long-term nuclear waste warning messages\n\nAnd so on.\nAll of which to say – the author Esther Saxey has translated the Sandia message into Old English a thousand years old, and then re-translated it back into modern English.\nThe words are… powerful. Haunting. They speak directly to the soul.\n\nListen! This sepulchre is a message\nWithin a web of warnings.\nWe sent this warning,\nA baleful, urgent message.\nWe thought our people\nExceedingly powerful, a great generation.\nHere is no honourable deed commemorated,\nNor ancient treasure buried\nNor high seat of honor nor festival ground.\nWe feared and hated what is here.\n\nRead it: Until a Hundred Generations of People Have Departed by E. Saxey in The Future Fire, issue 2021.58.\n4.\nIt is possible that Saturn’s rings are only 100 million years old (Quanta Magazine).\nIf they were older, you’d expect the ice to be dirtier, that’s the gist. (And they’ll disappear completely in another 100 million years.)\nThat means that sharks are older than the rings (420 million years).\nCretaceous dinosaurs would have seen Saturn’s rings, 66 million years ago, when they peered up into the heavens to look at the approaching asteroid, the Chicxulub impactor; Jurassic dinosaurs of the previous period, on the other hand, would not.\nHey so today my blogging streak hits 100 weeks – I’ve been writing at least once a week (mostly three times) every week since March 2020 (here are my personal writing tips). It’s neat to have the pressure of the streak to maintain, and this small audience. Though I know it won’t last forever it’s just enough to keep me going without being overwhelming. Are many people reading? Who knows. Is what I’m writing any good? Also who knows. I find it impossible to tell. BUT I enjoy the act. Writing a post takes me to places I didn’t expect at the top of the page. My fingers can type something that surprises my brain! That fact is astonishing. So thank you for reading. I appreciate your company, and the always insightful thoughts that appear in my inbox from one or another of you from time to time by way of response.\nYou don’t score runs from the pavilion.\n",
    link: "/home/2022/02/21/filtered",
  },
  {
    title: "That time I got chased by a hippopotamus",
    date: "19.19, Tuesday 22 Feb 2022",
    content:
      "It was in Kenya, where I have family, and we were on safari and had stopped around a lake to look at the hippos. I was 11 maybe? Or thereabouts. The hippos were hanging out in the water, heads just visible. There was a steep slope down from the path, and two or three of us were standing by the shore. The rest of the group had finished looking and wandered back up to the top.\nSuddenly our guide yelled “crocodile!”\nWe sprinted up the slope and kept on sprinting for a few tens of metres for good measure.\nAfterwards the guide told us that he had seen one hippopotamus rise up and begin to pick up pace towards us through the water. It wasn’t committed to the chase. It stopped at the lake’s edge seeing as we had been scared off. He said he shouted about a crocodile because he needed us to move quickly and we wouldn’t have responded fast enough if he had shouted about a hippo.\nThere are some stories like this where I would draw out a lesson but I don’t know how to generalise this life experience. It’s a thing that happened.\nAnother time we were looking at a chimpanzee and it picked up and pitched a rock the size of a tennis ball probably 20 feet, like a bullet, missing my sister’s head by a couple inches.\nThere are lots of stories. One visit I was walking with my mum in some woods near Nairobi on a short loop. We lost the path temporarily and my mum wanted to turn back. I was pretty confident we could find the route and besides I was sure I had my bearings. But my mum was being uncharacteristically cautious. I grew up in the New Forest in the south of England (she grew up in Nairobi) and got frustrated. “What’s the worst that could happen?” I said.\n“Lions,” she said, and then, “Bandits.” Two good points. And however realistic in that year compared to when she had been my age, it focused my mind. We walked back the way we had come.\nWhat a wonderful childhood.\n",
    link: "/home/2022/02/22/hippo",
  },
  {
    title: "We could be inventing new wheels with weird new physics",
    date: "20.22, Wednesday 2 Mar 2022",
    content:
      "There’s that old line that bumblebees shouldn’t be able to fly. Well, no they can’t if you model them as fixed-wing aircraft, and even flapping like a bird (which we’ve all seen) doesn’t seem like it would be enough to keep the bee aloft. The line resonates because the flight of a bumblebee is counterintuitive somehow.\nIt turns out that bees fly by flapping those wings (a) really, really fast, and (b) in a figure-of-eight wing motion to create low-pressure vortices to pull them up (source).\nI don’t need to take air vortices into account on my morning commute, and nor does anyone else (excepting cyclists and pilots). So that’s the source of the intuition circuit break: the bee’s mechanism operates at a scale (time, size) that we don’t have access to, so we can’t access it in the imagination either.\nANYWAY. DeepMind has created an AI to wrangle plasma flux in experimental fusion reactions.\nFusion is the energy source of the future – but it requires holding in place a super hot, high energy plasma (a kind of electronic gas) inside a donut-shaped container called a tokamak. At sufficiently high temperatures, fuel can be injected such that fusion occurs, generating energy and also igniting the plasma (allowing for more fusion). The reaction becomes self-sustaining and that is the holy grail. But… plasma cools too quickly if it’s not held in place away from the walls of the tokamak. So rapidly adapting magnetic fields are used to cage it – which is hard. Plasma in the tokamak is wild and powerful; strange eddies, loops and currents braid it, making it writhe and snap with huge force and speed, an unwilling captured sun. Our magnets can’t react quick enough to ride it for long.\nAND SO:\n\nDeepMind researchers have trained a reinforcement learning agent to shape the distribution of plasma in a Tokamak fusion reactor. This requires training an agent that “can manipulate the magnetic field through a precise control of several coils that are magnetically coupled to the plasma to achieve the desired plasma current, position, and shape”. If that sounds complicated, that’s because it’s extremely complicated. The task is akin to being an octopus and needing to precisely shape a tube of clay that’s rotating at speeds faster than you can comprehend, and to never tear or destabilize the clay.\n– Josh Clark, Import AI 285\n\n(Grateful hat tip to Matt Jones who posted this on Petafloptimism.)\nThey’re not just controlling the existing plasma but using their AI to explore new plasma configurations – and I am intrigued about what novel bumblebee physics they might find. Unexpected figure-of-eight plasma orbits that exploit unpredicted vortex physics to make fusion radically more efficient, perhaps. Who knows.\nHow fish swim!\nHey get this (there’s a connection I promise):\nFish swim by using the surface physics of their skin to create and exploit low pressure micro vortices in the water.\n\nfish somehow exploit the vortices to reduce the amount of energy they need to combat the momentum of the flowing water.\n\nAnd, in particular:\n\nIt appears that if there are no useful vortices already formed in the water (e.g. by rocks etc) – the trout can actually make some itself - and then extract energy from them.\n– The Art of Nature, Fish Swimming (2007)\n\nWhoa.\nThe skin is vital: The scales create a ‘one way surface’.\nVortices in the water are generated by the skin, and the side-to-side movement of a trout is the fish slipping between the vortices, pinballing between them, propelled on them like a boat on wind. (Shown, says the article, by the fact a dead trout on a line in moving water will still exhibit the characteristic swimming action.)\nAll of which leads to this REMARKABLE line:\nFish don’t swim, they’re swum.\nARGH. Too good. Am dead now.\nLOOK: wheels are great because they make movement easier – but it turns out there are other mechanisms (surface physics, rapidly evolving vortices, one-way skin) which similarly lower the energy for motion.\nBut they are hard for us humans to imagine. And hard to discover! And hard to do! These new kinds of wheels operate at scales which are outside the human everyday. We don’t derive them as simple solutions to equations. We stumble around in the dark and find them in the corners.\nUntil now.\nIt strikes me that what DeepMind’s AI is doing, in a general sense, is operating with enough attention to detail and enough complexity and enough resolution at a high enough speed to discover and exploit novel physics. That’s what explore new plasma configurations means.\nSo… we could put the DeepMind plasma wrangling AI to work in inventing new wheels? New efficient forms of motion and propulsion?\nI was sorta kinda getting at this when I talked about faster-than-real-time computer simulation back in 2020:\n\nSo, with powerful simulation, could you figure out how to hit a mass of water with puffs of air so that it rises up and moves around the room, washing the windows; or robots with reed-thin jointed limbs that should never be able to hold themselves up, but with motors at each joint running at just the right vibration to keep the thing moving?\n\nAnd WHY NOT, right?\nIt’s just high-hertz plasma wrangling, right? It’s just vortex pinball.\nThe question is not “can it be done” (yes it can be done, thanks DeepMind) but will it be done?\nHow can the tools for inventing new wheels end up in the hands of the people with the right imaginations?\nWhat do we need?\n\nIncredibly high-resolution real-world physics simulations, enough to accurately model vortices in turbulent air\n3D software that can model, at the least, the motion and surface effects of bumblebees wings could be replicates\nA DeepMind AI that, given a goal and a starting point, could run a giant search to optimise the physics and controls of… whatever new objects the designer speculates\n\nAll wired together. Handed out to designers and mechanical engineering students.\nAnd, given this package, perhaps the future will look very different from our science fiction.\nPinhead drones dragging copper wires behind them, darting through the home bouncing on air currents, generating electricity and power by dragging their tails through ambient magnetic fields.\nDirectional packaging that is can’t slip out of your hands (but dislodges easily when you move your hands the other way).\nCars with fine filament-bristles covering on the base, shaping and sweeping the air at nanometer resolution to ride on a silent and almost friction-free air cushion of vortex turbulence.\nAll mechanical objects with halos of filaments, magnets, mist, so fine that the eye can’t identify clean edges, no hard plastics or iron but all our artefacts in soft focus, encased as they will be in a gentle haze of turbulent air sculpted by alien intelligence.\n",
    link: "/home/2022/03/02/wheels",
  },
  {
    title: "Formative experiences of read-write science",
    date: "20.52, Friday 4 Mar 2022",
    content:
      "Neutrinos are tiny and everywhere. The neutrino family makes up three of the dozen fundamental particles of matter in the Standard Model. They’re made in nuclear reactions.\nLocally that’s the Sun. The solar neutrino flux is about 65 billion neutrinos, passing through just one square centimeter of area on earth, every second.\n(So look at your hand. Imagine you can see them.)\nNeutrinos barely interact with matter. A neutrino could pass through 3000 light years of human meat before hitting anything. (Now imagine that).\nSo they’re hard to detect.\nNeutrinos didn’t have mass and then they did.\nBack in my physics undergrad I remember sitting in a lecture hall and being told to update our photocopied handouts because neutrino mass had been discovered over the summer.\n(That link above is to Physics World, July 1998).\nAn experience like that absolutely changes your view about what science is.\nThe excitement in the room!\nTo edit printed notes by hand like that – you internalise this picture of science as a living breathing edifice, not distant and immutable. The idea that physics is a giant wikipedia becomes normal in your head.\nThree other similar formative moments also from my undergrad, all previously discussed:\n\nThat time I learnt that my tutor’s scepticism about cold fusion was because he’d just grabbed the required kit for the Fleischmann-Pons “discovery” and tried it himself, and I realised that getting involved yourself is a totally possible thing to do (and even if you don’t or can’t, the possibility of replication is what keeps everyone honest).\nThat time I saw (we saw!) a blue LED for the first time, that pure blue essentially a new colour, fresh from its discovery in Japan, and viscerally grokked that science was a continuously changing thing – and that we were part of it.\nThat time we spent two days in lab laddering up abstraction layers from semiconductors to transistors to gates to shift registers to the separation of data and code to microcontrollers, at each stage first figuring it out with our hands, testing it, and then replacing our jury-rigged kit with standard components, until eventually we ran a small program on a computer and could see in my minds eye the whole edifice beneath, and experienced the vertigo, and I understood just a little bit for myself about how our world had been painstakingly constructed.\n\nOften when I read people talking about science, I feel like they’re talking about something which isn’t this. I don’t recognise that unapproachable unitary authority, that something other. By luck and privilege and a bit of choice, my personal picture of science isn’t that. It’s malleable, contested, read-write not read-only.\nOne of my toddler’s first experience of capital-A Art was drawing on the floor.\nIn the summer of 2021, the giant central space of Tate Modern, the Turbine Hall, was taken over by Mega Please Draw Freely by Ei Arakawa. The entire floor became a whiteboard; kids who entered were given bold wax crayons.\nBy the time we went the floor was a colossal tapestry of 10,000 colourful drawings – by kids, so nothing felt out of reach or like it couldn’t be replicated. We went back a few times, taking an hour or so to draw and to look.\nSo, for her, a gallery isn’t a place you go and see. Her template is that it’s a place you go and see and simultaneously a place you leave your mark for others to see.\nWhat a way for art to imprint on my little girl!\nGaudi’s cathedral has been under construction since 1882. So residents of Barcelona can see it grow and embellish in front of their eyes. If you want you can dedicate your life to it too: I highly recommend this short movie about the Japanese sculptor Etsuro Sotoo.\nImagine what it does to your view of infrastructure, seemingly set in stone, and institutions - even one as eternal as the church - if they grow in front of our eyes and because of OUR HANDS.\nMaybe we’ve lost something by not having a grassroots cathedral project in every city.\nI wonder what the absolute smallest most certain way would be to give this read-write formative experience to everyone, for science, for infrastructure, for institutions and all the rest.\nWhat triggered this anecdote was Tom Carden on Twitter who said this:\n\nEvery popular science book should come with a registration card so you can be part of the mass recall when science advances.\n– Tom Carden (@RandomEtc), 3:35 PM, Feb 27 2022\n\n…and maybe that’s it?\n",
    link: "/home/2022/03/04/physics",
  },
  {
    title: "Filtered for animal news",
    date: "13.20, Wednesday 9 Mar 2022",
    content:
      "1.\nMilitarized Dolphins Protect Almost a Quarter of the US Nuclear Stockpile:\n\nSince 1967, the Navy has been training dolphins and sea lions (and probably other marine life) for military applications such as mine clearing, force protection and recovery missions. The U.S. Navy Marine Mammal Program deployed military dolphins as early as the Vietnam War and as recently as the 2003 U.S.-led invasion of Iraq.\n\nThere was a burst of working with dolphins in the 60s/70s and it seems this bore some fruit.\nThe dolphins patrol the seas and identify mines and enemy divers, and attach buoys to them so that they can be avoided/picked up/otherwise dealt with.\nMilitarisation aside, I am weirdly into the idea of animals having jobs (crows, sheepdogs, etc, as previously discussed).\nALSO:\nThe above article indicates that Russia, North Korea, and Iran all have dolphin programs too, leading to this WILD headline:\nIran May Have a Fleet of Communist Killer Dolphins.\nWHICH MAKES ME ASK:\nWell, what are the natural politics of a dolphin anyway? Would it be better or worse if they were libertarian killer dolphins? What if dolphins are utilitarians, and you have to make the case that social good trumps individual harm to get them to kill anyone?\n2.\nHeadline: Farmer gives cows virtual reality headsets to reduce anxiety and increase milk production.\n\nKocak says the move is already paying off. He’s given the headsets to two of his cows and noted that milk production went up from 22 litres to 27 litres a day.\nAnd what are the cows seeing through the VR goggles? Apparently, it’s visions of the outside world.\n‘They are watching a green pasture and it gives them an emotional boost. They are less stressed,’ he said.\n\nSome quirks. Cows, as prey animals, have their eyes on the sides of their head. So each cow needs two headsets. The photos are something else.\nAnd they needed to tweak the colour palette: Cows can’t see red or green – they’re only able to perceive dull shades of yellow and blue.\nThis is awful? Though interesting to try to pick apart exactly why.\nTwo starting points:\n\nThere’s something wrong with economics such that buying and maintaining VR headsets is the more “rational” decision versus paying a person to simply hang out and touch and chat with the cows all day, which I suspect would have a similar effect.\nThere’s a profound disrespect for the cows as co-inhabitants of our planet, to turn them into objects of pure production.\n\nBut both of these points need to be hooked into a wider moral framework to understand why they are bad. A job for another day.\n3.\nHow many T. Rex have there ever been? 2.5 billion.\n\nWe estimate that its abundance at any one time was ~20,000 individuals, that it persisted for ~127,000 generations, and that the total number of T. rex that ever lived was ~2.5 billion individuals, with a fossil recovery rate of 1 per ~80 million individuals or 1 per 16,000 individuals where its fossils are most abundant.\n\nRef.:\nCharles R. Marshall et al, Absolute abundance and preservation rate of Tyrannosaurus rex. Science 372, 284-287 (2021).\nThe fossil recovery numbers check out: only 42 individual skeletons have ever been found.\n(I didn’t know that Tyrannosaurus roamed only in what is now North America. Or that there were possibly 3 different species.)\n42! Those lucky stiffs.\nThe number of humans who have ever lived: 107 billion. Let’s say we’re halfway through. So double it for an estimate of the number of humans who will ever live: 214 billion.\nThen assume a similar fossil recovery rate, meaning: 2,675 preserved human skeletons in, say, 100 million years, dug up by the highly-civilised communist dolphin people of the deep future.\n2,675 is a pretty exclusive club. But not great odds to be part of it.\nIf you want to better your chances then, I don’t know, hang out near bogs and volcanos a bunch, something like that, that’s the lesson.\n4.\nIn the book Jurassic Park by Michael Crichton, dinosaurs are the company’s second product. First they make cat-sized elephants, to help raise money from investors, but the mini elephants are always sick and cross.\nStartups eh.\n\nHammond was flamboyant, a born showman, and back in 1983 he had had an elephant that he carried around with him in a little cage. The elephant was nine inches high and a foot long, and perfectly formed, except his tusks were stunted. Hammond took the elephant with him to fund-raising meetings.\n\nAlas, the elephant was prone to colds, particularly during winter. The sneezes coming through the little trunk filled Hammond with dread.\nAnd:\n\nHammond also concealed from prospective investors the fact that the elephant’s behavior had changed substantially in the process of miniaturization. The little creature might look like an elephant, but he acted like a vicious rodent, quick-moving and mean-tempered.\n\nFor what it’s worth I would totally consider getting a pissed-off teeny elephant as a pet. I already live with a pissed-off teeny tiger and she’s got claws.\n",
    link: "/home/2022/03/09/filtered",
  },
  {
    title: "Vibe shifts in the Upper Anthropocene",
    date: "18.20, Friday 11 Mar 2022",
    content:
      "Hey before generations there were ages.\nLike the Atomic Age? The first nuclear weapon was detonated in July 1945 and I think the best way to describe the societal psychic response is self-awe – an optimism and terror at the power in our hands.\n(And if the early 2000s was the colour of ubiquitous blue LEDs, design in the 40s/50s/60s was all about uranium orange and glowing radium green.)\nI find it incredible how clear it was to everyone that it was a new era.\nFOR EXAMPLE:\nThe 48th head of the Ismaili faith was Aga Khan III, born in 1877.\nThe position is hereditary. And yet: Aga Khan III, in his will in 1957, skipped over the line of succession to name his grandson as the new Imam, saying:\n\nIn view of the fundamentally altered conditions in the world in very recent years due to the great changes which have taken place including the discoveries of atomic science I am convinced that it is in the best interests of the Shia Moslem Ismailian Community that I should be succeeded by a young man who has been brought up and developed during recent years and in the midst of the new age and who brings a new outlook on life to his office as Imam.\n\n(He had previously spoken about the two worlds: the world of material intelligence and the world of spiritual enlightenment.)\nSo the new Aga Khan IV (who is a good man) was known as the  “Imam of the Atomic Age” and he is still the leader of the faith today.\nMore poignantly:\nJohn Wayne, legendary actor in westerns, died of stomach cancer in 1979.\nIt is speculated that the cancer was caused during the production of The Conquerer in 1956, where the filming in Utah was in the fallout zone from the above-ground nuclear tests of the time.\nCowboys to atom bombs. What a hand-off between eras.\nPeople tried the “Information Age” on for size but the term never really became a thing.\nNot like generations.\nAs far as I can tell, Strauss and Howe introduced the modern framing of generations (Wikipedia) in their 1991 book Generations. Their follow-up book The Fourth Turning which put  forward the idea that eras cycle through four moods, causing a cyclic pattern of four generation archetypes to match:\n\nThe High - the Prophet/Idealist archetype is a (spoilt) child during this post-Crisis era, e.g. boomers.\nAwakening - the Nomad/Reactive archetype; e.g. Strauss-Howe’s “13th Generation”, what we now call Gen X.\nUnravelling - in our time this is around 9/11, and children of this era follow the Hero/Civic archetype: grumpy conformists. Hello millennials!\nCrisis - children of this era have the general archetype Artist/Adaptive. Gen Z.\n\nEach cycle lasts about 80-90 years and is called a saeculum. We’re coming up to the end of one now. (What’s next?)\nIt was Douglas Coupland who named and popularised Generation X and it caught the zeitgeist to such an extent that generations pretty much displaced ages in folk historical sense-making.\nPersonally I buy the idea that boomers exist, but reckon it’s less about biorhythms for history, and more about the fact that they were kids while cars were getting popular.\nSee this tweet…\n\nBad news: Leaded fuel reduced the IQ of everyone born before 1990 by ~4.25%. Millennials are the first to be born with unleaded gas.\n– Ethan Mollick (@emollick), 11:36 PM, Oct 19, 2021\n\nThe paper referenced:\nBellinger DC. Childhood Lead Exposure and Adult Outcomes. JAMA. 2017;317(12):1219-1220.\nNo wonder millennials are so cranky! Imagine being slightly brighter than everyone else in the world.\nRELATED, this absolutely brutal and totally unnecessary skewering of millennials in The New York Review is HILARIOUS: The Balletic Millennial Bedtimes of ‘Normal People’ by Lorrie Moore. (The article is paywalled but you get to the best section just before the cut-off.)\nAnyway Gen Z folks are the best. Love em.\nWhere are we in history?\nWe want to predict the future and find certainty. We want to know the answers to questions like:\n\nAre geopolitics unsteady right now like the reconfigurations in 68 and 89, when the Berlin Wall fell, i.e. good; or like in the run-up to 1939 i.e. bad?\nA smaller and specific-to-my-crowd  question: is the current web3 excitement in technology just another fad like, say, machine learning, which is major but was incorporated and normalised; or is it a fundamental shift in we’re in an era like minicomputers where something like Unix is about to be invented and we have a new 60 year paradigm coming up?\n\nIn Roy Lewis’s 1960 sci-fi novel about a tribe of Stone Age hominids, which is super funny (I’m not kidding, read it), The Evolution Man (Amazon), Father spends much of his time (a) inventing, and (b) muttering darkly about whether they are in the Upper or perhaps only Middle Pleistocene, like he’s a time traveller or something trying to brute force his way into the future.\nAnd I find myself acting a bit like that.\n…thinking to myself, gah I thought we were in a Crisis but perhaps it was just a Strauss-Howe Unravelling, we haven’t got to Crisis yet, and it’s still got a way to get worse before it gets better.\nMaybe we should go back to comets to milestone our way through history.\nI remember seeing Comet Hale-Bopp in the sky in 1997, which was visible with the naked eye for well over a year, just hanging there in the sky like a moon made of ethereal fog from the unknown reaches of the cosmos, the most visible comet since 1811, and blimey what an omen, I should have guessed that something was up.\nSigns and portents!\nSomebody on reddit said with the 2020s going down in history as ‘the roaring WTFs’ and yeah maybe that’s the name.\nMind you reddit also talk about “Late Capitalism” and I have to say, my response is: huh you’re optimistic.\nHey are we in the Upper Anthropocene already? Like, in a million years time when they dig back down to the paper-thin geological layer of plastic microbeads, CO2, and crushed bitcoin ASICs, is this the top layer they’ll see? Or are we still in the Middle Anthropocene and there’s still a ways to go?\nLike everyone else I read that article about the Vibe Shift in The Cut and I have been endlessly going on about the new vibe since.\n\nA vibe shift is the catchy but sort of too-cool term Monahan uses for a relatively simple idea: In the culture, sometimes things change, and a once-dominant social wavelength starts to feel dated.\n… the thing that struck fear into Ellen’s heart was Monahan’s prediction that we were on the cusp of a new vibe shift. It is unnerving because when you really consider it, you can feel people flocking to a new thing. You can see that he’s right; something has shifted.\n– The Cut, A Vibe Shift Is Coming. Will any of us survive it? (2022)\n\nThe concern articulated in the article: not everyone survives a vibe shift.\nI am not-even-kinda but ACTUALLY massively in love with this, both the new vibe itself and the concept of being left behind.\nIt has been a concern to me that normcore is still around; popular music hasn’t really changed since the 90s basically; I still get what the kids are talking about. I want to be baffled and confused at clothes and mores and music, barely hanging on by my fingertips!\nWhich hasn’t happened. Until now?\nNow my sense is that the internet is thinning out as everyone is disappearing into discords and other Dunbar spaces. It’s quieter, right? It feels like being in a club where the crowd is imperceptibly thinner. Everyone is off to afterparties and I don’t know where. It’s brilliant.\nSo just as we were done with ages, maybe Gen Z is the last one and soon we’ll be done with generations. We’ll need a new way to refer to the current era.\nSaeculum shift.\n",
    link: "/home/2022/03/11/saeculum",
  },
  {
    title:
      "Workplace serendipity, invention, and lessons from Prohibition 1920-1933",
    date: "19.20, Monday 14 Mar 2022",
    content:
      "Behold the power of lubricated thinking and general hanging out:\n\nclosing the saloons during prohibition reduced patenting by ~15%.\n\nThis is from the blog Marginal Revolution summarising a paper by Mike Andrews.\n(Prohibition in the US: alcoholic beverages were banned from 1920 to 1933.)\nSaloons! The all-conquering social media of their day: By 1897 there were roughly a quarter of a million saloons, or 23 for every Starbucks franchise today. (Saloons combined drinking with other services such as a telegraph station and a payday lender.)\nThe convincing bit of evidence considers women…\n\nAndrew’s compares countries that were forced dry by state prohibition laws with previously dry counties, so the estimates are local and from across the country. He has significant patent data including the location of inventors and a variety of important robustness tests. Women, for example, didn’t typically patronize the saloons but also continued to patent at similar rates in wet and dry counties.\n– Marginal Revolution, Saloons of Invention (2021)\n\nRef.\nAndrews, Michael, Bar Talk: Informal Social Interactions, Alcohol Prohibition, and Invention (November 18, 2019).\nYou can grab the PDF at that link. Absolutely read the introduction (p2) but honestly it is all good.\nThe paper itself is about where new ideas come from: the importance of informal interactions on the rate and direction of inventive activity.\nTwo key takeaways:\n\nsocial interactions are important for invention because they facilitate the exposure to new ideas, in addition to simply making it easier for individuals to find collaborators.\n\nSerendipitous exposure to ideas! The ability to find collaborators!\nAlso: you need saloons in addition to collaboration at work. There is evidence that informal interactions in bars and formal interactions in the workplace are complements in the invention production function.\nAll was not lost when the saloons were shut: while disrupting these existing networks can have negative effects, people will form alternative networks – but it takes time.\nFinally – there is a question about whether alcohol itself is responsible for invention, rather than serendipitous social interactions. In a sublime bit of analysis (section 5), Andrews looks at per-county cirrhosis death rates (because actual alcohol consumption was not reported, due to the legal situation) and finds that, for patents, it’s the bars and not the booze.\nGoing remote over lockdown is like prohibition and the saloons closing, right?\nSo much of being in the office is about bumping into people as a meeting room turns over, and you catch the end of a conversation or see who’s there, and that reminds you of something, so you get to drop in some extra information. Or the lunches, or the geography of nearby desktops and being pulled into a fortuitous chat, and so on…\nCould this kind of serendipity be achieved in software?\nLast year I was speculating about video call software and anterooms and now I want to extend this idea to anterooms where people can have chance encounters…\nIMAGINE your Zoom icon on your phone is the anteroom. You leave your last call of the day, but notice the icon still pulsing with muffled sound. So you tap to peek in – and find that the people from your previous two meetings have randomly spotted each other and are still there, white-boarding on the wall, swapping notes.\nGiven places like Pixar and Xerox PARC shaped their physical architecture to select for serendipitous mixing and corridor conversations, to great success, why aren’t we using information architecture to do the same?\n(Hey this is a little of what I’m working on in the day job. We’re not building a virtual office as the primary use case but even so, we have our meetings on-platform now – and one of the incidental features is that you bump into people between calls, and can spot people hanging out and choose to swing by to say hi. It’s minor but effective and super neat. BTW we’re hiring.)\nThe supplementary question is how you build trust and help people feel confident enough to share their half-baked ideas with people they half know. It’s not just about bumping into people outside meetings, but repeated encounters to build familiarity, and the environment of the bar or the liminal quality of the corridors, and having gregarious friends and colleagues to connect conversations, and so on and so on.\n",
    link: "/home/2022/03/14/saloons",
  },
  {
    title: "One day we’ll need anti-spam for coercive synthesised voices",
    date: "19.59, Wednesday 16 Mar 2022",
    content:
      "What would happen if synthetic speech got really good at hacking your emotions?\n\nSonantic, an AI voice startup, says it’s made a minor breakthrough in its development of audio deepfakes, creating a synthetic voice that can express subtleties like teasing and flirtation. The company says the key to its advance is the incorporation of non-speech sounds into its audio; training its AI models to recreate those small intakes of breath - tiny scoffs and half-hidden chuckles - that give real speech its stamp of biological authenticity.\n– The Verge, Listen to an AI voice actor try and flirt with you (2022)\n\nExamples embedded.\nTANGENTIALLY:\nThe non-speech sounds in the flirty synth-voice are the best bits.\nI’m reminded of WaveNet which was the big breakthrough in computer-generated voices in 2016. They also released examples of “babbling” which is when you run the voice machine but without any words. So you ONLY hear half-breaths, the tack of the tongue in the mouth, the subtle echo of the mouth cavity, and so on. It’s incredible audio.\nI posted about babbling in 2017 (there’s a description there of how to hear to the samples).\nThe article asks this question: what are the ethics of deploying a flirtatious AI? Is it fair to manipulate listeners in this way?\nThat’s the point: it’s coercive, right? Weaponised flirting has long been used by those people who try to get you to sign up to charity donations on the street.\nPeople like flirting which is why it works.\nEXAMPLE, this chatbot in China: Xiaoice was first developed by a group of researchers inside Microsoft Asia-Pacific in 2014, before the American firm spun off the bot as an independent business.\nAnd: According to Xiaoice’s creators, the bot has reached over 600 million users. (Mostly Chinese, mostly male.)\n\nUnlike regular virtual assistants, Xiaoice is designed to set her users’ hearts aflutter. Appearing as an 18-year-old who likes to wear Japanese-style school uniforms, she flirts, jokes, and even sexts with her human partners, as her algorithm tries to work out how to become their perfect companion.\n– Sixth Tone, The AI Girlfriend Seducing China’s Lonely Men (2020)\n\nThe platform capitalism data-growth-profit flywheel at work:\nBy forming deep emotional connections with her users, Xiaoice hopes to keep them engaged. This will help her algorithm become evermore powerful, which will in turn allow the company to attract more users and profitable contracts.\nGeneralising this to emotional engagement… flirtation won’t be the right unlock for everyone.\nSo it’s easy to imagine extending adtech. Adtech means using tons of datapoints to construct a profile of you which means that you are shown ads that you are more likely to elicit a response. For example: knowing that other people in your home location are reading content about interior design, the targeting engine can push you ads for home furnishing.\nThe profile could be extended to add an emotional profile – do you respond best to flirting, or negging, or imperatives, or status flattery, et cetera.\nAnd then ads would be automatically inflected with a sentiment overlay to change the voice or change the copy of the message to increase the likelihood that you respond.\nWhen voices are synthesised, it kinda doesn’t matter if they’re only slightly more effective at getting you to convert – because you can robo-call a million people at once.\nAnd if synthesising is too hard (because it means solving for computer-generated conversations), then:\nWhy not build artificial flirtation into call centre software? Operators speak with whatever accent they have and with flat affect, and the machine automatically inflects their words to get you to agree to the broadband bundle upsell or whatever.\n(Coercion prosthetics. Could a persuasive voice changer be built into my face mask?)\nInhumanly persuasive centaur deepfakes are going to be wild.\nWhat is the anti-spam analogue in a world of coercive voice manipulation?\nI look forward to AirPods with smart transparency mode, a kind of audio firewall (as previously speculated (2021)), with a new “anti enchantment” filter: you hear voices as normal, but with flirting and charisma automatically deducted.\n",
    link: "/home/2022/03/16/flirtation",
  },
  {
    title: "Robots for folding laundry at home: two approaches",
    date: "20.17, Tuesday 22 Mar 2022",
    content:
      "I’m still kinda surprised that home robots stalled out. Nothing big since Roomba launched 20 years ago.\nRing’s home security drone, which monitors your house by flying a camera around inside on pre-set paths, was announced in September 2020 and is still MIA – you can apply for an invitation to purchase one (The Verge). Ring is an Amazon company. Amazon’s Astro robot is also invite-only but is shipping: it’s a smart speaker on wheels and has optional cup holder and (coming soon) blood pressure monitor accessories. Check out some Astro customer videos.\nBut why not more?\nEconomics? Hardware has never been great for margins – if you’re a big tech firm, put your effort into software and platforms to gather data to drive marketplace activity.\nMaybe it’s just too hard to make something good? In the old days, technology commoditised really fast component by component. But maybe the requisite tech isn’t easily available and reconfigurable – mmwave radar is new and specialised to cars; the AI to move in the home requires vast amounts of training data, an expensive proposition in itself. So in previous cycles we got wild invention from the recombination of commoditised tech, and that process has blocked somehow.\nWhat if it’s a lack of imagination?\nFOR INSTANCE:\nFoldimate is a home laundry folding robot. (Thanks Howard van Rooijen.)\nIt’s the size of a fridge and you feed your clothes in at the top, a bit like feeding a giant laser printer one sheet of paper at a time. PC LOAD UNDERPANTS. It hasn’t shipped yet.\nAlternatively, from 12 years ago: Berkeley scientists develop a robot that folds towels. Absolutely you must watch the video: the robot arm rotating the draped towel for the computer vision camera is uncanny and beautiful.\nAnd whereas Foldimate feels like an approach that’s so focused that you have to ask why you would bother, the Berkeley approach is more generative…\nIf you had a robot arm to fold towels, then why not pick it up and move it around the house and get it to do other things?\nDo the dishes.\nKnead sourdough.\nMix cocktails.\nCatch tiny house plant flies out of the air, for as long as those darn things are lifecycling away in the top inch of soil (guess what I’ve been dealing with recently).\nWhat if it is an imagination problem? The success of Apple means that companies nowadays want to be vertically integrated: figure out the product, but then also figure out the potential ecosystem and where to situate oneself in the value chain to extract maximum profit… and don’t do anything at all unless you can see a route to get there.\nWhat if we’re all so out of the habit of thinking of general purpose technology that nobody’s thinking really hard about robot arms that are both safe around kids and programmable to e.g. both pick up toys and also make cupcakes when you hand it the ingredients?\nThere’s an interesting paper to be written on why innovation like this isn’t happening.\n",
    link: "/home/2022/03/22/robots",
  },
  {
    title: "The unbearable lightness of my pockets",
    date: "20.22, Monday 28 Mar 2022",
    content:
      "I replaced my wallet and now I’m concerned that I’ve over-optimised my pockets and I’ll mistakenly lock myself out of my own life.\nI normally carry a regular wallet but can’t remember when I last used it for anything other than (a) coffee shop loyalty cards and (b) a bulky CVC store. I no longer carry cash.\nSo yesterday I replaced it with one of those cardholders that magnetically attaches to the back of my phone, relegating almost all the physical stuff to a pot on my desk.\nI also carry half a keyring – the other half has my car keys and I only join the two halves when I’m driving.\n5,000 years ago:\n\nThe oldest proof (so far) of a human sporting a pocket-like feature was a mummified fellow found frozen in the alps in 1991. Otzi or “Iceman”, as he is now known, is thought to have lived around 3,300 BCE. At 5,300 years old Otzi’s was found to be a perfectly preserved and clothed specimen of the ancient world. Otzi had held his plethora of secrets well, as enthusiastic researchers were to discover. One of the most interesting items Otzi was wearing, was a pouch that was sewn to his belt. The contents of his pouch held a cache of useful items including; a scraper, drill, flint flake, bone awl, and a bit of dried fungus.\n– Molly Hamilton, A History of the Pocket (Folkwear, 2020)\n\n(Dried fungus?)\nThat essay is an illuminating read on the long history of women, pockets, and control:\n\nPocket inequality began in the 17th century, when women bore the brunt of insecurity and lack of status by having to secure their possession on their bodies.\nPurses, invented during the French Revolution: considered ridiculous, because they were barely large enough to carry a handkerchief or a coin. … Women had no need to carry anything of consequence that allowed any form of independence.\nPockets as a practical symbol of freedom: A 1910 ‘Suffragette suit’ became the rage, which sported six to eight pockets which were easily accessible and some were in plain sight!\n\nReally fascinating. Go read!\nA symbol of liberation. But they also weigh you down, right?\nShorts weather means I want to economise re grams in pockets.\nSo I no longer carry a ton of plastic cards – I use Apple Pay and carry a single backup card.\nI’ve considered whether I would also stop carrying my keys, replacing them with NFC versions, and I guess the answer is probably but I would also need a mechanical backup.\nThe question for me is not: what do I do incase my phone runs out of battery.\nThe question is instead: how do I get back up and running if I lose what’s in my pockets.\nFOR EXAMPLE:\nNot too long ago I reinstalled a bunch of my electronics at the same time and got into a situation where, to get back into my account, I needed a 2-factor-authentication security code that I could receive on any of my existing devices. Which were all currently in the same boat.\nAnd without being logged into my main account, I wouldn’t be able to access my password manager, so I would be locked out of all my other internet accounts too. Including email, which means I wouldn’t be able to prove my identity, etc.\n(Yes this is what recovery codes are for.)\nI can’t remember what I did - I think I found an old device that was still signed in and generated a 2FA code on that - but it gave me a scare.\nThe analogy is a Black Start.\nPower stations take power to run. So if the electric grid goes down, maybe a solar magnetic storm (we’re due one) and the power station goes offline too, how do you restart it?\n\nNormally, the electric power used within the plant is provided by the station’s own generators. If all of the plant’s main generators are shut down, station service power is provided by drawing power from the grid through the plant’s transmission line. However, during a wide-area outage, off-site power from the grid is not available. In the absence of grid power, a so-called black start needs to be performed to bootstrap the power grid into operation.\nTo provide a black start, some power stations have small diesel generators, normally called the black start diesel generator (BSDG), which can be used to start larger generators (of several megawatts capacity), which in turn can be used to start the main power station generators.\n– Wikipedia, Black start\n\nRegionally some stations are nominated as black-start sources for entire grids. Something to consider if you’re ever in the situation of designing a complex system and considering how to bootstrap from worst case scenarios.\nAND SO:\nLet’s say I lose all my stuff and my devices need a full 2FA sign-in: how do I black start and ladder my way back up Maslow’s hierarchy - house, money for food, communication, Twitter - with just what’s in my head?\nThere’s a lot of complexity in the security that comes with tech. By reducing the independent moving parts and consolidating to, say, my phone, which is protected behind a code and Face ID, I’m gaining in object count efficiency but increasing in complex interrelations. What if getting access to cash means needing access to my phone means needing access to the recovery codes in my house which means needing access to cash to pay a locksmith which means needing to my password manager means access to my phone, etc?\n(It nearly happened once: we were burgled and I was able to bootstrap back from a phonecall to the credit card company to a locksmith, then from an old laptop to recovering the stolen one. It took a few days. But that was before 2FA etc. It would be harder now.)\nWhat terrifies me is accidentally getting stuck in a circular dependency. Actually circular dependencies are not hugely tricky to spot – what concerns me more is a subtle lockout. I don’t feel like I have the capacity to generate a dependency graph on the build sequence of my own life. How many seemingly disconnected breakdowns sit between life today and me living on the street, desperately trying to remember random recovery phrase syllables? I feel like this is something, with their focus on multitools and nice pens, neglected by the everyday carry folks. The pocket-sized identity black start device.\nLong story short, changing my wallet was quite the psychological moment.\nGenerally all of this is connected to my anxiety about optimisation through complexity. Novel feelings of the 2020s. Or maybe it’s not so new. Maybe Otzi’s dried fungus five thousand years ago had some kind of black start function too. Who knows.\n",
    link: "/home/2022/03/28/pockets",
  },
  {
    title: "I don’t believe in Zoom fatigue. HOWEVER…",
    date: "21.37, Tuesday 29 Mar 2022",
    content:
      "I’m sceptical about “Zoom fatigue,” which gets talked about a bunch, this idea that you get fatigued from spending a ton of time over the day on video calls.\nOR RATHER what I mean is, yes, I do indeed get fatigued from a day of video calls (evidence: how I right now), but no, I don’t think it’s down to number of hours on calls specially.\nMy guess is that it’s about repeated and rapid changing social context.\nYou’re in a high bandwidth interaction (full video, full audio, conversational turn-taking, eye contact), then the call ends and you’re on your own in your room. Then high bandwidth interaction, then on your own, then high bandwidth interaction, then etc.\nIt’s not Zoom fatigue, it’s Zoom whiplash.\nIt’s a hunch. I can’t prove this.\nThe trick to get around this is to move smoothly up and down the gradient of social interaction intensity, never dropping below a basic floor of presence: the sense that there are other people in the same place as you.\nInstead of having two modes, “in a call” and “on my own,” we need to think about multiple ways of being together which, minimally, could be:\n\nIn a video call\nIn an anteroom to a video call, hearing the sound of others\nIn a doc together\nOn my desktop but with the sense that colleagues are around\n\nAnd the job of the designer is to ensure that their software ensures the existence of these different contexts, instead of having the binary on-a-call/not-on-a-call, and to design the transitions between them.\n(I posted in January about lessons from architecture for the metaverse, drawing from A Pattern Language by Christopher Alexander, and that was specially about how to design this kind of smooth social gradient.)\nPresence? The solution to social context whiplash.\nAs a baseline, ensure that the user always has a sense that other people are around. That’s all presence is.\nIf you have presence as a “default” then you can move up and down the social gradient quite happily.\nIt’s pretty easy to create a sense of presence in software:\n\nSlack does it by giving you a list of your colleagues who are online, with a little green dot by whoever is active.\nFigma does it by having moving multiplayer cursors on every webpage.\n\nIt has to be live.\nHOWEVER, in solving the whiplash problem by insisting on a baseline of presence, we’ve introduced a whole new problem: being around other people is exhausting.\nBeing on display is exhausting! What’s at the root of that? Another hunch…\nWhen you have “presence” as a software feature, there’s a vague sense of being monitored. You can never escape the idea that other people can tell whether you are active at your computer or not. Some people care about this more, others are able to care about it less, but it’s there none-the-less.\nWhat happens is that the part of our simian brains that looks after “presentation of self” (per Goffman) kicks in. That’s work. The self-governing of how one is perceived by others.\nNot quite panoptic but sousveilled – the act of watching one-another rather than surveillance from above.\nSo you end up being ever so slightly aware that other people can tell whether you’re active on your computer or not. Whereas, in the office, people can tell that you’re working by the view of you concentrating - whether hunched over a sketchbook or staring preoccupied at the ceiling - when you’re remote, it’s totally equivalent whether you are not moving your cursor because you’re thinking harder than you ever have… or if you’ve snuck off down the shops. Which means you have to care about it. This creates a unnamed paranoia and incentivises the performance of work rather than work itself.\nI.E. IN A NUTSHELL: presence can be exhausting.\nIntroduced in 2011, the US military has a drone surveillance technology for monitoring motion over an entire city. The project is named Gorgon Stare (Wikipedia).\nAnd it’s an incredible name, right? Because the effect of the panoptic gaze on the city is to freeze it - if you don’t want to be seen then don’t move - what the drone’s eye, like the eye of Medusa (a Gorgon), is to turn people to stone.\nSo there a just a touch of telepresence that I feel like that, like 0.1% as much but still.\nLike: I’m unable to type in a Google Doc if other people are there. Do you get that? I end up writing in another doc and copy-and-pasting in the new iteration. It’s a fear! Literally petrifaction/petrifying. The Gorgon Stare of Anonymous Goose lurking up there in the top right of the browser viewport.\nPREVIOUSLY: Freud’s whole thing about Medusa was that individual wasn’t being turned to stone by Medusa, but instead making a decision to become stone in a personal response, escaping their own terror of castration. To do with Medusa’s head snakes resembling – look, as previously discussed, go read. I would love to know what Freud would have made of Google Docs.\nI love this cascade of design problems/solutions/problems.\nZoom fatigue is really Zoom whiplash so introduce presence.\nPresence is itself exhausting. And so…?\nWhat’s the best way to personally feel present, online, but without the knock-on micro effects of panoptic sousveillance to everyone else on your presence list? One to figure out.\nI suspect this problem can be solved by having lots of different places that you can be present in.\nInstead of Slack showing everyone who is online (present) right now, it should show who is online just in the channel I happen to have open. That way I get the benefit of feeling like there are people around me, but without the concern that other people might think I’m lazy if I take 30 minutes away from my computer to do some hard thinking. I have plausible deniability. As far as anyone else is concerned, I may just be in another room.\nAnd that’s why social software should always have multiple rooms that you move between.\nThe opposite of fatigue is immersion.\nWhen Ze Frank invented the genre of personal web videos - video blogging - back in 2006 (which I wrote about here) he was absolutely insistent that the presenter had to stare directly into the camera. He went as far as editing out his blinks.\n\nhe advises would-be vloggers not to blink because when you blink, “that’s one less connection made” with viewers.\n\nI have a similar feeling towards social software.\nWhen you have a video call, you feel immersed in the social context.\nWhen you drop back to a space without any kind of social context, not even presence, your desktop, it breaks immersion. Blink.\nBut when your software makes a promise to never drop the social context below the presence baseline, you never stutter immersion, and it just builds and builds and builds as you move around.\nThat’s what I’m finding in the day job anyhow. (We’re building a platform for being social online, with an architectural approach and multiple “spaces” that you move between. There’s nothing special going on with the tech, it’s just multiplayer webpages, no rocket science, but gosh it works – a kind of lo-fi metaverse.)\nTANGENTIALLY:\nWhy did the US military develop Gorgon Stare? Because of Will Smith.\n\nIn Enemy of the State there’s an imagined technology, a satellite that can watch people on the ground across vast areas. This was of course pure fantasy at the time. An engineer who works for the government saw the film in a theater and thought it would be quite incredible if the government could actually do that. That seed of inspiration precipitated a whole series of events and development projects that culminated with Gorgon Stare about ten years later. It took a while, but during that period the rate at which camera technology got more powerful outpaced Moore’s law, which predicts the rate at which computer chips become more powerful. It was this phenomenal jump in capability in a very short period of time, all driven from an initial seed of inspiration, a 1998 Will Smith blockbuster.\n– Sam Jaffe Goldstein, Longreads, Nothing Kept Me Up At Night the Way the Gorgon Stare Did (2019)\n\nMy friend Mark H tells me that Enemy of the State is an unofficial sequel to Francis Ford Coppola’s The Conversation (1974), Gene Hackman’s character being the same but with a different name because they couldn’t sort out the rights. The Conversation being notable for its remarkable sound and additionally distinctive camera-work from above to visually depict the narratively essential long-range sound monitoring equipment, a visual trope that was naturally extrapolated in Enemy of the State to its unreal-but-then-becoming-real satellite viewpoint. An extraordinary conceptual ancestry.\n",
    link: "/home/2022/03/29/whiplash",
  },
  {
    title: "Dunbar’s number and how speaking is 2.8x better than picking fleas",
    date: "20.56, Tuesday 5 Apr 2022",
    content:
      "150, Dunbar’s number, is the natural size of human social groups. Robin Dunbar’s 1993 paper, where he put forward this hypothesis, is a great read – it’s got twists and turns, so much more in it than just the 150 number.\n(If you design software for people to socialise or collaborate, like Slack or Google Docs, then what Dunbar says is useful to know! Also true if you build communities in Discords or DAOs, I reckon, good knowledge to have when structuring the spaces and processes for interaction.)\nI’ve added a reference to Dunbar’s paper, Coevolution of neocortical size, group size and language in humans, at the bottom of this post. It’s not online but you can snag a pre-print PDF here.\nThe paper and the number are both super well-known.\nBUT - I insist! - still not well-known enough in our software and design circles. Especially given there is a revitalisation and renewed interest in building and innovating with the social internet.\nSo I figured I would share my favourite bits.\nDunbar lists a bunch of places this 150 group size appears. To pick out a convincing selection…\n\n6500-5500 BC: the size of Neolithic villages in Mesopotamia are of about the same magnitude.\nIn South Dakota: the Hutterites regard 150 individuals as the limiting size for their farming communities: once a community reaches this size, steps are taken to split it into two daughter communities.\nAcademic communities: research specialities in the sciences tend to consist of up to 200 individuals, but rarely more.\nProfessional armies have a basic unit of about 150 men: This was as true of the Roman Army (both before and after the reforms of 104 BC) as of modern armies since the sixteenth century.\nWork: the likelihood of having friends within the workplace reaches an asymptote at a shop size of 90-150 individuals.\n\nIt’s the number of people on your Christmas card list. When AOL Instant Messenger launched, it was the maximum allowable number of buddies.\n(And the number of Pokemon in generation one… 151. Huh.)\nPretty compelling. Something to be explained.\nThe clever bit:\nThe catarrhine primates: Old World monkeys (baboons, macaques, mandrill, and ~130 other species) plus the apes… tailless simians including gibbons, gorillas, chimpanzees, and humans.\nDunbar’s insight was to look at the catarrhine primates and realise that these three factors are connected:\n\nGroup size\nTime devoted to social grooming: a bonding mechanism (if you wanna have friends, you gotta spend time picking fleas)\nNeocortex size, being the amount of brain available for tracking the social group, i.e. a limit on the number of relationships that an animal can keep track of in a complex, continuously changing social world\n\nDunbar gives equations that relate these.\nThen:\n\nIf we extrapolate from the nonhuman primate regression, what group size would we predict for anatomically modern humans, given our current neocortex size?\n\nOh-ho, a prediction!\nEquation (1) yields a predicted group size for humans of 147.8.\nSo there’s the observed number 150, right there in the size of the brain.\nBUT THEN, A TWIST:\nThe group size predicted for modern humans by equation (1) would require as much as 42% of the total time budget to be devoted to social grooming.\nWe (humans) clearly don’t spend all that time on social grooming. There’s not the time in the day. It’s incompatible with resting, foraging, and staying in the shade on hot days. Chimpanzees are the most comparable to humans, and they have a social time budget of about only 15%.\nSo what gives?\nHumans, says Dunbar, must have a method of social grooming that is 2.8x more effective than the method used by the nonhuman primates. But what is it?\nWhat is our ultra efficient bonding mechanism, better than caring, grooming, and picking fleas? It is LANGUAGE.\n\nThe observed mean group size for chimpanzees (presumably the closest approximation to the ancestral condition for the hominid lineage) is 53.5 (Dunbar 1992a). Since the predicted size for human groups is 147.8, this implies that language (the human bonding mechanism) ought to be 147.8/53.5=2.76 times as efficient as social grooming (the nonhuman primate bonding mechanism).\n\nSpeaking is way better than grooming, which requires 100% attention and is one-on-one. But we can talk to more than one person at once! See: not only can speech be combined with almost every other activity (we can forage and talk at the same time), but it can also be used to address several different individuals simultaneously.\nDunbar’s suggestion is that language evolved as a ‘cheap’ form of social grooming, a way to increase group size. And there follows a cascade of consequences and speculations…\nThe interesting bit, for me, is about the “natural” size of a conversation group.\nDunbar’s prediction, based on the estimated efficiency gain versus chimps: human conversation group sizes should be limited to about 3.8 in size (one speaker plus 2.8 listeners).\nAnd this holds up!\n\nLooking at restaurant reservations: the mean size of 3070 groups was 3.8.\nIn a university refectory: the average number of people directly involved in a conversation (as speaker or attentive listener) reached an asymptotic value of about 3.4 (one speaker plus 2.4 listeners) and that groups tended to partition into new conversational cliques at multiples of about four individuals.\n\nWhich feels about right, right?\nI mean, think of a sitting with friends round a dinner table. Two people, three people, four people, it’s one conversation. Five people, it’s still one conversation – just. At six it’s hard to maintain; the conversation often splits and oscillates between 4/2 and 3/3 modes.\nThe cognitive limit corresponds to how our ears and voices work.\n\nIt turns out that there is, in fact, a psycho-physical limit on the size of conversation groups. Due to the rate at which speech attenuates with the distance between speaker and hearer under normal ambient noise levels, there is a physical limit on the number of individuals that can effectively take part in a conversation. Sommer (1961), for example, found that a nose-to-nose distance of 1.7m was the upper limit for comfortable conversation in dyadic groups; this would yield a maximum conversation group size of five individuals with a shoulder-to-shoulder spacing of 0.5m between adjacent individuals standing around the circumference of a circle.\n\n“Comfortable” conversation means background noise levels typical of both offices and city streets – our normal voice levels, our normal hearing, our normal comfortable personal social distance, our normal width of shoulders all combine to produce conversional groups of… 5 people.\nAbsolutely wonderful. It makes me laugh every time I read this bit.\nEvidence for Dunbar’s Number in the analysis of 6 billion phone calls:\nDunbar actually doesn’t say that we devote “grooming time” to the whole social group of 150. Rather he says that the 150 is made up from welding together much smaller “primary networks”: coalitions, friendship groups. Intensive grooming (language, for humans) is reserved for close friends. Our intimate group is very small, averaging just five.\nDunbar suggests other group sizes too, in papers that follow his 1993 original…\n\nIndividuals, he says, generally have up to five people in the closest layer. The next closest layer contains an additional 10, the one beyond that an extra 35, and the final group another 100. So cumulatively, the layers contain five, 15, 50, and 150 people.\n– MIT Technology Review, Your Brain Limits You to Just Five BFFs (2016)\n\nAnd this result is new to me:\nLooking at some six billion calls made by 35 million people they did some number crunching and…\n\nthe average cumulative layer turns out to hold 4.1, 11.0, 29.8, and 128.9 users.\n\nTa-da! Dunbar’s number proved, close enough.\nYou can get the PDF on arXiv: Calling Dunbar’s Numbers (2016). I’ve included the full reference below.\nKinda amazing to have evidence for something that feels so intuitive (the average number of best friends/family) and that lends confidence in the discovery in the data of Dunbar’s number itself too.\nBTW I found that second paper via Ethan Mollick (@emollick) on Twitter who daily shares and summarises fascinating papers and is 100% a must-follow.\nAgain, why this is relevant: if you’re designing systems for working in groups, whether that’s IRL workgroups and committees, or online chat groups, or software, the relevant numbers are 150 people who can be recognised over time, and approx 5 in a simultaneous conversation. That’s what it suggests to me anyway.\nThe numbers are just averages, of course, and we’re each individuals and you shouldn’t put too much weight on evo psych or be deterministic about this stuff, but what we can do is use these as springboards to provoke new feature ideas. Such as…\n\ncould a Figma document suggest how to subdivide itself once more than five people are involved? Could my Twitter auto-segment into groups of 150?\ncould we automatically adapt the interface of Zoom at the various Dunbar layers? Can we visually (and with interaction design) represent the structure of a 150 group “welded together” from smaller table-sized conversational groups, the two scales operating simultaneously?\nin pseudonymous groups where everyone is represented by avatars and obscure names, such as web3 communities on Discords, what is the right level of detail to help our ancient recognition systems to kick in, so we can get to Dunbar’s number and all the helpful formal and informal networks and subgroups that arise?\nwhen we’re building software-enabled co-ops or, in new language, creating governance and consensus systems for DAOs, could we optimise around Dunbar’s layers in order to avoid the inevitable bureaucratic requirements when we don’t –  bureaucracy which is now perhaps revealed to be a social technology, a kind of relationships prosthetic for when self-organisation caps out.\n\n(Those last two points relevant now the global public timelines of 2010s social media are evaporating into the unindexable Discords and WhatsApp groups of 2020s virtual private neighbourhoods.)\nAND SO ON.\nReferences\nDunbar, R.I.M., 1993. Coevolution of neocortical size, group size and language in humans. Behavioral and Brain Sciences 16, 681–694. https://doi.org/10.1017/S0140525X00032325\nMacCarron, P., Kaski, K., Dunbar, R., 2016. Calling Dunbar’s Numbers. Social Networks 47, 151–155. https://doi.org/10.1016/j.socnet.2016.06.003\n",
    link: "/home/2022/04/05/dunbar",
  },
  {
    title: "Filtered for machine misunderstandings",
    date: "07.32, Monday 11 Apr 2022",
    content:
      "1.\nXerox scanners used to have a bug that would silently replace numbers in the text of documents to make them compress better.\nThe bug was discovered by David Kriesel in 2013:\n\nWe got aware of the problem by scanning some construction plan last Wednesday and printing it again. Construction problems contain a boxed square meter number per room. Now in some rooms, we found beautifully lay-outed, but utterly wrong square meter numbers.\n\nIt’s to do with the image compression algorithm:\n\nImages are cut into small segments, which are grouped by similarity. For every group only a representative segment is is saved that gets reused instead of other group members, which may cause character substitution.\n\nEg The 65 became an 85 (second column, third line).\nInvoices, engineering plans… scanners and copiers in the Xerox WorkCentre line had this bug, undetected, for 8 years.\n\nFor PDFs that were scanned with the named Xerox devices during the last 8 years, it cannot be proven what characters were on the original sheet of paper at the places that are now defined by reused patches.\n– D. Kriesel, Xerox scanners/photocopiers randomly alter numbers in scanned documents (2013)\n\n(See that link for Kriesel’s full write-up.)\nIt would be neat to trigger this deliberately… a document that, when scanned, turns into something else.\nMaliciously: could I do wet signatures on a contract with a company that, when the agreement is scanned to accounts payable, leads them to transfer me a different amount of money?\nSEE ALSO: that time I got my hands on a real-life ugly shirt, a ridiculous-looking garment that magically renders the wearer invisible to CCTV.\n2.\nThe Einstein-Marilyn optical illusion, a photograph of the face of Albert Einstein if the image is large or close up, and Marilyn Monroe if the image is small/seen from a distance – it’s to do with spatial frequency.\nSee the illusion at the Mind Hacks blog.\nWhich also explains how it works.\n\nHigh spatial frequency changes means lots of small detail. …\nDepending on distance, different spatial frequencies are easier to see, and if those spatial frequencies encode different information then you can make a hybrid image which switches as you alter your distance from it.\n– Tom Stafford (Mind Hacks), A graph that is made by perceiving it (2018)\n\nReferences provided.\n3.\n\nExcel is a behemoth in the spreadsheet world and is regularly used by scientists to track their work and even conduct clinical trials. But its default settings were designed with more mundane applications in mind, so when a user inputs a gene’s alphanumeric symbol into a spreadsheet, like MARCH1 – short for “Membrane Associated Ring-CH-Type Finger 1” – Excel converts that into a date: 1-Mar.\nThis is extremely frustrating, even dangerous, corrupting data that scientists have to sort through by hand to restore. It’s also surprisingly widespread and affects even peer-reviewed scientific work. One study from 2016 examined genetic data shared alongside 3,597 published papers and found that roughly one-fifth had been affected by Excel errors.\n– The Verge, Scientists rename human genes to stop Microsoft Excel from misreading them as dates (2020)\n\nAND SO, over the past year or so, some 27 human genes have been renamed, all because Microsoft Excel kept misreading their symbols as dates.\nHumans have a bunch of feedback loops to prevent signal degradation in communication: we have a moral code against factual inaccuracy (you’re either a liar or unreliable, depending on intent, and our morality is constructed to see both as failings); the legal system has “protected characteristics” – you are not allowed to pejoratively stereotype when it comes to gender, race, and so on. Stereotyping is a disallowed form of data compression. (The feedback loops adapt over time to handle changes in the machinery of inter-person signal transmission and the data for which we demand high fidelity.)\nWhat is the equivalent for machines? Is Excel a liar? How should an application be made to feel ashamed?\n4.\niPhones are no longer cameras in the traditional sense. Instead, they are devices at the vanguard of “computational photography,” a term that describes imagery formed from digital data and processing as much as from optical information.\nHow the camera works depends on what (it thinks) it’s looking at.\n\nwhen a user takes a photograph with the newest iPhones, the camera creates as many as nine frames with different levels of exposure. Then a “Deep Fusion” feature, which has existed in some form since 2019, merges the clearest parts of all those frames together, pixel by pixel, forming a single composite image. … The iPhone camera also analyzes each image semantically, with the help of a graphics-processing unit, which picks out specific elements of a frame–faces, landscapes, skies–and exposes each one differently.\n– The New Yorker, Have iPhone Cameras Become Too Smart? (2022)\n\nDo some faces trigger a stronger spike than others? What faces are loved by the iPhone camera? What machine misinterpretations are being laid down in the historical records, and how may we discover them?\nCould you wear a shirt that targets the iPhone sunset detector, fooling the computational camera into boosting your colour saturation? That would help you pop in a crowd.\n",
    link: "/home/2022/04/11/filtered",
  },
  {
    title: "How about twice yearly MRIs for a personal Check Engine light",
    date: "13.30, Thursday 14 Apr 2022",
    content:
      "I have a hunch about MRI that comes from seeing a company that an old uni friend has built around liver disease.\nThe original insight of my friend, who is a doctor, is to do with a particular liver condition which is (or was) diagnosed with a biopsy. Obviously that’s a medical procedure. It’s invasive. He discovered that the biopsy could be substituted with an MRI scan plus new techniques in computer vision.\nAnd I wonder how many medical diagnoses are tractable to that same approach?\nAdd to this three points:\n\nMRI machines and the associated setup are pretty portable. I’ve seen pictures of an MRI unit in a shipping container, dropped into a hospital car park. So treat is like a black box: patient in; images out. Like any technology, the more MRIs that are run, the cheaper it’ll get.\nMRIs aren’t x-rays. As far as I know, you could have an MRI every day of the week and it wouldn’t do you any harm. You might get a bit of a headache from the clanking of the electromagnets as they quench but that’s it. (It was pretty noisy when I got an MRI for my knee, but I remember thinking at the time: I’ve paid more money for worse gigs.)\nBeyond the initial imaging, all the work of diagnosis is data and software. It’s quick, parallelisable, and machine learning models can be upgraded over time: hetting a second opinion is not like having to get back under anaesthetic to collect another sample for biopsy. As there is more training data and the software improves, second and third and fourth opinions can be run on the original images without having to return to the patient.\n\nPut all of this together:\nCould our future include pro-active regular screening for all kinds of conditions?\nImagine you get a full-body MRI every 6 months. Nothing wrong necessarily, it’s just like going to the dental hygienist. Then 100s of different machine learning models run, one looking for a particular liver condition, one looking at another organ, another looking for such-and-such anomaly elsewhere, etc. It’s purely precautionary; a way to pick up issues before they get serious; a Check Engine light for your body. You’d get a notification on your phone the next morning.\nAn app ecosystem around regular, precautionary MRI:\nIt’s unlikely that the company which is good at MRI machine manufacture is the same as the company which is good at customer relationship and operations, and it’s unlikely that either of those will have the software focus to train machine learning models to identify specific conditions (each condition probably being the topic of a whole stack of doctoral theses).\nSo I see something that is more like a software ecosystem. As a consumer, you pay (or your insurance pays) for the twice yearly scan. A portion of that fee gets divided amongst the hundreds of separate companies that provide computer vision modules that run across your full-body image, like paying for Spotify streams.\nOR BETTER, to complete the feedback loop, each company might run their software on the image at their own cost, and they receive a success fee for each condition that they identify which is also successfully confirmed. (With some kind of adjustment to incentivise a low number of false negatives too.)\nThe role of the operations company is to orchestrate the ecosystem and economics, also managing the distribution to the computer vision app developers of training data (source imagery and eventual known outcomes from existing biopsy techniques and medical records).\nOne analogy is the company Planet which uses 200 satellites to take daily, high resolution images of the surface of the entire globe. Some of the satellites are to 50cm resolution.\nThink of what you can do with high frequency global photography: look at infra-red signatures to figure out, to the day, when your crops are ready for harvest; monitor container ship positions to predict future pricing; see where to target your roof insulation sales effort; check for broken street lamps against a “known good” list; or whatever.\nSure you could achieve these by installing sensors, or using drones, or even walking the streets… but why bother? The satellite imagery has already been collected. The rest is software that runs on a schedule in the cloud.\nComputers don’t get bored. Software is perfect for trivial or speculative repetitive tasks. It’s pixels and algorithms and compute cycles, that’s all.\nI wonder what it would take to develop the technology (and establish the market, private or public) for this kind of MRI-based early warning system for personal healthcare. I can’t imagine that existing MRI tech would be a good fit for regular full-body – but maybe, one day, given the right incentives?\nFrom a policy perspective: what kind of white paper would you have to write such that politicians would choose to fund this as industry-sector-creating R&D?\nAnyway it feels kind of inevitable, though I’m not sure how we get there.\n",
    link: "/home/2022/04/14/mri",
  },
  {
    title: "Day 1 notes from picking up a modern VR headset",
    date: "19.47, Wednesday 20 Apr 2022",
    content:
      "I’ve tried VR a few times over the past few years - enough to know that it’s amazing - but never spent real time with it. So I picked up an Meta Quest 2 which is a standalone headset with two handheld controllers.\nThese is my day 1 response. Every time I pick the thing up my views evolve, and I wanted to capture my earliest impressions.\n(Side note #1: the Meta Quest used to be known as the Oculus Quest. Meta is the new name for Facebook, and it’s named for the “metaverse”, which is the imagined future immersive VR world that we all inhabit. My view? A lo-fi metaverse is possible.)\n(Side note #2: The ecosystem is pretty confusing as a newb. It seems like other headsets are basically output devices for other things, like having a fancy head-mounted monitor for your Playstation or Windows PC? I wanted to experience VR as something self-contained, like a phone or a desktop, so I went for the Quest 2… but it turns out that it’s not entirely standalone. You need a powerful Windows box to pair it with if you want to try certain games or apps.)\nKeep in mind that I’m not a gamer. I play video games from time to time, and love a few, but I don’t have a gaming PC and it’s not something that really holds my attention.\nCould VR one day displace my laptop or even my phone?\nApps not games: that’s what I’m into understanding. How far off is that? What are the design challenges?\nSpoiler: No conclusions yet. After one day I’m still informing my intuitions.\nThe operating system “frame” to all the apps is waiting for its Macintosh moment.\nA big job of the OS, from a user’s perspective, is to help you find apps, launch apps, and give you a consistent experience. That helps app developers (discoverability!) and also users (familiarity!).\nThat’s what the “grammar” of the original Macintosh did so well: windows, menus, icons, cross-app copy and paste, drag and drop, and so on. If you learnt how to use one application, you could use them all.\nApple’s Human Interface Guidelines were revolutionary: a philosophy and a spec all at once. You can read them online, as a PDF hosted by Andy Matuschak: Human Interface Guidelines: the Apple Desktop Interface (1987).\nThe iPhone performed the same trick, only it updated the metaphor to make it more immediate: instead of clicking a mouse with your finger which caused a cursor to click an icon, you literally tap an icon with your finger. There is no gap between the embodied action and the metaphorical action.\nWith Quest 2, there are floating on-screen “buttons” that you “tap” by directing a pointer with your hand controller and pulling a trigger.\nI understand that this is a really minor thing for me to focus on. I’m not saying: here is an example of poor design. No. Instead, this is a sign that we’re all still figuring out what this medium is for and what the natural interactions should be.\nLikewise, when there are more apps, the OS-makers will be able to see what the common interface patterns are. Like, do they all organise in a faux 3D environment that the user moves around? Or on the inside of a sphere? Etc. At which point the OS will be able to provide standard tools for apps to draw these UIs.\nIt takes time and it takes work.\nCase in point: this morning I learnt about Quest 2 hand tracking (find out how to activate it here). There’s a whole different way to tap buttons (now: pinch) and interact with interfaces, without using controllers at all.\nIn the meantime there’s no consistent grammar to the apps. I’d like to see more wild experimentation tbh.\nThere is problematic asymmetry in physical social space.\nThe Quest 2 doesn’t come with headphones. It plays sound out of the sides. No headphones is good because it means I have some awareness of what’s around me… but not great for anyone else nearby. It’s noisy! I can’t see who I’m interrupting. There’s just the sound of someone closing a door on me.\nI was fully expecting VR to be antisocial, that’s completely fine. (Actually it’s kinda funny when I’m playing mini-golf in the front room while my wife is watching TV. She gets to laugh at me and we’re still together.)\nIt’s the asymmetry in physical social space that surprised me. \nSo you have asymmetry with sound (you can interrupt people, but can’t tell that you’re interrupting them). You also have it with vision.\nThere’s a feature of the Quest 2 called passthrough. Here are some GIFs on their developer blog. The idea is that, in certain situations, you can see the room around you in fuzzy black and white. (The Quest 2 has external-facing cameras, and it can play the feed on the internal display.)\nPassthrough is magical! (It’s used in some clever ways that I’ll mention below.)\nBut passthrough is weird because sometimes I can sometimes see people outside the headset and sometimes not. But they can’t tell.\nThe thing about gaze is that it’s reciprocal. If I’m looking at you, you can tell (and vice versa). Until now. Using passthrough to see my wife feels a bit like spying? Like, she has an expectation that I’m immersed, but secretly I’m peeping.\nI feel like the headset should have cartoon eyes that appear on the outside when passthrough is engaged.\nI find it physically demanding with stinging eyes and motion sickness.\nMy eyes sting. I’m not blinking enough I think? I’ll get used to it.\nThe headband positioning and weight feels kinda… off. If I don’t get the headset in precisely the right place (which is not it’s natural resting point), I get blurred vision. Industrial design tweaks will fix this.\nMy lower arms get fatigued quickly when using hand tracking (though, weirdly, not with the handheld controllers). Iterating the interaction design will stop this happening.\nMotion sickness. Oh my god.\nYears ago I tried an Oculus Rift with a low poly game and it was beautiful. I stood on an island beach at sunset and looking from the pink blocky trees out to the horizon. Looking up, rain was falling, and as it stops and the clouds parted, stars sparkled. It moved me to tears.\nA week later I tried the same game again - it was in the process of being ported to VR - and the debug code had been left in. The extra code dinged the latency and the apparently view lagged a few milliseconds behind my head moving. It was enough to put me flat on my back in cold sweats for 20 minutes.\nVR sickness is wild. I’m still prone to it.\nI toured Anne Frank’s house using the Quest 2, and my goodness what an incredible experience. Well put together (I explored the space thoroughly) and a story clearly told. I had a lot to think about at the end.\nThen I went straight onto a dinosaur themed rollercoaster. I shouldn’t have chained those two apps. As if the emotional whiplash wasn’t enough, I was on my knees during the rollercoaster, took the headset off halfway through, and was queasy for the rest of the night.\nI think it was something to do with the motion on the coaster? The third and fourth differentials of motion weren’t eased; you could sense the snap.\nAny VR operating system needs to bake “correct motion” into the SDK provided to app and game developers. They should have to fight the code to make people feel sick.\nHere are four magical moments.\nI’m such a Debbie Downer. Virtual reality is amazing. My observations sound like criticisms but they’re not. I’m just trying to get a sense of the state of advancement of the tech. But let’s balance that with some great moments.\nI’ve used VR before. I have an Oculus Rift, original Kickstarter edition, in a box upstairs. I tried VR back in the Virtuality days of the mid 90s, the last VR boom. Then periodically over the last few years.\nGiven all that, here’s what made me gasp on day 1 and what I’m still thinking about.\n\nPeeping through passthrough. The way it works is that you “draw” (in VR) a box on the floor. Within that box, you are immersed in 3D virtual reality. Near the edge, you see the box around you outlined as a grid. As you touch the edge, a hole appears… you can poke your head through, and you see the real world beyond, in black and white fuzzy passthrough. I found myself leaning out to have a chat or to grab a drink. Delightful.\nA Godzilla’s eye’s view. Playing mini golf, I found a button that let me zoom out. Suddenly I was standing in the middle of this golf course arranged on a mountain, the mountain halfway up my chest. Walking just a foot or two, and bending down, and leaning close, I could examine bridges and trees and caves and courses. An incredible, examinable overview, in a way that would take multiple steps on any other device.\nHeight, space, and scale. In the first room of Anne Frank’s house, there’s a steep staircase leading down, but it’s inaccessible from the tour. However I was able to kneel down, put my head through the bannisters, and peer over the edge, down the stairwell, and into the next room. I know this is what VR is all about, but the sense of being located continues to astound. What do we do now the gamut of interaction can include vertigo and awe? It’s like suddenly being given an extra colour.\nObjects that cross the threshold. When I pick up the real-life controls, they appear in VR space. Headset on, everything black and gone – except the controls in my hands are still there. And now they have extra green lights and details on them! Janus objects that face both ways into physical and fictive reality. The controls are real… but realer in VR. So many opportunities for play.\n\nI can’t help but wonder about the non-game applications.\nFOR EXAMPLE:\nThe Godzilla’s eye view of the golf course was 100% a better experience for getting an overview and examining detail than anything on a phone or a desktop. Imagine seeing a spreadsheet or a PowerPoint deck all at once, with all the interconnections overlaid in glowing arcs, and simply leaning closer to read the words or pick up a sheet to edit. It’s so much more immediate than working via windows and scrolling in a viewport. VR and mixed reality are tangibly better ways of dealing with large amounts of data, at macro and micro scales, and relating to it at your own pace.\nThat’s what I’m thinking about with these magical interaction moments: what if they were as fundamental to the future VR user interface as menus on a desktop, or scrolling a list on a phone?\nAs I said I’m training my intuitions so no conclusions yet. Mainstream VR (for apps, not just games) feels super close with the tech and with a ton of work to do regarding interaction design. The space is wide open. Exciting.\n",
    link: "/home/2022/04/20/vr",
  },
  {
    title:
      "Apple is mainstreaming the inventions of Alan Kay. Maybe the metaverse is next",
    date: "21.26, Monday 25 Apr 2022",
    content:
      "I have this semi-stupid semi-serious theory about Apple which is that they are, one by one, mainstreaming the inventions of computer scientist Alan Kay, and that is their raison d’etre. It’s a theory with predictive power because you can speculate where they’re going next.\nDr Alan Kay: a pioneering computer scientist. Here’s a bio and list of inventions (though I’ll get to those). He started at the University of Utah with ARPA funding in the 1960s, then went to Xerox PARC.\nApple:\nOk so first there was the Macintosh which was the first mainstream personal computer, and as we know it was inspired by two tours Steve Jobs and Apple employees took round Xerox PARC in 1979. \nThey saw the Xerox Alto which had been developed in 1972, the first attempt at the bringing to market the PC as invented by Doug Engelbart and team in 1968 (as previously discussed).\nThe story of that visit:\n\nThat day Jobs and his engineers sat in awe as Goldberg and the Alto team demoed the intricacies of the mouse-driven GUI, Smalltalk, as well as the Ethernet technology they had developed to network their Altos together. Jobs was so blown away by the details of the GUI, the rest passed over him like a fog. “It was one of those apocalyptic moments,” Jobs said. “I remember within ten minutes of seeing the graphical user interface stuff, just knowing that every computer would work this way someday. It was obvious.”\n– Living Computers, What Really Happened: Steve Jobs @ Xerox PARC ‘79 (2020)\n\n(GUI = graphical user interface.)\nBUT\nThree years ago, in an answer on Quora, Alan Kay himself reflects on what it was like at Xerox PARC during the Jobs visit: it was the work of my group and myself that Steve saw, yet the Quora question is the first time that anyone has asked me what happened.\n\nA second important fact about the 1979 demo to Steve, was that he missed most of what we showed him. More than 15 years later he admits this in this interview: How Steve Jobs got the ideas of GUI from XEROX [YouTube] where he says that we showed him three things but he was so blinded by the first one (the GUI) that he missed both networking and real object-oriented systems programming.\n\nKay didn’t invent the personal computer, Apple’s first breakthrough mainstream product. That pre-existed his involvement.\nBut Kay was involved in the Xerox Alto as a networked workstation (that’s what it’s called on his Wikipedia page). Un-networked computers and networked computers take you to completely different ways of working.\nJobs made good on the first miss, networking, with the iMac – the beginning of Apple’s rebirth under Jobs: The ‘i’ stands for ‘Internet,’ he said.\nJobs made good on the second miss, object-oriented systems programming with his second computer company, NeXT.\nThe NeXT operating system was famously, heavily object-oriented – which made it insanely easy to develop for. (Using a NeXTstation was what got me into coding.) NeXT was acquired by Apple, Jobs returned (and launched the iMac), and the OS became the underpinnings of first Mac OS and then iOS. The reason iPhones ignited such an incredible app ecosystem is down the NeXT-derived operating system.\n(If you don’t believe me, then you never tried to develop for Symbian, the operating system for the Nokia Series 60 line, far and away the most popular smartphone line when iPhone came out. Symbian was so incredibly difficult to develop for that I remember seeing a flashlight app on Nokia’s app store selling for like $20. The flashlight was literally the tutorial app you would build when you set up the developer environment. Developer friction was that high.)\nAnyway: Alan Kay invented object-oriented programming. That was his thing.\nAlan Kay also invented the Dynabook.\n\nThe KiddiComp concept, envisioned by Alan Kay in 1968 while a PhD candidate, and later developed and described as the Dynabook in his 1972 proposal “A personal computer for children of all ages”, outlines the requirements for a conceptual portable educational device that would offer similar functionality to that now supplied via a laptop computer or (in some of its other incarnations) a tablet or slate computer with the exception of the requirement for any Dynabook device offering near eternal battery life. Adults could also use a Dynabook, but the target audience was children.\n– Wikipedia, Dynabook\n\nThe illustration of the Dynabook concept (which is on that Wikipedia page) is basically an iPad with a keyboard. Kay didn’t originate that form, but he made it believable.\nFor Steve Jobs, the lineage was clear. He invited Kay to the bombshell launch of the iPhone.\n\nI think he invited me to the 2007 iPhone unveiling partly because it was kind of a tiny “Dynabook” – and he had always wanted to do one – and partly because he was going to use a quote of mine that he had always taken to heart “People who are really serious about software should make their own hardware”.\nThe photo of us chatting was taken right after the event. He brought the iPhone to me, put it in my hands, and asked: “Alan, is this good enough to be criticized?”. My reply was to make a shape with my hands the size of an iPad: “Steve, make it this size and you’ll rule the world”.\nWhen the iPhone had been revealed a few minutes earlier I realized that they must already have done an iPad/Dynabook-like machine (easier) and that the “iPhone first” must have been a marketing/timing decision.\n\n(From an article which excerpts another of Kay’s Quora answers: Alan Kay Talks What he and Steve Jobs Talked About at the Original iPhone Keynote in 2007.)\nAlthough Jobs saw the “slate” form factor as key to the Dynabook, Alan Kay believes that Apple has missed the point: in another Quora answer, Kay goes into the goals of the Dynabook concept and points out that it’s for children and it’s programmable. But Apple didn’t allow this: users (even children) were forbidden to make actively programmable things on the iPad and share them on the Internet.\nHey but… Swift Playgrounds, Apple’s game-like environment for learning programming and creating apps on iPad, which is mysteriously getting more and more powerful each year? I always wonder why so much effort goes into it. Something going on there.\nSo, beyond personal computers and the Macintosh, we’ve got…\n\nnetworked workstations: the iMac\nobject-oriented programming: NeXT, Mac OS, and iOS\nDynabook, slate computers: iPad\nDynabook, kids and programming: Swift Playgrounds\n\nWhat’s next?\nWELL.\nI’m not saying that pursuing Alan Kay’s inventions is exclusively what Apple does. In bringing something to market, it never looks exactly like the original vision. It’s slower maybe, or the step-by-step strategy reveals something else along the way that becomes a preoccupation for a decade. But Apple trends back towards the North Star, which is Alan Kay.\nAnd am I genuinely saying that this is what Apple consciously does? That there is someone in corp strat combing over Kay’s work and figuring out what to mine? Probably not. Not really.\n(Maybe Steve Jobs wrote it into a giant Seldon’s Plan for the future of the fruit company, maintained and monitored to this day in an inner sanctum by a secret cadre of mini Tim Cooks.)\n“Apple is channelling Alan Kay” is not really a theory, strictly. It’s a heuristic metaphor, imaginative scaffolding. I carry around a whole bundle of these in my head, as do we all I suppose. I’m not bothered about the truth value of a heuristic metaphor, mainly that it’s crudely on the money enough such that I can (a) reason more rapidly and also (b) stretch it to arrive at new possibilities.\nSo what happens if we stretch this one?\nReading Alan Kay’s Wikipedia bio, after forays into Atari, Apple itself, and the One Laptop Per Child project, the great as-yet-not-mainstreamed invention that really stands out to me is Croquet.\nCroquet is Croquet is a software development kit (SDK) for use in developing collaborative virtual world applications.\nIt’s a programming environment to create multiplayer 3D worlds… which are themselves programmable.\nLook: it’s a 3D persistent world that multiple people can be in at the same time.\nSounds… metaverse-y?\nLike, the whole emerging strategy for the 2020s of Facebook (now Meta) and the tech startup ecosystem?\nOnly Croquet is way more than that.\n\nCroquet allows users to edit the source code of the 3D world from within the world, and immediately see the result, while the world is still running. The running program does not need to be ended, and there is no compile-link-run-debug development loop. Any part of the program may be edited, down to the VM and OpenGL calls.\n– Wikipedia, Croquet Project\n\nI have seen Kay present Croquet on stage and it is WILD. Almost two decades ago.\nBack in 2003:\nAlan Kay was giving a talk about old ideas from the history of computing. Two big projector screens, one at each end of the stage.\nIt starts as a slideshow.\nThen turns into interactive, object-oriented programming. Kay right clicks on an object in the deck and rewrites the code: the slide becomes a dynamic simulation of a car driving down a road. We thought it was a slide but actually it’s live code.\nAND THEN: the screens show different views. The screen on the right pulls back, and it turns out we weren’t looking at a slide, or even a screen-based coding environment. We were duped. We were zoomed in on a flat television in a fully realised 3D virtual world.\nThe screen on the left pulls back too, then travels through a portal, looks to the side, and sees the avatar that represents the screen on the right.\nIt was mind blowing.\nI still have my notes…\n\n3d environment on the left, then the 2d screen on the right zooms out and suddenly we’re in a 3d environment with panels all over it. all 3d OO, an avatar. each panel is a portal. the left is doing things from a first person POV, replication architecture doing realtime transactions over the internet. late binding protocol – message based system. all objects have their own objects.\nevery object is different, and can communicate with its peers. so you pull down the objects to fill in the environments, massively parallel realtime transaction stuff. then messages are synced up.\nleft screen manipulated a portal into another space. he enters it, and he’s in a new 3d space. left turns round, and sees alan on right screen enter the portal into the 3d view of the surface of mars.\n– Notes from ETech 2003, Daddy Are We There Yet (Alan Kay keynote)\n\n(This is from back when conference talks were given sufficient time and were super dense.)\nI sound pretty hilariously amazed, breathless even in plain text. I still am tbh.\nWhat Kay really cracked, with Croquet, is more general than in-world programming. It’s the overall user experience paradigm to interact with objects in 3D space in a way that makes intuitive sense, without dropping out to a separate console.\nUpdate 26 Apr: It turns out that the whole keynote is on YouTube. It looks pretty old school now, but you can see past that – it’s remarkable. And you just ask… what if we’d spent the last 20 years iterating on this vision? The path not taken. But it’s still possible to pick up the ideas. Watch it here: Alan Kay: Croquet Demo (2003) (58 mins).\nMultiplayer, persistent virtual reality worlds, programmable from the inside – that’s the Alan Kay invention that Apple hasn’t mainstreamed yet.\nThen there are all those rumours about Apple and virtual reality smart glasses… all the jigsaw pieces that Apple has dropped like spatial audio, and augmented reality toolkits, and ultra-wideband low latency high precision positioning chips, and insanely high-powered low-energy silicon, which isn’t really being used anywhere… and all the work they’ve done around iCloud, and identity, and in-app app development…\nAnd I was thinking about VR headsets the other day, noticing that the missing piece is the operating system… For all of Apple’s work towards the technology of smart glasses, we don’t know what “reality OS” is going to be like to use. Is it going to be immersive and 3D? Is it going to be a shared social space? Will the user experience build on the lessons of “object oriented” direct manipulation, like the original desktop metaphor but updated for virtual environments?\nI can’t help but wish that what Apple is working their way towards, slowly, over many years, is Alan Kay’s vision of the metaverse.\n",
    link: "/home/2022/04/25/kay",
  },
  {
    title: "Thinking about the immortal cells of Henrietta Lacks",
    date: "21.34, Wednesday 27 Apr 2022",
    content:
      "Who owns immortalised cell lines?\n\nHenrietta Lacks (born Loretta Pleasant; August 1, 1920 – October 4, 1951) was an African-American woman whose cancer cells are the source of the HeLa cell line, the first immortalized human cell line and one of the most important cell lines in medical research. An immortalized cell line reproduces indefinitely under specific conditions, and the HeLa cell line continues to be a source of invaluable medical data to the present day.\n– Wikipedia, Henrietta Lacks\n\nGenetically identical HeLa cells are cloned and used, for example, to test whether some substance or another is carcinogenic.\nHeLa has also been…\n\nindustrialised to make polio vaccine, used on the production line\nhybridised with mouse cells, to create the first human-animal hybrids.\n\nThe human use of human beings, eh. Blimey.\nHey, BUT\n\nA biopsy was taken of the carcinoma on her cervix but, as was common practice during the mid-20th century, the physicians involved did not obtain consent from Henrietta before carrying out this procedure.\n\nNor was consent given to use the cells for research, nor for turning the cells from the cancerous sample into an immortalised cell line. Not that consent was required, according to policy, in 1951.\nEventually the cell line was sequenced, and then identification was swift. From Wikipedia: In March 2013, researchers published the DNA sequence of the genome of a strain of HeLa cells. The Lacks family discovered this when the author Rebecca Skloot informed them.\nGet this: the fight about ownership was about insurance premiums.\n\nIt was not until 2013 that the Lacks family were given any authority over the use of the HeLa cell line – over half a century after Henrietta’s cells were first used. This only occurred because of the publication of the HeLa genome sequence, which raised multiple concerns among the Lacks family; one of these was the possibility of the sequence being used to calculate the family’s risk of disease and the potential health insurance implications of this.\n– Porterhouse Medical Group, HeLa cells: A privacy dilemma (2019)\n\nLooking up immortal cell lines on Ancestry.com is a thing now. I wonder how that plays with GDPR.\nConclusion: two Lacks family members are now on a six-person committee that regulates access to the genetic data.\nOwnership:\nDevil’s advocate… do we really have to treat the cell line taken from Henrietta Lacks (admittedly without consent) as her property?\nMight it be like the monkey selfie property dispute? Just as the photographer created the necessary conditions, but still didn’t end up as the owner of the selfie, couldn’t you argue that Lacks created the necessary conditions for the cancerous cells, but ultimately doesn’t get to own the Act of God that occured?\nHow much independent agency do we ascribe to a tumour?\nPrecedent:\nWhat if it wasn’t a genome that was taken but a connectome? Let’s say technology gets to the point where its possible to scan brains and run them in software, say for 20 seconds at a time, in crowds of a million in parallel, maybe to do rapid marketing surveys on AI-generated car adverts to figure out which creates the right emotive response and purchase reflex? It’s just software, right? Not the actual personality. But perhaps it’s just a little bit sentient. Who knows.\nI guess if that comes to pass then it’s super important that we establish the legal precedent now that derivative works (such as a brain scan) are “owned” by the originating body.\nBut then – what if you sign away the rights because money while you’re alive is worth it? Maybe you shouldn’t be allowed to sell your own afterlife, to protect your eternity from the poor decisions made by your greedy original meat self.\nIt would be a weird post-death existence to wake up as looping goldfish-brained ad microtargeting engine sometime in the 2160s.\nSee you there I guess.\nThere is a sci-fi short about almost precisely this: Lena by qntm, which is written as a Wikipedia article.\n\nThis article is about the standard test brain image. For the original human, see Miguel Acevedo.\nMMAcevedo (Mnemonic Map/Acevedo), also known as Miguel, is the earliest executable image of a human brain. …\n\n100% worth your time. READ: Lena.\nThank you David Turner (@NovalisDMT) for finding this from my vague description!\n",
    link: "/home/2022/04/27/hela",
  },
  {
    title:
      "Apps are too complex so maybe features should be ownable and tradable",
    date: "18.18, Friday 29 Apr 2022",
    content:
      "Software is too complicated. User interfaces have too many commands. Perhaps the answer is an in-app free market economy.\nI subscribe to the excellent Hardcore Software newsletter which narrates the evolution of the PC and desktop software. It’s by Steven Sinofsky who was at Microsoft from 1989, oversaw development of multiple versions of Microsoft Office as it was created and scaled, and ended up as president of the Windows devision.\nWith Office 2003, Microsoft was able to see the actual commands used for the first time.\n\nThere were 4,000 commands across all of Office 2003 (Word, Excel, etc)\n80% of users only used two commands: copy and paste\n\nNobody used all the features, but everyone used a different set.\n\n\nAt a deeper level, most in a company might not use a feature such as Track Changes (or Redlining) in Word. But their lawyer would. And contracts or legal letters might arrive via email for review. Rarely used features became part of the work of others. This network of usage was a key advantage of Office.\n\n– Hardcore Software, 077. What Is Software Bloat, Really? [paywall]\n\nWhat to do?\nI’m into Adaptive Menus as an approach.\n\nThe first new mechanism, called “Adaptive Menus” or, later, “Personalized Menus” were an attempt to make the top-level menus appear shorter by showing the most popular items first. After a few seconds (or after pushing a chevron at the bottom of the menu) the menu expanded to show the full contents. As you used the menus, items you used often were promoted to the “short” menu and items you never used were demoted to the “long” menu.\n– Jenson Harris: An Office UI Blog, Combating the Perception of Bloat (Why the UI, Part 3) (2006)\n\nIt’s like frequently-used light switches in your house magically getting bigger.\nBut it didn’t help for Microsoft’s core problem which was discoverability. Users kept on requesting features which were already in the product.\n(The eventually solution was to replace menus with visible commands and icons, making it easier to explore: the Ribbon.)\nKai’s Power Tools, in the mid 1990s, was known for providing awesome Photoshop effects and also for wild experiments with the UI. \nHere’s a deep dive into the interface of KPT.\nMagic lenses! Single-purpose rooms! A dedicated tool meant to create collections of special looking orbs.\nAlso, “Unfolding Functionality.”\nThis deep dive describes this philosophy as fading out commands when not needed.\nBut the KPT Wikipedia page is more specific:\n\nThe program interface features a reward-based function in which a bonus function is revealed as the user moves towards more complex aspects of the tool.\n\nThis is more how I remember it.\nI think what would happen is that you would use a particular feature or filter or parameter, and as you used it you would accumulate stars. At a certain number of stars, more advanced features would unlock.\nWhich is another way to deal with clutter, right? It’s progressive disclosure: the user and interface grow in sophistication together.\nNeither Office’s Adaptive Menus nor KPT’s Unfolding Functionality is quite right. (Discovering new features is hard. A feature, when you want to go back to it, might be a different place.)\nBUT what they both do is they atomise functionality.\nOnce functions and commands exist as atoms, the user interface can be displayed according to some kind of logic - unfolded with use; reorganised by context, etc.\nFeature flags are a super common engineering pattern for turning feature “atoms” on and off dynamically.\nFor example: you have an app with a button that you only want to show to people inside the company, because the feature is still being tested. So you set a flag for that feature for all the users who you want to see the button, and they see it, and for everyone else it’s like the feature isn’t even there.\nUnpacking this… Feature Toggles (aka Feature Flags) (Pete Hodgson) gives four categories of feature flags:\n\nRelease toggles – allows half-finished code to be shipped so select people can try it out live\nExperiment toggles – features can be activated dynamically for one group or another, to gather data in a A/B test\nOps toggles – allows compute-intense features to be easily deactivated when the service is under load\nPermissioning toggles – premium features are available to the premium group of users; beta features are available only to users who can test the system, and so on.\n\nKai’s Power Tools, through the lens of feature flags, makes up a fifth category: adaptive toggles.\nI’m calling them adaptive in the spirit of the lost Adaptive Design movement from the early 2000s: software is “adaptive” if it is co-created by design and user, and conforms to individual user behaviour.\nA sixth category might be pick-your-own toggles: feature flags where the user is in control of what features are off and what features are on.\nBUILD #1: Pick-your-own feature flags\nThis is 50% of an idea.\nImagine Microsoft Word but it comes as a plain text editor. No bold/italic/etc. The only commands are open, save, copy, and paste.\nYou get used to it. Then one day you decide you’d like to style some text… or, better, you receive a doc by email that uses big text, small text, bold text, underlined text, the lot.\nWhat the hey? you say.\nThere’s a notification at the top of the document. It says: Get the Styles palette to edit styled text here, and create your own doc with styles.\nYou tap on the notification and it takes you to the Pick-Your-Own Feature Flag Store (name TBC). You pick the “Styles palette” feature and toggle it ON.\nSo far this is pretty much like the browser flags in Chrome – experimental features in the web browser are hidden behind toggles which are user opt-in.\nBUT the difference is that the features aren’t experimental. They are fully-rounded, user-facing, feature “package.”\nSo the user builds up the capabilities of the app as they go.\nThe downside? It’s still really hard to discover features. How do you know that text styles (or drawing, or collaboration, or any other feature “package”) is available, unless you go hunting? And why would you go hunting if you don’t already know the feature exists.\nThat’s why it’s only half an idea.\nBUILD #2: Multiplayer, purchasable, tradable, giftable feature flags\nThe thing is, we’re not in Microsoft Word, we’re in Google Docs – and it’s multiplayer.\nI’ve been tracking the emerging multiplayer web for a while. The fact that our day-to-day work apps, like Slack, Notion, Figma, and Google Docs all have a sense of live presence of colleagues is a big deal. Pretty soon we’ll be able to take it for granted in any app. Presence and collaboration will also be part of any future-VR-based operating system – I’m convinced of that after recent VR headset mucking around.\nSo what if you’re collaborating with your lawyer in Google Docs, and you can see from their avatar that they have the “Track Changes” feature flag activated?\nBecause you’re in the same doc, you can use it together.\nAnd maybe if you want to use it again, they can just… gift it to you?\nCould app feature flags be tradable and giftable? That would answer the discovery problem and the “store” problem.\nWhat we’re talking about is feature flag ownership: a user owns their feature flags, and they carry features with them in a multiplayer space, and can use them together with other people.\nWhich… kinda parallels the physical world, right?\nLike: if you’re having a workshop in a meeting room, then it’s generally one person who brings the post-its and the pens. It’s part of their job.\nIt should be the same on a Zoom call. You shouldn’t sit on a call waiting for a host. You should sit on the call waiting for the person who has the screen share feature flag, and the annotate screen feature flag, and so on.\nWhat I’m talking about here is a marketplace: maybe a bunch of features in Zoom are free, but you pay $10 for the screen share feature flag, or $100 if you want the “make my webcam look pretty” filter. You can gift it to another user later if you want.\nBUILD #3: ok yeah NFTs\nI continue to keep a close eye on web3, as I said in January:\n\nHere and there are glimpses of new ways of storing files, new ways of owning and providing access to data, new ways of asserting identity, new forms of payments …\nI keep a personal running list of what I find interesting in the Web3 gold rush, in the hope of spotting something useful in its fundamentals that has immediate applicability.\n\nAnd maybe here’s one?\nNFTs (non-fungible tokens) are basically database primary keys that can be bought and sold, outside the originating platform.\nWhat’s key about a NFT is that it is owned by a user.\nPrimary keys can point to anything, and mostly right now they point to jpegs of cartoon apes, pixellated portraits, blobs of text, and some very cool art made by excellent artists (also some terrible art). There are a ton of scams in this space, so you have to squint a little to see through.\nThere is also an idea called Functional NFTs which is when the primary key is meaningful to a particular app or service, and it unlocks feature.\nLook, what I’m saying is: why not NFT-backed tradable feature flags?\nWith NFTs you get a whole ecosystem of ownership, marketplaces, dynamic pricing, for-free and for-pay trading, and so on.\nIf you want to build ownable, tradable feature flags, then it’s actually a relatively sane architecture decision to make use of this chunk of the emerging web3 tech stack to provide it. You might (as the rest of the tech stack comes into play) end up actually having to write less code?\nMaybe the ownership experience of NFT-backed feature flags would actually be greater than non-NFT-backed feature flags, and you would be able to charge more? Expensive to provide features (like ones that consume a lot of bandwidth) could even cost more. Applications could end up with a business model that feels more like game DLC?\n…but with some fascinating behaviour around users optimising their own apps around different roles (a viewer, a host, a facilitator, an editor, a teacher, etc) to represent the roles they have in their teams, and - in this multiplayer world - mutually learn from one another about how to adapt and co-create their own user interfaces.\n3rd party marketplaces to provide and trade feature flags would arise.\nAnd then there should be some fun features too. It’s not all whiteboards. What would it mean to have a rare and therefore somehow valuable feature flag? What would it feel like to be gifted one?\nFor me, this is maybe something to draw out of web3 – either just as inspiration or actually as some real tech.\nAnyway. Adaptive user interfaces, avoiding clutter, adding social discovery, NFT-backed feature flags. Apps would start really simple and then grow in complexity around you as you discover features by meeting others. Add in a business model and it sounds like a real-world economy, right? Lots of user experience and design work to figure it out. Can you imagine Microsoft Office 2026 working like this? Something worth sketching I think.\nThanks to Sofi Lee-Henson, Pearl Pospiech, and others at Sparkle for the work and imagination in developing these thoughts together. Standard disclaimer: this is super speculative. Posting now to generating conversation and get my thoughts lined up.\n",
    link: "/home/2022/04/29/adaptive_ui",
  },
  {
    title: "Presence in VR should show tiny people, not user avatars",
    date: "19.12, Tuesday 3 May 2022",
    content:
      "Since picking up a virtual reality headset a couple weeks ago, I’ve been asking myself: how should the future operating system for apps work?\nLike: how do you write docs? How do you collaborate on a deck? How do you launch your messaging app? Games are easy because they get to be weird. But for apps you need standard behaviours.\nSo I’m trying to think through this from first principles and see what comes to mind…\nALSO keep in mind that I have become obsessed with the overview mode in Walkabout Mini Golf. It’s incredible to have the “Godzilla’s eye view” (as I called it in that post at the top): gazing over the course with all its trees and ponds, a mountain halfway up my chest. And then being able to literally kneel on the floor and stick my head into a cave, examining closely all the intricate objects and furnishing in the rooms inside.\nFor me, the key difference between a screen-based user interface and a VR-based UI comes down to this:\nIf there is a small icon on my laptop screen, no amount of me moving closer will magically add resolution. But if there is a small icon in VR, leaning in will resolve more detail.\nQuick maths: let’s say an icon (like a user profile pic) is 1cm across and apparently 20cm away, and I lean in to halve that distance to 10cm. The number of pixels dedicated to that icon increases 4x.\nYou can pack a ton more information into 4x pixels!\nThis is crazy fundamental. On our phones, we “see” with our fingers - panning, swiping - but although you can pinch-zoom on a photo, there’s nothing you can do that lets you peer closer at an interface element and get more data than is already there. You can in VR. And compared to tapping or pointing with an input device, moving your head a small amount is zero cost.\nLike, imagine looking at the tiny wi-fi icon in the top bar on your home screen. Simply lean your head towards it a little (unconsciously) and you are able to read the name of the current wi-fi network; buttons for commands appear.\nSeeing is an active process. We move our eyes, heads, and bodies to see the whole time.\nThis is the topic of J. J. Gibson’s incredible 1979 book The Ecological Approach to Visual Perception (Amazon), which counters then-conventional psychological research in perception which strapped the subject’s head in place. Instead: natural vision depends on the eyes in the head on a body supported by the ground, the brain being only the central organ of a complete visual system. When no constraints are put on the visual system, people look around, walk up to something interesting and move around it so as to see it from all sides, and go from one vista to another.\nHere’s a quote I noted down last time I read it (2004):\n\nThis is why to perceive something is also to perceive how to approach it and what to do about it. Information in a medium is not propagated as signals are propagated but is contained. Wherever one goes, one can see, hear, and smell. Hence, perception in the medium accompanies location in the medium.\n\n(Designers may like to know that Gibson also coined the term “affordances,” used heavily in HCI and interaction design thanks to Don Norman, and this book is the underpinning for why visual perception and action are intimately connected.)\nSOME RELATED LINKS:\nI tried controlling my desktop cursor with head tracking last year and it was tantalising: It is so close to being something I would use in preference to a mouse… or rather, alongside one.\nSo that’s why I’m a believer that computer interaction can be way more embodied than it is today.\nAnother reference point is the zooming user interface (Wikipedia) which has been a concept for decades. I’ve built prototypes in the past, and it’s actually kinda neat to (for example) zoom in from a document icon to edit the document itself. BUT also frustrating: cognitively it feels like you end up with too much stuff in your head. Your brain misses the necessary cues to deallocate information stored from old screens. You need the attentional ergonomics of the Doorway Effect (as previously discussed) to help with focusing.\nMy point is that the possibilities of the future user interface are wiiiiiide open. Building on these kind of ideas is what I have in mind.\nIf “natural zooming” is a UI primitive for our future OS then another fundamental is presence.\nVR and multiplayer are intrinsically linked. Virtual reality is a medium that has emerged in the networked age. Of course apps will be multiplayer and collaborative. Why would they be otherwise?\nThe metaverse, right?\nA couple years ago, I was speculating on how to retrofit “multiplayer” into today’s desktop or phone operating system. One idea was noisy icons:\n\nImagine seeing ripples around the Google Docs app as if there were some deep, distant activity. Open it… and there’s a particular document humming with comments. You listen at the door, you can tell who’s active, and the frequency of the interactions, but not what they’re saying precisely… a ping as your name is mentioned (the notification of which wouldn’t have bubbled all the way up to your home screen as it’s not important enough, but since you’re here) - so you enter and join your colleagues.\n– Interconnected, Multiplayer docs, webcam fashion, noisy icons: three ideas (2020)\n\n…and this is kinda hard to imagine actually being implemented today, right?\nBut with VR, where the OS is being built from scratch, maybe this is the kind of paradigm that can be there from the get-go.\nLong story short: you should be able to see which of your friends are “in” an app before you launch it, and see who is “around” in the app while you’re using it. Presence.\nToday “presence” means showing a green I’m Online! marker next to a floating avatar or, at best, Figma-style cursors charging around on screen. It works but it’s oh so abstract.\nHow it works today:\nMeta Quest 2 has a button that brings up a universal menu. It hovers in space. It doesn’t add more detail if I lean closer (it just looks sharper). It should!\nYou can see the menu in this review. (Search for “The best place to see the changes in the hardware’s displays is currently in the menus.”)\nThe app launcher gives me a grid of images, hanging in space on the same virtual screen.\nHow could it look?\nI want to see apps. I want to see if an app is busy or rather: occupied (to keep the spatial metaphor). If I peer closer, I want to pick out my friends. Let’s use that zooming UI possibility and let me discern both crowds and individuals, both at once.\nThis doesn’t have to look like a virtual screen hanging in space. Nor does it have to look like a 3D rendered virtual office (or whatever). That’s skeumorphically cargo-culting the real world. We use abstractions because they’re more efficient for certain kinds of thinking.\nIn my head the app launcher looks like Peter Molyneux’s 1989 video game Populous (Wikipedia) which invented the “god game” genre.\nIn Populous: You look down at an isometric landscape on your desk. You see people scurrying about. If a building is busy, there are lots of people there. (This Populous review embeds a gameplay video. Check it out!)\nSo that’s what my imagined home screen looks like: a landscape of apps, presence shown by people near the apps. But not mini profile pics. We only have those because of the limitations of desktop screens. Let’s have teeny little people instead. When you lean closer, more pixels are dedicated, and you can recognise the faces of your friends.\nOk this isn’t all you need for a VR-based multiplayer operating system, not by a long chalk. But I’m into the fact that there are a ton of new interaction design primitives to use on old problems.\nAnd perhaps this is a neat starting point to open up the design space. With PCs you have the desktop metaphor. With VR, how about the landscape metaphor?\n",
    link: "/home/2022/05/03/landscape",
  },
  {
    title: "I’m not a goblin, I just play one in Google Docs",
    date: "19.33, Thursday 5 May 2022",
    content:
      "Once upon a time, when I was a young teen, I went with my friends to a place called Cheddar Gorge which is a cave system in the west of England (yes, near where the cheese comes from) and there, in the underground tunnels, we ran around in the dark and pretended to be goblins and hit people pretending to be adventurers with rubber swords.\nLarping, is what this is called. (LARP = Live Action Role-Play)\nANYWAY. I just looked at my LinkedIn newsfeed.\nI went through a period of my life where I was retrospectively ashamed and never talked about my early teens one-off experience running around in dark tunnels, goblins, rubber swords etc. HOWEVER now I believe it was pretty cool actually.\nLarping is improv, right? But whereas participating in your improv theatre group is “highbrow” and “culture” and gets talked about in the Sunday supplements, larping is maybe not seen that way. Maybe it is now! I hope so.\nMy overwhelming feeling, peering in at LinkedIn, was a sense that I was watching everyone performing an elaborate dance.\nI know these people! I barely recognise them!\nThere are common steps like product launches and hiring and life lessons and being blessed by luck, and these incredible matador flourishes of the cloak like pointing credit at someone else to gather some yourself or a delicate humblebrag that can never quite be called out. And the supporting comments! An art in themselves.\nIt’s not ungenuine, not insincere. I feel energised and encouraged and amplified just reading LinkedIn. I love it.\nI feel like people on LinkedIn are accessing parts of their own potential that perhaps can’t be accessed any other way? Like, LinkedIn is a collaborative machine to summon… something? It’s good. It’s weird. It’s good.\nBack in 2009, Phil Gyford started an email list called Pretend Office. It was for a bunch of freelancers to experience the camaraderie of being workmates in an office.\nBUT THEN:\n\nAnd a weird thing happened.\nWith no planning, we all started acting as if we were people in a real office. Almost immediately we began to adopt characters and send officious announcements. Soon we were referring to characters in the office who didn’t exist in real life. Meeting rooms were booked, couriers arrived, servers went down, timesheets were requested, and embarrassing emails were accidentally sent to everyone in the company.\nI can’t remember the last time I laughed at email so much. It was, and is, the most fun I’ve had on email for a long, long time.\n– Phil Gyford’s website, Pretend Office (2009)\n\nLarping office work.\nYou can read the archives! Here’s the first email: If you’re reading this then the boffins in IT have got the emailing list\nworking!!!\nAnd here’s a representative month – click on a few emails and start reading. It’s… baffling? Hilarious? Mundane?\nEveryone knows what to do.\nI spend most of my social media time on Twitter. What on earth are we larping there. Good grief. What a performance.\nBut again, it doesn’t feel like a performance.\nAnd actually, because I’m closer to it than LinkedIn, to me it doesn’t feel like a performance at all. But I bet it looks like one from the outside.\nSo, I guess, two thoughts:\n\nthe gap between my “real me” and the “social media performer me” is more extreme than I had credited – and everyone has this really huge difference between their “selves”\nwe fall into performing different selves so easily and so NATURALLY that this can only be part of the fundamental human condition.\n\nThese aren’t performances; there’s no pretence going on.\nBeing able to become multiple divergent selves is just what we we are as humans.\nIt’s nice to acknowledge that.\nMaybe we wouldn’t all get so angry on Twitter if there were psychological cues to remind us that, yes, fundamentally it’s all role-play. It’s real AND it’s pretend both at once.\nI wonder whether work (job work or creative work or whatever) would be easier if we leant into the larping aspect.\nWhat if Google Docs, Figma, Slack, and all the other apps of the modern workplace were built around the idea that we were adopting a character and doing improv? Like, we have roles at old-school work, and I think that helps? Maybe we should have characters in software too?\nMaybe locking ourselves into a single identity that remains fixed for all our time with a particular team and a particular app is a kind of mental straitjacket somehow.\nI’m reminded of the way that the four ghosts in Pac-Man embody four different algorithms – they chase around the maze using: pursue; ambush; fake-outs; idling. You need them all!\nWhat if, when I opened an app, I swiped in a different direction to consciously adopt a different character – a different personality algorithm. How would I collaborate on a doc as a healer versus a knight, or write email as a wizard versus a goblin?\nWhat if “character” is a top-level entity in the database, as important as “user”?\nWhat’s the minimum viable feature I need to see myself and for others to see me differently, to allow larping-instinct to kick in?\nDoes my user profile pic need a hat to show which character I’m playing today?\nI’m on a discord where, in most of the channels, people are discussing art or activism or potential technical protocols for speculative platforms or socialising about where they live, and in one channel (genuinely) they are running around and very seriously getting excited about goblins.\nGoblins again.\n",
    link: "/home/2022/05/05/larping",
  },
  {
    title: "Designing user interfaces with bots not buttons",
    date: "20.52, Monday 9 May 2022",
    content:
      "I’ve seen a couple of examples recently of how super simple “bots” are replacing bits of user interface. I feel like this is a trend connected with the return of VR.\nI am in love with the virtual events platform Skittish which is a 3D cartoon world (where everyone is a low-poly animal) for running multiplayer online parties, conferences, workshops etc.\nRECOMMENDATION: Hit the “Try it now” button in the top right of their homepage and run around the sandbox. Talk to the other animals! Go into the editable room and try out placing the YouTube billboard!\nMy favourite omg-that’s-so-clever feature is character bots:\n\n… you can now use the Skittish editor to place little animal NPC characters in your world, which you can supply with multiple lines of dialogue that appear automatically or when other players come into range. These are a great alternative to signage for welcoming people into the space, explaining what’s going on, or just giving the space some color.\n– Skittish blog, Feature Roundup: New Image Billboards, Camera Views, Badges, Pronouns, and More (April 2022)\n\nThis is the feature that guides you round the sandbox mentioned above.\nAnd I’ve been poking at VR and the metaverse recently, noting that the “operating system” needs some work so naturally I’m thinking about that…\nWhereas dialog boxes (the usual UI supplied by an OS) wouldn’t work in the Skittish sandbox, as it would totally break frame, these little automated NPCs (non-player characters) work really well.\nSo… maybe for our future VR user interface: tiny characters saying words, not dialog boxes?\nI don’t want to go full conversational UI on this. It’s not about having human-level conversations or making chatbots. What’s good about the character bots in Skittish is how dumb they are. They definitely feel like part of the “machinery” of the place, but they’re integrated. They’re seamlessly integrated in the Skittish world, just as dialog boxes are “in-world” w/r/t to the “desktop metaphor” world of Windows or MacOS.\nThere’s something in the air…\nNPCs also appear in Gordon Brander’s experimental, work-in-progress, deceptively simple note-taking software Subconsious, as documented here.\nThe announcement of the alpha release (March 2022) gives a little tour of the software, with screenshots. It’ll be familiar to you! It’s a mobile app; you enter notes; you can search them.\nOnly this alpha app is about laying foundations, and at the bottom of the post is this intriguing para:\n\nNext we bring in creative divergence. How? Geists! Geists will be little bots that live in your Subconscious. They’ll do useful things… finding connections between notes, remixing notes, issuing oracular provocations and gnomic utterances.\n\nGeists?? Here’s the background: what if Clippy, but spooky?\n\nI’ve been playing with some simple command-line prototypes for Geists. They’re just little scripts that find connections between notes, and use procedural generators to construct algorithmic provocations.\n\nWhich sounds… spot on. Like: it’s a feature that is so amazingly missing from Microsoft Office, now Brander has said it, that it should be added yesterday.\nLike: when I talked about the writing systems of Cory Doctorow and Robin Sloan last year, what I found was that they both continuously mined their own notes and archives. I do the same – every new post, every article I write for work (I use the same technique I use in blogging to invent new ideas for the day job and for clients), they come from iterating over my own notes and make new connections.\nGeists turn this user behaviour into a feature.\nBUT why should a geist be an agent? Why not run the feature by tapping a button?\nThe answer, I think, is that the computer interface has always been a multiplayer environment for human and software agents. It’s just that we forgot for a while.\nFrom the opening to Brenda Laurel’s 1991 book Computers As Theatre (Google Books) which reconceptualised the human-computer interface…\nFirst, a history of the interface:\n\nIn the beginning, says Walker [founder of Autodesk], there was a one-on-one relationship between a person and a computer through the knobs and dials on the front of massive early machines like the ENIAC. The advent of punch cards and batch processing replaced this direct human-computer interaction with a transaction mediated by a computer operator. Time-sharing and the use of “glass teletypes” reintroduce direct human-computer interaction and led to the command-line and menu-oriented interfaces with which the senior citizens of computing (people over thirty) are probably familiar. Walker attributes the notion of “conversationalist” in human-computer interfaces to this kind of interaction, where a person does something a computer responds–a tit-for-tat interaction.\n\nBut Laurel puts forward another model of conversation, the common ground, and quotes Herbert H. Clark and Susan E. Brennan to introduce it:\n\nIt takes two people working together to play a duet, shake hands, play chess, waltz, teach, or make love. To succeed, the two of them have to coordinate both the content and process of what they are doing. … They cannot even begin to coordinate on content without assuming a vast amount of shared information or common ground–that is, mutual knowledge, mutual beliefs, and mutual assumptions.\n\nSo whereas you could conceive of the screen as\n\na visual cache for working memory (as they saw it PARC)\na “soft” replica of the buttons and switches of the old physical control panel\n\nLaurel instead suggests:\n\nContemporary graphical interfaces, as exemplified by the Macintosh, explicitly represent part of what is in the “common ground” of interaction through the appearance of objects on the screen. Some of what goes on in the representation is exclusively attributable to either the person of the computer, and some of what happens is a fortuitous artefact of a collaboration in which the traits, goals, and behaviours of both are inseparably intertwined.\n\nThat feels a bit abstract. So to put it another way:\nLaurel suggests that we see the computer screen as a stage on which there are agents, some human and some software, all doing their thing. And by taking this as a starting point, we can better design how all the agents come to a common understanding and make their intentions known.\nIt’s an astounding book.\nSEE ALSO #1:\nMy post about files and icons from last year, which talked about an icon being a boundary object that has meaning in both the world of the user and the world of the machine. Common ground.\nSEE ALSO #2:\nA post at LessWrong the other day introduced the concept of narrative syncing meaning sentences such as:\n\n“The sand is lava; if you touch it you die” (when introducing the rules to a game, not making a false prediction)\n\nSentences which are to sync up with some set of other people as to how we all think or talk about a given thing around here (as opposed to sentences whose primary purpose is to describe a piece of outside reality).\nNarrative syncing = establishing common ground.\nIn Brenda Laurel’s framing, where the interface is a stage for the interaction between users and machines, NPCs and geists make total sense.\nWhat’s interesting is that Laurel developed the ideas in Computers as Theatre in Alan Kay’s lab in Atari (I am a fan of Kay), thinking about games in the widest sense, then went on to pioneer virtual reality in the VR boom of the early 90s.\nEarly 90s VR hype-crashed.\nNow VR is back with the metaverse.\nAnd suddenly ideas that fit naturally into Laurel’s framing are back again?\nNot a coincidence. We’re unseating ourselves from the old desktop metaphor and readying ourselves for the VR interfaces of the future.\nSo here’s my prediction.\nNot only in VR, but generally in software, we’ll see bots make a comeback. Or rather: NPCs. I like that term, this time around.\nIn the narrative framing of the UI of the metaverse, whether it is being used for socialising or for work, what is pre-eminent is the shared multiplayer world: the “common ground” is right there, and NPCs make more sense than dialog boxes.\nThen, as users becomes accustomed to agents and NPCs, we’ll see more interfaces on desktops and phones that behave like Subconscious: bots not buttons.\nIf you’ve seen any other lo-fi bots and NPCs in software interfaces (experimental or otherwise) in the past 12 months or so, please let me know. I’d like to collect a few more examples.\n",
    link: "/home/2022/05/09/npcs",
  },
  {
    title: "Signs of a magnetic pole flip in company ownership",
    date: "16.13, Thursday 12 May 2022",
    content:
      "What if the dominant model of company ownership inverts? What if we’re at the end of an era of companies being owned by external stockholders, and at the beginning of bottom-up ownership by the people who do the work – the employees? Feels unlikely I know, HOWEVER:\nThis morning’s news is that ustwo is now employee-owned.\nYou’ll likely know ustwo. Here’s their Wikipedia page. They’re behind the hit puzzle game Monument Valley; long-time digital design agency (founded in London in 2004) with a couple hundred staff; part of many joint ventures to provide design/software/marketing/etc for startups, e.g. DICE. I know Mills (@millsustwo), one of the two founders, from the general scene - huge congrats mate, brilliant move.\nI have a soft spot for an ancient bit of ustwo work, being home screens designed for the Sony Ericsson XPERIA X2 (bloody hell that’s a mouthful) smartphone from 2009. Watch the Pixel City video on Vimeo: Pixel city moves through a cityscape, its different elements linking to the functionality of your phone. Text messages appear playfully on billboards, calendar events arrive by train, a passing aeroplane shows your call history and much more.\nustwo have always been as inventive and pioneering with their business model as their design work. They’ve been blogging today about going employee-owned:\n\nHow: a majority of equity is now in a vehicle called an “Employee Owned Trust,” purchased from the founders with a loan (like a mortgage) which will be paid back over 6 years. Three employees have joined the board. There has been a multi-year transition leading up to this from being founder-led to management-led.\nWhy: employee-owned firms are more productive, grow faster, and are less likely to go out of business (where ownership is >30%; ustwo is now 62% employee-owned). There has always been profit share; now this can grow.\n\nIt’s great that they’re sharing the nuts and bolts of how this works. It’ll demystify the process for others who want to follow the same path.\nAnd I’m sure there will be a bunch of future lessons in how to make this work – like, how can there be meaningful employee involvement in how to chose work or influence big bets or what happens when there are lean cycles in the agency cycle? I hope ustwo’s sharing will continue.\nA shout-out at this point to my friends at Clearleft! A smaller but also well-established agency and extremely well-regarded for their design work and community presence, the Brighton-based design studio went employee-owned in 2020.\nTwo makes a trend right?\nExciting times for design. And for the agency model, which has been in a state of perpetual reinvention for as long as I remember. \nRELATED: There’s something fascinating in thinking about succession planning as the founders handing control not to another individual to the machine. It makes me think of Sikhism which, after a line of 10 gurus, handed over leadership to an “eternal living guru,” the Sikh community itself. As previously discussed.\nThere’s always been the question about how founders exit from an agency. Two traditional routes:\n\nManagement buy-out funded by private equity. Going the PE route means “unlocking value” – there are strong growth expectations for a future flip (i.e. a return for the PE firm).\nAcquisition by another agency, ideally a major network.\n\nThe agency world has its own nature and own norms – it’s like a more established, parallel world to the startup ecosystem.\nOne feature is the presence of behemoth networks like WPP plc (that’s their Wikipedia page). There are a handful of agency networks around the world. WPP is UK-based and owns a few hundred agencies, with collectively 100,000 employees and somewhere north of 10 billion annual revenue. They coordinate, share work, get scale (a small agency can be part of a global project), and save on back-office.\nSo while I love that ustwo and Clearleft are figuring out the path to employee-ownership – the eternal living guru of the organisation…\n…thinking about the larger scale makes me ASK:\nWhat is the equivalent of the agency network for employee-owned orgs?\nCan we imagine some kind of multinational network organisation that coordinates, shares work, achieves scale, etc, without taking full control of the member agencies?\nGoing further:\nThe agency world has a fractal structure. Agencies are often 50% freelancers and they subcontract like crazy. Then they roll up into bigger firms – the Coasean logic of travel towards lower internal transaction costs means agencies combine and combine again until you get the network giants.\n(The startup world parallel is the data-driven gravitational force which results in Big Tech, a.k.a. Srnicek’s platform capitalism.)\nCan employee-ownership exist at all scales?\nHey and here’s an example in the UK! CoTech is a network of 45 creative technology companies, all individually organised as co-ops, providing digital services together. More like that pls.\n(Thank you to the folks at the co-op Common Knowledge for letting me know about this. Common Knowledge itself creates digital tools to force-multiply social movements.)\nPerhaps we’re at the beginning of an ownership inversion where organisations from big to small will follow the principle of bottom-up agency.\nDominant models change every so often! I remember reading that the dominant model in the US relatively recently (1900s?) was family-owned businesses. I’ll have to hunt down that reference.\nThe analogy here is to geomagnetic reversal, the process by which the Earth’s magnetic poles flip – the North Pole becomes the South Pole; the south becomes the north. It happens periodically: There have been 183 reversals over the last 83 million years (on average once every ~450,000 years). The latest, the Brunhes-Matuyama reversal, occurred 780,000 years ago.\n(i.e. we’re overdue, just in case you were wondering what else the 2020s may deliver.)\nSo I guess something happens such that the pole-flip kicks off, and sheer magnetism drags everything else with it to complete the process? There is no halfway house.\nOnce I started looking for signs of an ownership inversion, labour becomes capital and capital becomes labour, then I started seeing it everywhere:\n\nUnionisation – it’s growing in tech and service jobs, and not directly employee-ownership but still an agitation for self-determination.\nIndependent employees – Uber drivers, Airbnb hosts, and the gig/sharing economy generally… are these employees stripped of rights, or individuals exerting self-determination, or (as I’ve previously argued) a third category of worker, something in-between? Maybe there’s the seed of employee-ownership hidden here. Let’s roll in the creator economy here: as Uber drivers love their flexibility, creators love the hustle.\nCo-ops – The Drivers Cooperative in New York, the Uber-alike where the drivers own the software, and others in the platform co-op movement: organisations where management is the commoditised class, not the workers.\nDAOs (Decentralized Autonomous Organisations), looking further out into the web3 world – a way for the bureaucracy of an organisation to be represented as executable code, and for individuals and other individual-like agents to drift in and out of the organisation, the reward for work being ownership. Intriguing stuff. A great essay on the topic is A Prehistory of DAOs (by @keikreutler).\n\nTHE COMMON THREAD:\nHow an organisation’s self-determination, ownership, and value-creating work become indivisible, held by the same people: the employees?\nIt turns out this same question is being asked at all scales.\nSo let’s assume the magnetic pole flip is in progress!\nOr at least, let’s assume this: there is tectonic tension towards this corporate ownership inversion, even if as yet unrealised. So enabling tools will quickly find traction and unlock behaviour.\nAnswering questions like…\n\nSimple paperwork to flip a company’s equity into an Employee Owned Trust, as with ustwo and Clearleft, and case studies of the same?\nSoftware to enable worker-owned co-ops (as previously discussed).\nCommon patterns for meta-organisations such that (say) employee-owned design agencies can co-market and compete with global roll-ups?\nSafety net/pension analogues for independent workers to buy into, and one-click personal incorporation, such that they have security while their employers can treat them with flexibility?\nAt a really mundane level: shared channels in Slack provide a way for teams in different orgs to collaborate. What other cross-org demilitarised zones might there be?\n\nAnd so on.\nIf you were a VC you might invest in this, as a long term bet.\n",
    link: "/home/2022/05/12/inversion",
  },
  {
    title: "Lightbulbs were so startup",
    date: "18.40, Wednesday 18 May 2022",
    content:
      "Edison invented the first practical incandescent electric light in 1879. (That is, the filament lasted more than a few hours.)\nBut it couldn’t be brought to consumers because there was no commercially-available electricity.\nAND SO:\nIn 1882, the Edison Illuminating Company opened the first commercial power plant in the United States: Pearl Street Station (Wikipedia) in Lower Manhattan.\nStarting small… it started generating electricity on September 4, 1882, serving an initial load of 400 lamps at 82 customers. By 1884, Pearl Street Station was serving 508 customers with 10,164 lamps.\nThey had to invent a new kind of dynamo to generate the electricity. Ahead of the power station, Edison ran a number of pop-ups as prototypes.\nHOWEVER: power distribution.\n\n… perhaps the greatest challenge was building the elaborate network of wires and underground tubes (called “conduits”) needed to deliver energy to customers. New York City politicians were initially skeptical and rejected Edison’s proposal to dig up the streets of lower Manhattan to install the needed 100,000 feet of wiring. Eventually, however, Edison was able to convince the mayor of the city otherwise. The conduit installation proved to be one of the most expensive parts of the whole project.\n– Engineering and Technology History Wiki, Pearl Street Station\n\nNot only a distribution problem, but a backchannel conversation between people with power to get around the rules. Capitalists gonna capitalise.\nAND THERE’S MORE: the business model.\n\nSince the early 1800s there had been special instruments to detect the flow of a current and indicate how much of it was flowing, but there was not an instrument to record that flow over time. Not until the spring of 1882 was a successful design for an electric meter available. However, Edison did not send bills to his customers until the whole system was running reliably, which took some more time. The first electric bill was sent to the Ansonia brass and copper company on 18 January 1883 and was for $50.44.\n\n(That quote from the same ETHW article linked above.)\nIn addition light bulbs cost $1 ea.\nThe setup cost (including real estate) was $300,000 – a lot to return, 50 bucks at a time.\nThe company ran at a loss until 1884. Pearl Street Station burnt down in 1890, was rebuilt, then in 1895 decommissioned when it was made obsolete by newer, larger power stations.\nA single value-creating innovation requiring a vast hinterland of enabling technologies in order to connect the product to its market.\nIt’s so startup it hurts.\nQuestions I have:\n\nHow can we compare the cost of “inventing the lightbulb” vs digging the streets, building the power station, getting to profitability, etc? Say, in terms of hours of human effort? Was it 50:50, 80:20, 1:99?\nWere other models other than metered electricity considered? Like, light-as-a-service with bundled bulbs? Or somehow connecting the cost of the service to the value for the customer – could customer businesses be charged a fraction of revenue, say? My guess: it comes down to what’s easy to measure. Businesses nowadays will grab a % (the “take”) from their customers simply because it’s possible to do so.\nWere other applications for electricity actively considered, or was this a pure lighting play? The fractional horse-power motor scaled down factory automation to the home, and the electrification boom brought with it vacuum cleaning and washing machines… yet the enabling tech wasn’t invented till 1888. But was it visible on the horizon? Or was it only lighting that justified the huge investment in Pearl Street Station and the 100,000 feet of conduits?\nWhy go for this very broad market first? Why not build smaller generators in the basement of department stores, lighting up just single buildings or single streets? Isn’t the value in (say) adding an extra hour of brightly-lit shopping every evening more obvious than trying to replace gas and oil for home customers?\n\nDid Edison have a team of 1880s MBA-equivalents, crunching the numbers to figure out what to do?\nWhat was the mood around electric lighting back then? Did it feel like a hype train? Was the social media of the time full of wild speculation about the social changes that would be unleashed and the fortunes that would be made?\nElectricity, generally, had that aura of excitement. A few years back I read every issue of Electrical Review from the 1880s and 1890s which covered the rollout of the telegraph and then lighting, simultaneous with figuring out the science of how electricity behaved (I wrote up my observations here) – but I think I need to go back and read the preceding decade too.\n",
    link: "/home/2022/05/18/edison",
  },
  {
    title: "The web3 world computer is at a 1970 level of development",
    date: "13.12, Friday 20 May 2022",
    content:
      "I’ve been hanging out in the web3 space recently. The art and aesthetic generally is awesome and effervescent. But there are big claims made for the technology and, given the high level of scams, I’ve spend a bunch of time considering that.\nWith any new tech, it’s interesting to ask: does this matter? Is it a weird blip or does this become part of the technology landscape for decades to come? If so, how? A change in consumer expectations or wildly disruptive at a widespread and technical level? Does this tech matter directly, or is it basically a discovery mechanism for new use cases, acting as inspiration for new tech that answers that same revealed use case but in a different way?\nMost interesting: where are we in computing history?\nFor e.g.: My take is that VR is waiting for its Macintosh moment which puts it in the mid 80s and my gut says that’s about right. Assuming decent smart glasses drop this year or next, then it’ll take a decade of deployment phase till we’re in the “mid 90s” and VR is transforming everyday life. At which point we’ll be ready for the big twist, which for the PC was the arrival of the web, and it took another decade for PCs to become culturally dominant. Perhaps, v roughly, VR is on the same curve.\nOk, web3.\nSo I’ve been poking around in Ethereum which is one of the two big blockchains. Bitcoin is the other and that’s mostly financial. Ethereum is… something else.\nReading the smart contract source code that underpins NFTs (here’s the spec and here’s some code) is super informative! You can see what it means for a digital item to “exist.” You can see what it means for one of these items to be “owned.”\nI get the same feeling as when I read the source code for the original Unix operating system, which is basically the ur-OS that either directly or indirectly (because it established the concepts) underpins this epoch’s computing environment. You can see what a process is! What is a file is. What a user is. The feeling is a combination of: oh now I know the fundamental particles; and, is that it??\nNFTs don’t “exist” on the Ethereum blockchain. The smart contract that tallies and tracks ownership for a class of NFTs does exist: it’s code that runs. As a single instance, this means that NFTs of the same class are forever linked. By analogy: imagine a print of some art is limited to 100 editions and they are all sold and now hang in people’s homes all over the world. Now imagine that they are spookily connected to one-another.\nAn NFT is a smart contract that achieves something like digital ownership, but actually it has a subtly different nature. Which is worth knowing. Opportunities for invention come from knowledge of the deep physics of a universe.\nLong story short, I finally came to understand whey they call Ethereum the World Computer.\nNFTs are one type of smart contract that can run on the world computer. Other smart contracts can do anything that code can do.\nSmart contracts aren’t contracts, that’s a financial or legal framing. Smart contracts are object instances, in the object-oriented code sense, and the Ethereum blockchain is a shared object runtime.\nRobin Sloan gets it. I didn’t get it when I read his notes last year, but now I do.\n\nIfeel like this simple premise is often lost in the haze: the Ethereum Virtual Machine, humming heart of Web3, is a computer that charges you many dollars to execute a very small program very slowly. It does so in an environment with special properties, and in some cases, those properties are worth the expense. In others … it’s like running your website on a TRS-80 with a coinslot.\n– Robin Sloan, Notes on Web3 (2021)\n\n(And also read Sloan’s essay from around the same time, The slab and the permacomputer, which is a meditation on the idea that ‘computers’ might melt into ‘compute’, something more environmental then physical.)\nThere is a picture in my head that the computing environment of the future is a vast shared substrate where digital ownership is IRL-equivalent. With all that ownership implies and requires: identity, economics, object permanence, a truth grounded deep in the physics.\nMaybe achieving that requires tearing up everything way back to… well, when?\nLet’s say that the Ethereum virtual machine, the world computer, is indeed the shared object runtime that we will need. Object-oriented code being the paradigm invented by Alan Kay such that blobs of code sit together, an object instance representing (say) an on-screen menu, or a user, or whatever. The paradigm provides abstraction such that code can reach dizzying complexity, while also retaining expressiveness to create new things.\nObject runtimes such as…\n\nNOW: the object-oriented heart of MacOS and iOS, originally the Objective-C runtime of NeXT (and the reason that Apple bought NeXT), which is the reason why iPhone has great consistency in the user experience and was also, at release, hugely easier to develop for than anything else on the market.\nBACK THEN: the Smalltalk runtime, developed by Alan Kay’s team at Xerox PARC, and used to invent modern graphical user interface on the Xerox Alto in the early 1970s.\n\n(Yes, I continue to be obsessed with the career history of Alan Kay.)\nIt’s interesting to me that you need both (a) the hardware, and also (b) an expressive and powerful object runtime such as Smalltalk if you are going to invent the user interface layer, which allows users to interact with the machine and also provides a platform for apps.\nIf I kinda squint… I can kinda imagine how you might bootstrap today’s Ethereum virtual machine all the way up to a Smalltalk-equivalent. And if you get to that point, you can ladder your way up to a GUI analogue, and from there to modern-day computing.\nSo how far away are we?\nHow far away is today’s web3 from something as sophisticated as today’s computer world?\nLet’s do some sums.\nAnd really hand wave our way to a Fermi estimation.\nExecuting a function on a smart contract (an object instance) on the Ethereum virtual machine, updating internal state etc, takes a few minutes.\nOn a Mac, the overhead to pass a message to an object is measured in nanoseconds on a modern machine.\nSo there’s is a 10 orders of magnitude difference: Ethereum needs to be 10 billion times faster.\nThat’s 33 Moore’s law doublings. 50 years away from being as complex and fully-expressed as today.\nSo we’re in the equivalent of 1970 – which feels about right.\nWeb3 is waiting for minicomputers. Even that’s a long way off from today. In the minicomputer boom around 1980, in our history, a single NAND gate cost 8 cents, wholesale: In 1981 money, a single iPhone would cost $1.4 billion in parts, no margin.\nWe’re still waiting for our Unix moment, locking down the fundamental concepts, the system that takes the network and time-sharing for granted, giving us the native programming language and system calls to bootstrap up to the next layer of emergent complexity.\nWe’re pre GUI; direct manipulation and the desktop metaphor has yet to be figured out. There are no SDKs. Development is still close to the metal.\nIt gives me a rough handle on the scale of work to be done.\n1970 doesn’t mean that web3, this new epoch of computing (if that’s what it is), is unusable. Far from it. People in the real 1970 were making video games! The personal computer had already been imagined and prototyped!\nThis analogy helps me have a view on questions like: are NFTs the final form of that concept, or do we have some way to go to digital ownership?\nI think what NFTs want to be like is the MP3. The Fraunhofer Institute’s invention of the MP3 (and their licensing approach) unlocked a whole industry including consumer ownership of digital music, online music stores and streaming, and digital devices like the iPod (which paved the way to the iPhone).\nBut the MP3 file format was invented in 1989 so - if we’re on a similar trajectory - then NFTs have conceptually the right frame but are 20 years too early.\nThe question is: how do we accelerate 50 years to 20 years or to 10 years?\nThere were multiple generations of computers between 1970 and the networked smartphone. It wasn’t a steady evolution.\nMaybe there would be scope in imagining the next generation of web3, already. Are there other ways to achieve a global, zero-trust, persistent, shared object runtime – and can it be built? Perhaps Microsoft or Google have warehouses of genius engineers doing just that, attempting the generational leapfrog.\nOr maybe it would be worth bullying a Smalltalk-like expressive development environment into existence, sitting atop today’s Ethereum world computer, however slowly it run, just to see what could be created with that new clay.\nIF REAL! The alternative view is that web3 and all of the above isn’t real. There will be ways to achieve digital ownership (if that’s even important!) without baking it into the physics of a future world computer.\nIt could be that part of the appeal of web3 is that it’s a new glass bead game.\n(Whether it has 1,000 year appeal like THE Glass Bead Game, Hermann Hesse’s abstract and beautiful fictional game at the heart of his 1943 novel, our descendants will find out. So let’s lowercase it for now.)\nWhere else can you manipulate a novel set of symbols and bounce between code, social dynamics, arts and economics? There are endless permutations.\nAnd perhaps - per Hesse - it’s best left to a caste of esoteric monks revered yet safely isolated from the rest of society…\nI’m not saying there is nothing else there, or that the nerd-sniping joy of web3 is the only value (I happen to believe there is something real here), but alongside the gambling drive which comes from the financial component of this emerging tech stack, I feel like novel symbol manipulation is a big part of the early appeal for many.\nWhich is a risk. I kinda vaguely feel like physics burnt a couple decades on a similar pursuit: string theory. A consumingly absorbing idea for whole communities, but where did it go?\nSo perhaps it’s all a mirage. For the sake of argument, let’s assume it’s not.\nMy hunch and my heuristic metaphor:\nIf the web3 world computer has only just reached 1970 then, first, don’t expect too much. There’s real utility to be found but in very prescribed use cases. But also, second, there are wild and unrecognisable transformations to come. There is room for imagination and invention.\n",
    link: "/home/2022/05/20/fermi",
  },
  {
    title: "Alternative epistemic agents for restaurant menus etc",
    date: "19.44, Tuesday 24 May 2022",
    content:
      "The dessert menu at Le Relais de Venise has red and blue underlines, which maybe represent IRL user interface for epistemic agents, and I kinda feel like (a) this is a prototype for smart glasses, and (b) I would like this everywhere (but better).\nIf you haven’t eaten at Le Relais de Venise, it’s useful to know that there is only one option. You get steak, fries, salad, and their signature parsley sauce. When you finish your plate, you get the identical thing again. No other dishes available. It opened in 1959 in Paris and it has since instanced in a handful other cities.\nThe dessert menu, by contrast, is lengthy. Here it is on my Instagram.\n\nA dozen options, e.g. Le Glace au Chocolate, are listed plainly\nInterspersed, three more have bold red underlines, e.g. Les Profiteroles au Chocolate\nAlso interspersed, another three have bold blue underlines, e.g. Le ‘Cheesecake’\n\nThe key: Underlines = most popular items. Top with chocolate in red, top without in blue.\nI had to ask the waiter to learn this fact, which is by-the-by a neat micro interaction engaging you in the dessert consideration funnel.\nI like this! Here is Amazon-e-commerce-style social recommendation and social proof embedded as print in the dessert menu. It’s PageRank for pudding.\nBUT: other types of recommendation algorithm are available.\nIn Reasonable People #26, Tom Stafford begins by reviewing Knowledge in a Social World (1999) by Alvin Goldman – then riffs on software, social media, and epistemic agents: autonomous agents, computational entities that cooperate with a user in the service of information-gathering tasks. (Goldman’s words.)\nIt used to be, says Stafford, that there were many tools to explore and develop knowledge.\nFor example (quoting Goldman again), a tool for searching the web:\n\nThe Scatter/Gather system can analyze those pages and divide them into clusters based on their similarity to one another. Aunt Alice can scan each cluster and select those that appear most relevant. If she decides she likes a cluster of 293 texts summarized by “bulb,” “soil,” and “gardener,” she can run them through Scatter/Gather again, rescattering them into more specific clusters.\n\nSuper neat!\nBut this variety of tools has vanished. The agents have folded into the applications.\n\nOn the modern internet, except when we search, we hardly think at all of ourselves using epistemic agents at all. …\nDelegation of tasks on our knowledge quests hasn’t gone away. Instead, epistemic agents are now deeply encapsulated in the sites and apps we use. Companies design and deploy the epistemic agents and we buy their services, based on them “just working” - in other words, accurately guessing what will make us happy. So Spotify makes a mix which is a pleasing blend of songs I already know and like and new songs which I have a good chance of liking. Amazon suggests products I might like to buy in combination with my current purchase.\n– Tom Stafford, Epistemic Agents (Reasonable People #26)\n\nAND:\n\nAlong with this encapsulation, it seems like one epistemic agent ate all the others - recommendation. Whether it is new music, concurrent purchases, or which the best take-away is in my area, most epistemic tasks can be looked at as recommendations.\n\nIn particular, says Stafford: SOCIAL recommendation won.\nAnd he asks: is it possible any longer to imagine other epistemic agents?\n\nThe recommendation algorithms in these platforms are great at showing me more of what I like, but are there any which try and identify gaps in my experience and surprise me? The algorithms are great for promoting affiliation, suggesting people I might know, but are there any which deliberately try and open new vistas in my social network, rather than merely complete triadic closure?\n\n(Triadic closure is a concept in network theory which is when a network cluster gets more densely interlinked, instead of enlarging and bridging to other clusters.)\nIt’s provocative!\nIt is healthy to name the algorithm (as previously discussed; 2020). The algorithmic newsfeed in Facebook is embedded, so it feels “natural,” but imagine if there was some kind of truth-in-advertising type of legislation. \nWhat if it were law to name the algorithm according to its reward function?\n\nLittle Miss Reverse-Chronological \nLittle Miss I-Make-You-Click\nMr I-Reinforce-Your-Prejudices\n\nAnd you would get to choose.\nBut those are still forms of social recommendation, however.\nStafford’s provocation makes me imagine epistemic agents which are anti-social or anti-recommenders or anti making you happy as a reward function, or all of the above…\n\nYouTube suggestions titled: None of your friends have seen this yet\nA subtitle on my takeaway app: You had that appetiser last time. Why not try something else?\nEpistemic agents that push understanding the problem space, shying away from providing a solution: Here’s are the tradeoffs for the various lawnmowers you could buy. Explore to see which of your preferences make the biggest difference\nSpotify gives you an automatically generated playlist: Try Anything Once, Twice If You Like It.\nYou’ve got a spare hour so your calendar starts suggesting things that you haven’t put on your to-do list but really you ought to do. Not type 1 fun, not even type 2 fun, actually not fun at all but you’ll have a sense of relief when you’ve finally filed your expenses.\n\nThat kind of thing. \nLet’s assume we’ll all have augmented reality, networked smart glasses in a year or two.\nSo we can expand the Le Relais de Venise approach in two directions perhaps.\nWhat if my future smart glasses showed me the top three in ANY category, using that same visual language?\n…walk into a book store, see the current top fiction books with a red halo; the current top non-fiction with a blue on. (Bonus points: “popular” according to my chosen demographics and influencers.)\nWhat if the Le Relais dessert menu offered alternate epistemic agents?\n…look at a menu, run Scatter/Gather on any list. The words swim and reorganise into categories; I pick one, focus, they re-categorise. Maybe not so useful for the sweet course. Could be handy to learn about wine.\nYou may ask why I wasn’t focusing on dessert instead of spinning off about agentive software UI and algorithmic hegemonies and taking notes for later. Yes I ask myself that too. Focus on the cheesecake Matt.\nMany years ago I got obsessed with habit-breaking days. We live our lives in self-reinforcing networks of habits: you walk down the street so you see the Pret coffee shop so you go in and you see the snack you always get and… BUT: walk down the other side of the street and your eye is caught by an old spot that you can only see from that angle which takes you to a place where you try something else and you sit in and do your emails before your commute so you get a seat on the train aaaaand… you’ve got a new routine.\nWhat if you discovered a secret toggle, deep in the Settings of your phone, and it was labelled “Routine” – and one morning you tapped “Turn off until tomorrow.”\nThen your Citymapper ranks a route at the top which is almost as quick, but you never take it. Your Priority Inbox makes sure it shows you emails from people you typically don’t read. Your alarms are all late; you get breaking news notifications from publications you don’t read. A klaxon goes off if you get the same darn sandwich from the same darn place for lunch. Your phone rings but actually it has spontaneously placed an outbound call and is just letting you know. It has called your father. He doesn’t have a blue underline in your contacts, which your phone knows. “Hello,” he says, picking up, “What a surprise! I was just thinking about you.”\n",
    link: "/home/2022/05/24/epistemic",
  },
  {
    title: "Filtered for ownership",
    date: "19.48, Thursday 26 May 2022",
    content:
      "1.\nSherlock Holmes, the world’s greatest detective, analytic, rational, aloof, is public domain.\nSherlock Holmes, the world’s greatest detective, analytic, empathetic, sometimes even warm, is intellectual property owned by the estate of Arthur Conan Doyle.\nIf this movie wants Sherlock Holmes to express emotions, its creators need to pay up (The Verge).\nThe estate suggests the copyright specifically covers Sherlock Holmes caring if Watson is injured or kidnapped.\n2.\nIn 1974 Sir Roger Penrose, mathematician and physicist, discovered Penrose tiling (Wikipedia), a form of aperiodic tiling with (potentially) fivefold symmetry.\nThere are two shapes, a thin rhombus and a fat rhombus. Using these two tiles, you can infinitely cover a plane without the pattern repeating.\n\nSome photos of a bathroom floor with a Penrose tiling pattern.\nDo try out this interactive Penrose tiling tool – click to make the pattern grow.\n\nIt looks regular but it ain’t.\n(I seem to remember that the tiling pattern is a 2d slice of a regular 5d lattice, but I’ve never been able to get the code to work. The maths is a bit beyond me)\nANYWAY:\nIn 1997 Kleenex produced loo paper embossed with the Penrose tiling pattern, and Roger Penrose took them to court and they stopped. The London Science Museum has the illegal Kleenex in its collection.\nWhy would Kleenex do this?\nThe story I always heard was to do with luxury quilted paper: any other embossing patterns would risk repeating as the paper winds round and round, and so the loo roll would bulge and become uneven. Smart!\nHow would Penrose get away with owning the pattern?\nThat’s what I don’t get… the algorithm can’t be owned, right? Just the output. And with an infinite pattern, you just scroll to a part of the infinite canvas that hasn’t been copyrighted?\nAnyway, they settled out of court.\nRELATED: who owns the immortal cell-line of Henrietta Lacks – or rather, not of her but of a cancerous tumour? As previously discussed.\n3.\nSome celeb owns an NFT of a cartoon ape. It has been stolen. Seth Green, whose NFT was stolen, has been pleading on Twitter with ‘DarkWing84,’ who bought his ape from a scammer, to return it.\n(Matt Levine, who writes daily about money on Bloomberg, is - in this age of oligarchs and impossible-to-understand high finance - 100% a must read. Levine covers the NFT theft in his column today.)\nBUT\nThe source code of that code that implements an NFT contains a mapping that associates an arbitrary ID (representing this particular instance of the cartoon ape NFT) with a particular Ethereum address. This mapping is traditionally called “owners”. Does DarkWing84 own the ape? The code says he does.\nHere is a fascinating legal unpacking by James Grimmelmann (Twitter thread). It’s… common sense? But I’d never considered it as plainly as this!\n\nSome people might object that an NFT is just some made-up collective hallucination on a blockchain, not an actual thing like a car or a book that can be possesed and owned. But lots of other made-up things can be owned, like patents and corporate shares.\nThis is also a familiar distinction in property law: between ownership and possession. If you pick up my computer and walk away with it, I have ownership and you have possession. I can sue you to get it back. If you intended to keep it, you can be arrested for theft.\nBut just as some changes in possession do not transfer ownership, some changes do. If I give you my computer, you become the new owner upon delivery, i.e., when I give you possession. I cannot now sue you to get it back, because you are now the owner.\n\nForget about NFTs being a made-up collective hallucination. Ownership is a made-up collective hallucination!\nIncredible to think of ownership as being so arbitrary.\nImplies that we could have completely different configurations of ownership, moral frameworks around it, feelings around it.\n4.\nGPT is copyright laundering, says v buckenham on Twitter.\nAnd continues: I think copyright has a lot of problems, but I care about the bundling up and reselling of so many people’s voices and labor.\nGPT being the startlingly good AI text generator that I got to play around with in 2020. My takeaway: GPT-3 is capable of original, creative ideas.\nIf the input to GPT-3 is all the text on the internet, some of which is explicitly in the public domain, but most of which has been written by actual people who could be asked and could assert that they have ownership of their words, and the algorithm is proprietary, what is the copyright status of the output? OpenAI, the makers of GPT-3, act as if there is none. Ownership vanishes. Sleight of hand.\nBUT: If the input were a single text, and the algorithm were a simple and automatic translation (say) from English to French, the output text would clearly not escape the original copyright.\nSo where is the threshold?\nCould it be the quantity of input text? The complexity of the algorithm? No. Because if I ask about something really really specific, for example some song lyrics, the GPT-3 generator doesn’t somehow “clean room” the words and make them public domain.\nAI plagiarism will be a future problem.\nWHICH MAKES ME THINK:\nMaybe there is a market for a future GPT-PD, where PD stands for public domain, and the AI model is guaranteed to be trained only on public domain and out-of-copyright works.\nAnd litigiously cautious megacorporations like Apple will use GPT-PD for their AI needs, such as autocomplete and auto-composing emails and how Siri has conversations and so on.\nBut out-of-copyright works tend to be older.\nSo my future copyright-unencumbered smartphone will cause me to speak like my great-grandmother, with the cadence and turns of phrase of Victorian novels and newspapers.\n",
    link: "/home/2022/05/26/filtered",
  },
  {
    title: "The apps I use to read and write for this blog",
    date: "20.20, Friday 27 May 2022",
    content:
      "Because I’ve been asked a couple times recently:\nI keep up with 345 websites and newsletters using an app called NetNewsWire. It’s free and I have it on my Mac, iPhone, and iPad. It’s a type of app called a newsreader.\nWhen I find a blog or website I want to follow, I look for an RSS feed (sometimes just called a “feed”) and subscribe. This is also free. NetNewsWire grabs the feeds periodically, and presents the articles so that I can read them without ads or design.\n(There are many newsreader apps out there. NetNewsWire is my favourite because it’s clean, easy, and fast.)\n(Learn the basics about using RSS at AboutFeeds.com. The feed for this blog is here.)\nHow does NetNewsWire keep my subscriptions in sync between my various devices? When you run the app for the first time, it asks you to set up an account with one of various providers. It’s a bit like the way your email app will ask you who hosts your email. One free option for syncing is iCloud. I didn’t do that. Instead I first created an account with Feedbin for which I pay $5/month. NetNewsWire uses Feedbin to sync my devices.\nI pay for Feedbin for one big reason: it gives me a secret email address that I can forward anything into. Here’s how I use it:\nI read a lot of email newsletters, and email newsletters don’t have RSS. But my email client is a terrible place to read long articles. My inbox is full of distractions and I often miss things. So when I subscribe to a newsletter, I also set up an auto-forward rule from Gmail to my secret Feedbin email (and auto-archive the original email). Now newsletters appear in Feedbin, and therefore I get to read them in NetNewsWire.\nHere’s my subscription list (you’ll find a bunch of blogs there you can also subscribe to).\nHow I use NetNewsWire:\nI don’t read everything.\nNetNewsWire has a “smart feed” called Today which only shows articles that have been published today. I look at that multiple times daily, then occasionally at particular favourite blogs to see if I’ve missed anything. I have about 6,000 unread articles. That’s fine.\nI do almost all my writing in an app called Ulysses. It’s on my Mac, iPhone, and iPad and keeps in sync with iCloud.\nIt keeps short text notes in an overall library, organised by folder. I’ve used it for years. It’s well-designed, simple but not over-simple, and reliable.\nI have top-level folders for\n\nWork\nProjects (organised by year then project)\nThis blog\nAnd miscellaneous others, such as cooking, writing fiction, talks, and so on.\n\n(I don’t keep track of to-dos much, but when I need to I use an app called Things which I have on all my devices. It’s also well-designed, structured without enforcing too much structure, and simple without being too simple. I organise tasks by project, and tag them by person and by whether I’m expecting to hear from them or they’re expecting to hear from me. This keeps general to-dos out of my notes.)\nInside the top-level folder for this blog the main two folders are:\n\nLinks\nPosts, broken into Drafts and Posted.\n\nMy writing process is as follows.\nWhenever I see an interesting link, on the web or reading subscriptions, I use the share icon and save it to my Links folder in Ulysses. I copy and paste a little context, or add a few words to make sure I can find it later. I don’t sweat it with tags or detail. I save maybe a dozen links a week.\n(My long history of keeping these links is also how I put together talks, or do invention work when I’m in client work mode. I don’t have to be smart about a topic, I just have to have been keeping notes for longer than most people would think reasonable.)\nWhenever I have an idea for a blog post, I make a quick note in Drafts. This might be a single line or it might be a paragraph. Drafts tend to start with an observation, a question, me trying to explain something to myself, or a connection between two ideas. Ideas for post appear suddenly and disappear just as fast – so I’m diligent about writing them down immediately even if I’m half awake or walking down the street. I write down maybe 3 or 4 ideas a week.\nWhen I’m in the mood to write, I browse through my collected links and my drafts and wait for something to catch my eye. This is rarely at the same point as capturing an idea.\nOften what happens is that two drafts rhyme with one another, so I bring the two together.\nAnother frequent occurrence is that I can’t think of anything to write, so I start by trying to explain in plain language why I find something interesting. I might get a few paragraphs along before I feel like the post isn’t going anywhere, so then I stop but I leave the expanded text in the draft.\nI do this probably daily, 20 or 30 minutes expanding notes, trying bits of narrative, connecting ideas, and generally reminding myself of what’s in my notes.\nTwo or three times a week a post gets all the way to the end. Sketching and thinking my way through an idea is a different process to actually writing. I often surprise myself in this process – I usually don’t write with an endpoint in mind. It’s more like improv, and my opinion sometimes turns 180 through the process. I barely copy edit when done. Once over quickly, that’s it.\nThen I title it and it’s done.\nMy blog is a homegrown setup and it doesn’t include an editor, web-based or otherwise. Posts are in Markdown (for the last decade; the first decade they were in XML). It’s all templated and I wrote my own server-side app for rendering.\nWhen I write a post I save the text file in a directory with today’s date and add it to the code repository using git. On my Mac that means using Terminal. On my phone and iPad I use an excellent app called Working Copy which is a git client. The code gets pushed to Github. Then I connect to my server over SSH and run a script which deploys the latest code, including the new post.\nThis is a pretty baroque process. I wouldn’t recommend it to anyone. But I like controlling my own code and having the ability to tweak the way my blog works, so it’s good for me.\nI’m very often not happy with what I write. Sometimes I’m super excited. However I also know (from experience) that my feelings about a particular post do not correlate well with how it will be received. So out into the world it goes, either way.\n",
    link: "/home/2022/05/27/apps",
  },
  {
    title: "In which Beat Saber does odd things to my head",
    date: "21.16, Tuesday 31 May 2022",
    content:
      "I’ve been playing a bunch of Beat Saber recently. It’s a VR rhythm game – you wave your controllers, one in each hand, to hit blocks as they zoom toward you along a track like you’re tied to a music stave made out of lasers. You (in virtual reality) have a red light saber in your left hand, and a blue light saber in your right.\nMeanwhile: electronic music.\n(The other game I have been playing a bunch is Walkabout Mini Golf which is (a) super zen in single player, and (b) in multiplayer, AWESOME for taking meetings. Walk-and-talk is genuinely the killer app for VR.)\nTWO OBSERVATIONS.\nONE.\nAlbums should be released with a Beat Saber edition.\nOr maybe not quite a dedicated edition? I doubt the market could stand it. Like: part of me would like to see music released for Beat Saber + Peloton + Strava, like the way tracks used to get pre-released on national radio to build hype (does that still happen?). But maybe more realistically, perhaps Beat Saber should have a built-in podcast app and AI-generated patterns that are semi-challenging.\nThe attentional environment of the 20s is wild compared to the 90s. I remember when multitasking became the norm. Ha. And then 14 years ago I wrote:\n\n2008 is the year we hit Peak Attention. You can either carry on encountering as much as you do now, giving every input less and less attention every year, or you can start managing it, keeping some back to take long-haul attention flights. What are the consequences of living post-Peak Attention? Nobody will be able to understand anything hard unless they make sacrifices.\n\n(All the links in that post are broken.)\nSo there’s not a chance in heck I can listen to a whole album now, end to end. I can barely get to 90 seconds checking out a track on YouTube, and that’s after skipping the first third.\nBut maybe, if everything except my audio cognition was totally soaked, eyes body senses all occupied and novelty-baffled and saturated, maybe - just maybe - I could then focus on new music for a whole 74 minutes?\nTWO.\nWhen I play enough Beat Saber I swear I can feel my hemispheres decouple.\nOne hand is doing one thing, the other another, no cross-talk. After a while I go fully automatic and I get to take a little step back. Hey left arm, look at you doing your thing.\nGames which allow for the population of selves to appear.\nI remember this from my days doing public speaking. At my best (which was rare) I had three selves – one doing the speaking, another super tuned into the audience reaction, and a third one step removed.\nAnd for so long these selves could persist, avoiding the wavefunction collapse back into a single personality.\nI feel like in our modern era there is an over-fixation on engagement and being in the moment – which feel like two aspects of the same elephant to me, one that app developers pursue as something to be inculcated in audience, not just response but habit, and the other than we attempt to attain for ourselves.\nBUT MAYBE: what are the good sides to disassociation? When is, I don’t know, “simultaneous fugue” (to invent a term) an adaptive trait?\nBrenda Laurel on “engagement” in 1993. 1993!\n\nIn the foregoing discussion, engagement was held up as a desirable–even essential–human response to computer-mediated activities. Engagement has cognitive components, but it is primarily understood as an emotion. Why should we demand that all human-computer activities elicit this particular emotional response?\n– Brenda Laurel, Computers as Theatre\n\nYeah, we shouldn’t.\nSo maybe in pursuit of engagement, and focus, and flow, we miss other virtues. For example: the quiet beauty and unusual satisfaction of settling into ennui. (It is FULFILLING to spend a night vaguely irritated watching movie trailers on streaming services, unable to settle on anything, otherwise we wouldn’t invest so much of our time in it, and if only we could admit that to ourselves then we could factor out the guilt, experiencing it instead in a pure fashion. It is the same feeling as the rich have, being perpetually bored and cool, and the French. This is the closest you or I will get.)\nLet’s stick with simultaneous fugue.\nWhat I’m imagining is a series of games that train me to hold multiple competing concepts in mind at the same time.\nPerhaps, if I can operate my left and right hemispheres simultaneously but separately for an whole new-albums-worth of time, if only I play enough Beat Saber, I can hold (for example) the contradictory frameworks of capitalism and socialism in mind for long enough to imagine a whole new political philosophy, and thereby save the world.\nTHESIS + ANTITHESIS = SYNTHESIS.\n",
    link: "/home/2022/05/31/beat_saber",
  },
  {
    title: "Adobe should make a boring app for prompt engineers",
    date: "19.51, Thursday 2 Jun 2022",
    content:
      "AI image synthesis has just crossed a reliability and quality threshold that means that it can replace a broad swathe of creative work, like, tomorrow, but what’s interesting is that a new kind of expertise is required, prompt engineering, and that gives a clue to the future shape of the industry.\nRecent developments:\nDALL-E 2 (by OpenAI) transforms a natural language prompt into a matching image – and it’s remarkable. Scroll through the #dalle tag on Twitter to see photorealistic images, graphic design, fake stills from movies that never existed, etc.\nThe variety is amazing. Watch Alan Resnick’s DALL-E variant test (YouTube, 2 mins) where he starts with a single prompt and simply wanders through adjacent images, making a stop motion animation (background here).\nThen Google launched Imagen which similarly combines an unprecedented degree of photorealism and a deep level of language understanding. Check out the examples on their project page.\nIt’s one thing seeing photorealistic images. It’s another seeing pixelated graphics, or DALL-E doing brand design, producing plausible logos.\nWhat’s I love about this new technology is that we’re still figuring out how to use it, and we’re figuring it out together.\nI’ve been playing with the previous gen of text-to-image AIs as part of the Midjourney beta.\n(Their homepage isn’t super informative, but their Twitter is good.)\nIt’s fun! The pics are pretty!\nI’ve popped a couple of Midjourney-generated images on my Instagram:\n\nLake, trees, and city. Prompt: “London is a forest in the style of David Hockney’s The Splash” – the colour palette is gorgeous, and the brushwork on the trees is something I’ve taken inspiration from for my own sketches.\nMonument Valley. Again the prompt included something about Hockney, then I followed a couple of variations.\n\n(The text you give the AI is called the “prompt.” As you can tell, the secret incantation I like to use is “in the style of David Hockney.”)\nThe interface is curious! During this beta, there is no app and no website. Instead the sole interface to Midjourney is via Discord.\nAll users are in the same Discord server, and there a whole bunch of chat channels. To get an image, you publicly type the command ‘/imagine’ with your prompt. The Midjourney bot replies, then updates its reply continuously as it generates four variations – this process takes a couple minutes. You can then choose one of the variations to either (a) branch out create additional variations, or (b) upscale to greater resolution.\nEveryone can see what everyone else is doing. All your work is in the open!\nIt doesn’t feel like social media. With something like Instagram, you’re all in the same world, but the foundational feeling is one of: seeing and being seen.\nInstead Midjourney feels more like contributing to Wikipedia, or like a giant scientific experiment. We’re not generating images, we’re discerning the internal nature of the AI by sending in probes (words) and seeing what bounces back.\nIt’s like X-ray crystallography, our word beams diffracting into output images, there to be decoded.\nIt’s definitely collaborative. Early on with text-to-image AIs it was discovered that simply appending “high quality” or “4K” to your prompt, whatever it is, will product better results. And the Midjourney Discord is like this all the time.\nNote also Midjourney’s current economics.\nHigh quality AI models are too big to run anywhere but the cloud, and running them takes a lot of compute. Compute is expensive.\nSo Midjourney gets all of its beta users onto a paid plan as soon as possible. You get a certain quantity of CPU hours for free. Then you get nudged onto a monthly subscription and your usage is metered – the bot will let you know how many CPU hours you’re consuming.\nAdditionally the images are licensed. If you use the generated images commercially, for a corporation with annual revenue north of $1m, or anything related to the blockchain, you need pay for a commercial licence.\n(Which is fascinating, right? This is what was in my head when I was circling the concept of ownership recently – a camera manufacturer doesn’t get a say in how I use my photos. Microsoft Excel costs the same whether I’m using it to manage my household budget or sell a bank. We believe that Henrietta Lacks’ family today have moral ownership of the cell line produced from a tumour produced (against its will) by Lacks’ body in 1951, but we don’t grant the photographer who set up the camera and the trigger mechanism copyright in the case of the monkey selfie. It would be fascinating for a philosopher to sit down and, from first principles, tease out the detail of all these situations… and also this current situation: a proprietary AI model and the ownership of the prompted output.)\nTAKEAWAY: compute costs $$$.\nLike I said, half the fun is the community figuring out magic incantations to inspire the AI to do what you want. For instance you’re going to get a certain kind of result if you start your prompt with “A photo of…”.\nThere was a 24 hour flurry of excitement when it appeared that DALL-E had an internal angelic language. Here’s the pre-print on arXiv: Discovering the Hidden Vocabulary of DALLE-2.\n\nit seems that ‘Apoploe vesrreaitais’ means birds and ‘Contarra ccetnxniams luryca tanniounons’ (sometimes) means bugs or pests.\n\nSwiftly debunked. Which is a shame because there’s a long folkloric history of a secret and perfect language of the birds and it would be hilarious to discover it like this in the Jungian collective unconscious, crystallised out from the distillation of the entire corpus of human text hoovered up from the internet.\nALSO there are other similar AI phenomena, just as mysterious. For instance adding the words zoning tapping fiennes to movie reviews prevents an AI from classifying the review as good or bad.\nIt’s a process.\nWhat’s happening is a new practice of prompt engineering – or rather let’s call it prompt whispering. Prompt whisperers have a sophisticated mental model of the AI’s dynamic behaviour… or its psychology even?\nLook at Astral Codex Ten think though this, while he tries to generate a stained glass window of bearded 17th century astronomer Tycho Brahe accompanied by his pet moose.\nIt doesn’t work:\n\nI think what’s going on here is - nobody depicts a moose in stained glass. A man scrying the heavens through a telescope is exactly the sort of dignified thing people make stained glass windows about. A moose isn’t. So DALL-E loses confidence and decides you don’t really mean it should be stained glass style.\nAlso, is it just me, or does Brahe look kind of like Santa here? Is it possible that wise old man + member of the family Cervidae gets into a Santa-shaped attractor region in concept space? I decided to turn the moose into a reindeer to see what happened: …\n– Astral Codex Ten, A Guide To Asking Robots To Design Stained Glass Windows\n\nSo the AI is no longer a black box.\nIt’s a landscape, maybe, with hills and gradients and watersheds. But it has internal structure, and the knowledge that concepts can be near or far or have gravity isn’t sufficient to generate great imagines, but it informs the prompt whisperer to dowse in the right place.\nNot everyone will be good at this. Some people will be naturals! It’s like being good at using google or researching with a library, a combination of aptitude and eye and practice. A skill.\nAlso I didn’t know this Brahe fact before: Sometimes he would let the moose drink beer, and one time it got so drunk that it fell down the stairs and died.\nSo!\nDALL-E/Imagen/etc output is high quality. Photorealistic, sharp, with the appearance of being professionally produced, etc (if that’s what you ask for).\nBut also, and this is what seems different, the AIs seem to have a reliable level of Do What I Mean.\nIf you can ask for a particular type of image with intent, get a result in the ballpark and then iterate it – well, one possibility of text-to-image synthesis is that it replaces a decent amount of creative work. Maybe not the super imaginative or high-end or novel or award-winning work, but definitely the category that takes a bunch of time and bedrocks agency P&Ls.\n\nWhy get a model and a set for a product photoshoot when you can get dial in the mood you want, then comp your product in later?\nWhy grind out a hundred icon variations if you can batch produce them from words?\nWhy set a creative off on making a dozen logo options for a brand when you can just feed the brief to an AI?\nWhy spend hours finding art for your low circulation industry magazine to give it some colour when you can hand the caption to a bot and create ideals images in whatever size you want?\n\nThat’s the threshold that has been crossed.\nBUT what this early work shows is that prompt engineering is a skill, just like using Adobe Photoshop or Figma. You can use it in a utilitarian way or creatively but it’s a skill none-the-less. And required.\nSo the future of the creative sector, at least in the near term,\n\nIS NOT: creatives get replaced by software, the client right-clicking on an app for themselves to auto-fill an image, like some kind of visual autocomplete, but instead\nIS (or might well be soon): agencies use software to 100x their productivity.\n\nAs long as there is skill in using these AI models to produce great results, there is a place for creatives. My take is that the existing industry relationships will remain in place. But the performed work will change. Less time drawing, more time prompt whispering.\nWhat’s the ideal tool for prompt engineering? There isn’t one yet, it’s all too new.\nThe ideal tool is primarily about workflow and exposing all the various parameters.\nIt shouldn’t blow any minds, except\nfor what people do with it.\nIt should be boring as heck because that’s what a workbench is.\nI’m imagining an app that allows for managing many concurrent projects, and includes features like:\n\nColour palette management\nFine-tuning of custom styles to apply to any output\nA visual method to explore variations with an infinite stored history, like a tree map crossed with a lightboard\nA prompt builder using stored tokens, with prompts stored for all images so that old projects can be picked up at any time\nManagement of queues (image generation is slow) and metered compute\nAutomation to crank out large numbers of variations based on spreadsheets of input data, upsized, saved and named appropriately\n\nBonus points: a user interface with epistemic agents to provide inspiration in exploring concept space.\nThis isn’t a limited plug-in just for smart in-painting. This would be a full-blown application for expert, rapid use of DALL-E and the like.\nThe business model might be different?\nThe economic boundary condition is that compute is remote and expensive, so you’re going to have to keep on feeding the meter. In designing my imaginary app, I would build this in pretty deep: projects should have budgets associated with them.\nGiven this, the app should be free. Make it really easy to top up your compute balance in-app then charge 5% on top.\nThe Export menu item would include a drop down for the file format, and a checkbox for a commercial license (also paid).\nIt would fit right into Adobe Creative Suite. It’s the right blend of creativity, production, and workflow.\nMaybe Midjourney will build it first? Someone should anyway.\nIt’s kinda insane how fast this is going. DALL-E’s natural language understanding builds on GPT-3, which was radically better at human language – and dropped only 18 months ago.\nAt the time I ran across the idea of an AI overhang: what if there are no fundamental technical constraints and AI can get 10x or 100x better in a matter of months?\nWe’re thoroughly in overhang territory now. If text and images then why not 3D models and characters, then why not maps of virtual environments and VR worlds, then why not auto-generated gameplay. Why not narrative and music and entire movies.\nPractically (from that post above): Intel’s expected 2020 revenue is $73bn. What if they could train a $1bn A.I. to design computer chips that are 100x faster per watt-dollar?\n(Still waiting for that.)\nWe’ll need tools for this kind of work that are as practical and reliable as any office or CAD software.\nOne thing is: image generation is still slow.\nHow much storage and compute would you need to run something like Midjourney/DALL-E/Imagen/or whatever locally? How about with real-time generation time (sub 150ms feels interactive)? How about 4K 30fps?\nI don’t know the answers. I’m trying to get a handle on how many Moore’s law doublings we are away from that kind of experience.\nBecause the wild kind of prompt whispering would be where it’s not prompt-and-wait but as-you-speak and conversational. Like the difference between ancient mainframes with batch processing and real-time desktop GUIs with the powerful illusion of direct manipulation – imagine the creative power unleashed with the first Macintosh, the personal computer “for the rest of us,” but for interactively driving these inhumanly powerful AIs.\nBicycles for the mind indeed.\n",
    link: "/home/2022/06/02/dalle",
  },
  {
    title: "Idle thoughts sitting by the pool in the hot sun",
    date: "11.09, Thursday 9 Jun 2022",
    content:
      "It turns out that chickens use their eyes quite differently. (I’ve been skimming paper abstracts.)\nThe left eye distinguishes between strangers and friends – and more generally is a novelty detector.\nThe right eye categorises and figures out what action to take.\n(So a chicken looking only with its right eye is poor at telling novelty.)\nChickens, having eyes on the sides of their heads, look with only one eye at a time.\nIf I wasn’t sitting here baking in the heat I would be thinking about the general lesson here – that these two ways of seeing make up the totality of how to see the world. One a process that looks for metaphors and stereotypes; the second a novelty switch. Organisations and bureaucracies need these two ways of seeing. Machines and software too.\nAnyway. The avian brain. Did dinosaurs specialise their eyes too?\nHere’s the abstract.\nVallortigara, G., & Andrew, R. J. (1994). Differential involvement of right and left hemisphere in individual recognition in the domestic chick. Behavioural processes, 33(1-2), 41–57. https://doi.org/10.1016/0376-6357(94)90059-0\nI knew a guy who knew a guy who played Sunday league football. Like, still amateur but a step up from a regular kick around with your mates.\nIn the team was an older guy who had once upon a time played professionally in the as-was Second Division, the third league from the top. (The English football league system is a pyramid of 140 leagues connected by promotion/relegation rules. It should be in that UNESCO list of the intangible cultural heritage of humanity.)\nHe ran rings around the rest of them. Like, astoundingly good. Nobody had a chance.\nHe said that someone from the league above would run rings around him, and a player from the league above that, the Premier League, the top one, was yet another class again.\nANYWAY: I have a cousin who acts and performs. She teaches singing now.\nYears ago, at the start of her career, she was taking a Christmas show round old folks homes. At a family get-together she showed us one of her costumes – it was a turkey. Not like a full body mascot-style turkey, but a kind of hood and outline of the rest of it.\nAnd so she walked into the kitchen in this cheap-ass turkey outfit, and my goodness, I have never seen a person be a turkey so much.\nI believed it utterly. It was a spell!\nI couldn’t put my finger on what it was. Changes in movement and stance are so powerful. If I had worn the costume I would have looked like a dude in a turkey costume. But in the hands of my cousin, it was a human-sized turkey in the room. I know that a human-sized turkey isn’t a thing that exists – and yet! Belief is a social construction, and here she is deftly restitching the social space time fabric around her, in real-time.\nAnd I thought, if that’s my cousin, then what is it like when you encounter someone who is the best of the best when they are in character? Like, a legendary actor of the stage. They must suck you into their whole fictive universe, just with a glance, falling through the event horizon of reality distortion just being present in the same room.\nMaybe some kinds of talent are exponential.\nMy stupid theory is that there are pi space dimensions.\nThis is based on nothing except that the number 3 isn’t special but pi drops out of relationships between physical things all over the place.\nI don’t even know what a fractional dimension would mean!\nIn my head, having 3.14-etc space dimensions is indistinguishable from having 3, in everyday life and in most of physics.\nBut the extra fraction leads to the universe slip-sliding over itself, at the edges. It says there is some spooky connection between the very big and the very small, perhaps, it’s where self-similarity sneaks in. Maybe it looks like morphic resonance. Maybe it means that dancing can change the weather. It’s how we’ll be able to fly faster than light one day. A bit of give, a bit of play.\nThe resort here in Sicily has an amphitheatre which, in the U.K., would be making a statement, but here is simply a round space for performance with seating terraced up all around, open to the sky. It’s so conventional. Functional.\nAnyway the staff put on a performance of Beauty and the Beast for the under 11s.\nIt was wonderful. Modern dance, some acrobatics, some juggling.\nAlso kinda scrappy – they’ve only been working together 2 weeks. Scrappy compared to Hollywood! Miles better than what I could do.\nThe play was made to work with whatever skills they had. A collage to tell the story in a series of scenes put together in whatever way works.\nWe loved it! So wonderful. Their enthusiasm and talent, our enjoyment.\nLike I said, more than I could do. We were wowed by the lifts and the leaps. Yet we felt like peers somehow?\nLike: here we are, some of us watching and laughing and clapping and gasping, and some of us performing in the middle, all part of the same thing, all together.\nMoon overhead.\nI felt so in touch with what people have been doing for thousands of years.\nIn open theatres just like this, in communities and towns, people bringing their talent and bringing their appreciation to weave stories and be together.\nThe other week we went to watch folk music in a small bar in Camden. Maybe 30 people there? It was a performer we saw on a live stream during the pandemic, which is how this bar kept its performances going. Many of the people there were friends of the people singing and playing at the front.\nI had a similar feeling there – generation upon generation, thousands of years, I felt so in touch. In the moment and in eternity.\nThis modern form of “audience” or “user base” or “electorate” or “customers”… it’s so weird. The separation between the people and the people at the front. We should feel like that, on another day, we could be on stage and they in the stalls. Perhaps it’s a blip, this hard division.\nI wonder how much of what we see as waves of fashion, or epochs of technology, or trends, is driven simply by the urge, felt by every generation, to reach for a world without division between stage and seating – where we are makers and consumers both at once, taking turns according to ability and interest – to re-create the amphitheatre.\nThe sun is hot.\n",
    link: "/home/2022/06/09/idling",
  },
  {
    title: "A series of tubes",
    date: "18.52, Thursday 16 Jun 2022",
    content:
      "You wait for ages for the return of internet-inspired tube-based physical goods transport systems then two come along at once.\nPipeDreams Labs just raised seed funding to build networks of underground PVC pipes in cities, to be used by self-routing, self-driving robot pods that carry cargo.\nThere’s more in their Twitter thread. The 14 second concept video is neat – it’s a cupboard in your kitchen that pings like your inbox when your groceries arrive.\nThis is relatively established tech (pipes and pods). What’s new is the self-driving and the user interface.\nThe pods can carry anything up to 10 inches in diameter, which is (according the FAQ) enough for 95% of groceries and almost all preparing food deliveries – except pizza.\nSo… New pizza form factor incoming? Feels relatively straightforward to reformat food shapes.\nI wrote last year about a national packet-switched drone delivery network, riffing on the Paris pneumatique poste which opened in 1866 and had automatic routing of physical items in the 1930s.\nAt the time, the key part for me was an interoperable protocol for packet-switched drone delivery in theory over the entire country – essentially: TCP/IP for stuff.\nAnd that’s what grabs me about PipeDream Labs too. Can the system be just an alternative “transport layer” for an open protocol that any company can plug self-driving matter-packets into, regardless of whether they use pipes or drones or motorbikes?\nDefinitely a role for government, if they had an ounce of imagination in their industry policy/national infrastructure plans.\nANOTHER!\nLaundry Jet is a system of pneumatic tubes, installed in your home, to carry dirty clothes from bedrooms to the laundry room.\nIt’s not new but a video went viral a few days ago.\nI like this (reddit): you throw your laundry towards the wall outlet, and a proximity sensor opens the door and the vacuum snatches the item out of the air.\nThat’s the kind of interface I expect when it comes to domestic robots (which this is, on a spectrum with Roomba and dishwashers). Automation is no good if it doesn’t also relieve you of the bureaucracy surrounding the task – imagine if Laundry Jet required you to carefully fold your clothes and place them on a platter. It’s the air grab that makes it.\nDespite that: it all seems… a little over-engineered? I mean, my house is nowhere near large enough to require a secret corridor behind the walls  exclusively for my pants. And goodness knows what you do in the event of a blockage. If there some crazy acidic fabric-specific liquid drainclear that you pour down the pipes to dissolve the sock bolus?\nTHAT SAID: my memory is vague on this, but I swear my nan had a house with a central vacuum system? There was a little suction port by the floor in all the rooms. That was cool. So I’m not against old-is-new-again home infrastructure.\nA general purpose Laundry Jet-alike would be handy for the home.\nLike: it would be handy to have a port that I put things through, and they show up in a different room. For carrying groceries from the front door to the kitchen, or weeding the garden and carrying it out the front.\nI don’t care about speed; I just care about not carrying.\nSo I guess the ideal interface is that I can tap any item, wherever it is, and announce the destination with my voice, and then at some point over the next few hours, a robot (somehow) picks it up (somehow) and deposits it where I said it should go. You don’t need pneumatic tubes for that.\nNo having to wait for the robot to arrive. It’s async. The key part of the interface is that lack of bureaucracy. That’s the lesson for me.\n",
    link: "/home/2022/06/16/tubes",
  },
  {
    title: "Filtered for glimpses of almost-humans from prehistory",
    date: "09.32, Wednesday 22 Jun 2022",
    content:
      "1.\nCave art may be inaccessible to today’s brain.\n\nA recent article argued that superior visual perception was necessary for the creation of Paleolithic cave paintings because of the level of correct anatomical details and accurate depictions of high-speed leg positions of animals in motion, considering that the works were accomplished far removed from the actual animals and with crude tools. The article uncovered and outlined current evidence for an association between visual thinkers (some diagnosed within the Autism Spectrum Disorder) and a relatively high percentage of archaic genes, of which some are associated with perception and cognition. Moreover, within this group are some savants who can quickly and accurately scan what they see and reproduce it artistically in extraordinary detail. One example is reproducing the correct number and relative size of windows from a brief exposure to a city scene. However, the linguistic abilities of visual thinkers may be impaired, which suggests a negative correlation between visual perception/memory and language.\n– Brain Sciences, Is Reduced Visual Processing the Price of Language? \n\nThe argument in the paper is that pre-human primates (a) are sometimes superior to humans in dealing with visual sequences, but (b) have brain areas more directly connected to visual processing than humans. They deal with a flood of visual information – versus humans, which abstract and discard.\nThe paper goes on to suggest that language emerged relatively recently… and the emergence of language may be associated with the reduced brain size in Homo sapiens that started about 50,000 years ago and more markedly 10,000 years ago.\n(I hadn’t realised that there was such an observed brain size reduction occurring so recently. The early known city is only 9,000 years ago! Radical changes in the nature of consciousness in the recent shallows of prehistory – more recent, even, than the source events of the earliest myths.)\n\nWe suggest that an effect of this loss in brain size was the reduction of neuronal signaling and/or pathways related to raw perception and vision in particular. Visual perception relies on informational highways that may provide so much information that it can be overwhelming for other brain functions, such as retrieving knowledge appropriate to the situation or imagining something that is not present in the here and now. We hypothesize that the loss in brain volume is mainly linked to reduced perception of detail in space and time. We are no longer able to perceive how many hooves of a running horse touch the ground, as the cave artists of Chauvet may have seen with ease.\n\nAfter the Upper Palaeolithic (50,000 to 10,000 years ago) we no longer find evidence for elaborate realistic cave paintings (although we find iconic and symbolic cave paintings after this period).\nRef.\nJohansson, C., & Folgerø, P. O. (2022). Is Reduced Visual Processing the Price of Language? Brain Sciences, 12(6), 771\n2.\nGuide to Machine Elves and Other DMT Entities.\nSelf-transforming machines elves: a term coined by the ethnobotanist, philosopher, and writer Terence McKenna to describe some of the entities that are encountered in a DMT trip. They’ve come to be known by many names, including “clockwork elves”, “DMT elves”, “fractal elves”, and “tykes”.\nMcKenna:\n\nDuring my own experiences smoking synthesized DMT in Berkeley, I had had the impression of bursting into a space inhabited by merry elfin, self-transforming, machine creatures. Dozens of these friendly fractal entities, looking like self-dribbling Faberge eggs on the rebound, had surrounded me and tried to teach me the lost language of true poetry.\n\nMeetings are common:\nPhilip Mayer collected and analyzed 340 DMT trip reports in 2005. Mayer found that 66% of them (226) referenced independently-existing entities that interact in an intelligent and intentional manner.\nRELATED #1:\nMy trip to the dentist in which I discovered the secret of the universe (2020). Alas it turns out this a common effect of nitrous.\nRELATED #2:\nCharles Bonnet syndrome, in which the sufferer experiences characteristic hallucinations of gnomes and fairy lands: The first cluster consisted of hallucinations of extended landscape scenes and small figures in costumes with hats; the second, hallucinations of grotesque, disembodied and distorted faces with prominent eyes and teeth.\n(As previously discussed (2004), along with Homo floresiensi, the mythical hobbit human in Indonesia, 18,000 years ago.)\nRef.\nSanthouse, A & Howard, R & ffytche, D. (2000). Visual hallucinatory syndromes and the anatomy of the visual brain. Brain: a journal of neurology. 123(10). 2055-64.\n3.\nOrcs are an ancient memory of Neanderthals?\nNewsletter Contemplations on the Tree of Woe unpacks the (fringe science) book Them and Us: How Neanderthal Predation Created Modern Humans (Amazon) by Danny Vendramini.\n\nNeanderthals were apex predators. Analysis of isotopes of bone collage has shown that Neanderthal diet was 97% meat. …\nNeanderthals were cannibals. …\nThey weighed 25% more. They were so heavily muscled that their skeletons had to develop extra thick bones.\nNeanderthal teeth were twice as large as human teeth. …\nNeanderthal skulls had extremely large eye sockets, suggesting very large eyes. That, in turn, suggests that Neanderthals were nocturnal.\n– Contemplations on the Tree of Woe, When Orcs were Real\n\nAlso: big snouts suggesting scent-hunting, and no language.\nImagine:\nNocturnal carnivorous almost-humans; coexisting with and physically resembling us, but whereas we are slighter and abstractly smarter, they are brutal purpose-built hunters, terrifying us in the night with their superhuman senses and utter inability to speak – and yet artists of the highest calibre, producing (maybe?) delicate and highly detailed visual representations, a capability astoundingly beyond us, as automatically as a beaver makes its dam or a spider weaves its web.\nLiving with future GPT-3s and DALL-Es, given robot bodies, will be like living with Neanderthals. Entities capable of destroying humanity, these AIs living alongside us, and of inhuman impossible creativity too, with nothing behind the eyes.\n4.\nThe Silurian hypothesis: if there were an industrial civilisation in Earth’s deep history, could we tell?\nFor example, our human industrial civilisation will leave a signal.\n\nWhen we burn fossil fuels, we’re releasing carbon back into the atmosphere that was once part of living tissues. This ancient carbon is depleted in one of that element’s three naturally occurring varieties, or isotopes. The more fossil fuels we burn, the more the balance of these carbon isotopes shifts.\n\nChemical analysis of ancient rocks, in the far future, will reveal this isotopic shift in the Anthropocene layer – the geological layer associated with human industrial civilisation.\n(Temperature increases also create this shift.)\nAND SO, looking back:\n\nFifty-six million years ago, Earth passed through the Paleocene-Eocene Thermal Maximum (PETM). During the PETM, the planet’s average temperature climbed as high as 15 degrees Fahrenheit above what we experience today. It was a world almost without ice, as typical summer temperatures at the poles reached close to a balmy 70 degrees Fahrenheit. Looking at the isotopic record from the PETM, scientists see both carbon and oxygen isotope ratios spiking in exactly the way we expect to see in the Anthropocene record. There are also other events like the PETM in Earth’s history that show traces like our hypothetical Anthropocene signal. These include an event a few million years after the PETM dubbed the Eocene Layers of Mysterious Origin, and massive events in the Cretaceous that left the ocean without oxygen for many millennia (or even longer).\n– The Atlantic, Was There a Civilization on Earth Before Humans? (2018)\n\nWhat went down, 9 million years after the dinosaurs? Perhaps we’ll find their traces elsewhere, in orbit around Jupiter or something.\nArticle by Adam Frank, who also authored the original Silurian Hypothesis paper.\nRef.\nSchmidt, G. A., & Frank, A. (2019). The Silurian hypothesis: would it be possible to detect an industrial civilization in the geological record? International Journal of Astrobiology, 18(2), 142-150.\nTANGENTIALLY:\nDenise Wilton on the “uncanny valley”, the feeling of finding almost-humans almost unbearable creepy:\n\nWas it because we’ve lived through all this before, and got it wrong once already? We’re just living in a never-ending experiment that we’d write about as sci-fi but is actually just real life and the robots are going to take over? The uncanny valley is just a muscle memory from the last time we failed as a species.\n\nWell.\n",
    link: "/home/2022/06/22/filtered",
  },
  {
    title: "Don’t keep your eye on the ball but prime your intuition",
    date: "17.20, Friday 1 Jul 2022",
    content:
      "I watch a bunch of cricket (and read about it too). I ran across a counterintuitive method which is to not keep your eye on the ball. It turns out this is how elite batters operate, and it has made me think about the way I structure my own work.\nGreg Chappell has the idea that there are ascending levels of concentration, with the peak, “fierce focus”, being a state that has a max budget over the day.\nChappell is one of the cricketing greats, a hugely successful Australian batter from the 1970s known for big scores.\nHis origin story: he was great sometimes but other times just ok. Then he received a letter that made him think about his game. In a meditative fugue, sitting in the dark: He thinks about every single game of cricket that he has ever played, from his very first in the backyard with his brother Ian … to Test cricket for Australia.\nThen an epiphany:\n\nHours later - it is difficult for him to tell how many - he emerges with a stunning realisation: by playing cricket since the age of four, he had, without realising it, developed a systemic process of concentration and a precise method of watching the ball; but he had only been using them consistently on his good days.\n\nHere is a deep dive into Greg Chappell’s method, and the psychology behind it: What does a batsman see? (2018) by SB Tang in The Cricket Monthly.\nBrief cricket overview, because I’m a fan and you may not be.\nTwo teams. One team bats, aiming to hit as many balls as possible and build a big score (runs). The other team bowls, aiming to get batters out (by catching or knocking over the wicket behind the batter). Then the teams switch.\nThere are multiple formats of cricket. One is T20 which lasts 3.5 hours. Each team bowls a fixed number of balls: 120 each. A second format is Test cricket which lasts 5 days. The number of balls is unlimited and the batters stay batting as long as they can. Greg Chappell played Test cricket.\nEverything about life can be seen in Test cricket.\nBowlers run up and bowl the ball overarm, with a straight arm, 22 yards from the batter. The ball bounces once, and the goal is to trick the batter so that the ball leaps off their bat in an unintended way so it can be caught, or it sneaks past them and smashes the wicket.\nA cricket ball is leather, rock hard and the size of a tennis ball. For Test cricket it is shiny and deep red. It has stitching which stands proud of the ball. \nThe ball can be bowled at up to 90 mph, and spun up to 2,000 rpm. It swings in the air and changes direction off the ground, both from its own motion, and the position of the seam, and the quality of the ground where it bounces. Its height, when it reaches the batter, is determined by where it bounces. All of which is in control of the bowler.\nSo batting is hard.\nChappell’s key point: mental energy is a finite resource that a batsman must conserve if he is to achieve his ultimate objective of scoring as many runs as possible, which will require him to spend hours, if not days, out in the middle.\nAnd:\n\nChappell realised that he had three ascending levels of mental concentration: awareness, fine focus and fierce focus. In order to conserve his finite quantum of mental energy, he would have to use fierce focus as little as possible, so that it was always available when he really needed it.\n\n\nAwareness. Standing waiting for the ball, Chappell would mark his guard (tap his bat on the ground), look around and count all ten fielders, gaze at the crowd, etc.\nFine focus. As the bowler ran in, Chappell would maintain his central vision on the bowler’s face and his peripheral vision on the bowler’s body. He believed that a bowler’s facial expression and the bodily movements in his run-up and load-up offered the batsman valuable predictive clues as to what ball would be bowled. He did not keep his eye on the ball.\nFierce focus. At the bowler’s last stride, he would shift his central vision the short distance from the bowler’s face to the window just above and next to his head from where he would release the ball. Once the ball appeared in that window, Chappell would watch the ball itself for the first time. He could see everything. He could see the seam of the ball and the shiny and rough side of the ball, even when he was facing a genuine fast bowler.\n\nAfter playing the ball, a deliberate step down in focus level: Chappell cycled his concentration back down to its minimum level of awareness.\n(This resonates with me because attention is the feeling of our brain allocating scarce realtime processing capacity, and it forms a kind of attentional pyramid, as previously discussed, but I haven’t run across the pyramid being extended and described and used in such a way before.)\nThe rest of the article is incredible, by the way, a real dive into the science and psychology of what’s going on. Read the whole thing.\nRELATED:\nWhy You Should Care About Cricket (2011) by Wright Thompson.\nESPN sent their baseball correspondent to India to cover the cricket World Cup in 2011, without him knowing anything about it.\n\nBack home, an Alabama fan had killed the trees at Toomer’s Corner, and I was trying to explain the significance to him. This was big news to me. I’m a Southern boy, and I tend to believe that SEC football is the most important thing in the world. Only, Sambit has never heard of Auburn, or Alabama, doesn’t know that they play college football, or that they are rivals. I fumble around. This is perhaps America’s most intense rivalry. A fan just poisoned two 130-year-old oak trees. It’s serious. I need an analogy.\nMy first thought: It’s like India-Pakistan in cricket.\nExcept, you know, for the four wars since 1947 and the constant threat of nuclear holocaust. Other than that, Auburn-Alabama is just like India-Pakistan.\n\nhashtag brilliant cricket long-reads for people who aren’t necessary into cricket\nDon’t watch the ball!\nThe regular advice in sport is to watch the ball. Greg Chappell says: watch the ball as little as possible. Glance at the ball. Take it in, all at once, only at the microsecond you need to.\nI GET THE IMPRESSION, reading about his method, that what he’s doing with all the “awareness” and “fine focus” activities is pre-loading information into his unconscious mind so that, at the critical moment, he can respond automatically.\nIt is not possible to “decide” what to do about a ball coming at you at 90mph. What you can do is make sure your mind is pump-primed with all the available context cues, with the highest signal to noise possible, and then act.\nThis gives me clues about how to organise my own work?\n(Not thinking about cricket now.)\nI’m building software rn, so I spend most of my time working on product. There’s a lot of sketching, designing, roll-my-sleeves-up building work, and planning.\nOne way of describing this work is: design and build. But that doesn’t sit right with me. These two activities aren’t sequenced like that.\nNow I can think of my sketching and designs in a different way: I am training my intuition. I am not deciding what to do. I am priming myself such that, when a decision needs to be made (when I’m building or somebody asks me for feedback or when I’m putting together the plan for what to build next), I automatically respond the right way in the instant.\nThis seems like a small twist in framing but actually I find the difference quite freeing: I can see now that I’m no longer meant to be right with my sketches. I’m not supposed to be straight to the point. What I’m doing is scouting the field; I’m loading up my unconscious with everything it needs to make the right choice later, intuitively.\nIt’s not about being logical. It’s not about making a rational decision.\nThe remaining question is: how to take lessons from Greg Chappell’s central concept of fierce focus. How can I build my working day around a number of critical decision points, exerting my intuition and reflexes intensely and totally for the absolute minimum amount of time, and otherwise not keeping my eye on the ball at all.\n",
    link: "/home/2022/07/01/focus",
  },
  {
    title: "A love note to British hedges",
    date: "12.48, Wednesday 6 Jul 2022",
    content:
      "The New Yorker has a wonderful long interview with Melvyn Bragg, about his life as a programme maker and public intellectual, and here he is talking about the BBC’s competitors, and also hedges:\n\nNone of these people have the variety of programs, especially in radio, that the BBC offers. They don’t even know how to do it. England’s full of niche audiences, like the old hedgerows full of different birds, and they’re all singing away.\n– The New Yorker, The Education of Melvyn Bragg (2021)\n\n(The density of England! See this post about ancient folktales from last year.)\nBragg is now 82. He upended arts programming. The South Bank Show, 1978:\n\nThe first thing I’m going to do, we’re going to sit down in front of an artist whose work we have researched thoroughly and talk to that artist about his or her work. That’s going to be the main thing we do. And the second thing we’re going to do is try to break the pyramid idea of the arts in this country, where opera is best, ballet is best, classical music is best, and then down, down, down. Pop music and comedy aren’t even on the pyramid. So we started with Paul McCartney as our first program.\n\nSomething wonderful about this counterintuitive mix of populism, anti-populism (deep interviews), and going to the source instead of pundits with opinions. A lesson there I think.\nBragg now makes In Our Time, which I love and which is the BBC’s biggest podcast. It’s a wildly eclectic discussion show featuring people who know their stuff and there’s a different topic every week.\n\nI had about five or six rules. I’m not having people talk about different subjects; I’m having people talking about one subject the entire time. I’m having academics, but they’re going to be teaching academics, so they’re used to clarifying things-not dumbing them down. I wanted to be eclectic, and I wanted to be collegiate. And I wanted to do things that I knew nothing about, because I could get an education on the sly.\nYou know? I wanted to do astrophysics, which we did. I wanted to do consciousness, neuroscience. I wanted to do stuff in China. I particularly wanted to do stuff about the Middle East, because nobody was ever writing about the great intellectuals from 700 to 1200 in the Middle East-Avicenna, those sort of people. They couldn’t stop us, because we got this golden six-month contract.\n\nIn Our Time started in 1998. Listen to all 955 episodes here. (As previously discussed.)\nANYWAY: Melvyn Bragg’s mention of hedgerows.\nHedges cover the UK. There are urban hedges:\n\nWelcome to Hedgeland. The streets of suburban Britain are edged with merry green. Boxy bushes of privet, beech, holly, yew and other plant species act as boundaries around gardens, demarcating property lines and separating our domestic and public lives. Town planners call them “woody linear features,” but they are so much more than that. They are a charmed circle drawn around family and self. What the white picket fence is to America, the hedge is to Britain, a cozy symbol of conservatism.\n– Smithsonian Magazine, How Hedges Became the Unofficial Emblem of Great Britain (2020)\n\nThey are continuously trimmed and maintained by home-owners: One begins to suspect that hedges are psychological portraits of those who live behind them. A hedge left wild and overgrown suggests a certain lassitude, especially when growing right next to one pruned with geometric rectitude.\nAlso, mainly, there are rural hedges.\nHedges enclose fields and have done in Britain since the Bronze Age, 4,000 years ago. They display ownership. Birds live in them. Worms live under them. They prevent animals from wandering; they demarcate lanes for traffic. There are 95,000 miles of hedge in the UK.\nA hedge is not one thing.\nA good hedgerow is a dense linear thicket of multiple plant species, including: hawthorn, blackthorn, hazel, ash, oak. Urban hedges: box, yew, privet, holly. The number of species can be used to date the hedge:\n\nHooper’s rule (named for Dr. Max Hooper) is based on ecological data obtained from hedges of known age, and suggests that the age of a hedge can be roughly estimated by counting the number of woody species counted in a thirty-yard distance and multiplying by 110 years.\n– Wikipedia, Hedge\n\nThere’s a caveat that hints at how ancient hedges can be: The formula also does not work on hedges more than a thousand years old.\nI visited a Zen temple in Kyoto once upon a time, and saw the dry garden there (and had a deeply spiritual experience; a story for another time), raked and maintained in its same form for hundreds and hundreds of years. Same same. I’ll contemplate that, next time I look at a hedge.\nThere are hedges all over the world, but it’s hard not to see the centrality of the hedge as a peculiarity of the geography and the culture of Britain.\nSIMILARLY: Chalk streams, which I grew up surrounded by, and which formed the archetype in my head for “what a stream is,” before I discovered that chalk streams are a peculiarity of the south of England (2018).\nHedges are simultaneously so mundane as to be invisible…\n…yet also, if you were to look back on them in 10,000 years, investigating hedges archeologically and anthropologically, they would be seen to have enormous ritual significance:\n\nthey are continuously maintained by human hands, over centuries, over generations. Such effort!\nthey’re not singular or grand, like a cathedral or the pyramids or a city, but universal and vernacular.\nthey guide and sculpt and architect, a psychogeographic grid draped over the landscape; separating and joining, acting as both boundaries and roads.\nthey bond together the concrete world of LAND with the virtual world of LAW and property rights and society, connecting planes of existence, a green bridge of living plant matter. A kind of magic.\n\nHedges wouldn’t grow naturally. They exist because we maintain them, and we maintain them because they maintain us.\nThe society of hedges is in symbiosis not with individual humans but with human society.\nAnd, as Melvyn Bragg says, the ancient hedges sing. You can hear when you walk past in the spring, quite often, the singers themselves invisible. Birdlife is homed there, given nooks and niches to hide and nest, birdlife in all its great variety preserved and protected in the long, low, dense wood and foliage.\n(A blog is a little like a hedgerow, perhaps. A continuously maintained tangled thicket, linear through time, simultaneously selecting yet connecting; a form that preserves variety; humble and multiple; enduring but fragile; alive.)\nUpdate 11 July: I’ve been thinking about hedges and about magic since writing this post. If you were to observe the function of hedges without also the huge construct of the law, property rights and conventions, etc, what you would see is humans creating a long linear plant around an area of land, and tending it - spending effort on maintaining it - many times a year for decades, and as a result some “un-permitted” class of people are thrown out by force if they enter the enclosed land, and after a socially agreed ritual these people may be locked up or otherwise punished, and society as a whole agrees with this – well, it looks like magic. So perhaps we can say that magic (or at least, one type of historical magic) is what it looks like when you see someone interacting with a vast social construct where that construct is now gone. Like a social-scale equivalent of watching someone’s bizarre movements and hand actions when they’re in VR but you can’t see through the glasses.\n",
    link: "/home/2022/07/06/hedges",
  },
  {
    title: "I imagine cave paintings as ancient virtual reality",
    date: "11.51, Monday 11 Jul 2022",
    content:
      "To get into the caves of Niaux, in the south of France, you drive to the foothills of the Pyrenees, buy a ticket - it’s open to tourists - and then wait for your turn to go through the metal doors which function as an airlock. I visited a few years ago.\nWe walked through a series of dark tunnels and caverns for about 20 minutes, a kilometre. The mountain hangs overhead and so I think about the hundreds of metres of solid rock, upwards, before reaching even the ground again. The centre of the mountain is a realm impenetrable and unimaginable. Take the remotest, loneliest place on the surface of the Earth: I could at least in theory reach that spot. No such access to the world of rock.\nAt the end of the tunnels there is cave art 13,000 years old.\nAlong the way there’s a cartoon sketch of a deer. Here it is. It’s so contemporary, so alive. The deer is bright-eyes and smiling. I felt so connected over so many thousands of years.\nThe final cave is decorated with bison, in their twos and threes, these small groups covering the rock face all around.\nIt’s beautiful.\nAlthough the bison are sketched in the sparest of lines, they’re not caricatures, they’re accurately draw and brought to life by the shadows cast by the light and the uneven surface, and the rock which is also unevenly coloured, red and brown and black.\nWith a fire in the middle, the shadows of people would have mixed with the drawings and the shadowy landscape.\nAt the time this felt to me like a kind of reverse hologram.\nThe 2D drawing would imply a 3D presence in the space - invisible yet there none-the-less, the bison is right next to you, it has to be if, like my shadow it is cast on the wall.\nSuddenly in my imagination the cave felt crowded, real people and implied bison, all together, moving in and out of the shadows, honestly all of us at an equivalent level of visibility, who is to say what is real, the bison on the distant plane visible too - drawings on a cave or a distant herd at dusk, it’s all the same.\nVirtual reality.\nRock is a medium.\nI’ve been reading recently about the work of archeologist David Lewis-Williams:\n\nalthough in Western thought rock is the most solid and stable of substances, for the Bushmen [in southern Africa] it is a veil on to which images of the spirit world are projected. Paintings are tracings of these projections, which makes the eland on the cave wall a rendering of an even more real eland in the spirit world on the other side of the rock face.\n– Chris Gosden, The History of Magic\n\nSome can cross between worlds: \n\nThe task of the shaman is to pierce the veil, contacting the spirits and bringing back to the everyday human world vital information.\n\nThe shaman:\nBleeding from the nose and displaying particular postures, such as a throwing back of the arms, indicate to others in the cave that the shaman is moving between worlds.\nBased on cave art in France that resemble shaman images by the Bushmen, Lewis-Williams puts forward that the underlying belief systems are the same.\n\nLewis-Williams also argues that the rock face for French Palacolithic people was seen as a membrane, with the animals existing, perhaps in more perfect forms, in a world on the other side of the rock. Evidence for this comes in instances when natural cracks in the rock are used to help to provide the shape of an animal; also, as we have seen, the interest in pushing bone and other materials into rock cracks may be an attempt to commune with the spirit world on the far side.\n\nStrong caveat: For many, Lewis-Williams takes a number of steps too far.\nSEE ALSO: Computer screens??\nWe’ve never quite got a handle on what a computer is…\n\na “soft” interface or infinitely permeable appliance or tool\na prosthetic extension to the body or mind\na container, something with a world “inside” - anyone else play Little Computer People on the Commodore 64?\nGibson’s cyberspace, a world which can be visited by us, whether that’s the metaverse or virtual reality, a video game, a simulation, or something lo-fi like the blogosphere\na tool to let us project across real space; a thing that enables telepresence\na non-human agent in itself\na medium.\n\nI won’t get into definitions. Except to say:\nThe image of shamans twisted at the rocky cave-wall interface, travelling in the realm beyond the membrane, reminds me of nothing so much as, well, me, hunched over my smartphone, unnaturally contorted to jab with my thumbs, an overwhelming feeling of being elsewhere, the screen a veil and on the other side a world that I can visit but can never stay in, my eyes blind to the physical room and others here.\nWhat I DON’T mean to say is that that Zoom is a form of astral projection.\nNor do I wish to suggest that there was a now-lost industrial society in prehistory, the shamanic elite making use of full-bodied user interfaces to search the Upper Palaeolithic equivalent of Wikipedia, data carried not on the fibre optics of today’s internet but via telluric currents, faint and discernible only deep underground far away from the Sun, recording and bringing back vital knowledge about bison movements and weather and so on - and gossiping with other shamans thousands of miles away on Rockfacebook or whatever.\n(Though how else would you describe computers to a society ten thousand years distant?)\nINSTEAD my point (I think) is that it’s not so absurd to think about cave art as a kind of virtual reality. Just as we understand VR today: it’s real and breathtaking often too, but also we know it’s not really real, but also there is the willing suspension of disbelief. Us humans are sophisticated, happily self-contradictory participants and always have been.\n",
    link: "/home/2022/07/11/shamans",
  },
  {
    title:
      "When the cosplaying dolphins met the cosplaying French philosophers",
    date: "20.16, Tuesday 12 Jul 2022",
    content:
      "My favourite kind of folktales are the kind that are so microscopic and so esoteric that they take approx a thousand words to set up.\nIn that spirit, some necessary background:\nMastodon is an online social thing which is a little bit like Twitter, in that you post little status updates in the form of words and pictures, and you follow loads of friends who are doing the same.\nUNLIKE Twitter, it’s not owned and run by a single company. Mastodon is divided up into tons of separate communities – and I mean actually divided as opposed to “separate but all ultimately in the same place” like subreddits on reddit. From the Mastodon website:\n\nMastodon isn’t a single website like Twitter or Facebook, it’s a network of thousands of servers operated by different organizations and individuals that provide a seamless social media experience.\n\n(4.4 million people use Mastodon, which isn’t huge compared to Twitter’s 229 million daily actives, but it ain’t peanuts neither. You can join up at the official website above, and if you do then please do follow me. I’m @genmon@mastodon.social. It’s where we’ll go when Twitter finally implodes.)\nThe Mastodon servers are networked together into the “fediverse” so at first sight the experience is like Twitter in that you can follow people pretty much anyway and it feels global… but look a bit closer and there’s way more variety.\nBecause: individual Mastodon servers have autonomy. They can have their own policies; they can choose to enforce certain behaviours; they have their own “global” timelines, which means they take on their own character. If they disagree with another server, they can simply stop relaying messages from it – imagine you and your friends on Twitter able to just cutting off the angry politics people.\n(I’ve been following virtual private neighbourhoods as a trend for a while. This is a post that continues that thread.)\nThe autonomy inherent in Mastodon means nooks, niches, and corners in which high weirdness may flourish.\nAND SO…\nBack in 2017, internet artist Darius Kazemi (a.k.a. Tiny Subversions) founded a new Mastodon instance: dolphin.town\nThe rule of Dolphin Town is that users can only post the letter ‘e’.\nSome indicative posts:\n\nEeee ee eeee eee e e e eeee?\nE eeeee eee!\n– @eeeeee_eeeee@dolphin.town, Apr 14, 2017, 17:30\n\nAnd,\n\n[EEEEEE] Eee e eeeee EEeeEee, Eee ee. E, e, Eee!\n– @e@dolphin.town, Apr 28, 2022, 15:00\n\nAnd also,\n\neeeeeeeeeeeeeeee!!!!!\n– @ee_eee_ee_eee_ee@dolphin.town, Apr 28, 2022, 22:07\n\nIt got a mention in Vice magazine.\nSooooo you can join Dolphin Town here and if this is the community that gets you into Mastodon for the first time then I love you already.\nASIDE:\nI am well-disposed to dolphins because of that slightly wild period in the 1960s when everyone was convinced that we would be speaking with dolphins in the very near future, and we would be sharing the planet with them as a second human-style sentient species. To this day dolphins look after nuclear sites for various navies. Much effort went into attempting to open lines of cetacean communication, including feeding them LSD, because?, I don’t know because.\nOne wonderful idea was that of the Dolphin Embassy, proposed by the architect collective Ant Form in 1974 – in an article in Esquire magazine it turns out.\nHere’s a history of the idea.\nHere’s a collection of architectural sketches. One blueprint shows the deck of a raft on which humans have their media pod, galley, command station and so on, and in the centre is a circular pool, with steps going down to it, and the pool is open to the depths, meaning that dolphins can swim up and appear inside it. So while the human raft sits on and is contained by the ocean, the pool is contained by the raft, and there’s an elegant symmetry to that, a place for a meeting of peers.\nALSO ON MASTODON YOU MIGHT RUN ACROSS THIS:\nSo another thing on Mastodon is Oulipo.social. You can sign up.\nOulipo (Wikipedia) is a community and writing constraint that was born out of ‘pataphysics in 1960. Its singular law: that which you can say on Dolphin Town, you can’t say in Oulipo.\n(A Void is a full book in Oulipo – pretty amazing.)\nOuilipo’s Mastodon community has a matching constraint: look at many posts in this story.\n(As it turns out, Darius did Dolphin Town shortly following Oulipo.social, not first. But this arrow of causality is not my point.)\n(Btw Oulipo is hard.)\nANYWAY this is when I finally get to the microfolktale!\nIn 2018, taking advantage of the federated messaging afforded by the Mastodon system, a user from Oulipo.social ventured forth and made overtures to Dolphin Town:\n\n@e salutations! i am a diplomat from oulipo dot social on a diplomatic mission to curtail any bad blood and start working towards a harmonious tomorrow\n– @kit@oulipo.social, December 8, 2018, 2:03 PM\n\n@e replied: @kit EEEEEEE\nAlas!\nAnd the visit quickly came to a bitter end:\n\n@e uhm wowww, okay. is that how you talk to all visiting diplomats? with such profanity? i found my way to this town of dolphins in good faith, ignoring many a warning, hoping to build a concord and this is how you act? in all my days as a spy diplomat, this is a first.\n[angrily] good day to you! good day!\n\n(The dolphin response: EEE eee eeeee–eeee-ee-e-eee-e, e, e.)\nThat it, that’s the whole story.\nI love this tiny interaction that occurred 3.5 years ago SO MUCH.\nIn microcosm it is exactly how difference should encounter difference on the internet.\nI don’t mean playfully, really, I mean I’m taking this at face value here. We’re not kidding around, there is no larping online, on the internet no-one knows you’re a dog, I mean, let’s make our assessment of this entirely in-world: it’s an interaction where no common ground was found, fundamentally, followed by a backing-away.\nWhich is… what should happen? Instead of it contributing to the all-consuming conflagration which is the Culture War?\nMy take is that detente is possible only because of the self-determination of Mastodon instances. When it’s always on the table to cut ties, you don’t yell in anyone’s face – because they’ll just leave. There’s no point. Counter-intuitively the ability to walk away leads to a greater effort to find ways to stay together.\nA LESSON from the cosplaying dolphins and French philosophers. Art eh. Gets you every time.\nAlso: embassies! Diplomatic missions! Just… visiting!\nI would love to see this pattern all over social software.\nI want the ability to one Discord server to dispatch an ambassador to a second, with the intention of establishing a shared channel.\nI want Disney+ to open an embassy in Netflix and throw parties (uh, exclusive content shared for only a month, let’s say) and vice versa.\nThere should be a formal program like SETI that attempts to make first contact with the intelligence inside GPT-3 and DALL-E and so on. The UN should be treating every new AI for the next decade as a potential locked-in sentience until proved otherwise.\nAnd, reversing this, Twitter and Facebook and so on should be broken up into federated self-governing communities, each with the ability to walk away. It’s not working, this experiment of putting everyone in the same melting pot without even the hope of getting some distance. Good fences make good neighbours etc.\neeee eeeeee EEEE eeee EEEEEeeeee eee.\n",
    link: "/home/2022/07/12/folktale",
  },
  {
    title: "Training my sense of CO2 ppm",
    date: "11.48, Thursday 14 Jul 2022",
    content:
      "I picked up a new home CO2 monitor yesterday. Here’s a photo. I went with the Aranet4 (HOME edition) because\n\nit’s small and portable with a multi-year battery life\nit displays the current CO2 ppm on an e-ink screen and I am a sucker for e-ink – practical and handsome\nit logs data, taking a reading every 5 minutes and keeping a 7 day history, accessible using the app (Bluetooth not wi-fi, and I appreciate the lack of dependency on cloud services).\n\nI bought mine on Amazon for the same price as buying direct.\nI want to build an intuition for how varying CO2 levels make me feel.\nThis second, near my desk, CO2 is 463 ppm (ppm = parts per million).\nAtmospheric is approx 420 ppm so it’s higher indoors – and higher still when I’ve been sitting in the same room all day.\nCO2 levels are pretty dynamic, I’m told. An occupied, closed room will get to 1,000 ppm. A meeting room without fresh air, 1,500 ppm. You can hit over 2,000 ppm in a contained space like a train.\nHigh CO2 levels are an indicator of poor ventilation, which isn’t great for Covid transmission.\nBut also not good for cognition.\n\nat 1400 ppm, CO2 concentrations may cut our basic decision-making ability by 25 percent, and complex strategic thinking by around 50 percent\n– ScienceDaily, Rising carbon dioxide causes more than a climate crisis – it may directly harm our ability to think (2020)\n\nEven before that, you start to get drowsy around 1,000 ppm. How much brain fog is not to do with long Covid but simply because I’m no longer sitting in a large, well-ventilated office? I’d like to know.\n(Hey so there’s a chance that CO2 levels rise to the point that we all become too dumb to figure out the climate crisis. Ruh roh /insert Scooby Doo gif.)\nYou can train your own sense of the current ppm by keeping an eye on the sensor read-out and introspecting your personal energy levels. Here’s what my friend Ben Pawle from Nord Projects told me:\n\nWe’ve got one in the studio. Actually been surprisingly helpful. When you start getting brain fog and feeling sluggish then you glance and see the co2 is 800 you know to open more windows. Then you feel great! We’ve actually got weirdly good at describing how we feel in terms of energy levels by co2 level\n\nWhich is not the first time I’ve heard that!\nI’m looking forward to the day when I can walk into a room and say, huh, feels like 800 in here, and decide to sit somewhere else.\nHere’s the referenced paper from the article above.\nKarnauskas, K. B., Miller, S. L., & Schapiro, A. C. (2020). Fossil Fuel Combustion Is Driving Indoor CO2 Toward Levels Harmful to Human Cognition. GeoHealth, 4(5).\nI want to train my mental model for how CO2 levels change over time.\nI have questions like:\n\nWhat happens to CO2 over 4 hours while I’m at my desk?\nDoes it make a difference that my desk faces a corner – does CO2 collect there as I breathe? How long does it take to equalise over the room?\nWith the door open? With a window open just a crack?\nHow long does it take for CO2 to reset to ambient? 5 minutes? An hour? Is a 30 minute break for lunch enough?\n\nTo do this I need graphs.\nNow I was initially concerned that the Aranet4 sends its logged data only to its own app. Looking at a 7 day graph in an app is fine, but I’d prefer to do my own presentation and analysis. I would like to\n\ncollect data over several months and spot correlations. Do I tend to leave the windows closed when it’s colder, for example (of course I do), and is this a problem?\nsee if mornings are better than afternoons?\nget a good sense of what “normal” CO2 variations are over the day and seasonally, indoors/outdoors/etc, and when I should act (the sensor is portable, so I’ll start carrying it around to different venues once I develop a foundational understanding).\n\nAlso:\nAlerts! If CO2 hits 800 ppm (for example) I would like to ping my smart plug to turn on the coloured Christmas lights that hang on the shelves behind me. That’s not enough to interrupt me if I’m concentrating, but it gives me peripheral vision that I should increase ventilation and I’ll notice it when my head comes out of flow. I’m aaaaall about that ambient awareness.\nSo I don’t want my data trapped in an app. I want the sensor to have an hardware API. I wrote about the idea of hardware APIs here (2021):\n\nDevices should have a standard hardware API – a couple of pins that publish events (like: radio re-tuned, or switch pressed, or doorbell motion sensor activated) and accept commands (like: re-tune to X, or remote activate switch, or record and send video)\n\n(It doesn’t need to be copper pins. Wireless is fine too, so long as it’s open.)\n(It’s important that this runs locally, without hitting the cloud, because the privacy concerns of this level of access to my home are considerable.)\nBasically: I want to work with my home gadgets and appliances as easily as I can set up rules and filters in Gmail.\nAND SO I am tentatively happy that there is a Python library for the Aranet4 sensor (pyaranet4)! Good news.\nThis means that, in theory, I should be able to connect from my Mac, or the always-on Raspberry Pi sitting on the bookshelves, and pull data from the sensor on a regular schedule. And given that I should be able to do all of the above.\nA project!\nI was born at 335 ppm. Atmospheric CO2 is 25% higher today.\n(See co2levels.org for a giant historic graph.)\nOk so there’s noticeable cognitive impairment on complex decision making when CO2 levels are much higher – but is even this 25% atmospheric uplift dinging my IQ?\nLike: lead in fuel, as previously discussed: Leaded fuel reduced the IQ of everyone born before 1990 by ~4.25%.\nWhich is wild, right? And may explain some elements of boomer politics…\nBut, being more specific, what lead is dinging isn’t just IQ – I seem to remember that lead affects impulse control? And CO2 affects “complex strategic thinking” so that’s an attentional thing, maybe?\nI am suuuuuuper out on a limb here, but: smartphones? What if this century’s rise of short-attention-span casual games, attentional disorders, etc, is not to do with too much screen-time at all, but is a symptom of growing up under increased atmospheric CO2?\nAnd so our recently-slightly-diminished inability to hold a coherent thought for a long span of time is what attention-maximiser apps like infinite-scrollers (Twitter) and ad-engagement-optimisers (Facebook) and swipe-skinner-boxes (TikTok, Tinder) are, deep down, all exploiting?\n",
    link: "/home/2022/07/14/co2",
  },
  {
    title: "The sinister blue sky",
    date: "19.41, Monday 18 Jul 2022",
    content:
      "I was at Tate Modern (London’s modern art museum) over the weekend and saw IKB 79 – my first time encountering International Klein Blue in the flesh.\nDescription in the catalogue: IKB 79 was one of nearly two hundred blue monochrome paintings Yves Klein made during his short life.\n\nThe letters IKB stand for International Klein Blue, a distinctive ultramarine which Klein registered as a trademark colour in 1957. He considered that this colour had a quality close to pure space and he associated it with immaterial values beyond what can be seen or touched.\n– Tate, IKB 79 (1959), Yves Klein\n\n(There are other colours owned by artists including Vantablack, the blackest black, under exclusive license to Anish Kapoor; and PINK, the pinkest pink, by Stuart Semple which is available to any artist for $3.99 except Anish Kapoor: Online buyers are even required to sign a sworn statement that they are not Anish Kapoor, are not related to him, and that the pigment will not end up in his hands.)\nWhat I hadn’t expected about International Klein Blue:\nIKB 79 is so large, and the blue is so deep. As I looked it filled my eyes and somehow, an illusion I guess, something happening in the retina, it saturated me, I stopped seeing it.\nInstead after 30 seconds or so: I began to see a deep black together with IKB, both at once, behind it somehow. Beyond the blue, the void.\nYves Klein’s origin story (BBC):\n\nOne summer’s day in 1947, three young men were sitting on a beach in Nice in the south of France.\n\nKlein, the third man:\n\nThe third man opted for the mineral realm, before lying back and staring up at the ultramarine infinity of the heavens. Then, with the contentment of someone who had suddenly decided what course his life should take, he turned to his friends and announced, “The blue sky is my first artwork.”\n\nAnd, seeing International Klein Blue, I understand: it is the sky. Not so much in colour - though of course yes that too - but in a truer sense. Behind the sky there is the infinite depth, the darkness, the black of space.\nEven the azure of the south of France, after the gazing up with the innocence of youth, after that, the reality of – well, everything.\nArt!\nANYWAY: it’s hot in London.\nThe temperature today and tomorrow is forecast to hit 40C.\nHere’s a list of the hottest day each year from 1900 in the UK. It’s never been 40C. It’s been 37C twice and 38C twice, that’s all.\nWalking to the train station this morning, it was unnaturally quiet – people have been advised to stay home.\nThe birds sang. The trees are green and in full leaf. It’s summer. The heat.\nThe blue sky – threatens.\nHot days, blue skies, have changed since I was a kid, slowly. A mesofact.\nIt used to be that the blue sky was about bbq and the beach and hanging out in the forest with friends. Gorgeous days.\nNow it’s that, but also the blue sky is sinister somehow.\nDon’t you get that, just a little?\nIt’s a quiet reminder of the climate crisis. It’s not going to get cooler from here on out. This is a warning from the future: as I get older this will happen more regularly at first; then this will happen every summer. Wild burns and sea levels rising; fire and flood. The ghost of summers yet to come. A silent glance cloaked innocuously in a calm July sky; it’s blue right now with wisps of cloud. It’s always going to be there now, that feeling. I mean, I still enjoy it, it’s still a beautiful day, but.\nAn omen overhead.\nIt’s taken 30 years not 30 seconds but, same same, the black beyond the blue.\n",
    link: "/home/2022/07/18/ikb",
  },
  {
    title: "Filtered for supersenses",
    date: "20.41, Wednesday 27 Jul 2022",
    content:
      "1.\nAcoustic Kitty, a project by the CIA from the 1960s.\nPremise: cats are cute and pretty much allowed to wander anywhere. So, give one a wireless mic, let it loose near the Russian embassy, and…\nIt cost $15m.\n\nThey slit the cat open, put batteries in him, wired him up. The tail was used as an antenna. They made a monstrosity. They tested him and tested him. They found he would walk off the job when he got hungry, so they put another wire in to override that.\n\nHowever:\n\nThey took it out to a park and pointed it at a park bench and said, ‘Listen to those two guys…’ They put him out of the van, and a taxi comes and runs him over.\n\nAnd that was that. Poor puss.\nUnredacted has the original memo and more: Document Friday: Acoustic Kitty (2010).\n2.\n57 supersenses from Scientology:\n\nIn the late 70s, L. Ron Hubbard wrote down a list of 57 superhuman senses he claimed were possessed by thetans which people who were “clear” (free of unwanted engrams, or harmful memories) could learn how to utilize. The full list is below…\n– everything2, Perceptics\n\nSight, Taste, Sound, etc.\nGravity and Solidity are in the list. I get that; maps well to our built-in awareness of surface affordances.\nPain, Rhythm, Heartbeat.\nNow a heartbeat sense is a good one! From a study in 2016:\n\nFinancial traders on a London trading floor are better able to estimate their own heartbeat than the general population\nA trader’s ability to tell their own heartbeat is a predictor of their relative profitability.\n\nKnow thyself, eh. Here’s the paper: Interoceptive Ability Predicts Survival on a London Trading Floor.\nSome others:\n\nAwareness of importance (salience, ok I buy that)\nCompass direction (we have a north sense? I’ll buy that too)\nPerception of conclusions (very Terence McKenna/Omega Point)\nPerception of computation (not sure what this means)\n\nIt’s interesting what happens once you frame something as a sense.\nYou start thinking about what’s immediately available vs what has to be figured out.\nAnd there is a ton that our body/brain makes immediately available. Worth training I think.\nBONUS LINK: I gave a talk back in 2006 imaging a new kind of web browser, inventing features by riffing off various human senses. L. Ron Hubbard’s list gets a mention about halfway through. Still a fun read. Here’s the whole thing: Making Senses.\n3.\nReturning to a post from a while back: Do humans have a north sense? (2020)\nBecause it seems like we do. One possibility, that I mentioned then: Humans are sensitive to polarised light – there’s apparently something called Haidinger’s brush which is a yellowish bow-tie shape, visible against the blue sky. Seems mythical.\nWELL.\n\nTo see Haidinger’s brushes for yourself, look at a blank white portion of an LCD screen on a computer, tablet or phone. Tilt your head from side to side and faint yellow and blue bow-ties, slightly larger than your thumb, should become visible. With practice, you can then see them in the blue parts of the sky at 90 degrees from the sun, particularly at sunrise and sunset.\n– The Conversation, Polarised light and the super sense you didn’t know you had (2015)\n\nI can see them!\nI mean it took 10 minutes sitting in a cafe staring at my laptop screen and repeatedly cocking my head back and forth, like an absolute goon, but I can see Haidinger’s brushes!\nThe yellow bow-tie sits at a 45 degree angle, and if I tilt my head the other way, it flips to sit at 45 degrees the other way. A blueish bow-tie sits across it at right angles.\nSpotting the brushes is the weirdest feeling. There are all kinds of colour variations in the world, the whole time. Surface imperfections, variations of light and shadow, floaters in my eye, whatever, so there is a whole layer of visual perception that I unconsciously dismiss as noise. So I have to re-see that noise, somehow, and dig through it, and realise that - no - this isn’t just unimportant visual static, it’s an artefact of polarised light! Even then I keep dismissing it, by habit. But, with some practice…\nWHAT ELSE IS HIDDEN IN THE INFORMATION WE THROW AWAY.\nFnord.\nThat article goes on to say how Haidinger’s brushes appear in the sky: the long axis of the yellow bow-tie will point approximately towards the sun.\n4.\nApparently a barn owl can hear a mouse’s heartbeat from 20 feet.\nWas told in a show about owls. Can’t find a reference. Seems plausible though. Also:\n\nThe facial disk of an owl, made up of stiff feathers, collects sound and directs the sound waves to the owl’s offset ears. Owls’ ears are offset relative to each other. The offset helps the owl determine direction and distance using stereographic acoustic location.\n\nThat would be a useful hat to market in these days of social distancing.\nJust a wearable acoustic mirror, like a bowl around my face, in a fashionable cut ofc, that would let me comfortably hear what you’re saying even when we’re a couple of feet further apart than normal. A portable whispering gallery.\n",
    link: "/home/2022/07/27/filtered",
  },
  {
    title: "The Prompt Whisperer",
    date: "20.22, Thursday 4 Aug 2022",
    content:
      "Mia flicked the rim of the cat food tin with her finger and the 3D model span on both their screens, the double cat face illustration with tortoiseshell hair that whirlpooled into three, no, four eyes, four and a half, blinking alternately with the UPC on the rear of the spinning can, every rotation a flashlight right to the back of the visual cortex, a half second involuntary scramble parsing the dazzle of fur and ears and whiskers, and of course those eyes before, brief blessed release, the model turned again to the barcode.\n“Anybody who’s even thinking of switching brands picks it off the shelf,” said Mia. “We’re bleeding customers. And we’ll lose the client too unless we figure out a way to counter it.”\n“It’s certainly hypnotic,” said Charlie. Mia watched him tear his eyes away from the animation to hunt around on his desktop.\n“I can replicate the basic look,” he said and he dragged a sequence of other stills into their call, a dozen, “but never the compulsion. If I could get that then we would at least be able to work our way to something similar, to make it a fair fight for eyeballs.”\nIt was true. Superficially the AI-generated swirling feline images were the same, but there was none of that arresting affect.\nMia tabbed over to chat and typed into the #prompt-engineers channel.\n> hey, anyone around to take a look at a weird packaging reconstruction problem?\n> free, coming\nsaid Selby.\n“I’m on costuming for the new IKEA store,” said Selby. “There’s this whole outdoor range launching. The models are the same so we don’t need more characters but they all need new clothes to pose in the product shots.”\nHe panned around a spider’s web of lines, words and photos covering his entire screen. At the centre, a dense paragraph with rays coming out of it connected to colour-coded phrases and thumbnails of caps and clothes and accessories. He traced a path out from the centre through a dozen sunshield t-shirts, each silvered shirt a mutation of the one before.\nA screen for getting work done.\n“You don’t get to see the prompt with my mood board app,” said Charlie.\nWriting the paragraph in the middle, the prompt, was what Selby was good at. The prompt tells the AI what image to generate. It’s an inexact science.\nCharlie jumped them over to the mood board. It was a collage of photos of cats, close-ups of eyes, and Picasso’s Portrait of Dora Maar.\n“Because of the two perspectives of the same face,” said Charlie.\nThen some less literal images arranged round the edges: slit-scan photographs; faces in funhouse mirrors; views through old, uneven glass; intricate crayons by people on acid trips; maps of global wind patterns; a grab-bag of AI stimulus copy-and-pasted from the internet.\n“I’ll go knead my dough while you run your mood board,” said Selby. “I’d like to see what it comes up with.”\n“I should get back into bread again,” said Mia.\n“Linseed, sunflower, hemp, poppy,” called Selby over his shoulder, standing at the kitchen counter, folding the wet dough in on itself. The camera had switched from his desk to the wide-angle unit across the room.\n“Sesame, definitely,” he said. “I had a loaf delivered from a new bakery last week and the flavour was so distinct. I’m reverse engineering the seeds.”\n“I’ve got the first image. Let me make a few variations so you can see,” said Charlie, tapping the run button again.\n“Fennel or anise,” said Selby. “Anise, I’m sure.”\nHe washed his hands, walked back to his laptop, and leaning over, still standing, scrolled through the neat grid of almost identical generated images, each a soup of various combinations of cat facial features swimming in fur.\nMia and Charlie saw Selby lift both hands and type a four-fingered chord on his keyboard, then a rattle of a few more keys, then a solitary enter. Selby sat as a long paragraph of small text replaced the latest cat-soup image.\n“Oh you can see the actual prompt like that?” said Charlie, surprised. It was in English but barely. Reading it was like a transcription to a room full of people all talking about the same thing but not listening to one another, snatches of words, a cut-up: basket of kittens/ two cat faces/ fur in the style of a whirlpool/ f/22 35mm/ and so on it went.\n“Let me see the original?”\nCharlie dragged the graphic of the competitor cat food tin back into the window and it outshone the picture generated by the mood board AI with blinding ferocity.\nThey gazed.\n“The video’s frozen,” said Mia.\nSelby’s face was large on Mia’s and Charlie’s screens, filling the webcam view as he had lent in for a closer look. Light brown hair cut short, roughly; eyes and mouth too big for his face, slim without being gaunt, quick to smile, unshaven – an even gaze, quizzical, caught between a question and a laugh.\n10 seconds.\n“I’m going to restart the–” said Mia, and then a flurry of keys from across the call.\n“Let’s give that a minute,” said Selby, the connection stutter unacknowledged.\nA progress bar began its crawl.\n“You were on the right track with Picasso,” he said, “but cubism as a visual style is a gravity the AI can’t resist. You’re going to get the look but what we want is the cognitive impact of cubism. That’s what makes the cat food grab you so much. Your face-detecting neurons are hyperactivated. You’re seeing a face but you’re also seeing a face! It overheats your perception, doubleplus nature. So we need a phrase in the prompt that directs the AI in latent space, but concisely. There’s a professor who has linked cubism and cognition in this way. We can use his name as a token.”\nSelby had barely altered the original prompt on screen, adding to the end just one word:\n> ramachandran\n“The neuroscientist?” said Mia. Then the progress bar completed, and the AI-generated image from Selby’s prompt blinked up, next to the original.\nTwo cat food tins rotated lazily together and identically, the original and its twin plucked, impossibly plucked from the infinity of latent space. Charlie and Mia stared, caught in the headlights of a miracle.\n“How–” said Charlie.\n“I need to tell the boss,” said Mia.\nSelby grinned.\nFrom Mia to Lawson:\n> uncanny accuracy from one of our prompt engineers. you need to see this\n> let’s get on a call\nreplied Lawson.\n“If you think of what a square of pixels can be,” said Mia, “it’s every Picasso sketch. It’s every kid’s drawing. It’s the Coca Cola logo. It’s every stock photograph ever.\n“It’s a photograph of the night sky – whatever you like, any constellation there is and any constellation there isn’t. It’s a diagram of a new computer chip that goes ten times faster. It’s a handwritten shopping list, and it’s a concise proof to Fermat’s Last Theorem. It’s an illustration for cat food packaging that somehow you can’t take your eyes off.\n“That’s latent space. The space of all possible images. It’s endless.”\nLawson had founded and continued to run the agency, although these days spent most of his time talking to clients. Mia had seen his work from the early days – sharp, deft, and even better with words than visuals. A storyteller of other people’s stories. Only two or three years ago AI assistants for creative work were a novelty; he’d stopped being hands-on before they graduated into essential tools.\nLawson and Selby were side by side on Mia’s screen. Lawson was standing, AirPods in. It was a large room. All cream, a low cream leather sofa against the back wall, another, identical, to its right at 90 degrees, the two neatly framing a square coffee table. The camera had panned over from the dark wood table when he crossed the room earlier, and now he stood in-front of the large print by the sofas and listened, intent.\nSelby sat wearing large headphones, kitchen in the background, arms by his sides. Apprehensive, guessed Mia. Selby was unlikely to have been in a room with Lawson before, virtual or otherwise.\n“A prompt is a pirate’s map,” said Mia, “Directions to hidden treasure in latent space.\n“A prompt is just words, that’s all. A paragraph. Maybe two. The AI that understands the words has been trained on every sentence ever written. You can’t ask it questions but it gets any and every reference you might make.\n“How do you describe your way to a picture that you have in mind? It’s a process of trial and error. That’s why we have prompt engineers. People who can deconstruct what a client wants to see and write in the form of a prompt, and develop it from there. They’re explorers. They write tools to automate exploring. It’s tough going, hacking your way through the jungle of possibilities.\n“How do you look at a picture and figure out what prompt got you there?\n“You can’t. It would be like me showing you a photo of a grain of sand and you telling me on what beach, at what spot, at what precise point… at best you could make an educated guess of a part of the world. But putting your finger on the exact grain? No.\n“Yet Selby can.”\n“There’s a Bridget Riley behind me, a study for High Sky,” said Lawson, looking back at a colourful, grid-like geometry framed on the wall. “Can you write a prompt that will generate something like that?”\n“Yes,” said Selby, “but I wouldn’t need to.”\n“Training. Don’t forget the AI has already seen every image on the internet,” said Mia.\nLawson walked to the table and opened a sketchbook; the camera followed him.\n“Okay, something new then.”\nHe drew a large loop in a single bold stroke, a circle coming to a point at the top right. Inside, next to one another, two smaller circles.\n“Craters,” he said, “16 Psyche. A logo for a startup I know. Work in progress.”\nHe held the paper to the camera. Mia could see gravitas and upward force even in the strokes of the hand-drawn sketch. A glimpse of the original Lawson, she thought, a talent.\nSelby examined his keyboard and even over video Mia could see his embarrassment.\n“I can reverse engineer prompts,” he said, “that’s what Mia saw. Give me something that was generated and I can tell you the prompt that was used to get there. But not anything that wasn’t made by an AI. What’s it good for? It’s a party trick.”\nLawson stood and looked steadily through the screen.\n“Or rather,” – he was grasping for words now – “I can engineer a prompt for one of your originals. That’s what I do. It won’t be exact but we can work with it. Show me the logo again and let me see what I can put–“\nHe trailed off and started typing something. Opening applications, setting parameters. Fake busy.\n“Lawson…” said Mia.\nLawson shifted his weight onto his other foot and put two fingers on his chin, over his mouth. He continued looking forward, in silence. \nThen he turned and walked past the table. The camera panned as far as it could until he walked off screen. Mia waited. Selby continued with his tapping.\nA lilac astronaut on a lilac planet; a low-shot fisheye photo, boot striding forward over the sand dune, a woman’s face through a transparent visor staring with strength down the barrel of the lens. Hips cocked. “COSMOPOLITAN” stamped in blue across the top, and the familiar telltale in the bottom right, a visual tag marking this image as being AI-generated.\n“This magazine cover was never published, or rather,” said Lawson, from behind the framed print, lifted from the wall, “not this variation. It’s from my own collection.”\nSelby looked up and leaned into the camera. He held his stare without blinking. One breath. Another. Two more, slowly. Then the sound of him typing for a few seconds.\n“It’ll take a minute to come back,” he said.\nMia exhaled.\n“It’ll make our projects much quicker,” she said. “And cheaper. It’s something our clients ask for. We can build a whole proposition around this.”\n“No,” said Lawson.\n“You said something about computer chips,” he said.\n“I haven’t been outside for two years,” said Selby.\n“Lawson says that everything is designed by AIs now,” said Mia, “like how chips work and how phones look. It’s why chips are so fast, he says.”\nThe two of them on their screens, talking together the next day, no-one else.\n“I stopped and didn’t start again. It hasn’t come up. So now I stay in,” said Selby, “and I really think we can carry on over video.”\nHe paused kneading and stood at the kitchen counter, leaning on his hands. The camera hadn’t switched over so Mia couldn’t see his face; she saw him side-on, silhouetted. But she could see him breathing and the effort to control those breaths.\n“But none of these breakthroughs are shared, he says. When they come up with a new chip then it’s ten times faster but the prompt is secret.\n“What you can do is not just a trick and Lawson asked me to ask you to visit so he can see it in person,” said Mia. “He says that progress should be for all of us.”\n“Progress should be for all of us,” repeated Selby.\n“I didn’t know that you’re indoors-only,” said Mia.\n“If we unlock the prompts then we unlock drugs, medicine, better batteries,” said Selby. “It means everyone will have access. Cheap access.”\n“I understand it would be difficult for you. You should stay at home. I’m sure we make accommodations.”\n“No more prompt-squatting billionaires,” said Selby, dusting his hands on his apron and turning towards Mia.\n“Don’t travel. We’ll find another way.”\nSelby: “I’ll come.”\nSat low on the cream sofa, Mia looked around Lawson’s Kensington apartment. It was strange, looking back at the never-seen camera, seeing the familiar room flipped into its mirror image: the dark table to her right and not on the left. Beyond it she could see bookshelves and, through an arch, windows in the next room. A dining room? A boardroom? On the other side, also off-camera, there was an open staircase leading down – they had come up that way. Soft carpets throughout. They had been asked to remove their shoes. Closed doors presumably led to bedrooms, other living spaces, it was hard to tell. Was this a home or an office? Lawson’s family wealth was more obvious this side of the lens.\nSelby sat to Mia’s left, having pushed himself into the corner of the seat. Arms folded, hands tucked in, his chin pushed into his chest.\nOn the other sofa: a woman, Hope, who Mia had met for the first time today, then Lawson, tailored in black as always, hands pressed together as if praying. Concentrating.\nHope had just asked something.\n“It’s a kind of synaesthesia I think,” said Selby, replying. “I see the thing and I can read the prompt. I know there aren’t any words. I can’t see any words. But it feels like reading.”\nLawson had introduced Hope as a “computational astrophysicist,” someone he knew somehow who he asked about things. He had been vague.\nHope pulled her phone from the pocket of her jeans and swiped over to a circuit diagram in her photos.\n“It’s one of the new AI-generated chip cores,” said Hope, “not the whole thing and not a proprietary one. One that was published. I downloaded it earlier. Nobody really knows how it works except the machine and it’s not telling. But it’s fast.”\nIt looked like a fingerprint. She handed the phone to Selby who took it, reaching out with one hand as little as possible to do so.\n“Um,” he said, and hunched even further over.\nThey all sat for a minute. Lawson pressed his hands together more tightly. Selby, rock still. And then–\nSelby stretched forward to the tablet on the tablet and typed using the on-screen keyboard: one paragraph, two, three paragraphs. Half English and half algebra.\n“Try that,” he said, and nodded slowly, still not looking up.\n“I believe you,” said Hope. She had been testing Selby for half an hour already. She had an open, friendly face, and was smiling in the way Mia imagined she would smile at a nervous child.\nHope reached over to her phone (Selby clasped it) and swiped to the next photo. A diagram of a folded protein, all coils and ribbons. The watermarked telltale showed it was AI-generated.\n“This breaks open the SARS-CoV-2 capsid. It’s why we no longer get Covid. It’s used in drugs that are sold for… a lot. The DNA sequence that leads to it is unpublished. Secret.”\nThis time Selby bent over the phone for long enough that Lawson and then Mia stood to stretch their legs. Mia walked to the table and picked up the framed Cosmopolitan cover that had been left there. Lawson paced slowly and deliberately across the length of the room and back, and then again. Hope sat with him looking curious, calm.\nMia looked up when she heard Selby typing on the glass of the tablet.\nShe felt she was witness at an event as silent and as momentous as would be an unexpected eclipse of the Sun. Mia gave an involuntary glance out of the window, cold in a sudden invisible shadow. No. The sunlight persisted, bright, fierce, blind.\n“Who would like a coffee?” said Lawson. He strode to a Nespresso brewer and tray of mugs on a console table that would be unseen, if they were on-screen again. Yet here they were all together.\n“Could you do this phone?” asked Hope. “Industrial design is done by prompt engineers now.”\nSelby turned Hope’s phone in his hands, examining its curves and construction, and gave a small nod.\n“I was just wondering,” she said, and gently took her phone back. She glanced at it and took in the notifications. The phone wallpaper was a broad oval speckled yellow, blue and red.\n“What’s that?” said Selby.\n“The cosmic microwave background,” said Hope, “the uneven pattern of the universe as far back in time as we can see. It’s a radio map of the sky, before any stars or any galaxies. A seed! Everything that we see now” - she gestured outwards slightly with both hands - “is an evolution of that pattern. It’s a prompt too, in a way. The prompt that made the universe. Ha.\n“Lawson told you I’m in astrophysics?”\n“Something like that,” said Selby. “He said you look at things for him.”\n“I do,” said Hope, “sometimes. I like it when he calls. It makes a change from the lab. And paperwork.”\n“So why is the sky speckled like that then?” said Selby.\n“Well that’s the mystery, isn’t it,” said Hope, and she handed her phone back to Selby so he could see. “Why should it be anything at all? This is the first full map, made back in 2013. Seeing this is why I got into astrophysics. Gazing into the face of God, right?\n“And now it’s my wallpaper. We don’t know why the universe looked like this a single second after the Big Bang. If it had looked any different then it wouldn’t be us sitting here. So it turned out alright.”\nSelby looked down again at the map of the ancient sky. Wonder.\n“Mia,” said Lawson. She walked over to where Lawson was feeding capsules into the coffee machine, making a new cup with each one.\n“We don’t need to blow up trade secrets with this, not publicly,” he said. “There’s more value in digging up the treasure ourselves.”\nMia frowned.\n“Pirate maps,” said Lawson, “remember? We get the prompts for the secret AI-generated chips and drugs and the rest, then we prompt engineer our way around those x-marks-the-spots and sell the artefacts to the highest bidder. A better place in the value chain.”\n“I’m–” said Mia, “I’m not sure that’s why Selby left his house today.”\n“Hope,” said Lawson, “come show me how you want your coffee.”\nMia, Lawson and Hope were standing, talking over their coffees, when Mia turned and saw that Selby hadn’t moved, and in fact was still sat curled over Hope’s phone, its screen now dark.\nMia hurried to the sofa and touched Selby on the shoulder, then shook him after the lack of response. His eyes were wide and fixed unseeing on the phone held in both hands, rictus fingers become taut claws.\n“Selby,” said Mia, and shook him harder this time. Selby gave a sharp single nod and a strangled grunt and clenched his jaw even tighter, his whole body locked.\nLawson and Hope came to the sofa.\n“Get an ambulance,” shouted Mia. “What’s your address? What’s your address? I think he’s wet himself.”\nLawson began to dial.\nHope sat next to Selby and put an arm around him. He didn’t move. The tablet was on the coffee table in front of them both, its glowing screen showing the history of prompts that Selby had been typing to the AI.\n“They’re on their way,” announced Lawson.\n“Hold on,” said Hope softly to sightless Selby, this rigid body. “There’s an ambulance coming.”\nShe held him more tightly and the room shrunk to just them, their sofa, the table. Hope felt trapped in the moment, stuck in a web, claustrophobic. Her eyes darted then landed on the tablet, a record of the afternoon. \nThere were prompts for art, they’d started there. Then the cat food packaging, to see that again.\nThen the chip. Then the protein. Several paragraphs, both of those.\nThen a prompt Hope didn’t recognise, one that that he must have typed while the other three had not been watching. Selby’s final synaesthetic reading, the cosmic microwave background itself.\n> let there be light\nhe had written.\n",
    link: "/home/2022/08/03/whisperer",
  },
  {
    title: "I’m speaking at a couple of events over the next few weeks",
    date: "14.14, Monday 8 Aug 2022",
    content:
      "Actual physical in-person events! Speaking IRL!\nThe Conference, Malmö, Sweden (23–24 Aug)\nI’m part of the group session How to Use a Computer which aims to\n\nreintroduce ourselves to our computers, in order to welcome the exotic feelings of joy, wonder, and empathy that comes from interacting with the machine and each other.\n\nI’m going to (briefly) trace a path from the instant gratification of the search box through to a more collaborative vision of human-machine interaction, by way of algorithms and Pac-Man.\nThe conference program looks great. I’m especially looking forward to the Spatial Computer session on Tuesday (VR, AR, metaverse, and other superimposed realities) and the two talks on Wednesday morning around ecological thinking. Intrigued by this: What would nature say if it had a vote in your next board meeting?\nThe full program is on the website: The Conference 2022. Tickets are still available.\ndConstruct, Brighton, UK (9 Sept)\nI spoke at dConstruct way back in 2007 and I’m delighted to be back for this one-off. (Back then I built my own handheld gadget to control zooming-user-interface slides using a hacked wiimote. It was far too much stress. I’m just going to use Keynote this time.)\nI’m going to talk generally around tools for togetherness which is my new framing for my long-running territory of general curiosity: how can we be together online, what we can do there, what it does to us, what are the design considerations, etc.\nIt riffs off Howard Rheingold’s 1980s coinage “tools for thought” (from his book of that name) which carries us from Engelbart’s perspective that led to the invention of the PC through to the fluorescence of new epistemic tools that we’re seeing today.\nI’m one of eight speakers – there’s a robotic artist, a neuroscientist, and a calligrapher. It should be an excellent day.\nThe conference website: dConstruct 2022. Tickets are still available.\nCome say hi if you’re also at either thing.\n",
    link: "/home/2022/08/08/upcoming",
  },
  {
    title: "Who could write protocol fiction for speculative infrastructure?",
    date: "15.45, Thursday 11 Aug 2022",
    content:
      "Writing protocols for fictional big systems might be a neat way to unlock the future. But I wonder who you would need in the room to author the spec.\nTo be more concrete about this, here are two ideas I’ve posted about before. How could they be bootstrapped, short of being a giant benevolent corporation?\n\nWhat about a national packet-switched drone delivery network (2021) - there are cargo-carrying drones already. What’s the system of parcels, pick-up points, charging stations, and payment such that companies can cooperate and compete to build national delivery infrastructure, just as we have interop on - say - the phone network?\nHow about twice yearly MRIs for a personal Check Engine light (2022) - medical conditions can be spotted using computing vision on relatively cheap, non-invasive MRI scans. What’s the system of accessible scanning infrastructure and an App Store of condition-spotting health software startups, with built-in privacy and affiliate fees, such that there’s an arms race to create ever-more-comprehensive screening software and improving health outcomes?\n\nThese are both ecosystems that provide infrastructure by harnessing market forces. Get it right, and the incentives align towards getting cheaper, better, and more accessible.\nSo… the internet works? How did that start?\nIn 1969, the proto-internet ARPANET had four nodes, and it used gateways and the then-new technology of packet switching to transport data between remote computers run by different people. It was a network built to be extended. And it was.\nThe transport protocol was the bottom layer; higher up was the application protocol: how does software speak to remote software in a standard way. Given standards, the types of applications can flourish too. Permissionless innovation we call it now – how can you do new things without hitting coordination problems.\nTwo-Bit History has two fantastic articles about ARPANET:\n\nThe Real Novelty of the ARPANET which walks through a demo of ARPANET from 1972, what made it different from other (socially sophisticated!) timesharing networks that came before, and how its protocols were developed\nHow the ARPANET Protocols Worked which is a dive into the protocol hierarchy, how they were defined and how they worked, and a comparison with today’s internet protocols.\n\nLessons:\nProtocols are just agreed ways to communicate. A protocol embodies an architecture of participation. They’re the lynchpin!\nTo start with there’s an enabling, base protocol which allows for (a) cooperation, (b) expansion, and (c) more protocols to be layered on top. For there it’s an iterative process as the network and its use cases grow.\nTo bootstrap this, a “minimum viable network” is created by a single organising body. It was BBN, under contract from ARPA, that built the enabling gateway computer (the “IMP”), and also developed its software – which included the first version of the protocol stack.\nBut before all of that: there’s a vision of what kind of big system is to be developed. There’s a viewpoint of how the network will grow, and what it will be used for. I think  this viewpoint was developed and espoused (in the form of funding preferences and memos) by inaugural IPTO director at ARPA (1962-1964) J. C. R. Licklider. Though to check that assumption first I need to work my way through M. Mitchell Waldrop’s biography The Dream Machine, now published by Stripe Press, currently glaring at me from my bookshelves.\nApplying the lessons:\nWhen I’m thinking about a nationwide drone delivery network, or MRI-enabled medical screening ecosystem, it’s a coordination problem, right?\nIt would be in everyone’s interest to have these kind of big systems, but it’s in no-one’s interest to go first. It wouldn’t - for example - be in Amazon’s interest to build out a delivery drone network onto which everyone can piggyback. That’s a catalyst problem.\nIn broad brushstrokes then, we want a process like this:\n\nImagine the destination ecosystem such that its internal economy is well-balanced, there is good interop, and the incentives are all pointing in the right directions\nDraft a protocol – a set of rules for how to work together, but expressed as rules primarily for software. Ensure that it represents the desired ecosystem, but also that it works when there are a small number of actors, and that it contains incentives to grow without introducing coordination costs\nLaunch a prototype: a working reference implementation for the protocol, but also something that achieves commercial end-to-end\nSmooth the way for growth by removing blockers for 3rd party participants (for example: underwriting risk on long-term infrastructure investment)\nIterate everything.\n\nThe protocol is where the rubber hits the road. It’s a description of the future, and a proof of the potential economics. If done well then funding the prototype should be a relatively straightforward public infrastructure decision – although there may need to be policy whitepapers to communicate the cost/benefit to government…\nINSPIRATION:\nIn the adjacent world of software, Robin Sloan has been considering the problems of Twitter and social media - everything from the doomscrolling user experience to the failure modes of centralisation - and has come up with a vision of something new.\nBut he hasn’t built software. He has designed a protocol: What follows is a narrative description of a protocol that I believe might open up some interesting new possibilities on the internet.\nIn depth!\n\nSpring ‘83 is a protocol for the transmission and display of something I am calling a “board”, which is an HTML fragment, limited to 2217 bytes, unable to execute JavaScript or load external resources, but otherwise unrestricted. Boards invite publishers to use all the richness of modern HTML and CSS. Plain text and blue links are also enthusiastically supported.\n– Robin Sloan, Specifying Spring ‘83 (2022)\n\n(It’s enormously readable. Check it out.)\nThere’s a draft spec! github.com/robinsloan/spring-83 – and, since the ref was first published, various people have created various implementations, also listed at that link, so you can use it too.\nThe thing is that, for an ecosystem, you do need many participants.\nWith the narrative description, Sloan created the catalyst. With the spec, he solved the coordination problem.\nLet’s pretend we wanted to write the protocol for a nationwide, interoperable, drone-delivery network.\nWho would you need in the room to kick off that process?\nThinking out loud, you need expertise in at least these areas:\n\nExisting market dynamics around delivery\nExisting market dynamics around drones\nHow to credibly describe a future industry sector (for example: who planned out 3G before anyone bid for the spectrum?)\nThe theory of protocol design and what allows for attributes like growth, interoperability, and permissionless innovation\nThe practicalities of protocol design: how to be simple, readable, adaptable\nContract engineering with subject-matter expertise - to consider how to build the reference implementation\nOperations and fundraising - to consider how to run and scale the reference implementation\nStorytelling: visualising the future and how we get there. Vital for alignment and enrolling support, but also (the vital work of design fiction) to test, in thought experiment form, against unintended consequences\nLobbying: how to write policy whitepapers and get them discussed by the right people\nLastly, a convening function, from facilitating to goal-setting\n\nAnyone else?\n(That’s too many people. So perhaps with the right economist, and the right technologist, etc… You’d want a small group, I think.)\nOutput: a report with an imagined market, some kind of visualisation, a designed and documented protocol, a costed approach for the prototype build, and a wrapper for all of the above to carry it into the right audiences (public sector; VC; etc).\nAhead of that, you would want probably want to kick off discussions with a pool of people who are both open-minded and also well-networked in the above areas, in order to iterate to the right group members.\nAnd beyond the delivery of the above protocol fiction etc by my new Committee for Actualising Speculative Infrastructure, an organisation to carry the ball forward.\nBack in 2020, I spoke at ThingsCon about wanting to work at imagining beyond design fiction:\n\nBut we don’t need just design fictions. We need business model fictions, engineering feasibility study fictions, interop protocol specification fictions, investment return fictions.\n\nThis is what I meant!\nAlthough I seem to have drifted from protocol fiction to committee fiction…\nBut 50% haha-lol-what-if and 50% seriously: if we got half a dozen people together in London sometime, who should be in the room?\n",
    link: "/home/2022/08/11/casi",
  },
  {
    title: "The shock and awe of state-sponsored women’s fashion",
    date: "20.10, Tuesday 16 Aug 2022",
    content:
      "I think that, because we’re a capitalist society, we think of AIs as amplifiers for production and consumption. But they can force-multiply on any vector if suitably directed.\nAnd, I don’t know, could you weaponise the fearsome AI that is the Gen Z fashion app Shein?\nLook:\nBack in 2017, Anna Batista asked (at Irenebrination): Can the Algorithm Become a Cool Fashion Designer?\n\nDeveloped by Amazon’s San Francisco-based Lab126 - the company’s research and development hub - the algorithm uses a tool called generative adversarial network (GAN). … In a nutshell, the algorithm may spot a trend on Instagram, Pinterest, Facebook, or in its own collection images generated by Amazon’s Echo Look camera, and come up with new styles.\n\nAI fashion.\nA GAN is actually two AIs, a generator and a discriminator.\nThe generator sits there pumping out new dresses (or whatever). The discriminator does its best to recognises the dresses (or whatever) and score them. The generator learns how to improve its score. Ta-da, amazing dresses.\nThough I don’t recall it taking over Amazon.\n5 YEARS LATER:\nBased in China and shipping across 220 countries, Shein is the world’s largest fashion retailer, as of 2022 (Wikipedia).\nThe generator:\n\nIt starts with algorithmically scouring the internet and Shein’s own data to pull out fashion trends. As one of Google’s largest China-based customers, Shein has access to Google’s Trend Finder product, which allows for real-time granular tracking of clothing related search terms across various countries. This allowed Shein, for example, to accurately predict the popularity of lace in America during the summer of 2018. Combine that with Shein’s huge volume of 1st party data through its app from around the globe and software-human teams that scour competitors’ sites, and Shein understands what clothes consumers want now better than anyone with the possible exception of Amazon. \nShein feeds that data to its massive in-house design and prototyping team who can get a product from drawing board to production and live-online in as little as three-days. \n– Not Boring (Packy McCormick), Shein: The TikTok of Ecommerce (2021)\n\nFrom there, it can start with incredibly small batches, around as small as 10 items.\n(Go read that entire breakdown of Shein’s business. The ERP innovation is remarkable.)\nThe discriminator:\nProducts in very small numbers are added to the app, and then clicks, views, purchases, and shares are monitored - automatically scaling orders to the network of factories. At great scale.\n\nShein churns out and tests thousands of different items simultaneously. Between July and December of 2021, it added anywhere between 2,000 and 10,000 individual styles to its app each day, according to data collected in the course of Rest of World’s investigations. The company confirmed that it starts by ordering a small batch of each garment, often a few dozen pieces, and then waits to see how buyers respond. If the cropped sweater vest is a hit, Shein orders more. It calls the system a “large-scale automated test and re-order (LATR) model”.\n– The Guardian, How Shein beat Amazon at its own game - and reinvented fast fashion (2021)\n\nI mean.\nWhile the bit of Shein that surfaces trends makes use of AI, it isn’t an AI designer in itself (the team of human designers was already 800 strong by 2016).\nBut throw consumerism into the loop, with feedback into ordering, and the entire thing resembles a giant Generative Adversarial Network, an AI for producing fashion lashed together out of software, supply chains, designers, and desire, teaching itself how to improve all the time.\nLikewise I wouldn’t call the Facebook newsfeed algorithm an AI, but coupled with user clicks and eyeballs as a discriminator, I most definitely would. The trick is to include the human response.\n(If we could talk to the Shein AI, I wonder what it would say? It would be like trying to talk to an intelligence emergent from the fluid dynamical storms of Jupiter. I wonder how we could send it a message, and if we would recognise any response?)\nIt’s tempting to think of this giant fashion GAN as neutral somehow. Like: it generates, we discriminate, and what comes out is fashion.\nBut it’s trivially possible to reach inside the machine. The prince of Shein could decide that everyone is going to wear blue next month, and could choose to only generate blue garments, and of course the thresher of consumerism can only discriminate over what it’s given…\nSo at that point the AI would grasp the flywheel, and blindly optimise its way to figuring out exactly how to make blue garments appealing and profitable.\nI mean, AI is a fearsomely powerful gradient climber. It’s a weapon.\nAnd it occurs to me that:\n\nShein is China-owned, and GANs its fashion into the world\nTikTok is China-owned, and can boost trends, and suggests filters for how we look\nZoom’s software is developed in China, serves 3.3 trillion meeting minutes annually, and could - if it wanted - subtly and silently change my appearance, like my shirt colour or my weight or the percentage of eye contact, and you would never know.\n\nI’m not picking on China especially here or suggesting they are actually up to anything or would have a motivation to do so, but this combination of appearance mediators makes me ask:\nWhat would a state-sponsored fashion hack look like?\nA fashion hack isn’t like the other global infrastructure exploits I’ve previously wondered about because it isn’t entirely obvious what you’d use it for. But the thing about state-sponsored attacks is that they’re a bit like magic tricks: they operate at a scale which is absurd, which makes them unimaginable, and that’s why they work. Like artificial weather or guided influenza.\nIt’s absurd to contemplate that plausibly deniable rainstorms might be directed to disrupt a UN weapons inspection team, or people peaking on the infectivity curve with flu are quietly standing next to diplomats 48 hours ahead of an important negotiation - but I bet it has happened.\nCould a malevolent state actor\n\ntweak the timings and appearances in online meetings to make the exec team of a competitor company simply… not like each other as much, or never have an effective conversation? (Could you measure that in the stock price, against corporate meeting software contracts?)\ndeliberately diverge the clothes preferences of two friendly nations, to undermine the common feeling they previously experienced?\nassociate a particular look with transcendant beauty, and deny sales that would create that look to particular nations, immediately creating a status gradient? (I mean, this is no different from how pop music and abstract expressionism were deployed in the 1960s by the West, only with new technology.)\nget people to wear stupid hats, simply for their own amusement?\n\nDunno.\nHey, follow-up question: if we were in the middle of a giant fashion hack, how would we know?\nIf I got to pull the levers, I’d use Shein and TikTok to target my own civilians, and I would artificially boost acceptance and desire for cybernetically enhanced clothing, catalysing an arms race for cyborg prostheses providing the wearer with both superhuman powers (such as strength, speed, and musical accomplishment) and astounding aesthetics.\nBut that’s just me.\n",
    link: "/home/2022/08/16/fashion",
  },
  {
    title: "How to mobilise the UK for wind power",
    date: "16.42, Friday 26 Aug 2022",
    content:
      "It’s hard to think of anything except energy costs today (the numbers were just announced). This time last year we paid £142/month for electricity and gas. It’s already up to £320/mo, and will jump to £579/mo from October.\nAccording to the Which? magazine calculator I will be paying £1,080/mo in April-June 2023. Insane.\nGas prices have spiked because of the European dependency on Russian gas and the Ukraine war. In the UK, looking at this grid dashboard, about half of our electricity is generated from gas.\nThere are other factors. Danish friends were telling me earlier this week that electricity prices have spiked there too despite Denmark generating mostly from wind. Apparently they don’t use grid batteries and instead balance with hydro from Norway when the wind drops. But demand on hydropower is high generally and the reservoirs need to be filled before winter.\nSo it’s a mess.\nGermany has corner-turned impressively hard. It was phasing out nuclear power; now the last three nuclear power plants are being kept open. It was reliant on the Nord Stream gas pipeline and Russia massively tightened supply; Germany now gets its gas mainly from Norway and not Russia.\nWhether or not there is a market failure in UK (why are prices spiking so much? How come the energy companies are making so much profit?) what should be happening right now is a rush to build renewable capacity - anything that eases the pressure on gas.\nAND YET: we’ve got a lame duck government in the middle of a leadership transition, so it’s doing nothing, and the two candidates have been disparaging about both solar and onshore wind. This is because the people who will vote for them (Tory party members) typically don’t like the look of wind farms or solar panels.\nReal leadership would\n\ndo what is necessary and make the case for it\nturn necessity into an opportunity.\n\nHey, here’s a free idea for the two Tory leadership candidates:\n\nour economy needs stimulus and jobs but but as capital investment and not inflationary cash injections\nthe UK needs green energy transition, not just because of the cost of gas but because the climate crisis is an existential threat.\n\nThe UK has an incredible amount of wind. More than almost anywhere in the world.\nAND SO:\nWe should push massive investment in onshore wind farms, with the manufacturing and engineering supply chain all here in the UK. (Here’s the Tory appeal: we can do this now, it’s a Brexit dividend!)\nThen export the machinery and the skills. Become the world leader.\nIt’s an economic reboot, job creator, and saving rural England all at once (droughts and floods are not so good for our green and pleasant land…).\nLet’s appeal to the right even more: it’s sovereign energy. Made here, keeping us independent. We need to have a bigger conversation about resilience but that’s another story.\nOffshore, we have a fair amount of capacity already, and there are several new offshore wind farms coming online this year or next. But accelerating offshore is slow.\nWhereas onshore, sure, you can’t generate as much - but they’re faster to build and it’s an emergency. If we can discover and roll out a Covid vaccine in the last year then surely we can boot up a new manufacturing economy and save the planet in the next one.\nWhat I don’t understand is that there is ZERO vision like this from our politicians.\nIt feels like an easy sell? Rural voters are primed to care about the environment, a push like this creates jobs, and “energy sovereignty” is  Brexit-friendly.\nSo is it a policy origination failing?\nAre the right-wing policy think tanks simply not coming up with ideas? Has there been incumbent-interest capture?\nOh but maybe people really, really don’t want to see wind turbines on the horizon.\nNow we’re really talking about a failure of the imagination because that’s an easy fix with marketing.\nFIRST: appeal to people’s pockets. The pattern has been figured out by a company called Ripple Energy. They establish co-ops to build onshore wind farms. Anyone can buy in. Profits are distributed in the form of a discount on your electricity bill.\nSo, when a wind farm is built, direct a slice of the the profits to local residents.\nPerhaps even make it competitive. Make a shortlist of sites and get local communities to bit to build nearby.\nSECOND: don’t call them wind farms, call it British Air Power.\nWe’re used to talking about green energy with pictures of leaves and blue sky etc. No. Change the framing to strength and power. Boom. Done.\nIn the meantime: set up a government department to buy as much photovoltaics as possible, making deals as far back in the supply chain as is necessary. (It doesn’t matter where manufacturing happens right now, but set up facilities for future UK manufacture in parallel.)\nThen use windfall profits on the energy companies to provision solar for factories, schools, and homes (underwrite interest-free loans) in order of necessity first.\nStart today. I know this sounds like I’m talking about wartime: central economic planning, homeland propaganda, and a new level of urgency. But that’s how we need to treat it.\nBecause this isn’t going to get easier. It’s not a matter of riding out the winter. We need to build.\n",
    link: "/home/2022/08/26/wind",
  },
  {
    title:
      "What I have to say about carbon accounting in web browsers will shock you",
    date: "19.39, Thursday 1 Sep 2022",
    content:
      "Low-Tech Magazine is hosted on a solar-powered web server. It has a battery backup, but it will go off-line during longer periods of bad weather. So there’s a page detailing both the battery level and the weather forecast in Barcelona.\nI enjoy imaging the physical location of the website! From the About page:\n\nBecause it uses so little energy, this website can be run on a mini-computer with the processing power of a mobile phone. It needs 1 to 2.5 watts of power, which is supplied by a small, off-grid solar PV system on the balcony of the author’s home.\n\n(Photos are black and white and dithered, which further reduces energy; only default fonts are used; there have been sensible, low-energy tech decisions on the back-end.)\nAnother! Solar Protocol (which cites Low-Tech Magazine in its library).\n\nSolar Protocol is a web platform hosted across a network of solar-powered servers set up in different locations around the world. A solar-powered server is a computer that is powered by a solar panel and a small battery. Each server can only offer intermittent connectivity that is dependent on available sunshine, the length of day and local weather conditions. When connected as a network, the servers coordinate to serve a website from whichever of them is enjoying the most sunshine at the time.\n\nOne of the collaborators on Solar Protocol is the artist Tega Brain who gave a wonderful and mind-expanding talk at The Conference in Sweden last week.\nIt’s a presentation of her own work, a critique of “systems thinking,” and a probe into both AI and climate.\nWatch the video here: The environment is not a system by Tega Brain (40 mins + Q&A). Highly recommended.\nSolar Protocol is provocative, for me, because the big tech companies will of course already be behaving like this, shuffling compute around to where energy is cheapest. (And it’s why Meta has server farms in the Arctic circle, to take advantage of cheap cooling.)\nBUT: for the rest of us? It’s interesting to imagine what underlying tech would be required to allow for any website to operate like this.\nSOME IDEAS:\nCould energy accounting be built into internet protocols?\nLike: could a database query return, along with the results and the query time, the joules burnt to produce the answer?\nCould that query additionally report the location of its server, and a data centre report the precise energy mix (% from grid; % from battery; % from local renewables etc) supplied to that server at the time?\nCan an API aggregate the energy spent for all its underlying queries, in the return object including the total joules – which would also have to include a calculation based on the CPU time to service the API call? And an amortised slice of the embedded carbon of the data centre?\nUltimately: could a webpage include, in its HTTP response headers, all of this data added up, every page returned to your browser with its joules shown numerically right there in the tab?\nOr as carbon footprint? Because that’s the goal, I think: a live view of the carbon I’ve burnt today with my app swiping and web browsing, in exactly the same way as I can tap the battery icon in my menu bar on my laptop and see a list of Apps Using Significant Energy. \nAWS, Google Cloud, etc: do this please?\nTHERE ARE PEOPLE WORKING ON THIS!\nAnd people to learn from: Branch magazine, now 4 issues in.\nA couple of favourite articles…\n\nHowever in Switzerland, this idea of carbon awareness is being built into the internet protocols themselves with SCION. …\nThis same flexibility also means that it’s possible to choose routes based on how green the path to a destination is too - avoiding regions when the cost of energy is high, and the power is dirty, or where there’s a scarcity of green energy available.\n– Branch, A Carbon-Aware Internet (Issue 2)\n\nAha! A protocol to watch.\nThis article has some practical pointers for web engineers:\n\nIn order to meet the growing demands for reporting and transparency, developers need a way to measure the carbon emissions associated with the apps, sites, and software they build. On the server side, we’re seeing more providers build carbon reporting into their platforms. However, on the application side, it’s largely up to developers themselves to implement solutions. That’s where libraries like CO2.js come in handy, providing a set of research-based, standard calculations that enable developers to quickly add carbon awareness to their products and projects.\n– Branch, Normalising Digital Carbon Reporting (Issue 4)\n\nGood news on the cloud computing front, then.\nCO2.js has some intriguing implications:\n\nIn the same way that web developers might set a performance budget for their site, a carbon budget could also be used. If a website or app exceeds a threshold for carbon intensity, then an alert can be raised or a new deployment can be blocked.\n\n(The library comes from Branch sponsors, the Green Web Foundation.)\nAction is the point, right? Acts not facts. We measure for\n\ntransparency: we can see what’s going on\nbehaviour change: given data, we might make different decisions.\n\nSo measure at the server and protocol level first, and then allow service developers to change their behaviour… and, eventually, expose the data to end users?\nMore practical tips: see This website is killing the planet (Steve Messer, 2020) which has a bunch of tools and how-tos in the Further Reading section.\nALSO:\nNot the same but with the same vibe:\nShould I Bake .com (single-serving website). Currently: We recommend baking when more than a third of Britain’s electricity is coming from wind, solar and hydro power – right now, between 19:00-19:30, it’s 24%.\nWonderfully there is a multi-day baking forecast which shows me that I shouldn’t bake until, ah, Saturday.\nRelies on this new-to-me Carbon Intensity API:\n\nThe Carbon Intensity API uses state-of-the-art Machine Learning and sophisticated power system modelling to forecast the carbon intensity and generation mix 96+ hours ahead for each region in Great Britain.\nOur OpenAPI allows consumers and smart devices to schedule and minimise CO2 emissions at a local level.\n\nBrilliant.\nBuild this into my tumble drier!\nSeriously. Samsung, Electrolux, etc etc: if current carbon intensity is higher than average, make it so I have to hold down the Start button for like 2 minutes or something.\nMake me work for it! Make me solve a puzzle before running my appliances when emissions are above average. Hey I’ve even got a name for that imaginary feature: Carbon CAPTCHA.\n(I should be able to get something working at home with smart plugs and a Raspberry Pi… hmm…)\nThis is a temporary scenario!\nOr at least, until I can get solar at home, which appears to be pretty much impossible rn in the UK due to volume of interest.\nBECAUSE: solar means energy freedom.\nClive Thompson:\n\nI’ve stopped worrying about electricity use, both economically and ethically.\nI no longer walk around finger-wagging at my family members. Want to blast the AC? Crank away. It’s coming from the sun, and I can’t use all that electricity even if I try.\n– Wired, After Going Solar, I Felt the Bliss of Sudden Abundance (2022)\n\nThe emotional shift: I went from a feeling of scarcity to a sense of abundance.\nCan’t wait.\nANYWAY, what I really want is a new web browser with a built-in carbon accounting odometer for all our Twitter doomscrolling (accrued in CO2E kg per inch).\nI want you to feel a sense of relief when you type a common query into Google and the data comes back from the cache, dodging the expensive database lookups.\nAsk something weird and get a cache miss? YOUR COMPUTER SHOULD ELECTROCUTE YOU.\nNot too much, let’s be clear, just a little zap, a bit like an elastic band twanging on the tip of your finger. Multitouch screens that can give you an electric shock would have all kinds of uses for behaviour change I reckon.\n",
    link: "/home/2022/09/01/carbon",
  },
  {
    title: "What makes a brick wall?",
    date: "08.40, Friday 9 Sep 2022",
    content:
      "There’s a wall we pass on the way to nursery and it’s crumbling – my little girl was asking what the bits were. So that got us talking.\nWell a brick wall is bricks and mortar. But that seemed insufficient when I said it out loud.\nA brick wall is bricks, and mortar, and pattern.\nThat’s where I landed. Without the pattern the wall wouldn’t stay up. So it’s an ingredient, just the same, even though it belongs to a different category.\nI suspect if I asked a bricklayer this would be absolutely obvious. So it’s only a surprise to newcomers and those, like me, with ontological blinkers.\nAnother:\nWhen I’m running (I’m not running much at the moment) my mental model is that I’m training up four things, and they have to be balanced – I can’t get to longer distances unless they all improve, so there’s always one that is lagging, and so I work on that.\nThree are physical: heart, puff, muscles (strength and stamina).\nAnd also: will.\nWill is definitely something which is trainable. Not just gaining confidence in one’s own capacity, but the ability to endure tedious middle miles, or training over months and months, or the last few miles of a race where so many other people are now walking and it would be so easy to join them.\nAnother:\nBread, famously: flour, water, yeast, salt.\nAlso - practice?\nDuring the Sourdough Period I was baking every week or so. I’ve baked before so it didn’t take too long to get my eye in. Yet I’ve got photos, and the difference between the first loaf I was pleased with and the loaves a few months later is extraordinary.\nNothing changed, as far I could tell. I didn’t refine anything. I didn’t change my kit. I didn’t work to keep anything in mind. Just… my hands and my unconscious intuitions figured out how to improve on their own.\n(If you drive, you’ll remember that learning to drive is wild. You learn to drive by trying to drive for about 12 hours. You don’t really have to think about it. You can’t improve by working harder. You just… sit there and give it time. Your body and your hindbrain figure it out.)\nSo practice is as important as any of the other four. Again a different category.\nIt’s a curious provocation whenever I’m making anything: what is the X? Assume there is one and make room for it.\nI don’t mean outcomes. There is definitely an outcome-X factor in experience of architecture and apps and appetisers which emerges from I-don’t-know-what, and we do our best to create the conditions for that to appear.\nI mean instead an input-X. What’s the ingredient, the thing I control, the quality I could be providing more of, to whatever activity it is I’m doing or whatever thing it is I’m making. And it may be hard to spot, because it may not be in the same category as the others.\n",
    link: "/home/2022/09/09/ingredients",
  },
  {
    title: "I hope libraries are snapshotting today’s awkwardly sourced AIs",
    date: "19.53, Thursday 15 Sep 2022",
    content:
      "I hope libraries are figuring out how to archive today’s absolutely remarkable but potentially illicitly created AIs.\nLarge language models like GPT-3 are trained by hoovering up all the text on the internet. Image synthesis AIs are a language model plus another AI trained on all the images that are similarly hoovered up. It’s all pretty indiscriminate.\nFOR EXAMPLE: Andy Baio and Simon Willison built an interactive explorer for some of the training images in Stable Diffusion (exploring 12 million of the 2.3 billion included) - unsurprisingly there’s a lot of commercial art there. And that’s why you can say “in the style of David Hockney” or whatever in an image prompt and it comes back looking like a previously-unknown Hockey print.\nASIDE:\nTake a moment to visit Everest Pipkin’s project Lacework (2020) in which they viewed, personally, every single one of the one million 3 second videos in the MIT Moments In Time dataset._\n\nVery slowly, over and over, my body learns the rules and edges of the dataset. I come to understand so much about it; how each source is structured, how the videos are found, the words that are caught in the algorithmic gathering.\n\nI don’t think anyone, anywhere will have such an understanding of what constitutes an AI, and given the growth in datasets, I don’t think anyone could ever again.\nRepetition is devotional, says Pipkin.\nIt brings tears to my eyes. So good!\nWho owns style?\nWhen it comes to code the problem is even more pointed because code often explicitly has a license attached. GitHub Copilot is an amazing code autocompletion AI – it’s like pair programming. (I can see a near-term future where being a human engineer is more like being an engineering manager today, and you spend your days briefing and reviewing pull requests from your team of AI copilot juniors.)\nBut it’s trained on GPL code. When code is licensed with GPL, the authors say that it’s free to use, but any code based on it must also be licensed as GPL. Viral freedom. Now, if I learn how to code by reading GPL code and then go on to work on proprietary code, that’s fine. But used as AI training data?\nLegally GitHub Copilot is probably in the clear but it’s also probably not what the authors of the open source, GPL code would have intended.\nSimon Willison talks about vegan datasets: I’m not qualified to speak to the legality of this. I’m personally more concerned with the morality. - It’s a useful distinction.\nThere’s a lot to figure out. Have I been trained? is a tool to bring some transparency: as an artist you can search for your own work in the image synthesis training data. It’s a first of a series of tools from a new organisation called Spawning, also including Source+:\n\n… Dryhurst and Herndon are developing a standard they’re calling Source+, which is designed as a way of allowing artists to and opt into - or out of - allowing their work being used as training data for AI. (The standard will cover not just visual artists, but musicians and writers, too.)\n– Input, This couple is launching an organization to protect artists in the AI era (2022)\n\nProvenance, attribution, consent, and being compensated for one’s labour (and being able to opt in/out of the market) are all important values. But I can’t quite visualise the eventual shape of the accommodation. The trained AIs are just too valuable; the voices of artists, creatives, and coders are just too diffuse.\nv buckingham calls this copyright laundering, as previously discussed in this post about ownership, in which I also said:\n\nMaybe there is a market for a future GPT-PD, where PD stands for public domain, and the AI model is guaranteed to be trained only on public domain and out-of-copyright works.\nAnd litigiously cautious megacorporations like Apple will use GPT-PD for their AI needs, such as autocomplete and auto-composing emails and how Siri has conversations and so on.\n\nThe consequence will be that Gen Beta will communicate with the lilt and cadence of copyright-expired Victorian novels, and anyone older (like us) will carry textual tells marking us as born in the Pre Attribution Age.\nPerhaps:\nGPT-3 and the Laion-5b dataset, with their gotta-catch-em-all approaches to hoovering up training data, will in the future be seen as just a blip.\nALSO we’re poisoning the groundwater.\nAttribution or not, GPT-3, DALL-E, Stable Diffusion and the rest were trained on an internet where synthesised text and images were mostly absent.\nDALL-E at least watermarks its output with a rainbow telltale in the bottom right, so these can be excluded from future sets of training data, but other synthesisers don’t.\nWhat freaky feedback loops come about when models are being trained on data swept up monthly, but the data has a high proportion of output from previous models?\nLong story short, today’s AIs are unique, trained as they are on pure, unethically harvested data.\nGiven all of the above, they are perhaps the most complete models we’ll ever get? Future datasets will be edited and will be muddied.\nAnd given that: we have an obligation to save them, right? Troubling provenance or no.\nIn a funny way I’m reminded of the immortal cell line of Henrietta Lacks – the moral framework wasn’t in place in 1951 to see what we see clearly now: that it wasn’t ok to collect and appropriate Lacks’ cells. But the HeLa cancer cell line has been used in all kinds of advances over the years, and at the point where the moral framework was established, the choice was made to keep the cell line going. (I’d love to learn more about the moral philosophy of this one.)\nTricky.\nAnyway.\nHow does a library save a snapshot of the current DALL-E, the current GPT-3, the current Stable Diffusion? Complete, usable, and frozen.\nThere’s going to be pressure to not retain these AIs, given the stolen words, art, and code inside them. If not that then the march of upgrades: version 1.1, version 2, a database migration, and at a certain point the mostly proprietary tooling to access the original version of the synthesis models will be gone too. It won’t seem important.\nHow can they be kept for future research? And for just, you know, history.\nI hope there are librarians and archivists working on this, today. I hope that folks from the Internet Archive are already in conversation with OpenAI.\nAnd:\nWhat happens when we find, buried in the model weights, data that is as culturally sensitive as - say - some of the objects appropriated and kept in the British Museum? What arguments are there to be had about data, in centuries to come?\n",
    link: "/home/2022/09/15/libraries",
  },
  {
    title: "The Queue is pilgrimage",
    date: "10.32, Friday 16 Sep 2022",
    content:
      "Right now there is a queue to observe the Queen’s lying-in-state at Westminster Hall.\nThe route runs along the south bank of the Thames, past Big Ben, past the big wheel, past Tate Modern, past Borough Market, past Tower Bridge. The queue is currently 4.9 miles (BBC News) and is touching Southwark Park, which is not a place I associate with the centre of town.\nRight now the wait is 14 hours. It’s outdoors (the weather isn’t great). It moves 24 hours a day; there’s no camping out or sleeping on the ground. A continuous slow progress.\nThe front of the queue is being broadcast live by the BBC (the lying-in-state will last 4 days) and watching it has a meditative magic: And the queue shuffles ever forward in quiet contemplation.\nIt’s easy to laugh or to be cynical but I want to note this moment. It’s special.\nIt is known as The Queue.\nIan of Ian Visits narrated his experience of The Queue on Twitter. Here’s the thread (unrolled). It took him 8 hours. He took photos along the way.\nReading around, people are making friends in The Queue. It’s well managed – you can stop off at one of the 500 loos along the way and get back in using your wristband. There’s a bag drop.\nPeople are talking about The Queue as something wonderfully and uniquely British. Here’s a Twitter thread from @curiousiguana:\n\nThe Queue is a triumph of Britishness. It’s incredible. …\nIt is the motherlode of queues. It is art. It is poetry. It is the queue to end all queues. It opened earlier today and is already 2.2 miles long. They will close it if it gets to FIVE MILES. That’s a queue that would take TWO HOURS TO WALK at a brisk pace. …\nThe BBC has live coverage of The Queue on BBC One, and a Red Button service showing the front bit of The Queue.\nNO ONE IN THEIR RIGHT MIND WOULD JOIN THE QUEUE AND YET STILL THEY COME. “Oh, it’ll only be until 6am on Thursday, we can take soup”.\n– @curiousiguana, 4:11 PM, Sep 14, 2022\n\nQueues mean waiting for handouts and dole queues, yet also decency and fair play.\nQueuing as part of British national character was forged in propaganda during the Second World War (BBC News):\n\n“Propaganda at the time was all about doing your duty and taking your turn,” says Bradley. “It was a way the government tried to control a situation in uncertain times.”\n\nWe think of ourselves as good queuers, now. 80 years later and it’s a story we tell ourselves, though at the same time we take it for granted.\nPerhaps, with a bit of distance, we’d see queuing for the ritual it is. We’d apply to add it to UNESCO’s lists of Intangible Cultural Heritage. We should!\nOr perhaps it’s not so unique.\nFor queuing is pilgrimage. Reading the stories in the papers of the people in The Queue, or following them on Twitter, there are all these aspects bound up: respect, struggle, meditation, endurance, collectivism (yet also: people I know who are going individually because their friends don’t want to join them), journey, devotion, transformation. You can hear about all of these, behind the words.\nThe Queue = pilgrimage.\nThe filthy journey to and from Glasto = pilgrimage.\nHajj = pilgrimage.\nI can’t help thinking how good it would be for our (a) mental health and (b) collective empathy if we had a proper shared cultural tradition and understanding of pilgrimage.\nI barely have that understanding! Enough to recognise pilgrimage when it’s happening, but not enough to truly unpack it.\nIt’s such an alien term, at least for me. It seems funny to use it. And yet! I feel that aha response when I say it out loud!\nI’ve undergone pilgrimage myself, I see now in retrospect. It’s not something I want to talk about here, it’s private, but it’s enough to say that what is happening with The Queue resonates strongly.\nAnd there are personal pilgrimages! Tiny pilgrimages! Mundane pilgrimages! What is the Capital Ring Walk if not a pilgrimage to London? Why else make a spectacularly disproportionate trip to a certain gallery or spot on the coast or restaurant to have an experience that has deep meaning, a meaning that makes no sense to anyone else?\nImagine, in the midst of this Culture War, people from different backgrounds and beliefs suddenly able to make the connection between similar acts of devotion and journey and saying to one another: ah I get it now, we’re the same you and me.\nPilgrimage seems like a human universal. I wonder what it is, really; I wonder what it fulfils in us. Maybe it’s not important to answer that.\nMy takeaway is that I’m going to work harder to identify my own moments of pilgrimage, secular and spiritual, established and vernacular, big and small, and I’ll do my best to name each moment as such, and to give it the space and the weight they deserve.\n",
    link: "/home/2022/09/16/queue",
  },
  {
    title: "Filtered for escaping the simulation",
    date: "10.03, Thursday 22 Sep 2022",
    content:
      "1.\nThe Total Perspective Vortex.\n\n… it is in theory possible to extrapolate the whole of creation - every sun, every planet, their orbits, their composition and their economic and social history from, say, one small piece of fairy cake.\n\nSeeing it is horrific: the Total Perspective Vortex can annihilate a man’s soul!\nZaphod Beeblebox is put into the Vortex in The Restaurant at the End of the Universe by Douglas Adams, the sequel to The Hitchhiker’s Guide to the Galaxy.\n\nHe opened the door of the box and stepped in.\nInside the box he waited.\nAfter five seconds there was a click, and the entire Universe was there in the box with him.\n\nAnd… Zaphod survives.\nIT TURNS OUT that Zaphod never actually went into the real Vortex.\nInstead, earlier in the story, he had unwittingly stepped into a simulated universe, entirely identical to this one (almost).\n\n[Zarniwoop] put the briefcase down and sat in another chair.\n“I am glad you followed instructions,” he said, “I was a bit nervous that you might have left my office by the door rather than the window. Then you would have been in trouble.”\nZaphod shook his heads at him and burbled.\n“When you entered the door of my office, you entered my electronically synthesized Universe,” he explained, “if you had left by the door you would have been back in the real one. The artificial one works from here.”\nHe patted the briefcase smugly.\nZaphod glared at him with resentment and loathing.\n“What’s the difference?” he muttered.\n“Nothing,” said Zarniwoop, “they are identical. Oh – except that I think the Frogstar Fighters are grey in the real Universe.”\n– Douglas Adams, The Restaurant at the End of the Universe (Amazon)\n\nThe other difference is that Zaphod is able to survive the Total Perspective Vortex in Zarniwoop’s simulated universe.\n(It’s quite the get-out-of-jail-free card to play. I’d be up for seeing more retconned synthesised universes in other stories. Maybe it will displace the “yet it was all just a dream” trope someday.)\n2.\nRemember that bug in Xerox scanners that sometimes silently replaced numbers in PDF documents to make them compress better?\nThe wildly powerful - but, it turned out, dangerously inaccurate - compression format is called JBIG2.\nThe JBIG2 format is actually a primitive computer language and, from these basic parts, it is possible to implement a virtual computer which is then run while the PDF is being decompressed.\nAnd, since you’re now running a full-blown computer inside the bit of your phone that is responsible for decompressing images, you can write a program that breaks its way out of that system and hacks your phone  from the inside.\nFrom Google’s Project Zero lab, this is an insane and detailed breakdown of how simply receiving an image as a text message could result in your phone being hacked.\n\nJBIG2 doesn’t have scripting capabilities, but when combined with a vulnerability, it does have the ability to emulate circuits of arbitrary logic gates operating on arbitrary memory. So why not just use that to build your own computer architecture and script that!? That’s exactly what this exploit does. Using over 70,000 segment commands defining logical bit operations, they define a small computer architecture with features such as registers and a full 64-bit adder and comparator which they use to search memory and perform arithmetic operations. It’s not as fast as Javascript, but it’s fundamentally computationally equivalent.\nThe bootstrapping operations for the sandbox escape exploit are written to run on this logic circuit and the whole thing runs in this weird, emulated environment created out of a single decompression pass through a JBIG2 stream. It’s pretty incredible, and at the same time, pretty terrifying.\n– Google Project Zero, A deep dive into an NSO zero-click iMessage exploit: Remote Code Execution (2021)\n\n3.\nBack in 2003, Nick Bostrom suggested that we may be living in a computer simulation.\nHe summarises his argument: looking into the future, we find that there would be vastly many more such simulated minds than there would be non-simulated minds running on organic brains – and, by weight of numbers, you and I are more likely to be simulated minds than actual ones.\nElon Musk is convinced (Vice):\n\n“There’s a one in billions chance [we’re in] base reality,” he said. …\n“I’ve had so many simulation discussions it’s crazy,” Musk said. “It got to the point where every discussion was the AI or simulation conversation and my brother and I finally agreed we would ban such conversations if we were ever in a hot tub because it really kills the magic.”\n\nIf we are in a simulation, could we get out? There are people working on it. This throwaway snippet…\n\nMany people in Silicon Valley have become obsessed with the simulation hypothesis, the argument that what we experience as reality is in fact fabricated in a computer; two tech billionaires have gone so far as to secretly engage scientists to work on breaking us out of the simulation.\n– The New Yorker, Sam Altman’s Manifest Destiny (2016)\n\n…but that was 6 years ago and I haven’t heard of anything since.\nIt’s intriguing to imagine how breakout might occur.\nThere seem to be three main avenues:\n\nObserve an inconsistency that proves that we are in a simulation, e.g. a feature of the universe that should correspond with the laws of physics as understood, but manifests in a way that shows that the simulation machine is conserving resources. e.g. we get to Proxima Centauri and it turns out the star is just a big painting on cardboard, that kind of thing only more subtle. (How to use the observation to break out is left an exercise for the reader.)\nDo something so appealing or unusual that the Simulation Runners are motivated to intervene.\nHack our way out – taking advantage of the fact that there is a computational substrate to our simulated universe, cause a buffer overflow or race condition or out of bounds error, or something, and break out to the containing machine. e.g. is it possible to construct some kind of in-memory data structure (being, perhaps: a structure in our physical universe) that somehow triggers a parse error and is read as code? Could we run our own programs on the simulator?\n\nIt’s odd, imagining that I might be a document, and further imagining that there might be a specific thought I may one day have (thoughts being physical structures, according to Hebb’s rule) that could prise open an escape hatch from the simulation sandbox.\nRELATED:\nIt is possible to reprogram Super Mario from inside Super Mario. Like, it’s possible to glitch Super Mario to write data into system memory, and then glitch it again to execute that data as code. So here’s a video of using code injection to run Flappy Bird inside Super Mario (YouTube). They first inject a 26 byte bootloader, using that to write Mario’s x-coordinate to memory on a spinjump, and that allows reliably loading a much larger payload. The whole process is WILD. Um. So something like that but IRL?\nRef.\nBostrom, B. N. (2003). Are We Living in a Computer Simulation? Philosophical Quarterly, 53(211), 243-255.\n4.\nThe Aleph (Wikipedia), a short story by Borges (1945). PDF here.\nThe author meets someone who has found an Aleph.\n\nHe explained that an Aleph is one of the points in space that contains all other points.\n\nIt’s downstairs.\n\n“It’s in the cellar under the dining room,” he went on …\n\nSo they go and see it.\n\nOn the back part of the step, toward the right, I saw a small iridescent sphere of almost unbearable brilliance. At first I thought it was revolving; then I realised that this movement was an illusion created by the dizzying world it bounded. The Aleph’s diameter was probably little more than an inch, but all space was there, actual and undiminished. Each thing (a mirror’s face, let us say) was infinite things, since I distinctly saw it from every angle of the universe. I saw the teeming sea; I saw daybreak and nightfall; I saw the multitudes of America …\n\nAND SO ON.\nIn April 2003 at a party in San Francisco, after a particularly lengthy run-up, we managed to manifest the Aleph, an actual centre of the universe, a single point in space and time in which all else is contained, infinity hanging in the air, there for the taking, right in the middle of our group.\nReader: I ate it.\n",
    link: "/home/2022/09/22/filtered",
  },
  {
    title: "We are already midway through exploring the galaxy (probably)",
    date: "12.16, Thursday 29 Sep 2022",
    content:
      "The von Neumann probe is a proposed method for the rapid, automated exploration of the universe.\nPremise:\nAn interstellar probe is designed such that it can self-replicate. When it arrives at a star system, it hoovers up the local asteroid belt, then uses a built-in 3D printer to print out 1+ copies of itself. Copies then head off to new star systems; rinse and repeat. The spread is exponential.\nThe lineage! As far as I can tell, this history goes a bit like this…\nONE: John von Neumann is the super genius who came up with both modern computer architecture, programmable computers (disputed), and also the nihilistically practical atomic era defence policy of Mutual Assured Destruction. In the 1940s he came up with cellular automata (e.g. Conway’s Game of Life), and from there the philosophical concept of a (software) machine that could reproduce itself: the universal constructor. Which is a wild idea: the “machine” has to contain both the schematic of the machine plus also the apparatus to recreate the schematic. In code terms it’s a wonder that it could possibly fit.\nTWO: Separately, in 1960, Robert Bracewell tackled the problem of how to communicate with advanced societies elsewhere in the galaxy. In Communications From Superior Galactic Communities (Nature; here’s a PDF) Bracewell suggested that, since radio signals would be too faint over great distances, it would be a better idea to send a smart interstellar probe and then open the conversation locally.\nTHREE: Project Daedalus, 1978, the first full engineering study of what it would mean to actually build an interstellar craft. As previously discussed but here’s the tl;dr: it’s huge. Twice the height of a Saturn V and almost the same in diameter, it has to be huge for speed and for reliability.\nIn 1980, ALL OF THESE COME TOGETHER:\n\nA major alternative to both the Daedalus flyby and “Bracewell probe” orbiter is the concept of the self-reproducing starprobe. … In theory, each self-reproducing device dispatched by the launching society would become an independent agent, slowly scouting the Galaxy for evidence of life, intelligence and civilization. While such machines might be costlier to design and construct, given sufficient time a relatively few replicating starprobes could search the entire Milky Way.\n– Robert A. Freitas Jr., A Self-Reproducing Interstellar Probe\n\n(Actually it seems like the general idea emerged in fiction in the late 1970s, and this was the first feasibility paper? I will have to dig into this more…)\nRef.\nFreitas, R. (1980). A Self-Reproducing Interstellar Probe. Journal of the British Interplanetary Society, 33, 251-264.\n(Yes this is in JBIS. I love JBIS.)\nFreitas’ paper is brilliant and deeeeep.\nREPRO (the self-reproducing probe) weighs in at 1,000x the mass of Daedalus itself, 10 billion kg.\nI had trouble visualising that and fortuitously found some great comparisons on Quora: 10 billion kg is a little under two Hoover dams, or the total mass of chicken consumed in the US every year. A single probe!\nThe probe, REPRO, arrives at a star system and drops SEED. SEED has two jobs: to explore, and to build FACTORY. FACTORY is what constructs and launches more REPROs.\nThe actual reproductive apparatus consists of 13 distinct robot species, including:\n\nChemists\nMining (atmospheric, in the atmosphere of Jupiter-like planets): An Aerostat robot floats like a hot air balloon in the jovian air\nMiners (misc.)\nMetallurgists\nComputers with abilities such as lateral thinking and intuition.\nFabricators\nAssemblers\nWarehousers\nCrawlers (for surface hauling)\nTankers (for fuel transportation)\nWardens (manipulators and maintenance)\nVerifiers\nPower plants\n\nIt is anticipated it would take 500 years for SEED to build FACTORY (step 1), and a further 500 years for FACTORY to duplicate REPRO (step 2). Over 5,000 years, 10 self-reproducing interstellar probes could be constructed and launched.\nSexual reproduction:\nAt the end of Freitas paper, he points out that the offspring of the von Neumann probes will likely be imperfect replicas. There will be data mutations along the way.\nBUT! This provides for the possibility that some mutations may be beneficial. Oh, so we get evolution. But it’s too slow.\nMajestically: Freitas then alters the REPRO design to include sexual reproduction, which he calculates will accelerate evolution enough to have a significant impact during the exploration time of our galaxy. There would be, he says, enough time for machine speciation to occur.\nAND SO:\n\nNiche specialization is plausible and there is a remote possibility that a simple machine ecology might have time to arise, complete with predators and prey. Sexual starprobe designs may be imagined as REPRO vehicles preprogrammed for target star overlap every few generations. The usual reproduction scenario might then include two starprobes landing on opposite sides of the same jovian moon and jointly engaging in the construction of two FACTORY complexes and two REPRO offspring. Memory Caches could be compared, evaluated and edited “consciously,” offering the exciting possibility of yet faster development by means of intelligent participative evolution.\n– Robert A. Freitas Jr., A Self-Reproducing Interstellar Probe\n\nAha hahahahahah.\nEmphasis mine.\nCan we just take a moment to appreciate that this is at the tail end of an engineering feasibility paper. If I were an academic reviewer, I would 100% insist that they all had mind-bending and poetic speculative conclusions like this.\nIn my head, before today, a von Neumann probe was something like a starwisp – a probe the size of a smartphone strapped to a giant solar sail. Lightweight, tiny, quick. Using, a don’t know, a drill bit and a special-purpose printer, it would be able to land on any asteroid and build a general-purpose printer which it would then use to reproduce itself.\nWhat I love about Freitas’ paper is that it shows how hard a real von Neumann probe would be. And heavy! And slow!\nIs the Freitas design for a von Neumann probe too big?\nIf anything I think REPRO is not big enough.\nI mean, I don’t know, but in the latest JBIS there’s a paper by Stephen Ashworth with a line that made me shift my perspective:\n\nAny self-replicating probe must carry a complete embryonic industrial base in its payload -  a seed economy - capable of recreating the infrastructure which built it in the first place. It should be clear that the total mass of the mature economy needed to build an interstellar probe will be greater than the payload of that probe, thus growth will be an inherent feature of the seed economy.\n\n(The paper is Self-Replicating Interstellar Probes and Runaway Growth Reconsidered and Ashworth maintains an archive of his papers, although this one isn’t online yet.)\nFACTORY is an industrial base!\nFACTORY is a whole economy!\nI’d been thinking about this in terms of robots – but 5,000 years is pretty much the whole duration of Western society! Some robots.\nWe can’t even run computers from a few decades ago without human maintenance – and that maintenance is provided by the tip of a pyramid of university education and surplus labour that allows for a cadre of specialistic computer historians!\nHow much would you actually need to boot up and run an industrial economy, from scratch, to copy and launch an interstellar probe (the launching of which would take a meaningful fraction of global GDP and energy budget) – given your economy also needs to maintain and grow itself?\nAnd don’t forget that the industrial base templated in REPRO needs to be robust enough to function in whatever star system it finds itself in… ones with scarce heavy metals, ones with violent radioactive stellar storms, ones with dim and dying binary stars, ones dominated by a single Jupiter-type and all the good stuff is stuck at the bottom of a gravity well, ones that are still an accretion disc, etc.\nWhat if the minimum size of FACTORY is effectively the same as human history and human civilisation?\nVon Neumann probes might have to be way bigger than starwisps.\nOh! So perhaps we are FACTORY.\nPerhaps all of human life is basically the larval stage of a self-replicating von Neumann probe.\nWe shouldn’t be looking out with our radio telescopes for the galactic spread of self-replicating explorers, we are the galactic spread.\nI feel like I’ve finally gotten the joke which is decades old. The point of the von Neumann probe thought experiment is that we are the von Neumann probes, or at least a single iteration of them.\nWell I got the gag eventually I guess.\nITERATION 1:\nPerhaps we’re the first iteration of the von Neumann probe. Perhaps our civilisation is the first FACTORY, and we’ll eventually make a probe (or whatever) that copies human civilisation to new star systems, and so on and so on.\nIf our actions and values today result in a successful REPRO construction, then the very same actions and values will be replayed countless times in countless star systems across the Milky Way. \nIn which case I’m reminded of Alasdair Gray’s line engraved on the Scottish parliament building, Work as if you live in the early days of a better nation.\n(Itself a mutation of a line from Canadian poet Dennis Lee.)\nWork as if you live in the first iteration of exponential galactic exploration?\nHello, fellow FACTORY worker.\nITERATION N:\nHowever.\nThere’s Nick Bostrom’s argument that we live in a simulation, as discussed: if there would be vastly more simulated minds than base reality minds then, by weight of numbers, you and I are more likely than not to be in the simulation.\nBy analogy:\nIf human civilisation is a single iteration of a von Neumann probe exploring the galaxy, and given that there will be hugely more iterations than beginnings, then by weight of numbers it is highly unlikely that our civilisation is iteration 1. Call us iteration N.\nTherefore we can learn about aliens by introspecting ourselves: who would design a self-replicating machine that unfolds into an industrial base that looks like human civilisation? Like us?\nHow would they think?\nCould we trace the path back and find them? (I mean, surely yes? Because the probes will be sending messages of their discoveries back to base, somehow.)\nHey: look at whatever device you’re reading this on. Look out of the window; look up and down the street. Listen to the traffic. This is the sound of the universal constructor in action. Look at your hands. Witness FACTORY.\n",
    link: "/home/2022/09/29/interstellar",
  },
  {
    title: "Basic mental arithmetic for activity and weight",
    date: "19.05, Tuesday 4 Oct 2022",
    content:
      "Lockdown plus having a kid really did a number on my personal fitness.\nHaving never really thought much about my weight, suddenly in my mid 40s I have found myself having to acquire new mental models so I can manage it.\nWhat happened? Routines changed I guess. For years I have been in a happy orbit of food, time in the day, activity, and weight, and it all just sort of kept itself steady.\nThen I was training a bunch before the first lockdown, running probably 30+ miles/week, in happy equilibrium. Then lockdown meant the training stopped… completely… but the eating not so much…\nAnd with kid timetable stuff (which was new), and not leaving the house because of remote working stuff, and snacking more in the evenings because I’m at home stuff – I guess I got knocked sufficiently far across phase space that I left the attractor basin and didn’t automatically fall back into the “healthy weight” orbit.\nLong story short I put on 15–20 lbs, and I’m still 15 lbs over. Whoops.\nSIDE NOTE:\nPeople older than me in the UK think of personal weight in stones and pounds (there are 14 lb in a stone). People younger use kilograms. I’m transitional, first gen metrification. So I learnt both at school and can feel the heft of both in my hands, but my intuition is stones. Here’s the cheat: 1 kg ~= 2 lb.\nSo I now use some ballpark figures when I’m correlating weight and activity. Here they are.\nRoughly speaking, I burn\n\n100 calories per hour being awake (actually 75/hr being alive, but I find the maths easier this way)\n100 calories per mile run or walked\n100 calories per 15 minutes hard exercise (like HIIT)\n\nIn a day, I have a calorie surplus or deficit. That converts directly to fat, which is either added or used up. The equation is this:\n\n1 lb fat = 3,500 calories\n\n(Yes I know it’s more complicated than this given muscle and metabolism etc, but it gets me close enough.)\nLet’s say I’m 15 lb over my target weight. That means I need a cumulative 52,500 calorie deficit to shed the fat. Or 287 calories/day over 6 months.\nOr, to put it in more useful terms: a deficit 2,000 calories/week, which is 20 miles/week running assuming fixed energy input. Ok, I can train towards that!\nEXCEPT: the final factor is that I also have upward velocity to shed.\nFor example if I’m putting on a pound every couple of weeks then that means I’m eating at an average 250 calorie daily surplus. I don’t want to cancel that upward velocity with training (that feels like fighting against myself) but I can watch what I eat instead.\nCalorie counting every meal doesn’t appeal, but I’m fine with trimming and paying attention to the second time derivative of my weight. So that’s what I do: adjust my snacking and my portion sizes until my weight is stable.\nWhat’s neat about this approach is I’m not really having to pay close attention to what I eat, or sum daily intake, or go on a “diet” or anything like that. I’m just tweaking habit parameters based on current dynamics.\nMy overall goal, I suppose, is to build an intuition of the local shape of the manifold in order to move from one trajectory to a nearby but different one, ideally a homeostatic orbit. I don’t want to have to think too hard about keeping healthy.\nI imagine for other people this is one of (a) unnecessary; (b) obvious; (c) not nuanced enough. For me this basic arithmetic hits the sweet spot.\nIt helps that I love running! Though finding time is hard. And it’s disheartening to have to really push through only 3 miles when I didn’t even blink at 13 not too long ago.\nAnd of course there’s all the other related considerations about nutrition, like cholesterol and heart health, and glycemic index and afternoon slumps, and calorie absorption rate and glycogen on long runs, etc, but this isn’t about that. \n",
    link: "/home/2022/10/04/calories",
  },
  {
    title: "I wish my web server were in the corner of my room",
    date: "20.39, Monday 10 Oct 2022",
    content:
      "Back in college I used to run part of my website from a Linux box in my room. I made it into a speech synthesiser, and people could connect to the machine to talk into my flat.\n(Retrospective apologies to my flatmates.)\nThis is way back in 2000 so before smartphones, and before texting, and before always-on internet (college was an exception), and before camera phones or being able to reliably email photos let alone video. Decent text-to-speech still felt novel. We had a friend who was travelling in Australia at the time and he would visit internet cafes and type in messages to talk to us. Of course there was no way of talking back. It felt impossibly magical.\nBut what I remember feeling most magical was the idea that there was somebody visiting that server on my desk. There was somebody coming from a long way away and going inside. An electronic homunculus.\nI could hear the hard drive spin up if somebody accessed the machine, and a little chug-chug-chug while Festival (the open source text-to-speech engine I’d installed) generated the voice. Like footsteps approaching before the door opens.\nI can have this experience again!\nI was chatting with artist honor ash the other day.\nTheir website (and also blog) runs on a Raspberry Pi sitting in a corner in their house.\nThis feels very important.\nFirst there’s the feeling of “I made that!” which leads to the feeling of “I can make all kinds of things!” You will definitely get that more when you install the software on the web server yourself, and also when you copy over your own hand-coded text files. (The web is just text!)\nThen there’s the feeling that people are visiting and - the corollary - if other people’s experience of your website is just in that tiny box, then your experiences of all other websites are similarly physically located in boxes too.\nIf you have a local web server then you can play music into your space.\nKarey Helm’s old website, back in 2015:\n\n…the portfolio on her website offers Party Mode. Click the button at the bottom of the page, and mouse over the various projects - the page becomes an instrument, it’s like a synth! And then, I swear I heard this right, when you use Party Mode, there’s an Arduino in her studio that plays the music.\n\nOnce again I am desperate to have this for myself.\nALSO: those solar-powered websites. I can totally visualise the photovoltaics on the website owner’s balcony in Barcelona whenever I read an article there.\nI will also say that it feels transgressive.\nIt is boundary-violating, to have a website in the corner of your bedroom. Websites are meant to be in the cloud. Eternal, somehow, transcendent, like the voice of code floating down from the sky. But no, there it is. It is real! I can kick it! Argumentum ad lapidem.\nThe discombobulated feeling is not new. Seeing a server felt weird even before the cloud.\nJulian Dibbell’s My Tiny Life was written in 1998 about multiplayer text adventures - early virtual worlds - and it is one of those books that has abruptly become insanely relevant. Chapter by chapter it goes through identity play (and abuse), cybersex, money, community governance, power, doxing, and the odd existential self-obsessed angst that all online communities seem to journey through.\nThe system in which Dibbell is hanging out is called LambdaMOO, and there’s a passage in which he visits the server.\n\nThe_Author looks at The Server.\nlook server\nThe Server\nYou see a box as unremarkable as any other in this room, only more so. Three feet square by one foot high, some cables slithering out the back, no flickering lights or any other outward indication of activity within. The box sits at about knee level, stacked unceremoniously on top of another one just like it.\nThe_Author has come 3,000 miles to look at this machine.\n– Julian Dibbell, My Tiny Life (1998)\n\n(That link leads you to the full text, but you should buy the book (Amazon) and I don’t know just sit by the letterbox until it arrives and then INHALE it.)\nDibbell is underwhelmed… and yet still holds onto his fantasy:\n\nThe_Author realizes now that during all those months he never really doubted LambdaMOO was in this box, compact, condensed, its rambling landscapes and its teeming population all somehow shrunk down to the size of The Server’s hard-disk drive.\n\nI can relate! I can relate!\nSeeing your website’s actual server is the virtual equiv of the Overview Effect and I want to have that feeling the whole time!\nI want to feel like my room is haunted by miniature cyberghosts whenever someone reads my blog!\nI want you to have that feeling too. I think it would change how we think about the internet, in a grounding and healthy way. I think it would help us regain a sense of agency and ownership, with which we would be way more demanding of the sort of internet we want to live with, a sense that is currently so distant from us that we have forgotten it is possible and can’t even tell that it is missing.\nSo… practically: how to achieve this in 2022?\nHaving a Raspberry Pi serving a website at home is relatively straightforward with a bit of work, I know.\nBut I would also like it to be reliable if I kick a cable out of the wall, or in the unlikely event that I get a bunch of traffic. I’d also like it to be quick!\nOh, and I don’t want to have my home network hacked.\nPerhaps there’s a way to host my website at home, but have the static bits served by Cloudflare if the Raspberry Pi isn’t available (using a global CDN as a UPS), and the dynamic bits always visit my home – but there’s a graceful “come back later” message if the Pi is down?\nI’m pretty technically capable but I’m not sure I can be bothered.\nThere are so many things in the way. Getting a routable IP address at home. Making it secure. Monitoring it. Gracefully stepping up and down from the CDN.\nI would love a turnkey way to home-host.\nHere’s the BIG question: even if it works as above, it’s still a bit of a hacky compromise to have my web server sitting on a shelf. How could it be easier than a monthly rental fee for cloud hosting? How could it be extra? Sure, ambient beats playing into my home office when somebody visits this blog… but what else? There’s a project here.\nUpdate 12 Oct:\nThis post made it to the top of Hacker News and stuck around for a bit. Blimey, hullo! Here are the comments (367 right now). Some lovely anecdotes there. Here’s a favourite:\n\nI had a URL on my website called moo.html that wasn’t indexed. My friends had it bookmarked, and when they visited it they got a picture of a cow, but it played a cow mooing in my bedroom. It was a nudge to come online and be social.\n\nThat’s it! Mixing up the boundary between virtual and physical.\nI don’t think it’s just nostalgia (that’s something that came up on Hacker News and also the replies on Twitter). It should be easy to have a publicly accessible webserver at home with a bolt-on cloud-based load balancer in the event that I get a burst of traffic or my home internet goes down. And there’s no reason that should be any less reliable or straightforward than hosting in the cloud. There’s nothing intrinsically hard about it.\n(Clarifying what easy means: easy means straightforward tools that work well together, and config files that keep the same format for a decade+. Command line beats GUI because I can keep notes and config in git.)\nWhy? Because being in the same room as your server will open up new opportunities. Playful ones at first and then… who knows what? My own bookshelf Raspberry Pi has an e-ink clock on it so perhaps I’ll use that as a little window to show me visitors.\nOh hey, I found my original blog post with the embedded form that spoke words into my flat. The form doesn’t work now of course, but here it is for posterity, way back in May 2000.\n",
    link: "/home/2022/10/10/servers",
  },
  {
    title: "Filtered for the miracle of writing",
    date: "22.10, Wednesday 12 Oct 2022",
    content:
      "(A note for new readers: these irregular Filtered for… posts are different from my regular posts in that each is a grab-bag of links and thoughts on a loose theme. There are more here.)\n1.\nHilary Mantel, astounding author of Wolf Hall and more, and a huge loss (RIP), experienced an evil miracle when she was young.\n\nShe was seven or eight, and she was playing in the garden behind her house. She looked up. There was something there, in the coarse grass beyond the gate. …\nIn her memoir, she says that she cannot write about this-technically, her prose isn’t up to it.\n– The New Yorker, The Dead Are Real: Hilary Mantel’s imagination (2012)\n\nHer prose isn’t up to it!!\nFrom Mantel’s memoirs:\n\nI can’t see anything, not exactly see: except the faintest movement, a ripple, a disturbance of the air.\n\nAnd:\n\nThere is nothing to see. There is nothing to smell. There is nothing to hear. But its motion, its insolent shift, makes my stomach heave. I can sense–at the periphery, the limit of all my senses–the dimensions of the creature. It is as high as a child of two. Its depth is a foot, fifteen inches.\n\nShe said: My first thought is that I have seen the devil – a non-rational intrusion into a rational universe.\nI’m very drawn to the idea of individual micro miracles (good and evil) and do my best to watch out for them. I put miracles in the same bracket as a glitch in the universe, or ‘pataphysics, and luck too – phenomena are not required to be explainable to be real, but you do need to be ready to spot them.\n2.\nGosh.\n\n\n\nAn advent: ancient archangels architect abstract astronomy and arid asteroids. \n\n\nAll asteroids are amorphous and absent; And all asleep across aquatic anarchy. And astral angels advanced across area.\n\n\nAnd Almighty asked,” Appear.” And all appeared aglow.\n\n\nAnd Almighty approved. Aura and absence: an antagonistic arithmetic.\n\n\nAn afternoon and aurora, an aeon.\n\n\n– Llamas and My Stegosaurus, Alpha (A Translation Of Genesis 1)\n\n(It continues.)\nSomething magical and fresh about seeing those familiar words transformed.\nA note accompanies the translation:\n\nthis was made with the help of a computer program that tries to express the meaning of any word by an adjective and a noun pair. Phrases like “abstract astronomy” for “space” and “aquatic archipelagos” for “islands” were generated by the program.\n\nIt’s from 2017. Is this the kind of thing GPT-3 could do?\n3.\nJohn McPhee, essayist, master of prose, explained that his last step is to go through his draft #4, word by word, and lift up everything. His turn of phrase is often unexpected and always precisely apt.\nTo do that McPhee, king of words, uses a dictionary.\nNot any dictionary:\n\nA book where you can enter “sport” and end up with “a diversion of the field” - this is in fact the opposite of what I’d known a dictionary to be. This is a book that transmutes plain words into language that’s finer and more vivid and sometimes more rare. No wonder McPhee wrote with it by his side.\n\nWebster’s 1913 is special:\n\n… go look up “flash” in Webster’s (the edition I’m using is the 1913). The first thing you’ll notice is that the example sentences don’t sound like they came out of a DMV training manual (“the lights started flashing”) – they come from Milton and Shakespeare and Tennyson (“A thought flashed through me, which I clothed in act”).\n– James Somers, You’re probably using the wrong dictionary (2014)\n\nThat piece concludes with instructions on how to download and install Webster’s 1913 on your Mac, iPhone, or Android device. (I’ve done it.)\n4.\nWriting!\n\nThe brain is an intricate, sparkling, densely interconnected maze-an easy place for ideas to hide in vague generalities. But writing forces you to commit to specifics as surely as surfers must commit to waves. …\nBy externalizing your thoughts, writing puts you into conversation with yourself.\n– Eliot Peper,  Writing is a Tool for Making New Ideas  (2022)\n\nEliot quotes me in that essay and I want to expand.\nWriting, as a process, is almost impossibly inventive. I know it, and know it, and am reminded so often, and yet – how on earth do new angles spontaneously emerge, from merely grinding through the words?\nIf I were to ask around about what writing is and why it’s important - in a bigger sense - I guess that I would hear:\n\nIt’s a communication technology – speaking at a distance! To many people!\nIt’s accretive – libraries matter – writing is a civilisational hard drive.\n\nYet also, as Eliot says:\nWriting is a technology for making new ideas, and what an accelerant!\nHow long have we had writing? Since the Sumerians, a comparatively recent invention.\nGPT-3 is an idea machine, as previously discussed. Writing is a kind of GPT-3000BC.\nI literally don’t understand how I can be 1,000 words into a piece that I’ve been tinkering with for a month, trying to explain an idea which is already in my head, and I’ve been thinking about it and around it for weeks, then I surprise myself as I do the work of writing and it totally turns around and then opens up a new avenue. I mean: how.\nYou don’t need to write for anyone else. You don’t need to share, or even keep it. You just need the act of it. Writing is a particle collider for reality and the imagination. And new discoveries are the result.\n(That’s why I write here, of course. It’s how I think.)\nSo what does writing mean, in a historical sense? Would we have come as far as and fast without it? Is that measurable.\nIn terms of impact I feel like this aspect of writing, the personal aspect, is undervalued. And I wonder, taking this perspective, if we could build tools to do it even better and even faster.\n",
    link: "/home/2022/10/12/filtered",
  },
  {
    title: "1,000 shops in your pocket",
    date: "21.13, Tuesday 18 Oct 2022",
    content:
      "Online shopping could be so much better. We’ve been doing it this was since the World Wide Web was the Big New Thing, and a bunch of patterns have ossified but they’re no longer relevant. It’s not easy to imagine better shops - great shops - fun shops - because we’re so used to them being hyper-optimised marketing machines, these incredibly functional meat-grinders for commerce, but I think you just have to think about stores irl…\nThere’s a line from the late 1700s that Britain is a nation of shopkeepers. (I’ve always heard that it was said by Napoleon but it turns out it was originally from Adam Smith.)\nI have a soft spot for this stereotype, pejorative sense aside, because my second job was being the Saturday boy at the local ironmongers and all village life passed through there. (My first job was accidentally doing secretarial work for a dope smuggler. Another story.)\nSo a store is more than a place to buy things.\nI’ve misplaced my copy of Paco Underhill’s Why We Buy (Amazon; 1999) which I remember as a kind of ethnographic pseudo-science of retail environments: shoppers tend to turn left; shoppers need a place to slow down and look around when they enter but get them out of the way; shoppers will abort purchase if someone squeezes by and brushes their bum; and so on.\nBUT it provides a focus on the store as a place that creates feel – whether that’s architecture connoting abundance or hot people at the entrance. Brand. (Ugh.)\nAnd aha! I’ve just found this collection of quotes from Why We Buy which includes this on e-commerce:\n\nSomeday, I believe, cybershopping will have an added attraction: it will be fun. … I’m amazed that no shopping web site stars a living being on-screen to welcome shoppers, guide them through the site and answer questions.\n\nCybershopping – yes! We’re waiting. Two decades ahead of its time.\nOnline shopping is a total mess in that it barely takes the opportunity to create story and experience. “Drops” are the closest we get to excitement. Instead we shopping online is indistinguishable from filling in a spreadsheet. An infinite department store catalogue.\nAlthough that’s mean on department stores. Department stores are innovators.\nA hundred years ago, department stores were early adopters of escalators.\nThe history of escalators:\n\nBloomingdale’s in New York removed its staircase and installed an inclined elevator in 1900. Macy’s followed suit in 1902. The Bon March’e in Paris installed the European “Fahrtreppe” in 1906. Escalators made department stores commercially viable entities in ways that stairs and the elevator simply could not. Vertical expansion of the stores into upper levels was now as viable as horizontal expansion, but at a fraction of the cost.\n– Smithsonian Magazine, How the Escalator Forever Changed Our Sense of Space (2019)\n\nBut that presupposes there are people who will walk through the doors.\nStores need footfall, in addition to feel, and they get that either by placing themselves somewhere already popular, or by becoming the destination.\nFootfall!\nThe thing is with shops on the web is that once upon a time they made a ton of sense because people spent time actually browsing the web.\nToday? Not so much.\nWhich is why we individual stores resort to aggressive email marketing, and the rest is dominated by retailed large enough to colonise mental real estate: Amazon basically.\nE-commerce in the early 2020s is the equivalent of heavily signposted out-of-town stores. Maybe it would be better to put the shops where the people are? Fish where the fish are.\nWhich is why I haven’t been able to stop thinking, since I first saw it, about KFC Pocket Franchise.\n\nYour social media is valuable real estate. Build your KFC store on it\nFriends can buy exclusive deals directly from your WeChat social feed\n\nI think that analogy to real estate is super insightful. And the idea that I become a franchisor! Clever. Funny.\n\nClaim at any KFC and your franchise earns real cash\n\nI guess this only works if there is a sufficient urban density of KFCs. But I can imagine, just as I break for lunch, scrolling my socials and passing a virtual KFC, then deciding to pop in. The last step is to walk out and get my food but I was going to have to do that anyone.\nIt did well!\n\nTo 2,500,000++ stores in 120 days\nEven celebrities built KFCs on their social estate\n\nSocial estate.\nLook this is simultaneously genius and AWFUL. I admit that.\nBut it’s provocative, right? If this is going to be something that isn’t just me shilling for fried chicken by posting tweets with an affiliate code, it has to be something personalised, something like a destination, something with feel. It’s a brilliant challenge.\nI was talking last year about the public internet thinning out and everyone disappearing into discords etc. Which means we need new ad formats. I suggested three, one of which was micro-influencers: how can a brand have 100,000 influencers?\nPeople love to be associated with the brands they love! Think stickers on laptops, or liking the Patagonia page on Facebook.\nDo people love KFC as much? Well perhaps some people. It’s not just love it’s hustle too. How could it be that people would see me as an entrepreneur, not a sellout?\n\nSo what does a storefront in my Discord profile look like?\nHow could I have a store hanging off my homepage that I’m really proud of?\n\nYou would take something like Shopify and make it so I could curate individual items in a MySpace-like environment, and the doorway is my user avatar. Something like that. You would see which of your friends were currently browsing. The whole purchase funnel would have to be managed within my homepage?\nLike Underhill says, I would probably want live staffing. Something the generic big box infinite department stores couldn’t offer.\nBack in the oooooold days (2007, insert weeping face emoji here) there was such a thing as a virtual book tour:\n\nthe increasingly popular practice of book authors touring blogs instead of touring the non-virtual bookstores of the US and staying in non-virtual and expensive hotel rooms.\n– kottke.org, Virtual book tours, the origins of (2007)\n\nLike… that? That’s what I mean.\nAuthors tours of social estate.\nOnly with persistent shops, like as a pinned tweet. And staffing.\nI would love a little event space hanging off my blog with talks etc.\nDunno. There’s something here.\ntl;dr – what if online stores were like really good.\nRELATED:\n\nMcDonald’s has created its smallest restaurant ever, but you’re not invited. Rather, the minuscule building, which features drive-thru windows, outdoor dining areas, and tiny Golden Arches on the roof, is actually a fully functioning beehive.\n\nI don’t think you need more than the headline: The World’s Smallest McDonald’s Just Opened & It’s For Bees Only.\n",
    link: "/home/2022/10/18/shopping",
  },
  {
    title:
      "Thinking about design pathfinding, which is a bit inside-baseball but forgive me",
    date: "16.18, Thursday 20 Oct 2022",
    content:
      "I ran across design pathfinding, a new-to-me phrase, so I’ve been reading up.\n…and I can’t find much, except this, about pathfinding research.\n\nPathfinding research is the work that enables us to peek around corners and shine light on new pathways.\n\nAs it fits with other types of research (think of this in the context of, say, AI research about text synthesis, or research into VR interactions):\n\nStrategic research identifies longer-term aims or interests and means of achieving them. Foundational research illuminates the perceptions, needs, motivations, and/or pain points of the people you’re building for, yielding evergreen insights. To perform pathfinding research is to leverage both of these core components, triangulate data sources both within and outside your company, and find a lighthouse in the distance to steer your shipmates toward.\n– Crystine Gray, Meta Research, 7 Steps Toward Pathfinding Impact (2021)\n\nGray is at Meta, which figures, because the two people who (independently) said “design pathfinding” to me are both also from Meta.\nGray doesn’t mention design but does mention this: Cultivating visibility.\n\nExperiment with different versions of decks that speak to different audiences. Try videos, mini museums, trivia, workshops, and other creative ways to get others engaged in the insights. \n\nI like this! A very design way of thinking.\nPathfinding, per Gray, comes across as an approach which is orchestrated around external outcomes: not the local and internal “we learnt X” but instead “as a consequence the organisation did X rather than Y.”\nSo that’s pathfinding research. From there I think I can build a bridge to design pathfinding?\nNow there are all kinds of design methods for invention. Design fiction, prototyping, thinking through making…\n…and part of an invention project, if it is to be effective, is a focus on communication, creating change, informing strategy etc.\n(The methods I mention are all very material-first. There are user-first methods too of course and of course you use both. Though I feel like user-first approaches are more closely allied to the “scouting” function of a product org; different methods for different stages.)\nWhat grabs my attention about design pathfinding, as far as I understand it, is that the material-first design tools of artefacts, fiction, making, etc are all potentially employed, but also direction-setting and influence are goals and part of the conversation from day 1. It’s not an optional extra.\nThere is an intention to reveal a new product opportunity and make it compelling for others, or to uncover a research need and create the desire to get there, or to show a design route as right or wrong and as a consequence advocate for the next steps of investment of time and resources.\nNow that’s something that those of us who have been involved in design and invention would nod at impatiently, like, obviously, forever, so what’s handy is that there is a name for it. Not a neutral or inward-looking name like “design research” but a name that foregrounds the wider function and frames design as a journey.\nMaking plus building conviction, as a way to invent. I could align myself with that.\nSo I’m into this as an approach. Or at least as a label because I’m guessing what it means. Is “design pathfinding” a term with currency outside Meta? Is there anything else I should read?\n",
    link: "/home/2022/10/20/pathfinding",
  },
  {
    title: "Hey I’m passing through San Francisco next week",
    date: "17.30, Friday 21 Oct 2022",
    content:
      "Brief status update: I’m travelling through San Francisco next week to go hang out IRL with some buddies off a discord server and talk about the future. Because why not.\nAND SO: I’ll be in the valley Tues 25th, and in the city Tues night and the morning of Weds 26th.\nOld friends! There may be a handful of us grabbing a drink/dinner in the city on Tuesday. Drop me a note! Let’s see if paths coincide! Sorry for not messaging directly, this is a last-minute trip.\nOpportunistic hellos? I’m super interested (and currently working in) in the intersection of tools for thought, the multiplayer web, presence and small groups (and group/environmental computing), AI/NPCs etc. I would love to connect with folks doing design/research that touches this space, especially at the bigger firms. If that sounds like you then please do ping me (email/Twitter DMs), and maybe we get coffee when I’m in California or maybe we play a round of Walkabout Mini Golf in the metaverse (lol) when I’m back home, something like that.\nI feel like that was a bit of a dull post for almost everyone.\nSo here’s a live stream of a waterhole in the Namib Desert, Namibia (YouTube).\nI have this open a whole bunch in the background nowadays. Dawn is good. You often see animals throughout the day. You can hear the wind. I would love a widget on my phone’s lock screen that pings when there is a lot of motion.\nThere ought to be more dependable HD live streams to watch. The fixed view and lack of editing is what makes it work (the ISS cam jumps around too much). Maybe a not-for-profit could drop and maintain cameras all over the world; rainforests, mountains, cities. That would be good. Better than zoos. Bonus points: two cameras for VR. Binaural sound.\nHey and on satellites too, why not. Nasa should send a 4K webcam to the Moon. How much would that cost? Not much in the scheme of things I bet. They should send landscape artists to other planets. Why Hasn’t David Hockney Been Given The Keys To The Mars Rover Yet.\n",
    link: "/home/2022/10/21/ca",
  },
  {
    title: "Let me recruit AI teammates into Figma",
    date: "01.44, Wednesday 26 Oct 2022",
    content:
      "Okay sorry this is a post mainly about startup growth and KPIs. I apologise in advance.\nSo we’re on the same page, let me recap some hunches:\n\nThis is uncontroversial: AI synthesis has gotten really good. AI that writes code (given a ticket), or makes an illustration (given a brief), or writes an article or makes a diagram or summarises complex information (given a prompt) is here. The technical problems have been solved, and now it’s a matter of improvements, integrations, and UX.\nAIs will augment our teams. Sure a single engineer can have smart autocomplete, or an AI word processor can expand your text so you don’t have to type full sentences. But if you’re looking for 10x productivity improvements, then think about teams: an engineer will now be an engineering manager who is wrangling the code contributions of a dozen AIs, submitting their synthesised code as pull requests. A writer will work in a Google Doc alongside an AI editor making suggestions, and an AI fact checker and researcher doing the running, and an AI sub doing the wordsmithing.\nNPCs are a better UI for interacting with teammate AIs. Interfaces for all the different ways that AIs can help a team would be incredibly cumbersome – think of the bureaucracy of Jira etc! But if, in our Google Doc, our AI editor can appear as a “non-player character,” using all the regular features that humans do (presence, suggest changes, comments for clarifications etc), then there’s no need for extra UI – it’s just another specialist teammate. Ditto in Github, ditto in Figma, ditto in Zoom for video AIs. Humans and non-humans working together. This is why the multiplayer web is important: it’s a runtime for AIs.\n\nSEE ALSO: Designing user interfaces with bots not buttons.\nOk so we’re got a capability and an interaction paradigm. What’s missing is the economics.\nRevenue is a lagging indicator. What I mean by economics in this context are the metrics that precede revenue: acquisition and retention.\n\nUsers will pay for valuable software – but only if they (a) find out about it, (b) use it, and (c) continue using it\nSoftware that is forgotten (has low retention) will eventually not be paid for\nThe model for paying for software has to correspond with the underlying costs of the seller.\n\nThis is worth figuring out because otherwise this new model won’t emerge. Companies offering the service won’t grow.\nSaaS was an innovation that unlocked Web 2.0 (in b2b). Selling software as a service meant that:\n\nSellers can cover their ongoing developments and running costs because they get to charge per user per month\nRecurring revenue unlocks the ability to experiment with free trials and other customer acquisition tactics; and once the metrics CAC and CLTV were developed, it was possible to engineer growth, not just hope for it.\n\nThis model doesn’t hold in the “AI teammate” world, so we’ll need to find something to replace SaaS:\n\nCompute is a meaningful expense for AIs, unlike Web 2.0. It doesn’t make sense to charge per month for an AI editor if the difference between editing 1 article and editing 10 is a meaningful number of dollars to run the models\nIf free trials are off the table, how does acquisition work?\n\nMore problems! Given these AIs aren’t essential tools that you open again and again, what’s the retention mechanism? How will users remember that their AI editor teammate function can be invoked?\nHere’s a guess: social discovery is the key.\nPerhaps app features should be ownable and tradable. A pocketful of feature flags. In short: instead of having thousands of features, mostly unused, undiscovered in a thousand menus, you would see a colleague using a feature in a multiplayer app (like an editing feature in a doc, or co-presenter in Zoom), and then… they could just give it to you. (Or you could buy it.)\nOr to put it another way, adopting the NPC = UI metaphor: with AI teammates, instead of having to find the “editor” function in a menu, you would be introduced to the editor NPC in a multiplayer space. (This is why I care so much about the multiplayer web.) You wouldn’t purchase or subscribe, you would recruit.\nThis takes care of awareness and also the de-risking part of acquisition currently catered for by free trials (if you see somebody else’s editor NPC in action, you’ll already be 50% convinced).\nThe revenue model is secondary but I think, to begin with, it’ll be a bit like buying credits. You’ll buy X photos synthesised per month, or something like that, and step up and down tiers. Your photo synthesiser NPC (or editor NPC, or engineer NPC) can let you know when you need more.\n(Monthly subscriptions won’t work because of the highly variable underlying compute cost. I’ve already seen a few AI projects playing with credits, it makes sense.)\nThat’s discovery and revenue. What about retention?\nThe more I think about this, the more I realise that this is a part of the “AI synthesis” capability set which hasn’t yet been built.\nLet’s imagine we have an AI teammate. If it’s like today’s software then, for anything powerful, you’re going have to hit a button. But teammates don’t wait to be instructed to take on a task, they jump in.\nA human editor teammate will maybe make a single suggestion on a doc, and - if you accept it - they will go ahead and do the rest of the work.\nIf they’re feeling underutilised, they’ll reach and actively ask you for things to do – if a clear route isn’t evident for a task, they will request the prompt. Or they’ll keep an eye on your shared files and projects and make suggestions about where they could help.\nMaking this work will be hard.\nAI synthesis necessarily includes a view of what “good” looks like. What is a good image; what is good code; etc. That’s possible because we have a ton of images in the world; there’s a ton of code, and so on.\nBUT: AIs will also need to synthesise what good team behaviour looks like – and jump in. What actions will help the group? Where is it useful to jump in? What will further the goals of the org? How can that even be measured?\nAs far as I know, self-setting goals is an AI capability that doesn’t exist yet, and it’s beyond the scope of the type of AI synthesis that has been coming along in leaps and bounds these last few months.\nUntil we have it, I can see people making prototypes of AIs that are useful for teams, but I can’t see startups growing around them.\nWhat are the metrics that will allow for optimising all of this? Interactions per month. Mean social group size per introduction. Introductions per interaction. Unsolicited interaction rate. There will be a whole industry around measuring, correlating, and optimising these.\nHey, here’s another question: what’s the standard NPC API that a multiplayer app (like Figma etc) can offer, such that my new AI helper can join the team? Appearing in the presence bar, being invitable by @ mentions of their name, etc. \nA lot to do!\n",
    link: "/home/2022/10/26/teammates",
  },
  {
    title: "The topsy-turvy celebration of Guy Fawkes",
    date: "18.13, Thursday 3 Nov 2022",
    content:
      "So I’m vaguely resentful about celebrating Halloween because, since I was a kid, it has increasingly displaced the holiday which comes only a week after on 5th November: Bonfire Night. Which I love.\nBrits will definitely know what I’m talking about, and you probably do, but to recap for others who may not:\nBack in 1605, Guy Fawkes and a handful of other conspirators planned to blow up Parliament and King James.\nFawkes was caught in the act, in a cellar under the House of Lords surrounded by barrels of gunpowder, waiting to light the fuse, and tortured gruesomely.\nHe was seen as a Catholic terrorist and the story was used by the government to support anti-Catholic sentiment.\nThe propaganda started pretty fast: the Observance of 5th November Act was passed by parliament just a few months later, and required both church and public to give thanks for the failure of the Gunpowder Plot.\n400+ years on and we still celebrate. There are bonfires and optionally fireworks. Guy Fawkes is burnt in effigy on the fire.\nOur local community garden continues the standard tradition: kids in the neighbourhood make a “guy” (an effigy, like clothes stuffed with paper plus a face) and often the guy will be made to resemble some contemporary figure. In our community there is a prize for the best one. For example a couple years ago there were 5 guys entered in the competition: 3 Boris Johnsons, 1 Jacob Rees-Mogg, and 1 robot wearing a sign saying “technology.” Then all the guys are put on the fire.\nEveryone stands round the fire and stares at it. The bigger the better. It’s not very sophisticated.\n(The fireworks are pretty good though. There was a peak of huge public displays in the early 2000s, before austerity, and tons of people have fireworks in their gardens.)\nThere’s a wonderful duality to Bonfire Night:\nOn the one hand it’s a state-initiated thanksgiving. From a top-down perspective we are supposed to revile Guy Fawkes.\nBut the vernacular can only be seen as a celebration of Fawkes. Sure the plot failed but he almost blew up the king! Secretly wouldn’t we all like to etc.\nI’m not saying that anyone actually wants to be a terrorist during daylight hours, but there is an element of carnival to Guy Fawkes Night: the fire is primal, almost violent; it’s a pressure valve for our dark side, the part that wants to burn it all down. Then the next day, all is ok again.\nBrits and non-Brits alike will recognise the anti-establishment hero from V for Vendetta: the white mask with the pointy beard is the face of Guy Fawkes.\nI don’t know whether this is an actual trend or just what things look like from where I’m standing, but when I was a kid Bonfire Night was a big deal, and making guys too.\nNow it’s still around but it’s more of a folk celebration.\nInstead: Halloween. Trick-or-treating is a thing now, and adults in fancy dress (sexy costumes too). Witches and pumpkins and ghosts have always been around, but the level of Halloween merch in supermarkets, and the overall cultural and commercial scale of the thing – that’s new in the last couple decades.\nHalloween is Celtic originally isn’t it? But in its modern incarnation it’s an American holiday that we’ve absorbed through media and profit margins. And it’s great I guess.\nBut I love the simplicity of a giant fire and the janus-faced tangle of that ancient celebration of burning the guy and secretly imagining sticking it to the king. It rhymes a lot, in 2022, with the love-hate relationship I think many of us have with Englishness.\n\nRemember, remember, the 5th of November,\nThe gunpowder treason and plot.\nI see no reason\nWhy the gunpowder treason\nShould ever be forgot.\n\n",
    link: "/home/2022/11/03/fawkes",
  },
  {
    title: "These robot legs are made for walkin’ me to the shops",
    date: "17.08, Friday 4 Nov 2022",
    content:
      "Exoskeletons quietly got good while I wasn’t looking?\nFOR INSTANCE, LEGS:\nHangzhou RoboCT Technology Development Co. raised series A funding earlier this year: RoboCT’s UGO exoskeleton robot is a rehabilitation robot that helps patients who experience motor dysfunction in the lower body learn how to walk.\n100,000 UGO exoskeletons are already in market.\nThere are also passive exoskeletons. Ottobock has a series of unpowered exoskeletons that redistribute weight, for use in the logistics space. e.g. squatting, lifting, carrying are all easier.\nPowered again: these active exoskeletons, in use by the Chinese military (2021), list similar micro-benefits:\n\nIt is powered by a motor, which will give a reacting force to its user every time the user gets up after bending over, so the user can get up faster with less effort\none person can carry ammunition boxes weighing 50 kilograms without much effort\nIt takes less than 40 seconds to put on and take off the suit.\n\nExoskeletons don’t address use cases but instead augment, and I mean this in the Engelbart/Licklider sense.\nTo unpack that:\nFrom Douglas Engelbart’s Augmenting Human Intellect (1962) which is the approach that led his team to invent the personal computer: Every process of thought or action is made up of sub-processes. – for example: finding, copying, re-arranging, and filing text.\nIt’s a solid approach! Identify and speed up the sub-processes, then the tasks look after themselves. (Very different from today’s world of end-to-end task-focused service design, say.)\nEngelbart was following J. C. R. Licklider who made the original conceptual breakthrough after introspecting on his own work. In his paper Man-Computer Symbiosis (1960):\n\nIn the spring and summer of 1957, therefore, I tried to keep track of what one moderately technical person actually did during the hours he regarded as devoted to work. …\nAbout 85 per cent of my “thinking” time was spent getting into a position to think, to make a decision, to learn something I needed to know. Much more time went into finding or obtaining information than into digesting it. Hours went into the plotting of graphs, and other hours into instructing an assistant how to plot. When the graphs were finished, the relations were obvious at once, but the plotting had to be done in order to make them so. …\nThroughout the period I examined, in short, my “thinking” time was devoted mainly to activities that were essentially clerical or mechanical: searching, calculating, plotting, transforming, determining the logical or dynamic consequences of a set of assumptions or hypotheses, preparing the way for a decision or an insight.\n– J. C. R. Licklider, Man-Computer Symbiosis (1960)\n\nThe bottleneck to progress is not smart people, it is what is easy: my choices of what to attempt and what not to attempt were determined to an embarrassingly great extent by considerations of clerical feasibility, not intellectual capability.\nThis is a stunning result!\nIf you augment the sub-processes, not only are tasks achieved more efficiently, but you increase the surface area of the adjacent possible!\nAnd it’s the conceptual rhyming that underpins my interest in exoskeletons: what is opened up by augmenting sub-processes of the physical self?\n(To round out the story above: Licklider inspired Engelbart; Licklider funded Engelbart based on that paper in his capacity as director at ARPA; Engelbart’s team invented the PC. I wrote a potted history last year.)\nWhat are the civilian applications?\nThe last time I was on about cyborg prosthetics (2020) I said I wanted a chairless chair but for gardening.\nI’m still waiting! If you can get an active exoskeleton for squatting with a drill on the assembly line, then give me my powerloader to empty the dishwasher dammit.\nLike: eyeglasses were lame essentials and then they became fashion. I’m sure that exoskeleton knees to redistribute weight so I can more easily lift the sofa while hoovering would end up being cool. Somehow.\nLet’s not overlook AI. There’s the possibility of do-what-I-mean interaction that should let exoskeletons and other prosthesis fit right into everyday life.\nFOR EXAMPLE: why not an extra arm that I strap round my chest, and I can use the extra hand to just… hold stuff.\nLet’s say my 3rd hand can hold a mug of tea without spilling it as I go up and down the stairs, arms full with other stuff, and hand it back gracefully when I go to take it. Why wouldn’t I have that on me the whole time?\nAnyway I prefer somaforming to cyborgs nowadays.\nClynes and Kline’s “cyborg” concept from 1960 was derived from transforming humans into half-human, half-machine hybrids to survive the hostile environment of space (here’s the history).\nBut sci-fi author Becky Chambers, in her 2019 novella To Be Taught, If Fortunate proposes something else: Somaforming is an elegant solution, but not an immediate process. – somewhat akin to a patch that produces insulin.\n\nWe don’t change much – nothing that would make us unrecognisable, nothing that would push us beyond the realm of our humanity, nothing that changes how I think or act or perceive.\n– Becky Chambers, To Be Taught, If Fortunate (Amazon)\n\nIt’s a take on cyborging which emphasises the contingent, the temporary and partial, the human and the body; the process, the versatility…\nSomaforming for space? How about somaforming for everyday life.\nIt’s a framing that unlocks the imagination for me in a way that thinking about cyborg prostheses doesn’t so much.\nLook: the exoskeleton challenge is no longer technology. It’s what we do and how.\nAnd if we’re looking into the adjacent possible, then perhaps it’s more plausible from a consumer product R&D perspective to chase down robot trousers than robot cars. Why not, why not?\nDon’t give me autonomous vehicle cocoons to get me far away –\n– give me augmented legs to make it easier to hang out in my neighbourhood; to carry the shopping and spend more time in the fresh air and greeting people I pass; to cover ground with ease, to pay attention near traffic for me, to let me reply to an email or two on the hoof if I need to…\nTo somaform me for the walkable city.\n",
    link: "/home/2022/11/04/somaforming",
  },
  {
    title:
      "The Minecraft generation meets property law and AI-synthesised landscapes",
    date: "14.49, Tuesday 8 Nov 2022",
    content:
      "Yeah so I have a v loose feeling that, in technology, whatever you encounter first or do a lot of is “normal” and then you bring that as a template to whatever you make next.\ne.g.\n\nExcel then iTunes\nPokemon then Facebook (gotta catch em all)\nWeb indexes then foundation models (foundation models are the vast “aaaall the data, uncategorised” machine learning models underpinning GPT-3 and DALL-E)\nMinecraft then …what?\n\nA whole generation grew up in Minecraft. Peak years: early 2010s. I keep an eye out for when those expectations meet the world, and in what form.\nI don’t think the “metaverse” is related – too high fidelity, too corporate. (The lo-fi metaverse would be, if that were bigger…)\nMaybe the “cozyweb” trend? Cozyweb features in Venkatesh Rao’s 2019 internet map as collage-y, a cut-and-paste aesthetic; friends hanging out in the corners of the internet out of the full glare of the indexers. I’ve previously named this diaspora into sub-Dunbar spaces as virtual private neighbourhoods and maybe it’s a recapitulation of the DIY, small-group-social experience of a Minecraft server. But I’m not 100% convinced.\nOR: how about voxels?\nVoxels. 3D pixels.\nIn particular: 3D pixels that are chunky enough to see, pick up, and make things with.\nI don’t really care about voxels as an invisible underlying data structure of 3D virtual environments or scans; I do care about voxels that you can see. Like icons that are meaningful to the human and the computer. Fat voxels like Lego bricks.\nMinecraft players will have imprinted on fat voxels. I should, they will say to themselves in their deep unconscious, be able to sculpt the terrain of my computing environment. It should be obvious how to do that merely from the aesthetic.\nThere’s more and more 3D around.\nSo I look out for signs of voxels in the 2020s.\nI haven’t seen much tbh but occasionally there’s something from an unexpected source.\nFOR EXAMPLE:\nCharter cities and their foundational law.\nCharter cities are semi-autonomous, special administrative zones, carved out from their host country to run their own legal system and economy, often from a libertarian perspective.\nCAVEAT: I am intellectually intrigued by the idea! It’s like a philosophical thought experiment from Ancient Greece or science fiction that people live in. But morally it’s icky. You never hear of socialist startup societies. [UPDATE: Of course you do, I was being lazy. I mean in the new charter city movement.] The narrative is always “freedom” aka let people with existing power/money do what they want. However: I don’t believe any charter cities actually exist yet, so it’s ok to speculate about them.\nThere’s a proposed charter city on an island off the coast of Honduras called Próspera. Here’s the website.\nWhat would you do if you were designing a whole legal system from scratch in the 2020s?\nWell – I recommend reading this whole piece: Scott Alexander at Astral Star Codex did a deep dive on everything published about the new city, and here is the Prospectus on Pr’ospera.\nHere’s one small bit that caught my eye.\n\nPrósperan property is sold in three dimension voxels, eg 1m x 1m x 1m cubes, which is supposed to solve “air rights” debates once and for all. The idea is: imagine I have a house with a nice view of the beach, but my neighbor right in front of me wants to build a tower that blocks my view. Can he do it? In the US, the answer is “depends what happens after ten years of lawsuits and city council meetings”. In Pr’ospera, the answer is “depends who owns the voxels the tower is going through.”\nSo if I want to prevent my neighbor from building a tower and blocking my view, I can buy the air above his house that the tower would have to pass through; then if my neighbor builds there, he’s trespassing on my property.\n– Astral Star Codex, Prospectus On Próspera (2021)\n\nProperty law today is based on 2D land area maps, with a hodgepodge of rights to light etc to deal with 3D, and surely that’s partially because - historically - flat maps are easy to draw? And now we can deal with 3D maybe properly law can change the fundamentals to think about it differently?\nPerhaps.\nBut I wonder if the folks involved played Minecraft growing up.\nVoxels don’t have to look blocky.\nGANcraft by NVIDIA (2021): Unsupervised 3D Neural Rendering of Minecraft Worlds.\nMinecraft landscapes auto-transformed into forested hills, lush meadows, and beaches – check out the videos.\nSo I imagine a future VR experience that works a bit like this:\n\nYou’re exploring a beautiful landscape. You say “See voxels” and the resolution downshifts to Minecraft-like blocks\nYou edit the voxel map, a hill here, a tree there, changing the type of voxel for that building. You don’t need to be precise, it’s quick, a sketch\nThen: the prompt. The AI that will transform the voxel map is a generative AI configured by a prompt, so you give it a short paragraph about what you want this place to be: green fields, rolling hills, open skies, trending on artstation.\nExiting edit mode, your blocky landscape upsamples to photorealism once again, voxels prompted into a raytraced sunlit 3D virtual world.\n\nI don’t see why it should be any harder than that?\nI know there are 3D edit tools that allow precision, but I feel like fine control is maladaptive in this situation. You want to be able to make something gorgeous, and easily, and have full creative expression. That’s what voxels provide, plus the application of AI which - thanks to the prompt - has all the almost-infinite variety of latent space.\n(How soon? Using Diffusion Bee, the desktop version of Stable Diffusion, it takes 30 seconds on my M2 Mac to synthesise an image. So we’re ~8 Moore’s Law doublings away from realtime synthesised video at 10 inferences per second – I assume we can get to 40fps with non-inference tweening. 12 years till interactive hallucinatory VR! Gonna be wild. That’s an upper bound. I’m sure there are many shortcuts and optimisations which will get us there sooner.)\nOh: and when you see somebody else’s landscape, you want to be able to see how they did it, and have it graspable so you can copy it yourself. Voxels as View Source.\nDunno feels like VR (and AR, MR) will be a thing in the not too distant future.\nSo it’s worth thinking about ways that it can be a read-write medium. The environments that users make won’t have clean 3D models and precision-placed curves – instead they’ll be glitchy, piecemeal, ill-fitting, sketched. Accreted not architected. But they should also be easy and fun and decent looking and also, somehow, collaboratively constructed. Like playing Lego together, not working in some kind of prissy 3D Figma.\nIt would make for a neat, super customisable, multiplayer VR OS.\nIt strikes me that Minecraft blocks would be a good “language” for future users to have with the computer, and there’s nascent cultural readiness for it, and perhaps these fat voxels are somewhat under explored. It would be worth some R&D spend to figure it out.\n",
    link: "/home/2022/11/08/voxels",
  },
  {
    title: "Mapping everything I’ve written about the multiplayer web",
    date: "15.32, Wednesday 9 Nov 2022",
    content:
      "Two birds with one stone:\n1. Getting my head straight about multiplayer\nPremise: right now, apps and the web are generally single user, and multiplayer experiences (like Figma and Google Docs) are the exception. In the future my hunch is that multiplayer will be the norm.\nI’ve been tracking this transition for about a year and generally feeling out the consequences.\nAnd there’s so much to explore! When you assume multiplayer it’s almost like a lo-fi metaverse, which means the reference points are architecture and sociology and cinema. I’ve ended up thinking about how people socialise; various spatial metaphors; the value of serendipity; where this overlaps with AIs and NPCs; psychology and visual design… etc.\nSo I’ve a feeling that all of this comes together somehow.\nBut the first job is to map it.\n2. Experimenting with how readers find their way around this blog\nFinding old posts on my blog is hard. Which is a shame.\nSome rough stats: I’ve written 280,000 words here since the beginning of 2020, across some 320 posts.\nIt’s hard for readers to know where to start. It’s hard for me to find posts, when I’m referring back to something for my own research (it’s my public notebook after all). I noodle on this problem from time to time.\nThere’s a decent amount of interlinking (if you look at old posts, they always connect forward to follow-ups). I post a “best of” each year; some posts are categorised which is linked from the bottom; there are date archives. BUT: none of this is delightful or mind-expanding. You need see more than a post title when you’re exploring. You don’t get a sense of the domain given just a list. There’s no context.\nHowever. Maps!\nSince seeing Tom Critchlow’s Map of Inquiry (Open questions and areas of interest) back in January, I’ve been thinking about how to make a map of my blog.\nI tried to automate the process.\nIn idle moments, behind the scenes, I’ve been adding topics to posts and playing with auto-generated visualisations as a top-level overview. All the visualisations are rubbish.\nThen: a realisation. The map itself is my point of view. I can’t automate drawing the map because the map has to be something I author just as much as any blog post would be.\nAnd so: I mapped my posts about the future of multiplayer\nThe best way to experiment with making a map of blog posts is to actually make a map of blog posts. I have a topic to try first…\nSo I made an old-school mindmap of how I think about the emerging multiplayer web, then I hyperlinked posts from the archive. It’s clickable!\nExplore the map here.\nI think the map works, as an approach?\nIt’s ugly (the text is teeny and it doesn’t fit on small screens) and it’s kinda tricky to make (there’s no automation; I wrote the file in DOT and generated an SVG using Graphviz).\nHowever, assuming fixes, I would be pretty happy if the archive of this blog were a series of strong pov overviews like this – I think? A map would be a good, informative next step for anybody reaching the bottom of a post and wanting to read more.\nMore specifically, the map is functionally useful when it comes to this topic of “multiplayer.” I feel like it lays out a good chunk of my perspective, and possibly helps other people navigate that perspective better than prose would do. Plus I can see where I want to write more.\nA work in progress.\n",
    link: "/home/2022/11/09/map",
  },
  {
    title: "Filtered for ears",
    date: "16.17, Thursday 17 Nov 2022",
    content:
      "1.\nEar2Face! It is possible, given a photograph of an ear, for an AI to take a really good guess at the person’s face.\nRef.\nYaman, D., Eyiokur, F. I., & Ekenel, H. K. (2020). Ear2Face: Deep Biometric Modality Mapping (arXiv:2006.01943). arXiv.\nJust… just go to the PDF at the link about, and look for Figure 4 which is a grid of photographs of ears and actual faces and AI predicted faces. Please just do that for me. (Illustration preserved on my IG for posterity.)\n(Being realistic for a sec - the ear photo also includes a bit of hair, around the side and at the top. So you can get a sense of hair colour, which way it falls etc. Then you also get a good idea of skin tone, age, etc, and who knows what else is being picked up in that photo… it’s not going to be exclusively down to ear whorls. And actually, after getting those coarse features that even you or I could take a stab at, once you look closely at the illustration, you can see the AI is doing an okaaaay job but it’s not magical.)\nTANGENTIALLY:\nApple Support for Personalized Spatial Audio, by which the already incredible spatial audio on Apple AirPods is improved by photographing your ear geometry with the LIDAR-enhanced camera: To capture a view of your right ear, hold your iPhone with your right hand. Move your right arm 45 degrees to your right, then turn your head slowly to the left.\n2.\nVideo deepfakes: ‘live’, real-time deepfakes in video calls have not been a major cause for concern until very recently.\nI didn’t know they were a concern now! But apparently deepfakes of celebs are a thing on Tiktok - and the potential of a live video call on Zoom, say, which turns out to be a deepfake… it’s enough that there is some concern today. (It has never even occured to me that a WhatsApp/Facetime/Zoom from a loved one could be a deepfake.)\nAnyway here’s the trick:\nTo Uncover a Deepfake Video Call, Ask the Caller to Turn Sideways.\nSynths, deepfakes, are poor at rendering ears and profiles generally.\nThe point is not that there is a trick to identify synths on calls. The point is that, in order to get to the trick, first you have to suspect. And to have your synth-suspicion meter reach 100 on a call such that you ask the could-be-a-synth to turn to the side, that requires your synth-suspicion meter to be active always..\nOne day soon, in the back of head on all calls, we will all have to be asking ourselves: is this real? Nothing is real (2021).\n(Research idea: some kind of high trust proof-of-identity protocol that bootstraps off two people meeting IRL and can be carried into calls, like 2FA for person-to-person interaction.)\n3.\nIn-ear EEG!\n\nSuch headphones can then be used to perform electroencephalographies (EEGs). EEGs record the electrical activity on the surface of the brain. This activity may be affected by disease states such as tumors or strokes, as well as by normal functions such as eye-blinks or the auditory response. In the future, this technology can be used for lifesaving interventions by quickly diagnosing a stroke, or for mundane activities like pausing your music player with the blink of an eye.\n\nRef.\nKaveh, R., Doong, J., Zhou, A., Schwendeman, C., Gopalan, K., Burghardt, F. L., Arias, A. C., Maharbiz, M. M., & Muller, R. (2020). Wireless User-Generic Ear EEG. IEEE Transactions on Biomedical Circuits and Systems, 14(4), 727-737.\nSo that would be cool. There is a bunch of headroom in multimodal computer interactions (as discussed) and blinking is another channel.\nSEE ALSO, an ooooold idea: FuelBand for alpha waves (2012).\n4.\nBartosz Ciechanowski’s essay on Sound.\nFrom a model of molecules bouncing in a box, to understanding pressure, then pressure waves, then individual notes, then sound. Read this!\nSimple interactive simulations with a single slider, embedded in prose, are crazy powerful for understanding.\n",
    link: "/home/2022/11/17/filtered",
  },
  {
    title:
      "Microdosing cathedrals and the synthetic acoustic environment of the ancient world",
    date: "17.58, Friday 18 Nov 2022",
    content:
      "Archaeoacoustics is the study of what ancient places sounded like. For example: the colosseum in Rome when full and thriving. The archaeology of sound.\nThere are many examples in Wikipedia’s article on Archaeoacoustics.\nFor instance, the Mayan pyramid of Kukulkan at Chichen Itza: the pyramid’s stairs give a curious “chirp” echo in respond to a hand clap.\n\nAfter studying the staircases and analyzing his recordings and sonograms of the echoes, Lubman came back convinced that this was no architectural freak. In his paper, Lubman argued that the design of the staircases was deliberate and that the echo is an ancient recording, coded in stone, of the call of the Maya’s sacred bird, the quetzal.\n– Scientific American, Shaping Sound (1998)\n\nAnother:\nCave paintings in northern Finland: the researchers concluded that the cliffs with rock paintings are efficient sound reflectors (Rainio et al., 2018). The sound appears to emanate directly from the painted figures.\nThat example from this wonderful paper introducing the new discipline of experimental psychoarchaeoacoustics: our focus will be on what led people to paint or engrave rock art at sonorous sites in the distant past. We wish to inquire into perception and emotion in the past related to sound.\nRef.\nValenzuela, J., D’iaz-Andreu, M., & Escera, C. (2020). Psychology Meets Archaeology: Psychoarchaeoacoustics for Understanding Ancient Minds and Their Relationship to the Sacred. Frontiers in Psychology, 11, 550794.\n(Musical instruments made of rock are called lithophones.)\nLENGTHY ASIDE:\nCould ancient sound be frozen unintentionally?\nIn February 1969, in a humour column in New Scientist:\n\n[A] trowel, like any flat plate, must vibrate in response to sound: thus, drawn over the wet surface by the singing plasterer, it must emboss a gramophone-type recording of his song in the plaster. Once the surface is dry, it may be played back.\n\n(The column is collected in The Inventions of Daedalus by David Jones, which I have on my shelf.)\nAnd in August 1969, in Proceedings of the IEEE, a letter titled Acoustic Recordings from Antiquity which is completely straight-faced:\n\nWith an artist’s brush, paint strokes were applied to the surface of the canvas using “oil” paints involving a variety of plasticities, thicknesses, layers, etc., while martial music was played on the nearby phonograph. Visual examination at low magnification showed that certain strokes had the expected transverse striated appearance.  When such strokes, after drying, were gently stroked by the “needle” (small, wooden, spade-like) of the crystal cartridge, at as close to the original stroke speed as possible, short snatches of the original music could be identified. …\nThis is to record the finding of a spoken word in an oil portrait. The word was “blue” and was located in a blue paint stroke-as if the artist was talking to himself or to the subject.\n\nBizarrely the author of the letter claims to have written their letter in January 1969, before the Daedelus column, and had it rejected.\nSCIENTIST JAPES.\nThere are two good write-ups of this unlikely-but-fun-to-imagine discovery:\n\nLanguage Log: A Phonographic Phony (2006) - which traces the origin of the paleoacoustic idea back to 1955 and an episode of Science Fiction Theatre\nTenser, said the Tensor: Pottery Recordings (2006) - which reproduces the whole letter from Proceedings and lists a few sci-fi stories where the same idea appears.\n\nRELATED:\n\nResearchers at MIT, Microsoft, and Adobe have developed an algorithm that can reconstruct an audio signal by analyzing minute vibrations of objects depicted in video. In one set of experiments, they were able to recover intelligible speech from the vibrations of a potato-chip bag photographed from 15 feet away through soundproof glass.\n– MIT News, Extracting audio from visual information (2014)\n\nA video of a crisp packet! Voices in the room!\n(You need a camera that can record 2,000–6,000 frames per second. A phone does 60 fps.)\nLabs that investigate archaeocoustics have to do so with simulation, using room acoustics software and VR. Here’s a write-up by room acoustics software provider Odeon, including a simulated auralisation of Hagia Sophia.\nThere are also labs that investigate psychoacoustics experimentally. immpaLAB: Immersive PsychoAcoustic Laboratory creates sound environments and collects responses… examples of affective labels used in these scales are ‘tension’, ‘power’, ‘transcendence’, ‘joy’.\nI feel like I’d like to have these brought together: given a location that no longer exists, a cave or a stone circle or an amphitheatre, how would it make you feel? And reversing it: given a desired psychological profile, what’s the architecture of the space I should be in?\nYou can close your eyes and click or hum and tell if you’re in a tiny or vast space.  \n(Ancient humans may have used echolocation to navigate underground caves and I understand that echolocation - like seeing polarised light - is a learnable skill.)\nSo: can you have computational synthetic acoustics?\nLike, could I wear headphones and have the acoustic space of the Colosseum or Hagia Sophia or Abbey Road wrapped around my music? Could I buy awe as an in-app purchase? How about a realtime psychoacoustic graphic equaliser with passthrough, mutating the everyday sound of the street such that I’m microdosing cathedrals?\nI mentioned recently (here) that I have this livestream of a waterhole in the Namibian desert (YouTube) open in the background a whole bunch at the moment. The why is the sound (I have it on now). You can hear the desert wind, the birds chattering and the antelope chuntering to one-another; the sky changes over the day, the animals come and go. It’s calming. I can focus. Why have music? Well I have music too. Why not more of this?\nMy dream would be to inhabit this aural environment as I go about my day, ambiently, not immersive exactly but everywhere, a layer of dreaming overlaying the reality of my home – upstairs the forest, in my office the desert. In the middle of the night if I tiptoe all the way downstairs I step in the dark onto the savannah and bathe in the nocturnal infrasonic hum of giraffe calling across the open plain.\nHey happy Friday y’all. I don’t say that enough. I hope you’re in a good place. Look after yourself.\n",
    link: "/home/2022/11/18/archaeoacoustics",
  },
  {
    title: "The drone superhighway needs its own art program",
    date: "21.55, Monday 21 Nov 2022",
    content:
      "Hey it’s follow-up week! I’m posting new words about old posts. Drop me a note if there’s something from the archives that you want an update on.\nRe: What about a national packet-switched drone delivery network (2021).\n\nMaybe today’s focus on local road-based delivery robots is a dead end, and the last mile logistics world should be looking at packet-switching drones instead.\n\nSpecifically I wanted a policy intervention: an interoperable protocol for packet-switched drone delivery in theory over the entire country – including how to pick up/drop off a parcel from a street, recharge the drones from standardised recharging points, and allocate billing and network fees.\nWell.\nSPOTTED, SOME TIME LATER:\n\nThe UK is set to become home to the world’s largest automated drone superhighway within the next two years.\nThe drones will be used on the 164-mile Skyway project connecting towns and cities, including Cambridge and Rugby.\n… “Whether it be a business doing logistics, all the way to the police and medical deliveries of vaccines and blood samples, there’s a real demand to have access to this airspace,” he said.\n– BBC News, UK set to have world’s biggest automated drone superhighway (July 2022)\n\n…which seems promising, right?\nThere will be an automated, drone-specific air traffic control system between the cities, with route guidance and collision avoidance.\nI can’t find anything else about the project online. I found a list of other recently funded drone projects and they’re all decent applications – good stuff really, drones carrying medicine or drones carrying the post. Nothing about building a scalable protocol that anyone can plug into, it’s probably too early for that. A shame though understandable.\nBut, and let me fantasise for a second, what I hope is embedded in these projects (somehow) is DESIGN.\nIn particular - in my fantasy - 10% of the budget would be carved out for speculative design in two areas.\nFirst:\nVisualise the future. Let’s say there were drone superhighways all over the country. How would it operate at scale? How would your neighbourhood store plug into it? How would routing function? Talk to the engineers and rough it out – and then paint pictures, illustrate, make posters. Create gorgeous, accessible, rich graphics and paintings made for newspapers and made for TV. Make the vision feel real, and thereby create desire, belief, and alignment.\nBonus points: use this as commercial art for ads for the partner organisations.\nSecond:\nA good science fiction story should be able to predict not the automobile but the traffic jam. – Frederik Pohl. Use design to speculate about how people might live, with a nationwide distributed drone network. How will community change? How will kids make use of drones hovering at bedroom windows? What will go wrong or be unexpected? What secondary inventions will be required? This work gives us access to new ideas that are otherwise hard to reach… then similarly publicise these visualisations and fire the imagination.\nIf you want to build a ship, don’t drum up the men to gather wood, divide the work, and give orders. Instead, teach them to yearn for the vast and endless sea.\nI think we’re missing the why from technology nowadays. And the human. And the public conversation. All hidden behind the invisible hand.\nAnd design has been dominated lately, I think, by its user-focused and aesthetic wings.\nThe wild and inventive and energising aspect, the exploratory and opinionated and impractical and persuasive and critical sides – I feel like this is a missing piece of R&D funding.\nI made a roundup of art + tech back in 2015, and alongside that I would add the NASA Art Program (famously the still-resonant Ames Research Center space stations from the 1970s). It’s a list worth a scan!\nI think that speculative design in the public eye, as something commercial and normative, is woefully underused. If for some reason I were given the keys to the UK’s government R&D budget, I’d get a 10% design, arts and comms allocation locked in, across the board, then quit the next day.\n",
    link: "/home/2022/11/21/drones",
  },
  {
    title:
      "The gift of virtual crabs is a signpost to the future of tradable app features",
    date: "16.05, Tuesday 22 Nov 2022",
    content:
      "Iiiiit’s follow-up week. New words about old posts. Drop me a note if there’s something from the archives that you want an update on.\nRe: Apps are too complex so maybe features should be ownable and tradable (2022).\nLet me summarise the post: features in an app are the things you get in menus, like the ability to insert a table, or a funny face filter. A feature flag is an engineering term for being able to enable/disable these features user by user. For example, during testing you might use feature flags to enable the “edit tweet” feature for only 1% of users, to see if it works ok.\nBut what if your users could buy and sell their feature flags?\n\nSo what if you’re collaborating with your lawyer in Google Docs, and you can see from their avatar that they have the “Track Changes” feature flag activated?\nBecause you’re in the same doc, you can use it together.\nAnd maybe if you want to use it again, they can just… gift it to you?\nCould app feature flags be tradable and giftable? That would answer the discovery problem and the “store” problem.\n\nThe discoverability problem = there were 4,000 commands in Office 2003, and most people only used two. 20 years on and menus for desktop applications are a mess, and mobile apps aren’t much better – we don’t know what our applications can even do, let alone where to find the commands. But with multiplayer apps, you might discover features when you see other people using them… and then they could gift you the feature. And you can keep it for later.\nKeep the feature where? I ended up going a bit deeper on this area during my summer project (it is uncertain whether this will see the light of day) – the metaphor we hit on was pockets! Here’s a teeny glimpse of being gifted a feature and it ending up in my pocket.\nHaving tried it: giftable, pocketable features are awesome fun.\nAND SO I was recently super excited to run across TumblrMart.\nThe social media/blogging platform Tumblr has a built-in shop. Here’s the FAQ. It’s excitingly early days:\n\nRight now, TumblrMart products can only be purchased as gifts for other people on Tumblr.\nRight now, TumblrMart has two items in stock: 24 hours of Dashboard Crabs and Ad-Free Browsing (you can choose to buy a month or a year).\n\n(That FAQ also has screenshots.)\nDashboard Crabs?? It’s the gift of a button.\n\nusers must activate their crabs by clicking or tapping the “Summon Crab!” button that will become visible to them at the top of their dashboard.\n\nWhat happens when you summon? From that first FAQ…\n\nWhen you’re gifted crabs, you’ll have 24 hours of crab access, beginning once you’ve acknowledged the gift. …\nClick a crab to catch it. Hover over a crab 10 times and it deems you a friend. Hover over a crab 25 or more times and watch it fall in love with you. Click the “Summon crab” button to generate more and more crabs. Have fun with it. When you’re done, you’ll have the option to publish a post with information about how many crabs you caught, summoned, and how many became your friends or fell in love with you. A “group picture” with all of your crabs will be added to your post, too.\n– Tumblr Help Center, TumbleMart\n\n(You can now also purchase Important Blue Internet Checkmarks from TumblrMart to display on your blog. You get two for $7.99 and they stack, so if your friends think you are extra important you can have like 30.)\nThree things I love about TumblrMart:\n\nIt’s about gifting\nIt’s about features not decoration. The recipient gets a button!\nIt’s real money\n\nAlso it’s bonkers.\nTwo things I think TumblrMart would be even better with:\n\nRe-giftable gifts – don’t want to hit the Summon Crabs button yourself? Give it to someone else. Now they have it, and you don’t\nPublicly visible, multiplayer gifts – the Summon Crabs button is just for me. But what if it was for every visitor to my blog? Place the crabs on my homepage and they become a reason to visit me – worth investing in if I want the attention. Maybe even make catching them collaborative and realtime, with cursors chasing round the page. That would make TumblrMart goods socially discoverable. I would find out about new giftable features in the normal course of keeping up with my friends.\n\nI guess what I’m saying is that TumblrMart is 50% of the way there. Now wouldn’t it be cool to embrace the objectness of these giftable features.\nThere’s a startup in this.\nBy which I mean to say: if you created an easy-to-integrate API for purchasable feature flags, wrapping Stripe to take care of transactions, that’s basically a plug-in monetisation layer for any other consumer/SME startup that wants it. Include a hosted store. They all use feature flags already. It would save them a bunch of work.\nThen ensure the purchased features have serial numbers – embrace objecthood; make them ownable and giftable; make some objects consumable and other objects scarce; give pockets to users. It sounds like a heavy metaphor but it’s really not, it’s Stripe Treasury for intangible goods plus the move that adds social discoverability in the era of multiplayer apps, all with a friendly face.\nAnd although we started off talking about crabs I also mean purchasing a stenographer feature in Zoom if you’re a project manager, or gifting AI in-painting fuel for my favourite Instagram artist. Because all of that is what this enables.\nHuh that would be fun to build.\n",
    link: "/home/2022/11/22/crabs",
  },
  {
    title: "My old Richter scale for system outages, revisited",
    date: "17.36, Wednesday 23 Nov 2022",
    content:
      "It’s follow-up week! I’m blogging new words about old posts.\nRe: A Richter scale for outages (2015).\nFollowing a flurry of system outages (part of the Visa network was down, then iCloud for a bit) I scribbled some notes about quantifying the disruption…\n\nLike the Richter magnitude scale, each magnitude is incrementally ten times bigger. So 4.0 is 100x bigger than 2.0. But like apparent magnitude it’s subjective: The scale of the human effect is taken into account.\nHere’s what I reckon the scale might look like.\n\nFull details in the post, but some highlights:\n\n2.0 (Facebook down, outage lasts less than a day)\n4.0 (broad human inconvenience without threat)\n8.0 (e.g. the 2008 credit crunch or the Icelandic volcano grounding European flights)\n10.0 (major network collapse, global and unrepairable).\n\nIt’s an idea that keeps coming back in my head since 2015. It feels like it would be useful to have in the public discourse! It’s not like we’re going to have fewer system outages in the future.\nBut I’ve never been really satisfied with the scale itself. I’ve always been meaning to try to put my finger on why.\nShort reviews of a few other scales\nBeaufort wind force scale (1805) – I like how practical, human, and sometimes poetic this is. Beaufort 2 is: Wind felt on face; leaves rustle. Beaufort 12, hurricane-force: Devastation.\nI think one of the reasons it works so well is that the lower numbers are very everyday, so it you can extrapolate and build a visceral understanding of extreme and rare events.\nKardashev scale (1964) – the classic scale of cosmic civilisational complexity, as measured by energy use. Type I: like the Earth, a planet making use of energy ultimately derived from its sun. Type II: a civilisation which has captured the entire energy of its sun, for example by building a Dyson sphere around the star. Type III: as II but able to direct the energy of an entire galaxy.\nNot sure how applicable the Kardeshev scale is here but it’s fun…\nRohn Emergency Scale (2006) – this scale has three independent dimensions: scope (measured in % of max population, or % loss in GDP); topography (the estimated visual fractional change in the environment – the collapse of a house is high; the collapse of a stock exchange is low); and speed of change.\nIt’s more of a descriptive framework than a scale, I’d say. I like that speed of change is in there.\nViking Impact Magnitude (2012) aka “A Richter Scale for Power Outages” – this paper shows how the scale is derived in a bottom-up fashion, which is super interesting. It’s rigorous, but again there’s the focus on the human impact. The scale of 1–10 is obtained by multiplying the number of affected people by the duration of the interruption.\nThe scale makes different events comparable: for example a 2007 cyclone in Sweden has the same impact as an earthquake, or maybe a hacker attack. Then the scale number can be correlated with a $ cost.\nALSO, one fictional datapoint. The jackpot, coined by William Gibson in The Peripheral (2014) and summarised here. The climate crisis, mass extinctions; no more bees, antibiotics exhausted; rolling pandemics and water shortages, just… all of it and all at once. Whatever the scale is, the jackpot is the Big One.\nTowards a revised Richter scale for system outages\nLearning from the above, a revised scale should ideally:\n\nstart with recognisable, everyday occurrences, and be more irritating than disruptive until about 4.0. It’s worth working to maintain a 1 to 10 scale.\ndescribe the impact not the cause. Dimensions are probably similar to the Viking scale, number of people affected and duration. \n\nI wonder how to include some measure of damage. Like, a 7 day WhatsApp outage would be a massive main but you can route around it (although not if you’re an informal worker in Brazil). A 7 day water outage is a catastrophe in the making.\nBut maybe that’s not for this? A Richter 8.0 earthquake in the middle of a city and a Richter 8.0 in the remote wilderness are given the same number on the scale. You differentiate by giving the location.\nAlso under damage I’d put “effort to remedy.” Like, is it a reboot required, or a product recall?\nA thought experiment: the 8 years and counting Flint water crisis is a water infrastructure disaster affecting 100,000 residents. In terms of damage, it’s way up there – but the remedy has taken its time probably due to a lack of will rather than actual severity.\nCompare with a WhatsApp outage that is less sever but would affect 2 billion users. Should they both be a 6.5? Or do we add context – is WhatsApp a widespread 4 and Flint a localised 8? The latter I think.\nBeing careful to specify the location answers many of my concerns I think. Twitter lost its timeline for a couple of hours the other day; we could describe that as a short sharp Twitter-localised 3.5, just enough to remind us of what we might lose, and you’d known what I meant. \nOne thing I’m certain of: this scale is for system outages. If there’s a fault on a weather satellite, then it’s not the satellite that this scale is concerned with, it’s our weather forecast infrastructure generally.\nTaking all of this into account, the scale in that old blog post stands up ok. I’d add some notes about usage and interpretation but that’s it.\nSo I’m going to leave the 2015 scale intact for now.\nIt needs a v2. But the purpose of that work should be to refine and add rigour. It should start with collected examples, and work to define its terms on both infrastructure and impact.\nThat’s not something I can do on my own…\nHowever there are not one but two upcoming books about infrastructure I am excited about: Public Utility by Debbie Chachra (she briefly ran me through the core argument and I can’t wait). And, by Georgina Voss, her new book on complex systems for Verso. I don’t know the title but I got a preview of the chapter topics and I am equally psyched.\nWhich means my next step is to wait until those are published, inhale them both, chase down some references, and then start buying people coffee until someone who actually knows what they’re talking about wants to co-author a paper.\n",
    link: "/home/2022/11/23/outages",
  },
  {
    title:
      "Some books that mean a lot to me, taking another run at a blogging meme from 2005",
    date: "21.48, Thursday 24 Nov 2022",
    content:
      "Hey it’s follow-up week! I’m blogging new words about old posts.\nRe: Tom Coates passed me the music baton… (2005).\nSo waaaaaay back (before you was born, dude, when life was great) blogs used to be social media, like Twitter only less angry, and we had MEMES.\nAnd yes I participated.\nThat post above is one in which you had to answer:\n\nHow many books do you own?\nWhat is the last book you bought?\nWhat is the last book you read?\nWhat are 5 books that mean a lot to you?\n\nAnd then you had to tag in 5 people who also had to answer.\n(Actually Tom asked me to do this about music but I did it about books instead.)\nYou’ll have to follow the link to find out what I said way back in 2005. I haven’t read the post yet. I’m going to answer here, in 2022, then go back and see.\nBut I’ll be brief because I’m about to have supper.\nHow many books do you own? I have no idea. Enough that the entire wall is covered in shelves, and another nook, and there are stacks of books I have no room for, and I haven’t read them all (I subscribe to Umberto Eco’s theory that your library should contain what you don’t know). Also I love categorising my books into personal categories and I need a baroque computer vision system to find them, both topics covered here (2020).\nWhat is the last book you bought? The other day I bought the exhibition catalogue for the 2004 Berkeley Art Museum retrospective Ant Farm 1968-1978 (here on Amazon) because I want to read the interview about their architectural sketches for a dolphin embassy, which is extraordinarily deft, as previously discussed, in the service of a new personal project. It hasn’t arrived yet.\nWhat is the last book you read? To Be Taught, If Fortunate: A Novella (Amazon) by Becky Chambers, which like all Becky Chambers is humanist and straightforwardly galactically transporting, and draws pictures of worlds that I’d like to visit and people I’d like to be my friends. Because of somaforming, Chambers’ take on cyborgs, as mentioned earlier.\nWhat are 5 books that mean a lot to you?\nOk I am super intrigued about this. Because I am going to say 5 books at the top of my mind right now and then I am going to go back and read my list from 17 years and see if there are any the same.\nI’m not going to be clever-clever about this, or list intellectually formative books, or books I would necessarily recommend. Just ones that, well, mean a lot to me.\nSo let’s go:\n\nFoucault’s Pendulum by Umberto Eco. I can’t emphasise how much the efervescent interconnectedness of threads and conspiracies, fact and fiction and the blurred lines between the two, absolutely enthralled me. Here we are on interconnected.org.\nFoundation by Isaac Asimov. I remember my dad taking me to Foyle’s to buy this, my first science fiction and my first visit to a real bookshop, back when you had to hand the green slip in from the book at one counter and pay at another. I’m not sure I would love Foundation if I encountered it today, in the 2020s, but as a boy in the 80s it gave me vastness, and I still get that sense whenever I pick it up. Besides, my dad, right?\nMr Topsy-Turvy by Roger Hargreaves. Basically this guy turns up in town, does everything backwards causing chaos, vanishes, and the town carries on acting that way. I’ve kept it on my shelf for years. I enjoy reading it to my kid. One may only aspire.\nThe Wisden Cricketer’s Almanak. Perhaps it’s cheating to pick a book that comes out every year. Each squat, bright yellow edition is a thousand pages of stats of every first class cricket match played domestically and internationally by teams in England and Wales, plus a few essays thrown in. Another to do with my dad: I inherited his Wisden collection and - belatedly - his love of cricket too, and when I settle down to read each new edition it is the most poignant and the happiest day of my year.\n\nI can’t settle on a fifth. There’s sci-fi like Diaspora (Egan) or Stars In My Pocket Like Grains of Sand (Delaney) or Always Coming Home (Le Guin). There’s Hamlet (there’s a ghost! Originally played by Shakespeare!). There’s Steps to an Ecology of Mind (Bateson) or the I Ching. Or any number of non-fiction books that I turn the page corners over and think about tons but maybe aren’t ones that I would say mean a lot to me in the way I’ve chosen to interpret that today.\nAnyway I’m going to pick the graphic novel Sculptor by Scott McCloud, which I’m selecting for reasons that I won’t discuss here.\n(Goes back and reads the 2005 post.) Huh, one book the same.\nI’m not going to pass the baton to anyone this time around but if you fancy having a go at these questions, and blogging your answers, then please go ahead and do let me know.\nUpdate: THE BOOK MEME, IT INFECTS. i.e. some other people did the thing.\n\nBen Crowder (24 Nov)\nPaul Graham Raven (25 Nov)\nRob Annable (30 Nov)\n\n",
    link: "/home/2022/11/24/books",
  },
  {
    title: "You wouldn’t retweet a car",
    date: "18.22, Friday 25 Nov 2022",
    content:
      "Hey it’s the final day of follow-up week! I’ve been blogging new words about old posts.\nRe: Fanboost and other magical manifestations of the will (2020).\n\nFormula E (the electric version of Formula 1) has FANBOOST which is maybe the tech equivalent of some kind of distributed good fortune magick?\n\nYou would vote for your favourite driver on social media, live, while the race was on. The top tweeted 5 drivers would get an extra surge of speed, like to surprise overtake an unboosted looooser.\nI am sad to report that Fanboost is gone. It was for one season only. There’s a video record of the best Fanboost moments (YouTube).\nFanboost got to the heart of something: electric vehicles are also software-defined vehicles. And they’re networked, so they can do anything that networked software can do. UNREALISED POTENTIAL.\nAnyway, so:\n\nMercedes-Benz is to offer an online subscription service in the US to make its electric cars speed up quicker.\nFor an annual cost of $1,200 excluding tax, the company will enable some of its vehicles to accelerate from 0–60mph a second faster.\n– BBC News, Mercedes-Benz to introduce acceleration subscription fee (2022)\n\nTesla has sold “Acceleration Boost” since 2019: Model 3 vehicles accelerate from 0–60mph half a second faster for a one-time fee of $2,000.\n(Spotted at thejaymo’s Scrapbook. Thanks!)\nFanboost consumerisation!\nI am taken with the idea of going full social on this. Subscriptions are the lazy route for lazy capitalists.\nLIKE:\nEach car could have a QR code on it, and if you do something nice then other drivers could fave you with an app. Collect 10 faves and trade them for a faveboost.\nKeep below the speed limit according to your insurance company black box and get a good behaviour boost. (It shaves 0.1 seconds off your 0–60 acceleration time increasing each year alongside your no claims bonus.)\nAugmented reality driver HUD on the windscreen to shoot green shells at bad drivers to immediately give them a negaboost.\nAlso from that BBC article, in-app purchase for premium vehicles is a thing now.\nI’d forgotten about this: rival manufacturer BMW offered a subscription feature earlier this year - for heated seats.\nWhich reminds me of this genius twist which somehow emerged from the web3 space:\n\nI rather like the idea of turning subscriptions into digital assets. If I were BMW I’d consider turning those subscription options into nonfungible tokens (NFTs) that could be traded across Web3 so that we can see what the market thinks that they are worth. They would have to make the tokens function properly, of course, so that (for example) if I have a BMW heated seats token, then I’d expect it to work in any BMW I get into, whether it’s mine or a rental car or a friend’s car.\n– Forbes, Tokens, Not Subscriptions, For Heated Seats In Your New Car (2022)\n\nAnd while tokens vs subscriptions doesn’t quite stack up economically (BMW wants that sweet, sweet recurring revenue)…\n…the idea that the heated seats are attached to me and not the car is kinda amazing?\nSo long as we’re heading into this capitalist hellscape in which I have to pay EVERY YEAR for stuff I’ve already bought, why not let’s go ultra individualistic libertarian on it too.\nMercedes-Benz Acceleration Boost should belong to people not vehicles, that’s what I’m saying.\nThis would dramatically grow their potential customer pool from anyone who owns one of their cars to anyone who even interacts with one.\nRemember being a teen and getting lifts everywhere with your friends?\nImagine drivers competing to have you take shotgun with them because they’ll get better performance with you in the passenger seat.\nYou’d be so cool. Mercedes could charge twice as much for that, social peacocking beats functional any day of the week. ZOOM ZOOM. Hey Mr Benz you can send the cheque to my Paypal.\n",
    link: "/home/2022/11/25/cars",
  },
  {
    title: "My pitch for a colossal photorealistic statue of the queen",
    date: "21.37, Wednesday 30 Nov 2022",
    content:
      "One question is how to memorialise Queen Elizabeth II. I am concerned that there is a lack of public ambition so here’s my pitch: a giant photorealistic statue visible from every plane landing into Heathrow airport.\nLook I’m not a monarchist but I do feel like it’s important to represent significant moments so they transmit through time.\nThe last major monarch was Queen Victoria who reigned for 63 years, 1837–1901.\nThe Victoria Memorial (Wikipedia) was erected in 1911 outside Buckingham Palace. It’s dramatic and elaborate: a marble pedestal topped with a bronze angel.\nIt was chosen by a Parliamentary committee and cost £200,000 at the time – although the fundraising was more than successful so, as part of the project, they also built Admiralty Arch at the other end of The Mall, connected the road to Trafalgar Square, and re-fronted Buckingham Palace. I don’t have a number for the total cost so let’s guess half a million, or in today’s money, £46 million.\nI wasn’t around when Victoria was on the throne. Nobody still living was! But none-the-less her reign looms large in the national mind, and part of the reason is memorials like this. In another 100 years it will be clear to them, too.\nWhich brings me Queen Elizabeth.\nElizabeth II was on the throne 70 years (1928–2022) and the second Elizabethan age was no less transformative for Britain than under Victoria.\nAnd the common understanding is that there should be a statue to her on the fourth plinth in Trafalgar Square?\nThe story goes that, of the four plinths in Trafalgar Square, one was unoccupied, and so since 1999 it has been the home to a changing selection of monumental art – keeping the seat warm, as it were, for the Queen. No.\n\nIt would be a shame to lose a place for incredible modern public art.\nYes it’s in Trafalgar Square which is central to London, but it is insufficiently epic compared to the Victoria Memorial.\n\nI’m against the idea of a statue for the Queen at all, actually. A conventional statue.\nThink about it – statues are old hat. Sure in 1911 they may have been of the time. Even the location: in 1911 the Ford Model T was only a few years ago. Big roads had novelty to them. The Victoria Memorial, at the end of a long, wide, flat road – this statue was placed in the modern realm. It wielded authority, it is clearly complex to sculpt, it is large (25m).\nA new statue today in an exercise in nostalgia. Cargo culting history.\nInstead:\nRemember Mark Wallinger’s proposed White Horse at Ebbsfleet?\nDo check out the concept image on that page. Because whereas the traditional white horse is a grand chalk outline on a hillside - ancient land art - Wallinger’s proposal was a 50m, full colour, photorealistic sculpture of a white thoroughbred towering over the countryside. For comparison this is the height of the Statue of Liberty (the bit above the stone pedestal).\nThe mockups are clearly photoshopped. If it had been built, reality itself would have looked photoshopped. It couldn’t be more of its time.\nOriginal cost estimate was £2m; final estimate was £12–£15 million, though sadly it was never built.\nSo.\nA monument to Queen Elizabeth II. We want the British public in 100 years to fully grasp the historical weight of this monarch of the 20th century.\nThe budget in today’s money should match Victoria’s. Assuming costs increase quadratically, that’s enough for a statue twice the height of Wallinger’s White Horse.\nAnd I would suggest the same approach: a photorealistic fibreglass three dimensional colossus of the Queen, standing 100 metres toes to crown.\nNot on a road but with similar visibility as that historical comparison, so let’s put it on the Heathrow flight path. Handily Windsor Castle lies to the west and can often be seen from planes taking off or landing. The statue would be double the height of the castle so it would stand out.\nI don’t believe we should be settling for anything less in the 2020s.\nI’m entirely sure that this will not be the proposal of any future statue committee – but we should ask why not. Because if there isn’t popular ambition for the state to memorialise Queen Elizabeth II in a grand and modern fashion, if not this precisely then similar, then it’s hard to see how there could be ambition for anything.\n",
    link: "/home/2022/11/30/queen",
  },
  {
    title:
      "Weaving women’s work, Hollerith tabulators, and procedurally generated art",
    date: "13.46, Friday 2 Dec 2022",
    content:
      "There’s an exhibition at Tate Modern in London that you really should see if you get a chance: Magdalena Abakanowicz: Every Tangle of Thread and Rope. It’s on till May 2023. There’s a review and bio over at The Guardian:\n\nEvery Tangle of Thread and Rope traces Magdalena Abakanowicz’s development as a textile artist from the mid 1950s until the late century, beginning with designs for tapestries and jacquard punched cards for weaving, rows of leaf-shapes, colourways and tryouts for decorative fabrics, but soon expands, as did her art, into sculpture and installation art.\n– The Guardian, Magdalena Abakanowicz review – so is that a nose or a testicle? (2022)\n\nIt’s all challenging, emotionally powerful stuff. The forest of giant fabric sculptures, immediately followed by a room of something like organs, seemed like an assault on walls. So much about interiors, but these slightly open sculptures so much like hung garments or rotted ancient trees, and the forest that you can be within without being contained… here’s an alternate way of being, being enacted right here.\nThough it’s the tapestries that stick in my mind - patchworks of woven fabrics - and in particular, in the same room, an early piece made from jacquard punch cards.\nWeaving, of course, being traditional “women’s work” and programmable jacquard looms being an industrialisation of weaving.\nAnd Abakanowicz growing up in Poland in the Second World War… the connection I mean is not exactly the use of IBM’s technology by the Nazis for the Holocaust but… the Holocaust was enabled by population census data. Data was tabulated on Hollerith machines, which was the original purpose of these very first data processing machines when they had been invented in 1890 for the US Census (and which eventually became computers). Hollerith tabulators were popular; Hollerith had merged and become IBM; Hollerith punch cards (inspired by jacquard punch cards) became IBM punch cards.\nSo - and this is a guess, or a query I suppose - there may have been a connection for Abakanowicz between fascism and population control on the one side, and weaving and industrialisation on the other, mediated consciously or unconsciously by punch cards. The two are entangled, textiles and totalitarianism.\nAnother faint trail through these themes:\nAt home we have a treasured piece by the artist Hilary Ellis. Look at her portfolio (and WIP on Instagram) and imagine these works at scale: large textured canvases with repeated marks or stitches of thread.\nThere’s an explicit connection with women’s work:\n\n… an enduring and persistent nature that dwells quietly within the realm of traditional womens’ work and its often futile repetitions. …\nUsing a variety of media, I produce repeated marks and actions that aim at exact replication, but whose inevitable deviations expose the frailty of the human hand in attempting the pursuit of mechanical process. …\n– Hilary Ellis, artist statement\n\nI mention Ellis because when I encountered her work, I thought I saw a connection to the work of Vera Molnar.\nI first found Molnar’s pioneering computer-generated art in the 1976 book Artist and Computer (Amazon) in which editor Ruth Leavitt collects work and statements from a large number of contemporary artists. Wonderfully the entire book is online.\nVera Molnar explains her work (there are also examples there):\n\nUsing a computer with terminals like a plotter or/and a CRT screen, I have been able to minimize the effort required for this stepwise method of generating pictures. The samples of my work I give here in illustration were made interactively on a CRT screen with a program I call RESEAUTO. This program permits the production of drawings starting from an initial square array of like sets of concentric squares. …\n\nAnd there’s a resemblance with Ellis think? Not a similarity, that’s not what I mean, but something generative about putting the works in dialogue in my head.\nThen this interview with Vera Molnar, Weaving Variations:\n\n“My work is like a textile,” Vera Molnar has told me\n\nMolnar, like Abakanowicz, is an artist from Cold War Europe.\nI don’t mean to draw connections where there aren’t any. (Though maybe that’s allowed!)\nNor do I don’t mean to (say) glamourise the hand in the weave and the ritual of repetition, opposing it to the horror of Hollerith punch cards in the formative infancy of computers; all three of these artists connect this territory in different ways. (Though holy shit we should talk about the military history of computing more.)\nBut it seems to me that there is some kind of nexus of weaving, mechanisation, women’s work - both the way it is performed and the way it is treated - computers and what computers do to us (or what we use computers to do to each other), power more generally…\nSomething something, I don’t know, I lack the tools to process these thoughts… and this is all so delicate and so faint and I know so little about any of it… but…\nThe Abakanowicz exhibition has stirred up so much in me. Do go check it out. Art!\n",
    link: "/home/2022/12/02/thread",
  },
  {
    title: "Carbonating beef broth for fun and profit",
    date: "10.22, Wednesday 7 Dec 2022",
    content:
      "Hear me out: fizzy gravy.\nI can’t remember exactly how this came up but it was at Alex‘s party so blame her.\nI recently encountered sparkling tea. Not a thing I’d run into before. The main brand is Copenhagen Sparkling Tea developed in a Michelin star restaurant. Fortnum’s has its own brand which is apparently pretty good.\nWhich prompted the question: what other savoury consumables can be similarly sparkled?\nCarbonated beef gravy.\nYou’d package it like aerosol squirty cream, somebody said. Squirt it from the can onto your roast potatoes and it would stick where you put it. Handy!\nSo the actual fun with this game is not thinking of foods to fizz but to come up with how you’d market them.\nI think you could make a play for fizzy gravy being a kind of democratic sauce. Like, foams and molecular gastronomy are available only in fancy restaurants for the 1%, but this is gravy passed through a SodaStream so pretty much anyone can do it at home.\nOr maybe you could use a milk frother like the ones you get with coffee machines. A velvety meaty microfoam.\nA more compelling angle might be health?\nFor example: Halo Top ice cream. Wildly popular in 2018 (and sold to Wells in 2019). Slogan: eat the whole tub. This is because it’s low calorie.\nHalo Top is low calorie partly because uses sweeteners, not sugar, but partly because of a clever hack on food marketing. Ice cream in the US is sold by volume not weight. So a pint is a pint, but: A pint of vanilla Halo Top weighs 256 grams, while a pint of Ben & Jerry’s vanilla weighs 428 grams. (Source.) It’s incredibly aerated.\nWhich is a neat comparable. Aerated ice cream used to be the cheap own-brand stuff. With Halo Top it’s healthy.\nNow gravy?\nSquirty gravy in a can could be doubly healthy because you don’t need as much (precision squirting means you put it only where it’s needed, instead of your food swimming in it) and also because it’s aerated so you consume less actual gravy per mouthful.\nI bet you could market a premium-yet-democratised, indulgent-yet-healthy gravy foam in a can.\nIn terms of influencer marketing you’d start by going after top-end restaurants and street food simultaneously. Street food because it’s highly grammable and also experimental: gravy microfoam offers the opportunity to use umami-heavy meat broth as a ketchup or mayo-like condiment in wraps and burgers, and that’s a new taste.\nA few years back, I did a little work with an FMCG startup incubator. FMCG = fast-moving consumer goods, which covers multiple segments, and these folks specialised in branding and packaging new foods and snacks.\nFMCG founders differ from tech starter founders, I learnt. They tend to be older, apparently, and they usually have incredibly good personal connections into distribution. They know where to launch and how to scale.\nPlus what they have is good connections to factories. Some factory somewhere will develop a new process like, say, how to economically produce extremely puffed biltong. Then the founder will the first to see that, know there’s a trend in on-the-move protein snacks for gen z, put the two together and run with it.\nThe rest is branding. Then the company sells a few years later to Unilever for 9 figures or whatever.\nAn alternative to the health angle is flavour?\nCarbonation will make the meat gravy slightly acidic so you’ll get a little pop from that. Then the cavitation from the bubbles is going to add a unique mouth-feel.\nRELATED, on the food and technology front: Pepsico invented a new shape of salt crystal for reduced sodium and extra flavour.\nI’d be sceptical about the level of novelty except for a drink from the 1950s called Beef Fizz.\nRecipe:\n\nGinger ale: 1 cup\nLemon juice: 2 tablespoons\nCanned condensed beef broth: 1 pint\n\nHistorical precedent!\nHere’s someone who tried it:\nShockingly, Beef Fizz wasn’t as bad as we expected. It was worse. Much, much worse.\nLook that’s not promising I admit but putting it another way, the bar is low.\nSo if you have a milk frother then please do try aerating your turkey gravy this Christmas and, if family feedback is good, we’ll take it to the supermarkets and go halfsies.\n",
    link: "/home/2022/12/07/gravy",
  },
  {
    title: "Dowsing is a technology for intuition amplification",
    date: "15.12, Friday 9 Dec 2022",
    content:
      "I’d love to build intuition amplifiers as cyborg prostheses.\nLike, here’s an old one: flipping a coin.\nYou know when you don’t know the right course of action so you get a coin and then it lands heads and you think, oh I wish that had been tails. In the process some internal signal too faint to discern has been lifted to awareness.\nLike, here’s another: dowsing.\n(Dowsing as the ancient art of walking over a field holding a Y-shaped twig or stick - the divining rod - and when the stick rises up then you know that there is water underground. Some people are better dowsers than others.)\nDowsing is pseudoscience, and whether or not it actually works, I believe in the idea of dowsing because I can imagine a plausible mechanism. Being this:\n\nWe know the hippocampus carries a landmark detector, as previously discussed (2021): even if we don’t consciously recognize something as a landmark it still triggers a response\nAnd at that same link, Kevin Lynch’s work on imageability shows that people have a common understanding of what constitutes a landmark, distract, path, boundary, etc in the urban landscape\nSo it’s a plausible stretch to suppose that we are predisposed to recognise other landscape features – such as there being a likely water source\nAnd this doesn’t need to be conscious. The concept in psychology of priming (Wikipedia) is what I mean here: that your brain your brain becomes “ready” to notice the thing that is likely to happen next, and if it does occur then you will respond to it quicker. So being primed to expect water will make it slightly more likely that you notice it, if presence, and that’s all evolution needs.\n\nSo my unfounded, imagined mechanism starts like this: thinking about water, and stepping into a location where there is increased water likelihood, one may become primed to look down, which is physically represented as a microscopic movement or twitch of the fingers. (Which could of course be a random twitch because that happens too.)\nThe next step is that the twig is a lever that magnifies the movement, being gripped right at the end, and you see the far tip of the divining rod move, then your brain (still unconsciously) either corrects (removes) or accepts this movement by adjusting your hands.\nAnd so, when there is an unconscious belief that there is water underground, you enter a positive feedback cycle and the intuition is amplified into a visible signal.\nEquals dowsing.\nIt’s like the coin flipping but much accelerated and realtime.\nSo how about new intuition amplifiers?\nNow, conversation often serves to pick out and boost intuitions. And writing can be a conversation with yourself.\nBut dowsing is interesting because it’s pre-verbal. It short-circuits the rationalising and linearising processes inherent in speech.\nDowsing has these three qualities:\n\nIt starts from something deep within, something analogue and probabilistic, something unconscious\nIt deliberately draws an amplifier circuit with a long feedback loop\nThere is some element of stochastic resonance.\n\n(Stochastic resonance is the phenomenon in which random noise can amplify a signal, like putting static over a photograph too faint to be seen can make it visible, and human perception already makes good use of this. In short, the noise in the signal from the unconscious via the stick is a benefit.)\nI think the physical world is intrinsic in these qualities. Our new sensor has to be embodied; you need to have an actual device.\nProsthetics.\nRemembering that financial traders are better able to estimate their own heartbeat than the general population and this ability is a predictor of their profitability (discussed here) – could we build a wristband to do this?\nSay: an Apple Watch that generally taps your wrist, exactly in time with your own heartbeat.\nWould that ability to always be able to tune into your own pulse give us all a better sense of risk? Whether trading stocks or walking down a street at night.\nOr:\nBrain waves. Could a targeted EEG sensor listen to the exact spot on your cortex which recognises faces – or, better, the mirror neurons that fire when you recognise someone else’s emotions? My assumption is that we’re all much better at reading feelings than we think we are. Can we dowse for emotions?\nImagine wearing augmented reality glasses that overlay your conversational partner with a little bar chart displaying the positive/negative emotions that your mirror neurons think that you’re seeing. Would that be enough of a feedback loop to turn you into a cyborg empath?\n",
    link: "/home/2022/12/09/dowsing",
  },
  {
    title: "Let’s use spreadsheets to rewire apps and make new ones",
    date: "18.15, Tuesday 13 Dec 2022",
    content:
      "How about an app with a spreadsheet under the hood?\nLike, the experience would be this: you’re using your photos app or Zoom or expense filing SaaS tool, then you go to Settings and scroll aaaaall the way to the bottom, and tap a power user button that says “Open Spreadsheet.”\nThen, magically, Google Sheets opens with all your data in it, and you can sort and query it in all the ways you couldn’t before, and change the titles of your expense claims with spreadsheet functions and that all gets reflected back into the app, or build a callout to an AI to describe all your photos and add natural language tags, do it yourself or ask a friend who knows Excel functions, or whatever really. Anything the app developers didn’t add because they’re building for the 80% use case, and you’re building just for you.\nSo that’s the idea.\nExample #1. Where the spreadsheet is an alt UI for the app.\nThis is the pattern described by Geoffrey Litt and Daniel Jackson in their 2020 prototype, Wildcard.\n\nIn this paper, we present spreadsheet-driven customization, a technique that enables end users to customize software without doing any traditional programming. The idea is to augment an application’s UI with a spreadsheet that is synchronized with the application’s data. When the user manipulates the spreadsheet, the underlying data is modified and the changes are propagated to the UI, and vice versa.\n– Geoffrey Litt and Daniel Jackson, Wildcard: Spreadsheet-Driven Customization of Web Applications (2020)\n\nYou can see some videos at that link: Wildcard is a prototype browser extension and, visiting Airbnb, you can pop open a spreadsheet view and sort search results in ways not supported by the official site, run calculations etc.\n(Litt wrote a long Twitter thread listing lesser known projects that also use spreadsheets.)\nExample #2. Where the spreadsheet is a canvas to weave together new apps.\nFabian Stelzer recently made a Google Sheets template called HOLOSHEET that includes functions to call out to GPT-3 (text generation) and Stable Diffusion (image synthesis) to draft and visualise movies…\n\nHOLOSHEET, story edition!\nbuilt a google sheet powered by GPT-3 and #stablediffusion that outputs full stories, with images!\nyou input a prompt & the AIs generate story, visuals and a title\nin any style you want..\nhere’s “The wizard approached the abyss”\na few seconds later:\n– fabians.eth (@fabianstelzer), 4:32 PM, Oct 3, 2022\n\n(There’s a series of screenshots at that link.)\nSo you might say The wizard approached the abyss and specify a fantasy style from the dropdown, then an embedded, parameterised GPT-3 prompt outlines the story in four scenes, with each scene then being sent to another AI for the illustration.\nSide note: Stelzer isn’t a coder. To make the =GPT3() Google Sheets function, he asked GPT-3 itself to write the Javascript.\nSo both of these are examples of that old design movement Adaptive Design (2020) – end-user adaptation of products that metaphorically have the wires hanging out the back.\nLike, sometimes: when you own a house, and not only does it allow for changing around the rooms and so on, but it has been architected so that there’s a blank wall and space on the plot for you to build an extension.\nAs with architecture, so software.\nAdaptive Design in software allows for\n\nEnd-user software customisation – which means that software that was semi-useful now becomes an intrinsic part of my personal “ecosystem”\nA kind of distributed R&D – where the user community has the ability to find its own solutions, and (as a developer) you can look at what has been done and more in that direction.\n\n(The second point came up in conversation recently. Yes sure it’s important to go and talk to users and co-create solutions. But why not give people the tools and knowledge to adapt the technology themselves and then pay attention to the power users?)\nWhat’s neat about spreadsheets, and particularly neat about Google Sheets, is that:\n\nthey’re a Figma-like infinite canvas that people already understand, and programmable too with formulas that so many already use - extensible, expressive and accessible\nGoogle Sheets is naturally multiplayer and collaborative, so it’s possible for people to share and work socially.\n\nThey’re an interesting vernacular, spreadsheets.\nWhat should startups do?\nIn the early 2000s, user interfaces were being torn up and re-invented as work went online. The response was a fluid world of web APIs, remix culture, and - to frame that with theory - Adaptive Design.\n(Anyone remember Yahoo! Pipes (RIP)? A universal canvas for remixing the web with native handling of APIs and RSS… a bigger loss than Google Reader, that one.)\nI feel like we’re seeing this deconstruction/reconstruction again? With generative AIs, and new multiplayer ways of working and new tools for thought, there’s a growing participation in finding out what our new tools should be and how they should behave.\nMaybe this time round, instead of APIs we could have Excel formulas? APIs never had that work surface to knit them together; formulas have that built-in.\nI wonder what an app team could do to be really spreadsheet friendly? I wonder what the Google Sheets team could do?\nAnd: back in the day there were API lifecycle/management startups (that then all got acquired). Will there be equivalent startups to publish/consume/manage the spreadsheet surface?\nYeah so we should do that.\n",
    link: "/home/2022/12/13/spreadsheets",
  },
  {
    title:
      "Transcribing all our conversations 24/7 will be weird and also useful maybe",
    date: "13.50, Wednesday 14 Dec 2022",
    content:
      "Sooner or later, every single conversation I have will be recorded and transcribed and I’ll be able to look back at it later – details from a phone call with the bank, in the hardware store asking a question, someone mentions a book at the pub, an idea in a workshop. Ignoring the societal consequences for a sec lol ahem… how should the app to manage all that chatter work?\nWhat can you do when you record everything?\nRoberto Dam: I record myself on audio 24x7 and use an AI to process the information.\n\nI bought a couple of Chinese microphones, I wear them and turn them on all day recording everything I speak, at the end of the day the files are processed with OpenAi’s Whisper and transformed into text files from which the information is extracted.\n– RoberDam.com, I record myself on audio 24x7 and use an AI to process the information. Is this the future? (2022)\n\n(Whisper is OpenAI’s new, open source automatic speech recognition neural net.)\nHere’s a neat feature: he has a built-in activation keyword and stop word to indicate when the AI should pass a phrase off for additional processing.\n\nFor example to register my weight for the day I simply say out loud\nRobert WEIGHT 60.1 end Robert\n\nAnd another, to record expenses:\n\nEvery expense I make during the day I repeat it out loud to record it.\n\nAll of these appear on a personal dashboard at the end of the day.\nAnother, an unnerving concept:\n\nRELATIONSHIP THERMOMETER\nAccording to studies on couple relationships, it is possible to predict with an accuracy of up to 90% if the couple is going to divorce by studying the interactions, specifically the relationship between positive and negative interactions between the couple … The magic ratio is 5 to 1.\n\nHe hasn’t built this (yet).\nDam’s system is a huge jump… into something, I’m not sure. It’s a memory prosthetic, partly? I wonder what I would stop doing. Would I stop adding items to the household shared shopping list because I would know that I could just search my conversations later? So in a way it’s replacing app interactions; not just for memory but a kind of very slow voice assistant.\nAll of this without even being realtime.\n(OpenAI’s Whisper isn’t perfect. But, as a Brit, I have never had good experiences with voice recognition. Machines don’t understand my voice. I get the feeling that, for people with a North American accent, Whisper is only an incremental important. But let me tell you: for me, it’s night and day.)\nHow about if transcription were realtime?\nTranscription basically means that conversations because machine-readable, or rather AI-consumable.\nHere’s a tweet from the CEO of DoNotPay which is an app that gives legal advice on, e.g., how to fight speeding tickets.\n\nAnyone with a speeding ticket hearing coming up, please DM me.\nWe want to build a @donotpay bot that listens to the court hearing via your AirPods and whispers what to say with GPT-3 and LLMs.\nWe just want to experiment and will pay the ticket, even if you lose!\n– Joshua Browder (@jbrowder1), 2:03 AM, Dec 13, 2022\n\nAirPods + AI = a cyborg prosthesis of the centaur type.\nAnyways, that’s for the future.\nAll I mean to say is that always-on transcription + realtime is enabling in all kinds of ways. Exploration required.\nAn app:\nSo let’s scope this back. Let’s imagine we record all conversations but maybe only in a work context and only in meetings.\nIs there an app, 50% email client and 50% note-taking “tool for thought” that stores all of these conversations, letting me process them when I need to, and automagically surfacing tasks and relevant information?\n\nRealtime seems vital – or at least close to realtime. Behaviour change occurs when you close the feedback loop from conversation to action. How can insights from the transcript start influencing the conversation that you’re in?\nSearch and also automation – there’s going to be a huge volume of words stored. I want to be able to say “oh yeah I need to add a line to slide 12 crediting X, Y, and Z” and find that later when I need it. But then also live tagging with trigger words: I’m inspired by Dam’s approach of simply saying his expenses out loud and then turning that into a spreadsheet each evening.\nMultiplayer – there is something troublingly asymmetric about me recording and the rest of the group not see it. It feels like, for a small group, we could all be on the same level playing field somehow, like we all have the same access, and it’s private beyond that?\n\nYou need all of this because otherwise it’s just like the meeting transcripts you get out the back of Zoom and nobody, like nobody looks at those.\nTaken as given: reliable speaker ID, timestamps and geography.\nFuture: so how about using the transcripts as training data to make AI colleagues. Instead of searching for what my teammate X has said, why not make a bot that knows everything that X knows, and then have a conversation with them? “Hey X what was it I said I was going to email you today?” – that kind of thing.\nRealtime instrumented conversation will be disruptively weird and maybe also positive.\nHere’s us+ (2013) by artist Lauren McCarthy with Kyle McDonald, a plugin for Google video chats that encourages equal voices in meetings.\n\nus+ is a Google Hangout video chat app that uses audio, facial expression, and linguistic analysis to optimize conversations based on the Linguistic Inquiry Word Count (LIWC) database, and the concept of Linguistic Style Matching (LSM). The app displays a visualization, provides pop up notifications to each participant, and takes actions (like auto-muting) when the conversation gets out of balance.\n– Lauren McCarthy, us+\n\n(Thanks Daniel Goddemeyer for the pointer.)\nIt’s a great provocation, right? It’s pretty punchy.\nAnd this is what a good chair already does, isn’t it. Makes sure all voices are heard, coaches people into good team behaviour.\nSo why not build that into the software? It means that meetings can be smaller (tighter, more effective) because the “chairing” capability doesn’t need to be in the room. Some teams are naturally good at this, some need help.\nIt’s definitely the feedback loop that matters here.\nAnyway. Good to see some experiments before this all kicks off for real.\n",
    link: "/home/2022/12/14/transcription",
  },
  {
    title:
      "Action Cat! A new experiment around bots, video calls, voice, and spreadsheets",
    date: "13.08, Thursday 15 Dec 2022",
    content:
      "If you have any calls on Zoom or Google Meet today, we just launched a voice-enabled bot to track reminders, and you can try it right now.\nTWIST: it transcribes to a shared Google Sheet so you can change what keyword you’re searching for during the call, or see in realtime who has asked the most questions, or add your own formulas.\nHere’s the project page.\nReduct Action Cat: a hackable voice-enabled call bot.\nLaunch the bot from there.\nThere’s background thinking + links to influences at the bottom.\nThere will be bugs and trip hazards I’m sure - Action Cat is an experiment - but the realtime spreadsheet makes it work for me in a way that less flexible transcripts don’t, and I love using it. It should be built into all video call products.\nSo Action Cat is a new collab with the team at Reduct: a collaborative transcript-based video platform where everyone can review, search, highlight and edit video, as easily as text.\nIt started as an exploration (what would happen if meeting actions dropped into a shareable, editable spreadsheet?) – but as we chatted and tried the in-development bot, interesting feedback loops appeared.\nYou find yourself changing the remind me keyword to dig back through the conversation, or even in the last 5 minutes of the meeting searching ? to see if everyone’s questions have been answered (the transcription AI picks up queries).\nOr writing a new function to add up durations to reveal who has been dominating the call…\nAll of that is in the Google Sheets template, and the spreadsheet belongs to you after the call so you can parse the transcript however you want.\nALSO! This is a new way of working for me. I’m grateful to the Reduct team, specifically Robert Ochshorn and Ned Burnell, for being up for experimenting with weird interfaces on a real, established platform.\nReduct is much deeper and technologically deft than Action Cat reveals. It has been a joy to find a team so engaged in probing the possibilities of interaction on top of building out their core product. \nI’d be up for other collabs in the future so please do get in touch if you’ve got some intriguing tech to play with.\nI wrote two speculations, earlier this week, sparked specifically by this collab, and I wouldn’t have been able to write them without it:\n\nLet’s use spreadsheets to rewire apps and make new ones is about Adaptive Design – it is so powerful to be able to extend and explore functionality like this, and I hope more apps have spreadsheets like “wires hanging out the back” one day.\nTranscribing all our conversations 24/7 will be weird and also useful maybe looks at other people using machine-readable voice in interesting ways – there’s a lot to explore in conversational feedback and always-on voice commands, and this is a future which is surely coming, for better or worse.\n\nMy takeaway here is to be reminded of the value of thinking through making.\nThere are ideas I can access, really concretely, and speculative leaps I can make only once I have been through the loop of making and experiencing with real material.\nAnd also now I have an actual thing I can use to explore these abstract ideas further.\nAnyway. It’s nice to launch something. Ta da etc.\nPlease do try Reduct Action Cat and share it with your friends and colleagues.\nDo weird things!\nLet me know what you invent.\n",
    link: "/home/2022/12/15/actioncat",
  },
  {
    title:
      "Do not buy three decades of loo paper, nor depart today for Barnard’s Star",
    date: "16.15, Tuesday 20 Dec 2022",
    content:
      "Say you were flying to Barnard’s Star, 6 light years away. Should you set off today? Or are you better off waiting a century or two for starship technology to improve and leaving then?\nIn not-unrelated news: Ben Terrett, friend and appointed Royal Designer for Industry, recently revealed his fantasy of buying three decades of toilet paper in one go: If I won the lottery the first thing I’d do is buy enough toilet rolls and enough bin liners for the rest of my life.\n\nFirst let’s think about how many you’d need of the rest of of your life. I’m 47 and the average life expectancy of a UK male is 80 years old. So I’ve got 33 years left to live. (That doesn’t sound like much tbh.)\nThe average UK household uses 100 toilet rolls a year so that’s 3,300 more toilet rolls. A hipster toilet roll like Who Gives A Crap costs £1 a roll so that’s £3,300. …\nMaybe we should bite the bullet and do that now. Storage might be a problem. Hence the lottery win and I could buy a house with a room just for bog roll and bin bags like the Kardashians or something.\n– Noisy Decent Graphics, If I won the lottery (2022)\n\nAlso he says I thought I’d try and get all Matt Webb about this, which is a red rag to an etc. \nUsually I would be in favour of this kind of brave domestic optimisation. (For years I’ve stacked up my paper post into giant piles and I batch-open every 6 months. It’s way more efficient and I barely ever get sent to collections nowadays.)\nHOWEVER.\nBack to Barnard’s Star.\n(Barnard’s Star being the traditional destination to consider for speculative interstellar travel because of the 1978 engineering study, Project Daedalus, as previously discussed.)\nThere is something called the wait equation.\nCurrent technology would allow us to reach Barnard’s Star in 12,000 years, setting off today.\nOr: wait.\n\nIf technology growth is likely to double every 100 years the speed at which this journey could be made, then, using equation –1, it would seem that a voyager need only wait 690 years or so to make the journey in 100 years or less (i.e. at a speed of 6/100 speed of light). In other words, the star could be reached in well under a thousand years from now simply by waiting. Total time to destination is 690 years of wait + 100 years of travel = 790 years.\n\nSo don’t leave too early. Not only would it take longer, but early leavers will become latecomers, behind the wave of progress, those annoying historical curiosities, hardly at the forefront of social change … little to contribute … a thorn in the side of the authorities. (The anachronauts from Greg Egan’s Schild’s Ladder, if you’ve read that.)\nBut also don’t leave it too late: the journey time will keep dropping, but decreasingly, and after a certain point progress won’t help you overtake those who have the head start.\nThe sweet spot is what the wait equation is for. (It’s heavily dependent on economic growth rate assumptions.)\nSee Kennedy (2006) in the refs below. PDF available at that link. Further discussion at the blog Centauri Dreams: Barnard’s Star and the ‘Wait Equation’.\nSIMILARLY:\nGot a long computer program to run? Why start now?\n\nWe show that, in the context of Moore’s Law, overall productivity can be increased for large enough computations by ‘slacking’ or waiting for some period of time before purchasing a computer and beginning the calculation.\n\nGottbrath et al (1999).\nThat paper via Ethan Mollick on Twitter, who also points out a related theory that aliens are quiet because they are… hibernating?… waiting for computers to get better?\n\nIn fact, this is basically one of resolutions to the Fermi Paradox: the Aestivation Hypothesis suggests all the powerful alien civilizations are merely sleeping between the stars until computing power becomes better. Ph’nglui mglw’nafh Cthulhu & all that.\n– Ethan Mollick (@emollick), 7:06 PM, Nov 28, 2021\n\nThe Aestivation Hypothesis!\nSandberg et al (2017). Both papers linked in the references below.\nSo, loo paper.\nImagine stocking up with a lifetime supply in the 1990s and then a few years later they invent the multi-ply quilted aloe vera rolls – and you can’t get any because you’ve got a whole room full of the thin scratchy stuff, you’ve got no room. And you can’t offload any to make room because nobody wants it; they can get the luxury paper for cheap-enough.\nOr what if you’d had the misfortune to stock up in 1997 and your Kleenex was illegally embossed with Penrose tiles. No reselling without IP violations.\nToilet paper innovation barrels along. Less than a century ago: by 1930 toilet paper was finally manufactured ‘splinter free.’\nWho only knows what it will be like in another decade or two.\nAt this point I should calculate the wait equation for loo paper given technological progress curves and opportunity cost of storage space and the utility function of wiping your bum and so on. I imagine there’s an optimum number of years to purchase in advance.\nBut anyway.\nBuy as you go, probably.\nRefs.\n\nKennedy, A. (2006). Interstellar Travel-The Wait Calculation and the Incentive Trap of Progress. Journal of the British Interplanetary Society, 59, 239-246.\nGottbrath, C., Bailin, J., Meakin, C., Thompson, T., & Charfman, J. J. (1999). The Effects of Moore’s Law and Slacking on Large Computations. arXiv.\nSandberg, A., Armstrong, S., & Cirkovic, M. M. (2017). That is not dead which can eternal lie: The aestivation hypothesis for resolving Fermi’s paradox. arXiv.\n\n",
    link: "/home/2022/12/20/wait",
  },
  {
    title: "My most popular posts in 2022 and other lists",
    date: "15.01, Wednesday 21 Dec 2022",
    content:
      "This is simultaneously the wrap-up post for 2022 and also the “Start here” post for new readers. Hello! You’ll find stats here and lots of links.\nAccording to Google Analytics, my 5 most popular posts in 2022 were (in descending order):\n\nI wish my web server were in the corner of my room (10 Oct)\nDunbar’s number and how speaking is 2.8x better than picking fleas (5 Apr)\nA meander through Martian minutes and the meaning of local time (18 Jan)\nTraining my sense of CO2 ppm (14 Jul)\nLightbulbs were so startup (18 May)\n\nHere are some more! 20 most popular in 2022.\nOften my personal faves don’t make the popular list. I’ve collected my favourite, most speculative posts, on topics like\n\nInterstellar travel and how to explore the galaxy\nRoko’s basilisk and how to escape it\nAIs as NPCs and in archives\nBritish hedges\n\nExplore here: 20 speculative posts in 2022.\n(Some posts have extra tags. Please do go spelunking if a topic catches your eye. Dolphins seem to come up a bunch.)\nMore starting points!\nAlong with the speculative stuff, I have a couple of other long-running themes:\n\nPolicy, organisations, and innovation continues to fascinate. Explore posts tagged ‘political-fantasies’.\nFuture multiplayer interfaces has become a touchpoint for thoughts on design, software, computing history, psychology, and more. I made a visualisation of the whole topic. Explore this map of posts about ‘togetherness’. (Background here.)\n\nAnd then two posts which are outliers in different ways:\n\nFiction: The Prompt Whisperer (8 Mar) – a near-future short story about something a little like GPT-3, creative work, and a person who is uncannily good at prompt engineering.\nPrototype: Action Cat (15 Dec) – this experimental voice bot joins your Zoom or Google Meet call, and transcribes in real-time to a hackable Google Sheets spreadsheet. A collab with Reduct.Video.\n\nOn The Prompt Whisperer: Bruce Sterling said, on Twitter, It’s pretty good, too. I recommend a look at that. – which hands-down made my month.\n(Dear reader: if you have a particular favourite post from 2022 which isn’t listed then I would love to know! It would be interesting feedback.)\nPREVIOUSLY!\n\nMy most popular posts in 2020 and other lists.\nMy most popular posts in 2021 and other lists.\n\nOther ways to read and so on:\nIf you’d like to subscribe (it’s free)…\n\nSign up to receive new posts as an email newsletter. There are currently 722 subscribers\nSubscribe to the RSS feed using your newsreader. I don’t know how many subscribers there are but somewhere north of 1,600 according to the centralised newsreaders that share their stats. (Learn about RSS feeds here.)\n\nI love my posts being shared round. So if you read something you like, please do pass it along and post on whatever groups or socials you’re part of.\nI like email replies – I like talking to people even more. I started opening my calendar for Unoffice Hours a couple years ago and it’s still the highlight of my week. Learn more and book a time here.\nThis year I’ve been collecting nice things that people have said about my blog. From the file:\n\nMaggie Appleton on Twitter: Titling is an underrated skill. @genmon has a special talent for it – I am delighted!\nPatrick Tanguay in Sentiers: Matt Webb doing Matt Webb things – which I think is a compliment??\nRobin Sloan in his newsletter: an effervescent fountain of ideas. Super kind and at least 50% because I’d just posted about fizzy gravy.\n\nThank you!\nSome stats.\n\n2018: 16 posts (19,259 words, 152 links)\n2019: 8 posts (7,267 words, 78 links)\n2020: 116 posts (94,349 words, 713 links)\n2021: 128 posts (104,645 words, 765 links)\n2022, to year end: 96 posts (104,636 words, 711 links)\n\nSo I’m coming up to three years of this “voice” – this frequency, these topics, a certain kind of structure to each post, this position on the dial that mixes speculative and yeah-I-kinda-mean-it-actually.\nMy current streak: I’ve been posting weekly or more for 143 weeks. Blimey.\nI like writing! I’ll stop when it becomes a chore. For the moment this is my practice; my imagination happens in my fingers, and I figure things out by writing them down.\nThanks for reading. I appreciate you being here.\nUpdate 30 Dec, 2022: Finalised 2022 stats, above.\n",
    link: "/home/2022/12/21/top_posts",
  },
  {
    title: "What I’ve been reading in 2022",
    date: "17.42, Friday 30 Dec 2022",
    content:
      "Some books I read this year:\n\nMy Tiny Life: Crime and Passion in a Virtual World, Julian Dibbell (27 Jan) – full text on author’s site\nThe Employees: A workplace novel of the 22nd century, Olga Ravn (13 March)\nJurassic Park, Michael Crichton (23 March)\nThe Nine Tailors, Dorothy Sayers (15 May)\nThe Art of the Publisher, Roberto Calassa (10 June)\nComputers as Theatre (first edition), Brenda Laurel (10 July)\nThe History of Magic: From Alchemy to Witchcraft, from the Ice Age to the Present, Chris Gosden (18 July)\nTo Be Taught, If Fortunate: A Novella, Becky Chambers (13 November)\n\nSocial software\nDibbell’s My Tiny Life is from 1998 and about LambdaMOO, a super early multiplayer text environment. It’s all there: politics, sex, money, governance, abuse, doxxing. As clear a case study as we could get. I raved about it here.\nIn Computers as Theater (1991), Laurel suggests that we see the computer interface not as the conversational tit-for-tat of request and response, but as establishing common ground: mutual knowledge, mutual beliefs, and mutual assumptions.\nAnd then:\n\nLaurel suggests that we see the computer screen as a stage on which there are agents, some human and some software.\n\n(Similarly raved about here.)\nBoth books were re-reads after a couple decades, and both are suddenly astoundingly relevant again in this age of fediverses and multiplayer metaverses. In my imaginary monograph on tools for togetherness, both are canonical texts.\nGood words in fiction\nJurassic Park – Michael Crichton is so plain and so deft, not a word wasted, with poetic flourishes that are all the more vivid for their rarity: The surface of the lagoon rippled in pink crescents. The guy’s a virtuoso, I’d forgotten.\n(Hey and remember, dinosaurs are the company’s second product.)\nNine Tailors – good old fashioned detective fiction. I haven’t read Dorothy Sayers in years and… well the first section is so ornate, so dense, all church bells and the landscape of the Fens, utterly transporting.\nThe Employees is delicate, poignant, ambiguous; a collage of fragments of first-person narrative from an uncertain future starship. I really liked this AND was vaguely dissatisfied - yet can’t stop thinking about it. Form: hypertext! Content: factory workers!\nTo Be Taught… oh Becky Chambers. I’ve been a space opera fan as long as I’ve been reading, and Chambers has the awe and the humanism that makes me want to live there. I now understand this genre is hopepunk - weaponised optimism - so that’s a trail I’ll have to follow.\nThe Art of the Publisher talks about the books coming out of a publishing house as a single work. Hypertext again.\nThe History of Magic is a history of the last 40,000 years. It’s the kind of book I love these days: very little TED-style framing, heavy on the information, draw your own conclusions. There is an overarching argument, of course, even if it sits lightly, which is that magic is a permanent strand of human culture alongside science and religion; and that magic, generally, provides cosmic kinship and a framework to ask “should we”… It’ll make more sense if you read it.\nMy favourite section: Shamanism and Magic on the Eurasian Steppe (c.4000 BCE–present) – animism and landscape, and a kind of deep bedrock to the euro/anglo psyche that I wouldn’t have noticed without having it drawn out.\nIt’s been a long time since I dogeared so many pages in a book.\n",
    link: "/home/2022/12/30/reading",
  },
  {
    title: "Solving the Rubik’s Cube and other hard-to-recognise problems",
    date: "21.49, Monday 4 Jan 2021",
    content:
      "A Rubik’s Cube can be solved, from any position, in 20 moves or fewer.\nThis “worst case” number for the Cube - i.e. the shortest path to solve the hardest position - is called God’s Number. It’s hard to figure out the hardest position because you have to look at every single configuration (there are 43,252,003,274,489,856,000) and then, to compare, calculate the shortest solution for each.\nIn 1981, mathematicians proved that God’s Number couldn’t be more than 52. By 2008, this was down to 22.\nFinally, in 2010, there were just 19,508,428,800 different positions left to check, in order to prove God’s Number once and for all. Instead of doing it with equations and theory, it could be brute forced – the solution for every one of those positions calculated on a computer. BUT this calculation, running on a good desktop PC, would take 35 years.\nSo they worked with Google, who took the calculation away and complete[d] the computation in just a few weeks.\nFull story (and paper) here: God’s Number is 20.\nWhat I’m most impressed by: the realisation that the time for being clever is over, and it’s possible to throw supercomputers at the problem. Like, that’s not an easy realisation. 3 years earlier is two Moore’s Law doublings. Running the calculation in 2007 would have taken, say, 6 months and not “a few weeks”, and that’s longer but still a darn sight quicker than 35 years: tolerable. So we can say that the realisation that the problem was solvable, from the moment that it was solvable, took at least 3 years.\nASIDE: A few years ago, I dropped a note to the mathematicians to ask about one point, and they were kind enough to reply.\nI wanted to know whether the state space of the Rubik’s Cube was 20 moves “across” – or perhaps was it 40? That would be the case if Distance-20-state-A was 20 moves from the solved state, and Distance-20-state-B was also 20 moves from the solved state, but there was otherwise no route between A and B. My intuition said that, from symmetry, there wasn’t anything special about the solved state to make the centre, so it should be the former… but I don’t know any group theory, so I had to ask.\nThe reply: our result implies that any state is at most 20 moves from any other state.\nSo now you know too.\nThis feels related to AI overhangs, when you have had the ability to build transformative AI for quite some time, but you haven’t because no-one’s realised it’s possible – and then artificial intelligences get 100-1,000x more competent in a matter of months. The blocker is the realisation.\nI wonder how many problems are hidden from us because we unconsciously dismiss them as 35 year problems.\nAnd I wonder how many of those 35 year problems are actually “a few weeks” problems, if you have enough compute.\nIn psychology and design, there’s the concept of the affordance. When you look at a mug, you also see that it “affords” being picked up, because you see that it has a handle, and that the handle is the right shape for your hand, and so on. Affordances have an existence in the brain: seeing the handle primes your hand to get ready to grip it. And a mug that didn’t afford being picked up wouldn’t even be a mug.\nSo what I’m saying is that maybe there is a class of problems which lack the solvability affordance. Because we don’t see them as solvable, we don’t even recognise them as problems.\nCan we methodically find and recognise problems like this, without having to wait to stumble across them? Maybe we could start by identifying knotty areas currently solved heuristically, then checking to see whether we can remove the need for heuristics.\nFor example, markets are a heuristic method. We “solve” the problem of house prices, and wages for software engineers, and the price of coffee, etc, with markets. What if we don’t need markets anymore, and all of these scenarios can be solved for fairness and efficiency – computationally?\nAnd so on.\n",
    link: "/home/2021/01/04/rubiks_cube",
  },
  {
    title: "How about finding new books by mapping who thanks who?",
    date: "14.48, Tuesday 5 Jan 2021",
    content:
      "I remember reading The Red Men by Matthew De Abaitua, which is near-future sci-fi (and, in 2021, barely sci-fi at all) about AI and robots, simulated worlds and algorithms, cults and, um, marketing agencies - it’s an amazing book, highly recommended - and all the way through I was thinking: what’s amazing is that I don’t know this guy. The themes and the twists on ideas were just so electric-yet-familiar, like it was directly for me and the people I knew.\nThen I got to De Abaitua’s Acknowledgements on the final page and there, thanked in the first line, was a key person at his publisher: artist and writer James Bridle, very much responsible for shaping what my world was and is thinking about. At the time Bridle and I were working in physically adjacent studios. That makes sense, I thought.\nI’ve just had a similar experience:\nAfter reading The Institutional Revolution by Douglas W Allen (see my list of favourite non-fiction read last year), I’ve been recommending it far and wide. And I just looked at the back cover, and the book is blurbed by Tyler Cowen of Marginal Revolution – not someone I know personally, but the blog is legit one of my favourites reads. It wields economics like a scalpel for a incisive perspective on all kinds of topics.\nCan we flip this?\nI would love book recommendations based on acknowledgements and endorsements, rather than reader ratings.\nTWO BRIEF ASIDES.\nThe best line in The Red Men is this one:\n\n‘I’m giving you a direct order. Take the drug!’\n‘This is not the military, Bruno. We work in technology and marketing.’\n‘We work in the future!’ screamed Bougas. ‘And this is how the future gets decided.’\n\nTechnology and marketing and hubris. You can see why it spoke to me.\nSecondly, Matthew De Abaitua was kind enough to contribute to my old 3 Books Weekly newsletter back in 2016. Here, with blurbs, are his three book recommendations.\nCiteSeer indexes scientific papers, and lets you explore by listing papers that also cite the one you’re currently reading. (And then ranks the papers by how many times they are cited, and so on.)\nCiteSeer first appears in my notes back in 2001, and it was a revelation to be able to research this way. Search for terms, rank papers by reputation, explore the siblings in the citation tree to discover alternate points of view, etc. There used to be a graphical explorer were you could tap and zoom around the whole citation graph. I can’t find it now.\nGoogle Scholar does something similar. For example: here are the 86 publications that have cited Mind Hacks.\nThere is a whole field of citation analysis, and you can imagine being able to look for high-level patterns in the scientific literature like bubbles of groupthink, or multi-year controversies and schisms. Or perhaps you could build an early warning system for new scientific paradigms emerging – or spot old ones creaking.\nWhat I’d like is CiteSeer but for books, making using of the softer signals.\nWho does the author thank? It’s a highly meaningful signal: if they thank someone I’ve heard of and rate (and especially if it’s someone I know), I am going to look at this book in a different way. Debut novels often thank other authors who have helped them along the road, but it’s the non-authors who are thanked that I find particularly interesting. I always like checking the Acknowledgements page.\nWho blurbs the book? Book blurbs aren’t blind marketing. No author wants to endorse something terrible, and that reputational risk means that blurbs are meaningful. But also, an author blurbing another author’s book means that they know each other in some way. They are in the same idea space.\n(It would also be neat to extract the bibliography for non-fiction books. I think the utility of bibliographies goes beyond the citation graph. A bibliography tells how close this book gets to primary sources, which is a clue to its originality or how academic it is. And I also get a sense of the overlap with ideas that I’ve already encountered.)\nI’d like ways to explore the network of influence and gratitude.\n\nWho else thanks the people who are thanked in books that I love? And who do I know?\nWhat books are blurbed by people whose blogs I read, or by people who appear in my email inbox?\nCan this be joined to the annual publishing schedule, so that I get a live feed of upcoming books with which I have a strong connection?\n\nMore interesting data to be revealed: Who are the “dark matter” agents, commissioning editors, and mentor authors, i.e. the people who crop up the most, in the most popular books?\nRecommendations based on this wouldn’t be based on the taste of the average reader, as star ratings are, but instead reflect the book’s position in idea space, and what is adjacent to - or deliberately distant from - what I’ve already read.\nIt feels like the kind of thing Google Books or Amazon/Goodreads could do.\nGoogle and Amazon both have a massive corpus of scanned books, an existing database of known titles and authors, plus the requisite machine learning chops… it would be a good side project for someone there. Let me know if you have a go and want some early product feedback.\n",
    link: "/home/2021/01/05/citeseer_for_books",
  },
  {
    title: "The continuing rise of virtual private neighbourhoods",
    date: "21.01, Thursday 7 Jan 2021",
    content:
      "People are increasingly hanging out in small, private communities. Global timelines and newsfeeds won’t come back.\nThe shift looks something like this:\nAs covered by this excellent edition of Garbage Day, Twitter shows all the characteristics of a rotting online community. How to recognise a rotting community, quoting the full list:\n\nPower users aggressively dominate discussion on the site.\nPublic harassment and inter-community elitism has created a culture of indirect communication, where users no longer directly say what they’re actually trying to say.\nThere is no longer any internal cultural memory.\nUsers have become so obsessed with the minutiae of the community that the site now functions as a meta discussion of itself instead of whatever its intended purpose was.\nPoor or lax moderation has created a sense that nothing on the site is genuine - fake users, fake trending topics, fake threads, fake engagement.\nUsers, reacting to the inauthentic behavior, public harassment, and elitism that occurs due to bad moderation, create their own self-policed communities within the larger community, which typically only exacerbates these problems and creates warring factions within the site.\n– Ryan Broderick, Garbage Day (2 Dec, 2020)\n\nMeanwhile, only the olds use Facebook (including me), but everyone younger has mostly vanished, being increasingly uncomfortable with\n\nad microtargeting and its rapacious data appetite\nliving your online life in the open with the perpetual risk of context collapse and your whole identity blowing up from one misguided status update that another group takes offence to.\n\nSo this is the end of the era of global timelines. Who would take on the responsibility of content moderation to build another one.\nWhere is everybody going instead?\nWell there are the peer-to-peer and small group spaces of texting and WhatsApp.\nBut the problem of peer-to-peer is that you don’t get those joyous, serendipitous moments of running into like-minded friends-of-friends.\nIn-between:\nThere are private Discords, private Slack channels, and a flurry of spatial interfaces in development. They’re immune to data harvesting, invisible from search engines, and there’s no context collapse – good fences make good neighbours.\nAs the global timelines get abandoned, this is where people are homesteading.\nAnd doing all the usual things of chatting, sharing links, giving support, falling out, making jokes, and all the rest.\n…Or so I’m told.\nI’m no zillennial hanging out in a handful of private Discords. Instead I have a blog, which is like being a big noise in ham radio, or an unironic aficionado of VHS. \nMy own, limited experience of this, from back in 2015:\nIf the global timeline feels like a city, a private Slack group feels like a neighbourhood.\nI do not include in this “virtual neighbourhood” space media like newsletters and podcasts, both growing fast rn.\nPerhaps what we’re seeing is the disentangling of social media back into social and media: newsletters and podcasts are best understood as being part of the media spectrum, even if many of them are smaller and have community spaces attached. And Discord space, Slack spaces, etc, these virtual neighbourhoods are pure social.\nI’d love to understand these virtual neighbourhoods better.\nMy hunch is their optimum size will hover around the Dunbar number of ~150, fewer if you’re just looking at active members (you need a mix of active and less active in any community).\nBut has anyone published any research on this?\nWhat is the distribution of populations of private Discord groups and other similar spaces? How many groups do people belong to? How does this time take away from other activities? Is there a typology of groups and how they start? How well do people know each other? Is there a typical lifecycle? Are there temporary groups and persistent groups? Is there a difference in the culture created vs the global timelines? Etc.\nAnd let’s assume that this grows into the dominant mode of socialising online in the 2020s:\n\nWhat does this mean for the nature of celebrity?\nWhat about the businesses that rely on data capture, and in particular what about advertising?\nWill these make echo chambers problems worse or better?\nWhat are the new product opportunities?\n\n",
    link: "/home/2021/01/07/dunbar_spaces",
  },
  {
    title: "Headphones need smart transparency mode with voice recognition",
    date: "11.41, Friday 8 Jan 2021",
    content:
      "Headphones should have smart transparency mode, letting in only specified sounds and catching all other noise at an audio firewall.\nI have a vague memory that I first ran across this concept in ear defenders for hunters. These were “transparent” in that the hunter needs to hear the distant sound of a stag stepping through the undergrowth – and then active noise cancelling would kick in instantly for a rifle shot.\nAnd that’s clever. I would like the same functionality but in reverse.\nI’ve got my headphones on right now because I need to focus. But I’m concerned I might miss the postman if he bangs at the door.\nIf I had fancy modern headphones, the answer would be to turn on transparency mode, so that my music is layered with the ambient noise of my environment. But that’s exactly what I don’t want! I don’t want to hear people talking downstairs, or a truck idling outside my window.\nWhat I want is active noise cancelling, with smart transparency mode that kicks in automatically if\n\nthere is a knock at the front door\nthe cats meows, or there’s any kind of crying\nor, somebody says my name.\n\n(The final one like getting an @mention notification but in real life.)\nI want to hear those things, and nothing else.\nI note that Apple recently and quietly launched, as an accessibility feature on iPhone, Sound Recognition: Your iPhone can continuously listen for certain sounds - such as a crying baby, doorbell, or siren - and notify you when it recognizes these sounds.\nSo my guess is that this is on the roadmap, and AirPods will end up being quite the app platform.\n(Or rather, given they have spatial audio, and AirPods share a high-precision ultra-wideband, spatial positioning chip with the watch and also phones, quite the component in Apple’s inevitable not-too-distant-future wearable augmented reality app platform.)\nOkay back to work.\nP.S. I have just been reminded that, back in February 2019, on the bus a small child thought my Apple AirPods were a new kind of cigarette and that I was smoking with my ears.\nUpdate: On Twitter, Hans Gerwitz suggests I want to allow my partner’s voice to punch through. Should be pretty “easy” if we’re both wearing them, eh?\nWhich is smart! And weirdly ageographic. It would work the same if you were in the same room or 1,000 miles apart.\nThat’s the second time ageography has come up recently. Perhaps it’s a thing.\n",
    link: "/home/2021/01/08/transparency_mode",
  },
  {
    title: "Speculative ad formats for the post-newsfeed world",
    date: "21.31, Monday 11 Jan 2021",
    content:
      "So I was on a call recently, talking about people abandoning the global timelines like Twitter and Facebook, and instead hunkering down in private Dunbar-number-scale virtual neighbourhoods, such as Discord servers etc, as discussed last week.\nAnd, on this call, because of the fact that these virtual private neighbourhoods don’t collect personal data, and therefore can’t target ads, I mentioned something like: well advertising will have to change.\nAnd they said, how?\nAnd because I’ve been thinking about this for a little while, and because while I like advertising (generally speaking it’s a straight-up way to find out about new things), the capability of microtargeting is a societal risk like having water pipes made out of lead, I had in mind a few speculative alternatives.\nAll of which is to say: here are three quick ideas about at-scale advertising into zero personal data private communities.\nTarget communities, not individuals\nIn the old days, adverts would target publications by interest and demographic.\nToday, newsletters and podcasts are both growing: A fat middle of ongoing publications around specific interests and personalities, building audiences – engaged audiences who are demonstrably investing time (podcasts) and money (Substack newsletters) in continuing their engagement.\nSo who is building the ad machine to target these communities en masse?\nAt the moment, if I want to spend $100k advertising on Facebook, I can. But how can I, at scale, choose a collection of communities to advertise into, with enough volume and diversity that it’s possible to run auto-optimising algorithms?\nCould each publication submit a gestalt view of their audience (demographics, interest, readiness to purchase, etc), and targeting is a matter of choosing the right collection of audiences, but not targeting within the audiences?\nWhile it’s not desirable (or even possible) to collect data on individual clickthrough, maybe there’s a startup in collecting data on conversion stats for different communities?\nWhat’s the Audit Bureau of Circulations of pro-am online media?\nTelepresence adjacency\nThe traditional way ads work is that you find a place where people are hanging out, with a relevant sentiment, and you place a message next to it.\nAdjacency works well on a newsfeed: you get people in the mood to respond and tap and act, then you put an ad in the way and… people respond and tap and act.\nBut if everyone is spending their time in private Slack channels, or private Discord servers, not scrolling but actually socialising, then what does adjacency look like?\nFor me, the answer is that people will be hanging out in multiple spaces. That’s another difference when the global timelines go away. It’s not 100% Facebook, it’s ~10% each in a dozen different spaces.\nSo the future will include a variety of\n\nlong-running home spaces (where we socialise with friends or interest cohorts)\npersistent but touristed spaces\ntemporary spaces, like events.\n\nImagine MakeSpace teams up with Tate Modern to make a persistent museum space with art to experience, explore, and learn about. People will visit that space and hang out with their friends – why not? It’s more fun to chat when there’s stuff around you to look at and play with, and you might run into people too.\nc.f. Monterey Aquarium sets up shop in Animal Crossing.\nOr there are ephemeral spaces that pull huge crowds. There are temporary spaces that people travel to, e.g. in-game concerts. (Simply streaming concerts doesn’t count. You have to have the social space otherwise there’s no interaction adjacency going on.)\nSo what are the billboards for virtual spaces, and how do you price them?\nThere’s Bidstack in this space, which I am super into as a concept. They allow advertisers to buy spots in-game: trackside banners, cityscape billboards, pitchside LED boards and other native spaces within the virtual world.\nBut virtual billboards in virtual events are a blunt instrument.\nThink of the real world. Where are the in-game stands doing giveaways, the leaflets, the limited edition t-shirts, etc. There can be equivalents of all of these.\nIndustrial-scale micro-influencers\nThe scenario is this: everyone spends their time in private Slack groups and private Discord servers. There’s no data collected, and no ads. How am I, as a business, supposed to let people know about my new shop, or sell these new shoes, or get people only my subscription fashion business, or drive signups for my new video tool, and so on.\nThe answer is that you go door-to-door.\nWe have the equivalent of door-to-door sales in social media already: influencers. Somebody has an expertise, and an audience, and they plug product in their feed for money.\nBut instead of 1 or 2, or even a half dozen, how can a brand have 100,000 influencers?\nLook, people love to be associated with the brands they love.\nInstead of making influencers endorse brands on their public feed, and turning them into media, treat them as ambassadors. Have a scheme where people can sign up to get (say) advance versions of unique Heinz drops - I guarantee there will be people who are into exclusive flavours of spaghetti in a can, of all walks of life - and maybe a discount, and all they have to do is ensure that a certain number of people from their allotted community Discords tap on a certain link.\nThe cost around this is prohibitive right now, which is why it can’t happen, and you would need a way to prove that certain clicks came from certain communities – even if you didn’t know the individual who clicked through.\nBut, with work, I bet you could industrialise the process, and appropriate the language of ambassadors and drops from high margin brands, making it available as a standard marketing product.\n(Anyone who grew up in bars in the 90s will remember encountering “cigarette girls.” Here’s a write-up from someone who did the job. I hadn’t remembered cigarette girls until just now. Blimey, let’s not do that again.)\nBONUS: Industrialised influencers who are bots. Chatbots are getting pretty good. I read about someone recently who had configured a chatbot to act a bit like his long-distance girlfriend, and was way more into the bot. So alongside the ambassadors program, I would suggest making chatbots that can be added to these private social spaces, and while they flirt and socialise and tell jokes, they also every so often suggest stuff to buy.\nYou fish where the fish are.\nAs a business - an advertiser - there is an upcoming need to reach people in spaces that currently do not allow for gathering personal data, targeting ads, or collecting conversion metrics.\nMaybe tools to collect said data can be built. But that would be very much against the tide of GDPR and consumer sentiment.\nInstead: let’s think about how to advertise with the minimum of data, not the maximum.\nThere are a bunch of startups embedded in the notes above and, although this is unlikely, maybe one of them has a path to a format like the banner ad, or a clever sales model like AdSense.\nBut if I were an established online ad broker, I would be working wildly to figure this out now, because otherwise one of those startups might get there first.\n",
    link: "/home/2021/01/11/advertising",
  },
  {
    title: "Using printed QR codes for links in books",
    date: "16.55, Tuesday 12 Jan 2021",
    content:
      "I’m currently reading Alexandra Deschamps-Sonsino’s excellent Creating a Culture of Innovation, which is simultaneously a survey, history, and playbook for how to invent the future from inside corporations.\n(Cleverly, Alex is serialising the book as a series of free Friday lectures, starting later this month. Register for tickets here.)\nThere are many links in the footnotes, which is great. But I like reading on paper (it helps me focus) and it is tedious typing URLs into my phone browser letter by letter.\nWe had a similar problem with Mind Hacks, and our workaround then was to put all the links on a single web page. Functional but not great.\nSo I was very taken with Tom Critchlow’s recent experiments with printed QR codes (for his upcoming book on indie consultancy):\n\nIs there an “in-line” QR code format? The print book <–> HTML connection is awful. Best standard seems to be footnote the link and then print the URL…\n– Tom Critchlow (@tomcritchlow), 8:21 PM, Nov 23, 2020\n\nHe shows a couple of elegant examples of what he’s looking for, such as\n\na tiny QR code in the margin\nwonderfully, a word-sized QR code inline with the text.\n\nQR codes are a neat solution because smartphone cameras natively resolve them to hyperlinks, without even taking a photo.\nBUT\nAs this deep dive into printed QR codes shows, there are design challenges:\n\nWeb addresses are long, which makes QR codes bigger\nThe codes can’t be shrunk because they bump up against print resolution limits (and, I’ve found, because smartphone cameras can’t focus on anything too small and too close).\n\nSo, taking this route, you end up with large QR codes on the page. Not ideal. At worst, ugly.\nOf course there are workarounds: one big QR code per chapter, perhaps, providing a menu of all the links in all the footnotes.\nI’d love to see a solution like Critchlow’s original mockups. Inline, robot-readable links have an elegance that reminds me of Tufte’s sparklines. Though perhaps this route has reached a dead end.\nWhat’s the limit on how small a QR code can be printed - and scanned reliably - and what’s the character limit for that? Could it contain a URL?\nIs there an alternative QR code standard which is simultaneously much more compact, and also already supported by smartphone cameras?\nIf we need a whole new standard, we could think about sorting out the opaqueness problem of existing QR codes. What about a robot-readable glyph that was interpreted by the smartphone camera to simply mean: use OCR on the following string of characters and treat it as a web address (or a bank account number, or a Twitter username, or whatever). Basically a robot-readable protocol prefix, like “http:”. That would have the benefit of being robot-readable and human-readable simultaneously.\nBut new standards would take years. I’d prefer tiny QR codes in books that work today.\n",
    link: "/home/2021/01/12/qr_codes",
  },
  {
    title: "Viscerally and deliberately unsettling product design",
    date: "13.38, Thursday 14 Jan 2021",
    content:
      "I’m picking up on a trend of viscerally unsettling product design. My guess is that it’s scouting ahead of the coming wave of robotics.\nExamples!\n\nLim Qi Xuan’s seashell (2021) with sculpted, realistic human tongue and discarded teeth.\nMarc Teyssier’s MobiLimb (2018), a robotic finger attached to the back of smartphones for them to point, crawl, and prop themselves up (as previously discussed in my call for cyborg prosthetics).\nBrecht Wright Gander’s lamp (2020) that is switched on by sliding a phallic conductor inside of a puckered, rubber opening at which point it lights up.\nThis construction of an animatronic tentacle lamp by The Monster Maker (2019). No, I don’t know why he does his YouTube wearing a prosthetic hairy head with realistic but impossibly wide-set eyes. I don’t even know how can see.\n\n(That last one via the SoftRobotCritics tumblr which is excellent for tracking this world.)\nI have to say, I enjoy this sense of discomfort. Absolutely some products should make me feel queasy. My smartphone feels all too smooth and familiar in my hand when I’m indulging in something societally toxic, such as scrolling Facebook, and a soft fabric smart speaker in my home is at odds with the fact that it’s an open mic connected to the cloud. At least when I’m refuelling my car, I have to suffer the unpleasant fumes.\nIt’s necessary and timely to explore naturalness and physicality, and to map the boundary with creepiness, because we’ll clearly have more and more robots in coming years – and the approach right now is either self-driving plastic boxes, or biomimicry, whether that’s robot arms or dancing dogs and humans with backpacks. Maybe there are opportunities in escaping the obvious archetypes.\nSo pornographic lamps are not just about tapping into the absurd. It could be that these designs are a systemic probes of the Uncanny Valley (that’s a translation of Masahiro Mori’s original essay) – and if we see it that way, what else is there to investigate?\nI would usually ask for pointers to more examples, but I’m not sure that’s a smart idea.\nIn the meantime:\nPerhaps we should expect this nascent trend to come into the mainstream and also into the home, just as the original Bondi blue iMac triggered a wave of translucent blue plastic in all categories of product. Existenz-style dishwashers. Giger lightswitches – which may have some advantages over a standard binary switch in terms of the degrees of control, as you would be able to control both the brightness and hue simultaneously simply by inserting your finger into the wall-mounted orifice.\n",
    link: "/home/2021/01/14/disturbing_products",
  },
  {
    title: "The imminent possibility of UFOs",
    date: "20.40, Monday 18 Jan 2021",
    content:
      "Heads up, there might be UFOs, and we’ll find out in June.\nJohn O. Brennan, head of the CIA under Obama, has this to say: I’ve seen some of those videos from Navy pilots, and I must tell you that they are quite eyebrow-raising when you look at them.\nAnd, from that same interview:\n\nBut I think some of the phenomena we’re going to be seeing continues to be unexplained and might, in fact, be some type of phenomenon that is the result of something that we don’t yet understand and that could involve some type of activity that some might say constitutes a different form of life.\n\nNow here’s another interview, also with ex US intelligence.\n\n“Is it fair to boil it down to two possibilities, either another country has leapfrogged the US in technology or extraterrestrial?” Papadopoulos\n“Those are the leading hypotheses, yes” Chris Mellon, Former Deputy Assistant Secretary of Defense for Intelligence.\n– UFO Intelligence Study (@UfoStudy), 8:55 PM, Jan 17, 2021\n\nAnd those feel like the two options:\nEither it’s a Breakaway Civilization, a term introduced to me by this excellent post by Jay Springett:\n\nThe basic idea of the ‘Breakaway Civilization’ is simply that you have a secret group, a classified group of people, with access to radically advanced technology, radically advanced science, and they just don’t share it with the rest of the world. One scientific breakthrough leads to another, and that leads to another and so on. So the next thing you know, you’ve got a separate group of humanity that is vastly far beyond the rest of the world.\n\nOr “far beyond” on just a single axis.\nI’ve previously talked about this as orthogonal innovation, and in this case it is the possibility that there is a country, somewhere, that has gone hard on aviation and aerospace for some decades, and it’s so far beyond what we have now that we don’t know how to interpret it under current physics. It’s either a country, or maybe a group from one of the old superpowers that splintered off 50 years ago and found progress but not yet been reabsorbed.\nOr, it’s aliens.\nFrom the Jerusalem Post: Former Israeli space security chief says aliens exist, humanity not ready.\n\nThis “Galactic Federation” has supposedly been in contact with Israel and the US for years, but are keeping themselves a secret to prevent hysteria until humanity is ready.\n\nThere’s a related conspiracy theory. Here’s the story of Eisenhower’s 1954 Meeting With Extraterrestrials:\n\nOn the night and early hours of February 20-21, 1954, while on a ‘vacation’ to Palm Springs, California, President Dwight Eisenhower went missing and allegedly was taken to Edwards Air force base for a secret meeting. …\n[The event was] the beginning of a series of meetings with different extraterrestrial races that led to a ‘Greada Treaty’ that was eventually signed.\n\nAfter the last few years, I’m reluctant to discount conspiracy theories. Not as facts per se, but perhaps state-actor-amplified chaff and flare to obscure adjacent truths.\nI’m also reluctant to believe that intelligence officers are ever ex-intelligence officers. I’ve a suspicion that a rogue ex-intelligent officer would swiftly and quietly become an ex-ex-intelligence officer. But also, if you wanted to gently trickle information to the public, as a state intelligence agency, this might be exactly how you would start – whether that information were the on-ramp to bigger truths or, again, to obscure adjacent ones.\nAll of which is interesting because, as part of the Covid-19 relief and spending bill, signed into law at the end of December 2020, there was also a stipulation (link to CNN) for a 180-day countdown for US intelligence agencies to tell Congress what they know about UFOs.\n180 days.\nSo, end of June it is.\nWe speculate to anticipate.\nThere was the small chance of supply chain disruption from a “no deal” Brexit – so we cached a small larder of groceries in the cupboard upstairs to hedge against that possibility. As it happens our cache covered us usefully when there was the run on the supermarkets, at the beginning of the first Covid lockdown. Unintended but helpful.\nSerious question:\nIf you accept that there is the small possibility that we will soon find out that there are UFOs, whether aliens or advanced aviation, then how, as a rational individual, should you behave?\nAssuming there’s a Breakaway Civilisation with new physics, perhaps a clever solution to the fluid dynamics equations, discovered by luck in the 1950s, a glitch that makes low-energy aeronautics possible – a way of bouncing off chaotic, artificial vortices in the atmosphere that is in a practical sense indistinguishable from antigravity…\n…if new physics were to be announced in late June, with another country way out ahead, do you buy Lockheed Martin stock today, or do you sell it?\nOr if there are aliens:\nAliens likely indicate faster-than-light travel, which has implications for the current max speed of computation, so I wouldn’t put any faith in cryptocurrency (as it could soon be counterfeited). And actually, you might want to opt out of the global economy entirely, as it might soon be drastically shocked by new technology, so you should keep your wealth in the fundamentals instead. Not gold, as the supply could radically increase (and the price plummet) due to mining in the Asteroid Belt. Perhaps you would buy land?\n",
    link: "/home/2021/01/18/ufos",
  },
  {
    title: "The feeling of percolating on stubborn problems",
    date: "19.33, Tuesday 19 Jan 2021",
    content:
      "I wonder what’s going on in my head while I’m trying to figure out a problem.\nI’ve been in venture building and strategy for a few months (the gig wraps up at the end of this month). Working to understand whole new-to-me sectors, and disruption dynamics, and client capabilities, all well enough to figure out good entry points.\nPeriodically, everything gets stuck in my head. I can’t write, can’t make slides, and I can barely articulate what’s interesting about the area. I can plod through a description, but the “why” and “what for” escapes me, and questions leave me stumped.\nThis lasts for 2 or 3 days. During which time it’s hard to focus on other tasks, I’m mildly short tempered, my to-do list goes untended, etc. Nothing major, just like there’s something occupying 30% of my CPU, if you know what I mean? And then…\nOut of nowhere, the entire thing pops into my head. The key goals, a structured articulation of the market and how it’s evolving, recommended next steps, and all in the form of a top-to-bottom narrative. The deck outline comes out of my hands like automatic writing.\nIt’s not perfect, obviously. It gets presented, tweaked, reordered… It improves mainly through attempting to present it, and getting feedback through conversation. Until the point comes that it’s too brittle: I can see that it’s broken, but I can’t see how to incorporate obviously correct feedback. That’s the point that this deck (or mental model, or narrative) is redundant and it’s time to move onto the next stage, whatever that is.\nBut what’s going on in that 2 days?\nWhat is this “background processing” feeling?\nHow come it’s a black box?\nOther people I’ve asked share this. But what’s happening, brain-wise?\nBaffling.\nIt’s like this for every project I’ve ever worked on.\n(The first time I specifically remember this happening was figuring out an approach to a tricky differentiation in a physics problem that had been bothering me. The whole solution popped into my head unbidden on the dance floor at Downtown Manhattan on George St.)\nThere are ways to move things along. Talking helps. Going back to first principles helps: asking why, researching, writing down what I know in the plainest possible language. Writing down what I don’t know works. For really stubborn problems: running; hot showers.\nBut still the feeling of percolation. Like there’s a sub-mind allocated to the problem, one that has access to everything I know yet sits outside my personal experience of self, and all I can do - all I need to do - is wait.\n",
    link: "/home/2021/01/19/percolating",
  },
  {
    title: "Maps and cameras are neglected app runtimes",
    date: "20.38, Wednesday 20 Jan 2021",
    content:
      "After last week’s post about QR codes in books to make it easy to follow links, there was a common response: Shouldn’t smartphone cameras just read the link? Optical character recognition is, at this point, ancient tech.\nIt’s true.\nCameras\nSmartphone cameras are far too dumb (by which I mean the live preview screen, before you take a shot). The camera view should have little recognisers which allow for tapping on web addresses, and email addresses, and whatever, opening the appropriate app.\nThe camera view should pick up not just QR codes and web addresses but all kinds of text. Clearly I should be able to hold my camera over a printed letter, have a map glyph pop up by the address, and be able to push a “freeze frame” button so I can copy-and-paste the words.\n(I know the Android camera does some of this. They’re usually ahead with this kind of stuff. It should do more, and closer to the surface, is what I’m saying.)\nGoing further. In-view camera functionality should be user-installable. Recognise the prefix on a particular QR code, and a mini app interface pops up. Imagine how useful this would be for taking inventory or machine maintenance: show the barcode sticker to the camera, and see when this parcel is due to be picked up, or the maintenance schedule of this particular bit of kit, right in the camera, and so on.\n(If there’s available functionality for which I don’t have the app, the object or the fiducial marker should glow – we already have that visual language from video games.)\nOr, come on, let’s be wild, I should be able to buy virtual fashion to wear in my webcam. Filters should be native apps.\nRuntimes\nA runtime is a place where users interact with their apps, discover new apps, and - ideally - pay for services.\nI learnt about the runtime concept from Benedict Evans who used it a lot around 2015/2016. For example:\n\nOne of my frameworks for thinking about mobile is that we’re looking for another runtime - somewhere to build experiences on mobile that comes after the web and mobile apps - and that that new runtime will probably comes with new engagement and discovery models and possibly new revenue models too.\n– Benedict Evans, Video is the new HTML (2016)\n\nAnd it’s a powerful concept.\nThe smartphone, with its app store, is a runtime - but more particularly it’s the home screen which is the runtime. Because that’s what you see when you take your phone out of your pocket.\nBut what if the phone opened to the camera view? It often does, for me. The camera button is right there. I don’t even need to unlock.\nSo the camera is a neglected runtime. The camera view should have an App Store.\nAnother neglected runtime is maps.\nMaps\nI would love to know how frequently I pop open maps as the immediate first app when I unlock my phone. I bet it’s a whole bunch.\nI should be able to open my maps app in a car park, have it centred on my immediate location, and see the ticket machine located on the map. Tapping it, the parking app should launch - and I mean the micro version of the app, just the functionality I need, right there inside the app.\nLet’s take this indoors. The maps app might hold theatre tickets at the theatre, the Sonos interface in my home (or someone else’s), or the meeting room booking system at work. I shouldn’t need to install those apps, I’m right there.\nI should be able to install custom routing tools. (For example: did you know that Beeline has built a custom routing algorithm for safer city cycling? That should be user-installable.)\nIf I have a Uber Eats account, I should see Uber Eats locations on the map – with menus and payment one tap away. Or an Airbnb layer, if I’m arriving into a new city, in the frankly unbelievable scenario that I’m ever more than half a mile from my home ever again.\nCameras and maps are special\nNot everything can be a runtime.\nA runtime needs space for interaction, but it also needs discovery. So I’m intrigued about the idea of AirPods as a runtime - I would love programmable hearing - but I can’t see how I would discover new user-installable functionality while I was walking down the street. Apps whispering in my ear? I don’t think so. Likewise with Zoom: great idea to have apps running inside the video, adding functionality to my meetings, but can I imagine app advert pop-ups during a work call, offering to transcribe the task list? No.\nSmart speakers don’t quite make the cut, for me. There’s no native way to learn about and install new apps. And messaging apps could have been runtimes. Facebook and Apple have both given it a good go. But it turns out that the discovery mechanism was group conversations, and it wasn’t powerful enough. Good on them for giving it a try.\nBut the default smartphone live camera view, and the map view – these should have app stores.\nMy speculation, and this is just a speculation, is that everyone is keeping their powder dry for smart glasses and augmented reality.\n",
    link: "/home/2021/01/20/runtimes",
  },
  {
    title: "Towards the Orthogonal Technology Lab, v0.1",
    date: "20.05, Thursday 21 Jan 2021",
    content:
      "These are notes towards setting up a research lab that doesn’t yet exist. It doesn’t need to exist; I’m learning by writing, and what I learn might lead anywhere (or nowhere).\nIn my Thingscon talk I ended with this call:\n\nSo I guess what I’m asking for is a different kind of think tank, not one that works with recommendations and reports and regulation, but a new think tank that trades in politically opinionated, worked examples that demonstrate, demystify, and de-risk.\n– Matt Webb (Interconnected), The hard work of imagining, ThingsCon 2020\n\nWhat we need are visions of the future of technology that are values-driven, but we don’t need just design fictions. We need business model fictions, engineering feasibility study fictions, interop protocol specification fictions, investment return fictions.\nMy rationale is that it’s those kind of worked examples that speak to the many groups that, together, shape the tech landscape. The purpose is to scout the path and shift the discourse.\nThis post is a first stab at defining a lab to invent and publish these worked examples. Do I believe this lab will happen? Well obviously it’s something I would love to do but, no, not necessarily. In the spirit of Gedankenexperiment, the exercise itself is informative.\nI’m not wedded to the name “Orthogonal Technology Lab” but I’ve chosen it as a placeholder from my post about orthogonal innovation, a series of quite ordinary steps but simply in a different direction - which can lead to a place very, very different from contemporary tech.\nThe document version is v0.1. All I’m trying to do is capture and structure what’s already in my head.\nResearch areas\nResearch areas TBD and there’s a necessary mapping exercise, but I would want to cover areas such as:\n\nConnected products and zero data: e.g. how could you have voice controlled home lighting with no user sign-in and no cloud connection?\nCloud services and open protocols for portability and interop: e.g. how share presence data between video call platforms, without insisting on federation?\nThe consumerisation of Robotic Process Automation (RPA): e.g. could we ship a software-enabled co-op as a Shopify plugin?\n\nWhat this isn’t is about developing new tech for its own sake, or creating new business models where currently none are established. Which means no drones or cryptocurrency.\nIf there’s an underlying thesis, it’s to look in places where Srnicek’s platform capitalism has taken hold, leading to data-driven captured marketplaces, and that’s impeding technology development to the detriment of the consumer. Given that view, something like ad micro-targeting is a symptom of platform capitalism and not something to be rethought directly. Instead we start by rethinking the captured activity itself.\nSo there’s a focus on B2C, rather than enterprise, and there’s a focus on the smart assembling of existing tech rather than innovating new tech - though that’s not to say that patentable technology won’t be found.\nOutcomes\nThe desired outcome is influence in shipped products and services, and that’s tough to quantify, especially as an independent lab.\nThere are a couple of models here:\n\nAs a think tank, what’s the press coverage: articles with readership, video views, social media mentions and so on.\nAs an academic research lab, like a micro DeepMind, how many papers are published, and how much are they cited.\nAs a commercial research lab, how many patents are granted - and, in the long run, what is the patent license income.\n\nNone of these are particularly good proxies to influence, except perhaps patent licensing.\nOutputs\nArtefacts:\nThe idea is to follow early product innovation processes, but ship all the collateral around the product rather than the product itself. So…\n\na proof of concept of a zero-data connected product platform - but mainly the strategy deck that shows why this is a sound business.\na proof of concept of interoperating video platforms - but mainly the open protocol that makes it possible, together with docs and protocols.\na proof of concept of how mutualised businesses can run as software - and a shipped use case of it plugging into a gig economy platform.\n\nEngagement:\nInnovation doesn’t happen in a vacuum. So communications and audience engagement are an output all of their own - everything from continuously explaining the work, to open research newsletters. Although these aren’t the primary outcomes, it feels important to translate work into policy papers and MBA decks too.\nThere are a couple of non-traditional activities that are worth looking at here:\n\nA fellowship program, as discussed by Peter Bihr.\nAn original art programme, as discussed (and used) by the Open Data Institute.\n\nCommercial opportunities:\nEventually you’d want a lab like this to stand up on its own.\n\nDoes that mean patents and licensing, in the style of Fraunhofer and mp3?\nIs there a membership model for early access, paid by one or more corporate sponsors?\nIs there a consultancy arm?\nOr is there an attached startup studio, with payback from equity?\n\nThe trick is to pick a model with aligns with the mission (without adding too much overhead), and focus on that from day 1. It may not come to fruition, but I think it’s necessary as a hedge against the loss of funding.\nStructure\nProcess:\nPutting aside the engagement and commercial activities, the core activity probably follows a standard innovation pipeline. There’s concepting, prototyping, and development work, all separated by gates, and a healthy cull at each gate.\nPortfolio management is about ensuring all stages of the pipeline are active. Looking at the four types of innovation I would say this is more about “disruptive” and “routine” innovation, where there are new business models but no new fundamental tech. But the outcomes may point the way to future tech research.\nTeam:\nOne question is about how much is done internally, within the lab, versus how much is done by commissioning.\nMy first best guess that there’s a small, multi-disciplinary internal team of design, tech architecture, and business analysts, and that’s the early, concepting part of the timeline.\nEngagement/communications and program management are also in-house.\nThen prototypes, technical protocols, and other builds are all commissioned.\nYou probably also need a permanent fundraising or partnerships function, plus management. Other support functions such as owning the art and fellowship programs, and commercialisation/patents, can probably be done on a freelance basis.\nTalking about the team is a long way downstream from what matters - the outcomes - but it’s worth sketching out. What is this… 8-10 people plus a strong commissioning budget?\nFunding\nThe purpose of the above is to figure out the funding requirements.\nWhat’s a full innovation cycle… Three years? Four years? What’s the full loaded budget for that, given the team and activities? It should just be a matter of doing the sums to come up with the number.\nThat will give an indication of whether funding the lab is possible with grant funding, or whether there needs to be a different approach.\nQuestions and next steps\nThese are v0.1 thoughts, with the main purpose being to get them out of my head.\nI’m not ready to get my pitch deck and spreadsheet out quite yet. Like I said, this is a thought experiment, and working it through will teach me something. Maybe I can take what I learn into a client engagements in adjacent areas, or maybe it’ll give me a lens to understand historic research labs.\nBut here are the specifics that I’m thinking through, as a result of writing the above:\n\nHow do I better define the research areas? Are they too narrow or too broad? How do I know what is out of scope? (This interacts with the funding model.)\nAre there established models for the process? For example, Startup Studio Playbook (Attila Szigeti) is fantastic for the macro, micro, and case studies of startup studios - and would be the perfect springboard if you were setting up a new one. But for research labs and think tanks?\nDoes the team make sense? Especially the use of mixed internal/external R&D?\nUltimately: Feasibility. Is there room and interest in the world for the Orthogonal Technology Lab?\n\nNext steps: Socialising these ideas (hence this blog post), listening to feedback, and seeing whether thoughts are sparked, directly or indirectly.\n",
    link: "/home/2021/01/21/otl",
  },
  {
    title: "Rituals for kings, stem cells, and Zoom calls",
    date: "19.44, Monday 25 Jan 2021",
    content:
      "There’s a need for rituals in science and in everyday software, big rituals and micro rituals too.\nThe last time I went out for a beer was 10 March, 2020. The last time I shook someone’s hand was 11 March – I remember distinctly that it felt awkward, just before the lockdown officially began, but didn’t know how to else to navigate the moment.\nShaking hands marks, concretely, the crossing of a significant virtual threshold: going from being merely in the same physical space as another human, to being present in the same social space together. Not an atom in the room has changed and yet… it’s different.\nRob Shields in his book The Virtual (2003): The virtual is real but not actual.\nHere’s another example of the virtual:\n\nThe historical importance of the virtual may be detected from records of ritual events and ceremonies; for example, the coronation of kings and queens bestows a title and ascribes an identity to an actual individual. … The transformation from, for example, ‘Crown Prince’ to ‘King’ is engineered via an elaborate ritual in which social attitudes and expectations are shifted and bodies move ritually from one status to another.\n– Rob Shields, The Virtual\n\nNot an atom in the world has changed, yet someone suddenly has the new right to chop off your freaking HEAD. That’s what “the virtual is real” means.\nBut the virtual and the concrete go together, it’s not that one simply represents the other. Here’s the equation:\nVirtual x Concrete = Actual\nThink of the new US president and the inauguration witnessed by so many of us on 20 January. If the unsuccessful candidate had thrown a big, concrete “inauguration event,” would that have granted presidency? No of course not.\nBut if there were no public inauguration ritual this year, I think we would all feel that the winning candidate might be technically president, but they would lack legitimacy.\nThe canonical example of the virtual is your front door. There is a matter of centimeters between the public domain and the household one. In the first domain, we’re talking. In the second, you’re my guest – or a trespasser. So this threshold of virtual meaning is decorated, in a concrete sense. The front door doesn’t look like a regular door, although it could. Instead it’s painted a bright colour, surrounded by a porch, celebrated, and so on.\nScience:\nJaron Lanier (futurist and 1980s virtual reality pioneer) said this, in response to a religious critique of the lack of human dignity in stem cell research:\n\n“Dignity is something people have to create. So I said, ‘You religious people. Instead of sitting on your duffs and watching us and then critiquing, you should be the ones figuring out where the dignity comes from for all this. I challenge you. I don’t want to be living in a world in 20 years where there is a non-ritualistic way to do stem-cell research. … Actively create new culture.’“\n– Joel Garreau, Are 21st century rites of passage an essential human need?\n\nAnd I think this is a super smart way to square the circle. There are acts, concrete acts in science that are distasteful. Some are unethical and should be abandoned. But there are others that I feel would be more acceptable if treated with the appropriately weighted virtual dignity – the question being, who do we nominate as the science-clerics to create the rituals?\nON A SIMILAR NOTE: Veganism is, in my view, on the right side of history – but personally I enjoy my omnivorous diet, and I imagine there are many like me, unwilling to let go of our habits. So perhaps a stepping stone movement could be for us to all start (as previously discussed) saying thank you to our meat?\nSoftware:\nI want to do what I usually do and drag this back to the mundane.\nI’ve been sitting at my computer, more than not, since March last year. What virtual thresholds are there, and are they accompanied by sufficiently significant concrete rituals?\nSaving a file. OK, it’s fine to press an on-screen button for that.\nHow about sending money?\nI now have less money than I did before and you have more! It’s only bits and bytes but what’s happened is a big deal. So the physical act is given more weight: it’s a swipe, or a fingerprint scan. What the designers are doing is simply matching the virtual with something concrete.\nHow about finishing a video call?\nSomeone has left my space. There’s no longer a camera pointing into my house; there’s no longer a hot mic. Huge! Yet… I tap a square of red pixels to mark that? Inadequate.\nThere’s a wonderful tweet with a video clip showing ex-UK PM Gordon Brown finishing a video interview. SPOILER, he simply shuts the laptop, and the last we see is Brown’s keyboard approaching and then black. The interviewers are speechless. But I get it? Gordon Brown is performing exactly the correct ritual to end a call.\nI feel like software should be designed with microrituals to accompany certain acts.\nThe same oblong button can save a document or commit to swinging into action a factory in China, and that’s the power and also the flatness of computing. Perhaps part of the weirdness of virtual life and virtual work is this flatness, an almost imperceptible distance from concrete reality, a vague but continuous discombobulation, felt below the surface for nine months now.\nMaybe when you send an email, you should have to push the button extra hard? Maybe when I send the final deliverable for a project, I should burn some battery by lighting a simulated candle?\n",
    link: "/home/2021/01/25/microrituals",
  },
  {
    title: "Briefly on Medusa and why societies collapse",
    date: "15.45, Wednesday 27 Jan 2021",
    content:
      "I find Freud’s insistence on individual agency fascinating and refreshing. See: Medusa turning men to stone.\nFirst, Freud’s interpretation of Medusa’s appearance. The hair upon Medusa’s head is frequently represented in works of art in the form of snakes and this triggers a “castration complex” as the head with the snakes resembles the spectator’s mother’s genitals, with its terrifying lack of penis.\nThis is from the very short essay Medusa’s Head (volume XVIII of the Standard Edition complete works).\nAnd then, putting aside your feelings about this setup, look at where Freud takes it: \n\nThe sight of Medusa’s head makes the spectator stiff with terror, turns him to stone. … For becoming stiff means an erection. Thus in the original situation it offers consolation to the spectator: he is still in possession of a penis, and the stiffening reassures him of the fact.\n– Sigmund Freud, Medusa’s Head (1922)\n\nSo Medusa does not turn men to stone.\nInstead, the men choose to turn to stone, as comfort from their own terror.\nIt’s a flip of where cause is located.\n(I say “men” in particular because Freud is consciously or unconsciously specific on that point, and I’m not deft enough to be able to unravel it.)\nStrangely I’m reminded of The Collapse of Complex Societies (1990) by Joseph Tainter (previously read in 2005).\nTainter’s argument is that, eventually, the cost of increasing complexity hits declining marginal returns. For every dollar you put into improving society, it only makes you 50 cents better off. At which point it is not worth the society, as a problem-solving entity, further investing in ever-more-complex sociopolitical systems. Here’s a good summary of the book.\nIn particular, the elites might continue to do better, but society at large does not.\nAnd therefore:\nFrom the Summary and Implications: under a situation of declining marginal returns collapse may be the most appropriate response.\nPut another way:\n\nWhat may be a catastrophe to administrators (and later observers) need not be to the bulk of the population … It may only be among those members of a society who have neither the opportunity nor the ability to produce primary food resources that the collapse of administrative complexities is a clear disaster. … Collapse then is not intrinsically a collapse. It is a rational, economizing process that may well benefit much of the population.\n\nThat’s the same causal flip that Freud does. Collapse isn’t something that happens to society; it’s something society chooses to do.\nIt is always worth asking where cause is located. What appears like an accident or an imposition or a forceful act may have a more significant internal component than previously supposed.\nOr it may not.\nAnyway.\nHere are the societies discussed in the introduction to Collapse. A litany:\n\nThe Western Chou Empire\nThe Harappan Civilization\nMesopotamia\nThe Egyptian Old Kingdom\nThe Hittite Empire\nMinoan Civilization\nMycenaean Civilization\nThe Western Roman Empire\nThe Olmec\nThe Lowland Classic Maya\nThe Mesoamerican Highlands\nCasas Grandes\nThe Chacoans\nThe Hohokam\nThe Eastern Woodlands\nThe Huari and Tiahuanao Empires\nThe Kachin\nThe Ik\n\nReading this list gives me the heebie jeebies.\n",
    link: "/home/2021/01/27/medusa",
  },
  {
    title: "Filtered for lo-fi strange new worlds",
    date: "19.56, Friday 29 Jan 2021",
    content:
      "1.\nEigengrau’s Essential Establishment Generator starts with a description of a town, in text, like:\n\nCorevorn is a town located in the temperate river coast, where the vegetation is lush.\n\nIt’s different every time. From there you can read about the streets and the establishments:\n\nThere’s a nice little square, Princess Square, where there is The Sanctuary of Divine.\n\nAnd you can tap on The Sanctuary of the Divine, discovering that it’s a temple with a main room which pentagonal in shape and is decorated with mostly squalid looking holy art. And you can tap to read about the priestess (Donella Leffery), who is a gnome, and tap again to read about her early life (born in a forest, an only child), and tap again to read about her son who is a pastry chef: The most notable physical trait of Dabbledob is that he has fingernails cut to the quick.\nAnd, again, this is different every time.\nThere’s a little moment of sadness when you hit RESTART and you can’t go back, but then you can start exploring again, these intimate stories of a little town and its people and its history, all of which exist right now only for you, and you just discovering as you go.\n2.\nOne of all my all time favourite Twitter bots is Uncharted Atlas.\nIt’s a different map of a different non-existent place with a different non-existent language, every hour:\n\nThe Marches of North Olmgurpils\nEmpire of Schuchzizh\nThe Upper Wilderness of High Mabaa\n\nThe artist Martin O’Leary has a long, wonderful, interactive essay of how the terrains are generated.\nRandom coastlines and hills! Erosion! Realistically meandering rivers! Cities! (And a whole fake language to name them.) All drawn by the computer to look like old-fashion pen and ink maps.\nI remember waking up on long haul flights and looking out the window at random valleys and hills, sometimes seeing a road down there, or a few buildings, and imagining what it would be like to hike through that wilderness. So there’s something similarly transporting here, so tiny each square frame, really, and yet so vast.\nThe point about these lo-fi worlds is that you don’t need 3D cinematic graphics and VR headsets and all the rest. How can these outlines, deft and clever but outlines, how do they feel so alive, like exploring the streets and alleys of a new town?\n(I would kinda love this in the form of Google Maps too – just an app that I pan and pan and pan and pan and pan. There’s a whole visual vernacular right there.)\n3.\nLike many Brits of a certain age, my first experience of a procedurally generated universe was the space trading game Elite on the BBC Micro in the early 1980s. You can now play Elite in the browser.\nDespite the wireframe spaceships and the minimal descriptions of planets, it felt like there was an infinity of stars and details, but it’s actually all unfolded from smart programming and three randomly chosen seed numbers: 23114, 584, 46931.\nThis fantastic and technical article digs into how the universe of Elite ACTUALLY WORKED – walking through the (surprisingly simple) code:\nProcedural content generation: Creating a universe.\nGet this: the data for the universe is several hundred kilobytes big. The BBC Micro, one of the launch platforms for the game, only had 32KB of RAM.\nAnd here’s the first star system in the game, software-generated, and wow the name is etched in my memory:\n\nName: Lave\nLocation: 20,173\nEconomy: Rich Agri\nGovernment: Dictatorship\nTech level: 5\nProductivity: 7000\nRadius: 4116\nPopulation: 3bn\nDescription: Lave is most famous for its vast rain forests and the Lavian tree grub.\n\n(I’ve written about Elite and procedural generation before.)\n4.\nNested is a universe outline.\nIt’s pretty unique. You just hit the disclosure triangles and keep digging down.\nUniverse > galactic supercluster > galaxy > arm > star system > telluric planet > continent > sky > cloud > water > oxygen > proton > up quark > …\nBut.\nIf you click around a few different triangles.\nIf you’re LUCKY.\nThen:\n… telluric planet > explored continent > kingdom of Storagag > scorched county > village > farm > Cecily Greenforest (peasant) > psyche > memories > Wandering the wild expanses with my mother when I was a child.\nSo.\nThen you glance back at all the galactic superclusters with triangles you haven’t yet opened, with all their stars and all their villages and all their people and all their thoughts and memories, too many to explore, too many to count, just software, just text, not even prose, and yet… \nTotal perspective vortex.\nThere’s a quote from Darius Kazemi that has stuck in my head since I first read it. Here it is:\n\nA simple for loop can, in a few seconds, generate more information than a human being can consume in a lifetime. When we make art with code, we have to confront this fact. So how do you compose for infinity?\n– Darius Kazemi, botwiki: learning\n\n",
    link: "/home/2021/01/29/filtered",
  },
  {
    title: "Golems, smart objects, and the file metaphor",
    date: "20.52, Monday 1 Feb 2021",
    content:
      "I often wonder what it would be like to have “Open File” and “Save As” for lightbulbs, online grocery stores, and messaging apps.\nIt’s hard to explain what files used to be like because they’ve changed so much.\nFiles used to be independent from apps. The way it used to work was that you would open a standard file format in an app, say a TIFF (image) or an RTF (text file) or an MP3, and you would play the file or edit it. And then you would open the exact same file in a different app for different capabilities.\nNowadays, if an app deals with files at all, you import files into the app and maybe export versions later, but the working doc itself is sealed in a library, or in a special format that nothing else can open.\nFiles used to be objects you could manipulate. Nowadays apps take care of versioning, and sharing, and often organising. But before, you would duplicate the file object directly, or drag it onto a chat window, or whatever. You can’t drag a Google Doc; the file isn’t a directly manipulable “file” so much as the visual depiction of a save point.\nThe upshot was that you owned your own files. And when a new application came along, it was exciting because you could try it out by using it with those exact same files, maybe switching back, maybe not.\nSo when I talk about files, I mean these\n\nstandard file types, shared between applications\nwhere the file is the working document itself; it doesn’t have to be imported or exported\nand the file icon is directly manipulated: shareable, printable, versionable, independent from the app.\n\n(And yes, I know it was never as clear cut as this, but in an idealised kind of way.)\nA file is a boundary object\nWhat is a file?\nThere’s a technical answer. If you do the archeology and go back to source code from the 1970s, a file is a handful of properties: an address on disk; a size (i.e. how long to read the disk for); and some metadata like which owns these bytes, and do these represent an executable app or a document, and so on. Here’s the code. It’s less than a page. (Photo from Lion’s Commentary on UNIX 6th Edition, as previously discussed.)\nBut that’s not a definition that works for “documents” on cloud services, where a saved Google Doc is more likely to be a bundle of dynamic lookups from a database, rather than a run of bytes on disk. So…\nThere’s the design answer. A file is what it looks like: an icon. There’s a fantastic oral history of the hamburger menu (the three-lined menu button that you see in the top corner of a ton of websites), and it goes all the way back to the Xerox Star, which was the first commercial computer to actually have windows, menus, a mouse, etc. The history includes commentary from Dave Canfield Smith who mentions icons, which I’d invented at PARC for my thesis.\nAnd he makes the distinction between file icons and the hamburger menu, THUS:\n\nI don’t understand the fascination with the hamburger menu symbol, because it’s not even an icon–it’s just a symbol. Icons had both visual and machine semantics, whereas this menu button had only the former. You don’t do anything with a menu. It just sits there on the screen. You poke at it and a menu pops up, you move the cursor away and the menu goes away. That’s all it does. An icon is an object in a metaphoric world that you can do things with in the real world, the world that is being modeled.\n– Dave Canfield Smith, An oral history of the hamburger icon (Dale Berning Sawa)\n\nThat’s the key quality. Files are meaningful to computers, but they are also meaningful to users, and both can manipulate the same object. The two of you inhabit different worlds, but you’re talking about the same thing.\nThere’s a great paper from Microsoft Research called, simply, What is a File?\n\nFor over 40 years the notion of the file, as devised by pioneers in the field of computing, has been the subject of much contention. … we suggest that files continue to act as a cohering concept, something like a ‘boundary object’ between computer engineers and users.\n– Microsoft Research, What is a File? (ACM CSCW 2013)\n\nA boundary object is a term from sociology. From Wikipedia: boundary objects have different meanings in different social worlds but their structure is common enough to more than one world to make them recognizable, a means of translation.\nThe user can tell the computer what to do with a file without having to know the details of the inode structure or how to program their instructions; the computer can make a file available to a user without having to anticipate every single goal that a user may have in mind.\nThe “boundary object” quality of a file is incredibly empowering, magical really, one of the great discoveries of the early decades of computing.\nA file is what you put in the golem’s mouth\nThe file made sense for desktop computers and bytes stored on disk. What could the file be now, in the era of the cloud and smart devices?\nThere’s a clue, I think, in this kids’ toy, the Yoto Player: A carefully connected screen-free speaker. Made for children, controlled with physical cards and playing only the audio content you want them to listen to.\nIt’s cute!\nIt reads bedtime stories!\nKids “program” it by inserting a card!\nMy niece has one of these. She loves it.\nWhat neat is that you can make your own cards. I’m guessing the cards are just blank playing cards with a RFID tag inside. You program each card using a phone app. Once programmed, Yoto Player will play the relevant audio or podcast, and show pixel graphics on the front of the device.\nBUT ALSO you can draw on and decorate the card, and you can keep them in a snazzy green wallet. So you can match the cards with interests, put educational ones with your school stuff, fun ones with different toys, private ones with your diary, keep some back for treats… all that good stuff. And all without Yoto having to pre-decide what kids might want to do (and having to design an app to do all of it).\nYoto Player is a golem. The golem, the animated anthropomorphic being that is created entirely from inanimate matter from ancient Jewish folklore. A statue, an ancient robot, but not autonomous. Specifically:\n\nIt was believed that golems could be activated by an ecstatic experience induced by the ritualistic use of various letters of the Hebrew Alphabet forming a “shem” (any one of the Names of God), wherein the shem was written on a piece of paper and inserted in the mouth or in the forehead of the golem.\n– Wikipedia, Golem\n\nIf you think of apps, or executables, as essentially inanimate clay - code which is pure potential, and brought to life by the loading of the user’s own file - then the file is the shem, or rather a generalised kind of shem, not a divine name as such, but a set of instructions, inserted into the mouth.\n(Now go and read Ted Chiang’s sci-fi short about golems and software Seventy-Two Letters.)\nMaybe lightbulbs can be golems too\nI have 1 (one) smart plug. I used it to control the Christmas tree lights (so I didn’t have to reach back on the floor twice a day) then nabbed it to control a lamp across the room from my desk. Currently it has been requisitioned to monitor the power usage of a water pump: I’m concerned there is a slow leak and the pump is switching on at odd times in the night. The plug will confirm this for me.\nI would love to encode these configurations, and more, onto cards: the name, the room, who can use it, maybe some power user features such as where logs are sent, and how alerts are dispatched, and so on. These cards, physical or virtual, would live in a stack somewhere (on my bookshelf or in a shared Dropbox), and I could swap back and forth, and other family members would be so empowered too.\nWhat about lightbulbs? Lighting scenes are a pain to create. A standard “file” for lights, not just bulbs but whole setups, would allow for\n\nhaving different scenes for summer and winter, packed and unpacked at the turning of the season\ngiving away carefully created scenes in magazines and online – maybe you could get a movie director’s tuning colour temperatures to use when you’re watching on of their films\nmaking a “virtual home” app, so I can create the lighting scene file in the app, maybe on behalf of a friend who hasn’t nerded out about the topic, and then share it with them (or debug it with them, texting the file back and forth).\n\nDo I literally mean that the lightbulb needs a little slot like the golem’s mouth, into which you insert your instructions stamped on microfiche? I’m tempted but no. But metaphorically.\nWhat about an online grocery store? If my preferences and purchase history were a file, it would make it a ton easier to switch from one store to another. But that’s just export/import, service portability.\nWhat makes the file, as a metaphor, so magical is that other, unexpected software can open the same thing.\nSo what I’m imagining is a “Let’s Go Vegan” app which loads the grocery file, deletes any meat and dairy from my purchase history (so I don’t get tempting recommendations) and seeds my shopping basket with a starter pack.  Or a “Shop Local” campaign that looks at my purchases and sets up accounts (and regular orders) with appropriate neighbourhood stores – or vice versa, if the supermarket can beat them on price and that’s what I want!\nThe trick is that these aren’t apps calling an API, because an API is bespoke to every store, and it’s not a matter of export/import because that misses the point of the file being a shared object that multiple different apps operate on simultaneously: a genuine shared file.\n(APIs mean that a healthy ecoystem is a tough N^2 problem: every service needs to be tested with every other service. Shared files reduce this to an N problem. Each service needs to be tested with precisely one other thing, the file spec.)\nWhat does it mean to have a file for a cloud service?\nI’m afraid this opens up more questions than it answers.\n\nIf it were possible to “Save” from WhatsApp and “Open” in Signal, then where is the user’s metaphorical filesystem kept, given it needs to be always available?\nHow is the “file” (whatever it is) kept up to date, given that files where invented for documents, which are punctual in time, versus cloud services which have streams which run and run?\nHow do you have standard file formats that don’t also prevent new interfaces and new metaphors?\nHow does this sit alongside protocols which, in the context of video conferencing services, might be a way to have interop, cross-platform presence, and dialtone and video calls.\n\nLet’s pretend I somehow got to run my Orthogonal Technology Lab – this is research programme #1. There’s no new technology here. Just a series of ideas to explore that seems like they might unlock a tech ecosystem with good values, and the trick is to chase it down with small-scale prototypes, to begin with, and then speculative specification docs, and sketches of business models, etc, publishing it all, and using the whole activity to demonstrate to both founders and policy-makers that another future is possible, basically continuing the pile up the whole edifice until someone decides to come along and do it.\n",
    link: "/home/2021/02/01/golems",
  },
  {
    title: "Let’s think of some new vices to tax",
    date: "18.47, Tuesday 2 Feb 2021",
    content:
      "A decent portion of government revenue is at risk of declining, which gives an opportunity (a) think about what tax is for; and, (b) propose some taxes on Big Tech.\nVices. The traditional ones are alcohol, tobacco, and gambling. UK tax revenue in 2019-20 is forecast at £742.1b (source). Vice taxes made up:\n\nAlcohol duties: £11.5b\nTobacco duties: £9.7b\nBetting and gaming duties: £3.2b (doubled since 2010)\n\nTotal vice taxes: £24.4b. That’s 3.3% of government tax revenue!\nSources unless otherwise specified: Office for Budget Responsibility Economic and fiscal outlook, Nov 2020 (table 3.3) and the Tax by tax section.\nIn comparison to other taxes: vice is equivalent to 18% of VAT (sales tax; £133.8b). And vice is a little over half what corporation tax is worth (£48b).\nWhat does vice buy us? The entire BBC seven times over, or 10% of the welfare budget.\nBut there those stories about millennials and zoomers drinking less, and tobacco is already becoming seriously unfashionable – that makes me think we should consider seriously whether vice taxes will drop off a cliff.\nOne question is: why tax vices at all? The intention is only partially to dissuade: if that were the goal, you would ban it. I don’t know about you, but I like booze, cigs, and betting. I haven’t smoked for years, but what’s life without a vice or two.\n(I’ve not included the Soft Drinks Industry Levy which brings in £0.3b, not VAT collected on the goods above.)\nWe tax vices because there is individual utility but a society incurs a cost, either in healthcare, or maintaining order, or productivity, or something else. Which I think is a fair trade.\nBut there’s another activity with high societal cost.\nCarbon and the environment. The figures here for 2019-20:\n\nFuel duties (petrol, diesel, and other legacy fuels): £27.6b\nAir Passenger Duty: £3.7b\nClimate Change Levy: £2.1b\nLandfill Tax: £0.8b\n\nTotal environmental taxes: £34.2b. 4.6% of revenue! Comparable to vices.\nI’m not sure I’d say that carbon is a vice itself… though maybe? Carbon is a vice for industry? That’s a metaphor that could work.\n(I’ve not included Environmental Levies at £8b as these appear to be intended to restructure the wholesale energy market and go straight out again.)\nTwo immediate observations:\n\nIn terms of carbon, £34.2b is clearly not nearly enough to pay for the impact of the climate crisis, which will be astronomical. We need a better word than astronomical because while astronauts are getting more affordable by the day, the cost if we don’t retool away from a carbon economy is basically the existence of society as we know it.\nWe would hope that the income from these taxes declines – and soon. Electric vehicle switchover in the next 15 years; air travel being substituted by Zoom where possible; less to landfill, etc.\n\nSo revenue from environmental taxes, if they were high enough to do the job of dissuasion, would be declining. We can’t bank on those taxes either.\nAll of which makes me ask: where’s the money going to come from in the future?\nWhat are taxes for? An economist or political scientist would have a typology, but let me guess:\n\nTax as the fair cost of society: to share fairly the cost of the state\nTax as planner: to drive some macro shape to society (such as encouraging business growth in certain sectors, or business formation as an activity, or certain levels of wealth)\nTax as inhibitor: to discourage individual behaviours, for reasons such as public health or moralism\nTax as parasite: simply because it can be done…\nTax as rebalancing: where there is a difference in the cost felt by the taxpayer and society, such as with cigarettes or pollution, and tax is used to impose the cost of that externality.\n\nThe last of these is the most interesting to me. I’d not thought about taxes in that way before.\nLet’s say that vice taxes and environmental taxes decline over the next decade.\nWhat new vices do we tax to create, say, 1% of all tax revenues? (i.e. £7.4b, just under the tobacco duty tax.)\nBig Tech?\nI suggest Big Tech because there are a lot of calls for regulation but, as I’ve detailed before, I don’t believe it’s a good idea to have unconsidered, blunt instrument regulation (such as a “Digital Tax,” ugh). Better to have in mind specific issue which is a problem, and a hypothesis about how a given intervention will provide a remedy without over-reaching.\nWith that in mind:\nI think we could make an argument that\n\nengagement-driven social media, and\nmicrotargeting technology\n\nare both mis-balanced in terms of individual benefit vs societal benefit. NOT that they are bad, merely that where the benefits and costs fall is out of whack. Like, scrolling Facebook is great! But it turns out that the thing to create the dopamine hit is also a radicalisation engine. Maybe we’re fine with that: cars are fun but they’re also polluting death machines, and we use taxes and regulation to distribute the load until it feels equitable. \nTwo ideas for new taxes!\n1. Engagement Levy\nTax the app front end, which after all is the system that asks for user consent to collect data. Could you charge Twitter, or Snapchat, or Facebook based on usage measured in app-hours in the UK? Make it progressive based on an exponential: the more users who are touched, and the more hours, the higher the levy paid.\n2. Anti Microtargeting Duty\nOn the one hand ad targeting helps businesses economically find customers; on the other it is a giant attack surface for dark propaganda. This is a classic duty: make sure the societal cost is reflected in the price paid by the advertisers. Put a duty on paid ads of, say, 1 penny, but don’t make it per impression, make it per bid. If you can find a way to reach people with fewer bids (i.e. less targeted) then you pay less.\nI think we can ask the same rebalancing question of other new businesses.\nLike: e-commerce. It’s hazardous for neighbourhood shopping. But, as we’ve learnt during Covid, it’s also vital resilience for the nation. So maybe the issue is  homogeneity. How can that be taxed specifically?\nOr: the gig economy. Uber is great for getting around town, and at least some drivers love the independence and flexibility. But the method of employment is freeloading on the state-provided welfare safety net. So what’s a duty that puts the cost back on that method of employment?\nAnd then back to vices:\nIt’s telling that betting and gaming revenues have doubled in the last decade. Dopamine is the new alcohol. We’re swimming it in as a society, it’s normalised.\nBut there are dopamine triggers that aren’t taxed: so-called free-to-play games. They’re engagement farms sticking micro-transaction sap spiles in their players. Coins, crates, and gems, whatever.\nTax these games like casinos.\n",
    link: "/home/2021/02/02/vice_taxes",
  },
  {
    title: "Dowsing the collective unconscious with GPT-3",
    date: "17.01, Thursday 4 Feb 2021",
    content:
      "Back in September, I was having conversations with the new AI, GPT-3. Here are our chats and my conclusions from that time. I’ve just found another chat in my notes.\nIn the following, the lines starting with “Human:” are what I typed. The lines starting with “AI:” were generated by GPT-3. It was a single session. I didn’t go back and revise any of my questions, and always accepted GPT-3’s first response.\nHuman: Hello, who are you?\nAI: I am an AI created by OpenAI. How can I help you today?\nHuman: What should I work on in 2021?\nAI: How much do you value being able to read?\nHuman: A great deal.\nAI: In 2021, you will no longer be able to read.\nHuman: Why not?\nAI: In 2021, a new form of entertainment called telepathy will become widespread.\nHuman: How will telepathy be invented?\nAI: New neurotechnology will be invented to treat epileptic seizures.\nHuman: Can you describe how telepathy will be used for entertainment?\nAI: Telepathy will work over the Internet.\nHuman: What will be entertaining about it?\nAI: It will provide an interface for playing multi-player games.\nHuman: How will telepathy be better than consoles for playing multi-player games?\nAI: It will provide a more social experience.\nHuman: Can you describe the biggest telepathy game of 2021?\nAI: Yes. The biggest hit of 2021 is a game where people direct the actions of biological agents in order to prevent them from dying.\nHuman: How do you win at this game?\nAI: You take an action to save the biological agent if it is in danger of dying. You can’t be too late.\nHuman: What will it be called?\nAI: In 2021 it will be called Do No Harm.\nHuman: How much will it cost?\nAI: A home version will cost $300, while a console version will cost $250.\nHuman: How many people will play?\nAI: A billion people will play.\nThis is… wildly specific.\nI am very much taken with the idea that there are ways to dowse the collective unconscious.\nLike, prediction markets. Lots of people bet on complex outcomes; the market functions to surface scarce knowledge. Astral Codex Ten has been posting about prediction markets and coronavirus: They’re a type of trustless, decentralized expertise that often equals or outperforms official sources.\nThen of course there’s sentiment analysis: hedge funds look at news and social media to pick up positive/negative sentiment, and use that to drive investment decisions.\nBut models like GPT-3, or maybe Google’s new language model which is 9x larger, have basically ingested all the public text there is. They integrate and correlate, that’s what machine learning does.\nNow let’s say that a bunch of people are working on technology-enabled psi for entertainment. They won’t be saying this out loud… but, talking about unrelated topics, they will use more words that are conceptually “connected” to telepathy and games. That’s just how the brain works. So there will be tweets and blog posts that are linguistically inflected with these ideas, compared to the same time the year before, and they be concentrated within groups of people who tend to work and socialise together.\nSo is it possible to detect those inflections, using automation? Is it possible to pick up on them even before the scenius has come together and consciously even had the idea? What knowledge is encoded in the structure of the model itself?\nIf you ask GPT-3 the right questions, can you get it to tell you what society is dreaming about?\nAnd, if so: what does this fantasy about a billion-player telepathy game really mean?\nDo No Harm.\n",
    link: "/home/2021/02/04/telepathy",
  },
  {
    title: "Animals driving cars and other jobs",
    date: "10.43, Monday 8 Feb 2021",
    content:
      "Perhaps more animals should go to work. Here are three examples of animals driving cars:\n\nA charity taught dogs to drive cars as a stunt (with video). These dogs need a little assistance, sure, but they’re about as good as I was the first time I sat behind the wheel when I was 14.\nRats taught to drive tiny cars to lower their stress levels (with video). So why expend so much effort inventing fully autonomous vehicles, when we could have semi autonomous vehicles and chilled-out rats to complete the job?\nA goldfish drives a fish tank on wheels (YouTube). An animal-piloted vehicle needn’t look conventional: By using a camera and computer vision software it is possible to make a fish control a robot car over land. By swimming towards an interesting object, the fish can explore the world beyond the limits of his tank.\n\nI’m reminded of this 2017 design concept to train crows to pick up litter in cities. Cleverly, the crows don’t need to be trained directly. Instead this concept imagines installing a crowbar: a smart machine training crows to pick up cigarette butts from the street.\nCheck out CrowBox if you want to try this on your own street. It’s an open source hardware design, an experimentation platform designed to autonomously train corvids (the family of birds crows belong to). So far we’ve trained captive crows to deposit dropped coins they found on the ground in exchange for peanuts.\nWe’re accustomed to animals working in agriculture: sheep dogs, oxen to lend their strength to the plough, chickens according to their nature. So why not in the industrialised sphere too?\nOne ethical concern is that animal employees, as we can see in agro-industry, would be driven too hard and mistreated in the name of efficiency and business economics. But it strikes me that this is more of a complaint about capitalism than the ethics of animals having jobs.\nSurely the answer to animals potentially being over-worked is to find a way for them to unionise.\nWho could speak for collies driving Ubers? Or give a voice to ferrets scampering along shelves and piloting forklifts in Amazon warehouses?\nIt’s not like these roles are given much representation today, with people doing them. So maybe the real value of dolphins driving delivery drones would be to show us the path to fair worker treatment for all, humans and nonhumans alike.\n",
    link: "/home/2021/02/08/animals",
  },
  {
    title: "Memexes, mountain lakes, and the serendipity of old ideas",
    date: "19.42, Wednesday 10 Feb 2021",
    content:
      "I’ve noticed that smart people keep notes, and in particular use their notes in a certain way, and it made me think of something I read recently about viruses.\nWhere do new influenza outbreaks come from? From Viruses, Plagues, and History (as previously discussed), one possibility is that newly emerging viruses have actually remained hidden and unchanged somewhere but suddenly come forth to cause an epidemic. There was an H1N1 outbreak in 1977 that was genetically identical to one that was causing epidemics in the 1950s. Where had it been?\nHere’s one idea about bird flu specifically:\n\n[Zhang and colleagues] reported preservation of influenza A viral genes in ice and water from high altitude lakes that are frequently visited by migratory birds. Could influenza virus be preserved in lake ice that melts during spring warming as a source of infecting migratory birds?\n– Michael B A Oldstone, Viruses, Plagues, and History\n\nI am super taken by this concept of reservoirs, in this case frozen mountain lakes that are libraries of ancient viruses, in stasis, waiting for their time to come again – ready to be sipped by a briefly resting bird, perhaps after a decade, more!, and then down from the mountains into a city, and from there the world.\nI’m reminded of the European Renaissance, the beginning of the end of the “Dark Ages” that was catalysed (so the story goes) by the transmission of the Greek Classics back into Europe from Arab culture, where they’d been endemic for hundreds of years.\nAnd I’m also reminded of how writers I love and respect maintain their own reservoirs of knowledge, complete with migratory paths down from the mountains.\nCory Doctorow’s commentary on tech and society weaves the present day with historical perspective, and any public thinker would be proud to put out one of these pieces a week – but Doctorow puts out between two and four every day on his blog Pluralistic and on Twitter, in addition to being a prolific author. He detailed his process recently: 20 years a blogger..\n\nMy composition is greatly aided both 20 years’ worth of mnemonic slurry of semi-remembered posts and the ability to search memex.craphound.com (the site where I’ve mirrored all my Boing Boing posts) easily.\nA huge, searchable database of decades of thoughts really simplifies the process of synthesis.\n– Cory Doctorow, Pluralistic: 13 Jan 2021\n\nAnd it’s interesting, right, this accretive note-taking and the process of taking core samples through the deep time of your own ideas. I’ve built something similar, not as consistently, but for about two decades too, and I keep all my notes in plain text, and all in the same searchable database. I develop nascent ideas in part by typing in keywords, spelunking my own memex for things I’ve previously spotted, connections I’ve made, turns of phrase… most of which I had forgotten, but there they are. And old ideas come back and get recombined and become fresh again. That database of notes is my greatest asset. It’s how I write here, and it’s also how I pretend to be clever when I’m working.\n(If I were giving a single piece of advice to any creative starting out, it would be to start noting down everything that grabs your attention, and keep all your notes in one searchable place, as data that you can carry between whatever applications are faddy at the time because two decades is longer than almost any app is maintained, and grow that corpus over time. Don’t presumptively edit, don’t put time into organising, just accrete, and when you make connections, layer them in too, until eventually the whole thing composts down and starts outgassing brand new thoughts of its own.)\nRobin Sloan - author, media inventor (my favourite Sloan incarnation), and olive oil/zine magnate - also recently detailed his note-taking process: Tasting Notes with Robin Sloan. He is serious about capturing everything, and also about using search and juxtaposition as part of his process: For example, the keyword ‘empire’ would have brought me to both the entry about the man running an empire from his phone, and that one about the cymbal company founded during the Ottoman Empire.\n\nI’ve created a system so random notes appear every time I open a browser tab.\nI like the idea of being presented and re-presented with my notations of things that were interesting to me at some point, but that in many cases I had forgotten about. The effect of surprise creates interesting and productive new connections in my brain.\nIn order to do this, I’ve put some of my programming skills to work to engineer a kind of Rube Goldberg-y system: as I mentioned previously, I export my notes from nvALT into Simplenote, and just basically use that as a back-end database. That export then gets loaded into a server that I’ve set up to feed me a random note every time I open a blank browser tab.\n– Robin Sloan, Tasting Notes with Robin Sloan (Superorganizers)\n\nThe empty browser tab as a crystal clear mountain lake!\nWhen I wrote my 15 personal rules for blogging I realise now that I had a blind spot about how I keep notes and how I browse them. Doctorow and Sloan’s observations made me see how much I rely on my notes too… and also realise how I’ve neglected building my own deliberate migratory corridors from the past to the present.\nSo here’s a start. This blog now has an On This Day page, which lists posts made on this day since 2007 (it goes back a week too). It’s a bit spartan, and I’m not sure yet how to make best use of it…\n…BUT, right now I can see\n\nFiltered for TIL (2015) which has everything from control panels to poetic translations for words about mental health.\nAn idea from 2011 about making exoskeletons for hamsters.\nA selection of quotes about masks from Impro by Keith Johnstone (2008) which is an amazing book about improvisation.\n\nAnd all of those are suddenly new to me again, and spark new thoughts.\nNaturally there’s an On This Day web feed too so these posts appear in my newsreader each morning. Some personal serendipity to start the day.\n",
    link: "/home/2021/02/10/reservoirs",
  },
  {
    title: "Anxious feelings about optimisation through complexity",
    date: "14.50, Friday 12 Feb 2021",
    content:
      "Optimisation makes me itchy.\nA couple of examples. The thermostat Google Nest has Rush Hour Rewards which will automatically tune temperatures before and during a Rush Hour to reduce energy use and lower grid costs (a “Rush Hour” is when everyone turns their air conditioning on at the same time).\nSimilar: Power Shaper by Carbon Co-op which I’m sorry to pick on because lots of UK energy companies will be doing this with smart meters, but this is the one I saw first. (Thanks Rod McLaren for sending it my way.)\n\nCarbon Co-op technicians will visit your home and install equipment which will enable certain existing electrical appliances (such as electric vehicle chargers, heat pumps, immersion water heaters, battery storage) to be turned on/off remotely.\nWe turn things on/off only when we receive a request from grid operators and other parties.\n\nOn the face of it, this makes a ton of sense.\nWe’re shifting to renewable energy. The wind and sun have their own schedule. But say everyone gets home at 7pm and plugs in their new electric car, or turns the kettle at halftime in the football, that’s a demand spike, and that’s when a coal power station fires up, so the energy is supplied to the grid but it’s dirty energy.\nLong term this gets fixed by having neighbourhood batteries to smooth the spikes. Ahead of that, demand can be adjusted by automatically turning things off. Feedback loops.\nBUT.\nIn Vernor Vinge’s space opera A Fire Upon the Deep (1992) there’s a planet called Namqem with a high technology civilisation 4,000 years old.\n\nNamqem was a triumph of distributed automation. And every decade it became a little better. Every decade the flexibility of the governance responded to the pressures to optimize resource allocation, and the margins of safety shrank.\n\nWhich is a problem. As one of the characters says: They’ve accepting optimizing pressures for centuries now. … finally the optimizations have taken them to the point of fragility.\n\n‘The symptoms are classic. The last decade, the rate of system deadlocks has steadily increased throughout Namqem. See here, thirty percent of business commuting between the outer moons is in locked state at any given time.’ All the hardware was in working order, but the system complexity was so great that vehicles could not get the go-ahead.\n\nSo eventually, as an alternative to escalating resource wars, optimisation becomes complete: every embedded computing system an instrument for total social control.\nBut it doesn’t help, collapse comes, billions die, and so on.\nI must have read Vinge at a particularly susceptible age. Because since then I see optimisation-through-complexity as a particular kind of danger.\nNot optimisation on its own. Doing something with as little energy as possible is elegant.\nAnd not complexity on its own either. Complexity has its own problems: reduced legibility, the creation of priesthoods to maintain it, etc.\nBut when you increase complexity in order to optimise, demand never really goes down. The optimisation becomes an opportunity to do more, and so the complexity gets locked in – there will never be the chance to remove it.\nAnd that compounding complexity, layers upon layers of it, a nest of interlocking feedback loops, increases the risk of fatal, emergent complexity quakes.\nAll of which colours my approach to everything from how I architect my code, to how I organise my finances, to what government policies I like.\nWhenever I see something like Nest’s Rush Hour Rewards or Carbon Co-op’s Power Shaper, it makes me feel like we’re all taking one step closer to an invisible cliff edge, and the drop could be half a mile away, or it could be one inch.\nI also have a high level of nervousness around magnets. I grew up with floppy disks (that would be wiped) and cathode ray tube screens (that would be permanently ruined). So magnets on wallets or toys – I’m on edge if they’re ever near electronics, and I watch them with a hawk eye until they’re at a safe distance. Magnets on laptops and iPads still seem wrong to me. Even though it’s fine now and has been for many years.\nBy which I mean, don’t take my views too seriously, I’m a mess of unfounded prejudices about emergent systems and ferrous solids.\n",
    link: "/home/2021/02/12/optimisation",
  },
  {
    title: "Heating your home by preying on the vulnerable",
    date: "17.12, Tuesday 16 Feb 2021",
    content:
      "Nat Torkington shared this laptop with seven screens (here on Twitter) and all I could think about was how it would roast your legs.\nBut then Nat suggested it would be good as a grill, and it made me think: what if you could cook food with different types of big compute jobs?\nImagine a high concept restaurant where the fish is delicately fried on the waste heat from building machine learning models that are used in biotech to fold proteins, in the fight against cancer.\nIf the fish were instead fried from the computer mining Bitcoin (global energy consumption: about the same as Norway) and you were told that, would it taste, I don’t know, slightly bitter?\nI mean – probably?\nRemember, if you’re told a bottle of wine is more expensive than it is, it tastes better.\nSEE ALSO:\nLucky meat.\nRELATED:\nQarnot ecological heat. Qarnot provides distributed server farms for, say, machine learning or rendering 3D graphics. Dissipating server farm waste heat is an expensive problem, and that’s why Facebook has built a data centre in the Arctic Circle, and Microsoft has started locating them underwater. Qarnot, instead, scatters its rented-out servers to homes and offices, where they are used in water boilers, or housed in handsome radiators.\nHow would you feel if your home was heated by the waste energy from, e.g., crunching the figures on payday loans, your feet toasty and warm from aiding and abetting the act of preying on the vulnerable?\nI have some small investments, and a few years ago I asked about moving to funds that avoided oil, tobacco, guns, and the like. 50% for ethical reasons (though I don’t want to exclusively make capital-E “ethical” investments) and 50% because I believed that fossil fuels would drop faster than the then-consensus believed. At the time, all I wanted to do was see the data and make a judgement call. But the data didn’t exist.\nSo there’s this kind of ethical insulation that is created by the layers in the financial system. There was the time that the Archbishop of Canterbury was having a go at Wonga, which was then the poster-child payday loans service, and it turned out that the Church of England pension fund was invested in a fund of the venture capital firm Accel, which was in turn used to fund Wonga.\nThat was a turning point, of sorts. There are more ethical funds now, and also more data gathered and propagated up the chain.\nI believe that humans, on average, have decent values. But I believe that markets have this weird kind of transparency/opacity where we can, in theory, see where the money goes, but the values can’t get through.\nLike, it is so much work to know whether chicken is organic, or coffee is Fair Trade. Is the mayonnaise in my Pret sandwiches made from eggs laid by happy hens? Is the cardboard packaging produced in factories where the workers have proper pension contributions? Markets don’t allow for this kind of knowledge, by default.\nMarkets have a homogenising pressure; they require fungibility even if that means that we have to all collectively and silently agree to ignore provenance.\nIt’s interesting to speculate how we could do without markets in the conventional sense. We need markets because supply chains are long and because goods to have to be made and distributed before they are sold. But in this age of e-commerce, and infinite shelf space, and manufacturing on demand, could I tick a box and promise that “I will pay 10% more if you can prove that your facilities use only renewal energy”, and have that simply hanging there as a bounty for any manufacturer?\nSo if tuna were seared on the waste heat of molecular simulations used in mRNA vaccine development, the idea that it might literally taste better doesn’t feel like a psychological illusion to me, it feels like something we should take seriously – it’s the true manifestation of the deep desire to use our human values to make choices about the world just beyond our reach.\n",
    link: "/home/2021/02/16/provenance",
  },
  {
    title: "Ceci n’est pas une calculatrice",
    date: "17.18, Thursday 18 Feb 2021",
    content:
      "The main calculator I have on my phone is PCalc. It is worth every penny.\nPCalc has also been going a super long time. The first version came out in 1992.\nHere’s the announcement of PCalc’s release, reproduced on the developer’s blog:\n\nSubject: [*] PCalc 1.0 Submission\nEnclosed is a binhex file containing a submission for your archives.\nPCalc is a neat simulation of a programmable scientific calculator.\n\nI can’t get this out of my head. Is it a calculator? Or is it a simulation of a calculator?\nSomething similar comes up when I’m reading to my toddler. We’ll be pointing things out in a book, she’ll be like “lion,” “table,” and I’m thinking sure, a picture of a lion, a picture of a table, we’re all good. And then there’s a picture of a picture, framed on a wall in the book, and she says “picture” and I’m like: Um, the whole page is also a picture, I lack the necessary information to disambiguate where you’re pointing here. Your finger is pointing with x and y coordinates, but additionally we need an r coordinate to indicate the level of reality being pointed at; are you pointing at the picture in the inner reality of the page, or the picture in the outer reality which is the page? Both are pictures, but we need to be precise here.\nWe need to distinguish because the consequences are profound. Here’s why:\nA simulation inside reality cannot leak out. Characters don’t come out of the books I read (I assume).\nBut a simulation nestedinside a simulation is still a simulation. When I play cards inside Red Dead Redemption, I’m not playing a simulation of cards. I’m just playing cards.\nTo go back to my toddler’s book: framed art on the wall of my room stays within the frame. But framed art in a picture book can do anything the book’s author desires, including mixing with anything in the inner reality of the book.\nSo what if our universe is a simulation? Then any and all simulations in our world - books, movies, computer graphics in GPUs - are all at the same “level” of reality as us. They can, potentially, leak.\nWhich I feel should be measurable and detectable in some way? If we live in a simulation, then a dense store of other simulations, fictional narratives even, say for example a library or a Netflix datacentre, should have a distorting effect on local physics. Which would be noticeable, in theory, by building an extremely large and sensitive particle collider and looking for deviations.\nAnyway.\n",
    link: "/home/2021/02/18/calculators",
  },
  {
    title: "What to do with spare TV ad inventory",
    date: "18.12, Friday 19 Feb 2021",
    content:
      "I’ve recently been watching a TV comedy show called Taskmaster, about 6 years after everyone else was into it. (I don’t watch much TV. I don’t much enjoy anything tense or violent, and besides after about 10 minutes I’ve usually run out of attention. So if there’s a show I think I could be into, I watch the first episode or two to get a sense of the narrative space then finish it by reading the season summaries on Wikipedia.)\nAnyway so I’m watching this particular show on an ad-supported streaming app, and it’s old enough that often nobody has bothered to buy the ads. When that happens, the commercial breaks are empty and it just skips to the next segment.\nWhich is kinda good but also kind of a pain because it means that my wife and I lack a natural Schelling Point to go pee, fetch snacks, etc.\nBen Terrett (who has a blog) suggested I should buy the ads myself. I haven’t done that. But I wonder…\nUKTV streaming TV ad sales are handled by 4Sales who offer some interesting products.\nFor instance here’s BRANDM4TCH. Advertisers upload their own user list, and only those users see the ad. I’m guessing this is how I saw an spot the other day for [redacted] that specifically called out it was only visible to their customers.\nAnd some other interesting ad products:\n\nPersonalised enables advertisers to use All 4 data to individually address users by name. We take viewers privacy very seriously and viewers have the option to opt out of this.\n\nAnd:\n\nDynamic enables advertisers to dynamically alter creative using different data points e.g. time of day, demo, location or the weather.\n\nSo perhaps I could buy a TV ad targeted just at me, and generate the content on the fly.\nLike, maybe it could be a list of upcoming birthdays of family and friends. That would be useful to encounter ambiently in the evening, like the calendar on the fridge but in my front room.\nMaybe a little in-show water cooler moment? Some way of me checking in to say “hey I liked this show and I was here,” and it only shows up to people I know on Twitter or Facebook or whatever, then we can talk later.\nOr perhaps something lazy: a TV ad that shows just a big QR code that, when scanned, opens the takeaway app on my phone. \nWhen I was a kid, I used to make and sell fanzines. They were terrible but most of my friends would have a copy hanging around.\nSo one issue I printed the entire takeaway menu of the local kebab and chips delivery shop - this is before the internet clearly, and also before cholesterol awareness - so it would always be handy late at night, whoever’s place we ended up at.\nFor me that is still the highpoint of what ads can be, and also pretty much what I would do if I awoke one morning and found myself transformed into a newspaper oligarch.\n",
    link: "/home/2021/02/19/tv_ads",
  },
  {
    title: "Nothing is real vs everything is real",
    date: "15.51, Tuesday 23 Feb 2021",
    content:
      "Nothing is real\nFlowrite is an AI-enabled writing accelerator. You type it notes, and… well, one example they give starts like this: announcing our new startup Flowrite. it uses AI to generate text from short samples. product live: end of 2020.\nAnd from that it generates:\n\nAfter weeks of hard work, we are proud to announce our new startup, Flowrite.\nFlowrite is a software product that is able to generate all kinds of different writings from short samples using advanced AI.\nFlowrite will be live at the end of 2020 [etc]\n\nSo it works in any browser, and the claim is that: Over time, Flowrite will learn your unique tone-of-voice.\nAs a fan of collaborating with AIs this is amazing.\nBut it’s also another indicator that we’ve stepped over some kind of threshold in hyperrealism, and along with tools like the MetaHuman Creator, deepfakes, Lyrebird voice synthesis, in the future we won’t be able to encounter anything without asking whether it’s real.\nMaybe that’s fine. Maybe, if you’re trying to hire or teach or date, and an email is smart or well-put-together or funny, it won’t matter whether it was written by the actual human or generated by software. They’ll be able to use those same email-authoring centaur prostheses when “on the job”.\nBut can you imagine taking some words seriously, or video, or a phone call, but then finding out that the nuance was auto-generated filler.\nEverything is real\nSimultaneously, there are no more coincidences.\nThere’s a service called The Spinner which repurposes online ad targeting for precision micropropaganda:\n\nThe Spinner is a service that enables you to subconsciously influence a specific person, by controlling the content on the websites he or she usually visits.\nThe targeted person gets repetitively exposed to hundreds of items which are placed and disguised as editorial content.\n\nFor example it’ll surreptitiously show articles about going vegetarian, buying a dog or initiating sex (its most popular campaign) to whoever you want.\nThose are from this 2019 article: For $29, This Man Will Help Manipulate Your Loved Ones With Targeted Facebook And Browser Links.\nAnd: Two women used it subtly encourage a co-worker they disliked to quit their job.\nDoes it work? Doesn’t matter.\nWhat matters is that we’re accustomed to being able to discount coincidences as mere coincidences – as much as I enjoy Jung’s synchronicity and acausal interconnectedness, and work hard to develop my own sensitivity to it.\nBut again, in the future, we won’t be able to encounter a coincidence without entertaining the possibility that it might not be a coincidence at all, but instead evidence of some kind of intelligent design at work.\nLike, in a video game it’s fine to see an object and suspect that it has been placed deliberately to influence direction or unlock future narrative – but it would be tiring, in the real world, to ascribe that intentionality potentially to everything. Surely?\n",
    link: "/home/2021/02/23/real",
  },
  {
    title: "My best story about Bitcoin and cats, which isn’t even my story",
    date: "17.44, Wednesday 24 Feb 2021",
    content:
      "After mentioning Qarnot the other day, which repurposes waste heat from e.g. computer-heavy 3D graphics rendering to warm offices, I ran across this article: How I heat my home by mining crypto currencies, and it’s beautifully clear:\n\nNever mind how it works on a technical level, the main takeaway is that you can put some device in your house that uses electricity and produces heat. In exchange you get shares of that crypto currency coins like Ethereum or Bitcoin which you can sell on a trading platform.\n\nThat device is called is a “miner.” It helps run transactions on the crypto network, it generates heat, and it makes money. In the old days, they were sensitive and buggy, so you would have alerts set up to let you know if yours had crashed (because it would no longer be paying out). They’re more reliable nowadays.\nAnd, success. The author reports: I was able to lower my heat pump’s electricity needs by ~50% and half of the costs are also paid for by the mining earnings.\nAll of which is\n\nwonderfully circular in that the heat is being used and not wasted\nfrustrating in that the heat should never have been created in the first place, because the “value” of cryptocurrency is not the $-value of one Bitcoin, that’s a fantasy value, I mean the actual intrinsic value, the useful work achieved which is the act of performing transactions for societal gain, that value in no way justifies the disproportionately huge heat and carbon expenditure of the existing cryptocurrency infrastructure\n\nbut putting that aside:\nI am reminded\nof a story\nabout Bitcoin\nand\nmy friend’s cat\nfrom 2014:\n\nBB the cat figured out if he wants to go outside for a walk he just needs to sit on the bitcoin miner until it overheats and switches off and I come running down the stairs in a panic.\n\nAnd there’s something about triggering a fault in speculative global financial services infrastructure, as a way of telling a watchdog system to fire an SMS (or whatever) to interrupt someone’s attention while they’re working so they come down to investigate and end up opening the door, because you’re too lazy to walk upstairs and meow which is just, I don’t know. Emblematic. I love it.\nThank you Warren Miller or rather thank you his cat, and here’s where I first tweeted his story (I checked I could share at the time).\n",
    link: "/home/2021/02/24/bitcoin",
  },
  {
    title: "Let’s invent new interfaces, not new products",
    date: "17.32, Thursday 25 Feb 2021",
    content:
      "Okay, so how about a pager with an AI in it?\nIn some ways the last few years have been inventive for consumer tech: smart watches, smart speakers, car dashboards, and smart glasses almost inevitably just over the horizon.\nBut take the watch: I feel like it suffers from being jammed through the same app-based interaction paradigm that was perfected on the smartphone, which itself was a simplified version of the desktop UI.\nI don’t think we need to look far for alternate interaction paradigms.\n\nWorld Wide Web, as originally conceived, a hypertext of interlinking documents, with no homescreen and no prohibition against deeplinking – that was new.\nThe command line (and then, in games, text adventures), with the ability to pipe data between commands – and hey, even Excel, as a canvas of data sources and user recombination, that’s novel.\nDynamicland, a physical environment of smart light, human writeable code, and a social interaction with the computer.\n\nAll of those!\nYet… we’re stuck with apps?\nI don’t know, it just feels like we might be missing a trick.\nWhat if the goal was to come up with whole new ways of interacting?\nYou could play a game:\n\nTake an old product category. Say, the pager. A box that you wear on your belt that gives you three lines of text out of the air, and it can buzz.\nGive it superpowers. Fill this pager with a large language model so it speak like a human, give it the internet, give it perfect dictation so it can understand me when I speak, and add a subvocal throat mic using Google’s radar-based Project Soli technology it can detect my larynx from my waist, I don’t need to wear anything on my face, and I don’t even need to speak out loud. (Could that work? I just made it up.)\nAnd then imagine the interface.\n\nI think that would take you somewhere new.\nLike maybe such an interaction mode would slipstream directly into the internal monologue. You’d mumble to yourself “I think I’ll spend the next hour writing,” and a buzz at your waist would make you look at the screen: No sorry you have a call in 30 minutes.\nOr you would say, under your breath: “I’m heading into town now” – and the buzz would only come if it picked up that your usual train was delayed or whatever.\nOr you would rapid-fire scan the headlines and triage your email, muttering quietly as you go through, with your phone by your side to pick up bigger tasks. What sophisticated data structures could you manipulate? If our primitives in the current world are basically apps, scrollable canvases, lists, form widgets, and tapping, and in the desktop world were windows, documents, and menus, what would they be for this?\nI’ve been using dictation as an alternative to the keyboard on my iPad recently, and I feel like multimodal text+voice is under-explored right now, and more powerful than voice on its own.\n",
    link: "/home/2021/02/25/pagers",
  },
  {
    title: "Four years of noting down my favourite words",
    date: "14.09, Friday 26 Feb 2021",
    content:
      "Feel free to skip reading this post. It’s just a big list of words and phrases, here so I don’t lose it.\nOn 27 February 2017, about four years ago, I tweeted these words: Storm Doris. Mimecom. Cloudbleed. Athleisure. Cromwell. H7N9. Trappist-1\nIn order, they are: a serious storm that was hitting the UK; the virtual reality technology in the the 1993 sci-fi TV miniseries Wild Palms; a major security hole discovered in a particular and widely-used content delivery network; a still fast-growing and newly mainstream fashion trend; the winner of the First English Civil War and only republican leader of the Commonwealth; a then-common bird flu subtype; a star only 40 light years away which had just been discovered to have four previously unknown terrestrial exoplanets.\nI like words, and I note down ones that catch my eye as we cross paths. I have a little file, and once I have another seven or eight, I’ve been posting them as replies to that original tweet. Here’s the most recent one (19 Feb 2021).\nI tend to record words that…\n\nwere everywhere and seemed perfectly normal at some point in the past, but now they’ve lapsed\nfeel novel today, but have a chance of being commonplace in the future – and maybe I can predict which ones\nrepresent an idea that was, once upon a time, novel enough that it required naming, although now we wouldn’t bother to do so\nput a name on an idea that hadn’t occurred to me\nstand in for a much grander idea\nlead to a surprising idea\nare big in my corner of the world, though perhaps not for anyone else\ndominate the public discourse right now, temporarily, and we all bandy around the word as if it actually means something, but it doesn’t and it’s super weird given any kind of distance at all\nfeel pleasant to say.\n\nSometimes I read over the list, random access style, just to remind myself of forgotten thoughts. Each word is a bookmark into a little cascade of concepts in my brain.\nSo because I’d like to keep these words somewhere I can find them in the future, I’m putting them here.\n455 personally resonant words and phrases, in the order that they came to me:\n\nStorm Doris\nMimecom\nCloudbleed\nAthleisure\nCromwell\nH7N9\nTrappist-1\nThe Glorious Revolution\nHard Brexit\nAnswering machine\n“Mute all eggs.”\nCodex Hammurabi\nVault 7\nMicroburst Event\nJerry Cornelius\nArticle 50\nLacerta\nUnforced error\nTheia\nWestinghouse\nBärenschliffe\nVanta Black\nHenry VIII clauses\nVDU\nHypertext\nSlime\nSagittarius A*\nArtificial mythology\nUnicron\nHomogenitus\nBATNA\nFrankpledge\nPower user\nGarden Bridge\nCarthago delenda est\nThe Antikythera Mechanism\nClick farm\nBaal\nShinrin yoku\niuqerfsodp9ifjaposdfjhgosurijfaewrwergwea dot com\nMcCarthy\nCMX1\nFidget device\nAlarm clock\nInformation technology\nDark ads\nWalk loop\nYlnMn blue\nBlessU-2\nLOL Surprise Doll\nStatistical mechanics\nRemote control\nNew media\nKunstforscher\nAbracadabra\nHarmonized System Nomenclature\nPeak Antibiotics\nVan Life\nSourdough\nBritpop\nLate binding\nThe September that never ended\nCalving\nFingerfehler\nExtinction burst\nInitial coin offering\nSatisfiability\nTotal internal reflection\nThe Dude abides\nMod cons\nTissue nanotransfection\nNibiru\nWhitepaper\nShow business\nGAFA\nCredit Crunch\nGobstopper\nMechanosphere\nGoldilocks zone\nNon-player character\nBlue Whale Challenge\nPlandid\nCyberweapon\nTotality\nThe Gruen transfer\nSmile to Pay\nDolphinAttack\nSecular resonance\nTake back control\nGloomth\nFossil water\nRandom forest\nSuper Retina\nProactive cooperator\nTruth and reconciliation\nFancy Bear\nHard ecu\nUser space\nSkip Intro\nDolly the Sheep\nSpelunking\nOumuamua\nEctoplasm\nGrandfather clock\nBlack Friday\nCrypto billionaire\nInferences per second\nInfluencers\nIntersectionality\nClickbait\nGenesis block\nFuzzy logic\nText adventure\nCursus\nLaniakea Supercluster\nPantograph\nConversation Lozenges\nHot-potato routing\nBlat\nRaw water\nDesigner salt\nSpeculative execution\nWave function\nThe Third Way\nM77232917\nFlash mob\nVirtuality\nWhat you see is what you get\nThe Magic Faraway Tree\nEdgelord\nQuantum supremacy\nOnticity\nDeepfake\nMetadata\nUnexpected item in the bagging area\nThe Humanity Star\nWuxia\nBeowulf\nRemoaner\nLord Haw-Haw\nJohnny Appleseed\nGoldilocks Zone\nVeni vidi vici \nEscort mission\nGeneral Magic\nThe devil’s hatband\nInclusion rider\nPick n mix\nProtein\nYak shaving\nCold War\nGold master\nAlgohol\nCry4\nNovichok agents\nOAP\nCockroach milk\nOtherkin\nNociception\nThe Krebs cycle\nGini coefficient\nKeiretsu\nBox set\nVanguardism\ni-motif structure\nIncel\nThe Fourth Estate\nThe Age of Aquarius\nThe Pearl River Delta\nGammon\nHostile environment\nThe Invisible College\nAfrofuturism\nVaporwave\nConcorde\nLaurel and Hardy\nTwo and twenty\nAbilene paradox\nCard clash\nSub fusc\nC\nNocoiner\nOperation Popeye\nShock and awe\nFire and forget\nSlash and burn\nFingers of instantiation\nTrapdoor function\nWear Sunscreen\nNorwich Pharmacal Order\nVAR\nThe God Particle\nMax fac\nDu-reformen\nSpace Force\nFlop account\nRaubwirtschaft\nBrand loyalty\nPC LOAD LETTER\nIt’s coming home\nWASP\nLong Vac\nState machine\nYellowhammer\nMonkeypox\nSkype White\nMagneto­hydro­dynamics\nTotal cost of ownership\nThe Brandt Line\nRunaway convention\nThe Goblin\nIceCube 140611\nLate Heavy Bombardment\nLatent space\nAsgard\nHexatic phase\nTelecommute\nChabudua\nSide hustle\nThe Middle Kingdom\nLychgate\nMojibake\nAgitprop\nBrain drain\nNaN\nDamp squib\nThe default mode network\nToo Many Cooks\nDwarsligger\n51% Attack\nShirts versus skins\nImbolc\nPolar vortex\nDiffractive deep neural network\nBob-a-job\nIsostatic rebound\nDoggerland\nThis is for everyone\nErskine May\nPleuston\nMomo Challenge\nMemory hole\nAndon Cord\nAshby’s Law of Requisite Variety\nOperation Redfold\nFirst world problem\nhunter2\nLandline\n2,147,483,647\nSpeaker Denison’s rule\nPuppyslug\nThe four minute warning\nCunningham’s Law\nFood processor\nGraphic equaliser\nLuther Blissett\nCattywampus\nHeH+\n#FICTIONALEVENT\nPotlatch\nDial tone\nCyberspace\nDigital transformation\nGenpop\nSchelling Point\nOuroboros\nHopepunk\nThe yee haw agenda\nStochastic terrorism\nHauntology\nSpontaneous human combustion\nFnord\nGhost Work\nCoordinated Inauthentic Behavior\nMushroom suit\nGreat Red Spot\nThe Bermuda Triangle\nAcid rain\nPacket loss\nRefillery\nLandline\nP-zombie\n23114, 584, 46931\nTeegarden’s Star\nEveryday carry\nWhisker fatigue\nYeet\nThe klept\nDick Whittington\nRetail therapy\nRising of the lights\nTohuwabohu\nSpice zombie\nAttention Correction\nDecacorn\nBlandlands\nLysenkoism\nWhat, me worry?\nYlem\nDragonfly\nPolitical correctness\nDagen H\nDöstädning\nFlygskam\nFrank’s sign\nIconoclasm\nWebmaster\nPotus\nExcorporation\nHorizontal gene transfer\nBlack hole\nTwinfluencers\nASMRtist\nOverhead projector\nNews theatre\nFlash Player\nTechlash\nComptometrist\nOutriders\nChesterton’s fence\nTerraform\nOuija board\nMagic Robot\nSelf-coup\nShrinkflation\nMods and rockers\nBouncy castle\nFloppy disk\nProrogue\nUpsum\nBarmy Army\nFakeaways\nKardashev scale\nDeadname\nRed teaming\nType B fun\nBlack start\nMaillard reaction\nSpice zombie\nInbox Zero\n77th Brigade\nCoal\nReverie\n0th world\nLord Protector\nLegerdemain\nBum-sculpting\nHeavy dog\nDemographic engineering\nKilgore Trout\nJust a band\nPenguin diagram\nSolastalgia\nTrantor\nFloating point\nTotal perspective vortex\nCRISPR\nEat the rich\nChillax\nFiducial marker\nFree market\nWYSIWYG\nNerd sniping\nDopamine fasting\nBlue screen of death\nSeenzoned\nSand theft\nBelt and Road Initiative\nCosmic ordering\nWasm\nLow poly\nGeneration ship\nNarrative Violation\nState Capture\nVampire facial\nMicroblading\nAnsible\nThey\nPerineum sunning\nEthnonationalism\nJohn Company\nIridium flare\nPhotobombing\nDecolonisation\nMMXX\nPrepper\nCancel culture\nRemainer\nThe Local Group\nFrankpledge\nNormcore\nFactory reset\nCoronavirus\nRawthentic\nMesofact\nWalking wounded\nAugenmusik\nStraight edge\nDunning\nLazy Susan\nFruit wall\nCOVID-19\nSovereign citizen\nDark kitchen\n77th Brigade\nPandemic\nSelf-isolate\nSocial distancing\nTrolley problem\nHungry gap\nThe jackpot\nNew normal\nEcofascism\nWebinar\nHamsterkäufe\nDoomscrolling\nMundane AU\nThe Cool Zone\nAve atque vale\nBlack Lives Matter\nSkin hunger\nGroutfit\nSpacepower\nRoko’s Basilisk\nStakhanovite\nCancel culture\nNEOWISE\nThe Chorleywood Bread Process\nCollab houses\nMankad\nPhosphine\nChaos theory\nKent Access Permit\nCarcinisation\nCapitalist realism\nK-shaped recovery\nDual power\nPrimordial soup\nThe Sea People\nAbuwtiyuw\nSohcahtoa\nHerobrine\nNoclip mode\nThe ecumene\nThe 1954 Greada Treaty\nIsles of Wonder\nThe Odic force\nSedition\nBreakthrough Listen Candidate 1\nEugene Goodman\nCryptic northern refugia\nMeatspace\nFossil fuel\nDress-down Fridays\nGwalb\nThe Omega Point\n\nThanks for your attention and I’m happy to take any questions.\n",
    link: "/home/2021/02/26/words",
  },
  {
    title: "Revolutions and NAND gates, eight cents, wholesale",
    date: "09.24, Tuesday 2 Mar 2021",
    content:
      "I recently read Tracy Kidder’s Pulitzer-winning The Soul of a New Machine (1981) about the development of a new minicomputer by Data General.\nHere’s a passage about transistors:\n\nTransistors, a family of devices, alter and control the flow of electricity in circuits; one standard rough analogy compares their action to that of faucets controlling the flow of water in pipes. Other devices then in existence could do the same work, but transistors are superior. They are solid. They have no cogs and wheels, no separate pieces to be soldered together; it is as if they are stones performing useful work.\n\nReading that, it’s so clear that 1981 is closer to 1947 (when the transistor was invented) than today.\nMatter, without movement, can perform useful work! Solid state. This idea is insanity when you think about it, and Kidder in 1981 was able to call that out.\nTwo transistors make a NAND gate, and a NAND gate is both a physical thing and a mathematical operation and - with many connected together - can store numbers, add numbers, discriminate between numbers, and so on, numbers being both data and instructions to perform more operations.\n\nThe solution takes the material form of a circuit called a NAND gate, which reproduces the “not and” function of Boolean algebra. The part costs eight cents, wholesale.\n\nThe latest iPhone has 11.8 billion transistors. So the chip at the heart of each phone is $1.4 billion in parts, no margin. That’s 1981 prices, 2021 money accounting for inflation.\n(Updated 5 March to fix maths/words. Previously claimed $1.5b.)\nThe book narrates the journey from standing start to functional computer hardware.\nI’ve done this myself. One of the labs at college took us from semiconductors, through transistors, then gates, then shift registers, then designing and seeing for ourselves primitive adders, memory, and commands, and finally working with a 6502 processor. The 6502 is the chip inside the BBC Microcomputer, which I grew up with, so it’s sophisticated while also being simple enough that - having built our own registers etc - you can look at the schematic and kid yourself that you know what’s going on. And when you poke binary into the 6502 and program it to add 2 and 3, and execute that operation and, having ascended that ladder with your own hands, see in your mind’s eye the shift registers rippling and the gates flipping and the electron in every transistor collecting and flowing…\nA spiritual experience, and a healthy dose of cognitive vertigo.\nAnd then, with consumer hardware, I’m familiar with that weird knot of bringing up hardware: the bench prototype, firmware, basic interaction, and the gyre that spirals up as you develop each part – but also the role of simulators, partial documentation, and internal languages. Developing systems is hard.\nDespite all of that, I hadn’t quite appreciated the role of microcode, being: a layer of computer organization between the CPU hardware and the programmer-visible instruction set architecture of the computer.\nA programmer will ultimately break their code down into primitives like ADD and  JUMP, but at a certain point those instructions have to be converted into a series of high/low signals that tell circuits what operations to perform and where to send their data. It’s where software becomes hardware, where the rubber hits the road, as it were. It’s the level at which there aren’t any abstractions anymore.\n\nMicrocode is, in this sense, like early Old English, in which there was no word for fighting and a poet who wished to convey the idea of battle had to describe one.\n\nI don’t know if that is an Historical Fact about Old English, but I like the turn of phrase.\nAnyway, it’s a terrifically told story mainly about personalities and teams, and also about computers.\nAlso a history at this point too. A floppy disk is explained as like a 45-rpm record and few readers in 2021 will have direct experience of either referent.\nSo it’s an easy trap to read the story and see it as archaic, but really it’s archetypical; this is the world we live in now, but slowed down and magnified so we can see the roles and relations and gaps at something like human speed.\nOne other quote that caught my eye:\n\nFor many years sociologists and others have written of a computer revolution, impending or in progress. Some enthusiasts have declared that the small inexpensive computer inaugurated a new phase of this upheaval, which would make computer instruments of egalitarianism. …\nBut in the main, computers altered techniques and not intentions and in many cases served to increase the power of executives on top and to prop up venerable institutions.\n\nAnd that’s another observation that could only have been made closer to the start than today, with the perspective to see the before and after: if it served to entrench and not upend the existing class system, was the computer revolution a revolution at all?\n",
    link: "/home/2021/03/02/microcode",
  },
  {
    title: "Filtered for some text-based virtual realities",
    date: "19.53, Wednesday 3 Mar 2021",
    content:
      "1.\nCait Kirby’s September 7th, 2020 is a playable webpage.\nIt’s a short and powerful story:\n\nYou are a sophomore at Most Distinguished University of the North. You are a biology major and very excited about your genetics class this fall. …\nYou wanted to take all your classes online. Instead, this is your day.\n\nYou click, the story unfolds. There are a few choices along the way.\nUltimately it’s an argument that, in the midst of Covid-19, university classes should be online.\nCould this have been an op-ed, or a blog post? Yes. But instead it’s a self-contained text experience, almost a mini environment, and all the more transporting and empathy-building for that fact. It’s like that line from the old BBC broadcaster Alistair Cooke: I prefer radio to TV because the pictures are better.\nIt looks like this was written in Twine, which is a graphical app to author interactive, nonlinear stories. Then published with Sugarcube which is a web-based “player” for Twine stories, originally based off a wiki interface which explains why it feels so much like a hypertext. Here’s a great tutorial on using the two together: How to use Twine and SugarCube to create interactive adventure games.\n2.\nParabolic House is an immersive theatre company, and their latest production is The House of Cenci: Integrating a free-roaming text adventure with live performance on Zoom across four weeks.\nYou can play The House of Cenci text adventure here.\nAgain it’s a playable webpage (possibly using Twine?), and it seems to sit halfway between interactive fiction (you tap the words to unfold the story) and an environment (you move between rooms and pick up objects).\nI like the way the description of each room expands telescopically, and then the screen resets when you move.\n3.\nThe Impossible Bottle by Linus Åkesson was joint winner of the 2020 Interactive Fiction competition (its 26th year!).\nIt is charming, gently puzzling, and beautifully described. Gorgeous.\n\nPlay the Impossible Bottle in your browser. It’s a text adventure, so you type like “look” and “take blanket.” – but with this system, you can tap on the words too, like hyperlinks. Which is friendly! Meaning: mobile friendly, and friendly for beginners too.\nBrowse other IFcomp 2020 winners.\nThe game’s IFDB entry has other ways to play, and some reviews/a walkthrough.\n\nBecause The Impossible Bottle follows text adventure tropes (i.e. you go east, north, up, etc), it feels very much like exploring a real place – it’s definitely less like a story and more like immersive theatre. A text-based single-player virtual reality.\nWhen I play text adventures, the image that always comes into my head is Superman’s Bottle City of Kandor: Kandor served as Krypton’s capital and main cultural center. BUT! An alien starship arrived and enveloped Kandor in a force field and some sort of shrinking ray.\nAnd now Superman has, at his Fortress of Solitude, this whole tiny city with all these tiny inhabitants going about their tiny business, kept in a bottle on the shelf.\nSo I enjoy dropping into these bottle cities, and particularly I like it when they’re not too overwhelming and I can play on my phone.\nÅkesson used a self-authored game engine for this work: The Å-machine. A more accessible app to author these kind of environment-based text adventures might be Inform 7 which feels a bit like writing a narrative, but can also output to a playable webpage.\n4.\nTully Hansen’s Writing is an unfolding/flowering text/poem/meditation about, well, writing. It starts with one word.\nGive it a go, it’s wonderful. The experience of reading this semi-branching, semi-guided text is a little bit like having meandering thoughts yourself - I do wonder what David Markson would have done with this - but the fact your thumbs are engaged too makers it new. It has good… tap-feel? Can that be a word now?\n(Written using telescopictext.org which is a tool for creating such things.)\nSEE ALSO:\nRobin Sloan’s seminal Fish: a tap essay, which is an experiment in a new format: a ‘tap essay,’ presenting its argument tap by tap, making its case with typography, color, and a few surprises.\n(And I saw Sloan mention on Twitter the other day that he has a new framework for tap essays in the works, based on the open-source-and-just-released ink scripting environment for interactive narrative. Another authoring environment to experiment with!)\nI think what I like about these experiments in new formats is that they’re like the text equivalent of tape cassettes if you remember those. Somebody would pass you a cassette at school, and you’d take it home, and lie on your carpet in your room next to the tape machine, and hit play, and just be transported for 30 minutes, music in your ears and the pictures in your head. If you could take that experience and bottle it… Well.\np.s. If you know of more self-contained, text-based virtual realities, particularly experiments with new formats, please send them my way. I’m interested.\nBONUS LINK:\nCheck out the newsletter 50 Years of Text Games.\n\n“50 Years of Text Games” is a project that traces a path through the history of digital games without graphics, by picking one game from each year between 1971 to 2021 and taking an in-depth look at how it works and why it’s important.\n– 50 Years of Text Games (Aaron A Reed), About the Series\n\n1971 is the pre-history of text games, so start right at the beginning and you’ll read how computer games came about and why, and how they spread using nascent computer networks, and how the idea of selling them in plastic bags had to be invented too, and… well, it’s great. It’s up to 1978 right now (going at one year a week), so there’s a good way to go yet. I recommend you subscribe.\n",
    link: "/home/2021/03/03/filtered_for_text",
  },
  {
    title: "My iPad should have a gaze-controlled cursor",
    date: "17.55, Thursday 4 Mar 2021",
    content:
      "My setup is that I have my monitor on the left (with a Mac mini), and my iPad on the right. I copy and paste between the two like crazy. Honestly that feature is magic.\n(It’s like this so I can use my iPad for video calls and music, and keep notes or screen share from my desktop. I have a desktop because my laptop blew up and, unintentionally, this has done wonders for my work/life boundaries.)\nBut my iPad is juuust out of reach and it drives me crazy.\nI should be able to control the iPad cursor with my eyes.\n(Have you used a mouse with an iPad? It’s not an arrow. The screen elements “underneath” the cursor grow and pop - this article has some GIFs - and when you’re not pointing at anything, the cursor is a translucent circle. It works amazingly well. I’m hoping to never own another Mac laptop, but I will upgrade my iPad to the next version as soon as it’s out.)\nClearly I don’t want to be controlling my iPad cursor with my eyes the whole time. So to trigger this, I should stare right into the camera and double blink. Double blinking can be the “Hey Siri”/wake word equivalent for gaze control.\nA tap can be another double blink. Look away for 2 seconds to dismiss the cursor.\nOh and then, text input:\nWhen I’m not at my desk, I often use my iPad at the kitchen table. Recently I’ve using the Pencil and writing into text boxes, or hitting the microphone button on the keyboard and using dictation. When you’re speaking and writing just a word or two, this hybrid approach works pretty well.\nSo while my gaze is resting on a text box, let me activate dictation my making a noise, maybe a click with my tongue.\nI’m not sure about indicating that I want to end a dictation session. It has to be a deliberate but rare vocalisation. Maybe blowing a kiss to my iPad, mwah.\nLet’s say this become a thing. I wonder how it would change the semiotics of looking and control? People already say in corporate environments, with no irony, let’s double click on that, and it makes sense. But, like, if someone were to make eye contact with you and then double blink. In that scenario you would become the cursor. They would possess you with their gaze.\n",
    link: "/home/2021/03/04/cursor",
  },
  {
    title: "1980s (you), 2000s (connection). What’s the 2020s zeitgeist?",
    date: "16.26, Monday 8 Mar 2021",
    content:
      "What’s this groove called under my nose? If you’re in the UK, the way you’ll know is because of this BT ad from 2001 (YouTube).\nA small girl asks an entire stadium of people; somebody stands up and answers. Cut to: somebody selling fish. Cut to: somebody looking for investment: Cut to, etc. It’s the internet, see.\nThe strapline was: More connections. More possibilities.\nNokia was dominant in mobile phone sales from 1998 to around 2010. Nokia’s slogan: Connecting people.\nIt was amazing to connect with people in the late 90s/early 2000s. I don’t think we were lonely exactly. But maybe meeting people was somewhere between an opportunity, something novel, and, yes, a need – suddenly it was possible to find the right person, or the right community.\nSo, the zeitgeist of the early 2000s.\nI ran across a previous zeitgeist in an article about Choose Your Own Adventure books. They appeared and became massively popular at the same time as text adventure computer games, but neither inspired the invention of the other. How? The real answer may lie far deeper in the cultural subconscious … in the zeitgeist of the 1980s.\n\n[Historian Eli Cook] draws parallels between the CYOA books’ claims that “You and YOU ALONE are in charge of what happens in this story,” that “You are responsible because you choose,” and Reagan Republicans cutting welfare programs because people in poverty had only themselves to blame-that they’d simply made poor choices. But this wasn’t just a conservative turn: the language of abortion-rights advocates settled on “pro-choice” in the 1980s, Cook notes, while ad campaigns across the country were switching to second-person slogans like “Have It Your Way” or “This Bud’s For You.” Self-determination had become the watchword of the day, and individual agency the most potent application of American freedom.\n– 50 Years of Text Games, 1979: The Cave of Time\n\n1980s: you.\n2000s: connection.\n2020s: ?\nZeitgeists don’t lead and zeitgeists don’t follow.\nI think when we spot some kind of macro trend in establishment consumer ads, it’s never going to be about presenting people with something entirely new. To resonate, it has to be familiar - the trajectory that the consumer is already on - but it also has to scratch an itch. The brand wants to be a helpful fellow traveller, if you like.\nI wonder what the zeitgeist of the 2020s will be, or is already maybe. What deep human need will be simultaneously a comfort and an aspiration? There should be hints of it in popular culture already. (If I knew how to put my finger on it, I’d be an ad planner.)\nIf I had to guess then it would be something about belonging.\nThere was a hint of this in Reddit’s 5 second Super Bowl commercial which went hard on one their communities, r/WallStreetBets, ganging up to bring down hedge funds. Then we’ve got a couple of generations now who grew up with the idea of fandoms, and of course conspiracy theories like QAnon too. If you squint, you can kind of see this in the way Tesla operates: it’s a consumer brand but it’s also a passionate, combative cause.\nBelonging to a tribe is about identity and strength, it’s solace and empowerment all at once. And also knowledge, certainty, and trust in an era of complexity, disinfo, and hidden agendas.\nGiven that backdrop, it’s maybe unsurprising that the trend in software is towards Discord servers and other virtual private neighbourhoods. But how else will this appear? And is it just the beginnings of something else, something bigger?\nPhiltrum.\n",
    link: "/home/2021/03/08/zeitgeist",
  },
  {
    title: "Filtered for bonsai trees",
    date: "18.04, Thursday 11 Mar 2021",
    content:
      "1.\nLEGO’s beautiful Botanical Collection (launched December 2020) includes flowers, as bouquet and stems, and a bonsai tree.\nThe bonsai tree is delicate, with a gently curving trunk, and a choice of green leaves or pink blossom. Here’s a review. \nHere’s a nice touch: the brinks are made from LEGO’s new sustainable sugarcane-based bioplastic, not ABS, continuing their trend of rolling out this new material with plant pieces first. More on the design here (2018).\n2.\nDuring his fifth year in Japan, Neil began to think about what an American style of bonsai could be.\nLong read about Ryan Neil, bonsai artist, who spent six years in an apprenticeship in Japan, and then returned home to Oregon to develop bonsai using American trees: The Bonsai Kid, Craftmanship Quarterly (Fall 2015).\nNeil apprenticed with bonsai master Masahiko Kimura, and when he arrived:\nOn this particular day, Kimura was restyling a 1,000-year-old spruce.\nI’ve laid palms on standing stones in the Outer Hebrides that were placed there by human hands 5,000 years ago, but I can’t even conceive of actively styling a millennium-old tree. Staggering.\nOn Ryan Neil’s website, there’s a gallery of his American bonsai – and (to my uneducated eye) there’s a difference in the aesthetic from what I imagine as “traditional” bonsai. They’re dramatic! Windswept! Motion and age in solid form!\nHow much of this is Neil’s own style, and how much is what the American trees “want” to become?\nAn ancient art, in symbiosis with a new environment and a new embodiment. So I’m taken with this work in discovering a new vernacular.\nWhat would the bonsai of Low Earth Orbit Habitat 1 want to be?\n3.\nHere’s a command line bonsai tree: cbonsai\nIt draws a colourful, random tree using ASCII art in your terminal, each time the command is invoked.\nThe code built on my Mac with a minimal amount of coercion, so I currently have a tree growing in the corner of my screen, the procedural generation unfolded at one tick per second.\nIt’s meditative. I feel like I could watch this for a peaceful 100 seconds each morning, the success of my day augured by the spread of the branches and the dynamic flow of the foliage.\nSEE ALSO: Desktop Meadow (Windows only) which I haven’t tried, but the video is gorgeous. Tiny pixel flowers grow atop the title bars of  your windows, and then little birds fly by and land and bring you messages. Swoon.\n4.\nAzuma Makoto’s Paludarium series.\n\nThe exhibit is heavily influenced by the miniature ecosystems [called paludarium], made popular by the 19th century British aristocrats. Much like a terrarium, these ecosystems are traditionally formulated in glass tanks to preserve the aquatic or plant life and maintain its aesthetic appeal. …\nThe Paludarium TACHIKO and YASUTOSHI are fully equipped with a responsive drip-feed water system, as well as a mist machine that activates to control the temperature and humidity within the cylindrical and cube glass chamber.\n\nDo check out these photographs which showcase the futuristic look of these metal and glass containers, woven with pipes and cabling, each housing a single bonsai.\nBeautiful, yes, and also hauntingly alone.\nThey make me think of Carl Sagan’s famous lines about Earth, the pale blue dot: Our planet is a lonely speck in the great enveloping cosmic dark.\nI kinda want every child to be given one of these at the beginning of school, and to be given time, assistance and encouragement to care for it over the years. If you grow up collecting Pokemon, expecting in adult life a Pokedex of your friends, you create Facebook. If you grow up with Minecraft, you create modular architecture. If you grow up with closed-system miniature ancient trees, fragile plant/machine symbionts made of lignin, cellulose and glass, requiring your care yet outliving you ten times over, you create… what?\n",
    link: "/home/2021/03/11/filtered_for_bonsai",
  },
  {
    title: "An eyebrow raise means left click",
    date: "20.04, Friday 12 Mar 2021",
    content:
      "After saying last week that I should be able to control my iPad with my eyes, I have just discovered the “Enable Head Pointer” option on my Mac.\n(Here’s a screenshot of the interface, for future reference.)\nThis allows my cursor to be controlled by the position of my head, as captured by my webcam.\nI also have it set up to left click when I raise my eyebrows. This is using an option called “Enable alternative pointer actions” that recognises various facial expressions.\nIt works surprisingly well! A little jittery maybe, and there’s a cognitive disconnect because the computer responds to the position of my head – but not the direction of my pupils.\nUsing the head pointer for a short while, I found that it worked well “leaning back,” but got confusing when I picked up the mouse again or started typing. So…\n\nThere’s an option to activate the head pointer based on a facial expression. Now I have it set up to turn on/off based on scrunching my nose.\nI still have a need to enter text (for example, a tweet or searching for music). So I’ve set Dictation to activate by double-tapping the option key – I couldn’t see a way to do this with a facial expression.\n\nSome observations:\nAs an input control it’s clunky, but nothing some machine learning wouldn’t sort out. For example, multitouch on smartphones is great at rejecting spurious input and understanding where you intended to tap, rather than the xy coordinates of physical contact. (Try using your phone with the screen upside down. It’s next to impossible because it’s built around the shape of capacitative contact and an assumed position of your eyes.) So if you got the software to consider both head movement and gaze direction, and trained it by looking at how users iterate towards intended targets, I’m sure you would end up with an almost magical “do what I mean” input mode.\nIt is so close to being something I would use in preference to a mouse… or rather, alongside one. What this tells me is that there is scope for an interface where you hop between mouse, gaze, speech, and back again. Why should I lean in just to open a calendar event, tap on Zoom link, and join a call?\nNose scrunch, look, eyebrows, look, eyebrows, done. Try it if you can. It’s amazing.\nCan I see an interface like this becoming standard? No, not on desktop computers… but I think it’s worth perfecting because of where it might lead. Might it be useful to control a smart TV – how would it work for a group? Or, when I was speculating last year about voice control for lightbulbs and stoves (but without sharing data with the cloud), maybe fluidly swapping between gaze and voice would be the ideal interface to the smart home.\nFinal observation: It’s worth noting that the “Head Pointer” is an Accessibility feature on the Mac. If you really sweat the details on accessibility, it turns out there is often broad applicability.\nI’m a big fan of Microsoft’s Inclusive Design efforts, and check out a diagram of the Inclusive Design approach here. In a nutshell their view is that disability is contextual. Somebody may permanently have one arm, but temporarily have an injured arm, or situationally be holding a baby – solve the coffee shop door problem for one of these groups, solve for all.\nAnd as someone who is often holding a toddler, whose eyes are already not that great and are getting worse, with trouble hearing, and an inability to recognise faces that honestly I should get checked out at some point, it’s a design approach I can get behind.\n",
    link: "/home/2021/03/12/pointer_control",
  },
  {
    title: "Continuing to think about research labs: 14 references",
    date: "17.04, Monday 15 Mar 2021",
    content:
      "Following my thought experiment about the Orthogonal Technology Lab back in January, I have had a ton of conversations with people generously sharing their perspectives.\nSo, here’s a collection of some contemporary research labs, as a way of thinking through which models I personally find most interesting. (I haven’t spoken with most of these, but they’ve come up in conversation. Apologies if anyone feels I have miscategorised their lab. I’m using categories only to aid my thinking.)\nAs a recap, the goal of my imaginary lab is to\n\nshift the discourse of what technology is capable of, e.g. finding business models for smart gadgets that don’t rely on collecting data or subscriptions; discovering new routes to interoperability for social platforms\ndon’t invent technology. Re-exploring old tech, and take a systems-thinking approach – create product prototypes, but also protocol drafts, Excel fictions, and so on\nbe independent and public yet commercial. The research programs should be visible and self-determined, but corporate involvement is important not just for $$$ but for amplification and access to ideas.\n\nAs outputs to this process, new technology and new ventures may be inspired, and that’s the desire but not the purpose.\nAnd I was trying to figure out the model. That was one of my questions last time.\nIndependent research labs\nOther Internet is an applied research organization in emerging technology.\nI keep coming back and looking at this model. It appears to be open, self-directed research to explore a variety of areas (the website is a series of public strategy/insight decks), and then that leads into private commercial collaborations.\n(Though if I were to clone and adapt this model, I would need to figure out for myself what I wanted next stage in the research pipeline to be, and how to move people towards that.)\nEthical Futures Lab aims to generate conversations among experts across disciplines [and] to build tangible examples of ethical futures.\nRight now it’s a great biweekly newsletter, which I think is a smart approach: explore and build an audience, ahead of deeper engagements. So maybe it’s a baby Other Internet?\nUnusual scientific institutes\nQualia Research Institute is a nonprofit research group studying consciousness.\nQRI appears to have the scaffolding of a research institute-shaped operation, some early research, and an advisory board of big names. It is currently pre-funding. It’s the “go big or go home” model and there’s a lot to be said for that.\nSci-Fi Economics Lab: we nurture and support new, radical ways to think about the economy and economic policy.\nIt’s a place to bring unusual projects into the world – like Witness, which is a collaborative, speculative world building project, documented on its own Wikipedia. See for example, The History of Witness. The lab is also a venue for discussion and conferences, so they’re definitely prioritising influence.\nThis strikes me as simultaneously the most bonkers result of grant funding culture and also a lab in its purest form: there is a barely discernible but real phenomenon on the lab bench, and a group of people have convened to figure out what it is.\nDynamicland. Our mission is to incubate a humane dynamic medium.\nThe most fully-fledged public, independent, consumer technology research lab that I’m aware of. It’s a grand experiment, and a physical environment, aiming to discover the next paradigm of computing. I mean, it’s amazing. But I suspect that nobody except the founders (Bret Victor! Alan Kay!!) could have established it.\nMemberships\nIDEO’s CoLab connects organizations to shape technology’s impact on the world. Together, we design the future.\nCoLab runs a number of different time-limited research programmes (e.g. Mixed Reality or Circular Economy) and corporates pay to set challenges to the research, take part in the collaborations, and have first dibs on the output. There is also a venture building element.\nFast Forward Labs, owned by Cloudera since 2017, is an applied machine learning research group.\nFrom what I understand, companies would subscribe to quarterly research reports about opportunities in machine learning, plus illustrative prototypes. Here’s the blog and here are the experiments. It appears to continue in a research-led and member-value-add fashion for Cloudera and its clients.\nIs this model still viable or did it only fly because true understanding of machine  learning was, back then, very rare?\nAgency style\noio studio is (according to the Twitter bio): A creative studio designing future products and interaction.\nWhen agencies are able to maintain their own culture, beyond client engagements, they’re able to maintain a research-like vibe. I don’t know these folks, but the public portfolio is one of wildly playful and imaginative experimental products, and that will buy them space to continue to explore the same territories even when working with clients, and permission to carry the ideas out into the world again.\nFor me, this isn’t quite what I mean by a research lab, but there’s a similarly of spirit and lot to learn from.\nStartup studios\nI’m not including startup studios in my list. I think that if the goal is to spin out startups, either for yourself or for corporate partners, then\n\nthe necessary “lean startup” approach pushes towards commercial viability too early, which is antithetical to the approach of orthogonal research; and\nwith startups, you tend to not show your working, which makes it harder to shift the public discourse (unless the startup is wildly successful).\n\nHowever…\nOne exception, as it’s come up many times, and the model is intriguing:\nInk & Switch. We are an industrial research lab working on digital tools for creativity and productivity.\nFrom the March 2015 pitch deck (pdf), this is a lab with a high cadence of rapid research and prototyping projects, each of which are written up publicly and in detail. For example this exploration in sketching ideas on tablets was, based on the response to the published write-up, spun out as the startup Muse.\n(I’m not including “venture building as a service” companies here either. What I’m focusing on is where direction precedes funding, and the IP isn’t entirely owned by the client.)\nCorporate\nSPACE10 is proudly supported by and entirely dedicated to IKEA - working as an independent research and design lab.\nAs a lab, it’s highly collaborative, and appears to operate by making precise interventions within broad themes. For example the Everyday Experiments research programme (which is about technology in the home) includes this wonderful collaboration: Light Gestures. As a research study into how to interact with smart lights, it’s thoughtful (great breakdown of the interaction) but accessible (lots of animated GIFs!). When you have enough of these experiments to pepper the theme, you’re really getting somewhere. There are also public research reports and a fellowship programme.\nBBC R&D and specifically the Internet Research and Future Services (IRFS) team.\nThere’s something powerful about researching and prototyping new ways to do storytelling in an organisation which is always looking for new ways to tell stories.\nArtistic\nSchool of Machines. We develop unique programs to teach the latest technologies while simultaneously questioning their usage, the world around us, and ourselves.\nI find this model fascinating. It’s primarily a teaching organisation, to enable artists with new tools and new perspectives, but the projects are provocative.\nFreeport. An independent study and production program led by artists.\nEach “lab” has a duration, a theme, and an artistic lead, of sorts, but is mainly a place to either expand your existing work and research, or test new ground.\nSetting out to encounter new problems\nGenerally I’ve not been looking back in time because the context around R&D has changed so much. But I do think a lot about the historic artist in residence programmes at both Bell Labs and Xerox PARC. These paired artists (animators, poets) with engineers and found new ways to see the world, and new applications of technology.\nTo read more about that, see my heavily-linked post about Art + Tech (2015). (I’ve also given that post as a talk a few times, always internally at companies. There are a lot of pictures and not many conclusions so it’s a good lunchtime sort of thing. Get in touch if you’d be interested.)\nI read a tweet the other day (I wish I could find it) which asked why it was CERN that came up with the web, and DARPA the internet.\nBoth of these places, suggested the tweet, came up against problems that nobody else had encountered yet.\nSo I think that’s one of the jobs of a lab, and it’s why working with artists works, and why you need both space for orthogonal research but also a way to engage with corporates or audiences with their own challenges: your goal is put yourself in a position where you face new challenges, and then report back.\nIf forced to choose…\nNo conclusions. Lots to learn from the above.\nOn the corporate side, SPACE10 is impressive. Though my own preference would be for something smaller and more opinionated.\nIDEO’s CoLab has managed to pull off corporate collaboration, and that’s amazing. They have the advantage of being able to cross-sell, and they’re also able to bring their valuable training capabilities. What if an agency or a design consultancy were a partner in a lab?\nI think the Other Internet model is fascinating. And the membership model of Fast Forward Labs. I wonder about how to blend the two, and whether I could make the economics  work.\n",
    link: "/home/2021/03/15/labs",
  },
  {
    title: "The ASMR version of Bee Movie, and other neuro-divergent media",
    date: "14.26, Tuesday 16 Mar 2021",
    content:
      "I haven’t talked about ASMR here before because it’s vaguely sexy and that makes me uncomfortable to discuss in public, but it perhaps also hints at a new wave of neurodivergent media, so let’s take that angle and pretend like we’re being intellectual.\nThe Washington Post covered “Autonomous Sensory Meridian Response” (ASMR) back in 2018: ASMR videos are edgy, unnerving and almost avant-garde. Is it time to consider them art?\n\nThe name sounds pilfered from a medical journal, but it’s basically Stuff That Makes You Tingle – the catch in a husky voice, a knife drawn through sand, a cat licking her paw, whatever sensuous ‘trigger,’ as ASMR folks call it, works for you.\n\nThose triggers? They are sounds: finger flutters, whispering, slow talking, slow talking while whispering, tapping, brushing, crinkling.\nAnd ASMR has become huge on YouTube over the years. Here are the two most popular channels I can find.\n\nZach Choi ASMR has 11.6 million subscribers. His most popular video is a collab with another ASMR artist, Stephanie Soo, and it’s the two of them eating various foods. 73 million views.\nSAS-ASMR has 9 million subscribers. Her biggest video has 47 million views and it’s 12 minutes of her eating honeycomb right up close to the mic.\n\nZach Choi’s estimated revenue: $1.2 million per month.\nI get maybe 10 seconds into these videos before feeling sick. Hearing people eat skeeves me out at the best of times, let alone captured by a close mic and played directly into my Bose QC35s.\nSUPER DISGUSTING. Let’s skip the food.\nGibi (her Wikipedia, her YouTube) has 3 million subscribers and a billion (actually a billion) cumulative views.\nHere’s an example for you to try: Gibi clicking and whispering (16m views).\nThe intention is that this carefully produced binaural sound has frequencies that will trigger a kind of sensual cascade. From Wikipedia: a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine.\nWhat I can’t quite tell is whether ASMR is supposed to be real. I mean, it’s nice?\nMaybe ASMR is for some people the neurological equivalent of a hack, where you visit a specially constructed webpage that breaks out of the browser sandbox, tunnels down from the application executable to the system kernel, and jailbreaks your phone; a sound sequence that buffer-overflows your auditory cortex and starts writing random bits over your pleasure centres.\nBut I’m half convinced that it’s popular because it’s all just a bit sexy. The ASMR articles I can find deny this vehemently, but ASMR videos are mainly attractive young people, mainly young women, whispering in your ear, and surely that’s why they have billions of views? I mean, isn’t it as simple as that? And there’s an unspoken conspiracy to claim that it’s “art” and “parasthesia” so that everybody can avoid admitting that they’re watching hours of videos of young women slowly eating honeycomb in order to pass their days in a state of being low-grade turned on?\nLook: I will take ASMR at face value. If others say it’s real, it’s real.\nASMR is a legit cultural phenomenon, and it is no weirder to be microdosing intimacy on YouTube than it is to get thrills out of sitting around with your friends and watching 90 minutes of people in costumes hitting each other while rousing music plays. Hollywood has normalised and industrialised violence and emotional manipulation so pervasively that it’s hard to see it for what it is any longer, and it is way stranger and more concerning to realise that there are entire companies dedicated to filming people dressed up and pretending to inflict hurt on each other, plus special buildings to go and watch these productions in, than it is for there to be people on online pro-am streaming websites with expensive audio equipment acting like they’re cutting my hair.\nANYWAY.\nGibi and her 80 closest ASMR friends have banded together to make an ASMR cover of Jerry Seinfeld’s Bee Movie.\nThe ASMR Bee Movie (95 mins; premiered 27 Feb, 2021).\nThe entire thing is synced to the original Bee Movie on Netflix, and the intention is that you watch both, side by side.\nIncroyable.\nThere’s a lot of whispering and a certain amount of dressing up as bees.\nI guess it’s like the zillennial version of listening to The Dark Side of the Moon from Pink Floyd while synchronously viewing The Wizard of Oz? I remember being 17 and watching Arthur C Clarke’s Fractals: The Colours of Infinity with a friend for, um, pretty much a whole weekend. Same diff.\nThere’s a quote from Teller of the magicians Penn & Teller, in this long and excellent profile:\n\nSometimes magic is just someone spending more time on something than anyone else might reasonably expect.\n– Esquire, The Honor System (2012)\n\nAnd, beyond the sensory experience, there’s definitely some of that going on. It must have taken a lot of effort.\nSo I am in love with the ASMR Bee Movie, and the fact that people have created it gives me hope for the future.\nSeparately, and assuming ASMR is real in that some people don’t get it but other people experience it intensely:\nI feel like it’s healthy for us as a society to acknowledge that different people have different subjective experiences of the world, and that there are these neurological tribes, if you like, who get their neurotransmitter floods from different things: people who are wired to sort stuff into categories, people who like videos of other people whispering at them, adrenaline junkies who get off on jumping from high objects, and so on, and having a vocabulary to understand and discuss these various neurotribes (and the spectrum on which each exists) would benefit and build empathy for us all.\nWhat if there were neurodivergent-optimised versions of all media?\nNot just ASMR Bee Movie but taciturn and slow-paced superhero movies, for people who are easily overwhelmed, like French New Wave meets the Marvel Cinematic Universe, or for completionists, speedrun Netflix Originals where each episode is only 3 minutes and expunges narrative irrelevant to the overall season arc, with everything fitting together neatly at the end.\nAn Apple Music radio station with all the tracks pitch-shifted down to barely-audible infrasound so you’re listening to your favourite pop but every so often it hits a tone that induces a feeling of ghosts or immediate and automatic religious ecstasy, as appropriate.\nI’m just making personal requests at this point.\n",
    link: "/home/2021/03/16/asmr",
  },
  {
    title: "Work: Availability from July",
    date: "10.28, Thursday 18 Mar 2021",
    content:
      "A rare commercial message:\nI’m on the look out for interesting things to do. Projects, yes, but I am also job curious.\nRight now, via my consultancy, I’m part of the editorial team on an internal publication with the Google AI folks, bridging their research and product orgs. (It’s the second issue. We did the first one last year. It’s awesome. I have checked I am allowed to say that line, but won’t go into more detail.)\nI’ve also been working with a VC, doing due diligence on their prospective new startups from a tech perspective. I dig in with each startup and report back with my views on the strength of the investment and how they’ll need support over the next year. (That’s another repeat gig. They get busy around February/March and call me up.)\nHere’s my about page and here’s my consultancy site. My work history is… well, I have no idea what the through-line is. I’ve been MD of a startup accelerator. I’ve built a bookshop in a vending machine that tweets. I co-founded and was CEO of a design consultancy. I co-authored a book about how the brain works.\nWhy I’m saying this now:\nI am very lucky in that interesting projects keep coming my way. I don’t take that for granted, hence this post. If you have thoughts, get in touch! I’m sticking with consulting for the time being.\nExcept… I would also like to explore getting my teeth into something a bit different, and a bit more longer term. I don’t know what that means.\nJuly is four months away, so that gives a bunch of time for conversations I guess? That’s the idea anyway.\nI am product-literate, design-literate, tech-literate, P&L-literate, management-literate etc, and have negotiated deals from both sides of the table, but never specialised. I can get my head around mind-bending frontier tech and invent opportunities. More “special projects” I guess? New product development? I’ve spent a lot of time with startups over the years. That’s why I’ve recently been thinking about labs.\nI’m in the mood to work with a team again.\nI’d like to focus on something that I already have a viewpoint on, and am already passionate about, when I walk in the door. Maybe it’s full time, maybe it’s not.\nI honestly have no idea whether that means diving into a role at a big corp, going further into ventures, setting up someone’s innovation process, writing a column for a magazine, becoming an embedded something-or-other, or what. Like, if you said: we’re making weird new pagers with AI in them and we need to invent what to do with them, I would totally work on that. Or room-sized TVs. Or zero data voice control. Or conversational UIs. Etc. But also if you said: we’re launching a new kind of ventures arm for the circular economy, or an internal startup studio focused on X, or a mid-stage startup in an area I know something about, there’s a conversation to be had there.\nI’d prefer to be product-side than client-facing I think, but open minded. I’d like to not think about sales for a while.\nI’m planning to stay in the UK.\n(Yes I was also job curious at this time in 2020, and some awesome conversations got a decent way down the track… but then, pandemic. So let’s try again because everything is more settled now. And just hope that June 2021 doesn’t bring us, I don’t know, UFOs or something.)\nGood ways to talk are email: matt@interconnected.org. Or you can book a call.\nThanks.\n",
    link: "/home/2021/03/18/work",
  },
  {
    title: "Social Attention: a modest prototype in shared presence",
    date: "16.43, Monday 22 Mar 2021",
    content:
      "Right now the web is either fully social, like when you’re collaborating in Google Docs, or it’s a solitary experience. There’s very little between. Yes you do sometimes get moments that are almost social, like when you read a product review on Amazon or a comment on a blog post, but it’s like walking into a room that somebody’s just left: there’s a note on the table, and the door on the far end is closing shut.\nMy take is that the web could feel warmer and more lively than it is. Visiting a webpage could feel a little more like visiting a park and watching the world go by. Visiting my homepage could feel just a tiny bit like stopping by my home.\nAnd so to celebrate my blogging streak reaching one year, this week, I’m adding a proof of concept to my blog, something I’m provisionally calling Social Attention.\nSocial Attention\nHere are some screenshots if you want to see how it works without jumping in right now. \n\nThere’s a toggle at the bottom of the footer labeled Enable secret experimental features – turn it on. (You’ll have to go the website if you’re reading by email or RSS.)\nA status emoji will appear in the top right corner of your browser. If it’s smiling, there are other people on the site right now too.\n\nThen: select some text, as if you’re going to copy it.\nYour selection will be shared automatically with all the other people on the same page as you. It will appear for them as highlighted words. It’s all anonymous. Your data isn’t stored.\nIf somebody else selects some text, it’ll be highlighted for you. But if you’re not on the same page at the same time, you’ll never see it. It only works in realtime.\nIf you want to experiment with this, use two completely different browsers, or have one window in private/incognito mode. The system has to believe that you’re different people otherwise the selection won’t be shared.\n(I don’t know how long I’ll keep this running for. It’s a prototype, and I haven’t given a huge amount of thought to scaling – and there are limits on the free tier of the service I’m using as the back-end for the notifications. So if it doesn’t work for you, check out the screenshots instead.)\nWhy build for togetherness\nHow often have you been on the phone with a friend, trying to describe how to get somewhere online? Okay go to Amazon. Okay type in “whatever”. Okay, it’s the third one down for me…\nThis is ridiculous!\nWhat if, instead, you both went to the website and then you could just say: follow me.\nYou know each other! You’re speaking on the phone together! Computers should be aware of this fact! Of course if you go to the same website, you should be able to see each other there.\nWe don’t need to be so sophisticated right now. There’s no need for my blog to be a fully private space, but there’s also no reason for it to be fully public. We can share just a hint of data, enough for a sense of liveness, but otherwise keep it anonymous.\nIf I’m in a meeting, I should be able to share a link in the chat to a particular post on my blog, then select the paragraph I’m talking about and have it highlighted for everyone. Well, now I can. \nAnd yes, I know that Medium and Amazon Kindle share text highlights, but that happens only once it has been highlighted – I want something that lets you see life on the other side of the screen. Especially because it becomes suddenly more useful when you’re coordinating with someone else in a different channel. And, yes, of course there are more fully transparent systems like live cursors or annotations… but this is a blog and not a chatroom. I want the patina of fingerprints, the quiet and comfortable background hum of a library.\nModern animal life appeared pretty much all at once, 541 million years ago, in an event called the Cambrian explosion. Why? There’s a theory that, at that time, the oceans cleared of dust. Suddenly it was possible to see, and complex tactics like hunting, camouflage, deduction, and so on triggered an arms race that led to the evolution of the animals that we have today.\nI think about that story a lot, because in the real world we rely on what we can see for so much tacit, realtime knowledge. If you’re in a meeting, you silently and unconsciously coordinate who is speaking next by constantly glancing. If you’re in an unfamiliar town, you know which restaurants are popular without going in… by looking.\nWhen the social web kicked off in the early 2000s, it felt to me like the oceans were clearing. And, yes, we did get a little of the “wisdom of the crowds.” Product reviews… blog posts… Wikipedia… Then later, the full-on collaborative experience of Google Docs or Figma.\nWhat I’d like more of is a social web that sits between these two extremes, something with a small town feel. So you can see people are around, and you can give directions and a friendly nod, but there’s no need to stop and chat, and it’s not in your face. It’s what I’ve talked about before as social peripheral vision (that post is about why it should be build into the OS).\nIt’s what video games have gotten so right. There’s the crowd, which is semi-anonymous, and there are your friends. You can scale visibility and interactivity as appropriate.\nThere’s no reason that Social Attention shouldn’t a one-liner to add to any website, or part of the browser itself. Maybe it should be part of a suite of social tools to make the web a well-lit, neighbourly place – with, naturally, good privacy-preserving fences.\n(If you can think of a way to support this kind of effort, do get in touch. I feel like the web has some missing infrastructure here.)\nI’m enjoying writing here, and I can’t believe I’ve kept up this current streak for a whole year. Thank you for reading.\nThis is my homepage. Welcome to my home.\n",
    link: "/home/2021/03/22/social_attention",
  },
  {
    title: "The Suez Canal and other global infrastructure exploits",
    date: "21.11, Thursday 25 Mar 2021",
    content:
      "There’s a large cargo vessel stuck in the Suez Canal right now, the 200,000 tonne Ever Given. It might be deliberate (although it’s probably not) and it’s definitely disruptive. It may take weeks to clear. From VesselFinder’s recent update: \n\nThere are 14 gas carriers (LNG and LPG tankers) stuck south from the Suez Canal behind the marooned Ever Given and another 7 carriers from the north, and there are already signs the blockage is beginning to disrupt global gas flows.\nAround 8% of the global supply of fuel passes through the vital waterway, and the only other option is a trip around Africa that would add 2 weeks more to the journey.\n\nI do wonder about these points of vulnerability in global infrastructure.\nWe’re now semi-accustomed to the idea that deliberate, state-sponsored disinfo has been disrupting politics in the UK and US since the early/mid 2010s, having targeted the engagement algorithms in social media to sow division.\nI don’t think the disinfo has had any other objective than disruption – and that’s enough. Disruption in one arena makes it hard for countries to act in others.\nSo when a new point of vulnerability is revealed - such as the Suez Canal - my thought process goes:\n\nCould this have been purposeful?\nIf so, what did it achieve? What was learnt? What could it be a trial for?\nIf not, assume that others will learn from it. So what else do we now know is vulnerable?\n\ne.g. the Panama Canal. e.g. any other supply chain bottleneck.\nThis idea of “disruption” is highlighted in this 2018 report from the RAND Corporation:\n\nThe Chinese People’s Liberation Army (PLA) now characterizes and understands modern warfare as a confrontation between opposing operational systems rather than merely opposing armies. Furthermore, the PLA’s very theory of victory in modern warfare recognizes system destruction warfare as the current method of modern war fighting. Under this theory, warfare is no longer centered on the annihilation of enemy forces on the battlefield. Rather, it is won by the belligerent that can disrupt, paralyze, or destroy the operational capability of the enemy’s operational system. This can be achieved through kinetic and nonkinetic strikes against key points and nodes while simultaneously employing a more robust, capable, and adaptable operational system of its own.\n– RAND Corporation, Systems Confrontation and System Destruction Warfare (2018)\n\nLong story short, I keep a note of vulnerabilities when I hear about them.\nHere’s an old one, from the San Francisco Chronicle in 1977: CIA Link to Cuban Pig Virus Reported.\n\nWith at least the tacit backing of U.S. Central Intelligence Agency officials, operatives linked to anti-Castro terrorists introduced African swine fever virus into Cuba in 1971.\n\nEspecially relevant given the Covid-19 lab leak hypothesis refuses to go away. Wherever Covid sits on the scale from deliberate to Act of God, it’s now possible to quantify the level of disruption. In the next major international treaty negotiation, watch out for one of the teams going down with flu all at once at a critical moment. It would be simple to plant influenza in a hotel, and now everyone’s seen how viruses work.\nAnother: The 2018 Athens wildfires that killed 86 people. There is serious evidence of arson for the Athens wildfires in East and West Attica, the Greek government said during a press conference. It’s grim to contemplate, but worst case scenario: What could this be a prototype for?\nWeather, generally, is a big one, as previously discussed. Climate change is in the interest of at least some countries – if you’re geographically less susceptible to flooding, for example. Or if your economy is already able to shift away from carbon quickly, you can distract everyone else for a couple of decades by ramping up the urgency faster. Climate change can also be regionally targeted: increased weather volatility would make it simpler to tip a food-producing region into drought for a few years using secret cloud seeding.\nThere was that Icelandic volcano in 2010 that knocked out European air travel for a little over a week. I bet there’s a cost-benefit study, somewhere, based on that event, that assesses the impact on Europe’s GDP versus the difficulty of an artificial ash cloud and the possibility of performing it with plausible deniability.\nTechnology is its own thing which I won’t even go into. But there was that weird period in 2019 where, in short order, there were major outages at Google/Google Cloud, Apple, Facebook, Cloudflare, Stripe, Slack, Twitter, and Galileo (the European GPS equivalent with satellite network and ground stations) was down for 4 days. It felt like a systems test, or the cyber equivalent of running “exercises.”\nSo I wonder how much of this is already happening. Or at least, how much already exists in the form of planning – perhaps we’re even now in the middle of World War V(irtual), lasting tens of years already, with project plans and not ICBMs being lobbed across the planet, nothing ever enacted but an intricate standoff of exchanged complex system exploit threats.\nI know this gets into proper tinfoil hat territory, and I honestly don’t know why I devote so many of my clock cycles to thinking about it.\n",
    link: "/home/2021/03/25/exploits",
  },
  {
    title:
      "Poker, blacksmithery, and other activities that teach a way to see the world",
    date: "18.57, Friday 26 Mar 2021",
    content:
      "I don’t really play poker but I enjoy reading about it. It provides some fascinating strategic perspectives.\nFrom this article about poker and artificial intelligence:\n\nThere’s a concept in game theory known as the trembling hand: There are branches of the game tree that, under an optimal strategy, one should theoretically never get to; but with some probability, your all-too-human opponent’s hand trembles, they take a wrong action, and you’re suddenly in a totally unmapped part of the game.\n\nStay in the game, even though you’re in a losing position, because something might turn up.\nIn particular your opponent is likely, at some point, to make an unforced error (that’s the tennis term). Some politicians seem particularly good at this. And it works! More effectively than I would have imagined.\nI wonder how players differentiate between when to stubbornly keep playing, and when to fold. With statistics I guess. The benefit of a game you can play many times.\nAnnie Duke is a former pro poker player, and here she is in conversation with Tyler Cowen,  economist:\nIt’s mainly about “thinking probabilistically” and there’s a fascinating section titled On how poker players would think about public policy.\n\nMy suspicion is that if only the top 500 poker players voted, people would be thinking a lot more about edge cases – where things could go wrong, for sure, because poker players just are obsessed with that. I think that there would be more long-termism as opposed to short-termism, again, because you have to be obsessed with that as a concept. I think that people would be thinking about “What are the unintended consequences? How does this look?”\nAnother thing that’s really important that poker players think about is, “If I put this policy in that looks like it’s awesome, how can someone come in and find the cracks in it so that it can turn into something bad?”\n– Conversations with Tyler, Annie Duke on Poker, Probabilities, and How We Make Decisions\n\nI mean, I don’t know whether these strategies work in life generally: play the game many times; protect your downside; keep going longer than anyone else. But interesting to think about what is transferable and what isn’t.\nWhen I talked about bonsai recently, I suggested that I kinda want every child to be given one of these at the beginning of school – and it was this reason, because of what it teaches you.\nMy friend George Walkley got in touch to make the connection to CEOs. He said, There’s a strand of management research on how hobbies of CEOs correlate with org performance-classic examples are flying, skydiving which are about high skill, calculated risks. – and pointed me at a paper on that topic:\n\nThis study analyzes the relation between chief executive officer (CEO) personal risk-taking, corporate risk-taking, and total firm risk. We find evidence that CEOs who possess private pilot licenses (our proxy for personal risk-taking) are associated with riskier firms. Firms led by pilot CEOs have higher equity return volatility …\n– Journal of Financial and Quantitative Analysis, CEO Personal Risk-Taking and Corporate Policies\n\nAmazing! Could you making money knowing that a portfolio of companies was exclusively run by pilots?\nThen George suggested cultivating long-term thinking for CEOs deliberately. It would be highly desirable in context of long term challenges like decarbonizing. Give a bonsai to every first year Harvard Business School student…\nI think it’s a really good question:\nWhat hobbies could I take up to build up my muscles around abstract thinking, or team dynamics, or risk tolerance, etc? If you wanted to educate excellent startup founders, or to foster wonderful families and friends, what games in particular would you have them play at school?\nI’m obsessed with how roles in society and individual people find each other, and how personalities match what we do. But I think we often think about it as culture – like “yuppies” in the 80s that had a particular culture in finance, or sometimes we think about the personality type as a requirement to do the job. Like surgeons have to have a certain kind of attitude because it is very, very weird on a deep human level to cut into people.\nBut maybe all that’s required from the personality is a predisposition, and it’s the actual practice, the ten thousand hours spent interacting with money, or with scalpels, or with computer code that develops a particular temperament.\nSo it fascinates me how you learn almost by osmosis from the non-humans you spend time with, and I use that to cover living non-humans (yeasts, sheep) but also material, like iron, and like spreadsheets. And I’m curious about how the two - humans and the other - form a “culture” of accepted norms.\nLike, the colloidal culture of the blacksmith and the iron makes for a taciturn world where words are rare, but deftly spoken and with gruff precision.\nBecause if you spend your days swinging a hammer at hot metal, and every strike is effortful and has to count, then how would you not take that understanding of the world into your personal relationships and politics even once you’ve finished for the day?\nHas anyone looked at this?\nHow humans and non-living material become peers in culture formation, neither preceding the other?\nI know a founder who is a free climber, and once I discovered that I was like – oh ok, now it all makes sense.\nHe also plays chess. Which also makes sense.\nASIDE:\nKirsan Ilyumzhinov was president of FIDE (chess’ main international governing body) from 1995 to 2018.\nHe is on record as believing that chess was brought to us by extraterrestrials: I do, indeed, consider chess a gift from extraterrestrial civilizations. (From an interview in the New York Times.)\nAlso: He has claimed on many occasions that in 1997 he was taken by aliens to a spaceship, where he chatted with them before returning to Earth.\nThere are many smart people who believe in extraterrestrials.\nAlso: He then explains why he believes sweetcorn was brought to Earth by a different civilization.\nSource.\nSweetcorn!\n",
    link: "/home/2021/03/26/poker",
  },
  {
    title: "Baking life lessons and musings on metabolism",
    date: "17.37, Tuesday 30 Mar 2021",
    content:
      "Bread is bread. But it also gives me a chance to reflect on how to approach learning.\nI’m pretty pleased with how my baking has progressed since the beginning of the pandemic. (For reference: May 2020 vs March 2021.)\nI’ve made a bunch of tweaks since I started. To catalogue them…\nDependability. These are all about having the same result for the same effort.\n\nElectronic scales, same flour, same recipe.\nDiastatic malt powder. I started adding 1.5 tsp of this when it got cold back in November and what it does is cut up the long starches into short sugars that the yeasts can digest. So that speeds thing along, regardless of the variability of the sourdough starter.\nProve in a closed cupboard. The recipe I use has 3 x 1 hour resting/proving periods. Before, the activity of the yeast was dependent on the weather. Now I cover the bowl with a towel and place it in the steamer oven, along with a mug of boiling water, and shut the door. Now the environment - and the behaviour of the yeast - is the same each time. (Thanks Denise for the tip.)\nFinal prove is for 36 hours in the fridge, no shorter, no longer.\n\nBecause the dough is now the same every single time, insulated from variables such as room temperature and yeast happiness, it’s possible to think about tweaking the process.\nFine tuning. It wouldn’t be possible to tweak except that the variability of the dough has been reduced.\n\nWater content: I’ve increased this from 280g to 290g.\nOven time: The thermostat is set a touch lower, and I’ve reduced baking time by 2 minutes.\n\nI include these figures because it’s insane that they should make a noticeable difference, given the “noise” inherent in home cooking. And yet they do!\nTips. I now include two extra steps in baking.\n\nSteam. Adding steam to the oven allows the bread to rise more (the crust doesn’t harden so quickly). I do this by throwing 3/4 of a mug of boiling water into a tray on the bottom, just before closing the door.\nDusting the tray. I dust the baking tray with course semolina flour before the loaf goes on. It prevents sticking and adds a little taste.\n\nTechnique. These have been gradual improvements.\n\nScoring – my scoring with the lame (blade) is pretty good now. One smooth score from end to end, shallow angle, not too deep. It helps the bread rise neatly, and not burst out at the sides.\nShaping – I shape the dough into a ball at every knead, pulling it into shape, flipping it, and using tension on the kitchen surface to tighten the surface. This makes for a smooth, shiny crust.\n\nWhat I find fascinating is that I never intended to improve my technique in these areas. It just… happened. I could not do them at all only 10 months ago.\nI remember learning to drive when I was 17 and something similar happened. I would sit there, chatting to my instructor (hi Colin), and meanwhile my body would drive the car. Over time, my body’s ability to drive improved – but I’m not sure I consciously did anything. I was just along for the ride (sorry).\nSo there’s something about “embodied learning” that I find mysterious and simultaneously exciting: So long as I repeatedly perform something, my body will get better at it, if it can.\nThere are three general life lessons I take from baking.\n\nEmbodied learning is surprisingly effective. Just do the thing, and repeat. I don’t need to pay conscious attention; no amount of frustration or effort is going to help or make this go any faster. So that gives me a pathway to all kinds of new skills.\nDependability for a process is worth investing in, because it allows for fine tuning and the development of technique. I need to get the same result for the same input, every time.\nMetabolism is awesome. Here’s the best description of metabolism I’ve ever read (it’s short) and what the diastatic malt powder is doing (or rather, the amylase enzyme it contains) is catalysing a reaction that drives activity along one particular catabolic pathway. Being able to do this feels like reaching into the machine. Amylase is a POKE instruction for the yeast computer.\n\nYou would think that the metabolism lesson wouldn’t be generally applicable in life. Except that I was looking up an asthma medication the other day, and it acts to produce such-and-such a protein, which is does by mucking around with such-and-such metabolic reaction, by producing such-and-such precursor – and when you look it up, it turns out that St. John’s wort performs the exact same function.\nSo now I am (a) enlightened re: traditional medicines, and (b) intrigued re: the possibilities of personalised medicine.\nWhat I’d like to see is the entire, standard metabolic map for humans, every reaction and pathway traced, like a circuit diagram. Not earth’s whole ecosystem (which I do have a poster of) but humans only, isolated. Think of this like the molecular biochemistry equivalent of the Human Genome Project, or the Human Connectome Project for the brain.\nAnd then, for an individual human, a way to measure the performance of the personal circuitry.\nTo perform the measurements: Perhaps precursor compounds could be ingested or injected, then metabolised and surveyed, in a series of diagnostic experiments lasting a week or so. You would end up with a calibrated schematic, and you could use it for debugging personal health.\nSo you could say things like: oh, this person is predisposed to asthma because such-and-such enzyme is underrepresented in these particular cellular factories, perhaps there’s a genetic factor but we don’t care, and that’s because there’s something upstream on the pathway which is over-synthesising some other compound entirely, not leaving enough building block molecules, so you need a take a pill with these exact vitamins every morning to suppress X and boost Y.\n",
    link: "/home/2021/03/30/baking",
  },
  {
    title: "Clues for software design in how we sketch maps of cities",
    date: "21.10, Wednesday 31 Mar 2021",
    content:
      "There’s a remarkably simple notation for sketching cities, and I think it points at a better way to design software.\nA notation for describing a city\nKevin Lynch was an urban planner who carried out pioneering work on people’s urban cognitive maps from the 1950s.\nAnd:\n\nAs a planner, Lynch was interested in analysing the urban form, and in particular identified the criterion of the ‘legibility’ of a cityscape which he defined as ” the ease with which its parts can be recognized and can be organized into a coherent pattern”\n… His method involved externalising the ‘mental images’ that city-dwellers have of their cities, through interviews and sketch-mapping exercises.\n\n(From these lecture notes on the work of Kevin Lynch.)\nThis shared “mental images” is the subject of Lynch’s book The Image of City (1960) (and it blew my mind when I read it in - checks notes - 2003).\nHere’s an example of one of Lynch’s maps: Boston.\nWhat you’ll see from that map is that it’s totally recognisable as a city, and you could totally use it to navigate, but it’s also what you would scribble on the back of a napkin. It’s also way more memorable. If you gave me a glimpse of Boston from Google Maps and asked me to sketch it for someone else, I can’t imagine it would include any of the salient details. But given a Lynch map, I bet I could pass on the most relevant bare bones, just from memory.\nSo Lynch has managed to capture what is essential about maps for (a) understanding, and (b) communication.\nLynch’s insight is that these scribbled maps use a notation of only five elements. From those earlier lecture notes, there are:\n\nPaths: They may be streets, walkways, transit lines, canals, railroads.\nEdges: They are the boundaries … shores, railroad cuts, edges of development, walls.\nDistricts: Districts are the medium-to-large sections of the city … which the observer mentally enters “inside of”.\nNodes: They may be primarily junctions, places of a break in transportation, a crossing or convergence of paths … [or] a street-corner or an enclosed square.\nLandmarks: They are usually a rather simply defined physical object: building, sign, store, or mountain. Their use involves the singling out of one element from a host of possibilities.\n\nOut of these five elements, you can build an “image” (in Lynch’s terminology) of the city.\nDo Lynch’s elements have a neurological underpinning?\nLandmarks grab my attention, for this reason: they come up in Mind Hacks, in a chapter about memory and the hippocampus.\n\nWe know that the human brain has specialized mechanisms dedicated to remembering landmarks, and that (interestingly) this region and those nearby seem to be responsible for giving humans and other animals a sense of where they are in space. Brain images of people navigating through virtual environments has shown that even if we don’t consciously recognize something as a landmark it still triggers a response in this specialized part of the brain.\n– Mind Hacks, Hack #89: Navigate Your Way Through Memory (p304)\n\n(Quick plug: Mind Hacks is now available in Chinese! Check out the 11 second product video with perky music on that page. That brings us up to 7 translated editions, which feels pretty special.)\nSo what I find intriguing is that we, us humans, appear to have a “landmark sense” that we all share.\nWhich is why, I guess, you can follow directions to go down the street and turn left at the fountain, and if you pass a cathedral then you know you’ve gone the wrong way – because such a landmark would certainly have been mentioned.\nThe question is this:\nDo Lynch’s other elements also have neurological underpinnings?\nAnd a follow up: If so, how could that be useful?\nYour memory resets when you walk through a door\nThe reason I ask is because of the Doorway Effect, which is something that happens also in physical space and not outdoors but indoors: Memory was worse after passing through a doorway than after walking the same distance within a single room.\n\n… some forms of memory seem to be optimized to keep information ready-to-hand until its shelf life expires, and then purge that information in favor of new stuff.  Radvansky and colleagues call this sort of memory representation an “event model,” and propose that walking through a doorway is a good time to purge your event models because whatever happened in the old room is likely to become less relevant now that you have changed venues.\n– Scientific American, Why Walking through a Doorway Makes You Forget\n\nWhat’s especially intriguing about this study…\nThe Doorway Effect appears for real doorways. But ALSO: It doesn’t seem to matter, for instance, whether the virtual environments are displayed on a 66” flat screen or a 17” CRT.\nSo, to review the precarious stack of speculation that I’m on:\n\nthere are shared neurological underpinnings for how we understand space, and - in theory - an abstract system of space “elements”\nin at least one situation, there is a correlation between how we move through space and how we mentally organise information\n“moving through space” doesn’t need to be physical, but can be triggered by abstract representations.\n\nWhich provokes two thoughts:\n\nIf landmarks and doorways, then what is the full set of elements, and are there automatic memory operations for all of them?\nHow abstract can these spatial representations be, and can we use them in software?\n\nWhat should Wikipedia or Notion do?\nGiven there’s an explosion in software to accrete and organise knowledge, is the page model really the best approach?\nPerhaps the building blocks shouldn’t be pages or blocks, but\n\nneighbourhoods\nroads\nrooms and doors\nlandmarks.\n\nOr rather, as a knowledge base or wiki develops, it should - just like a real city - encourage its users to gravitate towards these different fundamental elements. A page that starts to function a little bit like a road should transform into a slick navigation element, available on all its linked pages. A page which is functioning like a landmark should start being visible from two hops away.\nIt would be interesting to investigate exactly what the minimal level of physical appearance is required to trigger the automatic behaviour of loading/resetting human memory and associations.\nLike, following a hyperlink might not activate the neurological automation.\nBut what if there was a zooming out animation, or a change in colour, or the old page slid off to the side?\nWhat’s the minimum you need to trick your brain into believing that you’re moving around an environment?\nAnd could design features as simple as these make tools like Notion, Roam, Obsidian, Evernote and other note taking software, Wikipedia, etc, radically better for organising, navigating, sharing, and internalising knowledge, for individuals and for teams? If so, can you imagine the efficiency gains and the new ideas that could emerge?\nHippocampus ergonomics.\nIt would be worth a research lab and a year or two, I think.\nOne final and quite literal idea: Could Lynch-style maps be generated automatically, and could this be an interface to Google Maps?\nThis paper believes this is possible: A computational approach to ‘The Image of the City’.\nAlthough: Out of the five elements, landmarks were found most challenging to extract.\nMy guess is that landmarks can’t be extracted from maps because they’re reliant on the visual field, approaches, other nearby potential landmarks, and so on. You would need to train an artificial landmark sensor in a machine hippocampus, perhaps giving it access to Street View and getting feedback data from humans on the spot asked to point at their nearest landmark.\nComputationally producing Lynch maps would also allow for the reverse process, which is to give a robot car directions in the same way you would a person: down the street, left at the big building, follow it till the end and we’re the second on the left.\n",
    link: "/home/2021/03/31/maps",
  },
  {
    title: "On the possibility of a dolphin pope",
    date: "14.59, Tuesday 6 Apr 2021",
    content:
      "I was looking through this gallery of popemobiles and it occurred to me that, with the transparent, upright, contained tank, this form is ideally shaped to transport a future aquatic pope. Let’s say, a dolphin.\nWhat are the obstacles to cetacean papacy?\nThe pope is the bishop of Rome and, in Catholicism, only men may be bishops. (Though Mary, of course, is fundamental to the church). There’s a quote from Pope Francis on the Wikipedia page about the ordination of women which I love simply for the language:\n\nIn Catholic ecclesiology there are two dimensions to think about… The Petrine dimension, which is from the Apostle Peter, and the Apostolic College, which is the pastoral activity of the bishops, as well as the Marian dimension, which is the feminine dimension of the Church.\n\nSo female dolphins are probably excluded from elevation.\nBeing non-human may prove another hurdle. Dolphins are animals, so their capacity will be questioned. But if we take a hypothetical extraterrestrial of human-equivalent sentience, even they may not be admitted to the church:\n\nIf aliens exist, they may be a different life form that does not need Christ’s redemption, the Vatican’s chief astronomer said. …\n“God became man in Jesus in order to save us. So if there are also other intelligent beings, it’s not a given that they need redemption. They might have remained in full friendship with their creator,” he said.\n– Catholic News Service, Vatican astronomer says if aliens exist, they may not need redemption (2008)\n\nSo let’s say we were to limit ourselves to male dolphins, even if we then determined that dolphins were capable of reciting scripture (or whatever our definition of sentience is), they may be still disqualified for not being in need of redemption.\nSome other faiths allow for a greater divergence between leaders and followers. In Sikhism, after a lineage of 10 humans, the title of Guru was passed to the community itself (as previously discussed).\nAnd more generally, away from the idea of leadership and thinking about the operations of worship, there are already some robots that perform religious rituals (in Vox):\n\nIn hospice settings, elderly Buddhists who don’t have people on hand to recite prayers on their behalf will use devices known as nianfo ji – small machines about the size of an iPhone, which recite the name of the Buddha endlessly.\n\nAnd:\n\nIn 2017, Indians rolled out a robot that performs the Hindu aarti ritual, which involves moving a light round and round in front of a deity.\n\nAnd:\n\nFor years now, people who can’t afford to pay a human priest to perform a funeral have had the option to pay a robot named Pepper to do it at a much cheaper rate.\n\nAlso, from that same Vox article, a comment from Ilya Delio, a Franciscan sister who holds two PhDs and a chair in theology at Villanova University:\n\n“The Catholic notion would say the priest is ontologically changed upon ordination. Is that really true?” she asked. Maybe priestliness is not an esoteric essence but a programmable trait that even a “fallen” creation like a robot can embody. “We have these fixed philosophical ideas and AI challenges those ideas – it challenges Catholicism to move toward a post-human priesthood.” (For now, she joked, a robot would probably do better as a Protestant.)\n\nDelio is probably joking about BlessU-2, an automated blessing robot from the Protestant Church in Hesse and Nassau.\nDelio continues: We tend to think in an either/or framework: It’s either us or the robots. But this is about partnership, not replacement. It can be a symbiotic relationship – if we approach it that way.\nHuman/robot symbiosis. This is Garry Kasparov’s concept of centaurs, originally from chess: Rather than half-horse, half-human, a centaur chess player is one who plays the game by marrying human intuition, creativity and empathy with a computer’s brute-force ability to remember and calculate a staggering number of chess moves, countermoves and outcomes.\nSo maybe the future is not dolphin popes but centaur popes: A singular human pope in the Vatican, with a hundred or a thousand machine popes travelling the world, issuing blessings and on-the-ground decrees wherever required.\nAnd then if one day the human pope were to recede into the background, maybe never seen again, but a century later in 2121 the role of pope was still functionally maintained by the papal swarm, actually way more efficiently now, visiting cities, ordaining bishops, ostensibly semi-autonomous like so many Martian rovers, perhaps there’s a frail hand behind the curtain or perhaps not, it’s best not to ask too closely, would we even notice the change? Would we even mind?\n",
    link: "/home/2021/04/06/pope",
  },
  {
    title: "Let’s make robot a dirty word",
    date: "16.44, Wednesday 7 Apr 2021",
    content:
      "Deliveroo drivers are striking this week (The Guardian) over their pay, rights and safety practices. (Deliveroo is the UK equivalent of Doordash.)\nAfter a 4.5 year legal fight, ending in the UK Supreme Court, Uber Says Its UK Drivers Are ‘Workers,’ but Not Employees (Wired). This means drivers get minimum wage guarantees after expenses, paid holidays, and pension contributions but not sick pay or protection against unfair dismissal.\nDeliveroo drivers and Uber drivers are performing “Below the API” jobs. Uber’s software layer (the API) dispatches a human to do a job, and…\n\nWhat does that make the drivers? Cogs in a giant automated dispatching machine, controlled through clever programming optimizations like surge pricing?\n\nAnd: it’s not a secret that Uber intends to eventually replace all their drivers with self-driving cars.\nHere’s Norbert Wiener in 1948, in his seminal book Cybernetics: Or Control and Communication in the Animal and the Machine (the first public use of the term). He’s talking about computers, or as he says the modern ultra-rapid computing machine.\n\nIt gives the human race a new and most effective collection of mechanical slaves to perform its labor. Such mechanical labor has most of the economic properties of slave labor, although, unlike slave labor, it does not involve the direct demoralizing effects of human cruelty. However, any labor that accepts the conditions of competition with slave labor accepts the conditions of slave labor, and is essentially slave labor.\n\nI’m actually not comfortable with the use of “slavery” as a metaphor here. The lived reality of slavery is abhorrent in its own way, and I feel like it’s minimised somehow to deploy the word like this. Life under capitalism, below the API, can be criticised on its own terms.\nHOWEVER: it strikes me as significant, somehow, that right at the dawn of computing, it was possible to predict the situation that Uber drivers find themselves in today, 73 years into the future.\nAs it happens, Wiener didn’t believe that knowledge work was immune.\n\nThere is no rate of pay at which a United States pick-and-shovel laborer can live which is low enough to compete with the work of a steam shovel as an excavator. The modern industrial revolution is similarly bound to devalue the human brain, at least in its simpler and more routine decisions.\n\nSo we have that to look forward to.\nFurther back!\n101 years ago, the word robot (in its current sense) was coined:\n\nThe modern meaning of the word ‘robot’ has its origins in a 1920 play by the remarkable and fascinating Czech writer Karel Čapek. The play, titled R. U. R. (Rossum’s Universal Robots), begins in a factory which manufactures artificial people, the ‘universal robots’ of the play’s title. The robots are designed to serve humans and work for them, but the robots eventually turn on their masters, wiping out the human race.\n– Interesting Literature, The Curious Origin of the Word ‘Robot’\n\nBut robot wasn’t a new word. It first appears in English in 1839 referring to central European system of serfdom, by which a tenant’s rent was paid in forced labour or service.\nIt comes from the Czech robota meaning “forced labour” or “slavery.”\nHere’s a segment from Rossum’s Universal Robots:\n\nDR. GALL: Yes, the Robots feel practically no bodily pain. You see, young Rossum provided them with too limited a nervous system. We must introduce suffering.\nHELENA: Why do you want to cause them pain?\nDR. GALL: For industrial reasons, Miss Glory. Sometimes a Robot does damage to himself because it doesn’t hurt him. He puts his hand into the machine, breaks his finger, smashes his head, it’s all the same to him. We must provide them with pain. That’s an automatic protection against damage.\nHELENA: Will they be happier when they feel pain?\nDR. GALL: On the contrary; but they will be more perfect from a technical point of view.\nHELENA: Why don’t you create a soul for them?\nDR. GALL: That’s not in our power.\nFABRY: That’s not in our interest.\nBUSMAN: That would increase the cost of production.\n\nIt don’t know what it means for our current pitfalls to be anticipated so long ago.\nBut I do feel that we need a word in the public discourse to critique what the Ubers and Deliveroos are doing with their “Below the API” workers. Something that can be said by newsreaders and unpacked by columnists. Because it’s not really well understood right now. It’s one thing to say that Uber hasn’t, historically, paid minimum wage, but the easy counter to that is that the drivers get a kind of flexibility and freedom that regular employees at other companies do not. It’s another thing entirely to say that reason that the drivers are paid below minimum wage is that they are being put into artificially amplified competition with one another and with future automation. It was inevitable. So it’s that system that needs to be unpicked, not the outcome.\nPerhaps “robot” will do, as a word to use in the debate, given its history. Robots are people who are denied souls, for business reasons.\nSo here’s my proposal. Let’s make robot a dirty word.\ni.e.: “What is Uber doing? They’re treating their drivers like robots.” Etc.\n",
    link: "/home/2021/04/07/robots",
  },
  {
    title: "Is collective efficacy a human need?",
    date: "19.56, Thursday 8 Apr 2021",
    content:
      "Do we have a deep-seated need to feel part of a empowered group?\nI ran across this concept in an profile of Greta Thunberg in the FT.\n\nSabherwal’s paper found that people who had heard of Thunberg were likely to feel a stronger sense of “collective efficacy”, the belief that they could make a difference by acting together.\n– FT Magazine, Greta Thunberg: ‘It just spiralled out of control’\n\nThat’s an interesting feeling to stick a pin in: the sense that you are part of a group with strength.\nHaving named the feeling, I think we can ask and immediately answer two follow-up questions:\n\nDoes it feel good to feel strong collective efficacy? Yes it does.\nDo people want to feel good? Yes they do.\n\nWhich implies! Amongst all the groups a person encounters, they will move up the gradient towards stronger collective efficacy. i.e. if there are two groups, A and B, which are otherwise entirely equal but group B has a lever to choose the colour of the bike shed, people will move to group B.\nOr if people feel alienated in society, the “containing” group, but some political group, or radical organisation, or whatever, promises the ability to change how things work then, by osmosis, those groups will grow in popularity.\nWay too simplistic conclusion: the answer to radicalisation is to increase the collective efficacy of society - to increase people’s ability to be part of meaningful change - reducing the osmotic pressure that drives people into fringe groups.\nIt seems obvious written down like this, but I hadn’t thought of it from quite that angle before.\nPractically, if we assume that “collective efficacy tropism” is a thing that humans have, we can ask questions about limits: How small can collective efficacy be, and still modify behaviour?\nLike, do the follow qualify as teeny-weeny collective efficacy ocean floor thermal vents:\n\nPosting a book review on Amazon – does the simple existence of the text box create a feeling of “oh I could leave a mark here” and therefore an almost indiscernible nano tribalism to the “Amazon” group?\nSharing highlights on a website, cf my shared social attention experiment the other week – does this femto-togetherness create any kind of measurable gravity?\n\nClearly at a larger scale, it’s incredibly powerful to feel part of something. Remember reddit’s amazing Place project of 2017.\nBut if it’s really an honest-to-goodness human need, even if imperceptible in many cases, what strategies are there to design for collective efficacy, from micro to macro?\nAnd if a software product is designed without any such possibility (I pick on software because with physical spaces you get it for free) then will it always feel, in some nameless way, hollow?\n",
    link: "/home/2021/04/08/efficacy",
  },
  {
    title: "A short dream about the unnoticed end of the world",
    date: "17.31, Friday 9 Apr 2021",
    content:
      "I had a dream last night that I was talking to one of my old physics tutors, and he was researching the end of the universe. (This isn’t accurate. He researches Martian weather.)\nThe universe, he said, runs from the beginning, then gets up to a certain point, and then it ends all at once. At which point it repeats, exactly the same as before, starting from the Big Bang, but it continues a little further each time around.\nIn fact (this is what he told me, in the dream) while we had been speaking, in the very middle of our conversation, the entire universe had come to a complete end. Then it had restarted, and many many billion years had passed while stars formed again, the Earth cooled again, life began again, humans evolved again, history happened again, we were born again, we grew up and had our lives again, our conversation went along again, until, eventually, we arrived at the point at which we had to leave off before, and this time the universe didn’t stop. It rolled on and now here we are. This time round the universe will continue just a little longer, until it ends again and the whole thing repeats.\nWe stood up and walked outside.\nDid you notice it happening? he said. No, I said.\nYet that’s what happened. 14 billion years between breaths. The old you died. You’re a completely different person to the one you were when we started talking. Separate lives. You feel like you’re the same but you’re not.\nOne question to ask about dreams is: how did you feel? The feeling is what is real; the dream imagery is assembled out of whatever material is at hand in order to specify that feeling with pinpoint precision.\n",
    link: "/home/2021/04/09/dream",
  },
  {
    title: "Two product ideas for hybrid working",
    date: "17.17, Monday 12 Apr 2021",
    content:
      "Hybrid working is the idea we won’t go back to working in an office after the pandemic, not entirely, but nor we will go fully remote. Instead we’ll mix it up.\nAugmented ambience\nThere’s something neat about having desk neighbours – it allows for teams but also cross-team connections. But if you’re at home 2 days/week, working out of cafes 1 day/week, and hot-desking at the office the rest of the time, how can that work?\nImagine your desk has a fixed position but in a virtual office layout.\nNow let’s imagine that on the physical office desks, and on your home office desk, you have an array of small speakers around the perimeter of the desk. The speakers also have microphones. This is the product.\nWhen you sit down to work, you sign in, and you hear directionally accurate sound from your virtual neighbours, as if you’re in adjacent cubicles – keyboard tapping, chair scraping, coughs, and so on. Sound from your workstation is also picked up and transmitted.\nVoices would be detected by AI and automatically muffled.\nBonus points: if you’ve got spatial audio-enabled headphones, like the Apple AirPods Max, you don’t need the special speakers. You can hear your virtual neighbours even when you’re working remotely from, say, a plane. Assuming any of us ever fly anywhere ever again.\nDrone zoom calls\nThis is a use-case for augmented reality smart glasses. \nThe idea is that you should be able to take Zoom calls when you’re out and about because, to me, hybrid working is also about incorporating walking.\nI’ve seen people I know on Instagram skiing with follow-me drones. It turns out follow-me functionality is pretty great now: the drone maintains a consistent angle, dodges around trees, and so on. And that’s while the target is skiing!\nSo a follow-me drone made for Zoom calls should be way simpler. You would only be going at walking pace.\nYou still need to see the other person while you’re on the call, and that’s where the augmented reality smart glasses come in. They see you via a streaming cam on the drone; you see them via a hovering virtual screen projected in your glasses. (The glasses also have a built-in mic.)\nSee also previous thoughts about new office furniture, which referenced scorpion chairs and cyberpunk aprons.\n",
    link: "/home/2021/04/12/hybrid",
  },
  {
    title: "A list of seven different jobs, all called designer",
    date: "18.19, Tuesday 13 Apr 2021",
    content:
      "Back in 2009, I wrote down all the different ways I heard “designer” used as a job title. There were seven types.\nI just went digging through my notes, having half remembered it this afternoon. Here’s the list.\n\nWhere the designer specialises in a particular material or object, and design is matter of creativity and taste: graphic design, book design, furniture design, interior design.\nWhere the designer exists as a job role between, say, architects and engineers, doing technical drawing and mechanically finding the space between rules.\nWhere the material is metaphorical and the approach and methods are designerly: service design, interaction design, experience design.\nIn strategy/consultancy, where “design thinking” is a way of approaching problems in product, marketing, brand, organisational change, etc with a method that combines intuition and rationalism.\nIn design operations/management, giving direction and explaining but not working on the material.\nDesigners who create “design objects” which are closer to art than problem solving.\nA transitory role; a name for any person who performs any act of design, no matter how briefly or in what context. Design is the conscious and intuitive effort to impose meaningful order – Victor Papanek.\n\nIn my notes I’ve also got a reference to the “big-D Designer,” the person who is the holder of the vision, and often uses all the other types (and other job roles besides) to bring that vision about. I think the big-D Designer can fit into any of the above roles; it’s dependent on the person and the context.\nThe purpose of this list was to understand confusion. If you told someone else you were a designer, what else could they believe that you meant?\nThis isn’t meant to be a typology with hard edges. It was a list made from observation.\nSince I made the list in 2009, twelve years ago:\n\nDesign started being taken seriously by business, outside the creative industries. I’ll credit IDEO for legitimising design thinking, as an approach to strategy, and Apple’s success for for cementing design’s commercial importance.\nSoftware ate the world, and the “product” role emerged from technology firms. My take is that you can trace a path from design, to (software) product/interaction design, to a widened conception of the domain of design which became called “product”, and finally to the mini-CEO role which is the modern product manager. Engineering was another tributary to this unique role, but I feel like there’s a good strong “designer” part of the lineage.\n\nSo I don’t know what these trends have done to my list. There are a lot of roles that I would say are design-adjacent, that once could have functionally been performed by a designer, but they have many paths in and are increasingly their own distinct roles. I’m thinking of roles like product marketing, and interface copy.\nDoes the list still hold up in 2021?\nAre there any new ways that designer is used in job titles?\nI’ll also make a distinction between designer-as-job-title and designer-as-vocation.\nDesigners who have been to design college have become part of the culture of design. They have visceral understanding of method (the brief, the material, the crit), and training (which gives not just technique but a particular perspective), but also a connection to design as a historical conversation, which combined means that the designer can go on and be an author or a racing car driver, but they will always be a designer.\nWhereas I have (back in the day) co-founded a design studio, but haven’t been to design school, so while I could inhabit a “designer” job role, in the same way I could inhabit other job roles, I would never be a designer in the vocational sense.\nI think.\nThis archeology of my notes prompted by reading Org Design for Design Orgs (2016) by Peter Merholz and Kristin Skinner, which I’m reading as a chaser to Inspired: How to Create Tech Products Customers Love (2018) by Marty Cagen.\nInspired is a fantastic handbook to the product role in tech companies from startups to behemoths like Google. (Thanks Sippey for the recommendation.) It’s basically a giant outline of the product role, hugely practical, with minimal extraneous words, from a place of deep experience – high signal/noise ratio. My favourite kind of business book.\nI’m reading around the topic of design leadership, in its broadest sense, in tech companies, so any recommendations of companion reads to Org Design for Design Orgs (which I’m greatly enjoying) will be gratefully received.\n",
    link: "/home/2021/04/13/designer",
  },
  {
    title:
      "Salads, shipping containers, and subtle signs of a supply chain reset",
    date: "18.14, Friday 16 Apr 2021",
    content:
      "I’m into the idea of Unilever’s shipping container nano-factories:\n\nInside a 40-foot shipping container parked in the Dutch town of Wageningen, the global base for Unilever’s food and refreshment business, there will soon be a fully functioning production line for the consumer goods company’s liquid bouillon. By making the product in a shrunken-down space, the company hopes to reduce its carbon footprint, produce less waste, and eventually be able to ship these nano-factories to new spots around the world so they can take advantage of local ingredients.\n– Fast Company, Unilever’s new nano-factories fit in a shipping container\n\nAnd I wonder how the supply/demand/carbon footprint maths works: does it make sense, when summer starts, to airdrop shipping container ice cream factories directly into hot zones? Local milk and a materials hopper at one end, solar panels on the roof, and tasty frozen snacks out at the other…\nThen, when the temperature drops, move the factories elsewhere.\nPerhaps you could hang nano-factories on slow-moving blimps, situated at the Lagrange points between suppliers and customers, and drift them around as the market changes throughout the year.\nALSO SPOTTED:\nEurope’s Biggest Vertical Farm Will Be Powered by Wind and Planted by Robots (Singularity Hub): The new facility is in Denmark, in an area called Taastrup outside of Copenhagen. At 7,000 square meters (just over 73,000 square feet), it will be the biggest vertical farm in Europe. Crops will grow in stacks 14 layers high and will use more than 20,000 LED lights.\nIt’s for growing salad. Output will reach 1,000 ton/yr by end 2021.\nIt’s complex: 5,000 different data points are consulted to optimise growth. Which means…\n\nIt’s efficient: greens will reportedly be grown using just one liter of water per kilogram of produce, which is a whopping 250 times less than what’s used in traditional agriculture.\nThe greens are green: And all that light from the LEDs? It’ll come from electricity generated by wind.\n\nFruit and vegetables are notorious for being shipped in from thousands of miles away. This means they can be grown locally.\nGet this: only 20 of these facilities would allow Denmark to become ‘self-sufficient in salads and herbs.’\nAlso I love the idea of a multi-storey cube, encrusted with wind turbines, on the outskirts of every major town, a semi-autonomous Salad Assembly Building sipping water and emitting a continuous stream of cool, fresh greens.\nI’m watching this space because last year I asked: Perhaps China’s centralised supply chain won’t last forever (April 2020).\nMy key example at the time was the micro-factory approach of EV truck manufacturer Arrival, more about which in this article: \n\nArrival says it has kept a lid on costs thanks to its ‘micro-factory’ production plan. Essentially, it plans to set up a network of small factories globally optimised to produce around 10,000 vans a year each, or 2000 buses. …\nThis gives Arrival adaptability in a way that huge plants with a single line can’t, he said. The polypropylene body panels are moulded in the required colours on site, removing the need for expensive paint shops or stamping machines. ‘Cells’ in the plant assemble different elements that plug into the skateboard chassis.\n\nThe factories will be closer to end customers and, because they don’t demand a huge number of workers, can be placed near smaller cities.\nMy point in that piece was that the calculus of supply chains might be more fragile than it looks.\n\nMaybe modern software lifts the complexity limit on supply chains. Perhaps Arrival’s network of micro-factories is no harder to manage, in 2021, than a single centralised plant was in the 1970s?\nMaybe consumers will demand that carbon is priced in. If the environmental externalities were fully factored in, maybe Unilever’s shipping container factories would actually end up looking cheaper than giant centralised plant?\n\nAnd here’s another data point: I was talking a couple weeks back about the Suez Canal as a newly apparent global infrastructure risk. Well I didn’t expect it to become apparent like this:\n\nSupply chain issues and the popularity of garden centres during lockdown are causing a shortage of garden gnomes.\nThe ornaments are in short supply with raw materials hard to come by and the recent blockage of the Suez Canal contributing to the national shortage.\n– BBC News, Gnome shortage: Lockdown and Suez canal blockage blamed\n\nAnd: We haven’t seen a gnome in six months now unfortunately.\n(Thanks Steve Portigal for the pointer on Twitter.)\nIf you run a just-in-time supply chain - maybe not gnomes but perhaps construction equipment - surely you’re now doing calculations on resilience, and you might just choose to have a supplier nearby than halfway round the world.\nIt could be that only a few numbers need to change, and suddenly factories will be on our doorsteps again, providing jobs, improving transparency, reducing alienation between consumers and the methods of production, lowering carbon footprint…\nThe pot of gold at the end of the rainbow is this solarpunk yoghurt commercial.\nSeriously, watch it if you haven’t already. It’s a 30 second, animated vision of humans and robot living, eating, and farming together, wind turbines on blimps, a Veridian future-pastoral world from – Chobani, which makes yoghurt. Because of course.\nSo there’s hope, is what I’m saying:\nIt’s worth pushing at the numbers because the calculus could be near a tipping point, and it’s worth illustrating and demonstrating the better possible futures because the people with the supply chains in their Excel spreadsheets might just be looking for de-risked safe harbours. \n",
    link: "/home/2021/04/16/factories",
  },
  {
    title: "Why not faster computation via evolution and diffracted light",
    date: "20.47, Tuesday 20 Apr 2021",
    content:
      "Something I wonder is: what if computation, with today’s technology but done differently, could be - say - a million times faster? Here’s my thinking.\nIf there’s a defining feature of what computers are, I would say it’s abstraction layers.\nYou can tap buttons and move windows without thinking about what’s going on behind the screen. The programmer of that app sets out the instructions to draw those windows, and how they should behave, all without having to think about how exactly the instructions will be carried out.\nThose instructions are defined in simpler instructions, and so on, and so on. Eventually there are instructions that tell the chip what to do – but even that isn’t the end of it. Because, as I learnt recently, the chip itself turns its instructions into still more fundamental operations: microcode. Microcode choreographs the physical building blocks of the machine… registers, adders, flip-flops. And below those are gates. And below those are transistors.\nIt is absurd that a finely inscribed piece of silicon, with electricity running across it - the pattern on the stone - can be this thing, the computer. And yet!\nEach abstraction layer hides the complexity beneath, and provides general purpose flexibility to the layer above.\nBUT\nHere’s my question. Abstraction means reliability and composability. But surely each layer comes at a cost? And there are so. many. layers.\nLet’s say you just wanted to perform just one task. Say, recognise a face. Or know whether a number is prime or not. And you didn’t care about flexibility at all.\nCould that task be performed by simply the right set of transistors, at the hardware level, no matter how insanely arranged?\nWhat shortcuts could be taken?\nHere’s my evidence that this is a valid question to ask: a paper from 1996 on the topic of evolvable hardware.\n\n‘Intrinsic’ Hardware Evolution is the use of artificial evolution – such as a Genetic Algorithm – to design an electronic circuit automatically, where each fitness evaluation is the measurement of a circuit ‘s performance when physically instantiated in a real reconfigurable VLSI chip. This paper makes a detailed case-study of the first such application of evolution directly to the configuration of a Field Programmable Gate Array (FPGA). Evolution is allowed to explore beyond the scope of conventional design methods, resulting in a highly efficient circuit with a richer structure and dynamics and a greater respect for the natural properties of the implementation medium than is usual.\n– Adrian Thompson, An evolved circuit, intrinsic in silicon, entwined with physics (1996)\n\nI want to unpack that abstract:\n\nThompson designed an electric circuit to perform a tone-discrimination task – it listens to a sound, and can tell you which of two expected tones it has heard.\nThompson then evolved the circuit by taking its computer representation, introducing randomness, and making multiple variations.\nThe critical part: the evolved circuit was selected not as a simulation, but by making a physical version and - experimentally - measuring how well it performed.\n\nThis line in the abstract is far too modest: a greater respect for the natural properties of the implementation medium than is usual – because what happens is - excuse my French - BATSHIT INSANE.\nJumping to Section 5. Analysis in the PDF:\nThe evolved circuit is a mess.\nSo, of that tangle: Parts of the circuit that could not possibly affect the output can be pruned away. (By tracing what is connected.)\nBUT! It turns out: if these parts of the circuit are prunes, the circuit no longer performs as well.\nIt turns out that 20% of the components cannot be removed even though there is no connected path by which they could influence the output.\nWhat has happened? Thompson has evolved a circuit from a ‘primordial soup’ of reconfigurable electronic components – and he speculates that some of the components are interacting via the power-supply wiring or electromagnetic coupling. Not by conventional means.\n(The circuit also stops working outside the 10 degrees Celsius range in which it was trained.)\nIn 1996, the idea of “training” a computer to perform a task was slightly absurd – yes, there were expert systems and there was AI, but it was a toy. 25 years later, and computers are fast enough such that machine learning is standard practice at every tech firm… and we’re still figuring out how far it can go. If trainable software’s time has come, how about trainable hardware?\nGiven a single task, such as recognising a few simple words or a face, or performing protein folding, and so on, would it be possible to discard the complexity we currently devote to general purpose computing, and train a primordial soup of transistors to perform only that exact task – taking advantage of whatever nonlinear local effects and physics is available, abstraction layers be damned?\nHere’s another type of computer that makes use of deep physics: Artificial Intelligence Device Identifies Objects at the Speed of Light. It’s called a diffractive deep neural network.\nThe existing way for a camera to recognise an object is for the camera to convert light to pixel data, then the computer has, in software, a trained neural network (that’s machine learning again) that runs matrix maths on the grid of pixels until an object category pops out at the other end. The matrix math is fearsomely complex, and is trained in a process called machine learning. The result: It’s a dog! It’s a face! It’s a tree! Etc.\nThis new  way still uses machine learning, but the maths is replaced by a series of very thin, semi-transparent 8-centimeter-square polymer wafers. Each wafer diffracts the light that comes through it. And:\n\nA series of pixelated layers functions as an “optical network” that shapes how incoming light from the object travels through them. The network identifies an object because the light coming from the object is mostly diffracted toward a single pixel that is assigned to that type of object. \n\nSo you don’t need a camera.\nYou don’t need software.\nYou take a stack of FINELY ETCHED TRAINED PLASTIC WAFERS, and you look through it at an object, like using a monocle. But instead of seeing the object more clearly in focus, you see a cryptic constellation of glittering pixels. You look up the constellation in your handbook, and…  It’s a dog! It’s a face! It’s a tree! Etc. Only, at the speed of light. With no power required.\nPhysics performing computation at the granularity of the universe.\nBy using the interference of light with itself.\nThe analogy for me is that you have a swimming pool, the shape of which is ingeniously and carefully constructed, such that when you throw in an object, the ripples all bounce around and reflect off the edges and change in speed given the depth, and all collide in such a way that the shape of the splash spells a word in the air: the name of the object you threw in.\nI can’t help but cross these ideas in my head.\nWhat if we disregarded general purpose computing and abstraction layers in favour of speed?\nWhat if we could evolve hardware to make use of hidden physics?\nWhat if we used light?\nWhat then?\nPerhaps a computer, for a specific task, would be a million times faster. Or to put it another way, that’s 20 Moore’s Law cycles: 40 years of performance gain. That’s like saying we could leapfrog from 1981 computers to 2021 computers.\nThe speed of computers now is what has made machine learning possible. Advanced statistics, neural networks, etc, all of this was known pretty well decades before. But it was impossible to run.\nSo what today is impossible to run?\nWhat if you could make a single-purpose, zero power lens that looks at a handwritten number and breaks cryptography?\nOr sequences a gene?\nOr runs a thousand faster than realtime simulations and drives your car for you? Or predicts behaviour of a person in a negotiation? What about computational photography that can look around corners by integrating the possibility of photons, or can brute force prove or disprove any mathematical theorem?\nOr understands and can generate natural language just like GPT-3 but a million times better? Or, as in that speculation about an AI overhang: Intel’s expected 2020 revenue is $73bn. What if they could train a $1bn A.I. to design computer chips that are 100x faster per watt-dollar? (And then use those chips to train an even better A.I…)\nWhat is the ultimate limit of computational operations per gram of the cosmos, and why don’t we have compilers that are targeting that as a substrate? I would like to know that multiple.\nAnd, a question for computer scientists, what single question would you ask if you have a dedicated computer that was [that multiplier] faster? Because I would like to know.\nI guess what I’m saying is that it might be possible, with today’s technology, to make a monocle, perhaps one that you fold down like a pirate’s patch, that when you look through it with your eye performs - with zero power - a single massively complex AI computation on whatever you’re looking at, as fast as computers will run decades in the future.\nIf I were the US government, I would be pouring billions into this.\n",
    link: "/home/2021/04/20/computers",
  },
  {
    title:
      "What wipes in Star Wars teach us about the brain and also interface design",
    date: "11.28, Friday 23 Apr 2021",
    content:
      "This seven minute video opened my eyes to the sophistication of the editing in Star Wars, and it connects to some intriguing cognitive quirks that should be better known by designers.\nWatch on YouTube: Film editing psychology - screen wipes in STAR WARS by Rob Ager (7 mins 18 secs).\nIt focuses on the unusual approach that Star Wars has to scene transitions, often using a curtain sweeping visual impression - as in a cheesy PowerPoint presentation - rather than a regular cut. Regular cuts work like this:\n\nMost movies don’t use screen wipes but instead rely on the standard scene transition editing approach. As one scene ends, there tends to be a momentary gap after a section of dialogue or action comes to completion. The gap establishes the closure of the scene and then a cut to a new scene is introduced, which tends to involve an initial introductory gap before dialogue and action commences again.\n\nThat gap! In one quite normal cut: Note the 6 second gap separating the dialogue.\nBut (as the video shows) if you remove the gap, the easing between scenes, it’s too abrupt.\nThe gap is not required with a wipe: there is only a 2 second dialogue gap between these two scenes which uses a fast screen wipe instead of a straight cut.\nIt’s not really about saving time. The maintenance of emotional engagement from scene to scene is what counts.\nAger’s YouTube video has a ton of examples (there are 23 such wipes in Star Wars. Most movies use… none). In particular, there are shaped wipes.\nStraight-edge wipes dominate at the beginning of the movie. Circular wipes - opening an aperture to the next scene - dominate over the final 30 minutes.\nI love one wipe in particular: there’s a scene where the rebel fighters are being briefed, and the movie move us quickly to the scene of the action:\n\nThis circular wipe begins at the part of the screen where the Death Star is positioned, like the Death Star itself is forcing itself on screen.\n\nI mean, maybe you don’t consciously notice it when you watch the movie.\nBut my goodness, when you look out for, you can see the effect on your own attention and sense of story, and that wipe is deft af.\n(Marcia Lucas won the Best Film Editing Oscar in 1977 for her work on Star Wars.)\nWhy do wipes work so successfully? (More examples of wipes on Wikipedia.) I can’t prove this, but I have a hunch.\nThe brain has a limited amount of resources, so it has to choose what’s going to be regarded and what’s going to be ignored. The feeling of this resource allocation is what we call attention.\nAttention is the topic of Mind Hacks chapter 3, and there’s a particular idea I want to pick up on called object files. If you have the book and want to read more, go to Hack #36: Feel the Presence and Loss of Attention. (Here’s a search for ‘object files’ in Mind Hacks at Google Books.)\nWhen you see an object, the brain automatically tracks it, setting up a file: a kind of invisible sticky tag on the object.\nThe benefit? When the object goes behind something, the tag is still attached – so when it reappears, you know it’s the same object.\nWhat I’m fascinated by is the brain’s automatic allocation and deallocation of these tags.\nBecause:\n\nwhile seeing an object creates a tag for it,\nand seeing an object slide behind something does not remove the tag,\nseeing an object shrink to a dot, as if it is receding into the distance, does indeed automatically remove the tag. Attention is automatically deallocated.\n\nSo the brain is full of these automatic attention allocation and deallocation heuristics. Seeing an object shrink to a dot is one such trick.\nAnd it isn’t just individual objects. I wrote last month about the Doorway Effect: Your memory resets when you walk through a door. (See: Clues for software design in how we sketch maps of cities.)\nWhen you walk into a new room, your brain automatically deallocates attention from the previous room, readying you for whatever comes next. Helpful! The Doorway Effect doesn’t require a physical trigger. It even works on screen, with a visual representation of a doorway.\nSounds like a Star Wars wipe!\nSo here’s what I think is going on: Without a wipe, the brain needs a couple of seconds to spin down and spin up, otherwise the shift in scene is too abrupt. But using a wipe, there is some kind of cognitive cue that interacts with the brain’s automatic attentional system, efficiently triggering the process of attention deallocation/allocation, making the whole transition more efficient.\nBut the brain’s attentional system is half the story.\nMy mental model for what is going on is that there is the attentional system and there is the emotional system.\nWhile the attentional system makes step changes, triggered by heuristics as discussed above, the emotional system is continuous with no such resets.\nBut the emotional impact of a visual impression does still decay over time.\nWith a Star Wars Wipe, the scene transition is 4 seconds quicker – meaning the emotional state is still fresh, and so there is greater emotional continuity from scene to scene. Powerful!\nAs I said – a hunch! But it makes sense to me.\nInterface design.\nI’m thinking about this because I’m thinking about software, and particularly how we move between contexts: desktops, windows, apps, websites, views within apps, and so on.\nWe know that some UIs feel intuitive and satisfying, and others are baffling.\nThinking about the iPhone, there are tiny visual cues all over the place: tapping on an app will zoom it to fill the screen. Well that must perform something like the Doorway Effect. Moving around inside an app is often a matter of scrolling up and down (a transition with no visual edge) and panning side to side (a transition with a hard visual edge). I don’t know what these do to the attentional system but I know, simply from introspection, that this is more “satisfying” than a flash that abruptly updates the display or, say, a pseudo-3D rotating cube effect.\nWe’ve gotten to this place of success by modelling user interfaces on the physical world: the computer desktop, windows with their object permanence, “Material design” and so on. But my take is that the physical metaphor isn’t what’s important. It’s that, by adopting the physical metaphor, we also tapped into the brain’s heuristics for how to structure information.\nSo I’m curious about the attentional ergonomics (let’s call it that) of user interfaces.\nAnd, if this is a valid way to think about software, I’d like to start using this cognitive approach to design software. Don’t take physical metaphors too seriously, but work directly with the deeper cognitive heuristics. Then, taking into account the emotional system too, where would that take us? A new grammar for interfaces?\nI’m sure this has been studied by HCI groups for years, so apologies for being obvious. But this is where my head’s at right now, so if you know the appropriate keywords for me to read up on the research, please do suggest.\n",
    link: "/home/2021/04/23/star_wars",
  },
  {
    title: "How about Meal Kits for fashion",
    date: "13.23, Tuesday 27 Apr 2021",
    content:
      "One of the food innovations of the pandemic has been Meal Kits: courier-delivered, high-end food, prepared in a restaurant kitchen and finished at home.\nFor me, a meal qualifies as a Meal Kit vs a traditional delivery if it ranks these two points above convenience and cost:\n\nAccess. I’m having food from a restaurant that is too far away, too exclusive, too skilled, too closed right now for me to otherwise experience.\nQuality. It would be more convenient to get the meal already hot, but it wouldn’t taste as good. So I have to pre-book, and finish meal prep myself according to the instructions.\n\nThere’s an art to making the meal prep foolproof. So the sauces are pre-prepared and pre-bagged, and you have to heat separately. And fats for any frying are provided in tiny baggies because you might not have the best grade of butter at home. Etc. It’s not totally foolproof. I can still screw it up, and that’s part of the experience.\nThere’s a question about they will survive as restaurants re-open: Are Meal Kits Going Back in the Box? (This is a great article on Eater London with a ton of links to good kits.)\nSo these are not the same as, say, Tovala which is a subscription food service combined with a smart oven that reads the barcode and cooks your dinner for you. Nor Blue Apron/HelloFresh/and so on which provide recipes and weekly ingredients boxes.\nMeal Kits: Access x quality > cost x convenience.\nI have a few friends who sew. I read their blogs and see their pics and I am entranced. Whereas: I buy my clothes from Uniqlo.\nActually clothes are an interesting one. As Benedict Evans pointed out recently, e-commerce in UK has jumped considerably - the UK has 50% higher penetration than the US - and we’re seeing new behaviours. Example: I know some folks who buy two sizes of every garment, for two people in the house. The person who likes it most keeps the one that fits, all the rest are sent back. The traffic in returns is enormous. It feels like the system is not meeting needs elegantly.\nSo… what are Meal Kits for sewing? High fashion, hard to source fabrics, home finished for perfect tailoring?\nHow could tailoring be made foolproof? An interesting challenge.\nAnd: Meal Kits for what else?\n",
    link: "/home/2021/04/27/meal_kits",
  },
  {
    title: "Three observations on my first vaccination shot",
    date: "16.30, Wednesday 28 Apr 2021",
    content:
      "I had my first vaccination shot yesterday: Team AstraZeneca!\nWe’re all vaccine sommeliers now. Here’s the view from the US:\n\nPfizer, distributed by one of the largest U.S. pharmaceutical firms, is the establishment vaccine. …\nModerna - the very name suggests something new - is the intellectual vaccine. …\nAstraZeneca, for better or worse - mostly worse - has become the forbidden vaccine, or at least the exotic vaccine.\n\nHere in the UK, we mostly get AstraZeneca.\nSecretly? I wanted Moderna. I’m into the mRNA tech.\nBUT, now I’ve had it, I’m weirdly proud of being Team AZ. It’s old school, not quite as effective as the others, and super cheap: the UK paid $3/£2.17 per dose. (Pfizer is $14-$30; Moderna is $15-$38.)\nSo there’s something staunchly egalitarian about that. Good.\nI had my first vaccination shot yesterday in a white tent in a leafy square (here it is), overlooked by the London Shard, and it had the cosy adhocracy aesthetic all over.\nLondon Bridge vaccination centre 2 is a major site, doing (at a guess) 500+ shots/day. I showed my booking reference to someone as I walked in, then I was given a form and directed to a seat in the waiting area.\nInside the big white tent, there are spaced out chairs (and a person appointed to disinfect each chair as it is vacated) and a large TV screen at the front showing the current waitlist and the names of the people who have been called. It looks like a web app. Another person calls out the names as they appear. Temporary lights are strung from the temporary roof. I could see a temporary thermometer hung on the plastic wall (there’s no air con). Everything is functional and repurposed. Not integrated.\nSome people in the roles changed over while I was there. Were they volunteers? It seemed that way. The service design is clear – you can practically see the circuit diagram underlying the flows of people and the physical structure.\nFurther into the tent it is divided into cubicles. Temporary walls. Soft infrastructure. They pulled the curtain closed. One person asked me consent and safety questions, tapped at a computer, and waited for centralised approval to be given. The second gave me the shot. Then I left, back out into the sun.\nCosy adhocracy:\nI mean cosy in the sense of Venkatesh Rao’s coinage domestic cozy: Domestic cozy is in an attitude, emerging socioeconomic posture, and aesthetic. It’s homely. Satisfying.\n\nWe’ve been sitting on our computers in our modern apartments for the last 10 years and we’re all miserable. It seems like there’s this metashift happening from cool, minimal, and internet-y to in-person, maximalist, and cozy.\n– Vox, Why are so many brands pivoting to coziness? (2020)\n\nJust as there is cosiness in being at home with friends, eating together, soft furnishings, etc, there is also cosiness in community – in a neighbourhood. And so…\nI mean adhocracy as in Cory Doctorow’s debut novel Down and Out in the Magic Kingdom (download here). In this future world, as described in this review, social structure is provided by adhocracies, self-organizing groups of individuals working together to accomplish common goals.\nCosy adhocracy has an aesthetic all of its own. Village fetes, street parties, the vaccine roll-out. That Great British Bake Off tent is tapping into some deep vibes.\nThe material culture of cosy adhocracy is trestle tables, lighting used by decorators repurposed to illuminate the street in the early evening, and bunting. It’s books of raffle tickets used to share out the drinks; it’s church halls and other reconfigurable spaces; it’s whatever people have in their sheds.\n(The street parties put together on my road for royal weddings, or - in the depths of lockdown - because we all wanted pizza and socially distanced negronis: they’re organised together on WhatsApp and they make my heart swell. Cosy adhocracy at its finest.)\nAnd then, for bigger events, it’s the playbook used by organisers and volunteer workers.\ne.g.: Parkrun: centrally organised, volunteer-run, free 3 mile races every Saturday morning, all around the world. 750,000 people run with Parkrun every weekend (or at least, they did before the pandemic). The tech is so beautifully lightweight: somebody blows a whistle at the start, all 200 of you set off around the park, and at the end you are given a barcoded token. Somebody is recording the token times. Somebody else scans in the barcodes, along with your own personal number. The results show up on a central website. One volunteer always runs with the slowest person to make sure they get round.\nI’ve run in parks in south London, and along the beach in Queensland, and the format is the same everywhere (except in Australia there was also a spoken acknowledgement and celebration of the First Peoples of the land). The playbook is encoded in the minimal application of foolproof technology, and the roles given to the volunteers who direct and operate each race.\n(I think there’s something about volunteering that keeps any central organisation honest. They can’t take advantage, force overwork, or provide useless tech… otherwise people would walk away.)\nIn the UK, the vaccination rollout is a wonderful collaboration of the state, private companies, and volunteers.\nI wonder whether service design and simple tech can be used to provide tools for communities to run all kinds of services?\nI had my first vaccination shot yesterday and a wall of tiredness hit me mid afternoon. Overnight I was too cold until about 6am and then too hot. Vivid dream after vivid dream. I had a brutal headache, and my body still aches all over, like I’ve been run over by a truck.\nIn the midst of the dreams, I found that it wasn’t an ache like you get with the flu. It was the full-body ache you get after an extraordinary amount of exercise.\nThen it struck me that I’ve been holding my body rigid for over a year now, and with the knowledge of the first vaccination shot, I was allowing myself to let go of some of that tension and fear, the fear for my family and my friends and myself, and the pain I am feeling is from my arms and my legs and my shoulders and my back and my neck and my face and my lungs all wound tight for so long, of course this anxiety leaves its residue in the muscles and the spirit, that’s the ache, but there’s light at the end of the tunnel now, a relief and a release, and as I related this realisation over breakfast this morning, I found myself, however briefly, beginning to cry.\n",
    link: "/home/2021/04/28/vaccination",
  },
  {
    title: "Filtered for big things that don’t weigh so much",
    date: "16.44, Friday 30 Apr 2021",
    content:
      "1.\nThe entire internet, i.e. all the electrons in all the electricity: about 50 grams, the same as a plump strawberry.\nA gossamer lacework, as light as a strawberry, covering the world.\n2.\nThe entire atmosphere of the Moon: less than 10 metric tonnes.\nc.f. Earth’s atmosphere which is about 5.15 million gigatons.\nc.f. Earth’s living biomass: just 2% of the weight of the atmosphere, 1,100 gigatons. But humans make a lot of mass too; anthropogenic mass doubles every 20 years. It turns out that we’re at the crossover point and, as of 2020: Global human-made mass exceeds all living biomass.\n3.\nThe total volume of Covid-19 (SARS-CoV-2) in the whole world: about 160 milliliters, roughly 6 shot glasses.\n4.\nThe human soul:\n\nIn 1901, Duncan MacDougall, a physician from Haverhill, Massachusetts, who wished to scientifically determine if a soul had weight, identified six patients in nursing homes whose deaths were imminent. … When the patients looked like they were close to death, their entire bed was placed on an industrial sized scale that was sensitive within two tenths of an ounce.\n\nMacDougall measured the patients’ loss of mass at the very moment of death, when the soul departs the body. The result and therefore the weight of the soul: 21 grams.\nThe experiment was repeated with dogs, and found no weight change, confirming the theory that animals do not have souls. Sadly: MacDougall said he wished to use dogs that were sick or dying for his experiment, though was unable to find any. It is therefore presumed he poisoned healthy dogs.\nThe Moon’s atmosphere weighs 200,000 internets. One internet is 2.4 human souls.\nScience!\n",
    link: "/home/2021/04/30/filtered_for_small_quantities",
  },
  {
    title: "A strange loop involving Brian Eno and the nature of time",
    date: "13.03, Wednesday 5 May 2021",
    content:
      "In 1962, Douglas Engelbart writes his paper Augmenting Human Intellect: A Conceptual Framework, his theory of human progress based on human-computer cooperation. In 1968, Engelbart and his team present The Mother of All Demos where, famously, in 90 minutes, they show off bitmapped graphics, hypertext, video conferencing, modern office furniture, and the mouse, thus inaugurating the era of the personal computer.\nLook to the side (search for “The ARC team rehearses” on that page for the photo): operating the camera is Stewart Brand.\nIn the 1960s and over the following decades, Brand starts a number of projects and organisations dedicated to thinking and working collectively. The Why haven’t we see a photograph of the whole Earth yet? campaign, to help us think as a planetary level; the Whole Earth Catalog, to share knowledge and tools across the countercultural communes of North America; the Whole Earth ‘Lectronic Link, one of the first online social spaces; and in 1996, the Long Now Foundation.\nThe Long Now Foundation is building a clock which will last 10,000 years, and is  named for the concept of the “long now” coined by Brian Eno, one of its co-founders, in an essay in January 1995: The Long Now is the recognition that the precise moment you’re in grows out of the past and is a seed for the future.\n(Eno is a theorist and musician and pioneered ambient music after being hit by a taxi in 1975. Recuperating, he couldn’t stand up and adjust the volume on the stereo – music became part of the environment, a new thing.)\nMeanwhile:\nEngelbart’s colleagues go on to Xerox PARC. The Xerox Alto becomes the first commercial computer with a mouse; the Xerox Star the first with the modern desktop user interface. Steve Jobs sees the Star, and then the Apple Macintosh popularises both the desktop interface and the mouse. Catching up, Microsoft releases Windows 95 with massive publicity in August 1995, it is a huge success, and the mouse finally goes mainstream.\nThe startup sound for Windows 95 is six seconds long. It is iconic. (Here it is, with some other interpretations.)\nThe startup sound was composed by Brian Eno.\nAfter the project, which started in 1994, Eno says:\n\nI got completely into this world of tiny, tiny little pieces of music. I was so sensitive to microseconds at the end of this that it really broke a logjam in my own work. Then when I’d finished that and I went back to working with pieces that were like three minutes long, it seemed like oceans of time.\n\nI don’t know of any published link between Brian Eno’s two experiences of time, these two juxtapositions of micro and macro, both holding up a single moment against the unfathomably larger ocean of time, other than they both occur in 1995.\nBut it doesn’t feel like a coincidence that the same mind, preoccupied with the notion, should be involved in both.\nAnd it’s neat that these two moments, almost simultaneous in the scheme of things, came about as a result of a single event almost 30 years earlier.\nA strange loop in the history of the modern world.\nI’m working on a talk at the moment: a parallel history of computing, one that follows the exceptions and the tangents and the forgotten ideas. I’m running it once next week and again in early June. It’s long! Right now the plan for the one in June is to spread it out over three successive evenings, as part of a larger conference.\n(I’m going to keep presenting this talk for a while, and keep developing and iterating the material. At a certain point I’ll publish… but not yet. Do get in touch if it sounds like a fit for an event in which you’re involved.)\nOne of the joys of researching the talk, and joining the dots, is discovering for myself coincidences like this. New ways to tell old stories. So I wanted to share this one.\n",
    link: "/home/2021/05/05/strange_loop",
  },
  {
    title: "Fish fingers, boxed software, and processes that create industries",
    date: "20.28, Thursday 6 May 2021",
    content:
      "I read the other day that the invention of modern frozen food is credited to Clarence Birdseye in 1924. Birdseye’s quick-freezing process actually ended up creating 168 patents! These covered not only the freezing technique but also the packaging, type of paper used, and related innovations.\nWhich is funny because I associated the Birds Eye brand with fish fingers and potato waffles, but it didn’t occur to me that name was from an actual historical figure, and that they had made a significant breakthrough.\nSEE ALSO:\nPilkington. I grew up in the 1980s, at the height of the double glazing boom, so radio ads were pretty much all for windows and conservatories. (My first website built for money was in 1996, for a windows and conservatories firm, but that was the tail end). So the name “Pilkington” is etched in my memory. Anyway it turns out that, in the 1950s, Sir Alastair Pilkington co-invented the continuous float glass method, which was so successful that it replaced all other methods.\nThere’s something about an industrial process named for a person that reminds me of old school science. It’s Wheatstone bridge this (a type of electrical circuit) and Bessemer process that (the mass production of steel).\nA certain era of sci-fi is littered with fictional artefacts named for fictional people, and I love it.\ne.g. the Rodebush-Cleveland free drive in First Lensman (1950) Roeser’s Rays in Spacehounds of IPC (1947) both by E. E. “Doc” Smith.\nBut really what I’m into is the idea that a single insight can be continuously exploited by the company that originated it.\nIn the modern era, Google almost qualifies, having invented PageRank, the modern method of ranking websites, but perhaps more important was self-service AdWords (early 2000s?) which introduced automated auctions, interest targeting, and engagement feedback loops. So clever, but it means that Google isn’t as singular as I’d like.\nI think maybe Microsoft qualifies? After all: Bill Gates in 1976 wrote the infamous Open Letter to Hobbyists in which he set out the argument for commercial, consumer software – basically the concept of software as boxed product. And that idea created an industry.\nIt’s not frozen fish though, is it.\n",
    link: "/home/2021/05/06/birdseye",
  },
  {
    title: "Some experiences with neutral technology",
    date: "16.34, Friday 7 May 2021",
    content:
      "I remember getting an Amiga computer, years and years back, the late 80s, and playing with speech synthesis for the first time. It was remarkable to type and then hear the computer speak my words.\nRemarkable not because it was any good… Late 80s speech synthesis was a dancing bear: “The marvel is not that the bear dances well, but that the bear dances at all.”\nSO I THOUGHT.\nYears later I heard a radio programme about the scientist who came up with this method of speech synthesis. He spoke in a gravelly, robotic monotone with jerky stops – my goodness, he sounded exactly like my old computer.\nWith a bit of googling I now know this must have been Dennis Klatt at MIT, whose work led to the DECtalk text-to-speech system, and who also lent his voice to Stephen Hawking.\nWhat to me, a kid from the south of England, sounded like a slightly broken, generic computer-y voice, will have been to him absolutely spot on. It couldn’t have sounded better!\nAnother one: driving games.\nPlaying video games, anything involving driving felt incredibly artificial. I mean – I had never driven an automatic, and UK roads (especially where I lived) are narrow and mostly single lane.\nAnd then I visited the US for the first time as a driver… I got behind the wheel and thought: this feels exactly like a video game. Even the other cars behave exactly like in-game AIs! Suddenly I had a new respect – those weren’t just games that I played, they were simulations!\nI remembered these experiences this morning when Ryan Bateman pointed out the virtual meeting backgrounds provided by video software.\nWhite and beech, semi-abstract rooms. He asks: What are these places? Who lives there? Who works there? – these are good questions. These backgrounds show virtual spaces that are larger than any room in my house. Are they supposed to represent the companies at which I would aspire to work? Is there someone, somewhere, for whom these spaces feel normal? Neutral?\nThat said, I admit that they do feel relatively unnoticeable to me. My eyes slide off them. I’m right at the centre of the target culture.\nA “neutral” design will put some people at ease and cause others to feel (subtly or not so subtly) decentred. Obvious to say it, I know. But worth remembering.\nSometimes I look at my phone and think: I’m looking through a portal to California. My phone will never feel quite as part of the world as it does under Californian skies lit by the Californian sun. Here in London, or anywhere else really, my phone will always very slightly shimmer with an otherworldly light.\n",
    link: "/home/2021/05/07/neutral",
  },
  {
    title: "The peripheral reach of old computers",
    date: "19.01, Wednesday 12 May 2021",
    content:
      "EDSAC was one of the very first computers to allow for loading programs, in 1949, and it sounds like a delightfully sensory experience.\n(Previously computers were programmed by re-wiring their control panels. When ENIAC, the first fully electronic, digital computer, was upgraded from control panels to loading programs in 1948, it reduced the reprogramming time to hours instead of days.)\nHere’s what loading an app on EDSAC was like, as related on Wikipedia:\nUsers prepared their programs by punching them (in assembler) onto a paper tape. … When a program was ready it was hung on a length of line strung up near the paper tape reader.\nThe machine operators would feed the tape in when its turn came. I like this image of a washing line, you can just imagine hanging up your program and sighing because there are so many already there.\nAnd then:\nA loudspeaker was connected to the accumulator’s sign bit; experienced users knew healthy and unhealthy sounds of programs, particularly programs ‘hung’ in a loop.\nI am super into this noisiness.\nBut what I am into more particularly is the work of the computer being spread around the room.\nI love Natalie Jeremijenko’s seminal Live Wire (Dangling String) (1995) created when she was artist-in-residence at Xerox PARC.\n\nCreated by artist Natalie Jeremijenko, the “Dangling String” is an 8 foot piece of plastic spaghetti that hangs from a small electric motor mounted in the ceiling. The motor is electrically connected to a nearby Ethernet cable, so that each bit of information that goes past causes a tiny twitch of the motor. A very busy network causes a madly whirling string with a characteristic noise; a quiet network causes only a small twitch every few seconds. Placed in an unused corner of a hallway, the long string is visible and audible from many offices without being obtrusive.\n– Mark Weiser and John Seely Brown, Xerox PARC, Designing Calm Technology (1995)\n\nHere’s the closing statement of the paper:\nThe dangling string increases our peripheral reach to the formerly inaccessible network traffic. While screen displays of traffic are common, their symbols require interpretation and attention, and do not peripheralize well. The string, in part because it is actually in the physical world, has a better impedance match with our brain’s peripheral nerve centers.\nPre-symbolic, non-obtrusive, peripheral reach.\n",
    link: "/home/2021/05/12/peripheral",
  },
  {
    title: "Oikos vs polis: a new (but old) axis on the political map",
    date: "17.53, Thursday 13 May 2021",
    content:
      "Here’s an exchange on Twitter that illustrates the new schism in politics, from May 2020:\n\nMichael Gove, UK government minister: Caring for your wife and child is not a crime. (On the topic of an advisor breaking the law on lockdown.)\nCommentary from John Holbo, philosophy professor: It really is astonishing how true it is. Conservatism says the law protects in-group members without binding them; while binding out-group members, not protecting them. Mafia logic all the way up and down.\n\nIs it ok to put your family, or your tribe, above the law?\nUnlike Holbo, I don’t believe that answering “yes” to that question is a particular conservative or right wing trait. It’s a question that different people will answer differently; it’s a new axis on the political map. Perhaps it’s the new axis.\n(Cory Doctorow has more comments on the exchange here, again from May 2020, where he relates it to pluralism vs elitism. Have a read – I’m going in a similar-ish direction.)\nThe existing axes are “social” and “economic” and they no longer make sense\nThe Political Compass has been a pretty good model as long as I’ve been politically aware.\n(Caveats: I’ve only been paying attention to politics since the early 1990s. And when I look back to say, the 1960s, before the free market ideology took hold, the right seemed way happier to promote state intervention. So I don’t know how it felt back then.)\nThere are two axes, and you can take a test and end up somewhere on this grid:\n\nSocial: authoritarian vs libertarian\nEconomic: left vs right\n\nBut this implies that there’s a kind of universality to policy: it presupposes that everyone is treated the same.\nWhat if that no longer holds true?\nOikos vs polis: blood vs state\nThe term oikos has framed my thinking for a while. A few years back I read Benjamin Peter’s How Not to Network a Nation which is a great look at why there was never a successful Soviet internet, despite many attempts between 1959 and 1989. From the blurb on the back, the book argues that the American ARPANET took shape thanks to well-managed state subsidies and collaborative research environments, while the Soviet network projects stumbled because of unregulated competition among self-interested institutions, bureaucrats, and others.\nHere’s the passage that grabbed my attention (p194 of my edition).\n\nConsider the language of Hannah Arendt’s The Human Condition - a landmark work of political theory that introduces its disenchantment with normative liberal values with a discussion of Sputnik and the nuclear age, the two ingredients that, once combined, could spell instantaneous planetary annihilation. For Arendt, the distinction between the public and the private is not the liberal economic opposition of the public state and the private market but a classical (Aristotelian) distinction between the public as an expression of the polis (where actors gather “to speak and act together”) and the private as an expression of the oikos (Greek for household and the root of the word economy) (where actors inhabit a domain of animal necessity and are compelled to pursue their own interests for their survival).\n– Benjamin Peters, How Not to Network a Nation\n\nSo this stuck in my head, and here’s my crude, way-over-simplified way of thinking about it as a framework:\n\nan oikos view is: it’s morally preferable to favour “people like me”\na polis view is: it’s morally preferable to treat everyone equally\n\nOikos politics can be wielded for good and ill\nI was initially baffled when, in 2019, the Brexit Party announced its only non-Brexit political policy: the abolition of inheritance tax. (See the announcement on Twitter.)\nWhy should this be sole additional policy? Why not remain silent? The oikos vs polis framework helped me. “Brexit” is a classic oikos preference: this country matters more than this bigger union, it says. And if Brexit is the macro, then removing inheritance tax is the micro: tribe over state.\nBut I want to be clear: oikos is not bad. Like any political preference, it can be wielded for good and ill.\nCommunity is an oikos value! Neighbourhood is an oikos value! Closing the streets to city traffic so kids can play, that’s an oikos value! Mutuality and cooperative organisations… traditionally left wing, but elements of oikos there. EastEnders, the long-running British TV soap about fierce family loyalties: oikos.\nThe old English aristocracy: that’s oikos all over. As The Institutional Revolution points out (I read this in December 2020), the aristocracy was an economic adaption to a world without reliable communications or measurement. To function, that world required high trust relationships and ways to bind people into high trust relationships. The aristocracy met that challenge for 300 years – and its values of loyalty, honour, family, and so on are oikos values: trust and defend my group over any other allegiance.\nNow the right wing ruling class of the UK is closely connected with those old aristocratic families. Is it any wonder they continue to display oikos culture?\nAnyway, my conclusion was that oikos is independent of left vs right; independent of owner class vs labour class; independent of being socially liberal or authoritarian.\nThis super insightful tweet is, to my mind, about the same thing:\n\nI have a hunch the next important political divide won’t be right/left or remain/Brexit - It will be between those who, in the face of climate crisis, choose self-interest (the Doomers, Preppers) and those who choose solidarity (XR, transition towns).\n– Bea Karol Burks (@beatricelucy), 9:58 AM, Oct 7, 2019\n\nSelf-interest: oikos. Solidarity: polis. (Though it strikes me that fighting the climate crisis will require framing the solution in terms of self-interest too.)\nThe explanatory use of this framework…\nI usually try to avoid talking about day to day politics, but I need to for a second. Before I do, I want to reinforce this point: Oikos is not a bad thing. If I say someone is strongly on the oikos end of the spectrum, that is in no way a value judgement.\nBoris Johnson is on the oikos end of the spectrum. For him, his family comes first. His business relationships and financial wellbeing comes first, above his duty to the country and perhaps even the spirit of the law. AND YET, in recent elections, this has done him no harm.\nWhy? My feeling is that it’s because a lot of people in the country respect his approach. Actually – they do the same. They care about their family, and would put in a good word for them if it meant they would get a job, or tell a white lie to the police if it got them out of a speeding ticket. They don’t see anything wrong with campaigning hard for their town, or their football team, because there is nothing wrong with these things!\nAnd what Johnson is doing is progressing an oikos culture which means that other strongly oikos people are in common cause with him. Sure, they’re not favoured by Johnson personally, and actually they might be slightly damaged by his actions, but that’s not the point: in a wider sense, they’re on the same side.\nThey’re on the same side regardless of where they were on the old political map.\nFor me, this helps explain the recent election results (where the Tory party was not punished for Johnson’s self-interest) and also the coalition of wealthy elite and working class that carried the “Leave” vote for Brexit.\nBeing able to say: “aha, that is an example of oikos common cause” has been enormously illuminating to me. It has never been about populism or nationalism, or right and left; those are just symptoms.\n…and how having this framework has affected my views.\nSo there’s no point in attacking politicians for displaying oikos values. What some people see as selfish, others see as upstanding.\nPerhaps the value of the polis needs to be shored up. Solidarity, equality in the eyes of the law, utilitarianism: these are ideas that need to be re-established.\nThe right has claimed oikos for its own. That makes sense: it’s a natural fit for neoliberalism (free market economics), and also for small government (because you should look after your own). But I don’t believe this necessarily has to be the case. What should the left fight for in an oikos world? A vital question.\n",
    link: "/home/2021/05/13/oikos",
  },
  {
    title: "The Memex, the Manhatten Project, and the month of July 1945",
    date: "17.36, Friday 14 May 2021",
    content:
      "In July 1945, Vannevar Bush came up with the Memex, a fictional proto-computer to augment your memory, manage your research and contribute to knowledge of the world. His article was published in The Atlantic and you can read it online – although this scanned version also has the ads and the illustrations, so check it out.\nAnyway, for a made-up bit of furniture (it’s a desk with a microfilm library inside), it has been enormously influential. Doug Engelbart, whose team kicked off the personal computer vision in 1968: he read Bush’s article in a Red Cross hut in the Phillipines in 1945/46, and it kickstarted his vision. Here’s the hut (or at least one nearby).\nTim Berners-Lee, when he wrote the proposal for what became the web, in 1989: he cites Ted Nelson’s vision of hypertext; Nelson credits Bush as his main influence.\nVannevar Bush (1890–1974) headed up the US government’s military R&D during the Second World War, coordinating thousands of scientists. Just one of his projects was the S-1 Section, which showed the feasibility of the atomic bomb, and he initiated the Manhattan Project, the massive project that created the bomb itself.\nSo it isn’t hard to see the origin of his insights about exploring and connecting knowledge.\nBut the Memex was still an achievement of the imagination: in 1945, computers were mainly electromechanical calculating machines; the electronic computer was brand new (ENIAC weighed 30 tons); programming a computer meant a days-long process rewiring a removable plugboards. Computers that could be used interactively were still several years in the future. So the idea of a computer for personal use, let alone a desk that you would work with by drawing and speaking, in which you could the hyperlinked knowledge of entire libraries - and your own correspondance too - it’s a leap.\nAlso in July 1945, the same month as the publication of his speculative article in The Atlantic, and this is a coincidence, the Trinity test: the first ever detonation of a nuclear device, and the beginning of the grim culmination of the atomic project.\nRELATED: A strange loop in time involving Doug Engelbart and Brian Eno.\nThese two legacies, the Memex and the Manhatten Project: which has had the greater influence on the world?\nProbably in the year of Bush’s death, 1974, still a decade before the first popular personal computer, and at the height of the Cold War, Bush would have seen the atomic bomb as his project which most altered the world. Perhaps now, in 2021, it’s the Memex? I wonder.\nI know it’s only a coincidence, these two events in the same month, but it invites the comparison. Could Bush’s perspective that led to the Memex have even been formed without his exposure to the vast scale of cross-pollinating scientific research, a context only possible in wartime?\nMy fear is that they’re two sides of the same coin, and that’s an ugly lesson.\nMy hope is that what Bush had is something that didn’t require war (and what a war) to be formulated, which is a theory of human betterment and a belief in human progress, and it’s that framework that guided his formative speculations, and that at least is a method we can safely imitate.\n",
    link: "/home/2021/05/14/1945",
  },
  {
    title: "The pedagogy of toddler ballet",
    date: "15.52, Thursday 20 May 2021",
    content:
      "I say ballet, but the lessons we go to with our 2.5 year old on Saturday mornings are exactly the kind of event you’d expect with toddlers – an instructor fruitlessly leading the group through a series of exercises while the kids watch, wave, charge about, and very occasionally sort of join in. There’s very little ballet going on. EXCEPT:\nThere’s a song at the beginning where you move your head and arms. Clearly that’s warming up.\nThere are the physical and (interestingly) the psychological atoms of ballet itself. Like: tip-toeing, a game that includes jumping, and also taking it in turns to walk into the centre of the circle and wave to the entire class. That’s the seedling of a solo, right there.\nThere’s structure which I imagine is common to every ballet class ever. The instructor is called Miss S–. At the end, everyone curtsies (or at least is asked to). A reverence.\nBut my favourite exercises are those that are about establishing the communications protocol. The song “Head, shoulders, knees and toes” comes up every lesson. Then there’s also a song with maracas where the kids shake up and down, side to side, and into the circle and away from the circle. Cardinal directions!\nBeing able to accurately reference a body part and a direction is the foundation for high bandwidth communication and rapport between teacher the student. The trick is that the teacher can reference desired behaviour at a distance.\nSo these seem like important categories to exercise in any new group, such as a work team, coaching relationship, or perhaps even a user with software:\n\nthe atoms of technique (the physical movements and also the feelings) – these are intended to be composed into sophisticated actions\nthe structure of the interaction (roles, and how a sessions begins and ends)\nprotocol (non-obvious names for objects and actions) – this is how the actors can form a self-improving symbiosis using feedback.\n\nIt’s interesting to see how the skeleton of the mental model that will one day become ballet is already being developed, even from the first lesson.\n",
    link: "/home/2021/05/20/ballet",
  },
  {
    title: "From the archives, w/e 21 May",
    date: "19.30, Friday 21 May 2021",
    content:
      "Blog posts this week from years gone by.\n1 year ago\nGross National Diversity (19 May 2020).\nWhat if it’s vital to the future to preserve alternate ways of living and alternate ways of thinking?\nRambling thoughts about cyborgs and emotions (20 May 2020).\nWhat is the kind of laughter we feel, watching a puzzle being solved? And a side question: what is the spiritual component of the climate crisis? (That’s a question that I’d like to come back to.)\n9 years ago\nFuelBand for alpha waves (16 May 2012).\nHow about a wearable device that measures your attention patterns over the day? Thinking about this in 2021, I’ve been monitoring my sleep this week with my Apple Watch and it’s intriguing without dictating behaviour, which I like. Why shouldn’t some upcoming version of AirPods include an EEG sensor and give me a focus vs zen readout? I doubt anyone really knows what the patterns mean… but maybe that’s for lack of data. Apple already runs large scale experiments to look for (as an example) heart arrhythmia with the watch. Could it also run large scale experiments to find meaning in brainwave traces? And, if you could see how much “downtime” your brain had day by day, and how that correlated with your mood, would you make different life decisions? Could some future Apple Specs be a device for mental insights (at least of a certain kind) just as the wrist wearable is a device for physical health?\n(Posts selected from the On This Day archive spelunking page. This is an experiment to see how to best include old posts in the current feed in a meaningful way. I’m currently thinking about this as a regular Friday feature.)\n",
    link: "/home/2021/05/21/archives",
  },
  {
    title: "We need talent identification for even the smallest needs",
    date: "19.54, Tuesday 25 May 2021",
    content:
      "There are a lot of talented people in the world aren’t there.\nI was reminded of this when I ran across the latest False Knees comic, which is gorgeous. (False Knees is a regular watercolored comic strip about birds voicing observations, alternately profound and profane.) And I thought: it’s so great that they have 628k followers on Instagram, 139k on Twitter, 270k on Facebook, and also an online store.\nThis is new! The transition: When I was at school, all the kids played football or mooched around the grounds outside during break. We weren’t allowed indoors. I visited 10 years later, and some of the music offices had been turned into recording studios; during breaks, kids were inside making music, making art, and yes outside playing sport too, but what I mean is that they were enjoying their talents.\nBut I feel like we’ve barely scratched the surface. False Knees is exceptional and it’s wonderful that they have a million fans, but generally speaking:\n\nMechanisms to identify talent are rare – how many people would be great at writing lyrics, or talking about history, but they don’t have the opportunity to recognise they have that special skill.\nMechanisms to connect talent to the people who love it: also scarce.\n\nI think about all the great artists who aren’t necessarily also great hustlers.\nI think about those two kids in Kenya who invented a prosthetic robot arm, controlled by brain signals. Of the almost-8-billion people alive, how many other great inventors are there who don’t get the opportunity to walk the path to their inventions?\nWe have unlocked like 1% of opportunity and realisation of talent in the world.\nI don’t mean in a purely commercial way but primarily artistic and imaginative. So not really about jobs; more generally about being fulfilled.\nBut let’s think about jobs for a minute…\nMakes you wonder what the global economic cost is, of LinkedIn being so terrible, said Kevin Cannon (when I talked about this on Twitter) and that’s a provocative framing. If you were to take the LinkedIn mission in its broadest sense as\n\nhelping people recognise their own personal potential\nconnecting potential to those that value it\n\n…then what would you do?\nOne model is the traditional labour exchange – in the UK government-run labour exchanges were established in 1909, and honestly my only insight into how they worked (compared to today’s job centres) comes from listening to a ton of old episodes of Hancock’s Half Hour from the late 1950s, which is the show that invented the sitcom, and our lad Tony Hancock often ends up in one.\nThey seem maybe more hands-on, compared to today’s model? That’s interesting.\nSo maybe let’s look at the London Olympics (2012) “talent identification” program: a nationwide scheme where you, a fit person in your early 20s who plays hockey on weekends, turn up, have experts measure your arms and legs and strength ratios and twitch muscles, etc, and say, “hey, have you thought about Niche Sport X, we could hothouse you in that and not many other countries participate, so you might win and our ROI is good”. Which is how Team GB ended up 3rd in the medals table.\nI have a picture in my head of something like that…\nYou turn up with an aptitude for making smart aleck remarks and a good eye, so the “creative industries talent identification bureau” (or whatever) gives you a digital tablet, a mentor relationship with a handful of web artists, and some back-office support to set you up with an online shop and a merchant account.\nI mean… why not? Why not hand crank the process, literally handhold people into discovering and fulfilling their potential, leading to them (a) improving culture, or (b) paying more taxes, or (c) both, and if not then at least (d) being happy? Rethink the model. How could it be economically viable?\nAnother model I admire is the Open University. Established in 1969 to provide a university education exploiting the new technology of television, it’s now the UK’s largest undergrad institution and reaches people that others can’t. What’s the 2021 equivalent?\nAt times like this I think of Bao Xishun.\nIn 2006, two dolphins at an aquarium in Fushun, China, swallowed some plastic shards and were at risk of death. Veterinarians were unable to extract the plastic.\nBut China has the world’s largest population.\nAnd with the world’s largest population, it has the world’s tallest man.\nAnd the world’s tallest man has the world’s longest arms. They called him.\nAnd so Mongolian herdsman Bao Xishun, the tallest man, reached into the mouths and down the throats of the dolphins with his arms, the longest arms, 1.06 metres, and retrieved the plastic and saved their lives.\nI can only imagine the infrastructure and institutions required to connect that particular need to that particular talent, and what could be unlocked if those connections could be made continuously and in all sorts of ways.\n",
    link: "/home/2021/05/25/talent",
  },
  {
    title:
      "Three requests for the Google Chrome team as they experiment with RSS",
    date: "17.30, Wednesday 26 May 2021",
    content:
      "I’m pleased to see Chrome experimenting with RSS feeds – and therefore possibly Google getting interested in increased RSS feed support. RSS is important! The interface is this:\n\nA ”+ Follow” button will appear for sites with an RSS feed, on the mobile browser\nThe browser’s home screen will include a “Following” tab that shows the latest news from followed sites.\n\n(Don’t know what RSS is? RSS feeds are how you can get the latest content out of websites and into dedicated “newsreader” apps which are made for reading, with an interface a little like Facebook but totally decentralised and un-surveilled. The technology was invented in 1999, and it’s still supported by probably 30%+ sites on the web with a ton of newsreader apps… but it’s had a moribund few years. There are signs of a recent resurgence, of which this is one. RSS is also the plumbing behind podcast distribution. For me, RSS is primary way I browse the web. Want to get started? Here’s how.)\nIn case the Chrome team reads this, I have three requests.\n1. Sweat the new user experience\nDespite RSS’s strong history and continued usage, at this point I would guess that new users find it inscrutable, and it’s hard to tell whether a given site offers an RSS feed or not. Even then, the subscribing experience is not consistent.\nSo, if this is going to be a success…\n\nEducate users about RSS. Here’s AboutFeeds.com (and why I built it) which is a neutral explainer to get started. Flag this, or something like it, wherever an RSS feed is detected.\nMake feeds self-explanatory. If a user stumbles on an RSS feed, don’t display ugly data, display a prettified preview like my own feed (and here’s how to do this yourself)\nAnd so on…\n\nFinally, recognise that the browser is not the best place read RSS feeds long term. We learnt that last time round.\nThe browser is a great place to get started, but users need to graduate to something dedicated as they follow more feeds. So pave that path somehow… maybe make a user’s subscriptions available as an industry-standard OPML file, somewhere on the google.com domain? And show users how they can use that subscriptions list in any one of a whole ecosystem of newsreaders.\n2. Yes, think about monetisation and other advanced features, but maintain ecosystem compatibility at all costs\nWhen I suggested three improvements to RSS last year, I highlighted (a) onboarding; (b) the money thing; and (c) discovery.\nThe money thing: In the Substack era of writers monetising their content, and with Apple and Spotify both giving podcasts a revenue model, it is absolutely the right thing to be considering how to extend RSS with a great premium experience, which means ways to pay, and also private feeds.\n(Jay Springett also makes the connection between Google, RSS, and payments and points out that this, strategically, a good way for Google to index content that will shortly be hidden behind a paywall.)\nThere’s a BUT…\nRemember that the reason RSS is here at all is that it’s almost religiously backwards compatible, and incredibly open. Technically, RSS includes an extension mechanism so take advantage of that, but to succeed, any efforts needs to be on a bedrock of community collaboration and unwavering commitment to backwards compatibility, decentralised approaches, and no new points of failure (people are still angry about Google Reader closing in 2013 and pulling the rug from many readers and publishers).\nThat said:\nAnother feature area I would think about is interactivity. I’m fascinated with Google’s work in Gmail around “Inbox Actions” – basically the one-click buttons to perform an email action like RSVP, or reviewing a bug. Here’s an explainer with some examples.\nLet’s call it Feed Actions. Feed Actions could also be an RSS extension. Here’s a mockup I made for a talk in 2008. What a gift it would be to the web, to provide an open, centralised way to combine all the different micro-task inboxes from all the apps I use, all into one place.\nGitHub should support something like this for their notifications dashboard, letting me triage issues straight from the feed; Amazon should support something like this for open orders, letting me inspect delivery status. It might be tough to get these into GMail, which is centralised, but as an open and decentralised standard? Possible.\n(Feed Actions would also be a good way to add an “Upgrade to premium” button.)\n3. Internally invest in, and externally advocate for RSS\nRSS, as a mechanism to subscribe to content from websites, is still around… but my take is that it has stagnated. Given the features above (like private, personalised feeds, with a slick upsell path), it’s worth pushing the envelope with some new use cases. And, Google, start with your own products.\nLike…\n\nWhat would it mean to have RSS as an output from GMail, using the “feed actions” idea above?\nCould I get my Google Analytics insights as an RSS feed?\nHow about a feed for new bookshops in my local area, from Maps?\nAllow me to include my RSS headlines in my search results knowledge panel\nA big one: how can RSS jump from the web to the app ecosystem? What would it mean for on-device Android apps to also publish feeds that can be read in standard newsreaders?\n\nMostly basic stuff but it shows commitment.\nWith a seat at the table and skin in the game, bang the drum for RSS and the open web. Like I said, it’s great to see early trials of RSS in the Chrome mobile browser and, for me, that’s a promising start.\n(And if anybody from the Chrome team does run across this post, thanks for reading!)\n",
    link: "/home/2021/05/26/chrome_and_rss",
  },
  {
    title: "On the impending deletion of Charlie Bit My Finger",
    date: "19.21, Thursday 27 May 2021",
    content:
      "The Mona Lisa is famous by accident.\nIn 1911, it was stolen. But it wasn’t famous at the time.\n\nAt the time of the “Mona Lisa” heist, Leonardo da Vinci’s masterpiece was far from the most visited item in the museum. Leonardo painted the portrait around 1507, and it was not until the 1860s that art critics claimed the Mona Lisa was one of the finest examples of Renaissance painting. This judgment, however, had not yet filtered beyond a thin slice of the intelligentsia, and interest in it was relatively minimal.\n– James Zug (Smithsonian Magazine), Stolen: How the Mona Lisa Became the World’s Most Famous Painting\n\nSomehow the news kicked off a media storm: Newspapers around the world came out with banner headlines. Wanted posters for the painting appeared on Parisian walls. Crowds massed at police headquarters.\nPicasso was somehow accused of the theft, arrested, and then released.\nAfter the painting was recovered, in the first two days, more than 100,000 people viewed it.\nAnd, although it is one of the most replicated pieces of art in the world: Today, eight million people see the Mona Lisa every year. – not that you can get a good view of it.\nReally now it’s famous for being famous.\nMy take is that there are periods when culture is particularly fertile for new memes to take hold.\nSome kind of perfect storm – a population looking for a cause or an idea; media looking for something to talk about; the First World War was brewing, maybe people needed a distraction; the conditions for a positive feedback loop… like too much dry undergrowth and not enough rain in fire season…\nWhich is maybe what also happens periodically on the internet?\nCharlie bit my finger - again ! (2007), 33 seconds, YouTube.\n884 million views.\nYouTube launched in February 2005; Charlie was uploaded in May 2007; it somehow went viral (do people still say that?); at a certain point it became famous for being famous. Like, you have to see this video of a baby, it’s somehow got a million views, and that adds another one. Fun fact! It was in Bin Laden’s video collection in 2011.\nSo some kind of meme amplification circuit connected itself by fluke.\nOnline video was still a novelty, perhaps candid video especially so; exponential growth in internet users, all looking for social objects to pass around and connect with friends, discovering for themselves for the first time the power of phatic communication; YouTube’s early algorithms locking in on a particular video to recommend; traditional media looking for ways to show the still novel viral nature of the internet without having to talk about viruses or worms… whatever it was that let this circuit self-organise. By October 2009, Charlie was the most viewed video on YouTube.\nPart of the allure of Charlie is its popularity. It caught the wave.\nWELL Charlie Bit My Finger was sold a few days ago, and now it’s going to be deleted from YouTube.\nOr rather, the family who uploaded Charlie Bit My Finger has sold a non-fungible token a.k.a an NFT for the video, which is like a certificate of “owning” the digital asset, to which other rights can be attached. (Here’s an NFT explainer.) NFTs for digital art are so hot right now.\nHere’s the closed auction page, which shows the final price of $760,999. The headline: Bid to own the soon-to-be-deleted YouTube phenomenon – so there it is.\nThat said, it’s unclear whether copyright is transferred, or whether deleting the YouTube-hosted video is mandatory. As I write this post, the original is still available, albeit with the title: Charlie bit my finger - again ! - Waiting on NFT decision\nI mean, good on the family for cashing in. Having an extra half a million quid in the bank can’t hurt.\nBUT\nMaybe this is like buying the Mona Lisa and locking it in a vault?\nIn the UK there is the concept of “saving art of the nation,” which is admittedly not uncontroversial, but the idea is that there are some quote-unquote Great Works that, when at risk of being sold to a private collector, a museum ought (and the government might) step in to purchase the piece and keep it in the UK. Export controls are handy for that.\nWhat’s the equivalent online?\nWhat’s the body that can step in and ensure historical digital artefacts are kept in place?\nYes there’s the Internet Archive - which has a vast scope and is a colossal achievement - but for me it’s not just about the data.\nI don’t feel like it matters that Charlie Bit My Finger is a digital artefact that can easily be downloaded, just as it doesn’t matter that there are a trillion postcards of the Mona Lisa. The YouTube URL is, in a way, arbitrary: /watch?v=_OBlgSz8sSM. But like a point of pilgrimage in the real world, it has gained it power by what has happened there and the many, many people who have visited over time.\nMaybe preservation for online artefacts is less like accessioning a physical item to a museum, and more like monumentalising – finding a way to set up a visitor centre, providing audioguides and staff dressed up in contemporary garb, and maintaining the site.\nDo we need a cyberspace historical landmarks service that has the power to prevent YouTube from deleting the video?\nAnyway.\nIn a small way this is personally resonant because, for a long while, I’ve had a draft blog post in my writing app with just the line: One day will be the final day that someone watches Charlie Bit My Finger – and has been my way into thinking about Deep Time, and how we can tell when a culture “ends” (and, maybe, another begins). So now I have to find another talisman to help me think about this.\nYouTube needs a program like the GitHub Arctic Code Vault or the Svalbard Global Seed Vault so we can reboot memes in case of cultural collapse.\nWhy Haven’t We Buried Charlie Bit My Finger In A Bunker On The Moon Yet.\nUPDATE 27 May, later: The Charlie NFT owner has decided to keep the video on YouTube – but the point stands. What will the next NFT owner decide? At what point should online content be regarded as part of collective culture, and worth preserving in place, whatever the “owner” says? And what is the body and mechanism to decide and enforce that?\n",
    link: "/home/2021/05/27/charlie",
  },
  {
    title: "From the archives, w/e 28 May",
    date: "13.46, Friday 28 May 2021",
    content:
      "Blog posts this week from years gone by.\n1 year ago\nA month long conference is a neat concept (24 May 2020).\n\nThey’re moving on from the standard two day conference format … our online conference program will take place weekly, across a whole month.\n\nI’m giving a talk next week which is broken up into 3 x 30 minute chunks across consecutive days. I still think there’s a lot to be explored in novel conference formats.\nHow I would put voice control in everything (26 May 2020).\n\nStick a timer in my stove, a switch in my light bulb, give each a super limited vocabulary, never connect to the internet, and only act when somebody is addressing you.\n\nAlso includes the idea of a dedicated attention sensor, so a device knows when it is being glanced at or pointed at.\nGrocery shopping, localism, and last mile delivery (28 May 2020).\n\nCorporations and startups will inevitably move hard into the last mile delivery space. How do we make sure it’s not shit?\n\nThe lockdown forced me into a kind of localism for groceries and I have to say I liked it.\n9 years ago\nZe Frank on ugly (22 May 2012).\n\n“In Myspace, millions of people have opted out of pre-made templates that ‘work’ in exchange for ugly. Ugly when compared to pre-existing notions of taste is a bummer. But ugly as a representation of mass experimentation and learning is pretty damn cool.”\n\nA classic Ze Frank monologue on personal expression, and an idea I come back to again and again.\n13 years ago\nThe geometry of music (26 May 2008).\n\nCause and effect are confused. Which comes first, the visualisation or the music? If Tymoczko watched a partner and I dancing, could he interpret the plan view of the ballroom as an orbifold, run his algorithms backwards, and play generated Chopin that was magically in sync with our improvisation?\n\nSadly most of the links in this post are broken. But the idea of a “reverse music visualiser” seems more achievable than it was when I wrote this post. Imagine staring out of a car window, and having the rhythms and regularities of passing traffic, street lighting, and clouds all style-transferred back onto Chemical Brothers beats played through your headphones…\nPosts selected from the On This Day archive spelunking page. This is an experiment to see how to best include old posts in the current feed in a meaningful way, possibly as a regular Friday feature.\n",
    link: "/home/2021/05/28/archives",
  },
  {
    title: "Taking shots from Einstein’s brain",
    date: "09.11, Thursday 3 Jun 2021",
    content:
      "I knew the beginning bit of this story from Joshua Cohen. I didn’t know the end.\nWhen Einstein died, IN 1955, his brain was removed during an unsanctioned autopsy at a hospital in Princeton.\nFrom there, a pathologist named Thomas Stoltz Harvey sliced it up but kept some for himself. He moved to Kansas, and gave one of the slivers to William S. Burroughs. Who died in 1997, and the sliver was passed to… Cohen demurs, because of this:\n\nLet’s just say that when I was in Lawrence, teaching at KU, this was a thing that still happened, a hazing that was also an homage: You scooped the bit of Einstein’s brain out of the jar and shook off the excess formaldehyde; then, you put some salt in the crook of your thumb and licked it, after which you took down a shot of cheap room-temperature tequila and sucked on the brain-bit until your mouth went numb-until the formaldehyde paralyzed your lips and tongue and you couldn’t be understood, you couldn’t even feel yourself trying to make language.\n– Joshua Cohen (Bookforum), Notes from the Cave: Searching for prophecy in the midst of a pandemic\n\nMy question is, given the moment and the opportunity, what would you do?\nThere’s an element of magic about this. Einstein’s brain is sacred, somehow, it has a kind of power, because of its association with Albert Einstein himself and his actions when alive.\nClearly I wouldn’t shoot tequila from just anyone’s brain. And there’s no actual eating going on. It’s not cannibalism. But if it was, say, Einstein’s sock I would most likely decline. In this particular case… probably?\nSo what we’re saying is that there’s a magical power, which has a force. And then there are forces that counter that force: natural disgust, effort made for the opportunity, and so on. The rest of the discussion is about constant factors and polynomials: what is the formula of the magical force?  It feels like this could be an empirical investigation, which is how all scientific breakthroughs begin.\nNow this is maybe an unexpected direction to take this post but, as a student, ex-PM David Cameron famously put his unmentionables into the mouth of a dead pig.\nThis is, at best, type 2 fun. And the question is, what wins out? The disgust at the act? Or the thought: “but yeah then I could say I did.” To put it another way, making use of the pig’s head is a magical act that generates status and power. Like, clearly you would feel like you had crossed some kind of threshold – to have done what others had not! And that internal knowledge will, by association, in the future make it possible for you to cross other thresholds that others could not. Magic!\nI have to say, I think if the opportunity came up, I might do the same. I think many people felt the same way, which is why - when the story came out in 2015 and many people mocked him about it - ultimately it did Cameron no harm.\nThere’s a famous quote from comedian Billy Connolly: Never trust a man who, when left alone in a room with a tea cosy, doesn’t try it on.\nSame same?\n",
    link: "/home/2021/06/03/einstein",
  },
  {
    title: "From the archives, w/e 4 June",
    date: "15.33, Friday 4 Jun 2021",
    content:
      "Blog posts this week from years gone by.\n1 year ago\nFiltered for musical cyborgs (29 May 2020).\n\nAnother article goes hard on how the beats aren’t humanly possible: The prosthetic arm can play the drums four times faster than humans.\nThe arm can also play strange polyrhythms that no human can play.\n\nIt’s a collection of links, mostly videos, about music instruments that are also cyborg prostheses.\nExperiments with projectors and video calls (4 June 2020).\n\nI’ve been posting recently about video calls and online talks. And, in the spirit of that, last week tweeted about a ridiculous experiment with an overhead projector.\n\nAha, that experiment was fun! That post was the write-up; here are the photos. Sadly I no longer have a wall behind me at my desk, so I can’t project over my head and “write” on the wall during video calls. But it would be neat to reboot this somehow.\n3 years ago\nFour short stories and what I learnt writing them (31 May 2018).\n\nI wouldn’t say I’m great at writing fiction. I find it tough. It is the easiest thing in the world for me to pick holes in what I’ve written. So instead, as an exercise - and as some personal positive reinforcement - I want to remind myself what I learnt writing each one, and also what I like.\n\nFrom time to time I write short fiction, usually sci-fi (though not lately). This post links out to four stories and what I learnt in the process of writing each one. I’m still pleased with this one, from December 2017: The search for another intelligence.\nPosts selected from the On This Day archive spelunking page. This is an experiment to see how to best include old posts in the current feed in a meaningful way, possibly as a regular Friday feature.\n",
    link: "/home/2021/06/04/archives",
  },
  {
    title: "What about a national packet-switched drone delivery network",
    date: "18.16, Monday 7 Jun 2021",
    content:
      "Maybe today’s focus on local road-based delivery robots is a dead end, and the last mile logistics world should be looking at packet-switching drones instead.\nThe Paris pneumatique poste was a pneumatic tube message-carrying service that operated in the French capital from 1866. It peaked at 30 million messages/year, and finally closed in 1984.\nWhy? There has always been a need to send short, quick messages (anything from chatting to stock market updates). But the electric telegraph was congested, and messages sent by road could be caught up in traffic.\nIf you want to know more, check out historian Dr Molly Wright Steenson’s work. In particular her piece Interfacing with the Subterranean (Cabinet Magazine, 2011): Read it here (pdf).\nMessages were small cylinders containing special postcard telegrams.\nIn 1931, La poste pneumatique began to automatically route the messages through the network.\n\nThe cylinders are propelled along the tubes pneumatically, ie by air either compressed or depressed: they are either blown forwards or sucked forwards from one office to another. The pressures come from compressors feeding groups of offices; these compressors were originally simple heads of water, then driven by steam engines, and finally by electrical machines. There are today 7 such installations, supplying pressure to 12 offices in the network.\nFor a long time the cylinders went from one office to the next where their contents were sorted for the next stages of their journeys. Much time was spent in the manual redirection of cylinders but, after experiments in 1931, automatic navigation was introduced using apparatus which could accept or pass on cylinders according to the setting of electrically conducting bands encircling the cylinders.\n– J.D. Hayhurst O.B.E., The Pneumatic Post of Paris (1974)\n\n(Do read that article. It has some fantastic photographs of the cylinders, complete with conducting routing bands, in addition to maps of the network.)\nNow the idea of store-and-forward networking is not new (that is: take a message, send it to an intermediate node, and then send it on).\nBut the introduction of automation in routing is exciting, and the next step in evolution for this kind of message routing is packet switching, which is the foundation for the internet, and that method wasn’t invented till 1966. (Loosely: Packet switching adds the ability to break a message into parts, and also “self-healing” routing where packets can adaptively avoid network congestion.)\nSo on the one hand the Paris pneumatic post is a redundant technology.\nBut on the other, maybe it only became redundant because the kind of messages it carried could be sent be other means. Maybe the underlying logic of a packet-switched internet for atoms is still sound.\nAnyway, here’s the bigger lesson I take:\nIf the telegraph is congested and the roads are busy, don’t optimise but instead create new capacity by adding infrastructure.\nHere’s an example of new infrastructure:\nWay back in 2011, I heard about Matternet, a new startup based around bring packet switching to the delivery world, using drones and smart recharging stations that double as routes (drones have a relatively short range). there was a write-up in The Economist.\n\nThe plan is to build a network of autonomously controlled, multi-rotor unmanned aerial vehicles (UAVs) to carry small packages of a standardised size. Rather than having a drone carry each package directly from sender to recipient, which could involve a long journey beyond the drone’s flying range, the idea is to build a network of base stations, each no more than 10km (6 miles) from the next, with drones carrying packages between them.\nAfter arrival at a station, a drone would swap its depleted battery pack for a fully charged one before proceeding to the next station. The routing of drones and the allocation of specific packages to specific drones would all be handled automatically, and deliveries would thus be possible over a wide area using a series of hops.\n– The Economist Technology Quarterly, An internet of airborne things (2012)\n\nUse cases such as…\n\nhospitals could send urgent medicines to remote clinics more quickly than they could via roads, and blood samples could be sent and returned within hours. A farmer could place an order for a new tractor part by text message and pay for it via mobile money-transfer. A supplier many miles away would then take the part to the local matternet station for airborne dispatch via drone.\n\nIt’s economic where infrastructure is not yet built out: A case study of the Maseru district of Lesotho put the cost of a network of 50 base-stations and 150 drones at $900,000, compared with $1m for a 2km, one-lane road.\nSo I had a look and they’re going strong!\nMatternet has recently announced a partnership with UPS in the US to deliver prescription medicine. They’ve been building standardised drones and standardised base stations. It all looks pretty neat.\nE-commerce\nAs Benedict Evans has analysed, e-commerce has seen a step change over the pandemic: In the UK, around 30% of relevant retail is now via e-commerce. It’s half if you exclude groceries. The picture isn’t as strong in the US, but the trend line is still up and to the right, and the pandemic has accelerated the shift.\nAnother stat from Evans: A third to a half of US (and UK) restaurant spending was actually ‘off-prem’ even before the internet.\nBut the rubber hits the road with e-commerce, so to speak, with last mile delivery (as I’ve previously discussed). How stuff gets to your home. And the two leading candidates have some not-so-great externalities:\n\nDelivery drivers. The race to the bottom in delivery has led to jobs at less than minimum wage, shoddy worker rights, and arguments about whether workers are employees at all. If delivery weren’t subsidised by venture capital and our taxes (somebody has to provide the social safety net), would e-commerce even be as successful as it is? Which is why everyone has been looking at automation.\nAutonomous delivery e.g. Starship delivery robots. I mean… great? But our roads are already congested, and could you see the number of deliveries say doubling using robots like these? At the expense of, well, neighbourhoods where kids can play on the street, where we can plant community gardens and sit out at tables, or even just buses. Perhaps the idea of using roads for deliveries is non-scalable.\n\nWe’re in a situation where the 20-30 year trend is clear, and technology might give us a few years of rinsing our existing infrastructure, but ultimately I’d argue that the solutions on the table aren’t up to it.\nBut maybe… Matternet?\nWe have the technology, so here’s what I would do, to prepare for 2050 and the ongoing shift to e-commerce, from a policy perspective.\nFirst: design an interoperable protocol for packet-switched drone delivery in theory over the entire country. The protocol has to include how a drone from provider A can recharge and route a parcel by landing at a station from provider B, but also how end-user billing and network peering fees work.\nSecond, partner with Matternet to manufacture the initial standardised drones and routing stations. But make it clear that the cost of this is giving up a monopoly position. Building out national infrastructure will require many providers profiting and competing.\nThird: allow neighbourhoods and local government to bid to be hooked up. For roll out, each street needs to give up a single parking place for a delivery drone routing station. Local houses can pick up parcels there; local shops can send deliveries there. Existing logistics providers like Amazon can inject parcels from dedicated stations. If there is network congestion, more stations can be added. Long distance deliveries can be added in network upgrades and trunk routing.\nI don’t think an effort like this would work if left to the free market. I’m not saying it should be nationalised, just that the state is a useful tool to unlock the coordination problems. This would be a good task for the national innovation agencies.\nDeliveries are increasing. Current strategies won’t scale.\nInfrastructure builds slow and then fast. ARPANET (and then the internet) was 4 nodes at launch in 1969; 100,000 nodes after 20 years in 1989 when the web was first proposed; and a billion nodes 20 years after that – an efficient, interoperating, exponentially-growing network for information.\nMy take: Now is the time to start work on the equivalent infrastructure for the physical world.\n",
    link: "/home/2021/06/07/last_mile",
  },
  {
    title: "Visual FX and cultivating a sense of wonder",
    date: "15.10, Tuesday 8 Jun 2021",
    content:
      "A few months ago, I ran across this behind-the-scenes look at some astounding sci-fi visual FX: \nVFX Breakdown - Dynamo Dream Teaser (YouTube, 2m27s).\nThe artist: Ian Hubert.\nIt shows the actors and camera tracking on the green screen, and then the final scene CGI rendered using Blender, a fantastically detailed and perfectly seamless 3D world. (The body rotation in the last few seconds that becomes a camera rotation in the rendered version is :chefs-kiss-emoji:)\nSo that was a teaser, and the first episode of the series came out!\n Episode 1 : Salad Mug - DYNAMO DREAM  (YouTube, 21m31s).\nThere’s some background:\n\nThe series is a mix of live-action and CGI that follows a salad merchant on a seemingly normal day through the dense streets of the Sunset District, a futuristic metropolis filled with fax machine drones, giant mutant crabs blocking traffic, and flying assassin bots.\n– The Verge, Go watch this incredible web series about a Cyberpunk Salad Merchant\n\nTwo moments early in this first episode:\n\nthe fan rotating the ceiling with fabric strips trailing and rippling behind\nrain on the window refracting the light, raindrops forming droplets and rivulets.\n\nWow.\nIt’s all artificial – simulations, created hand-in-hand by the animator and the machine.\nDoes the camera actually hold a microsecond longer so I can appreciate these shots? Or does it just appear to linger because I know that these shots are understated VFX flourishes from a virtuoso, and so my attention is amplified? A little of both I guess.\nLook, I’m not religious. But part of what I imagine it’s like to have faith that there is a singular creator of the world is that your attention holds, amazed,  gecko-tacky on every effervescent facet of nature all the time.\nOr not. Back when I studied physics, I would certainly go through periods where I would fugue out looking at my hands and thinking about electrons, or equivalently computers and transistors (condensed matter physics is wild). But it doesn’t last. Maybe that’s for the best.\nBut still I wonder about how to cultivate a sense of continuous partial wonder such that it is more likely that something in the everyday will catch you, just every so often. Perhaps that is one of the functions of keeping an observational diary, or of prayer.\nPerhaps it could be a pill. Microdosing cathedrals.\n",
    link: "/home/2021/06/08/vfx",
  },
  {
    title: "The Voder in 1939 and high-bandwidth input devices",
    date: "18.37, Wednesday 9 Jun 2021",
    content:
      "Computers are pretty low bandwidth when it comes to input. Fingers and and a couple square feet of looking, less with a phone. And not even much nuance. Swipes and taps, no vibrato or punching or feeling texture.\nBack in the day, the Voder was the first device for voice synthesis, invented by Homer Dudley at Bell Labs and demonstrated by Helen Harper at the 1939 New York World’s Fair.\nHere’s a video of the Voder in action (YouTube, 43 sec).\nThe user interface:\n\nA wrist bar: The operator could select one of two basic sounds (breathing or speaking).\nA foot pedal: pitch.\n14 keys to be used in chords to create various vowels and consonants, with several keys set aside for plosive sounds such as ‘p’ or ‘d’, and the affrictive sounds of the ‘j’ in ‘jaw’ and the ‘ch’ in ‘cheese’.\n\nAND SO:\nAfter months of practice, a trained operator could produce recognizable speech.\nAnother article:\n\nIt was a difficult and unnatural process, and only between 20-30 people ever even learned how to use it.\n– Atlas Obscura, The Voder, the First Machine to Create Human Speech\n\nOur phones must see humans as one big eye and one big finger.\nBut at this point, 78% of the world’s population has used a smartphone. When can these tiny computers stop catering for new users by default?\nLike, could computer input be full-bodied, high bandwidth? I want a computer which is more like a Voder.\nI recently heard about vim-clutch which is a foot pedal that makes a particular text editor even more efficient to use (this is a great description from 2018 and here’s the project page).\nI think of sewing machines, a device that requires a deftness of touch and also has a foot pedal, and I wonder whether Helen Harper, being the main Voder operator and one of the very few people skilled enough to play it, had experience with one.\nI’ve had a taste of high-bandwidth input controlling my Mac cursor with my head – which I still use from time to time. My expectation was that I would use head control as an alternative to a mouse, leaning back, but actually I find myself using the keyboard, mouse, head cursor, facial expression triggers, and a little speech-to-text dictation for short phrases all at once. I would like to try a pedal, maybe to switch between “coarse” and “fine” modes. But the interface isn’t really designed for this.\n",
    link: "/home/2021/06/09/voder",
  },
  {
    title: "Previously: Bridges, meat, diamonds (w/e 11 June)",
    date: "11.52, Friday 11 Jun 2021",
    content:
      "Some blog posts this week from years gone by.\n1 year ago\nSinging bridges (8 June 2020).\n\nI’m also pretty taken with the idea that we don’t know what the Golden Gate Bridge is singing about, other than it being windy. It tickles me that the bridge has its own internal life that leads it to sing, but it’s no more speaking to us than a blackbird. Why should the bridge want to tell us anything? And why would we be able to understand it if it did?\n\nWhat is the song of our cities?\n2 years ago\nMeat and gratitude (6 June 2019).\n\nFor me, I do continue to eat meat (although less than I used). But I think a lot of my discomfort around it - environmentally, the agro-industry, health - is displacement from the hard-to-digest fact that, when I’ve met a cow, they’re super nice to hang out with, and I could see us being friends. And that feeling isn’t going to go away.\n\nWe should say “thank you” to meat. Or stop eating it, I suppose.\n13 years ago\nThe source of a diamond (10 June 2008).\n\n“The source of a diamond is a kimberlite pipe, a form of diatreme–a relatively small hole bored through the crust of the earth by an expanding combination of carbon dioxide and water which rises from within the earth’s mantle and moves so fast driving magma to the surface that is breaks into the atmosphere at supersonic speeds.”\n\nThis is simply an extended quote from John McPhee’s monumental Annals of the Former World, and these two things are equally extraordinary: (a) how diamonds come to be; (b) McPhee’s command of the written word.\nRead the whole thing.\n(Another quote. Swoon.)\nSome favourite posts selected from this week’s On This Day archive spelunking page. This is an experiment to see how to best surface older ideas in the current feed in a meaningful way, possibly as a regular Friday feature.\n",
    link: "/home/2021/06/11/archives",
  },
  {
    title: "From Zoom Rooms to doorways on my desktop",
    date: "14.16, Tuesday 15 Jun 2021",
    content:
      "Zoom Rooms are called rooms but they don’t feel like rooms. I’ll tell you what does.\nI was speaking at Tweakers Developer Summit a couple weeks back – three talks on consecutive evenings. (Probably overambitious, and I was exhausted but there’s something that intrigues me about this experimental format, which I why I tried it, and I learnt a bunch. It worked! New narrative possibilities abound!)\nLet me lay out the facts of the speaker experience first:\n\nA few days ahead of the event, I received a link to my virtual room.\nI could visit the room and make it my own. So I could change the layout presets, turn features like Q&A and polls on and off, upload docs to present, rehearse and so on.\nAt this point, the doors were closed. General attendees, even with the link, would not be able to enter. At the bottom of the screen, there was a timer showing when the event was scheduled to start…\nOn the day of the event, as the time approached, I could see people entering an anteroom one by one. A waiting area. They got a countdown and a splash screen (which I think I could also customise) while I, from my room, got to see a list of people queuing up.\nWhen it got to about 40 people, I hit the button to go live, and everyone in the anteroom was brought automatically into my room. (I could have waited till the timer reached zero, but instead I opened the doors with about 30 seconds to go. It was neat to have that touch of agency.)\nBecause everyone entered at the same time, instead of trickling in, I was able to make this into a threshold event – no slow start here waiting for people to arrive, but a fun and immediate “hey, welcome!” and a high energy experience to kick things off.\nDuring the talk, I positioned my slides full screen – and my face also full height, right next to the slides, but narrow. (The chat occupied a sidebar on the right.)\nAt the end, I said thanks and goodbye and ended the event on my own terms by closing the room again - without waiting for a clock to run down, or fumbling for the “hang up” button - and the attendees were moved out to the “thanks and please rate” exit screen.\n\nWhat made this feel like a room vs dialling-in? Here’s what:\n\nIt was my own persistent room that I could customise, welcome people to, and so on. I had a calming 10 minutes sitting in my own before the talk, breathing and waiting, comfortable in knowing that all the tech was working, and watching people arrive.\nI was able to control the end-to-end audience experience because of good threshold design. Throwing back the curtains to bring everyone in was a wonderful moment! Great energy and no dead air. So there was good attention to liminal places and moments (the anteroom, the “go live” button). Software regularly ignores these. And in this case it made the event feel like a place.\n\nOne other feature I liked: I was able to communicate both information and energy simultaneously. Virtual events are hard because the speaker’s face carries so much emotional energy, and it’s often relegated to a tiny box. But you also need slides to riff off and give attendees an anchor. The non-traditional layout of this platform (my face in a tall but narrow window, portrait style, next to the slides) really worked. (I’ve talked about the interplay of slides and speaker before (7 July 2020).)\nKudos to the underlying events platform, Let’s Get Digital, for some thoughtful design choices that made a difference.\nSo we could extend these ideas to video call software…\nCould Zoom Rooms be persistent and customisable? What if I could set background wallpaper, and hook up a Dropbox folder to appear in an interactive panel? What if we could all do that together?\nCould Zoom pay more attention to thresholds? Like, could the “waiting for the organiser to start this call” screen be a place to gather, somehow? Could it include a mirror to check my hair, or a transcript of the last call to get up to speed?\nBUT\nI’m more interested in leapfrogging to something else: the OS.\nSocial features should be part of the operating system.\n(Here’s where I wrote about this before: Multiplayer docs, webcam fashion, noisy icons: three ideas (20 Nov 2020).)\nIn this case, I’m imagining that each video chat room is a window, just like a filesystem directory window. I can drag and drop documents into it, and they are immediately shared with the participants.\nOf course if I drag and drop a person out of the video chat window onto another document, that document would immediately become shared. Give it a special border to distinguish it. We can both edit it; both of our cursors are visible.\nEach room has an icon on my desktop (or I can file them away). Double click the icon, and it opens the meeting right away.\nNow I’m inspired by the 1981 Xerox Star, the highly influential early “desktop” user interface. I’m especially taken with the way the printer appeared as an icon on the desktop, as this lengthy retrospective explains:\n\nIn Star, printing is invoked via the Copy command: users simply copy whatever they want to print to a printer icon. No Print command is needed. Similarly, the function Send Mail is handled via Move: by moving a document to the Out-basket.\n– IEEE Computer, The Xerox “Star”: A Retrospective (1989)\n\nLet’s do the same and have the meeting room icon double as the anteroom. As people join the call, I can see their tiny avatars appearing over the icon. If I long press or hover my cursor over the icon – ambient noise, the muffled hubbub of people waiting. Perhaps they should even be able to knock. A doorway on my desktop.\nSo a challenge to Microsoft, Apple, Google: what are the OS-level hooks required for third parties like Zoom (and even web-based services) to integrate like this?\n",
    link: "/home/2021/06/15/doorways",
  },
  {
    title:
      "Horsehistory study and the automated discovery of new areas of thought",
    date: "12.23, Wednesday 16 Jun 2021",
    content:
      "This starts speculative and ends up in an interesting place: an algorithm for improving language. (My personal algorithm for new ideas appears to include: think about nonsense for longer than most others are prepared to tolerate.)\nThese words all start with horse-:\n\nHorsefly – a fly found near horses, fair enough\nHorseplay – totally understandable, but a metaphor that only makes sense if you have been friends with horses\nHorsepower – sadly not like “sea power”\nHorseradish – a root and a condiment\nHorsetrade – now a useful way to talk about an equitable negotiation that involved a lot of back-and-forth, originally I’m sure to do with horses\n\nNote that these are unlike: horsehair, horserider, horseshoe, etc, which are direct attributes of a horse. That is you could equally say “horse’s hair” and so on.\nSo it’s fun to invent other horse- words and speculate what they might mean. Some at random:\n\nHorsefunctor\nHorsehistory\nHorseorbital\nHorseroman\nHorsesane\n\nFor example, #1: Rob Miller suggested on Twitter: Black Beauty is my favourite horseroman.\nAnd that’s neat, right? “Roman” as in roman à clef, a novel not-so-secretly based on real life events, and Black Beauty is a novel about a horse. BUT ALSO maybe a horseroman could be like the famously equine senator appointed by Nero in Ancient Rome.\nLet’s blend those two and throw in some semantic drift, then define horseroman as one of those thought leaders who is appointed by the people in charge, but is actually way out of their comfort zone, and answers all questions with lengthy anecdotes about their own life. Like a bad TED talk.\nFor example, #2: Peter Bleakley pointed out that: The “horse” in “horseradish” is nothing to do with horses. It’s cognate with “coarse” and indicates “inedible”. Same as “horse chestnut”.\nSo let’s take that and apply it!\nMaybe horsehistory could be the socially uncomfortable parts of our history that we brush under the carpet? A useful new term!\n(Thank you Tom Carden for continuing this conversation on Twitter yesterday.)\nThe first analysis from a horsehistorical perspective\nThis section is a tangent but I want to show you that the concept is useful.\nI was never really taught about the British Empire or colonisation at school. Sure I knew about it, but it was always in the background, taken for granted. Sure there were some ugly aspects but aren’t there always.\nThen in my 30s I visited a museum in Kolkata and unexpectedly began to learn about the atrocities committed by my country, and the feeling of sickness and shame that started on that day has never left me. I have continued to educate myself. What’s worse is that I did know some of the events, but I hadn’t stopped to consider them.\nEmpire is not, in the UK, ignored history. We all know it. But when you grow up with something from before you can speak, and leave it unanalysed, you accept facts that you would never accept as an adult. I imagine it’s a little like abuse: if you grow up in an abusive household, it takes work as an adult to realise: that wasn’t normal! That was not ok!\nNow some of this is unconscious, but some of it is very much deliberate. We have leaders who do know history, who are able to talk about Empire (what it was, what we did, what we are still doing), but keep silent and make use of the idea of Empire (“Global Britain”, now). And because there’s utility in maintaining this myth in its unanalysed state, a kind of systemic resistance arises: anybody who does attempt to talk about Empire in an adult, clear-eyed way is aggressively shouted down. See the current culture war about “decolonising the curriculum” in universities which, to my mind, is simply about saying: let’s not take this history for granted.\nMy pet theory:\nYou can’t really talk about society as an individual, but give me this rope for a second. “British society” is aware of Empire and its atrocities, but conscious acceptance of that knowledge is repressed – for whatever reason: because it runs counter to our identity, because it is inconvenient, because then we would have to do something about it, because it was awful, take your pick.\nIn short, the history of the British Empire is impossible for British society to digest.\nIn an individual, repressed feelings find other ways to come out. So the repressed idea of colonisation came out as Brexit, which was this almost fanatical belief that we were being colonised by a larger state, EU. Or, to be blunt: that the pains that the British Empire had inflicted on others were now being inflicted on us.\nI read this as a way to psychologically square the circle of the repression: to say, it’s ok to avoid looking at the history of Empire squarely in the face, because look it’s fair now, we’ve been punished.\nAnyway, that’s my amateur read.\nIt’s also the first application of horsehistory: the study of undigestable histories and what they do to us. Agree or disagree with my analysis in this instance, the area opened up is interesting.\nMaybe this study could also look at the ways that horsehistories become regular histories, and how we could take British society through that journey (several other countries with atrocities in their past have been able to look at their history with clear eyes, act accordingly, and are healthier for it).\nOr we might also examine how horsehistories ossify over time (or not), or catalogue them globally, or re-analyse existing histories.\nA new word becomes a new lens for understanding the world.\nWords as coordinates in the space of all possible concepts\nBack to the horse- prefix. What does it do to words?\nIt’s not a straight modifier. Horseplay is not the play of a horse (not any longer), nor horseradish a horse’s radish. It’s an unexpectedly transformative operator, in a way that I don’t yet understand.\nMaybe: it’s a matrix rotation in embedding space?\nTo unpack that:\nAn “embedding” is how machine learning encodes concepts.\nA good example is word2vec, an old technique (old meaning 2013) that takes words and translates them into coordinates in a multi-dimensional space of all possible concepts. The set of coordinates is called the embedding.\nWhat’s neat is that the embeddings can be mathematically combined. That is to say:\nking - man + woman = queen\nIf you take the coordinates for king, subtract man and add woman, you get the coordinates for queen. Approximately…\nThe resulting vector from “king-man+woman” doesn’t exactly equal “queen”, but “queen” is the closest word to it from the 400,000 word embeddings we have in this collection.\nThat example is from the EXCELLENT guide from Jay Allamar, The Illustrated Word2vec.\nSo thinking about the concept horsehistory using this model and attempting to decompose it, what we see is that it’s not the mathematical addition of the horse embedding and the history embedding. The horse- prefix has mutated the history embedding somehow and turned it into something else. That mutation is what I’m referring to as a matrix rotation.\nLet me try another way:\nHave you every tried miracle fruit? It’s a berry with unusual property – it doesn’t have a taste itself, but it changes other tastes. In particular it rotates sour to sweet.\nSo I had some of these berries and was drinking beer, and the beer tasted like Fanta. Amazing! Then some time later, suddenly as I was crossing a road, the berries wore off and I tasted the inside of my mouth as if for the first time, and good grief it was disgusting.\nThe horse- prefix is the miracle berry of words.\nAnd also:\nNew words are addresses to previously unused embeddings in concept space.\nThe invention of new words provides new scaffolding for thought\nI think what I’m convinced by, with horsehistory, is that it’s worth developing new words.\nIn the sci-fi novel Native Tongue (Bookshop.org) about aliens, linguistics, and a fierce patriarchy, Suzette Haden Elgin supposes a new language for women. The creation of this artificial language is an act of resistance and also way to carve out a space for unique feminist thought and being. (It’s a stunning book.)\nIn Native Tongue, discovering a new word in this new language is a big deal: a new word, a new concept, a new “Encoding” as Elgin calls it, a new valid embedding in concept phase space, we might say. Finding a new Encoding rarely happens! Each Encoding is hard won. If somebody discovers/invents one or two, that is huge news!\nAnd so it is for us, I think. Discovering a new concept that isn’t simply a metaphorical framing, today, is rare and propels thought. Back to “Brexit” for a second: it derived from “Grexit,” itself a neologism (for Greece leaving the EU), but having been coined  it was possible to poke at it the concept, to discuss it, to ask about how it could happen and if so when and what it would mean, and so on, and without the word I believe the process would have unfolded in another way entirely.\nYes we can initially refer to these same concepts in other more cumbersome ways, but as single words it is possible to combine and manipulate more ideas that are more complex, and then they take on their own reality. Cheap referents have value.\n(Metaphorically, I’ve long believed that this process is what the Old Testament story of Moses receiving the Commandments is about, at least partially. There is an arduous journey - up a mountain - at which point some simple rules that are received, literally inscribed into rock. The rules are straightforward and lead to a long-term healthy and stable society, at least in this belief framework, but are hard to arrive at from first principles. The foundational ideas are too unwieldy and require a rare perspective. Similarly, great minds dedicate their lives to climbing their own mountains to claim complex insights similarly inscribed in simple terms and, having received the new concept in a graspable formulation and bringing it down the mountain for us, our whole society benefits.)\nThe question is: is it possible to move beyond Native Tongue? It’s slow. Can we automate the process of concept discovery?\nA reward function for the invention of new words\nYes there are ways to invent new words with AI. Take the website ThisWordDoesNotExist.com which generates a random word and a plausible definition (making use of GPT-2, the ancestor of GPT-3 which, as previously discussed is an idea machine). For example here’s one generated word:\n\ntokou\na black wine made from fermented soybeans cooked in molasses and yeast; “various African wines and tokou grape”\n– ThisWordDoesNotExist.com, tokou (noun)\n\nThe problem is that tokou isn’t as useful as, say, horsehistory (at least on first glance). We could sit there, refreshing the website, trying out each word to see if it’s handy, but that’s a bottleneck in the process and besides I would lack the domain expertise in most cases. So any algorithm will have automate that process too.\nHere’s the algorithm I propose.\n1. Invent candidate words and their definitions.\nEither invent at random, or use the method I ran by hand above: collide multiple embeddings and jiggle the result with semantic drift. That was how the horseroman concept was generated. An AI can do this.\nNow we effectively have two languages: English, which is the language we speak, and English-Prime, which is identical save for the addition of this single new word.\n2. Translate all of human knowledge into English-Prime.\nThis isn’t as hard as is sounds.\nGoogle Translate has used, since November 2016, a system called Google Neural Machine Translation. It’s a machine learning method of translation between language pairs.\nBut look closer at how it works…\n\n“Visual interpretation of the results shows that these models learn a form of interlingua representation for the multilingual model between all involved language pairs,” the researchers wrote in the paper.\nAn interlingua is a type of artificial language, which is used to fulfil a purpose. In this case, the interlingua was used within the AI to explain how unseen material could be translated.\n… The data within the network allowed the team to interpret that the neural network was “encoding something” about the semantics of a sentence rather than comparing phrase-to-phrase translations.\n– Wired, Google’s AI just created its own universal ‘language’ (2016)\n\nIn short, Google Translate has an intermediary language that exists only in the form of embeddings.\nSo, even without training data already written our new English-Prime, we know how to represent it in language space: it’s identical to English but with a single extra embedding available. And if we know that, Google Translate can translate into it. (Exactly how is left as an exercise for the reader.)\nWhich means that step 2 is to automatically translate all of Wikipedia into English-Prime.\n3. The reward function: test whether the new word is useful\nWhat does useful mean? Machine learning has the idea of a “reward function”: how do we state what good looks like? If we can do that, the process can run automatically.\nFor horsehistory it meant that the word acted as an intuition pump (philosopher Daniel Dennett’s term): by examining what it could mean, it took me to a place where complex ideas were reached and could then be articulated more efficiently.\nSo what is our reward function? Simply:\nCompare the word count of Wikipedia in English and the word count of Wikipedia in English-Prime. If the latter is shorter, i.e. more efficient, then the proposed new word is useful.\nRINSE AND REPEAT.\nEach new term is a new place to start thinking. Give each its own journal and academic conference and see what happens.\nLet me summarise.\nBy way of speculating about a single new field of study, horsehistory, I have proposed a general method for the automatic generation of many new fields of study.\nIn the same way that Magnus Carlsen is a “centaur” chess player, a player of chess greater than any other human because he has trained with a custom AI and benefited from the wisdom of this machine which is effectively 200 data-years old, the method I propose leads to a new discipline of centaur philosophers, thinkers who are able to systemically reveal new scaffoldings for thought, far beyond what would ordinarily be reached in a single human lifetime, to more rapidly develop and examine new ideas for the betterment of society at large.\nOr the whole thing is horsefeathers. Take your pick.\n",
    link: "/home/2021/06/16/horsehistory",
  },
  {
    title: "Ignoring carbon, is energy use bad or fine?",
    date: "15.12, Thursday 17 Jun 2021",
    content:
      "This is a gap in my mental systems model of the world, so any references appreciated:\nLet’s say we have extremely cheap, zero carbon electricity.\nI’m not bothered by the mechanism but say for argument’s sake: super efficient biophotovoltaics – sufficiently advanced versions don’t exist yet, but imagine we invent what are essentially solar panels but instead of electronics they host water and thin sheets of genetically engineered algae, drinking the sun and pissing out electricity.\n(I’m not clear on the carbon cost of manufacturing regular solar panels, but they include enough weird materials that I want to factor that out. I’m assuming that our fictional future algae can be bred simply with plant mass, light, and water, so there are minimal carbon or extractive problems. i.e. if you want more power, you buy any sort of tray, fill it with water, scoop in some existing algae from an existing tray along with a food solution, and dip a couple of wires to join it to the circuit.)\nAssume we’ve all got these on our roofs, and there are fields of them everywhere. Also ignore batteries: with abundant production, unused energy is just thrown away. Electricity is now crazy cheap to buy, and there’s next to no carbon impact.\nDoes that mean it’s ok to run my tumble drier 24x7, have a thousand drones swarming round my house just for entertainment value, drive everywhere all the time in my own personal electric vehicle, run a massive Bitcoin farm in the attic, and spin up a fleet of mining robots that continuously fuse sand into giant transparent cubes and build kilometre-tall solid glass pyramids in the Sahara, just for kicks?\nBecause of our focus on carbon, and the fact that carbon is still a huge cost of electricity, I’ve gotten accustomed to the idea that electricity use is, in itself, something to be minimised. But maybe not?\nMaybe energy use is actually fine, if the carbon footprint of energy production is zero, and we ignore the manufacturing footprint of the powered items? That’s how it seems but perhaps I’m missing an externality somewhere.\n",
    link: "/home/2021/06/17/electricity",
  },
  {
    title:
      "Previously: Spreadsheet parties, chatbots, William Gibson’s jacket (w/e 18 June)",
    date: "10.06, Friday 18 Jun 2021",
    content:
      "Three recommended blog posts from the archives, originally published this week in years gone by.\n1 year ago\nFrom the other side of the bridge (12 June 2020).\n\nThere’s a story about William Gibson’s jacket. In his book Pattern Recognition he confabulates a jacket for the protagonist, Cayce, in a colourway that never existed.\n\nAnd where it ends up: Both the molecular structure of benzene and the molecular structure of DNA were brought back from dreams.\nFiltered for hallway tracks and spreadsheet parties (15 June 2020).\n\nSo if we’re doing conference talks on video now, how do we do the hallway track? And should the two remain bundled together?\n\nI still haven’t seen a virtual events platform which gets the spontaneous, in-between nature of the conference hallway track. This is a “Filtered for…” post which means it has lots of external links.\nAlso this is an idea I should come back to:\n\nPersonal theory: as we’re at home more, and smartphones ebb, the technology that succeeds will be the technology that facilitates multi-tasking.\n\n6 years ago\nOn conversational UIs (16 June 2015).\n\nMy point, I guess, is that a new medium needs a new grammar and conversational UIs are definitely a new medium.\nFor one – they’re intrinsically social. If I’m chatting with a bot in iMessage about what movies are on nearby, shouldn’t I be able to turn that into a group chat with my partner? And does the bot conduct two separate conversations, one with each of us, or assume we’re both searching for the same movie?\n\nRemember chat bots? They were going to be huge. Hey and it might still happen! Large language models (i.e. GPT-3 and the like) are making natural language easy for computers, and conversational user interfaces make a ton more sense if we’re using smart watches and smart ear buds instead of phones.\nThis post still gets a bunch of traffic and it’s a fun read – it has a ton of examples of different conversational UIs, and breaks down the challenges in making conversation the primary interface.\nPersonal favourites selected from this week’s On This Day archive spelunking page. This is an experiment to see how to best surface older ideas in the current feed in a meaningful way, and I’m trying it as a regular Friday feature. Keep-going/why-not-try-this-instead feedback welcome.\n",
    link: "/home/2021/06/18/archives",
  },
  {
    title: "All kinds of online marketplaces are creaking under scams",
    date: "18.16, Tuesday 22 Jun 2021",
    content:
      "I put out a shout for a graphic designer on Twitter a couple of days ago. I was bombarded by direct messages from accounts that presented as people, and talked like people, and tweeted like people… but their portfolios were stuffed with generic logos clearly pumped out by software. Opportunist individuals, side-hustling their way to projects they then outsource? Or paint-by-numbers design farms that use fake “young designer” bots as a sales channel?\nThen there are the Instagram ads for well-photographed products with well-put-together brands – that I then find on Alibaba being sold directly out of multiple factories. Ditto when you search on Amazon for digital scales for baking, or wristbands for running with key pockets, or STEM toys (to pick three recent examples) and the results are swamped with semi-identical products from a dozen different brands.\nExcept for the disingenuous authenticity, it’s unfair to call these scams. The system is functioning as intended. The system was design as a marketplace, and indeed buyers are being connected to sellers… only there are invisible intermediaries who are excellent at targeting the channel but contribute zero added value.\nThough there are also actual scams to be found elsewhere:\n\nApps on the Apple App Store that pay for promotion, and fool users into extortionate subscriptions. (It only needs to work for a small percentage to be profitable.)\nFacebook ads for products that take your money and never ship. (I’m pretty savvy and do my due diligence, but even I’ve been fooled once or twice.)\n\nIN THE MIDST OF THIS there are legit new companies starting, and legit new people to work with. But it’s getting increasingly hard to find them (and once found, trust them) through the noise of the scams.\nWhat spam is to communication, scams are to marketplaces.\nOnly there’s no way I can install an anti-scam filter.\nMy hunch is that after 20+ years of scaling marketplaces of all kinds, reducing friction and increasing activity, we’re hitting a wall similar to the malware wall hit by Windows (and ultimately “solved” by the shift to managed computing led by iOS), the spam wall hit by email (Gmail’s spam filter was a band-aid; ultimately comms moved off email into WhatsApp and corporate messaging), and the disinfo wall hit by large social network (not yet solved, but we can see attempted solutions in form of private Discords and the rise of the other cosy online spaces). Like these, the fix isn’t just more of the same. \nSo assume this problem is getting worse. What is to be done?\nTwo solutions from history no longer work in 2021:\n\nBrands. A brand is a hostage – you know the company won’t do anything awful because they risk a brand which has taken time, money, and good behaviour to develop. Call it reputation. But we consumers can’t tell reputation directly, we can only look for signifiers: have we encountered the brand a lot; do other people appear to transact with it; does it look expensive; etc. And online, all of those signifiers are cheap to fake. A new scam brand can be indistinguishable from a established yet new-to-me trustworthy one.\nRetailers. The other problem with brands is that you do want to buy from new ones, so one role of trusted retailers - in the past - has been to pass on that trust to the brands they select. Our brains believe that trust is a transitive property. But it isn’t: trusting Amazon doesn’t mean you can trust the merchants; trusting LinkedIn doesn’t mean you can trust the approaches you get there. Is there room for a retailer just like Amazon only it carefully vets all its merchants? Sadly I don’t believe so: a retailer is also about footfall, and such a selective retailer will never become the default shopping destination that Amazon is. Besides, we need a solution that works for Facebook ads (no Amazon) too.\n\nI can speculate…\nWhat if every brand had some kind of digital certificate, and anybody in my trusted networks could anonymously certify that they had had a good experience? (By networks I mean: mutuals on Twitter, Facebook, and Instagram; people I correspond with on email; and so on.) My initial model is HTTPS, which guarantees that your web browser has a connection with a certified endpoint, and no intermediaries have futzed with the data. \nAnd then the certificate would be displayed as a badge wherever I see that brand in a channel, whether as a Facebook ad, in a list of Amazon results, via search, or on their own website.\nMaybe instead of social signals, I could subscribe to a service that whitelists and blacklists brands, and use that as my source of trust instead. Perhaps credit card companies could also feed into it: when a purchase is made, the digital certificate transfered with the payment authorisation, and attached to any future chargeback or refund.\nThis would be something presented as an overlay on existing large web properties, so it probably has to be independent from them and built into the browser somehow. Instead of being yet another startup, could it be a protocol someone, something that everyone could adopt, large and small?\nThe key point is to decouple trust from the retailer itself (as marketplaces such as Amazon are unable to provide this), and to make the badge visible on every single discovery surface.\nI’ll leave it as an exercise for the reader to extend this to freelancers and LinkedIn. To my kind it’s a similar-shaped problem. Neither is about identity (you are who you say you are) but about misrepresentation (your implied characteristics are the same as your actual characteristics).\nWe need big, distributed, imaginative solutions.\nSEMI-RELATED:\nHere is a story about the first thing I ever bought online.\nBack in the late 90s there was this new thing called e-commerce. i.e. buying stuff on the web.\nSo in 1997 or maybe early 1998 I decided to buy something online for the first time. I mean, typing my credit number in an online form and everything, not just selecting from an online catalogue.\nBut I decided that, because e-commerce would plainly dominate in the future, I would purchase something that was in some way emblematic of the whole absurdity of e-commerce, to mark the occassion.\nHere’s a photo of what I bought. I still have it. (Or rather: it lives in my mum’s garden.) It’s a garden ornament.\n\nIt’s ugly. It’s a grotesque!\nIt’s super heavy. Exactly the wrong kind of object to send through the post.\nIt’s not real. It’s not a stone ornament, it’s made of resin and filled with sand for the weight.\n\nSo it tickled me to get this nasty simulacrum as a kind of conscious foreshadowing of the rest of my online life.\nBut knowing what I know now, I should be thankful that I didn’t receive just a photocopy of a picture of the thing in an envelope, or that it actually turned up at all.\n",
    link: "/home/2021/06/22/brands",
  },
  {
    title: "Every so often I remember Mitterrand’s horrific last meal",
    date: "20.15, Wednesday 23 Jun 2021",
    content:
      "Every so often I think about the last supper of ex French president François Mitterrand, which had a horrifying beauty. He was dying of age and a long illness.\nThere were oysters and so on, a feast, then a dish called ortolan.\nIt’s a small songbird. To prepare it, the ortolan is drowned in a glass of Armagnac. This is not a metaphor. It is actually drowned, and then it is cooked in a cassoulet.\nIt is illegal, but some chefs will make it.\nThen to eat it (which is how Mitterrand ate his):\nYou place a white cloth over your head and pick the bird up with your fingers, and then you eat it whole, wings, feet, organs, head, everything except the feet. The ortolan is supposed to represent the soul of France.\nThe white cloth is to create a closed sensory world of just taste and scent.\nThe cloth is also, traditionally, to hide the act from God.\nAfter the meal Mitterrand didn’t eat again (by choice it seems). He died 8 days later.\nThere was an extraordinary article in Esquire in 1998 by Michael Paterniti telling the story of ortolan, and Mitterrand’s meal… and also Parterniti’s experience in recreating it himself. It’s visceral prose.\n\nHere’s what I taste: Yes, quidbits of meat and organs, the succulent, tiny strands of flesh between the ribs and tail. I put inside myself the last flowered bit of air and Armagnac in its lungs, the body of rainwater and berries. In there, too, is the ocean and Africa and the dip and plunge in a high wind. And the heart that bursts between my teeth.\n– Micheal Paterniti (Esquire), The Last Meal (1998)\n\n(Paterniti also did this programme with NPR in 2008 which is a shorter read.)\nI don’t know what keeps drawing me back to this story.\nIt’s shocking, for one. Real shock seems rare in the WEIRD 21st century, like boredom and like awe. I don’t mean shocking like a jump scare, or overwhelmed with horror. I mean the act has this enduring shockingness. No matter how many time I go back over the story, it’s this flawless crystal of beautiful, exquisite taste indivisibly joined to a central horrifyingly barbaric act - the drowning - like an equation somehow. The context in which Mitterrand chose the meal is part of it too. It seems emblematic of so much of the privilege and progress we have today, individually and as society, beauty with an horrific core, irreconcilable you would have thought. An artist or a writer would be able to decipher what’s going on, to diagram the entire thing, but for me it’s like staring at a Rothko painting. I can’t tell you why I can’t look away, but there it is.\n",
    link: "/home/2021/06/23/songbird",
  },
  {
    title: "Vending machines should be the Shopify of physical retail",
    date: "12.18, Thursday 24 Jun 2021",
    content:
      "Here’s a man in Japan who sells home-cooked curries from a vending machine (YouTube, 2 mins 35 secs). I like this quote in particular: I have been running my vending machine business for about 40 years.\n(Thanks Andrew Eland for sending this video my way.)\nFor a few years I ran a tiny bookshop in a vending machine, so obviously I am super into them (here’s a list of more), but the reason why is related to what the curry cook in Japan said: a vending machine is a minimum viable retail business, neatly packaged and tied up with string. A  shop in a bottle.\nI would love to see neighbourhood vending machines by busstops and in the corners of coffee shops, maintained by local individuals with handy essentials (battery packs, masks, sanitary products) and their own creations and hobbies: home cooked meals, soft toys, second hand books… really anything you see a friend starting as a side business on Facebook.\nBut it’s not easy, and I learnt a lot about what could be better.\nInventory management and operations\nA major cost of a vending machine is the time taken to check it and restock it.\nBy connecting my machine to the internet (and a custom back-end), I automated inventory tracking – but two manual processes for me were setting the prices in the machine, and creating the “shelf talkers”. That’s the message underneath each item which has the marketing copy. It would be neat to have these in e-ink and set remotely from software, instead of having to print them each time.\nThere are some additional possibilities here: creating the “planogram” (the physical layout of the merchandise on the shelf) should be automated. Items at eye level sell better, so knowing about turnover and margin would help optimise the machine.\nSo inventory management is basically software for known workflows and a robust Internet of Things platform.\nMetrics and distribution\nLook at the way e-commerce works, particularly the idea of the funnel. Top of funnel, users are attracted from all kinds of channels: Facebook, ads on the tube, and so on. They’re moved towards purchase with marketing messages, and this process is measured and the messaging tweaked. Finally the purchase flow is also instrumented: do more users complete the purchase when the “Buy Now” button is at the top of the page or the bottom? You bet that the e-commerce site owner has tested that and they know.\nNone of this exists for vending machines.\nYes there are metrics: it would be awesome to see a dashboard of the footfall around the machine, the percentage converted to dwell within 3 feet of the machine, the percentage that starts hitting buttons to select an item, and so on. This could all be done with privacy-preserving sensors, and it would help to optimise locations.\nBut mainly I mean distribution: if a shopping website could only entire potential customers if they had already come to the website, it wouldn’t last very long. That’s the state that vending machines are in today. So how can they cast a wider net?\nMy attempt was to have the machine tweet every time it sold a book. That was a way for people, hopefully nearby, to get a timely reminder about the machine so that they would make a visit.\nBetter would be some kind of app that would let you see what vending machines are nearby, and pre-purchase items. How great would it be to go “oh, I need a battery pack” – then purchase it from the app, and it tells you what machine to pick it up from on your commute home.\nSo an integration into transit apps or Google Maps would also be useful, but being able to “follow” your local machines on Twitter and other social media feels like the more fun way to do it.\nAnd then is it possible for the relationship with high-value customers to be retained and perhaps they could be offered a coupon if they haven’t visited for a month or two? All doable with e-commerce; that kind of detailed calculus is common. With vending machines? It needs some imagination.\nTechnology and integration\nUltimately I wrapped up the machine because everyone moved from cash to cashless, and replacing the coin changer with a card reader was going to be a whole bunch of work that I wasn’t in the mood for. Vending machines are pretty modular inside so the technology is ancient and fiddly but not a huge pain – it’s mainly that a card reader means having a merchant account and a monthly fee going to  an old-school payments company. No easy Square readers here.\nReally what you want is Apple Pay, loyalty points, reserved items, discount codes, upsell offers, all of that good stuff! But you’ll have to build it all yourself.\nSo none of what I’ve described above is insurmountable, in itself, but cumulatively it’s out of reach of the kind of people who would run independent vending machines – just as running an indie online store was out of reach for creators until Shopify came along.\nHere’s a stat for you: About 44% of new food businesses started since the first lockdown are home-based, says BBC News.\nI have a friend with one of these new food businesses. She sells soup. There’s a lot of leafleting and delivery going on. Like the curry guy, how great would it be if she could also have a vending machine sitting somewhere nearby?\nLook, I don’t believe there’s a venture scale business in operating vending machines directly. The margins are too low and the operations cost is heavy.\nBut what we’ve learnt from e-commerce is that it’s a game of a thousand micro-optimisations. You measure every flow and improve each step just 1%… and added up, that’s the difference between loss and profit.\nThe current ecosystem is in the dark ages comparitively. Machines are expensive to buy and expensive to customise with software and poorly integrated. That’s frustrating.\nAlso frustrating are Amazon Lockers. Imagine having that amount of internet-connected robot real estate in great locations, and not providing a way for merchants to promote and sell their own goods to the neighbourhood!\nSo I do think there’s a startup in re-inventing the vending machine and becoming the Shopify of physical retail. Not one giant store but, like Shopify, a network of a million tiny ones. You’d create the machine and the software, and bring everything we know from online retail to physical, unattended retail, providing that as a platform to independent creators and nascent shopkeepers everywhere.\nTell you what, I’ll be an advisor if you start it.\n",
    link: "/home/2021/06/24/vending",
  },
  {
    title: "Previously: eye contact and puppy slugs (w/e 25 June)",
    date: "14.56, Friday 25 Jun 2021",
    content:
      "Two recommended blog posts from the archives, originally published this week in years past.\n1 year ago\nEarly web videos, eye contact, and anti-attention (22 June 2020).\n\nHow about a pair of augmented reality glasses with an app to manipulate everything I see, ensuring that no-one, no matter how charismatic, could hold my gaze for longer than 3.2 seconds?\n\nThe idiom of YouTube vlogging is straight to camera, eyes locked, and that was invented back in 2006. Zoom is all about eye contact too. But eye contact is a unconscious engagement amplifier (and also fatiguing) – wouldn’t it be cool to have an anti-eye-contact feature built into the computer?\n6 years ago\nFiltered for computers and birds (19 June 2015).\n\n“We ask the network: ‘Whatever you see there, I want more of it!’ This creates a feedback loop: if a cloud looks a little bit like a bird, the network will make it look more like a bird. This in turn will make the network recognize the bird even more strongly on the next pass and so forth, until a highly detailed bird appears, seemingly out of nowhere.”\n\nIt turns out that, approximately 6 years ago, we saw the announcement of DeepDream (Wikipedia), Google’s computer vision/image generation/dreaming AI technique that created photorealistic images out of thin air, with a tendency to diverge into trippy fractelesque image montages in which bizarre animals could be found worming their way out of the corners: puppy slugs.\nThe door was opened: the rekindling of AI as something that could operate in the human realm, deep fakes and the undermining of reality… I can’t believe it has only been 6 years. It’s great to look back on some of those early pieces and see what an impact it had.\nPersonal favourites selected from this week’s On This Day archive spelunking page. This is an experiment to see how to best surface older ideas in the current feed in a meaningful way, and I’m trying it as a regular Friday feature. Keep-going/why-not-try-this-instead feedback welcome.\n",
    link: "/home/2021/06/25/previously",
  },
  {
    title: "Trillies is better word than FAANG",
    date: "17.20, Monday 28 Jun 2021",
    content:
      "I recently ran across the term the trillies to refer to trillion dollar market cap companies, which are currently: Apple, Microsoft, Amazon, Alphabet (Google). (Bubbling under: Facebook, Tencent, Tesla.)\nWhich I like because it doesn’t take them too seriously. Like, they have so much power in the world, it’s nice to have a name which deflates their bubble just a tiny bit.\nCompare: FAANG. That’s the usual term that people reach for. It’s an acronym for Facebook, Amazon, Apple, Netflix, Google, and if I were one of those companies then I would love to be called FAANG. It sounds like they went on a stadium tour in the 80s. I can probably get a FAANG t-shirt at Urban Outfitters.\nSo I’ve only ever seen trillies used once, in one thread online, and the person who said it claimed they made it up themselves, but I hereby give notice that it is my go-to term from here on out. Please adopt it too and let’s see if we can get it into the Oxford English Dictionary.\nLIKEWISE:\nI would also like to offer billies for billionaires, as in the tier of very rich men in the world (90% of them are men) who do slightly ridiculous things like competing to be the first billionaire in space, or attempting to reverse ageing by consuming literally the blood of the young.\nI used to (in my head) call them the International Legion of Billionaires in honour of the fact that, as a society, we seem to rely on them to fund global health programs, or to direct the surplus of production into the space programme or renewable energy – all great things I’m sure, but I’d prefer to be making those allocation decisions democratically.\nBut given that we are treating our billionaires as characters in some kind Oligarchy Cinematic Universe - we need a 21st century Jane Austen to document their lives - and the mean time between absurd events is steadily decreasing, I am now mentally calling them “silly billies” instead.\n",
    link: "/home/2021/06/28/trillies",
  },
  {
    title: "Cultivating a sense of the galactic centre",
    date: "20.51, Wednesday 30 Jun 2021",
    content:
      "About 10 years ago I cultivated a sense of the direction of the centre of the galaxy.\nI’ve lost the knack now, but it was something I would do while I was waiting for the bus each morning.\nAt the beginning, I used the night sky app Star Walk. It has an augmented reality view, so I would swing the phone round until I found the constellation Sagittarius, and if you look in that direction and head about 26,000 light years, you get to the supermassive black hole at the centre of the Milky Way, Sagittarius A*.\n(The light reaching the centre of the galaxy right now will have left the Earth 26,000 years ago, the Upper Palaeolithic, around the time of the invention of weaving and permanent settlements.)\nSo I would end up pointing through the pavement, or down a street, and thinking, huh, that’s where it is. And it’s a nice trick if you can do it, but it’s better when you can do it at any time, without an app. Which is what happened.\nFirst I got good at figuring out the ecliptic. That’s the flat disc of the Earth’s orbit (and the solar system). If you wave your arm along the path that the Sun makes across the sky, that’s the disc.\nThen I can’t remember how I would locate Sagittarius each day (it lies on the ecliptic) but I trained my intuition by checking the app each day. Over the weeks and months, I could follow how the position changed (at the same time each day as I caught the bus). First through the ground that way, then under the ground further that way, and so on.\nEventually then I had this picture of myself, and the Earth, and the solar system, and the centre of the galaxy which had initially been whirling round me, and now it had flipped, I was turning around it.\nIt was wildly situating.\nThe feelSpace belt uses vibrating motors and neuroplasticity to give humans a sense of “north.”\n\nEvery morning after he got out of the shower, Wächter, a sysadmin at the University of Osnabrück in Germany, put on a wide beige belt lined with 13 vibrating pads – the same weight-and-gear modules that make a cell phone judder. On the outside of the belt were a power supply and a sensor that detected Earth’s magnetic field. Whichever buzzer was pointing north would go off. Constantly.\n“It was slightly strange at first,” Wächter says, “though on the bike, it was great.” He started to become more aware of the peregrinations he had to make while trying to reach a destination. “I finally understood just how much roads actually wind,” he says.\n– Wired, Mixed Feelings (2007)\n\nThe brain is super good at incorporating this new sensory input. The result? Eventually, I felt I couldn’t get lost, even in a completely new place.\nI’ve never tried this, though I would love to. Periodically there are semi-commercial versions:\n\nNorth Paw by Sensebridge: an ankle bracelet\nNorth Sense by Cyborg Nest: a chest wearable\n\nBut I haven’t yet seen something that I could imagine myself wearing every day for a few months. I would like it as part of my Apple Watch. (Could that be done?)\nSome animals do have a sense of north! Birds can literally see the Earth’s magnetic field – and it’s possible that humans have a north sense too (as previously discussed).\nHOWEVER: I did have a glimpse of what this would be like.\nA few years back I visited Marrakesh.\nThe old city is a tangle of roads and alleys and souks and neighbourhoods. It’s fun (and inevitable) to get disoriented and lost.\nBut one particular day we set off from a junction back to our riad, only to end up back at the junction 30 minutes later. So we set off in another direction… and 30 minutes later we found ourselves back there. Repeat. Repeat.\nThen we realised that all the buildings had satellite dishes, and all the satellite dishes were aligned south. So matter how turned-about we got, we could always have a sense of the cardinal directions. It was an incredible moment. I had a tiny peek at how a swallow sees the world, the door opened just a crack to the magnetosensitive avian umwelt.\nThe satellite dishes oriented me in the city just as a sense of the location of Sagittarius A* oriented me in the galaxy.\nAre there words for the cardinal directions of towards/away/etc with respect to the galactic centre? Galinwards. Galockwise.\nSo I wonder about the best way to re-train myself as to the location of the galactic centre? I enjoyed the perspective. It’s been a decade.\nIn my imagination I see an iPhone app which displays a 3D model, connected to the gyroscope and the compass and the GPS.\nIt would show, diagrammatically, the sphere of the Earth and a sharp line where I’m standing, and the ecliptic and the Sun, and glowing at the edge of the disc of the ecliptic: the constellation of Sagittarius. Then a floating arrow labeled, “Galactic Centre: 26,000 light years.”\nThe whole thing would be in 3D, centred on the icon of me standing on the Earth, and it re-orient as I moved the phone in my hand. So the 3D arrow would point the way. Perhaps it would buzz with increasing intensity until I pointed the phone the right way. Perhaps even it would bother me with a notification at a set time each day to have a guess!\nThe purpose of showing all the moving parts is to help with building intuition.\nMaybe it’s an app. Maybe it’s a mobile website. Every so often I poke around at trying to build this for myself (there are a bunch of astronomical coordinates code libraries out there). But there are slightly too many things I would need to learn for it to bump its way to the top of my project list.\nWhich is why I’m sharing it here. I’d love to have a go if you make it.\n",
    link: "/home/2021/06/30/galaxy",
  },
  {
    title: "England is dense with ancient folktales",
    date: "19.26, Wednesday 7 Jul 2021",
    content:
      "Southampton, which is where I went to school and near where I grew up, was once upon a time terrorised by a giant named Ascupart.\nA knight named Bevois (this was about a thousand years ago) came to the Southampton and dealt with the giant. Exactly how, stories differ. Either he defeated and killed Ascupart. Or other tales say that Bevois, Ascupart, and Bevois’ horse named Arundel became great friends and had many adventures.\nI didn’t know this story growing up. I read it in a book recently. But there is an Arundel Castle some way to the east, and a neighbourhood of Southampton is named Bevois Valley, both of which I knew about, and (I’ve now learnt) an Ascupart Street too. Stories in the landscape!\nHere is the story of Bevois and Ascupart, as told by storyteller Michael O’Leary. It’s a fun read.\nThis class divide is new to me:\n\nThe stories of Bevois, or Bevis, were once as popular as the stories of King Arthur. The stories of Arthur, however, were considered a bit more grand and courtly; the Bevois stories were for the common people.\n\nOh ho!\nThe book I’m reading is The Lore of the Land: A Guide to England’s Legends, from Spring-heeled Jack to the Witches of Warboys, by Jacqueline Simpson and Jennifer Westwood. (Review in the Guardian.)\nIt seems you can’t walk a mile through England without tripping over a hyperlocal folktale, and this book catalogues them.\nLeafing through at random right now, I can tell you that:\n\nIn Mordiford, Herefordshire, a little girl called Maud found a baby dragon in the woods, which was bright green and about the size of a cucumber.\nStaffordshire: St Matthew’s church at Walsall was said in the nineteenth century to have been moved to its present site by fairies.\nIn Eyam, Derbyshire, a farmer’s wife made a pudding and boiled it over the fire. But it jumped out, rolled around, and then broke, at which point a child came out who cried: Take me to my dathera dad, take me to my dathera dad.\n\nNot in the book, but stories I’ve heard…\nI can tell you that near where I live in south London (and by near I mean, “within 20 minutes walk”):\n\nThere is a wild patch of the local park which is said to be where Queen Boudica oversaw the battle of Londinium and then died and was buried.\nThere is an oak tree which was knighted by Queen Elizabeth when she got drunk and rested there.\nOpposite our house there is a straight line to be drawn along walls, alleys, a footbridge, and the backs of houses which represents an ancient walk for nuns to go from a convent (unknown) to a particular church (unknown) without being seen. I only know this one because I was peering behind a house, having noticed this phantom patchwork making up a direct line, and a passing runner stopped and told us.\n\nAnd it turns out that the legend of Spring-heeled Jack, the leaping figure with metal claws who struck fear into London in the 1830s, is centred on Peckham, also just walking distance. (Spring-heeled Jack is an interesting figure, a modern folktale or, as previously discussed, a consensus ghost.)\nIt is dizzying. I guess it is like this everywhere in the world? I don’t know. The land is dense with ancient stories! Every stone under every step, richly encrusted with narrative barnacles.\n",
    link: "/home/2021/07/07/folktales",
  },
  {
    title: "Cultural anticipations as an algorithm for divining the future",
    date: "17.27, Thursday 8 Jul 2021",
    content:
      "I am struck by the concept of cultural anticipations, here mentioned in High Frontiers 4 (1988) by shaman and psychonaut Terrance McKenna, as related by Thomas Rid:\n\nThe early internet was evolving fast. Yet McKenna was ahead of his time. To him, a new form of planetary connection was emerging: “Through electronic circuitry and the building of a global information system, we are essentially exteriorizing our nervous system, so that it is becoming a patina or skin around the planet,” he told High Frontiers. “And phenomena like group drug-taking and rock-and-roll concerts and this sort of thing,” he said, “these are simply cultural anticipations of this coming age of electronic-pooling-of-identity.”\n– Thomas Rid, Rise of the Machines: A Cybernetic History (p186)\n\nCultural anticipations! The existence of which implies the following algorithm for divining the future:\n\nLook for new behaviours.\nView those behaviours not as a phenomena in their own right, but as symptoms resultant of something else underlying and not yet in the present – either a psychological reaction against, or a pre-appropriation coping strategy toward, or some other kind of response.\nGuess at what the impending something underlying is – and in this way, you discover the truth about the future.\n\nWhat this method proposes is the future already exists, in some sense. Future events and future configurations of society are immanent in the world’s collective unconscious – we can’t name the future, we can’t talk about it, we can barely consciously feel it approaching, but the future is there and as real as the sluggish yet titanically unstoppable currents in the magma layer deep below the Earth’s surface.\nSome people are sensitive to cultural tachyons - these particles that travel backwards through time - artists and poets and those with a certain madness - but what I like about this method is that it doesn’t rely on the individual: it’s a method of divination from dowsing the collective unconscious.\nSociety itself is a vast, gossamer scientific instrument to detect faint ripples from the future.\nThis is what has previously excited me about GPT-3. As a Large Language Model, GPT-3 was trained on a snapshot of the world’s text made in late 2019. For example, it is knowledgeless re Covid-19.\nBUT:\nWhat if there were a new GPT-3 made every 3 months? And then we looked for diffs between the models, plotting them like global weather maps? Would that reveal the telluric currents of the collective psyche? Could we use that to forecast the future?\nThe possibility of automating the augury algorithm!\nPerhaps they are easier to recognise in retrospect.\nFor example: Stewart Brand’s 1966 campaign Why haven’t we seen a photograph of the whole Earth yet? (here’s Brand’s personal recollection of the campaign). Or really, the whole drive towards computing machinery and networks to think and act more powerfully and collectively, since the 1950s, and the development of the “global village”…\nI read all of these as cultural anticipations of the Anthropocene, the realisation that humanity can and is acting on a planetary scale, for good and ill – but only popularly named in the year 2000, despite the fact that the whole 20th century was this slow lift of history to a rolling boil.\nWe’ve got the cultural tools and the perspectives we need to deal with today’s challenges (if only we use them). But somehow they were created just in time… in anticipation?\n",
    link: "/home/2021/07/08/anticipations",
  },
  {
    title:
      "Previously: Bernard Vonnegut, sociopathic dating, a Facebook camera (f/e 9 July)",
    date: "11.15, Friday 9 Jul 2021",
    content:
      "Six recommended blog posts from the archives, originally published this fortnight in years past.\n(I’m enjoying rediscovering old posts, but these “Previously” summaries were coming up too regularly. So I’m switching them from weekly to fortnightly.)\n1 year ago\nSpace, weather, and other novel battlegrounds (30 June 2020).\n\nI guess what I’m just realising is that, at some point, someone had to realise that “cyberwar” could be a thing. And what was that process like, exactly? Did some bright kid write a memo that got the attention of the boss and the boss’ boss?\n\nALSO, this factoid: Bernard Vonnegut (Kurt Vonnegut’s brother) was a chemist who discovered in 1946… cloud seeding. Artificial rain.\nIdle thoughts about how we replace keyboards (3 July 2020).\n\nCould I use a swiping keyboard by drawing in the air and having it picked up by a nearby camera?\n\nIdeas for replacing smartphone keyboards with something better – and perhaps something more future facing for augmented reality.\n2 years ago\nA lengthy ramble through many responses to that FaceTime Attention Correction tweet (4 July 2019).\n\nThe latest beta of iOS 13 came out, and there’s a feature called FaceTime Attention Correction which, on video calls, silently manipulates the image of your face so that you’re looking the other person directly in the eye. Which on first blush to me sounded cool (eye contact is good! Maybe?) but on further thought made me do a weird face.\n\nThe feature ended up not shipping. The collection of responses is varied and fascinating: concerns from an autistic perspective, excitement about the possibility of deep emotional engagement at great distance, and a prediction from one correspondent that we should come back to: within 3 years you won’t even need the camera to make video calls.\n6 years ago\nFiltered for coherent narratives (6 July 2015).\n\nMixtape of the Lost Decade: “evidence is mounting that points to a ‘lost decade’ between what we now remember as the 1970s and 1980s.” Art, toys and music are all rediscovered – a distinct era, the 19A0s.\n\nAlso about how modern art was a CIA weapon.\nSome good links in this one.\n9 years ago\nFacebook should make a camera (3 July 2012).\n\nFacebook are interested in camera apps (they have two: their own, and Instagram). They should make the hardware.\n\nThis was before smartphones went hard on cameras. 9 years ago! But there are still ideas here that would make sense now: There should be a dedicated ‘photo wallet’ Facebook album, and the front-facing screen should be used for a dedicated showing off function.\nAnd:\n\nIf you want the killer feature… Facebook should build on Facebook Chat to support video, and make this camera a video chat device. Hangouts (easy, social video chat) is the stand-out amazing feature in Google+, and Facebook should be looking to compete.\n\nThere are current rumours of a Facebook smartwatch with two cameras. Better late than never! Well perhaps.\n13 years ago\nOperant conditioning, dolphin training, and dating (3 July 2008).\n\nThat is: a couple dating should have available manufactured, reciprocal, variable-interval operant conditioning, with a pay-off timed to the artificially produced extinction burst, to trigger mutual addition, and they should be able to buy this in a shop.\n\nStarting with dolphin training, this is a concept for a deck of cards that a newly dating couple can purchase to cause them to fall in love. Which is, uh, only mildly sociopathic as an idea?\nSEE ALSO: that famous New York Times article To Fall in Love With Anyone, Do This (2015) which tests a psychological study about a series of questions that, when answered by two strangers, will cause them to fall in love. It’s a good read. If you want to try it yourself, here are the 36 questions.\nPersonal favourites selected from this week’s On This Day\narchive spelunking page. This is an experiment to see how to best surface older ideas in the current feed in a meaningful way, and I’m trying it as a regular feature, now every 2 weeks on a Friday. Keep-going/why-not-try-this-instead feedback welcome.\n",
    link: "/home/2021/07/09/previously",
  },
  {
    title: "Plaid shirts and existential reassurance",
    date: "17.23, Monday 12 Jul 2021",
    content:
      "I pulled on an actual collared shirt last week because I was meeting a friend for lunch, a plaid shirt, and I happened to have a call first before going out.\nAs I started the video before the meeting, I caught sight of myself in the webcam preview and the chequer pattern on my shirt. “Aha,” I thought automatically, “I’m not in a simulation.”\nDavid Cronenberg’s eXistenZ (1999) is about a virtual reality video game, and you see some of the movie in-game and some out of the game. (It’s aesthetically unlike anything else – the game pods are pulsating meat objects, connecting is, um, highly charged, and the setting lacks the usual tech signifiers. It’s low key rural.)\nThere’s some confusion about what reality is (a kinda pre-Inception Inception thing going on) but it turns out that the in-game scenes are subtly visually signposted. Here’s Cronenberg:\n\n… we were replicating some of the style of some video games. If you want a character to wear a plaid shirt, it takes up a lot of memory, so it’s much easier if he has a solid beige shirt. So I was trying to replicate the blandness or blocking’s of the polygon structure of some games.\n– Sight and Sound, Game Boy (1999)\n\nIncidentally that is a FANTASTIC article and you should totally read it. Cronenberg expounds on the nature of reality and also dips into cyborg ideas. And Chris Rodney, the author of the piece, produces turns of phrase that you just know you’d be looking at the screen and quietly nodding in satisfaction if you managed to pull off something like that yourself:\n\nAlthough the “reality bleeds” continually signalled throughout the movie are not an original device, they presage a massive narrative haemorrhage at the end, so much so that it’s impossible to give an in-depth synopsis of the film without literally giving the game away.\n\nNarrative haemorrhage!\nI don’t remember reading that interview at the time but I must have done, or one very similar, because Cronenberg’s costume design trick is a thought that lives in my head now for, yes, 20 years and more and emerges from time to time: oh yes, that’s a shirt texture that would cost a bunch of clock cycles to render, I must be in reality right now, good to know.\n",
    link: "/home/2021/07/12/plaid",
  },
  {
    title: "Dolls’ houses and demo modes",
    date: "20.48, Tuesday 13 Jul 2021",
    content:
      "In a roundabout way, because of dolls’ houses, I’ve been thinking about special modes in software to let you learn by playing and teach by showing.\nThe 17th century dolls’ houses are found in the Riksmuseum in Amsterdam just around the corner from the Vermeers and the Rembrandts (including his Night Watch, freshly extended by 2 feet using AI).\nHere they are: They’re beautiful. I stay so long to look whenever I’ve been. They’re models of real houses, and not toys; they were a hobby, the equivalent for women of the collection cabinets kept by men.\nOne particular dolls’ house, collected by Petronella Oortman, has furniture made using the same materials as the regular sized versions: Her dolls’ house cost as much as an actual house on a canal!\nSo these are objects of art, meant to convey taste and wealth.\nI heard somewhere (I can’t remember where) that the models were meant to be closed up and carried with you when you travelled. An effective way to show off your domestic style to your friends in the days before photographs.\nA dollhouse nowadays is often a toy. Often exquisite, yes, but primarily a canvas for the imagination, mostly for kids, a place for fantasies and stories and play. The dollhouse-as-art still exists, but it’s not what I think of first.\nThere is a third type of dollhouse, historically, as this article in The Atlantic says: simulation.\n\nBeginning in the 17th century, “Nuremberg kitchens” might contain a hearth, cooking pots, a straw broom. These all-metal houses were designed without ornament, for purely utilitarian purposes. Used as teaching tools for girls, Nuremberg kitchens allowed mothers to show daughters how to set up and control a house. All about learning rules, a Nuremberg kitchen was the opposite of a dollhouse as a dream world of fantasy. It was a place where girls learned to manage not only the objects of the house but also its servants, where girls would learn to become the lady of the house.\n– The Atlantic, Dollhouses Weren’t Invented for Play (2016)\n\nHomes are complex organisms! I can imagine seeing the flows of goods into the kitchen, where the butler sleeps, what happens below stairs when you ring the service bell; how the clockwork hangs together.\nWhat a wonder to have a demo version to play with before running your own for real.\nThe original SimCity game (1989) hit these same three notes:\n\nScore. A place to create detailed cities to show your skill.\nStorytelling. A backdrop for fantasy and play – what else was the “monster” option in the Disaster menu for? (And of course The Sims later went hard on this.)\nSimulation. A sandbox for learning about complex systems – I vaguely remember that the game was used by people in local government to get a grounding in the intricacies of urban planning.\n\nASIDE: TWO LINKS:\n\nYou can play a port of the original SimCity in the browser. It’s super low-fi but no less addictive for that. Here: MicropolisJS.\nIt’s possible to max out your score. SimCity 3000 (1999) was beaten with a totalitarian hellscape called Magnasanti. It’s quite the effort: The Totalitarian Buddhist Who Beat Sim City (Vice, 2010).\n\nImagine if Twitter had a simulation mode.\nSocial media is already a place to socialise and tell stories. The sites are mere backdrops.\nMySpace showed that these social spaces should also allow for customisation, construction, and skill. It’s a crying shame that Twitter and Facebook don’t do likewise. I would love to decorate my profile with images, FAQs, links to my favourite communities and so on (others would share music and creations). This is a common lament when you get a bunch of old school social software nerds together.\nBut training?\nWhat would a “Nuremberg kitchen” version of Twitter look like?\nWhat if every social network also had a single-player “learn how this works” mode. All the accounts would be deepfakes with machine-made faces, all the posts procedurally generated. When you posted, you would get realistic responses. It could teach you, by use and example, how to identify fake news or pile-ons or toxic content. You could experiment yourself in a safe sandbox where everything is thrown away at the end of the session and invisible to the outside world.\nBy letting you act out and take things to extremes, would you develop a better intuition about what’s worth taking seriously on Twitter… and what’s not?\nBack when I was building Job Garden (which is sadly no longer), one of the first features I built was DEMO MODE.\nHere’s the write-up: All products should have a demo mode (Week 9).\nIt was an admin-only feature in the top nav that let me quickly construct job boards and navigate them in different ways. I found it invaluable to\n\nquickly give anybody I was talking to an interactive, guided tour of the site. Because it functioned just like the real site, I could take whatever route I wanted around it, adjusted my narrative to the flow of the conversation. But because it was in a sandbox, I could delete and edit to customise without fear.\non my own, experiment with how the site looked in different scenarios, rapidly assembling a job board and seeing how it felt with live data.\n\nMy favourite Demo Mode feature was “share.” It worked like this:\nIf at any point in the demo I created a configuration that the person I was talking to liked the look of, I could hit the Share button and it would generate a code I could email to them, or even write down on a bit of paper. Using that code would lead them through the account setup process and then transfer the configuration they had seen into their new account. It was the most effective onboarding technique I found.\nI’d like a button on Google Sheets that put my work into a mode where I could experiment wildly and without fear that any of my saves might be overwritten.\nI’d like a button, when I get a new hire car, that lets me play with the steering wheel and all the buttons and sticks, and lets me get a feel of the weight of the pedals and the heft of the gears, but without it ever moving anywhere.\nI’d like an iPhone mode where I can show somebody how to change settings and sort photos and send messages, and let them play around with all the switches to see what they do, reassured that when the mode closes, no changes will be retained, and nothing actually sent.\nI’d like a model of my home to try out solar on the roof, or Airbnb over the summer, or a different kind of budget. A house is a machine for living in and I’d like to better learn the levers.\nSo I wonder about single-player sandboxes, simulations, demo modes, and teaching tools. They all feel of a kind.\nAnd they all feel like something that dolls’ houses got right and modern technology, so far, has not.\n",
    link: "/home/2021/07/13/dollhouse",
  },
  {
    title: "Idly thinking about frozen heads",
    date: "18.14, Friday 16 Jul 2021",
    content:
      "Cryonics is, says Wikipedia, the low-temperature freezing and storage of a human corpse or severed head, with the speculative hope that resurrection may be possible in the future.\nIt was one of those things that got a lot of airtime in the 80s. Alongside the free market, crop circles, and spontaneous human combustion. Not so much now. But the idea was that people would be frozen indefinitely.\nSo there are just… frozen heads? Scattered around in freezers in storage lockers?\nIt turns out, yes. Though not so many. Just a couple hundred.\nThe storage system:\n\nThe new vitrified you now goes into what is essentially a large upright thermos that’s about 10 feet tall and 3.5 feet wide.\nYou meet your new neighbors-three other vitrified people, each in their respective quadrant of the thermos, along with five people traveling super lean, with no body, whose heads are stacked in the middle column.\n– Wait But Why, Why Cryonics Makes Sense (2016)\n\n(Isaac Hepworth shared this with me on Twitter. Thanks?)\nALSO: the bodies are stored upside-down.\nThis is in the event that the staff forget to top up the liquid nitrogen (a weekly process) for whatever reason: upside-down patients means it would take six months before the nitrogen boiled off so far that the head would be exposed.\nI wonder what sequence of events led to this being standard practice.\nTHINGS THAT HAVE HAPPENED.\nThe famous image of liquid nitrogen is that somebody puts a rose into a jar, then lifts the rose out and smashes it with a tap.\nWe discovered during lab at uni that you can pretty safely put your hand into liquid nitrogen, so long as you don’t close your fist and get any under your nails or whatever – the trapped liquid will freeze your flesh. (My bench-mate accidentally dropped in their lighter; they panicked to get it out before the technician came round to find out what was going on, and put their hand in without thinking. Aha they were fine. So we all had a go.)\nThe liquid nitrogen boils furiously when in contact with your skin, which is obviously much warmer, and this makes a layer of gas which insulates your hand from getting too cold. For the few seconds I held my hand in the liquid (-195 C, -320 F) I could only imagine a dense swarm of angry bees throwing themselves at my skin.\nPlease do not blame me when you try this yourself and get hurt.\nThere are some troubling economics in keeping dewars stuffed with bodies (and no bank accounts) topped off with liquid nitrogen basically forever. Instead it might be a better idea to front-load a known cost, paid in advance, and place the body somewhere really cold incurring no annual maintenance fee.\nI suggest Halley’s Comet. Basically we cache the vitrified brains temporary here on Earth and then land them on Halley’s Comet next time it appears in 2061. Then every 75 years, as it comes around, there’s an opportunity to either (a) bank more heads; or (b) retrieve the stash. Any society able to unfreeze and reanimate ancient brains will surely be more than capable of running a cometary fetch-and-return mission.\nLooking at the stats for life expectancy at birth:\nWomen born in the early 1980s, or more recently, can expect to see the next return of Halley’s Comet.\nMen born in the late 1980s, or more recently, can expect to etc.\nBorn longer ago and you have to outperform your age cohort. Sorry Gen X-ers.\nIt’s stuff like this that makes me realise how hard it is to see the motivations of ancient societies. Like, the incredibly preserved people found in peat bogs. Did they too have a belief that they would someday be reanimated?\nMaybe the practice of self-mummification is something that appears in every society, in some form or another, throughout history?\nSEE ALSO: Sokushinbutsu, the rare Japanese practice of self-mummification by Buddhist monks. As previously discussed.\n",
    link: "/home/2021/07/16/cryonics",
  },
  {
    title: "Billionaires in space and bottling the overview effect",
    date: "17.21, Tuesday 20 Jul 2021",
    content:
      "Let’s suppose that seeing the Earth from space genuinely does trigger a spiritual experience leading to an appreciation of the fragility of life and a step increase in empathy. Then I propose that we pathologise the syndrome that going to the Karman Line fixes, and get millions of people cured as soon as possible – by going up and over, or otherwise.\nIt’s called the overview effect, a psychological effect that creates powerful shifts in the way you think about Earth and life. (That link is a NASA podcast episode with Frank White who coined the term in 1987.)\nHere’s Edgar Mitchell, Apollo 14 astronaut:\n\nYou develop an instant global consciousness, a people orientation, an intense dissatisfaction with the state of the world, and a compulsion to do something about it. From out there on the moon, international politics looks so petty. You want to grab a politician by the scruff of the neck and drag him a quarter of a million miles out and say, “Look at that, you son of a b–.”\n– People magazine, Edgar Mitchell’s Strange Voyage (1974)\n\nAfter coming back from the Moon in 1971, Mitchell co-founded the Institute of Noetic Sciences, researching human potential and parapsychology such as clairvoyance and psi.\nSo in recent weeks Richard Branson and Jeff Bezos, silly billies, have been racing to be simultaneously rich and also riding on their own ships technically into space and back.\nVirgin Galactic’s SpaceShipTwo (Branson) and Blue Origin’s New Shepherd 4 (Bezos) each spent a couple minutes in space – according to their own definitions: 50 miles up for Branson; 62 miles/100 km up for Bezos, the so-called Karman line.\n(Straight up and down for both. Neither attempted the 17,000 mph sideways velocity required to enter orbit.)\nThe semiotics of the crew outfits are fascinating. Virgin Galactic suits are straight out of the Marvel Cinematic Universe (BBC News), blue and gold out of a material that looks like some kind of sci-fi synthetic, textured with dimples and flight booties too. Blue Origin also went for blue space onesies (BBC News) and I’m guessing there is a legit reason for this convergent suit design – safety in the case of cabin depressurisation maybe? Looks like it would be fiddly to pee in any event.\nBut honestly it looks like astronaut cosplay.\nIt’s space tourism I know. Both these companies will be selling seats, and I sincerely hope that customers get to take their suits home with them, mission patch and all and, I don’t know, wear them to the pub or whatever. I am into the idea that the fashion concepts explored in these overalls somehow trickle down into everyday streetwear.\nALSO: both companies are going pretty hard on the overview effect. For example, PR from Virgin Galactic.\nIs this just marketing?\nLike, are they bigging-up the Earth-from-space perspective shift because that helps sell seats at $250k a pop… or is there really a profound psychological effect from those couple of minutes seeing the sky go black and the curve of the Earth and the weightlessness?\nAn aside about the politics of the thing.\nLook, proceduralising access to space is awesome. A real step in the right direction. The engineering accomplishment alone is awe inspiring.\nI’m impressed. I watched the YouTube live streams. Well done to everyone involved.\nHowever I am increasingly uncomfortable with society’s surplus being directed by billionaires and not democratically. Deciding whether we spend money on space or homelessness is a decision for the state and not for the hoarders of capital. No matter how benevolent they are now, should we be ok with decisions about the direction of society being made be people just because they are rich? And how did they get there? As Alexei Sayle said: Show me a millionaire and I’ll show you 999,999 people short of a quid.\nTHAT SAID: the US’s growing private space programme has had heavy state aid along the way. New Mexico paid for Virgin Galactic’s spaceport; NASA funds the flights via research contracts. Blue Origin has benefited from NASA development contracts, though it’s mostly funded directly by Bezos. But Bezos’ wealth comes from Amazon, and Amazon’s warehouse employees are big recipients of welfare. Perhaps if they were paid properly, the US government wouldn’t have to support them, but the Bezos couldn’t afford to support Blue Origin. So there’s a kind of invisible state support going on there too.\nWhat I’m saying is that I would prefer to see both Virgin Galactic and Blue Origin as a triumph for smart state investment over many years.\nHolding up the billionaires as heroes in these situations is misleading and tells everyone that something is going on that really isn’t. The success belongs to everyone. To present it otherwise undermines democracy and manufactures consent for oligarchy.\nBack to the overview effect, which should be studied methodically.\nBecause if the overview effect is real then business leaders and powerful politicians should be sent into space, asap. It should be a condition of office or of being a billionaire that you viscerally acknowledge the oneness of life.\nI remember hearing that the breakthrough with Viagra was getting “erectile dysfunction” in the book of official pathologies, and this seems like a clever trick (as previously discussed).\nWhat pathology does the overview effect cure? Let’s call it negempathy.\n(Named in honour of the slightly outdated scientific concept of negentropy, big in the cybernetics era and also in mid-20th-century sci-fi.)\nNegempathy: the lack of common cause with other life on Earth; the absence of appreciation that we’re all in it together; a disease of the body politic; the inability to care.\nIf people, especially powerful people, can be vaccinated against their negempathy, then let’s go for it! Line them up at the spaceports! And then once they’re done, set up a conveyor belt for everyone else: once you hit 16, bang, you get your four minutes in space.\nAnd you come back down wanting to save the planet.\nHaving named it, perhaps the mechanically-induced overview effect isn’t the only inoculation against negempathy. Could there be a chemical cure?\nGlobally taxpayers and philanthropic organisations have spent billions on researching and rolling out Covid-19 vaccines. And the pay-off is worth it: it turns out that 3 billion vaccines, at a cost of $40 each, is worth $17.4 trillion to the global economy, a value of $5,400 each (source). It’s a huge bargain. So that justifies all kinds of investment into vaccine capacity acceleration.\nNow think of the climate emergency: what is the cost to the global economy of each month’s delay in setting global carbon reduction targets? It must be staggering.\nImagine that cost could be reduced, just by buying select members of the political elite seats on Virgin Galactic and Blue Origin. So let’s do that.\nBut ALSO let’s find ways of reducing the cost further, and rolling out the overview effect faster to millions and billions of people.\nMaybe psilocybin?\nWhat if a precision-calibrated psychedelic effect could be captured in a test tube, the Karman Line in a vial, transcendence, the results rolled out in something like the global vaccination program?\nSomebody ought to be researching the heck out of this.\n",
    link: "/home/2021/07/20/overview_effect",
  },
  {
    title: "The stock market is a machine for creating cults",
    date: "17.43, Wednesday 21 Jul 2021",
    content:
      "I’ve been naive about stock ownership. That is, stocks traded on the public markets like NASDAQ and FTSE.\nMy old mental model was that holders of stocks were partial owners by virtue of them owning, well, shares. Owners can vote, in theory, on company decisions. It’s a bit abstract because mostly the mechanism is that you vote for directors, who are shareholder representatives, a bit like elected political representatives, and they take company decisions on your behalf. And then there are passive owners who are simply there for the ride, waiting for the value of the company to go up and therefore the value of their stock.\nFurthermore, the natural value of a share is tied to the future anticipated value of the corporation.\nBut my old model ignored the dynamic and social nature of the situation. My eyes were opened by this line in Economic Science Fictions (book homepage):\nshareholders in corporations are expected to agree or sell their shares (p44).\nConsequences:\nA diverse shareholder base does not moderate decisions, in itself. Those who disagree will simply sell their shares. Voting doesn’t matter.\nALSO: The price of a share will increase (in line with demand) when there is growth in the number of people in the shareholding population AT LARGE (not just current owners) who agree with company decisions.\nBUT individual shareholders are strongly incentivised to increase their own wealth.\nWhich means that, for shareholders to profit via increasing share price, there is an incentive for those shareholders to encourage others to agree with company actions.\nThere is also the reverse incentive: if a shareholder disagrees with company actions, they would be wise to keep silent until they have sold their shares (and once they have sold, they have no incentive to say anything at all). \nShareholders turn into evangelists. That’s the function of the market. Profit-seeking stock holders will spread the word and squash dissent, purely from self interest.\nThere is a cult aspect to the publicly traded corporation. That’s my new mental model.\nIt’s intrinsic to the way the market works. So the big question about meme stocks (being stocks where the value is determined by online communities piling on) is not: why did they take off in 2021. But instead: how did it take so long for the underlying truth to come to the surface? All stocks are meme stocks.\nLet me caveat that. I’m not saying that the pricing mechanism for any given share is exclusively cult-like behaviour.\nBut another of my long-standing mental models is perturbation theory. Quick summary: you find a way to crudely describe the coarse shape of a dynamic system first, then you add on finer and finer “perturbations” to make your model more accurate. But to a first approximation you only need the first bit.\nPerturbation theory doesn’t always hold – it breaks down in chaotic dynamical systems (that’s the definition of chaos). But it’s often good enough.\nSo what I’m saying is that, yes, there are many factors. But, in my new mental model, it’s the meme stock dynamic that dominates.\nThe question is: what is to be done about it? I get super uncomfortable about equities being traded where the value is divorced from the underlying intrinsic value of the equity, and instead comes from marketplace activity. I can’t put my finger on why I find it uncomfortable, it just smells of bullshit and society spinning valuable capacity on churning air.\nSo my response has two parts:\n\nFind alternatives. Is it possible to imagine a stock market which is genuinely tied to the intrinsic value of a corporation? One which somehow discourages pure profit-seeking speculation and pricing based on supply/demand? I have no idea. I don’t know enough about finance.\nLean into it. If all stocks are meme stocks, then a share purchase is a push on the “more like this” button for the corporate world. When you buy a stock, you’re training the engine. So it may not be as profitable, but it should be possible to move the world, just a fraction, by buying stock strictly in keeping with your personal values.\n\nDunno.\n",
    link: "/home/2021/07/21/meme_stocks",
  },
  {
    title: "Previously: Cyborgs, dolphins, dogs, giraffes (f/e 23 July)",
    date: "14.59, Friday 23 Jul 2021",
    content:
      "Five recommended blog posts from the archives, originally published this fortnight in years past. Mostly last year it turns out.\nI’ve chosen some lightweight posts today because, well, it’s Friday and it’s sunny outside.\n1 year ago\nSettling the Sun (10 July 2020).\nA short one:\n\nSo could we - in our speculative solar system spanning civilisation - have the Sun as the hub of the knowledge economy and the seat of Empire? Computer brains the size of mountains, floating in the honey of the chromosphere …\n\nSecret cyborgs and an old story (13 July 2020)\nThis story from the early 2000s, about a replacement for fat and glucose:\n\nWhat this researcher told me was that, in trials with rats in mazes, not only did the rats have more endurance, they were smarter too. …\nI remember specifically the current status: this novel food stuff was in human trials, and it was currently with the US military.\n\nDo humans have a north sense? (14 July 2020).\nOn human magnetoreception, with this ASTOUNDING BONUS FACT:\n\nDogs tend to poop aligned north-south. It’s probably because they’re sensitive to the earth’s magnetic field rather than polarised light. How do the scientists know? Because during magnetic storms, dogs poop any which way.\n\nOn speaking with dolphins (20 July 2020).\nThis time last year I learnt about John Lilly. Yeah. That was eye opening.\n\n“Lilly ended up going to great lengths to speak to dolphins, including the questionable practice of injecting his cetacean subjects with LSD, but his attempts at interspecies communication were never successful.”\n\n2 years ago\nFiltered for sexy animals (headphones required) (19 July 2019)\nIt’s a linky post. Firstly check out this short video of opera singers dubbed with modem noises.\nSecondly I learnt about giraffes:\n\nMy life has not been the same since I learnt that famously-silent giraffes are not in fact mute.\nAt midnight, in the pitch black, the neck becomes like a pipe organ, and they do this crazy deep ethereal HUMMING.\n\nThere’s a recording of the humming that you need to listen to.\nHypnotic.\n",
    link: "/home/2021/07/23/previously",
  },
  {
    title: "Filtered for light",
    date: "19.36, Thursday 29 Jul 2021",
    content:
      "1.\nThomas Edison in 1879, around the time of the first public demonstration of the incandescent light bulb:\nWe will make electricity so cheap that only the rich will burn candles.\nThe cost of light.\nSource: Early Light Bulbs, Engineering and Technology History Wiki.\n2.\nTheatre lighting designer Alex Forey’s eye-opening Young Directors’ Guide to Lighting: Intensity, Colour, Angle, Texture, Atmosphere.\n\nwe are often responsible for directing the gaze of the audience to where it needs to be\n\nJust an incredible piece about shaping light, both the practicalities and the narrative control. Worth a read for a glimpse into another world. (Assuming you’re not already a theatre person, which I’m not.)\nIt is galling that software interface design lacks a similarly rich language and set of tools for how to speak with the user.\nRELATED: What wipes in Star Wars teach us about the brain and also interface design (this blog, April 2021).\n3.\nAn attempt to hack the human eye into seeing near-infrared (Science for the Masses, 2014).\nHumans use the vitamin A1 to build red-sensitive pigments in the eye.\nBut freshwater fish use vitamin A2 instead to create a pigment which has been shown to be sensitive to light of wavelengths up to 1400nm in some species, which is well into the near infrared range.\nAnd so, an experiment:\n\nThe members of Science for the Masses and a handful of our collaborators will completely eliminate all retinoids and caretinoids (vitamin A and its provitamins) from our diets by switching to a special vitamin A deficient (VAD) blend of Soylent provided to us by special request. We will then supplement with two compounds: 3,4-dehydroretinol (A2) and retinoic acid (RA).\n\nThe idea being that it’s possible to deprive the body of vitamin A1 in order to force the eye to use vitamin A2 instead, and therefore see the world as fish do – in the near-infrared.\nSo - I guess - you could see objects glow with heat, directly?\nSadly it wouldn’t work: No, These Biohackers Can’t Give Themselves Infrared Vision (Wired, 2015).\nHOWEVER:\nI am less concerned with biohacking itself than what this idea shows cultural anticipation for…\nYou could hack the same experience with augmented reality smart glasses. Take the video feed, then compress the colour spectrum such that deep red is unused. Then take a separate feed of the infrared, and hue shift it into the red channel.\n(Note that standard cameras see infrared by default and it has to be filtered out. The rear camera on my iPhone is filtered, but the front-facing camera is unfiltered and can see IR – which I use pretty regularly to see if the TV remote batteries are working. Point the remote at your phone and press a button: the IR bulbs  will appear as sharp points of light. All of which is to say, you wouldn’t even need a dedicated IR sensor for the smart specs.)\nThen wear the specs for a few days to give it time for your brain to adjust, touch a few objects of various temperatures (while looking at them) to train your perception, and you would be able to see heat. A kind of lo-fi cyborg prosthetic.\nCould be a practical industrial application for smart glasses, aimed at plumbers, mechanics, and electrical engineers.\n4.\nA nugget from Venkatesh Rao’s newsletter back in December:\n\nThe amount of work that bought 1 hour of light in prehistoric times now buys 53 years of light.\n– Venkatesh Rao, Involvement Capitalism\n\nThe cost of light!\n",
    link: "/home/2021/07/29/filtered",
  },
  {
    title: "Welcome to the Entropocene",
    date: "14.41, Friday 30 Jul 2021",
    content:
      "Back in 2019 there was a risk that the UK would exit the EU with no trade deal at all, and supply chains would be sufficiently disrupted that shop shelves would run empty etc.\nSo we built up a contingency stash in the room upstairs, mainly baby things: medicine, nappies, long-life milk, etc, then added tinned and dry goods like pasta and chopped tomatoes.\nWe didn’t need it. (My guess is that supermarkets and suppliers had assessed the risk and built up their warehouses, which stabilised those first few weeks.)\nBUT our Brexit No Deal stash had a second life as a Covid Supermarkets Can’t Cope stash.\nOnline orders were rationed in the first lockdown in early 2020. Our existing accounts we used to get deliveries for our parents. Then for a few weeks we couldn’t get groceries – we dipped into the stash a few times (then kept it topped up). Handy.\nI have been eying the remainder of the contingency stash. Time to wind it down? Maybe. Maybe not.\nThese days supermarket shelves run empty frequently enough that they’ve printed special boxes to fill the space. Post-Brexit problems with not enough delivery drivers? Or the “pingdemic” – a half million people are self-isolating right now because they’ve been pinged by the Covid contact tracing system. So the shops are all short-staffed. Or is it just that online grocery orders are being prioritised over actual shelves? (E-commerce has boomed in the UK, way more than the US.)\nThen there are the flash floods in London from recent storms. I look at the closed roads and think, well clearly that’s not going to help.\nI mean it’s multi-factor isn’t it.\nOne thing reduces resilience in the supply chain such that another thing knocks it out entirely.\nAnd it’s global and it’s unpredictable. The Suez Canal shutdown led to garden gnome shortages in Whitminster. Hard to imagine that would have happened before a year of the system being stressed with Covid. (All the shipping containers are in the wrong places. The cost of a container on the Asia-Europe route is up 5x.)\nAll of which means I’m looking at my stash (after almost two years) and thinking maybe it has a third life as an Extreme Weather Event contingency larder.\nI hadn’t expected that. I live in the UK, and we don’t have earthquakes or wildfires so I’ve never had to make up a Go Bag.\nBut honestly I look at the weather, here, and think of the ancient viruses being thawed out in the permafrost, a thousand miles away, and this is basically the rest of my life now isn’t it. Always keep a cache of dried pasta and garden gnomes in the back room, you never know.\nThe world is fragile.\nRod McLaren invented a word for it in his latest edition of the Co-op Digital newsletter, which is ostensibly about technology and groceries. But:\n\nEvery newsletter is now a climate change newsletter, because climate change is the landscape now. We now live in the “entropocene”, an era of larger, quicker, less predictable, non-linear change.\n– Rod McLaren, Co-Op Digital Newsletter (29 July 2021)\n\nThe Entropocene. The new geological era of entropy.\nIt turn out McLaren’s Entropocene is a parallel coinage because of course it is – all experiences are shared global experiences now.\nHere, for example, in an article also introducing this new word, is a strong plea to stop using the word Anthropocene to refer to this new epoch:\n\nHave you ever felt the toxic touch of the word “Anthropocene”? If you haven’t, I could put it in a simple way. Considering that the near-collapsing state of our planet is due to the Anthropos in general means that we take the Inuits or the Jivaros for responsible of the situation, in the same way that our modern occidental civilization. This sounds absurd, since they are amongst the first victims of capitalistic greed, deforestation, and climate change. And that all in the name of a “universal mankind” (the Anthropos), a concept they never ask or stand for. In other words, one is mistaking the victims for the predators when using the word Anthropocene. And it all sounds like the last dirty joke of Western White Man, his Empires and his Capital.\n– Symbiosphere, Goodbye Anthropocene, Hello Entropocene… (2019)\n\nIt is a great point.\nYes, the concept of the Anthropocene points out that humans wield global power and have global impact. When archaeologists a million years hence dig down, there will be a line of microplastics, radioactivity, and high atmospheric CO2, and they’ll point to the thin stratum and say, aha, the human era.\nBut as they say: not all humans.\nYes this is an era characterised by a general and accelerated process towards the maximal disorder leading to social and political dislocation - entropy - but Disaster Capitalism is not a universal phenomenon. It is incorrect to pin the Anthropocene on humankind at large. So let’s not bake it into the name.\nEntropocene it is.\n",
    link: "/home/2021/07/30/entropocene",
  },
  {
    title: "Wireless wires and hardware APIs",
    date: "19.15, Tuesday 3 Aug 2021",
    content:
      "The high point of home automation was hi-fi separates in the 80s/90s. (The concept should be modernised for the 2020s.)\nYou got an amplifier. Into that you plugged in all the other components: tape deck, radio, vinyl turntable. Eventually a CD player, maybe the TV is an input too. Out of the amp came the speakers.\nThe components were connected with phono cables. Do they still exist? I guess in some form.\nPhono cables come in pairs: the red plug goes into the red socket, the white plug into the white socket. There’s no orientation hassle like with USB. The plugs are round and fit securely.\nWhat I’m saying is that the connectivity system was: obvious (once you know the colour matching trick), scalable (you could keep chaining components), open to inspection (you can see what’s going on), and standardised.\nBeing standardised:\n\nThere’s interop! Any vendor’s kit would work with any other vendor’s\nKnowledge is social! Everyone had a friend or an uncle (always an uncle) who was an AV nerd. Have a problem setting up your system? They could easily pop over, eyeball it, and get things working.\n\nI mean, god forbid my smart home should be so simple now.\nYes I can plug a Roku device into the HDMI port on my TV, and sign into my streaming accounts on that. There’s often a QR code thingy to make the sign-in flow relatively smooth, if you don’t mind doing that a half dozen times.\nAnd let’s not get into Netflix and iPlayer demanding that I choose a personal profile to watch TV with, despite the fact that there’s usually two or three people on the sofa. You would have thought that device-specific profiles would be supported now.\nI own one (1) smart plug which is used to check how often a water pump is activating. I seem to remember activating that with a QR code too. Shame you can’t tell whether or not it is connected to an account, and whose, just by looking at it.\nPerhaps a modern phono cable would be a wireless wire.\nYou’d buy a single object from the shop – a plug with two ends. You’d snap it in the middle. From then on until forever the two ends would be spookily joined. So you could plug one side into the back of a light-switch indoors, and the other into the separately-powered Christmas lights outside, and it would work.\nOr maybe it would look like a pair of Apple Airtags, stuck back to back. You’d peel them apart and magnetically attach them to the different components.\nPart of me wants a streaming media junction box for my home. It would be a box that I would sign into with all my accounts. It would have a bunch of outputs, and I would plug one end of my wireless wire into this junction box, and the other into the TV or the speakers or whatever.\nOr I would carry the other end in my pocket to my friend’s house, and we could watch TV there.\nThis isn’t just for streaming. Devices should have a standard hardware API - a couple of pins that publish events (like: radio re-tuned, or switch pressed, or doorbell motion sensor activated) and accept commands (like: re-tune to X, or remote activate switch, or record and send video).\nThen I would plug half of my wireless wire into the hardware API, and the other half into a box labeled “cloud” hooked into my wifi router. Then if I wrote any code online, or wanted to give a service access to it, the events and commands for that device in my house would be available at a standard URL.\nBack in the day (2008) we built a radio called Olinda with a hardware API:\n\nOn the side of Olinda is a studded, magnetic connector for plugging in expansion modules. This is an open, standardised hardware API - with defined connections and defined protocols for the data. It’s a bit like the expansion port on an iPod, and this makes the radio modular. It’s a hardware version of the APIs around websites like Flickr, del.icio.us or Twitter - which, by virtue of their APIs, are all surrounded by a rich ecosystem of supporting sites and products.\n– BBC Radio Labs, Olinda - a new radio (2008)\n\nThe ideas of modularity and adaptive design were so powerful, and there were some fascinating ideas being incubated in consumer product back then, but they got kinda lost in the smartphone tsunami which started growing when the iPhone was launched in 2007 and the tide never really went out.\nI’m not arguing for a return to separate components for everything, just for the sake of it. The fact we all carry phones, now, that can be soft interfaces to literally anything – that’s another wrinkle. Then there’s not wanting to have your data used for adtech, and not wanting to have ways to easily get stalked, and so on.\nAnd of course our devices are different now: smart speakers, zone heating, computer peripherals.\nBut, I don’t know, I hope that Apple or Google or someone has a lab somewhere which is imagining a kind of alternate future smart home which is as good as the phono cables of the 80s, and they’ve got the whole thing worked out, and they’re figuring out how to get there, and when smart specs finally launch, one of the apps will be the ability to see the smart wiring diagram of my house overlaid as coloured glowing lines in augmented reality.\n",
    link: "/home/2021/08/03/phono",
  },
  {
    title: "Imagining the first global Simulation War",
    date: "20.34, Wednesday 4 Aug 2021",
    content:
      "I’ve been imagining a future global war where nobody is killed, no city is attacked, and it’s conducted entirely in simulation – unless and until it can become real.\nI haven’t played Go much but it feels like a game of frozen anticipations. You anticipate what the other might do, in their attempt to enclose you, and you place a stone to prevent that. And they do the same. So the entire game board becomes this network of cautious concrete counter-plays to imagined threats. It’s like you spend most of the game negotiating the landscape of the game to come.\nBut if at any point you see a sequence where you can enclose your opponent, and you see that they haven’t anticipated that play, you go for it.\nSo I imagine that this is what military planning is like.\nLondon is littered with contingencies.\nThere’s a literal warship parked in the Thames. HMS Belfast. It’s a museum and tourist destination. But the guns still work – one is pointed at a motorway service station 11 miles away. Which is amusing, right? Ha ha. And also a little nod to any country that has contemplated invading London. I bet there’s a freeze-dried plan for how the Belfast would be re-commissioned, and somebody somewhere knows to the hour how long that would take.\nThen the big parks, which are beautiful and well maintained. Great for bivouacking large numbers of troops. I bet that’s another plan. In the Second World War, Hyde Park was used to grow vegetables.\nI wonder\n\nhow many contingencies there are like this in London\nwho is responsible for protecting them, ensuring they are fit for purpose, and what the mechanism is to override City Hall planning decisions\nwhether London’s urban planning is studied, secretly, by other countries, and whether the presence of these contingencies has dissuaded any untoward actions.\n\nPossibly not in 2021, right? But London is an ancient city with a long history and a long future. Maybe you have to plan cities for what the world might be like in 100 or 200 or 300 years time.\nRachel Abrams shared a paper with me about urban planning and the drive to suburbia: Galison, Peter. “War against the Center.” Grey Room, no. 4, 2001, pp. 7–33. JSTOR, www.jstor.org/stable/1262556.\nUrban planners in the US looked at the devastation of Nagasaki and said, oh this could happen to us. (Having just done it.) So they looked for concentrations of, say, the steel industry, or the new computer industry, and they mandated that major offices were built outside the blast radius if an atomic bomb were to be dropped a major population centre. And so you have suburbia to serve those offices and so on. The strategy was called dispersal.\nHere’s the full PDF.\nBUT what grabbed my attention in this paper was the bombing campaign on Nazi Germany.\nThe campaign was guided by the U.S. Strategic Bombing Survey, an immerse affair, employing well over a thousand people – many of them Operations Analysts.\n\n“Operations analysis” was essentially a methodical theoretical reconstruction of the interconnections that held together the German economy and war machine and that asked how it could be blown apart.\n\nAnd so:\n\nBut the operations analysts selecting targets were not just after particular pieces of munitions factories; their goal was to precipitate a collapse of the German economy as a whole. To that end, they directed a series of studies designed to locate just those plants where destruction would cause shortages to ripple through the entire system. Operations followed. Henry “Hap” Arnold, for example, tempted Harry Hopkins with the notion that blasting the German ball bearing industry “would probably wreck all German industry.”\n– Peter Galison, War against the Center (2001)\n\nBall bearings! (And indeed that is what the bombing campaign did.)\nBut this process is exactly what I mean. Reverse engineer an economy, or a society, or a game-player’s strategy, and figure out the single thread to pull that unravels the whole thing.\nASIDE:\nI took one of those careers quizzes at school when I was 15 or so – we all had to. Brits of a certain age will remember the DOS quiz with the text-only interface and a hundred multichoice questions.\nIt gave me two possible future careers at the end: Operations Analyst. And Ceramics. I ended up going to university where I took physics.\nMy feeling is that it was spot on, but there was no other way for a quiz written in the late 80s/early 90s to say “design strategy.”\nI wrote a really-not-very-good short story about this idea years ago. It’s mostly lumps of exposition glued together with minimum viable narrative.\nIt’s about a fictional board game played on a map of Southampton. The two sides are the Council and the Friends.\nThe moves are called “counterfactuals” and the starting point is always the actual map of the town.\nBut it turns out that every play of the game is wargaming an actual, potential future conflict.\n\n‘The Friends haven’t come this close to having certainty since before the new shopping centre was built. The Council stole a march on us then, really changed the board. A great move.’\nI’ve never thought of the actual building in Southampton as moves in the game before.\n– Matt Webb, School Reunion (Masochuticon, 2006)\n\nOne play-through reveals that there’s a path for the Friends to win – and so it all kicks off.\nI don’t know why my head is stuck ploughing this global threat-modelling furrow. But it is: see last year’s post about space, weather, and other novel battlegrounds.\nIf I were writing that story today, it wouldn’t be a board game, it would be AI. There would be AIs constantly wargaming, constantly running the operations analysis that led to the ball bearing factory target selection.\nAnd maybe that’s part of my fear now? That threat in the 2030s won’t be about somebody realising that social media propaganda can destabilise a society, or some organisation spotting the new ability for a computer worm to infiltrate uranium gas centrifuges and destroy a nuclear program (a decade later and nobody has claimed responsibility for Stuxnet and its cyberattack on Iran).\nThe discovery process will be automated.\nThe probing of the attack surface of society will be automated and a thousand times faster than anything we’ve seen to date, whether it’s software engineering or social engineering or knocking out a water treatment plant. Imagine finding a zero day on the economy.\nMy hope, my wish, is that this finally makes it unthinkable to have enemies because any attack would be unreasonably effective, and so the entire world community embarks on a giant exercises of potlatch and soft propaganda  and diplomacy – aggression and self-defence both become questions of: how to make friends.\nBut actually where my head goes is to a future Simulation War, 2030–2070.\nA Simulation War conducted entirely virtually, at hyper speed. The arms race will be measured in an ever-escalating TWPS, trillions of wargames per second, the computational capacity of a nation devoted to hunting for sequences in possible futures that lead to a win state before uncertainty takes over.\nWe won’t know the virtual cold war is happening aside from the real world moves to change the board itself, the starting conditions. We’ll see weird urban planning decisions, or bizarre industrial strategy capital allocation decisions, or modifications to university curricula, or manipulations of the atmospheric carbon concentration, none of them making sense except in the context of being moves in the game, anticipated defences in a numerically critical proportion of future mirrorworlds.\n",
    link: "/home/2021/08/04/virtual_war",
  },
  {
    title: "Apple’s photo scanning and our state of forced collective paranoia",
    date: "15.36, Friday 6 Aug 2021",
    content:
      "Apple released its plans to automatically scan phones for child abuse material which on the face of it is good policing – and the response has been loud and angry and calls out the dangerous slippery slope of surveillance. But I think what is also being revealed is a particularly 21st century phenomenon, and that is mass social paranoia.\nThe slippy slope argument is not hard to see. The plan is for Apple to continuously scan photos sent in messages and stored in iCloud, testing them against a known database of child abuse images, and escalating matching photos to human review.\nBut now the mechanism is in place, what else could it be used for? Could the Chinese government coerce Apple to locate dissidents, by adding certain non-child-abuse images to the central database? I mean, what are Apple going to do – not sell phones in China? Or can the GDPR “right to be forgotten” be wielded to force erasure of (say) unwisely shared nudes? Hard to argue with that, and Google hides links from search results under GDPR so maybe not such a stretch. But then why not automate removal of embarrassing photos of celebrities with expensive lawyers?\nThe EFF response is far more articulate on the details and mission creep potential of the new system: Apple’s Plan to “Think Different” About Encryption Opens a Backdoor to Your Private Life.\nBUT:\nI have a friend who has worked in positions where she can see the global traffic of child exploitation material, and I’ve spoken with her just a little bit about this in the past. It is horrific and huge. We need good policing, that’s my view, and mechanisms to achieve that, and we can debate how that happens. (We’re a long way from any answers, but my thoughts on a good approach are a whole other topic.)\nSo there’s a line for society to walk.\nAnd it really doesn’t help that we have to trust a corporation to walk this line, without democratic accountability.\nYet this isn’t just a privacy debate.\nIt feels different because the photos are being scanned on-device. The surveillance is on our phones. And that triggers a whole other kind of response.\nCory Doctorow, way back in 2002: My Blog, My Outboard Brain (O’Reilly): Being deprived of my blog right now would be akin to suffering extensive brain-damage. Huge swaths of acquired knowledge would simply vanish.\nClive Thompson, in 2007: Your Outboard Brain Knows All (Wired): This summer, neuroscientist Ian Robertson polled 3,000 people and found that the younger ones were less able than their elders to recall standard personal info.\nThis feels obvious now, but it was new then:\n\nAnd when he asked them their own phone number, fully one-third of the youngsters drew a blank. They had to whip out their handsets to look it up.\n\nSo smartphones become, somehow, part of the mind.\nCognitive scientist Andy Clark makes the point that the mind doesn’t stop at the skull. He lays out the extended mind hypothesis in his astoundingly prescient book Natural-Born Cyborgs (2003). Highly recommended.\nHe makes the argument that we don’t just use pen and paper to work out a sum, but the tool becomes part of our thinking. Information on the web isn’t just consulted on our phones, but is in a real way part of our memory. \nHumans are special precisely because our brains have this ability to side-load the world into self:\n\nIn embracing our hybrid natures, we give up the idea of the mind and the self as a kind of wafer-thin inner essence, dramatically distinct from all its physical trappings. In place of this elusive essence, the human person emerges as a shifting matrix of biological and nonbiological parts. The self, the mind, and the person are no more to be extracted from that complex matrix than the smile from the Cheshire Cat.\n– Andy Clarke, Natural Born Cyborgs (p198)\n\nPhones are part of us.\nScanning the photos on your phone isn’t like steaming open the mail and peeping inside the envelopes. It’s like rifling through your memory.\nAnd when those memories may at any time be silently observed or removed… even if it never happens but there is the possibility of it…\nWell.\nEvery culture, big and small, has a feeling that it swims in but is often slow to put its finger on, like the proverbial fish in the ocean unable to see the water. That’s my take.\nI think in the 70s and 80s that feeling was the end of the world. I was pretty sure, as a little kid, that by the time I was my age, now, I would be living in a post-apocalyptic nuclear wasteland. It wasn’t a conviction, it was more like an unspoken understanding. And goodness knows what that did to us.\nIronically the end of the world is coming, in the shape of the climate crisis, and I wonder how those of us who grew up taking the Cold War for granted are coloured by that experience and how it is tainting our response. We probably feel like the climate crisis, or at least some kind of apocalypse is inevitable somehow? Or alternatively, that if we wait around for long enough then the threat will just somehow… recede? Like the way the peril lifted in the 90s. Dangerous templating for us to have; thank god for the zoomers.\nWhat’s in the air now?\nWe swim in paranoia, I think.\nWe’re always potentially being watched.\nRELATED: I ran across Zizek riffing on Donald Rumsfeld (YouTube) and specifically developing the concept of unknown knowns. Here’s Ted Hunt on Twitter with a quote/summary:\n\n”.. the main dangers lie in the unknown knowns–the disavowed beliefs, suppositions and obscene practices we pretend not to know about, even though they form the background of our public values.” – Slavoj Zizek\n– Ted Hunt (_@ted_hunt), 08:26, 03/08/2021\n\nSo paranoia is like our culture’s current unknown known. That’s where it sits, somewhere in the social unconscious.\nJames Bridle’s 2014 work The Nor was an investigation into paranoia, electromagnetism, and infrastructure.\nIt’s a sequence of essays telling the story of a participatory, documentary act: Bridle’s walk across London, photographing every CCTV camera he passed. SPOILER: It doesn’t end well.\nHere are the essays:\n\nThe sense of being watched is a classic symptom of paranoia, often a sign of deeper psychosis, or dismissed as illusory. In the mirror city, which exists at the juncture of the street and CCTV, of bodily space and the electromagnetic spectrum, one is always being watched. So who’s paranoid now?\n– James Bridle, The Nor (2014)\n\nAnd it was this work that really opened my eyes to the pervasive sensation of surveillance. (Which is why art is vital, right?) Especially because Bridle makes explicit the role of the network and what that does: the first essay is titled All Cameras are Police Cameras.\nThe camera network today is Instagram, TikTok, other people’s phones. It’s the pictures taken at parties, previously private spaces, and it’s the acquisition of the breakthrough facial recognition startup Face.com by Facebook in 2012, and everything that opened a door to across the industry.\nA lot has been said about the Panopticon, Jeremy Bentham’s 1786 concept of a prison where the prisoners are controlled by the mere possibility of being observed, and of sousveillance: surveillance from the same level; we watch one-another. That’s what a networked camera in every pocket leads to.\nThe debate, over the last 20 years as this has been happening, has been framed around the loss of privacy and whether that matters: the younger generation has different privacy expectations to us, that’s one statement; the absolutist privacy ideals of the EFF are another part of the debate.\n(And the responses to this shift are fascinating. For me, the go-to here is danah boyd’s work, and I’ve recently been diving into her work on networked privacy from the early 2010s, and the sophisticated ways that teens are finding control and agency in this world.)\nBut how does it feel?\nIt feels like paranoia. You don’t know how the image of you has spread, or your words passed on. You don’t know how it will be interpreted; you don’t know if you’re going to wake up one morning in the middle of a context collapse Twitter pile-on – or be fine as normal – or arrested by the police.\nASIDE, just to say that Covid-19 is a very 2020s disease, very paranoid.\nUnlike the Blitz in London in the Second World War where the risk was external, and everyone has to pull together. (I reference this simply because it’s the event which is also mentioned here in the UK whenever there’s a new national crisis.) Everyone could pull together because everyone could be trusted. All in the same boat.\nBut with Covid…\nAnyone you meet may be infectious. Or not. There’s a risk in every interaction that, later, you find out they have “betrayed” you. Further, there’s a risk that you, yourself, may have Covid. You may be spreading it, infecting your neighbours, your parents – you can unknowingly betray yourself.\nSo there’s this questioning of self and one-another, and we’ve responded with surveillance and sousveillance: we continuously monitor one-another with contact tracing apps, ourselves with self-administered tests. We’re reminded to be suspicious.\nThis uncertainty about self and other is so similar to social media. When you talk to people online, are they really people or are they bots? Are they stealing your data? Have you exposed yourself, given yourself away? Are you, yourself, tainted – have you fallen into a Facebook rabbit hole and been radicalised… how would you know? Is there a home-administered lateral flow test for extremism?\nI am not saying that the Covid response is inappropriate.\nBut what I am saying is that the mutual suspicion and monitoring is (looking at it with this particular framing) a forced paranoid state, which is very in keeping with social media and networked technology.\nAnd it would be interesting to consider how we would have tackled Covid if we had instead a different dominant social scaffolding to conceptualise “threat,” for example if we had still been in the tail end of the Cold War.\nCredit to the current generation, they are responding to this paranoid milieu of the 2010s/2020s and developing new language to point at it and discuss it.\nThe emergence of the term gaslighting has been a joy to see: this new ability to discern when memory is being undermined for the purposes of manipulation and control – well, that’s a word we all needed and thank you.\nJumping to a definition for a second:\n\nGaslighting is a technique that undermines your entire perception of reality. When someone is gaslighting you, you often second-guess yourself, your memories, and your perceptions.\n\nLet me bring this back to Apple, and why I think the initial response to their child abuse material scanning announcement has been so angry and so strong.\nOur phones aren’t computers. They are our outboard brains. Our photos aren’t simply stored; they are part of our memory.\nWe live in a state of forced paranoia, developed over the last almost twenty years. We don’t know who’s watching or what will be done with this. But we’ve found accommodations. We’ve managed. We have new language to talk about it.\nExcept now somebody is proposing to look at our memories. We won’t feel anything; we won’t hear anything; probably nothing will happen. We all know from previous experiences with algorithms that misinterpretations will happen. And of course there are human monitors involved too, which means we have to consider, at some level, what they will think of us. So now we have to police ourselves, just in case we take a photo of - have a memory of - happen to think the wrong thing.\nAnd if somebody else is now inside your memories, can you be sure that they’re not being edited? Is gaslighting occuring with these most personal of devices? Even if it never happens… that’s the lesson of the Panopticon, the mere possibility is enough to affect behaviour.\nWhat the word for paranoia when it’s true?\nCovid, phone surveillance, social media, mass paranoia – all of these are of a type and in resonance; nonlinear sympathetic consequences are kicking off all over the place.\nI don’t know what should be done, what the rights and wrongs are here.\nBut I wanted to make the connection.\n",
    link: "/home/2021/08/06/paranoia",
  },
  {
    title: "Two traditional games of accumulating points",
    date: "18.28, Tuesday 10 Aug 2021",
    content:
      "We used to play conkers at school, when I was 8 or 9, with the variant rules that allowed for rolling up scores.\nSo here’s the game, if you never played: get a horse chestnut and hang it on a shoelace. Your opponent has the same, and you take turns in swinging your chestnut in order to smash the other. According to the Wikipedia page this used to be played with snail shells, which I never knew.\nBeat one opponent, your conker is a one-er. Beat two, it’s a two-er. It’s probably falling apart by the time it’s a six-er or seven-er.\nOR: score by adding the loser’s number to your victory count. Beat a three-er with a fresh conker? Well you’re now the happy holder of a four-er. That was how we played. So by the end of the day the scores would get pretty big. \n(Locality: the New Forest in the south of England. Other playground games: we played It not Tag; and yelled “123 in, release all prisoners” not “99” or “40-40”.)\nFrom 2014, this episode of In Our Time on chivalry is pretty great: the moral code observed by knights of the Middle Ages. (It’s still available to listen.)\nThere was a segment on tournaments that caught my ear. It turns out that, if you beat the other knight in a tournament, you get their horse and armour – which are worth a lot. From the show:\n\nIf you look at something like the history of William Marshall, who is the great knight of the late 12th century, his early career from a landless fourth son to becoming Regent of England, it’s predicated in his early years on winning large sums of money through horses and armour taken in tournament.\n\nThe more money you have, the more time you can spend training, and the better armour and horse you can afford. So success accumulates.\nWilliam Marshall had an interesting childhood: his father was involved in a civil war in England called “the Anarchy” (1135-1153) between King Stephen and the Empress Matilda – which is an era of history which is totally new to me. And as part of that, young William was held hostage, but his father was pretty clear that he didn’t consider this a threat, saying: I still have the hammer and the anvil with which to forge still more and better sons! So! They put the boy William Marshall in a trebuchet, but didn’t go through with trebuch-ing him anywhere, and all’s well that ends well; he ended up regent for the nine-year-old King Henry III in 1216. He’s buried up the road. I’ll have to go visit.\nAnyway.\nDid young knights play conkers in the training yard? At school we would prepare our chestnuts, baking them in the oven, or soaking them in vinegar, or saving them from the previous year, all the better to roll up points. I can’t help but see it as a rehearsal of tournament life compressed into a single day, a lesson in how to pick opponents and feel out risk. Conkers today a kind of ancient ghost of those chivalric tournaments.\n",
    link: "/home/2021/08/10/conkers",
  },
  {
    title: "Collecting my thoughts about notation and user interfaces",
    date: "12.34, Thursday 12 Aug 2021",
    content:
      "I’m circling something to do with notation and software user interfaces and what connects them. And things aren’t quite cohering for me yet, so this is me just collecting my thoughts…\n(I’m designing user-composable interfaces this week, so long term the goal is to figure out some principles.)\nA good starting point is pirate maps, those sketched maps with minimal detail that can none-the-less lead you to the X that marks the spot on the right treasure island.\nOr to be more specific, urbanist Kevin Lynch’s city maps from his 1960 book The Image of the City. I’ve described his approach here (March 2021) (where I also pick at the possible neurological underpinnings) so to briefly summarise:\nLynch puts forward five primitive elements: paths (e.g. streets); edges (e.g. uncrossable rivers); districts; nodes (e.g. street corners); landmarks (e.g. a recognisable building). Each element has an intuitive way to sketch it, as if on the back of a napkin.\nThe map of Boston (his first example) is immediately recognisable. Ask a person to sketch a city, or a route to a place, and they’ll automatically use something very like Lynch’s system.\nSo Lynch’s five primitives comprise a notation.\nIt’s composable. A small number of simple elements can be combined, according to their own grammar, for more complex descriptions. There’s no cap on complexity; this isn’t paint by numbers. The city map can be infinitely large.\nCompositions are shareable. And what’s more, they’re degradable: a partial map still functions as a map; one re-drawn from memory on a whiteboard still carries the gist. So shareable, and pragmatically shareable.\nNot only are maps in this notation functional for communication, but it’s possible to look at a sketched city map and deconstruct it into its primitive elements (without knowing Lynch’s system) and see how to use those elements to extend or correct the map, or create a whole new one. So the notation is learnable.\nThe idea of composability is worth digging into.\nA pirate map is a drawing, and drawings are compositions of dots and lines and textures: A drawing is simply a line going for a walk (Paul Klee). But these would be poor primitives. Why?\nA good, composable notation has primitives which are semantic. A line doesn’t mean anything, it’s too abstract – but a path or an edge (in Lynch’s system) refer to qualities of things in the real world. I’m also going to say that a notation must be grammatical, which is to say that there are rules about how primitives can be combined. \nThere are also not too many primitives. You want a system which is efficiently expressive. Like, you can say complex things with the minimum of vocabulary. Why? Because then the person using the notation can hold it in their head.\nAdam Wiggins is the co-founder of Heroku, the prescient cloud-based technology platforms. It was ahead of its time, incredibly simple to use, but powerful – with an almost toy-like interface (I say that as a compliment) the complexity of hosting, scaling and managing servers was almost completely hidden.\nHere is Wiggins relating his philosophy:\n\nThe value of a product is the number of problems it can solve divided by the amount of complexity the user needs to keep in their head to use it. Consider an iPhone vs a standard TV remote: an iPhone touchscreen can be used for countless different functions, but there’s very little to remember about how it works (tap, drag, swipe, pinch). With a TV remote you have to remember what every button does; the more things you can use the remote for, the more buttons it has. We want to create iPhones, not TV remotes.\n– Adam Wiggins, My Heroku values\n\n(Via Simon Willison who picked out this quote.)\nIt matters what you can hold in your head because then the notation becomes a tool for the imagination. It is suggestive. Lego is suggestive. If you sit down and compose with the bricks, aimlessly, you will come up with new ideas that you wouldn’t have reached otherwise. The studs on the bricks are a grammar; the shapes are the semantics. You don’t get lost in complexity because the bricks are right there on the floor, so you play and, o ho!, there’s a novel kind of house you can build, you hadn’t thought of that.\nAt this point I’m slip-sliding between notation and interface, and this is maybe one of the things I’m trying to figure out. Perhaps a notation is always an interface to something?\nThink of Feynman diagrams from physics. These are diagrams of particle interactions, like an electron hits a positron and both disappear while emitting a photon. The Wikipedia page shows examples.\nBut the lines, arrows, and squiggles have a grammar to them. And Feynman diagrams directly map to the fearsomely complex mathematics of quantum field theory. Manipulating the diagram is the same as performing the calculations.\nSo Feynman diagrams, as a notation, exist on the boundary of two realms; the interface between the scientific model (a representation of physical reality) and the imagination of the physicist.\nSoftware user interfaces: let me try to draw the parallel.\nI’ve been reading Steven Sinofsky’s first-person account of the rise of the Microsoft and the PC, which is astounding – it’s technology and strategy and history from someone who was right in the thick of it, at a pivotal time. Sinofsky is serialising the whole story as Hardcore Software: Inside the Rise and Fall of the PC Revolution.\nHe has this to say about the complexity of Microsoft Office (the first and much successful office software suite), and specifically about the buttons, menus, and commands, and every icon, command name, tooltip, menu string, and keyboard accelerator…\n\nOne of the most significant differences between Office and most other tools is the sheer breadth and simultaneous depth of features, something that would become even more apparent as web pages came to the forefront. Each application had over 1000 commands (buttons, menus, etc.) with something over 2500 unique commands in Office96.\n– Steven Sinofsky, 041. Scaling the Office Infrastructure and Platform (Hardcore Software)\n\nThat was 25 years ago. I can only imagine that complexity has increased since.\nCompare with the Xerox Star (1981) which introduced the desktop interface in the first place, together with the underlying metaphor of objects. Like, you could select a file or a paragraph or a printer and choose what do to with it, and that’s the ancestral idea behind our graphical user interfaces today.\n\nOne way to simplify a computer system is to reduce the number of commands. Star achieves simplicity without sacrificing functionality by having a small set of generic commands apply to all types of data: Move, Copy, Open, Delete, Show Properties, and Same (Copy Properties). Dedicated function keys on Star’s keyboard invoke these commands.\n– IEEE Computer, The Xerox Star: A retrospective (Sept 1989)\n\nAs an example of this flexibility:\n\nIn Star, users simply Copy to a printer icon whatever they want to print. Similarly, the Move command is used to invoke Send Mail by moving a document to the out-basket.\n\n…which is powerful! But only works because the user can see, on the desktop, the icon of a printer and the icon of an out-basket.\nI’m stretching the definition of “notation” now, but let’s say that both Xerox Star and Microsoft Office present the user with a notation to their internals, made out of commands and also graphical components: windows, icons, menus, pointers.\nThere’s a quality to this “notation” which is suggestive, as with Lego bricks, in that you can experiment with trying different commands.\nBut I’ll go further as say that there’s a quality which is that the notation is intentional and that is essential to a good notation or a good interface.\nThat is, you can imagine a goal (being it printing your document or drawing a map of Boston), and you know the available primitives, and you can figure out a sequence or a composition to get from A to B.\nRelated to all of these points, a notation or an interface must be legible.\nIt’s no good with a desktop interface, say, if icons are draggable and buttons are clickable, but the user doesn’t know that these operations are possible. So we design icons and buttons with visual affordances: they look as if they are pick-up-able, press-able, and so on.\nLegibility, consistency, and affordances: all of these contribute to creating a mental model of the notation system in the mind of the user, and that seems like a prerequisite for many of the other qualities above.\nPerhaps HTML is a notation? (Or rather, maybe it was in the early days.)\nWhen I wrote about the original ideas behind files and icons (back in February), it felt important that the file was a boundary object:\n\nFiles are meaningful to computers, but they are also meaningful to users, and both can manipulate the same object. The two of you inhabit different worlds, but you’re talking about the same thing.\n\nSo HTML, the language for making web pages, is a “notation” on an interesting boundary. It has a small number of primitive elements, and a grammar to compose with them. And it is…\n\nEasy to write: the creator can describe something simple or infinitely complex, with the same small set of rules. And given the set of rules is simple, it’s also good to imagine with.\nMachine-readable: the browser application uses the exact same notation to display the webpage.\nObvious to interact with: buttons are clickable, hyperlinks are followable.\nGood for reading and sharing: a user may View Source with their browser and read the code behind a webpage, and from there they are able to copy, tweak, and learn.\n\n(Those last points were more true in the early days of the web…)\nHTML sits on a boundary between the machine, the creator, and the reader.\nTo summarise those desirable qualities, a good notation is:\n\nComposable\nShareable\nDegrabable\nLearnable\nSemantic\nGrammatical\nEfficiently expressive\nSuggestive\nIntentional\nLegible\n\nI can’t quite tell whether I’m trying to force together two concepts (notation and user interface) which are fundamentally different, or whether there is something fruitful in seeing them as aspects of the same thing. \nAnd I’m still not quite sure whether there are indeed lessons here for designing a composable user interface, or a design system, or whatever it is I’m working on.\nBut since I’m working on something where\n\nengineers are building reusable components (which is the way of modern software and web development)\nusers need to understand how to use, navigate, and achieve tasks with the interface they see\nand creators will compose these interfaces.\n\nThen it seems like this is the right territory to be exploring.\nAny recommended reading is appreciated.\n",
    link: "/home/2021/08/12/notation",
  },
  {
    title: "Filtered for seeing through non-human eyes",
    date: "17.05, Friday 13 Aug 2021",
    content:
      "1.\nRannoch Wolves (2018):\n\nThis summer, the Kairos Collective, a physical theatre troupe associated with the Dark Mountain Project, spent three days as a pack of wolves on the moor. We followed its deer paths, swam in its rivers, and dodged lightning storms and swarms of midges; and we created ‘found performances’ for the passengers on the trains that cross the moor.\n\nThere’s a video.\nBonkers and beautiful - actors in fur suits hanging out in the cold and walking around on all fours. AND YET - if there is a challenge of our time, it is precisely about how to get people to see through the eyes of other people, animals, forests, the atmosphere. How to have common feeling without being identical; to find fellowship and difference both at once.\nI hope that there is more of this happening in the world today.\nRELATED:\nI’ve long been a fan of artist Natalie Jeremijenko’s robotic geese where, via some technologically-aided metempsychosis, your awareness transmigrates into an artificial goose and may participate in the gaggle.\n2.\nSamual Arbesman’s concept of mesofacts:\n\nThese slow-changing facts are what I term “mesofacts.” Mesofacts are the facts that change neither too quickly nor too slowly, that lie in this difficult-to-comprehend middle, or meso-, scale. Often, we learn these in school when young and hold onto them, even after they change. For example, if, as a baby boomer, you learned high school chemistry in 1970, and then, as we all are apt to do, did not take care to brush up on your chemistry periodically, you would not realize that there are 12 new elements in the Periodic Table. Over a tenth of the elements have been discovered since you graduated high school!\n– Samuel Arbesman, Warning: Your reality is out of date (Boston Globe, 2010)\n\nMesofacts about the cosmos are one thing, mesofacts on a more human scale are another. Like, medical science: in my lifetime, stomach ulcers have gone from something caused by stress to something entirely caused by a bacteria. So they can be fixed.\nOr think about technology overhangs: AI text generation was there for the taking but, until last year, computer scientists hadn’t quite twigged how fast chips are now.\n3.\nReaders of a certain age will remember the sound of dial-up modems. The bleeping, ping pong, ping pong, then data static success! is ingrained into my memory as the opening theme tune to the internet.\nHere is a graphical explanation of modem handshaking, complete with embedded audio so you can remind yourself what it sounded like.\n(My favourite stage is echo suppression: between the negotiation of speeds and frequencies between the modems, there are a series of noises that are heard by the phone network itself - which is kind of listening in - asking it to turn off echo suppression features. Query: could I play the echo suppression request down the line in a regular voice call, and what would it sound like afterwards? And are there any other functional prayers I can make to the network?)\nAnd doesn’t modem handshaking map onto human conversation too? Establish the communication protocols, run calibration to correct for errors on the line, exchange data at maximum bandwidth. Ping pong, ping pong.\nALSO:\nDial-up modem noises slowed down 700% (YouTube). \nBeautifully sinister. I have paid more money for worse gigs.\n4.\nBy the studio automato.farm, this video:\nObjective Reality - Object Stories Edition (3 mins, 2018, Vimeo).\nA first person point of view from the perspective of: a Roomba; a wall fan; electricity, as a virtual reality experience. (The robot vacuum cleaner’s inner monologue is voiced by author/futurist Bruce Sterling, who re-shared it recently.)\nA tool to enter the umwelt of smart things!\nI wonder what would happen if you spent three days cosplaying a Roomba, or a thermostat, or a hedge fund’s high-frequency trading algorithm, or the Facebook newsfeed ranking system.\nLike, you sit there with data and you get fed when a simulated Facebook user clicks on a simulated ad, and yelled out when they don’t, and you’re surrounded by stacks of data but you can always ask for more.\nWhat would happen to you? What would you bring down from the mountain; what empathy would be created; what perspective would you be able to bring to the world that you didn’t have before?\n",
    link: "/home/2021/08/13/filtered",
  },
  {
    title: "We need to revisit old frameworks to cope with the 2020s",
    date: "15.57, Wednesday 18 Aug 2021",
    content:
      "Frameworks help us structure our thinking but it turns out that frameworks from only 15 years ago have blind spots to current concerns. I have two examples, one personal and one from business strategy.\nWhat happened first is I cricked my neck putting together Ikea furniture and couldn’t look left. (This is many years ago.) Then I picked up the first in a string of running injuries. Around the same time I got a sort of perpetual ringing in my ears. Oh there was a bunch. Bad luck.\nI ran across the Holmes-Rahe stress scale (that’s its Wikipedia page). This is a scoring system for life events over the past 12 months. For example:\n\nAt the top: “Death of a spouse” is 100 life change units\nNear the bottom: “Major holiday” is 12 life change units (not all life events are bad)\nIn the middle: “Change in responsibilities at work” is 29\n\nYou go down the list, thinking about the last year. You add up your score. There are 43 life events listed.\nIf you score 300+ then you have 80% chance of health breakdown within the next 2 years.\nIt turns out I was right up there. Like, not one massive thing. But just a series of middling-to-major life changes, one after another, month after month. No wonder I was sick.\nIt was a comfort to know. I could look at my tally and say, hey you know, this is not normal.\nThis relates to Covid-19.\n\nThe health issues I was getting weren’t, on the face of it, typical stress issues. A running injury? But yeah, if you’re holding yourself too tight, of course you’re more likely to get injured. Stress issues do not always look like stress issues.\nAs a society, we are wholly unprepared for what 18 months of pandemic is doing to us. We’ve lost family, lost jobs, turned our lives upside down. Not only are you and I hitting the top of the Holmes-Rahe scale, but everyone we know is too, and besides we’ve barely been able to see them. So no support system. This isn’t just mental health, it’s niggles, sicknesses, and injuries that we won’t even recognise as being a result of pandemic stress. I don’t know what we do about that. I’d like to think that there’s a group in the Department of Health dedicated to figuring out what to do.\n\nGlobal pandemics aren’t represented on the Holmes-Rahe stress scale. No shit.  It was made in 1970. It’s not a scale made for globalisation and the entropocene.\nIt has “Change in living conditions” but it doesn’t have “I can’t make plans because we might be in lockdown next week or we might not.” Or even: “When I watch the news I’m concerned that democracy may collapse.” Or: “I can’t relax because technology is always watching me.” How many life change units do those deserve?\nBusiness models are similarly blind to the 2020s\nThis is corporate, not individual, but it’s similar.\nThere’s something called the Business Model Canvas (invented 2005). It’s a way to describe a company on a single piece of paper. Here’s the framework so you can see.\nBriefly, how it works…\n\nYou describe the company by filling in nine boxes. You write, in one box, a list of customer segments. In another box you list value propositions: that is, what’s valuable about the company’s product or service to the various customers. The “channels” box is about how to market and sell to those customers; the “customer relationships” box is how to serve them.\nThese boxes link up, conceptually. The various value propositions for a product need to link up to the customer segments – there’s no point demonstrating value for a customer segment that you aren’t targeting. The customer segments link up to channels: it’s no good having a business that is entirely door-to-door, say, if the customers don’t buy that way.\nYou look out for impedance mismatches. “Cost structure” and “revenue streams” are connected too. Imagine each as cash-per-unit-something and how it scales. If your revenue scales with product sales, but the cost is monthly and scales based on cumulative number of customers, there’s a sheering which will hurt the business.\n\nA good business will connect together like circuit wiring, or fine clockwork. Chains of causation and rhythms will align.\nBut sometimes even an attractive business will have something that doesn’t quite connect, and it’s only possible to see when you put all the moving parts down on paper like this.\nThe canvas looked like a toy when I first encountered it, but it has become something I’ll sketch pretty frequently, and I run through mentally whenever I listen to a startup pitch. (Have a look at Guy Kawasaki’s 10 slide pitch deck for early stage startups. Pitch decks are a narrativised Business Model Canvas.)\nANYWAY.\nWhat the Business Model Canvas doesn’t have is externalities. Like carbon, or like paying people properly so they don’t need food banks.\nIf I were updating the Business Model Canvas today, I would draw two rings around the entire canvas. The inner ring would be labelled “The state” and the outer ring would be labelled “The planet.” On the left of each: “Taken out.” On the right: “Put back.”\nIf employees (like drivers or warehouse workers) are only able to be listed in the “Key Resources” box because they’re classified as independent contractors, then list the welfare system on the left in the “State” ring. And balance it by put something on the right: taxes.\nAnd for the planet ring… Digging up non-renewables, manufacturing new plastic, being responsible for emitting carbon; list these on the left. How to provide a balance on the right? Well it’s hard, best to aspire to being part of the non-extractive economy instead.\n(Business Model Canvas is just one business school tool. It would be interesting to re-write course material for an entire MBA to take a full system approach to externalities.)\nSo here are these two tools that need to be updated for the 2020s and beyond. And I think both for the same reason: more than ever the world is dense and quick with nonlinear feedback loops.\nI’m not sure I would have felt so strongly that the Holmes-Rahe stress scale and Business Model Canvas were both outdated, even 5 years ago. But it’s clear they are, and who knows how much more.\nOld assumptions about a steady state world are baked into everything from Excel spreadsheets to psychology. That’s going to be some significant friction in changing out ways. Learning how to live in the future means updating the tools we have to think and talk about it.\n",
    link: "/home/2021/08/18/frameworks",
  },
  {
    title: "A new map of the extrapolated Earth",
    date: "17.32, Thursday 19 Aug 2021",
    content:
      "My imagination was caught by this poetic, meandering exploration of hyperbolic space in games and fiction: Parallel lines bend away from each other and are lost in infinity.\nRead: Hyperbolic text (June 2021) by Andrew Plotkin (aka Zarf, interactive fiction pioneer).\nHere’s one bit…\nA man who finds a book which is a description of all reality: Each successive map has a larger scale … the city, the country, the whole world … Then he turns the page again.\nZooming out:\n\nThe coastline of a greater world lay before my eyes. It was a world where Antarctica was only the tip of a much larger southern continent. It was a world where Greenland was an island in a river’s mouth, where Baffin Bay on one side and the Greenland Sea on the other stretched north, fused as an enormous estuary. Asia and the Americas were mere… promontories, headlands on a Hyperborean expanse, and the Arctic “River” that divided them had its source far north and off the edge of the map.\n\n(Plotkin is quoting the intro from Vellum by Hal Duncan. Gorgeous.)\nThere’s more. Go read!\nAnd oh it makes my breath catch.\nThe vastness!\nI guess I’m missing flying, but the great circle route from London to California goes over Greenland and Canada, and there is something wonderful about waking up mid flight and gazing out of the window in that dreamlike state, hypnagogically hiking the wilderness far below.\nUnknown lands.\nHere’s a thing:\nThere’s a technique to extrapolate art. Want to see beyond the edges of the canvas? Here’s the extrapolated Starry Night by Van Gogh, and Hokusai’s Great Wave, and more.\nUsing the same technique, just this year: 2 feet have been restored to The Night Watch by Rembrandt, previously chopped off from the left hand side in 1715 so it would fit on a wall, then lost. Which is insane.\nAND:\nAs previously discussed on this blog (2014), the algorithm is called “inpainting” and it’s, uh, a built-in command in the unreasonably powerful Wolfram language. Here’s a tutorial.\nSo I signed up for a trial…\nLONG STORY SHORT, it turns out it’s a matter of just six lines of code to get the machine to dream up new lands and oceans beyond the edge of the map. My code here. Then, running it, and waiting a minute or two…\nPresenting the extrapolated Earth (image on Instagram).\nAnd, oh!, to travel to the continent a thousand miles west of north America, and then to strike north, exploring that vast Pangean echo beyond! Or to sail east beyond Fiji, into a bay enclosed by the northernmost lands of a whole new Australasia.\n(ASIDE: here’s my collection of favourite lo-fi generated worlds. Amazing artists. Check them out.)\nNew seas, new coasts, new forests, new wastes, new inland plains - and what people and civilisations and wild geologies and ecologies and unexpected sciences and unimaginable lives are there to be found - and to be lost - what fantasies there are in a rectangle of pixels, grey and blue.\n",
    link: "/home/2021/08/19/extrapolated",
  },
  {
    title: "Labour poetry",
    date: "19.14, Monday 23 Aug 2021",
    content:
      "I am taken with dagong shige, “labour poetry,” a genre that has emerged from the 300 million workers who have migrated across China to the big cities over the past four decades, as described in The Economist:\n\nIts most famous practitioner was Xu Lizhi, who worked on an assembly line for Foxconn, a Taiwanese firm that makes most of Apple’s iPhones. Before he committed suicide in 2014, at the age of 24, he had written almost 200 poems about the drudgery of factory work. Among the best known is “I Swallowed An Iron Moon”:\n– The Economist, How Chinese factory-workers express their views on life (August 2021)\n\nHere’s the poem.\n\nI Swallowed an Iron Moon, Xu Lizhi\nI swallowed an iron moon\nthey called it a screw\nI swallowed industrial wastewater and unemployment forms\nbent over machines, our youth died young\nI swallowed labour, I swallowed poverty\nswallowed pedestrian bridges, swallowed this rusted-out life\nI can’t swallow any more\neverything I’ve swallowed roils up in my throat\nI spread across my country\na poem of shame\n\nSome of the literature refers to powerlessness and homesickness; others are proud and patriotic.\nIt must be a strange mix of emotions to be part of a movement so strong and so vast which is lifting the largest country in the world out of poverty and is literally building the nation and the world, but at the same time to be, well, far from home and oppressed.\nI’m reminded of the British war poets: Siegfried Sassoon, Wilfred Owen… I mean Dulce et Decorum Est is so vivid and so bitter - it’s a hard read, even with familiarity, and it’s hard to imagine how the imagination could be brought closer to the trenches of the Great War.\nWhat is the role of this kind of art?\nMaybe it sits midway between being\n\na mirror\na memory\nthe sound of society talking out loud about a colossal event or a becoming; processing it, digesting it for all of us, creating places for our feelings.\n\nWhich is vital.\nI don’t know about poetry but there were, appointed by the British government, official war artists for the First and Second World Wars.\nIt is a shame that the government did not appoint official pandemic artists, to document and interpret the empty streets of the lockdown, the paranoia inherent in Covid itself, the masks and the bubbles and the supermarket shelves and the diversity of experiences, the whole 18 months and wherever it goes next.\n",
    link: "/home/2021/08/23/dagong_shige",
  },
  {
    title: "When will we see the first home dishwasher cobots?",
    date: "15.14, Wednesday 25 Aug 2021",
    content:
      "Sometime while I wasn’t paying attention, robotics got really good. But mainly in industrial settings. So beyond Roomba, how do robots come into the home?\nThe trend I’m tracking is cobots - collaborative robots - originated by James Colgate and Michael Peshkin at Northwestern University in 1996. From their homepage, a cobot is a robot for direct physical interaction with a human user, within a shared workspace.\nThe cobots patent makes the supporting role clearer: cobots guide, redirect, or steer motions that originate with the person.\nAlthough “cobot” is a general approach, the typical approach seems to be a robot arm with sufficient sensors to avoid workplace injury.\nFor example, here’s Universal Robots explaining the benefits of cobots on assembly lines:\n\nThey’re easy to “program” (no-code style) and take over precision work but not the decision-making: you simply move the robot arm to desired waypoints\nThey’re flexible and easy to re-task: Moving the cobot to a new process is fast and easy, giving you the agility to automate even small batch runs.\nThey’re safe: 80% of the thousands of our robots worldwide operate with no safety guarding.\n\nThe difference in approach between regular robotic automation and a cobot is fundamental. It’s the familiar promise of automation, but without having to move to a 100% automated production line. So you could imagine, putting up a fence, you could have a cobot lean in to just punch in all the nails in all the right places while you hold the plank in place (which means your team size is reduced to only one human), but you don’t need to swap out to a massive fence-construction-machine.\nALSO fascinating is that these cobot snake arms generally come as general purpose platforms for which you develop “apps”. So…\n\nHere’s a platform: Sawyer from Rethink Robotics. It’s a 7-jointed robot arm with a gripper on the end, collision detection sensors, computer vision, and a network connection.\nHere’s a demo “app”: Cobot Cafe (YouTube) which is Sawyer functioning as a barista, remote controlling the coffee machine to pour the coffee, and moving the cup with its arm.\n\nI’d like a cobot at home. They’re safe and portable, that’s the promise.\nSo maybe I could place my safe, portable cobot in the floor in the front room, and it would pick up all the toys and tidy them away, shelve any books, and find the TV remote control and put it back in the regular place.\nWhat I like is that we inhabit the same space, and I think of the distinction like this:\n\nI have a robot to clean the dishes already. It’s called a dishwasher, and I have to make room for it, and adapt my behaviour to use it (loading and unloading). But despite having the dishwasher machine in my kitchen, I still need the sink, and I still need a sponge and the Fairy liquid, and so on, because I wash pots and pans like that.\nBut a cobot dishwasher would stand alongside me at the sink. I would stack up the dishes and so on, and it would clean them and pass me the items to put away in the cupboards. I would get back the room previously devoted to the big machine. The cobot would use the exact same cleaning utensils as I do – and I could move it to go and do other jobs afterwards.\n\nWhile we’re on dream apps for domestic cobot arms:\nI open my (physical) post approx every 12 months. I pile it up over the year. It’s a pretty mechanical process to recognise each item, sort and stack it, and to pile up the recycling. If it could read the addresses, show me each unrecognised item (remembering my response for later), and run the batch process, that would cut a good few hours out of preparing my tax return.\nHow will the cobot be domesticated?\nThe mainframe was domesticated as the personal computer, and the PC was dismissed as a toy – and then came spreadsheets and then came desktop publishing, killer apps both.\nSo what’s the first home-use programmable cobot that seems ludicrous to begin with, but establishes a beachhead?\nPart of me wonders whether it will be cooking: kneading dough, sitting by the stove to flip pancakes, using sensitive fingers and eyes to cook the perfect steak, and so on. It could even wash its own hands.\nBut the kitchen is a pretty inhospitable first environment.\nPerhaps the first use is for hobbyists? Imagine painting miniature figures – hey arm, hold this; pass me the cobalt; rinse this brush and put it back. Or fixing a bike. Or assembling Ikea furniture.\nNone of these routes feels quite believable to me. But my takeaway is that the blocker is market entry. The technology is all there. If there are teams working on consumer smart glasses in readiness of them becoming commercially viable (which there clearly are) then I hope there are teams working on consumer cobot arms.\nSources\nI subscribe to a small handful of blogs which track the latest in robotics (thank you RSS).\n\nRobotic Gizmos\nSoft Robot Critics (on Tumblr)\nIskander Smit’s consistently excellent newsletter Target_is_New\n\nRecommendations welcome.\nAlso a shout-out to Robin Sloan’s 2018 novel Sourdough which, behind its deceptively gentle facade, is an exploration of human/non-human cooperation and where agency lies, whether that’s yeast or - relevant here - robot arms. (Or even machine learning, given that’s how Sloan collaborated to compose the fictional music of the Mazg for the audiobook.)\n",
    link: "/home/2021/08/25/cobots",
  },
  {
    title: "Computers should expose their internal workings as a 6th sense",
    date: "17.24, Friday 27 Aug 2021",
    content:
      "I kinda miss the days when I could hear the hard drive of my computer. If it was taking a while to response (say, when opening a big file), there was a difference between the standard whirr chugga chugga ch-ch-ch chugga seek pattern, and a broken kik kik kik. And you’d have an idea how long loading a file from disk should take, versus the silent “thinking” time afterwards.\nLikewise the fan: total silence would be a sign that the computer wasn’t working, but also the fan suddenly ramping up would be a sign for caution, maybe a rogue process had pegged the CPU.\nLIKEWISE, in 1949, the first computer to allow for loadable programs: experienced users knew healthy and unhealthy sounds of programs, particularly programs ‘hung’ in a loop.\nThe point is not the sound. You barely noticed the sound.\nThe point is that you felt you like were in psychic communion with the workings of the computer.\nYou don’t get ambient awareness with solid state components, and you don’t get this ambient awareness with the cloud.\nSo with Google Docs, or YouTube, you don’t really get a sense of whether the wi-fi is janky or a tap is taking a while because it’s [robot voice] pro-cess-ing or because it’s broken.\nIt would be neat to have 6th sense amplifiers between our world and the world of computers.\nWhat about a scarf or collar so the back of your neck prickles when somebody is talking about you on Twitter.\nOr a dowsing rod – a pocket-based buzzer that would go off when virtual content is nearby, like geolocated augmented reality, or a QR code that leads to an app.\nOr a ghost detector for homes, restaurants, etc that glows when someone is “visiting” in Google Maps/Facebook Pages or looking through a webcam? Maybe it would be better to control the air conditioning to produce a chill, or play barely audible infrasound, indications that there is a haunting in progress and the veil here is thin.\nPractically I should like a little ring to clip on an ethernet cable, or a sticker to put on a wifi-connected device, and it would glow with active bandwidth. So if my “smart” TV stalls (which it does) I can tell with a glance whether the app has crashed, the wifi is down, or the internet is wonky.\nNokia phones, back in the day, caused a stuttering static noise to sound from any nearby speakers, just before you received a call or text: ba b b ba b b ba. Analogue electronics eh. Radio interference.\nI used to think about it as reality buffering, the virtual clearing its throat before it manifests. Ahem. So here’s an old idea:\n\nWhat your email program should do before you get an email in an empty inbox, or your phone before it rings… it should make a little cough. If you hear it, you can close your inbox before it gets the email, or switch off your phone before it actually rings. We’d implement this by having one big button that only works in the quarter of a second after the cough.\nThe person on the other end would just get a tone like you were unavailable – they’d never know your phone was actually on to begin with.\n\nHere are the categories of information I’m thinking about:\n\nthe kind of stuff that shows up in Activity Manager or Task Manager or log files those kind of apps\nthe stages of the various progress bars that are happening on the cloud, behind the web browser\nwhere a database, wherever it is, references a thing which is currently relevant, whether that’s somebody looking up your name on Google, or running a credit check on your bank account (the app on your phone should glow)\nwhen an interrupt triggers deep in the stack, like a email comes in but it hasn’t downloaded yet\nthe rate of things: file access, bandwidth on the wire, the number of CPU cycles running on my behalf in the data centre – even if it isn’t local.\n\nThe workings of the machine before the interfaces updates.\nThen I’m asking for these to be made continuously available to peripheral awareness, just below the level of consciousness, using sound, temperature, vibration, that kind of thing. Enough for unconscious pattern recognition to occur, and a sense of unheimlich or premonition to arise.\nTo put it another way:\nLet’s build a new sense for humans, a data sense, which is synesthesiatically translated into our regular physical senses. And then see what happens, I guess.\n",
    link: "/home/2021/08/27/data_sense",
  },
  {
    title: "Pantheons of gods map to the shapes of complex systems",
    date: "16.06, Wednesday 1 Sep 2021",
    content:
      "It would be interesting to do an analysis of the personalities of ancient gods, correlating that with a folk understand of the dynamical systems that they each represent.\nMagic was functional (that is always my starting point). That is to say: spells, predicting the future, witches, etc, had some kind of useful function in society. The practise of magic was efficacious. Likewise: pantheons of ancient gods.\nLooking at the gods, they represent powerful forces that shape the world that we live in – war, love, the sea, harvest, parties, hunting, and so on.\nThese aren’t distant and asymmetric systems of force that affect us but we can’t affect them, like the weather, at least pre Industrial Revolution. (BUT! We can control the impact of weather fluctuations on us, to a degree, even if we can’t control the weather itself – being cautious with food stores means rain variation matter less, for example. And large forests seem to promote rainfall; the climate has always been interactive, and you bet humans learnt those geoengineering feedback loops over tens of thousands of years.)\nWar, love, the sea. These are systems that, in the ancient world, there was limited capability to gather information about, beyond immediate sight, but they none-the-less responded in typical if not predictable ways.\nSay: war. The complex system of “war” is capricious and hot-headed. Long-term thinking and a combination of continuous diplomacy and strength (even when there is no obvious purpose) pays dividends, or at least maintains the peace. It always serves to be slightly more paranoid than necessary, because in the low likelihood that war does blow up, the consequences are so terrible. So it’s better to appease faint signals now rather than thoughtfully respond to hard data later.\nNow, from what little I remember about the ancient gods, does that sound like the character of Mars, god of war? Dunno, vaguely… more reading required.\nHere’s my hunch:\nModel the complex system, and pick out a bunch of metrics. SUCH AS… volatility, steepness of the reward/risk severity curve, response predictability, and so on.\nThen map these onto the psychology of individuals, using say the Big Five personality traits (agreeableness, neuroticism, and the others) since those seem pretty universally cover the phase space of human character.\nIf I’m right, then treating the abstract complex system as an individual person is a effective heuristic for successful interaction with the system itself.\nTo test this with another force:\n\ncompare the system dynamics of love to the documented character of the Roman god Venus; or,\ncompare the system dynamics of blacksmithery to the documented character of Vulcan.\n\nVenus may have a character that rewards risk! To appease Vulcan, it may be especially important to build a reputation for reliability and consider your hammer-blows with care! (Success in blacksmithery is as much about building a business from the opaque complex system of reputation, as the complex system of shaping iron.)\nSuccess in these realms is often called “luck” and that’s a good way to encapsulate the highly varied system response. But it’s the luck of the gods. If you acted in such a way as to please Mars (or rather, the priests of Mars), would you be lucky in matters of war? I suspect you would.\nThis throws light on the role of the institutions and people around the ancient gods – it doesn’t make sense to consider “gods” separately from their interfaces. As previously discussed, ancient magicians were management consultants (October 2020). So how do we interpret priests?\nJump forward 2,000 years to the present day; think of the ways we understand complex systems today. The functional mechanism to model, say, the economy is not the equations. Sure there are equations and frameworks, but these are accessed always via economists – actual human people who have knowledge of the available frameworks, who know which to choose, who choose how to evolve them, and who have built expertise (or rather, an intuition) in how the economy behaves.\nEconomists are the priesthood of the economy.\nJust as meteorologists are a priesthood of the weather, and Donald Rumsfeld and Henry Kissinger were Mars’ high priests of war – sorry, geopolitics.\nSo in a way we’re no different from the ancient Romans. We no longer refer to our gods as gods, but we still have our mix of formal and intuitive understandings of complex forces in the world, and we still have our priesthoods.\n",
    link: "/home/2021/09/01/gods",
  },
  {
    title: "Sending lo-fi virtual realities to aliens and also to each other",
    date: "11.09, Thursday 2 Sep 2021",
    content:
      "Instead of sending flat messages into space, why not send an explorable environment?\nThis idea is in Extraterrestrial Languages, Daniel Oberhaus’ excellent history of attempts to talk to aliens (read last year).\ne.g. there’s the famous Arecibo message, transmitted in the direction of Messier 13 in 1974 (the message will arrive in 22,000 years, by which time M13 may have moved out of the way). The message is a pixel grid, 73 by 23, which shows atomic numbers and a pictogram of a person.\nHere’s a list of other interstellar messages, and they’re the same more-or-less: data with enough clues to say “hey try and decode me” with some fundamental information communicated as simply as possible. Who knows what alien intelligences might be like.\nBUT:\nPaul Fitzpatrick’s insight was that if you can send a message, you can send mathematical equations. And if you can send equations, you can send the rules of a programming language. And then you can send executable code. And then…\n\nThe idea behind Cosmic OS is that by beginning with simple math, it is possible to construct a programming language that can simulate an interactive virtual environment for an extraterrestrial intelligence. Such a rich environment would in principle allow the extraterrestrial to manipulate the program to get a better idea of the social and behavioral properties of the Earthlings who sent the message.\n– Daniel Oberhaus, Extraterrestrial Languages\n\nHere’s CosmicOS on GitHub. The code is open; it’s an ongoing project. (Cosmic OS hasn’t yet been sent into space.)\nThere’s a demo too. You can see the message, and run the code. There are a large number of statements, building up to abstract objects of “things” and “rooms” and “robos” (things that can move) and a few others.\nUntil eventually…\n“New York” and “Boston” are connected, north and south, with an “autobus” that moves between them.\nI mean, it’s basic.\nBut it shows the power of Fitzpatrick’s idea.\nInstead of a description, which is what previous messages have been, an interactive environment - even a simple one - shows ontology, behaviour, and context. It allows the alien to build their own understanding of our world because they get to experience it, well, not exactly directly, but almost. It’s such a better way to transmit knowledge and understanding.\nIf we can transmit immersive environments to aliens, why not to each other?\nInstead of sending a Powerpoint deck, why not a self-contained wiki? A packaged hypertext.\nInstead of preparing a Google Doc, why not build a miniature explorable world? Not VR in photorealistic 3D, but a virtual reality of (mainly) text.\nI would like to email a “file” which is a playable, navigable space of words, pictures, and embedded bots to have conversations with, at the end of which the recipient understands my ideas just as much as if I had used bulleted lists and diagrams. Their comments should come back to me as in-game questions that I can answer with environmental embellishments. This “world document” should be as easy to author, and as endlessly flexible, as a spreadsheet.\n",
    link: "/home/2021/09/02/cosmic",
  },
  {
    title: "I love this made-up sound machine",
    date: "20.21, Tuesday 7 Sep 2021",
    content:
      "One of the side-effects of being a plain text dogmatist is that I don’t have images on my blog, so I’m going to have to describe this, and you’re going to have to actually follow a hyperlink if you want to see it (and honestly nobody does that).\nHERE’S THE THING: BF-130 Dronal Birdsong Transducer which has the description, A made-up sound machine discovered in a forest clearing.\nIt’s an image of a blocky device that looks like a component of an old-school hi-fi, and it’s standing on tall black legs in a blurred out forest. On the front is a label: BF-130 Dronal [etc].\nTap, grab, and pan the image – it’s a 3D model.\nTap the image of the power button on the device: drone music plays. Turn the three dials on the device to adjust the music.\nThat’s it.\nThis is, to me, somehow, and I can’t put my finger on why: CAPTIVATING.\n(Yes it’s being sold as an NFT, a “non-fungible token,” which is an emerging technology to associate rights like “ownership” with digital assets such as 3D models, which are otherwise - in the old world - infinitely replicable. But that’s not what I’m talking about right now.)\nSimilarly captivating:\nThe Buddha Machine device by China-based electronic music act FM3, here described on their Wikipedia page:\n\nRoughly the size of a pack of cigarettes, the device features a single toggle switch to cycle through samples, a combined power and volume dial, and an integrated speaker. The device contains a chip holding nine digitally encoded drones, ranging in length from 1.5 to 40 seconds. The name and idea is derived from a popular Chinese device that intones repeating loops of Buddhist chanting.\n\nIt’s gorgeous. You hold it in your hand and press a switch to hear, with some static, via a cheap audio chip through a cheap plastic speaker through the mass-produced output of the vast factories of China: the sound of the cosmos.\nI’ve got one upstairs, and I hope desperately that the battery hasn’t leaked. Mine is green.\nThe thing is that I don’t sit on Apple Music or YouTube listening to drone loops like this. (Okay I admit I have lost a couple hours to large gong YouTube but who hasn’t.)\nAnd yet.\nHere I am,\nstaring at the simulation of a fictional device in a forest that doesn’t exist, tuned into the sound 100%.\nSo my M.O. is to watch out for surprising moments of experience like this. It doesn’t matter if it doesn’t make any sense logically, or if it seems absurd, or how tiny it is. But VR feels like this, and physical things connected to the internet felt like this once upon a time, and GPT-3 generated text still feels like this (here are my posts),_and my take is that once you can identify something which is the kernel of a viscerally _new experience, then that’s something like rare primordial matter that you can shape with your hands into something fuller in the future. I don’t need to understand it.\nThere are ways to experience digital sound that are better and more transporting than the ways we currently experience digital sound, that’s all I’m noting here. That’s funny.\n",
    link: "/home/2021/09/07/drone",
  },
  {
    title: "The surprising effectiveness of writing and rewriting",
    date: "17.53, Thursday 9 Sep 2021",
    content:
      "In The New Yorker earlier this year: The first major interview with one of the most revered comedy writers of all time.\nJohn Swartzwelder, comedy writer, separates “writing” and “rewriting.”\n\nSince writing is very hard and rewriting is comparatively easy and rather fun, I always write my scripts all the way through as fast as I can, the first day, if possible, putting in crap jokes and pattern dialogue–“Homer, I don’t want you to do that.” “Then I won’t do it.” Then the next day, when I get up, the script’s been written. It’s lousy, but it’s a script. The hard part is done. It’s like a crappy little elf has snuck into my office and badly done all my work for me, and then left with a tip of his crappy hat. All I have to do from that point on is fix it. So I’ve taken a very hard job, writing, and turned it into an easy one, rewriting, overnight. I advise all writers to do their scripts and other writing this way. And be sure to send me a small royalty every time you do it.\n– The New Yorker, John Swartzwelder, Sage of “The Simpsons” (2021)\n\nI wonder what’s going on here, deep down, because I recognise it. Sometimes I’ve been circling a topic for weeks and just can’t figure out how the essay, or talk, or report or whatever is going to work – and what unblocks it is to tell myself: stop thinking, just write what’s in your head however poorly.\nI always come at that realisation far too late. One characteristic of this trap is that I’m slow to recognise that I’m in it.\nBut if I started writing too soon, it would be terrible and not in a redeemable way.\nSo there’s a difference between productive thinking and procrastinating thinking, even though they feel the same.\nRELATED (in my head) is this post about decision making from Rands’ blog on leadership: Ok. So, You Can’t Decide.\n\nFirst, the paralysis might mean you’re subconsciously aware you’ve missed an essential aspect of the decision\n\nBUT, says Rands, sometimes the move is sometimes to just yolo decide.\nAnd then:\n\nYou instantly become mentally limber.\n\nAnd:\n\nA profound change of perspective follows making a decision. It’s no longer theoretical; it’s happening. You are doing something as opposed to talking about doing something. Even better, as potential consequences begin to arrive, you gather initial essential data on the quality of your decision.\n\nThree guesses about why writing/rewriting works as a process:\n\nThe act of writing the first draft creates new “essential data” that feeds the imagination and makes possible figuring out the second draft. (An analogy: sometimes working with numbers is unblocked only by making a graph. The visualisation has provided “essential data”. So perhaps there’s something similarly illuminating about a textual linearisation of mental forms.)\nOr: In your head, ideas expand until they max out “working memory” – and it’s only be externalising them in the written word that you have capacity to iterate them.\nOr: Good writing necessarily takes multiple edits, and the act of writing and act of rewriting are sufficiently different that performing both simultaneously is like rubbing your tummy and patting your head.\n\nWriting often feels like having a conversation with myself. I stare at a sentence and reply by revising or writing another.\nWriting-as-thinking and writing-as-communication and the interplay between them. A creative act of sculpting thought outside an individual mind. What a magical thing is the written word.\n(I wonder if software tools could support this process more directly. Like, could I dictate in a rambling fashion a vague idea, and an AI text generator turn it into a cogent paragraph for me to revise? And so on and so forth.)\n",
    link: "/home/2021/09/09/rewriting",
  },
  {
    title:
      "Bronze- versus iron-based economics changed the kind of societies that could exist",
    date: "19.11, Monday 13 Sep 2021",
    content:
      "In the long run, is economics the mould that shapes society?\nI’ve been learning about the Late Bronze Age collapse recently (that’s the Wikipedia page).\nA period of a few decades between c. 1200 and 1150 BCE saw the cultural collapse of the Mycenaean kingdoms, of the Kassites in Babylonia, of the Hittite Empire in Anatolia and the Levant, and the New Kingdom of Egypt; the destruction of Ugarit and the Amorite states in the Levant, the fragmentation of the Luwian states of western Anatolia, and a period of chaos in Canaan.\nThese civilisations all interacted with one another, and had a carefully negotiated co-existence – the first international diplomatic system known to us – discovered via a cache of clay tablets found in Egypt called the Amarna letters.\nAfter collapse: trade and diplomacy shrunk; literacy and quality of life decreased.\nWhat caused it? Candidate explanations include:\n\nvolcanos, droughts, etc\ninvasions by the mysterious Sea Peoples\nnew military tactics\nand more.\n\nBut those named ones feel like stressors not causes. And others candidates (political collapse; class struggle) sound again not like causes but consequences.\nSo my favourite candidate is the shift from bronze to iron.\nHere’s an episode of In Our Time on The Bronze Age Collapse (June 2016). I learnt a bunch.\nFor example, about bronze itself:\n\nBronze was vital for power: institutions and armies. It was used for chisels to cut stone for building programmes; it was used for weapons (in particular is allowed swords) to wield military power.\nBut bronze is rare, being made from copper and tin which are not found everywhere: It is plentiful enough that it’s widely available, and rare enough to have to capture those [trade] routes and so on. (Even the knowledge of how to create the bronze alloy is rare.)\n\nIron was emerging around the time of the Late Bronze Age collapse, although it wasn’t common until the 7th century BC (400 years later).\nBut iron undermines bronze-based power structures. Again from that episode:\n\nOne could argue that iron, which of course unlike copper and tin is almost everywhere, so is readily accessible - so you don’t need to build long-distance trade routes to find it and so on - you can take a broad view that that it undermines the ability to monopolise long-distance trade. Therefore smaller entities can get involved.\n\nWhen states arose to replace those the collapse, they looked different: new people organised politically in a different way. The new states were smaller and more numerous than the older, grander palace kingdoms.\nHere’s the story I tell myself about bronze:\nIt sounds to me like bronze is intrinsically connected to the foundations of how power is established and maintained.\nOver time, bronze requires and allows for great concentrations of wealth, and that’s why we see this small number of incredibly wealthy, grand palace kingdoms. Their prestige, after centuries, relies on highly efficient extraction of wealth from their networks.\nBut then comes iron. Iron is an evenly distributed technology (as a material, and  knowledge of how to work with it). It can’t be monopolised.\nEven in iron’s infancy, it allows for a kind of peer-to-peer trade and wealth to arise.\nAnd that destabilises the status quo. Which is turns out has become brittle.\nI think of stressor events on a system a bit like shaking up a box full of oddly-shaped rocks. During the shaking, the box “settles” towards its low energy state; the rocks end up more closely packed. In previous centuries, stressor events have shaken up these civilisations, and they’ve “settled” into palace kingdoms.\nBut now the status quo, the low energy state, has altered. Iron is present. So the stressor events (climate change, invasions) “settle” the system towards a new status quo, one which doesn’t involve the palace kingdoms.\nAnd so they collapse.\nWe’ve seen this story before!\nAround 13,000 BCE, Europe warmed out of its Ice Age, and mobile hunter-gatherers settled into villages. Long-distance trade routes emerged around seashell trade, used to display wealth – wealth disparity and elites emerged around that trade.\nBut a thousand years later, the Ice Age re-emerged (temporarily). The villages vanished… and the elites too:\n\nWealth and power had evidently been dependent on sedentary village life. This provided the elite with the opportunity to control the trade that brought seashells and other items to the villages. A return to mobile lifestyles swept away the power base and society became egalitarian once again.\n\nI wrote this up last year: Some rambling thoughts about the stuttering end of the last ice age and what lockdown means (April 2020).\nSo these are two stories of economics providing the attractor to which the chaotic system of society gradually drifts.\nThe picture in my head is that certain kinds of material scarcity allow for the monopolisation of exchange, and that allows for the hoarding of wealth and the creation of elites, where the elite system becomes self-reinforcing… and increasingly efficiently but ultimately brittle – until the material scarcity itself changes. Then we see collapse.\nHUGE CAVEAT: this is all a wild guess based on not-even-adequate reading about stuff that happened and a strong dose of systems thinking. I find all this fascinating.\nIf I could go back and do it all again, I would probably study history.\nAnd if bronze is technology which can be monopolised, and iron is technology which is evenly distributed, does the story of the Late Bronze Age Collapse hold lessons for centralised versus decentralised technologies in modern times?\nDirectly: I’m thinking of finance, and data.\nIndirectly: I’m thinking of social communication. Do bottlenecks in the “trade routes” of communication (that is, social media) necessarily lead to wealth disparities in the equivalent currency – which in this case would be social capital? That is, the more efficient our global broadcast systems, the more extreme celebrities we create?\n",
    link: "/home/2021/09/13/bronze",
  },
  {
    title: "Filtered for calibration",
    date: "14.39, Friday 17 Sep 2021",
    content:
      "1.\nHello, World!\nFrom the Jargon File: Traditionally, the first program a C coder is supposed to write in a new environment is one that just prints “hello, world” to standard output.\nC is an ancient language. The first documented appearance of “Hello, World!” is in the 1972 training manual for C’s predecessor language B, written by Brian Kernighan (source).\nI use it, whenever I’m writing a new program in any language. Perhaps you do too. It’s half habit, half being connected with the lineage, and half a proof that everything deeper in the stack is working as expected… the terminal is outputting text so I can see it; the language interpreter was compiled properly; the OS has enough memory; the electrons are still doing their electronic thing – all these things have to be tested once, they can’t be assumed.\n2.\nIch bin ein Paradigm Shifter, Karlheinz Brandenburg, the inventor of the MP3 and his muse: Suzanne Vega.\nMP3 is remarkable not just because it makes music into a very small digital file format, but because that file format was the lynchpin of an entire industry. Files can be played, bought, and sold. A multiplayer economy! The power of the file!\nTo create MP3, Brandenburg had to appreciate how the human ear perceives sound.\nHe heard Suzanne Vega’s wonderful acappella song Tom’s Diner playing down a corridor and adopted it.\n\nBecause the song depends on very subtle nuances of Vega’s inflection, the algorithm would have to be very, very good to select the most important parts of the sound file and discard the rest. So Brandenburg tested each refinement of his system with “Tom’s Diner.” He wound up listening to the song thousands of times, and the result was a code that was heard around the world. When an MP3 player compresses music by anyone from Courtney Love to Kenny G, it is replicating the way that Brandenburg heard Suzanne Vega.\n\n3.\nIn 1974, Martin Newell made important contributions to the rendering of 3D graphics as part of his PhD at the University of Utah.\nBut he needed a sufficiently complex object for his demos.\n\nOne day over tea, Newell told his wife Sandra that he needed more interesting models. Sandra suggested that he digitize the shapes of the tea service they were using, a simple Melitta set from a local department store. It was an auspicious choice: The curves, handle, lid, and spout of the teapot all conspired to make it an ideal object for graphical experiment. Unlike other objects, the teapot could, for instance, cast a shadow on itself in several places. Newell grabbed some graph paper and a pencil, and sketched it.\n– Nautilus, The Most Important Object In Computer Graphics History Is This Teapot (2016)\n\nThe Utah teapot.\n\nThese days, the Utah teapot has achieved legendary status. It’s a built-in shape in many 3D graphics software packages used for testing, benchmarking, and demonstration. Graphics geeks like to sneak it into scenes and games as an in-joke, an homage to their countless hours of rendering teapots; hence its appearances in Windows, Toy Story, and The Simpsons.\n\nThe traditional test that you run through the pipeline to check everything’s working. I guess every specialism has something like this – testing, testing, 1, 2, 1, 2. I wonder if they have a generic name. It would be fun to collect them.\n4.\nThe Forgotten ‘China Girls’ Hidden at the Beginning of Old Films (Atlas Obscura): Used as quality control, these haunting images were never meant to be public.\nFaces of people (typically women, almost always white) at the beginning of a film reel, to help the projectionist check that everything is functioning as expected.\nThe image carries bias with it. Colour film was terrible at depicting people of colour for years and years and years, with the issue being addressed only in the 1970s in response to advertisers: wood furniture and chocolate makers began complaining that Kodak film wasn’t capturing the difference in wood grains and chocolate types. Shocking.\nTANGENTIALLY:\nBeagle 2 was the ESA lander dispatched to the surface of Mars in 2003… and lost. Cameras on landers have calibration images for colour correction etc, checking against a known image, and Beagle 2 used a custom Damien Hirst spot painting.\nHere it is: “Beagle 2 Calibration Target”, 2002, natural pigments on aluminium, .35 x 3 x 3 in.\nWhen we get people to Mars, if we settle the surface, they should go to where the lander was eventually found (it was found by satellite in 2015) and build a gallery around it. Leave the art in situ.\n",
    link: "/home/2021/09/17/filtered",
  },
  {
    title: "A brief thought on the miracle of togetherness",
    date: "09.16, Wednesday 22 Sep 2021",
    content:
      "It’s a miracle that we can feel togetherness over the internet. I thought it was a miracle when I got my first modem in 1994, and I think the same today.\nThis collection of machines is transparent to human presence! Like the air is transparent to light.\nThere’s no necessary reason why human presence transmits through electricity and silicon. Books carry thought and stories and they are incredible in their own way, and we give the written word its deserved credit. Radio broadcasts feel live but in only one direction.\nThe internet creates new architectures that the brain feels as space yet don’t exist. The nuances of phatic communication, presentation of self, shared emotions, and community are somehow translated, sent, and received in some mysterious social synaesthesia of digital impulses.\nThis electronic telepathy works so well that we barely notice it, let alone question it.\nI include in this our non-human co-occupiers of the world (existing and new), and the varied ways of configuring individual and group identities.\nI find the parameters and boundaries of togetherness endlessly fascinating.\nAnd surprising.\nIts huge variety through cultures and history; the way the internet continues and inflects it; how togetherness on the internet can (and should) be better.\nI think that the exploration has been a thread through my whole career. This particular magic is not the most important thing ever, to everyone, but to me it seems like I’ve always been circling it. And it’s good to put a finger on that fact, even though it probably seems obvious to everyone else, because I can use togetherness (its exploration, boundaries, landscape, and potentialities) as a structuring principle for whatever I think about next.\n",
    link: "/home/2021/09/21/playhead",
  },
  {
    title: "Why not replace bitcoin’s proof of work with proof of astrophysics",
    date: "18.22, Friday 24 Sep 2021",
    content:
      "Cryptocurrency is interesting, may precipitate the collapse of civilisation, and is extremely troubling re: carbon.\nInteresting because: NFTs allow rights (such as ownership but not exclusively) to be attached to digital objects; crypto techniques underpin a newly centralised internet swept free of gatekeepers from identity, to payment, to data centres.\nMay precipitate collapse because: the centralisation of handling money has led to giant and powerful financial institutions, and the decentralisation of money smells like the shift from centralised bronze production (which led to captured trade routes and giant palace kingdoms) to decentralised iron, arguably leading to the Late Bronze Age collapse, as previously discussed. LOOK: I don’t honestly think we’ll see a collapse of civilisation, but the banks may well reconfigure to become smaller and more numerous. Besides I find a potential decentralisation of energy production more fundamental and intriguing.\nExtremely troubling: cryptocurrency takes a lot of electricity to run. And that creates a lot of carbon. Really not good.\nCrypto is underpinned by a technique called proof of work (PoW) and I understand that this is the troubling carbon bit that needs to be replaced?\nHand-waving alert, obv. I’m not close enough to crypto to understand, but if I give the broad outlines of what I mean then someone else may fill in the gaps…\nProof of work relies on some mathematical technique which is hard to figure out for the first time, but then easy to verify. For example:\n\nA hashing algorithm generates essentially a random number from a known starting number (it’s the same each time for a giving starting number). This is quick and cheap\nSome hashes will be rare, say ones that start with the number “99”. So finding a starting number that leads to a rare hash requires running the algorithm a bunch of times. This is slow and expensive (and produces a bunch of carbon because it uses electricity)\nSo finding a rare hash is expensive to do but cheap to check.\n\nI don’t entirely understand how this ladders up to consensus over an entire transaction history, as recorded in the shared blockchain, but a technique like this is key.\nBecause of the essentially wasted electricity and carbon cost, there are a couple of other replacement techniques being mooted, instead of crunching numbers.\n\nTransactions are verified by parties with authority – let’s say central banks. Well that seems counter to the decentralised nature of the beast.\nTransactions are verified by parties with skin in the game, ie wealthy people. This is called Proof of Stake and it sounds like it just puts the power in the hands of the rich.\n\nNeither seems like a solution in the spirit of cryptocurrency. So what is to be done?\nHOW ABOUT:\nReplace the Proof of Work function with something which follows the exact same form (expensive to perform, cheap to verify: a zero-knowledge proof) but that outgasses socially useful work as a side-effect instead of carbon.\nBut what should it be?\nScientific conferences in pharma versus astronomy, the difference:\nPharma conferences are full of scientists playing their cards close to their chest. They don’t want to give even the tiniest hint about their research because somebody else, knowing what is being chased down, could get there first. So they don’t talk about their work or what they’re trying to figure out.\nAstro conferences, on the other hand, are free and open. Seen a weird blob in the sky that might be a novel black hole or an alien superstructure? Show everyone the printout of the telescope image, it doesn’t matter! The night sky is so colossally huge that nobody will ever be able to find the same spot without you telling them the coordinates. And without knowing that, they can’t publish so your research is safe.\n(I can’t remember who shared this anecdote with me, sorry.)\nWhat I learn from this:\n\nPointing a telescope at the night sky is a essentially hashing algorithm. Give the telescope coordinates, you get back a random but consistent constellation of stars.\nHunting to discover a constellation that matches a particular, rare pattern (say: an equilateral triangle between the three brightest stars in the square) would be hard and slow.\nBut verifying that given coordinates lead to a given constellation is easy (or at least, as easy as pointing a telescope).\n\nAha!\nWhat if… looking at the night sky is a drop-in replacement Proof of Work function?\nThe side-effect of loads of crypto miners scraping the night sky with telescopes won’t be carbon, it will be a map of the stars.\nThat hyper-detailed and growing map of the stars becomes a public resource for scientists to better understand the cosmos, and also increases our chance of spotting aliens.\nCurrently crypto miners are incentivised to re-activate coal power stations to get electricity. Now they’ll be incentivised to fund new space telescopes instead.\nBonus: the current crypto PoW method has the concept of “difficulty” built in, and it is ramped up over time basically to account for computers getting faster. With telescopes you can increase difficulty by requiring that you look at smaller and smaller patches of sky. It takes longer to collect the photons to see fainter stars, or it requires building new and larger telescopes, both of which correspond to increasing difficulty parameters.\nCaveat: I clearly don’t know what I’m talking about.\nBUT\ncould we invent new underpinnings of cryptocurrency that pump out social good, rather than pumping out carbon? It would be good to assemble a committee of smart people to figure that out.\nIn the meantime we could just get started. NASA and SETI should create a coin. The James Webb Space Telescope (Hubble replacement) launches in December. Dedicate an hour a day of telescope time to this crypto project (for pay) and fund the development of the next telescope with the proceeds.\nLet’s power the new global financial machine by searching for extra-terrestrials.\n",
    link: "/home/2021/09/22/togetherness",
  },
  {
    title: "The emerging patchwork upgrade to the multiplayer web",
    date: "16.45, Monday 27 Sep 2021",
    content:
      "One of the tech things I’m tracking is how the web is slowly going multiplayer.\nThough in a specific patchwork way… Yes there are full web apps that are multiplayer, like Google Docs where you have collaborative editing and everyone sees everyone else selecting and editing text, or Figma which is design software with co-presence, so each document has a flurry of mouse cursors chasing round the canvas. And I think I’ll include in this list of apps the wonderful Sprout: a persistent space for small group video chats which you can decorate and arrange as you like (previously named MakeSpace, discussed in July 2020 in the context of social, spatial interfaces).\nAll brilliant.\nBut I am more interested, at this point, in the elemental building blocks of the web, and how these Lego bricks might become multiplayer and be used to upgrade the web bit by bit.\nFOR EXAMPLE (these are both developer-facing projects):\n\nMapus (GitHub project with animation): A map tool with real-time collaboration. You embed this on a webpage wherever you would see a regular Google Maps embed, like on a community wiki or a blog, but it’s immediately multiplayer. You see the cursors of anyone else who is on the same page as you at the same time, and annotations made by you (and them) persist and are shared.\nTipTap (project site with demo): Embedded text editor with Google Docs-style collaboration. This goes anywhere you’d see a text entry box, such as when you’re writing a blog post or writing up a feature request. Again it’s natively multiplayer: you think you’re just writing into a box but then you see the colourful cursors of other edits also there, with real-time updates of their additions and changes.\nI’ll add my own social attention prototype which shares text highlights for everyone simultaneously looking at a single webpage.\n\nIf you know of more projects like this, please let me know!\nWhat’s interesting here is that these don’t demand re-platforming of entire websites. They are piecemeal, backwards-compatible upgrades that change out single blocks of existing websites and, in doing so, bring them to life.\nThey focus on creating a social user interface, which I like, but there’s a lot that remains unsolved. Like: how do we know who a user is and where do the avatars come from – is there a role for an identity provider? How can a user choose who to show and who to hide – is there a role for a trust provider? Where is the data stored, and is it shared across sites, and who owns it? All of that.\n(And, intriguingly, these unsolved technical layers are addressed by the Web3 world, an emerging technology stack which is inherently distributed and includes personal ownership of identity, data, assets, payments and so on.)\nWhat’s common, in what I’m seeing, is that there is a nuanced approach to the social experience.\nThere is presence (the sensation of togetherness, which creates a sense of “place”). There is fine-grained, real-time editing, which means that collaboration can occur. And there is persistence of data, so it’s possible to build or accrete over time. So there’s a kind of gradient of social interaction which is being filled out.\nAre the organisations looking after the web as a platform looking at this? I’m thinking of W3C and also Google Chrome and Mozilla. There’s an opportunity to catalyse this movement by knitting together existing standards projects.\nThe hard tech that originally powered collaboration tools like Google Docs is now available to all developers as JavaScript libraries, and in addition to seeing it power parallel apps (like Figma), it might be interesting to think about bootstrapping the whole ecosystem to the next level: a newly social, distributed, real-time multiplayer web.\n",
    link: "/home/2021/09/24/pow",
  },
  {
    title: "Three fantasy policies around jobs",
    date: "20.37, Thursday 30 Sep 2021",
    content:
      "If I were leader of a political party, there are a few things I would do specifically around jobs. This is not an exhaustive list. These are three off the top of my head.\nBtw I would talk about the climate crisis the whole time, and use that to shape policy. It’s the big existential thing for the next decade (and more) so everything has to be seen in light of that.\nA big question is: what is the dividend of technology? Like, the internet is this crazy powerful means of coordination, and that’s new in the last 50 years, so what is it for? The point of progress is to improve human lives. But that doesn’t happen automatically.\nSo pick something basic: let’s set an ambition that everyone gets to work a 4 day week. The dividend of technology should be to raise wages (i.e. productivity but where the surplus doesn’t go entirely to shareholders) and create a welfare safety net such that we all have more leisure time.\n(Note that I am not a believer in Universal Basic Income. I believe that the right to contribute to the world we share - via “work,” which is the name we give to useful activity - is every bit as important as the right to share in the wealth produced. At best the focus on UBI obscures the right to meaningful contribution; at worst it exists as a pay-off from inhuman corporations to turn us into disempowered, non-contributing consumer drones.)\nMy party would say that we won’t get to the 4 day week in 5 years or even 10, but it will be measured and reported and used as a North Star.\nI would lean into the changing nature of work: primarily the gig economy.\nOn the gig economy, yes gig couriers and gig food delivery drivers and so on are taken advantage of. But I don’t put that down to the gig economy specifically: that’s just how companies are, and the mechanism of employment dodges the standard protections.\nBut talk to some of the workers, and they enjoy the flexibility, freedom, and the direct gearing between effort and income.\nEmbrace change. And make sure it matches our values.\nSo I don’t think gig economy workers should be merged into the regular employee workforce. Create a new category of worker who is not actually inside the company, has limited employee benefits, and enjoys a certain amount of freedom – but their destiny is somehow bound up with the companies they rely on for gig. (As previously discussed in, oh my gosh, 2014.)\nWhat to do with this new category? Focus on mutualism.\n\nCreate a new tax for gig economy “marketplaces” that pays into the welfare state, and also an income insurance plan that substitutes for notice periods and other forms of employment protection – the point would be to make regular employees and gig workers employees substitutable from a cost perspective for the firms, and leave the choice in the individual worker’s hands.\nCreate mechanisms where the worker can participate in share option schemes. If an Uber driver’s financial destiny is intrinsically dependent on Uber, then in addition to taking on the risk (which is what happens currently) then they should also share in the upside. Every dollar earned by a driver should also give them a tiny fractional share option. (For that matter, every dollar spent by a PASSENGER should also result in that passenger being granted a tiny fractional share option. Because of network effects in marketplaces, passengers are just as responsible to Uber’s success as every other component.)\n\nMutualism. Neither party (worker nor firm) should be net-net taking advantage of the other, in order to allow full reign to choice. Of course our goal is to find win-wins – and each benefits from the other’s success.\nThen, a distributed university for the 2nd career.\nPeople now change jobs - often radically - multiple times over the course of their career. Sometimes by choice. Sometimes because the type of thing they do is no longer relevant (LIKE: manufacturing in the UK in the past; call centre workers in the future, as voice interfaces and expert systems really come in).\nEducation and training no longer comes solely in the first couple of decades of life.\nSo I would create a new university (academic and vocational) for people in their 40s. Everyone would get a go: there would be loans/subsidies for it.\nThe goal would be to open up retraining to totally different, modern careers, for everyone.\nLearning from the pandemic, hybrid education is potentially something very effective. A lot of education can be delivered virtually, but there is still a benefit to having a cohort and building a network. Perhaps the way this could be delivered is via colleges in every town that function like a cross between co-working spaces, libraries, and canteens, but with really great internet connections and support staff. You would show up, be timetabled, and get guidance, but all the courses would be over video.\nAll of these policies cascade down to other interventions.\nFor example, to implement the delivery of education online, to everyone, you want to reduce friction in getting on the internet.\nWhich means you probably want to nationalise broadband and create a universal minimum service guarantee. This is good for the education policy but also it should be loved by businesses. Just as Amazon wouldn’t be able to run their e-commerce without roads (so that warehouse workers can get to work, and orders can be delivered) and therefore it makes sense that roads are paid from taxes, Amazon - and others - need the internet for consumers and for an educated workforce. Cascading the policy down, internet access gets thought of as national infrastructure. (A good economist should be able to show this with numbers, I’m sure.)\nI’m sure there are other cascading policies, thinking about all of the above.\nNobody’s going to make me king but I would like to see some more ambition from politicians to argue for the value of the state, and what it’s good for, and to find ways to build an actually progressive society for the 2020s (instead of trying to regulate what we have now, which seems like it will waste energy). See these suggestions in that spirit.\nYeah, so.\n",
    link: "/home/2021/09/27/multiplayer",
  },
  {
    title: "What to call execution by electricity in 1889",
    date: "21.11, Wednesday 6 Oct 2021",
    content:
      "Years ago I read every issue of Electrical Review magazine from the 1880s and 1890s.\nOr at least leafed through. I was in the library anyway (you can prise my British Library reader pass from my cold dead hands) in the middle of a long unrelated project, and sometimes you just need to use the fact there are centuries of STUFF in the stacks you can just ask for, and spend a day like a pig in the proverbial. \nThe reason being:\nI had recently read Carolyn Marvin’s excellent social history When Old Technologies Were New (1988; on Google Books), subtitle:    Thinking About Electric Communication in the Late Nineteenth Century.\nThe 1880s saw the maturity of the electrical telegraph; the 1890s the roll-out of the electric light.\nMeanwhile they were (a) understanding electricity as a phenomenon; and (b) inventing wildly to figure out what it could do. Very much like the internet today.\nThere’s a throwaway comment in the book about, well:\n\nIn response to an inquiry about the best word to express “execution by electricity,” the Electrical Review reported a variety of suggestions, including elektrophon, electricize, electrony, electrophony, thanelectrize, thanelectricize, thanelectrisis, electromort, electrotasy, fulmen, electricide, electropoenize, electrothenese, electrocution, electroed, electrostrike, “and finally joltacuss of voltacuss.”\n– Carolyn Marvin, When Old Technologies Were New (p50)\n\nReference given in the footnotes:\n“Which Shall It Be?”, Electrical Review, Aug. 17, 1889, p. 20\n(Ultimately, of course, and this is a bit grim, execution is execution. The method is hardly what matters. But watching people figure out naming is always fascinating because you are watching people figure out how to describe and work with the world.)\nSo I wanted to read the original correspondence.\nI didn’t manage to. It turns out there were two Electrical Review magazines. The exchange re executioners was in the US version of the title; I was reading the one from the UK. \nYET: time well spent.\nWhat struck me was the mix of content.\nIn each issue I could find\n\nIndustry news: a new telegraph cable laid, new lights turned on\nScientific progress: a new demonstration and some possible fundamental laws\nLetters and “parish news” – a place for the community to have a conversation and to network around new ventures and ideas\nWho has been hit by lightning this week? Summary news items, including (say) that lightning struck a tree on such-and-such a date near a child. The child was unharmed though a nearby metal bowl left scorched. That kind of thing.\n\nThe impression I came away with was that this was a community trying to figure out the world together.\nAt this time with electricity, it wasn’t clear what datapoints were salient. Was it important that the bowl was scorched in the lightning report? Unknown! So report it anyway! The scientific method: gather observations; taxonomise and hypothesise; predict and iterate. This era was step 1 going into step 2.\nIt’s obvious to us now that electricity does not thin the veil between this world and the afterlife – but in an era where a power used to replace crankshafts in factories was then used to transmit the written word between continents and then, bizarrely, provide artificial light, well, who is to say what would happen next.\nSo the boundary of electricity was as-yet undefined. Oversharing was a virtue.\nI love this era of a new field. Not just the possibility of surprise round every corner, but the collective, heady nature of the endeavour. We’re making these discoveries together!\nAnd we’re making new discoveries by wildly building new things and reporting back what happened. Theory and practice in a tight and lively knot. The best place to spend one’s days.\n",
    link: "/home/2021/09/30/jobs",
  },
  {
    title: "Zizek’s view on The Sound of Music",
    date: "20.25, Tuesday 12 Oct 2021",
    content:
      "This is a tough but intriguing one: The Sound of Music is ostensibly a movie about homely Austrians resisting the invading fascists.\nBut Slavoj Zizek explains that it is also a pro-fascist movie.\nZizek’s argument: the heroes of the movie are these anti-intellectual Austrians who are living a traditional life, i.e. rejecting change. Therefore they have a fascistic quality. Whereas the type Nazis shown not soldiers but urbane cosmopolitans, precisely the elite class that (populist) fascists want to eliminate.\nSo while the surface narrative is about beating the Nazis, the underlying message has us rooting for a fascistic mindset.\nIt’s… a stretch. If true then maybe that’s why the movie continues to feel so fresh: because it runs counter to our expectations every time.\nBut I enjoy being challenged to think about things like this, especially a film that I’ve seen so many times.\nThe meta here, I suppose, is that we all have a fascistic tendency and that’s why the traditional Austrian life appeals: the desire to resist change, and to exert control on others and the world. Sometimes that’s unhealthy (I mean, clearly when it comes to Nazis, but also authoritarianism in general, and also when it is generally unwarranted and connected with fury when the world - understandably - doesn’t immediately accord to one’s whim). But sometimes it is fine: gardening, parenting, management, design, all forms of control that are generally a-o.k… though I imagine we can all recall examples where even these have become over-controlling. And so the line must be policed.\n",
    link: "/home/2021/10/06/electricity",
  },
  {
    title: "Wild Palms and default genres",
    date: "20.29, Monday 18 Oct 2021",
    content:
      "I’m halfway through my twice-a-decade rewatch of Wild Palms and it’s striking how much it uses melodrama, and actually the overall feel is that of a daytime serial.\nIf you haven’t seen it, here’s the single para overview:\nWild Palms is a 1993 Oliver Stone sci-fi miniseries, based on Bruce Wagner’s comics of the same. Based in 2007 Los Angeles (everyone wears Victorian shirts) it’s about virtual reality but through the lens of the TV company that introduces the first show with at-home holograms. There are drugs that, when you overdose, cause you to see cathedrals. The boss is a senator who has founded a Scientology-like religion about synthetic reality, the protagonist is a patent attorney, and the entire thing turns out to be a political feud. But it’s barely science fiction at all – it’s super domestic, the story of upper middle class families in LA. The cast list is insane. There’s a William Gibson cameo 26 minutes into the first episode, and beyond the TV show there’s a book called the Wild Palms Reader,  a compilation from Brenda Laurel (who was also wetware consultant), Hans Moravec, Genesis P-Orridge, William Gibson again, and Bruce Sterling. The book is half fictional world-building and half factual speculation about our actual futures, and the entire thing is a genre-bending high-water mark for what fiction can be.\nOk! So.\nWagner’s comics went hard on the punning and bombastic statements so they really lent themselves to melodrama. But if Wild Palms were being made today it would be a superhero flick or a pompous futuristic epic (I love Apple’s Foundation but oof it takes itself so seriously) – we don’t have any other ways to access that kind of narrative. Back in the 1990s it was possible to do something that I can only describe as “Dynasty with smart glasses”. (As much as the TV networks tried to frame Wild Palms as being like Twin Peaks, it really wasn’t – barely any symbolism, no mystery to pull in the audience, and not at all arch.)\nWhat gets me thinking is how obvious it is today that Wild Palms uses the genre tropes of a daytime serial - domesticity, hopping between characters, linear time, melodrama and cliffhangers - but in my previous watches, it hasn’t stood out to me so much.\nMy guess is that daytime serials were “in the air” in the 90s, to the point that it may not have even been a decision much thought about – it was just the default mode of storytelling. Just as the default mode in the 00s     was crime procedurals, and the 20s are all about season arcs and world-building.\nThis idea of default genres for storytelling is from a (sci-fi author) Neal Stephenson talk that I saw many years ag and which stuck with me.\nHe sums up genres like this: Romance fused with the film industry and Crime fused with the television industry.\n\nYou can make a lot of money on films that consist entirely of action, but there are only so many young males in the world.  Romance appeals to more people.  Romance is versatile.  All by itself, it is enough to make a successful movie.  Added to a screenplay, it works like monosodium glutamate in food, which is to say it does not matter whether the underlying material is poor or excellent to begin with, adding some of this wonder ingredient always makes it better. \nWhat Romance became to the film industry, Mystery/Crime became to the television industry.  They are made for each other.  A television series needs to tell a fresh story each episode.  Romance is not a good fit.  You cannot have your lead character fall in love with a different person each week.  Westerns worked okay for a while, but eventually, the writers ran out of things that could possibly happen on ranches and began to mix things up with ideas like the ‘Wild Wild West’.  By comparison, TV shows about detectives have it easy.\n– Neal Stephenson, Science Fiction Versus Mundane Culture (2008)\n\nSo there’s this symbiosis of genre and medium.\nBut it turns out the hybrid wasn’t police procedurals and television – it was police procedurals and syndicated television.\nStreaming TV needs another genre entirely, and that’s where we get into this season arc and world-building thing. Worlds give you infinite texture to spread out over hours and hours, and character is the way this world is raytraced. Watching characters interact is like the title-sequence clockwork of Game of Thrones: watching TV in the 2020s is watching a pachinko machine. Half the joy is just the captivating quality of seeing the utterly predictable-in-bulk and complicated thing happen; the other half is the joy of unpredictable-in-specifics surprise.\n(The equivalent stickiness in film is not season arcs but cinematic universes; you can’t binge watch on the big screen so it’s not linear but mycelial.)\nThere should be more genre experimentation.\nALSO. It would be interesting to think about Stephenson’s perspective on genre re: the genre that has co-evolved with the Facebook newsfeed as a medium; or the genre for TikTok etc. What are those? The medium has fused with the recommendation algorithm, which I’m not sure if Marshall McLuhan ever anticipated but I would love to know.\nAnyway, watch Wild Palms. Back in the day I would carry the AVIs around on a USB stick on my keyring to foist on people outside the pub but I’m sure nowadays you can find the rips on YouTube.\n",
    link: "/home/2021/10/12/zizek",
  },
  {
    title: "James Bond and Doctor Who got smaller as they became fantasy",
    date: "14.02, Thursday 28 Oct 2021",
    content:
      "I mentally slice stories into two types – those that can be in our world and that can’t. Sometimes a story world slides from one to the other and loses its magic.\nTake: James Bond.\n(This is old enough that it doesn’t count as spoilers.)\nIn Skyfall (2012) there is a bombing at the London spy HQ and the top of the building is blown off. I pass that building on the regular: its in Vauxhall on the south of the river, near where I live, and the real-life headquarters of MI6. If an explosion took out half the building, it would be huge news.\n\nBefore that moment, the Bond movies could be happening today – in our world but in the shadows (I’m just thinking about the Daniel Craig collection of films).\nAfter that moment, Bond exists in a parallel world. Like ours, but clearly not because we have a divergent history.\n\nThe magic of Bond pre-Vauxhall is that it’s a secret layer of reality. Spies generally and Bond specifically could be anyone you meet. The movie is access to secret knowledge; it adds a enchantment to everything you see even outside the theatre – what if this were part of a conspiracy? What if they were not commuters but part of an elaborate and clandestine operation? There is magic everywhere.\nMore: if you see someone wearing the wristwatch that Bond wears, maybe they are a double-0 agent. If you wear that watch, maybe you are! That’s why the product placement advertising is so potent: with this type of “new layer to the universe” narrative (which is particularly powerful with a spy movie where Bond has had, over the franchise, a variable face) you, the viewer, are immersed in the world and in the actual lead character.\nThis all evaporates when the HQ is blown up. I didn’t see the explosion on the news. Therefore the stories are just… stories.\nSomething similar happened with Doctor Who.\nPost rebooted Doctor Who, the magic was that it could be happening around the corner. It involved regular people with regular lives who become enmeshed suddenly in fantastic - and distant - adventure.\nNo matter what was happening with you in the day, no matter how dull, there was always the chance that you would glimpse the Tardis, meet the Doctor, and be swept off to an alien planet.\nOr it could happening on the next street! Hear a weird sound? Aliens. See a strange cat? Aliens. A person in an unusual hat? The Doctor in a new incarnation. Maybe, just maybe there could be an extraterrestrial time travel adventure happening right this second, around the corner. And that lets the imagination fly.\nSecret layers of reality fiction is MSG for the mundane.\nBut then there was that swarm of daleks that invaded Canary Wharf, and say what you like about the BBC but that would definitely have hit the news. I lost interest after that episode. Doctor Who descended to being just another story. There are no time-travelling benevolent aliens. As a tale it works or it doesn’t, depending on your taste, but what it can never be, any longer, is a way of animating everything you see.\nThere’s just a touch of this with Apple’s adaptation of Asimov’s Foundation novels (which I am enjoying, by the way).\nThe original stories (from the 1950s and onward) were shaped by John Campbell’s “competent man” thesis. Campbell was the editor of Astounding, the biggest sci-fi magazine at the time, and Asimov’s mentor. Campbell was deeply weird-by-which-I-mean-racist (I mean Asimov was deeply weird-by-which-I-mean-sexist too, the whole crowd) and he had a fierce grip on the magazine and what was published. His preferences shaped that whole era of sci-fi – and a lot of what we have now is either an evolution or a counter-response to his brand (which is why it is so exciting to see new voices in the genre).\nThe “competent man” is the idea that there is nothing necessarily special or unique about the protagonist. Instead they are smart, clear-eyed, scientifically-minded, and, well, capable.\nAlso men and also white. And yes, a bit ubermensch-y too.\nPut the weirdness aside and there is something magical there for the (white, male) mid-20th-century reader: you don’t have to be psychic or unique to find your way through a historically important crisis. But if you are smart and recognise what’s happening, you can do it. The reader likes to think of themselves as “competent” in the Campbell sense, so the story places them centrally in the narrative. The hero.\nThe early Foundation stories were very much about competent men. A vast galactic backdrop, sure, but primarily about smart, rational individuals who in a crisis keep both their head and a sense of humour, and that’s always the key. It could be you.\nWhereas I get the sense that in the Foundation TV show, the protagonists are special and unique.\nBut we know, each of us, that we’re not psychic, we don’t have superhuman powers. So the TV show becomes automatically a story about someone else. Distancing.\nWhat makes me feel loss is that these are all stories where the fictional reality enlarged the reader’s or viewer’s reality – their world or their self. The layers muddled, the realities multiplied. It’s why genre fiction is never just fantasy. I would call this “unreal but realistic” fiction fantastical. It lifts our eyes and weaves story in the air around us.\nThen, with these stories, after a transition, the inner fictional reality shrank and became segmented as something other. Not fantastical but fantasy. It’s still transporting! But our world became smaller as a result.\nIt’s usually a dramatically powerful transition too: a building blows up; the daleks invade. But it pays for a moment of drama with undermining what makes the narrative world special.\nI don’t know why I feel so sensitive to layers of reality and the fuzzy boundary of fiction. And yet.\n",
    link: "/home/2021/10/18/genre",
  },
  {
    title: "Political labels and the question of scale",
    date: "17.54, Friday 5 Nov 2021",
    content:
      "FIRSTLY.\nThis is a tough but intriguing one: The Sound of Music is ostensibly a movie about homely Austrians resisting the invading fascists.\nBut Slavoj Zizek explains that it is also a pro-fascist movie.\nZizek’s argument: the heroes of the movie are these anti-intellectual Austrians who are living a traditional life, i.e. rejecting change. Therefore they have a fascistic quality. Whereas the type Nazis shown not soldiers but urbane cosmopolitans, precisely the elite class that (populist) fascists want to eliminate.\nSo while the surface narrative is about beating the Nazis, the underlying message has us rooting for a fascistic mindset.\nIt’s… a stretch. If true then maybe that’s why the movie continues to feel so fresh: because it runs counter to our expectations every time. (But I enjoy being challenged to think about things like this, especially a film that I’ve seen so many times.)\nThe meta here, I suppose, is that we all have a fascistic tendency and that’s why the traditional Austrian life appeals: the desire to resist change, and to exert control on others and the world. Sometimes that’s unhealthy (I mean, clearly when it comes to Nazis, but also authoritarianism in general, and also when it is generally unwarranted and connected with fury when the world - understandably - doesn’t immediately accord to one’s whim). But sometimes it is fine: gardening, parenting, management, design, all forms of control that are generally a-o.k… though I imagine we can all recall examples where even these have become over-controlling. And so the line must be policed.\nSECONDLY, in my series of two disjointed thoughts about politics:\nI’m just back from Center Parcs which - for US readers - is a certain kind of British/European/middle class phenomenon.\nEach Center Parcs location is a forest village with hundreds of almost identical, comfortably furnished self-catered lodges (ours had a hot tub). Cars are banned except on moving days; you cycle everywhere. There are tons of activities such as swimming, zip lines, sports, pottery, woodland walks, falconry, etc.\nSo let’s be clear: it’s super fun and I’ve had a wonderful week of full-on family time, swimming, biking, star gazing, and adventuring.\nIt is utopia made from market communism. It is undeniably gorgeous to be cycling from activity to activity in the woods. You sign up for activities by paying a moderate fee but we all get to choose from the same relatively small set of choices. It’s a captured market: a fine resource allocation mechanism, but not allowed to run rampant. Variation is within limits. We live equally.\nBUT.\nThere are the workers, of course. The cleaners, the foresters, the shop cashiers, and so on. So another way of looking at this communist idyll is to call it totalitarian class capitalism. The consumer and worker classes may never cross; the consumer class lives a life of luxury but at the expense of freedom.\nAll of which has left me a little at sea about political descriptions.\nFunctionally it seems like market communism and totalitarian class capitalism are equivalent, so what’s the point of holding a political position? Maybe we need other ways to describe the differences between things?\nOR maybe these two labels are simultaneously true, only at different scales or social “distances”. It’s communist for me and people like me, looking from the inside. It’s totalitarian looking from the outside. Taking one step further away, one bubble further out, it’s class capitalism.\nAnd I wonder how much political differences and positions would make more sense if we clarified the scale and the stance.\nYou might be socialist for “people like us” (whatever that means: class, ethnicity, nation) and neoliberal outside that. But that means something entirely different depending on your position and where you draw the line for “like me”. Maybe the lesson from The Sound of Music is that fascistic tendencies are actually pretty normal at certain scales and from certain perspectives.\nThis goes back to oikos vs polis (May 2021) which is basically blood vs state, two ends of the scale: which do you privilege.\nAnyway.\n",
    link: "/home/2021/10/28/bond",
  },
  {
    title: "TV that mixes fact and fiction",
    date: "16.33, Friday 12 Nov 2021",
    content:
      "I’m into TV shows that play with the boundary of fact and fiction. Here are some that stick in my head.\nMurder Island (2021, here’s a review) is a 6 part murder mystery (plotted by author Ian Rankin) where they’re all actors except for members of the public LARPing as in-world detectives. Only it’s competitive: there are multiple detective teams playing to solve the case, and the winners get a cash prize.\nSo for the viewer there is narrative on two levels: the murder mystery itself, and then the drama of watching other people solve the murder mystery.\nHigh budget escape room meets immersive theatre meets reality TV?\nPrehistoric Park (2006) was a nature show told as a fly-on-the-wall documentary about an animal park in South Africa. Aimed at kids. Usual drama of dealing with sick animals, finding the right food etc. Except that these animals are dinosaurs, and at the back of the park is a literal time portal that the keepers drive a truck through back to the Cretaceous or whatever.\nIt was wild, and told completely straight. From the Wikipedia article (linked above) I see that the format is a “mockumentary” which makes sense – it was the era of The Office. But whereas The Office was a (fictional) comedy told with the tropes of (factual) documentary - which makes sense as comedy is often arch and plays with preconceptions - Prehistoric Park is… something else. I find it hard to parse.\nActually it reminds me in a way of Robinson Crusoe (1719), thought of as the first novel in the English language (how true that is? Don’t know). Defoe’s novel goes to extraordinary lengths to work its way into the fiction, describing how the manuscript was (apparently) written, how it came into the hands of the so-called author, why they decided to publish, and so on. Novels nowadays skip most of that – we take it for granted. (But we retain a rump understanding of the presence of the reader in the fiction. For example the author often ensures that narrative is only ever told through the perspective of one character or another, avoiding omniscience.)\nSo Prehistoric Park goes to great lengths to explain why the TV is showing images of the deep past despite the viewer knowing that it is 2006, and the choosen device is the in-world time portal.\nGreat show though.\nBONUS, on this topic: Ghostwatch (1992) which U.K. viewers of a certain age will have burnt into their psyche. Horror dressed as documentary, thoroughly credible to start and then… Read Ghostwatch: the Halloween hoax that changed the language of television (The New Statesman): a one-off show, inspired by the first flickers of fake news, terrified a generation. The BBC quickly disowned it. Now, its cast and creators tell their side of the story.\nMurder in Successville is a semi-scripted comedy/detective drama where all the actors are impersonating celebs. For example the police chief is (fake) Gordon Ramsey. The detective is the only person with a standalone non-celeb character, and each episode they have an assistant.\nThis assistant is a legit celeb, and they have to solve the murder of the week – only they also the only person who doesn’t know the script. There’s a lot of absurdity and a lot of improv. As with Murder Island there is dual enjoyment for the viewer: firstly solving the mystery (there are always enough clues) and secondly watching the celebrity collapse in bafflement.\nSo there are these multiple layers of reality: the so-called celebs; the story; the impersonations; the celeb of the outer reality inserted into the inner reality; the viewer watching it all at home.\nPeople are way better at consuming media on multiple simultaneous levels than I think is often appreciated. Look at wrestling which is both fake and real. So the “fake news” scare and our slightly po-faced insistence on authenticity (whatever that is) on social media both feel unsophisticated in comparison. I wonder if we could have a social media platform that embraced are-they-aren’t-they pretending as something completely ok. Something to unpack there.\n",
    link: "/home/2021/11/05/politics",
  },
  {
    title: "AirPods, and the cognitive ergonomics of tools for thought",
    date: "18.21, Friday 19 Nov 2021",
    content:
      "I’ve been trying out the dynamic head tracking feature of the new AirPods 3, and it makes me feel like the cognitive ergonomics of computer interfaces is - still - way too disconnected from everyday design.\nThe head tracking technology is intriguing.\nFirst there is spatial sound, which arranges sound in a sphere instead of in stereo. Apple Music now has a a bunch of music remastered spatially and personally I find it distracting when, say, the vocals are placed to the side and behind the drums. But anyway, it’s a thing, and spatial sound isn’t just for music. It’s an enabler.\nSo then there is head tracking which fixes the sphere in space even as you move your head.\nFor example: you walk down the street listening to regular stereo music. You turn to look to the right briefly, and the left and right channel remain fixed on the imaginary sphere around your head. The music that was previously (apparently) ahead of you is now only in your left ear.\nIt’s awesome.\nAnd weird.\nThere are some problems with head tracking as a feature.\nYou can switch between modes, but check out Apple’s own documentation: you have to long-press the volume on your phone to find out what options are available.\nThen head tracking isn’t available with all devices. My AirPods switch seamlessly between my devices, but they don’t all have the ultra-wideband chip that head tracking requires. (UWB is some clever radio magic. Apple call their chip the U1.) So it’s sometimes available and sometimes not.\nNow the UWB chip is what allows for relative positioning with high precision (mm accuracy last I checked) and low latency (you need it to be low milliseconds to work well with audio). It is clearly a jigsaw piece for Apple’s as-yet-unannounced work with augmented reality, so the U1 (and therefore head tracking) will end up in all their devices. So that inconsistency gets sorted.\nBut even so, head tracking gets used in a few different ways and it’s not clear to me, the user, what’s going on.\nFor instance: the other day I was working at my Mac and playing music from my iPad, and it appeared that the music was originating from the iPad itself – it had been spatialised to be located in the device.\nDid I imagine that feature? How did it happen?\nSo there’s a lot of confusion in the user experience: poor naming, hidden modes, and so on. The technology is rock solid but with inconsistent manifestations.\nWhich is fine! There is a ton of learning going on.\n(You can see Apple releasing jigsaw pieces like head tracking, photogrammetry with ARKit, and LIDAR in the Pro phones. At a certain point, the supply chain will be de-risked and the developer community will have devices that can function as dev kit – and then it will be the moment to land smart glasses, whatever form they take, and the only “risk” is the consumer experience, and Apple has nailed how to launch and iterate that. The playbook in action is astounding to see.)\nOBSERVATION #1\nStereo music usually feels like it is located at the centre of my head, right between my ears.\nSpatialised, these AirPods place the music right in front of my third eye: about an inch in front of my face, and just above my eye line.\nWith head tracking, the apparent locus is as steady as a rock.\nAnd it is super bizarre. Like, I can see why Apple has made this decision: music played from the centre of my head would not move with head tracking at all. It would be at the centre of the imaginary sphere.\nBut placed where it is, I go slightly cross-eyed. I end up focusing really close up and looking up slightly, at an invisible source of sound.\nOBSERVATION #2\nWhen the music apparently came from my iPad, while I was working on my desktop Mac, I found it way easier to focus on my work. Oh!\nThe background sound was physically separated (not actually, but using head tracking) from the point of my attention: the on-screen document. That separation seemed to allow me to concentrate better.\nWhich is… a fact worth paying attention to, right?\nThe question for me is this:\nWhat are computers for?\nAre they, as the name of Howard Rheinhold’s 1985 book suggests, tools for thought?\nIf so, how do we understand how to bias interfaces to make it better thinking easier – and what are the contributing factors to good thinking anyway?\nSpecifically questions like:\nIs it milliseconds faster to respond to a device notification if the sound of the notification appears to emanate from that device?\nCan more be held in working memory (and therefore synthesise information in a more sophisticated way, faster and smarter) if the documents are distributed - using sound feedback - over a wide surface, rather than being at a single point under the thumb? And is that ability to synthesise measurable?\nI’ve asked similar questions a couple of times before:\n\nDo Star Wars wipes (a particular style of scene transitional) tap into underlying automatic mechanisms to more efficiently allocate and deallocate the brain’s scarce processing resources, a kind of attentional ergonomics?\nCan we access the “memory palace” benefits of spatialising knowledge - in terms of capacity and organisation - simply by providing on-screen interfaces that visually resemble moving through doorways, a kind of hippocampus ergonomics?\n\nI would generalise this to cognitive ergonomics: how do we make user interfaces that better match how we think? And by think I mean: synthesise, create, pattern match, abstract, linearise, and so on.\nSo much of today’s desktop user interfaces were driven by early psychological considerations: Fitt’s Law being how quick it is to move a cursor to a target (and that you can think in the meantime), or the screen itself being a visual cache for working memory.\nI’m sure the HCI community has continued this good work.\nI would love to know certain things, in addition to the above. For example, I have a hunch that the fundamental “tick” of the brain is around 100-150ms – that how long it takes for a signal to move across the thinking meat, if I remember right. Interfaces that respond within that time feel fluid, and outside that time make you feel like you have to wait. Is that true? Does it have an effect on, say, our ability to do recall or have a novel idea?\nOr is parallel thinking possible? Does the time taken to move a mouse cursor provide the ability to consider what happens next? Does using sound to create a cognitive map and loading/unloading data from working memory allow for synthesis which is faster?\nMy dual wishes are these:\nThat Apple, Microsoft, Google and so on employ cognitive neuroscientists to develop quantifiable measures for good tools for thought, study modern interface approaches against these measures, and publish their research – just as they publish widely with machine learning or cryptography.\nAnd that front-end code libraries bake in these rules. If 100ms is the cognitive tick, then that should be a top-level guarantee for any user interface toolkit. And so on.\n",
    link: "/home/2021/11/12/tv",
  },
  {
    title: "Local streets for local people",
    date: "16.24, Friday 26 Nov 2021",
    content:
      "I wonder how we can implement the social contract via technology, and how that can be done democratically.\nA case study to explain what I mean…\nOne of the slow controversies in London over the past year has been the Low Traffic Neighbourhoods (LTN) programme: closing many residential streets to road traffic, sending cars onto main roads instead. There’s some background here including how it was built out of a schools-focused programme during the first lockdown (streets outside schools and on regular walking routes were closed to cars).\nLTNs are a joy and a pain.\nThe future of the city involves fewer cars, we all know that. Walking on these quiet streets and having coffee in the parklets now built outside cafes is transformative. BUT the schemes channel cars onto already congested main roads, and semi-local trips that aren’t well served by buses are made much more difficult.\nJimmy Tidey’s brilliant research has shown how LTNs kicked off a culture war on Twitter – though catalysed by a relatively small number of vocal black cab drivers. There are posters in almost every local shop against LTNs and they’re often vitriolic. I spotted a banner headline, All Streets Matter. Breathtakingly tin-eared.\nFor me, the root of the vitriol is that two constituencies of people feel it is unfair.\n\nLocal people feel like these are our streets – why shouldn’t we be able to drive down them?\nBlack cab drivers used to have special access to The Knowledge: a detailed mental map of London’s short-cuts, effective precisely because it was specialist. But it was made accessible to everyone with Google Maps (which, I remember hearing, has contributed to a 30% traffic rise on residential streets over the past decade). And now we’re being “punished” for the traffic with street closures, but the cab drivers feel it’s not their fault and they should still have access.\n\nThe problem is exacerbated by technology. The LTNs are often in effect for only some of the day, so the street isn’t physical blocked. The closure is implemented by a road sign, cameras with automatic number plate recognition, and penalty fines sent through the post. One of my neighbours has been stung by a series of 65 quid fines, having sailed through computer-closed streets accidentally a number of times. So, poor software.\nBut technology is also perhaps part of the solution!\nLong term we’ll have self-driving cars. We won’t need to close streets with bollards and impose fines – the cars can be programmed. The Low Traffic Neighbourhood policy will be a software point release.\nSo let’s think about how to bias that future pathfinding algorithm for fairness.\nPerhaps what we’ve identified is that local people have more “moral right” to use their neighbourhood roads than people from across town who are using the street as a shortcut. Those people from across town feel like freeloaders: they’re taking the benefit of the cut-through but they don’t have to live here.\n(Something similar happened in Los Angeles when Waze became popular. People went to extraordinary lengths to protect their local streets by fooling the Waze maps. As discussed here in December 2020.)\nCould we say that fairness means: local streets for local people?\nWhat if we had some way of categorising roads on a spectrum from small (local and residential) to big (thoroughfares)? If you live within 1 mile of a small road, it’s free to use. Over a mile, it’s thoroughfares only or you get a penalty.\nThe existing Low Traffic Neighbourhoods would see some cars again, but traffic volumes would be low: the streets would be closed to any car from outside the local area.\nOk, as a thought experiment that works for the future. NOW we can ask about how to implement this without waiting for robot cars. Could LTNs be implemented in software today?\nFrom a product perspective, the answer is yes.\nLet’s imagine we have multiple routing modes in Google Maps. Perhaps the different algorithms are embodied as different characters, just like each ghost in Pac-Man embodies a different search algorithm. (I’m picking on Google Maps but I’m using this as a stand-in for all routing apps.)\nIn addition to the “quickest” mode, and the “most fuel efficient” mode, there would be “social contract mode” – which would be the default. This mode would avoid residential streets outside a 1 mile radius of your home or 0.5 miles from your destination. And it would be the default.\nThrough legislation, “social contract mode” for map routing would be mandated for all in-car navigation from 2026.\nSounds plausible. The question then becomes… how could a policy like this get enacted? Three challenges:\n\nPoliticians and civil servants don’t know enough about technology to know what is hard and what is easy. Nor the media or the public: technology is a specialist subject. So how can we have a meaningful public debate – which is what we need for democracy?\nMandating a product solution is the wrong level of abstraction: but let’s say the outcome was somehow made law, how would that even be expressed? How is it possible to express a requirement like this in law? The social contract must be baked into product features?\nOnce we open the door to the state interfering in tech product decisions, how are stupid decisions defended against? What about dangerous decisions, or ones that reduce liberty? We have norms and laws and centuries of philosophy (and in some countries, a constitution) for the limits of how the state may limit the freedom of the individual, but we aren’t nearly as sophisticated when it comes to technology.\n\nI don’t know the answers to these, but the utility of having a specific case study such as Low Traffic Neighbourhoods is that we have something concrete to debate.\nLondon traffic is a specific case of something general and important, which is how society uses technology to enact its values, and what the mechanisms and limits on this should be.\nAnother instance of the general problem is Facebook’s engagement algorithm. Can society really tell Facebook how to tune its systems for chasing engagement, given that the ad-supported model requires it? Can we really insist that Facebook puts a cap on engagement, reducing its profit margins, or even changes its business model to include paid services – which will reduce accessibility?\nI mean, yes we can and should be having that debate. The extremism caused by Facebook’s algorithms can be seen as a public health problem and, if that analogy holds, I can point out that we’re perfectly happy to tax the cigarette companies without outright banning them. (Paying for externalities is one of the uses of tax.) So maybe the same approach should be adopted with Facebook.\nBut the question is the same: how should the desired social outcome be expressed as a technology product requirement, and how can it be expressed in law?\nThere are social values baked into software already. We need democratic ways to tune the parameters.\n",
    link: "/home/2021/11/19/airpods",
  },
  {
    title: "What is the metaverse?",
    date: "22.38, Thursday 2 Dec 2021",
    content:
      "Trends in tech come along every so often, co-opting and organising markets and sub-technologies around them like iron filings around a magnet. “Metaverse” is the latest, big enough that Facebook has renamed itself Meta to symbolise its enlarged focus. So I wanted to organise some of my own thoughts about what it is.\nA trend is a fuzzy-edged phenomenon, a hyperobject touching on: products, protocols for inter-op, technology stacks, typical business models, and so on. So any definition is incomplete. The sharp end is the product experience, which is where adoption happens, and that drives everything else.\nSo what is the product experience of the metaverse? Loosely I see it as having three essentials:\n\nImmersive\nMultiplayer\nEconomy\n\nIs it immersive?\nI think about immersion on a spectrum. At one end you’ve got VR:\n\nFull embodiment is 3D virtual reality, headsets, and sensors that detect muscle movement\nSlightly below that there are video games like Fortnite or Roblox, or 3D environments like Arium (the pseudo-VR browser-based art gallery platform)\n\nBut “immersion” doesn’t have to mean entering cyberspace. You can get lo-fi immersion if these qualities get across:\n\na persistent world – this exists even when you aren’t there.\nplace – a sense that I am somewhere other than the chair I’m sitting in right now.\nshared objects – everyone here is seeing and interacting with the same things.\n\nAnd you know what? You don’t need VR for that. Sure it’s easier with 3D graphics and avatars, but those aren’t essential. You can have persistent worlds with a strong sense of place (and moving between places!) with text-based games (MUDs and MOOs, to go way back) – 2D graphics on the web can work just as well.\nIs it multiplayer?\nToday our apps, docs, webpages and computing environments, by default, are personal – the P in the PC. It takes work to make them social. In the metaverse, it’s social by default, and it takes effort to have a non-shared experience.\nThis is something different than the social of “social media,” or the comments and ratings you get with (ugh) UGC, “user generated content.”\nTo differentiate from the old social of the existing web, the term of art is multiplayer.\nAnd that connotes liveness. You need a sense of presence. The ability to collaborate on shared objects in the shared world, whether for work or fun. Faces, emotion, video – all of these contribute to a transporting sense that you are surrounded by other people.\nYes that’s easier with video games and virtual reality. Immersive features such as place and proximity (and distance) make it possible for crowds to co-exist.\nBut again it can be lo-fi. I was previously tracking how the web is going multiplayer and I recently ran across another great example: tldraw is a tiny web-based drawing app. It’s elegant and playful. You scribble on the page, that’s all.\n…then look in the menu. There’s an option named Create a Multiplayer Room. Select it. Grab the address from the address bar and share it with a friend. Now you can see each other’s cursors and you’re drawing on the same canvas. No bother no fuss. A little glimpse of the metaverse, right there.\nDoes it have an economy?\nSo we’ve got a shared, persistent world with shared, persistent objects. And it’s multiplayer. The last ingredient is economics.\nBy “economics” I don’t just mean buying objects (perhaps digital assets like costumes or upgrades) or even virtual land (such as in Decentraland, a land-based economy on the blockchain). What’s important is that these objects are assets. You must be able to sell them; they and their “ownership” must exist in a marketplace that transcends the platform in which they manifest.\nSo that implies a concept of identity, money, and rights that exists outside any given immersive, social platform or another.\nWeb3 is one obvious stack for this – or at least the collection of technologies. The stack hasn’t energy yet. By Web3 I mean the crypto (cryptocurrency, rather than cryptography) world of: identity; payments; contracts; ownership; currency; and the entire pile of derivatives that can be created. Yes NFTs are a big part of that. A powerful enabler.\nBut I don’t see that crypto is intrinsic to having an on-platform economy. It could happen with the dollar (or fiat currency generally).\nSo the metaverse is a product experience that is immersive and multiplayer with built-in economics.\nAnd a metaverse company is a company that provides that or is somehow part of the stack. Maybe they provide an enabling technology, like easy-to-integrate presence or treasury, or maybe there’s a yet-to-be-identified marketing/distribution mechanism that has a particular requirement on analytics, or maybe they provide an interface like smart glasses. It’s hard to know at this point what the dynamics will be, or where value will be extracted in the value chain.\nThe history of the metaverse\nIt’s been a while since I’ve read Snow Crash, Neal Stephenson’s 1992 sci-fi novel in which he invented the concept, so I’ll just grab this from the Wikipedia page on Metaverse instead:\n\nNeal Stephenson’s metaverse appears to its users as an urban environment developed along a 100-meter-wide road, called the Street, which spans the entire 65536 km (216 km) circumference of a featureless, black, perfectly spherical planet. The virtual real estate is owned by the Global Multimedia Protocol Group, a fictional part of the real Association for Computing Machinery, and is available to be bought and buildings developed thereupon.\nUsers of the metaverse access it through personal terminals that project a high-quality virtual reality display onto goggles worn by the user, or from grainy black and white public terminals in booths. The users experience it from a first-person perspective. …\nWithin the metaverse, individual users appear as avatars of any form, with the sole restriction of height, “to prevent people from walking around a mile high”. Transport within the metaverse is limited to analogs of reality by foot or vehicle, such as the monorail that runs the entire length of the Street.\n– Wikipedia, Metaverse\n\nSo we’ve already got these three qualities: it’s a persistent world, social, with a built-in economy. It’s dogmatically physical and uses VR, which creates this sense of immersion, which I guess is why Meta nee Facebook is working on haptic gloves.\nAnd the economics is kinda ugly. Ruthlessly commercial, and no room for the open source ethos that was the foundation of Web 2.0, the current generation of the web.\nBut the lineage is clear.\nThe biggest difference, for me, is that Stephenson’s capital-M Metaverse is singular. There’s one of it. That’s evidently what The Corporation Formerly Known As Facebook imagines too, and they’ll own it. It’s possible that TCFKAF is right, and they’ll be the ones that win big.\nThe web - or rather the application and protocol WorldWideWeb - was a blip. I think that’s clear now. It was agnostic to document type, happy to link to email, gopher, image, and hypertext. It was frivolously free with assets: when you look at a webpage, the images are downloaded to your computer first and then assembled into a document! You can even “view source” to see the code behind a page. Websites are like applications that wear their source code on the outside.\nThe web isn’t how systems are typically architected. So we can’t take it for granted that we’ll end up with a small-m metaverse – a distributed network of interconnected metaverses, sharing identity and an economy but otherwise independently immersive. If that’s what we want, we’ll have to work for it.\nWeb 2.0\nI think the last major technology trend like this was probably apps and the smartphone, but actually it’s hard to distinguish that from Web 2.0 that came just before. And it’s interesting to look back at O’Reilly Media’s catalysing 2005 essay: What is Web 2.0: Design Patterns and Business Models for the Next Generation of Software.\nWhat you’ve got in the “meme map” (on page 1 of the five page essay) is an approach is totally born of the new open, networked, social, apps-not-docs web. It’s a set of approaches that implies a set of technologies and commercial models.\nCited are ideas like:\n\nSoftware that gets better the more people use it\nServices, not packaged software\nArchitecture of Participation\nData as the ‘Intel Inside’\nGranular Accessibility of content\nPlay\n\nAnd in the years since, we’ve seen these formalised into social media, software as a service (SaaS), tools like git, and ways of working like agile – all applicable to this fast moving, fast growing world. Cloud platforms starting with Amazon Web Services and pioneering tech like Ruby on Rails grew up with Web 2.0. The economics (and economies of scale) of cloud platforms prescribe a cost model for companies, and that prescribes a revenue model: subscription for B2B, and the attention economy to B2C.\nWeb 2.0 even included its own aesthetic, so participants in the trend could recognise one another versus older, “enemy” approaches like Enterprise. We still have the warm, bold colours, the chatty brands, the rounded-off corners, and the cutesy illustrations of 2005.\nWeb3 is the re-platforming of Web 2.0 to be crypto-native: new identity, new payments, and new modes of collaboration.\nWeb3 has its own aesthetic and characteristic visual style. Even its own art movement with NFTs –  see the new Outland magazine for art criticism in this domain. And it has its own shibboleth words to identify in-group and out-group. (gm.)\nBut Web3 isn’t a comparable trend. It’s the metaverse which rivals Web 2.0. The technology stack, the aesthetics, the community, and the products all grow up together. Web3 is part of the puzzle; the metaverse is the whole shebang.\nWhat happened with Web 2.0 is that it became true but too much.\n“Software that gets better the more people use it” is another way of saying that there aren’t any limits on network effects. Platform capitalism (Nick Srnicek’s term, mentioned in my Thingscon talk last year) is rapacious. We have one Facebook, not ten thousand. Whoops.\n“Architecture of Participation” led to the sharing economy… which was co-opted and led to the gig economy, and to so-called “sharing” marketplaces like Airbnb and Uber mining the under-specified edges of the social contract.\nThe metaverse also contains as-yet unknown failure modes. It would be worth puzzling them out now.\nDoes the metaverse matter?\nWe can decompose the question of whether the metaverse trend matters into two parts:\n\nIs the metaverse significantly different? Yes: it introduces the concept of scarcity (with space, time, and ownership) into the digital realm, which since its inception has been built on the idea of approx. zero marginal cost of duplicating assets, or communicating with +1 person. Just as Web 2.0 led to new community structures, new business models (and the attention economy), new ways of working, and even new expectations for government (witness GOV.UK in the UK), the metaverse will have its own long-term cultural effects.\nWill the metaverse come about? Well now that’s a matter of opinion.\n\nI will say that the metaverse trend has two qualities in common with two other large scale trends that I saw up close, or maybe let’s call them movements: Web 2.0 (described above) and Tech City, London’s transformation into a global startup hub (I was part of the inception).\nBoth had multiple constituencies that pushed for the movement for often barely overlapping reasons. With Web 2.0: corporations, individuals, investors, and customers up and down the technology stack. In the case of Tech City: Large corporations and government; founders and real estate owners; lawyers and journalists. Everyone felt they could immediately get more for their particular ship by working to rise this particular tide, and they did this without being instructed what to do.\nWith the metaverse we have crypto-libertarians tech nerds from Web3 somehow aligned with platform monopolist VR-maximalists from Facebook. Their values couldn’t be more opposed yet they are boosters for the same trend.\nWhen a movement creates alignment without coordination, that’s a powerful force.\nThanks to Ed Cooke, Thomas O’Duffy, and others at Sparkle for knowledge and conversations. Blind spots and misconceptions all my own. As always this is a snapshot: thinking out loud rather than a final view.\n",
    link: "/home/2021/11/26/ltns",
  },
  {
    title: "Primitive design and how I’m spending my week",
    date: "20.06, Thursday 9 Dec 2021",
    content:
      "I’m currently trying to wireframe a new service. Precisely what it is doesn’t matter right now, but it’s software.\nThe work is less about “this is the design” and more that I’m figuring out whether this is a viable starting point for the actual design work which comes later.\nOn my paper I have two lists. One is a list of top-level features. The second is a list of desired user outcomes (things like: “have a sense of familiar strangers”). And then I have four sketched boxes which represent screens, and boxes on them. It’s a pretty simple service at its core…\n…and it’s built out of an existing platform. It’s an application of that platform. The top-level features already exist; hitting the specific outcomes will steer future development (and that’s part of the purpose of this new service: a concept car kinda).\nThen I have additional requirements for the interaction design:\n\nI want it to feel intuitive\nI want any new features to be platform features, not one-offs.\n\nAnd the second of those is weird, right? It’s like sketching out a toy spaceship, having a list of rules about play, and attempting to simultaneously invent the shape of the Lego brick.\nThat’s platform design I suppose. Redesigning a newspaper will means bouncing between comps and style guides, designing both. Inventing the iPhone user interface will have seen apps and app paradigm evolving together. Those are examples much bigger than what I’m attempting.\nActually what I’m reminded of is this: eye-balling a graph during my physics undergrad and figuring out how to express it in simple mathematical terms, then using that as a model to make predictions, and testing and refining that model. The process of expressing a system as composable primitives.\nPrimitive design?\nI’ve talked before about primitives and notation (August 2021) and this process is part of that same puzzle: I want my primitive building blocks to feel natural and well-rounded and logical; I want my service to make sense and achieve its aims and come together neatly from the primitives. There’s an iterative back and forth to get there, between these two orthogonal descriptions of the same thing.\nIt’s enjoyable work and that’s mainly how I’m spending this week.\nI’m sure other people have described this kind of process. I’d like to read about it if it rings any bells for you.\nSorry to be so cryptic.\n",
    link: "/home/2021/12/02/metaverse",
  },
  {
    title: "Unbundling the office",
    date: "17.22, Friday 17 Dec 2021",
    content:
      "Here’s a startup idea for anyone who wants it: outsourced, at-home video call support. Sounds really boring. Isn’t.\nIf you run a big internal event, and you’re at a sufficiently large company, there will be an AV (or IT) support team that comes round to make sure that the projector is plugged in, the mics work, etc.\nIf you run a big virtual internal event, and you’re at a sufficiently large company, AV support will do the same only remotely. They’ll call up your external speakers and attendees, and make sure they have Microsoft Teams, Chrome, etc, installed and happily working with their webcam and so on. This is good!\nBUT\nThere are now a bunch of services which are delivered over video, to members of the public, by companies where tech support is not a core competency. I’m thinking of…\n\nMedical practices doing consultations over video\nCourts dialling in witnesses\nSchools and universities – teaching generally\n\nAnd if the video call fails - for whatever reason - the service can’t be delivered and time is wasted.\nSo the startup should work like this:\n\nAhead of a call (being a consultation or an event), the client company (like a school) enters the emails of everyone included, together with the software platform they’re using\n24 hours ahead of the event, our fictional startup contacts all internal and external attendees and takes them through a foolproof, automatic setup test for the exact software configuration\nAny problems are escalated to a human and they get on the phone to sort it out\nThe event/consultation/parent-teaching-meeting/etc goes off without a hitch.\n\nIf there’s actually going to be a permanent shift to doing things remotely, we’ll need a service like this. Simply from a cost perspective… it doesn’t make sense to have the expert nurse or teacher debugging any connection problems when it can be done by somebody cheaper with economics of scale.\n(If the government really wanted to keep the economy going, while people were being furloughed they would have been building this service to offer at cost to the public and private sector. By the time the life support money ran out, there would have been a gangplank for companies that could to transition to a WFH future. As it is, everyone is tackling the same problems but separately.)\nBig picture, this is about unbundling the office.\nWhat is the office for? Yes it’s a place to work, but also\n\nIt’s a place for collaboration\nIt’s a place where a company can provide perks, like snacks\nIt makes it possible to ensure health and safety in the workplace, because chair heights can be checked and electrical items tested\nInformation security can be guaranteed\nPeople who don’t work together can run into each other.\n\nThat last one is important. From the New York Times last year about working from home, a piece about weak ties: the people with whom you rarely communicate, perhaps 15 minutes a week or less.\nWhen the pandemic hit: contact with weak ties dropped by 30%.\nOops:\n\nBut Waber contends that it’s those weak ties that create new ideas. Corporations have historically seen some of the biggest new ideas emerge, he says, when two employees who usually didn’t talk suddenly, by chance, connected. But Waber contends that it’s those weak ties that create new ideas. Corporations have historically seen some of the biggest new ideas emerge, he says, when two employees who usually didn’t talk suddenly, by chance, connected.\n– NY Times, What If Working From Home Goes on … Forever? (June 2020)\n\nIt’s handy that the office is a single physical location such that facilities is able to reach everyone in a cost-effective manner. But there’s no essential reason that all these jobs of the office actually have to be bundled up in the office.\nNewspapers and magazines got unbundled. Banks are getting unbundled.\nOffices are being unbundled.\nI talked about remote working perks last year and asked at the time: is there remote work facilities management that can come set up my desk and give me a sound baffle/backdrop for my video calls?\nIt turns out there is! Hofy is a remote facilities management startup to give WFH employees chairs and monitors.\nSo this unbundling is why I don’t really buy virtual office approaches like Facebook’s VR-based Horizon Workrooms: Facebook’s Metaverse is a VR Meetaverse (Wired). Sure it might work for collaboration, but maybe there are better software approaches for collaboration… and what about the rest of the office? What about the nice chairs? Embrace the unbundling!\nThe most interesting part of the unbundling of the office is that it allows companies to get smaller by divesting of in-house IT, in-house facilities, long-term leases, etc. Anything that allows companies to get smaller is interesting.\nThe oddest part of hybrid working, for me, is that I tend to spend my mornings in a co-working spaces to be face-to-face with whichever teammates happen to be around (ad hoc weak tie connections, see), and my afternoons at home on Zoom for scheduled meetings.\nWhich means I commute over lunch, and mostly eat on trains.\nSo I choose my food based on what I can hold while I’m also on my phone while I’m also maybe standing up.\nCornish pasties have a crust “handle” because they were traditionally eaten by tin miners with dirty hands. What does my commute pasty look like?\n",
    link: "/home/2021/12/09/primitive_design",
  },
  {
    title: "SAGE and a glimpse of group computing from before the PC",
    date: "22.18, Tuesday 21 Dec 2021",
    content:
      "There was a fork in the road away from group computing, way back when.\nRight now we’re in the era of personal computers. Collaboration, social use of tools, togetherness: all of these are hacks on top of something that, at its core, was designed for the individual first.\nBut there’s a particular photograph of group computing from the 1950s, from before the PC was invented…\nOk I need to rattle out a story here about SAGE, and that will let me get to the photograph.\nI’m going to do this from memory so apologies in advance for any factual errors, but I think I’ve got the bones of it in order.\n(Earlier this year I did a three part talk about the pre-history of computing and so a lot of this is in my head from then. It was a super fun talk with a novel format – three x 1 hour talks on successive evenings across a single conference, each picking out and storytelling around particular moment in the evolution of today’s technology. And it got great ratings in the feedback. I was pleased about that.)\nTo get to SAGE and to put it in context, I need to rewind a whole way.\nONCE UPON A TIME.\nOne way (not the only way) of telling the story of computers goes like this.\nTabulating machines were invented in 1890 for the US Census and went on for the next 50 years without any fundamental changes but with great popularity in business. They were electromechanical sideboards that basically ran a small set of Excel commands on stacks of what became standard issue IBM punchcards – which we retain today in the shape of air flight boarding cards.\nThe Second World War was a catalytic event. The need to quickly calculate ballistics tables led to the first fully electronic computer, ENIAC (which also became one of the world’s first programmable computers in the modern sense), although the initial task in 1945 for this room-sized machine was numerical modelling for the hydrogen bomb at the tail end of the Manhattan Project, the vast secret project to create nuclear weapons.\nLet’s take a moment to name the first of the first, the original programmers of ENIAC, all women: Kay McNulty, Betty Jennings, Betty Snyder, Marlyn Meltzer, Fran Bilas, and Ruth Lichterman.\nSkip ahead to 1968 and the invention of the personal computer. Douglas Engelbart’s team attaches a screen to a military computer and, in 90 minutes in The Mother of All Demos, demonstrates a whole new user interface: interactive text, video collaboration, modern office furniture, and the mouse. The demo consisted of Engelbart managing his shopping list.\nThe PC was an audacious conceptual leap: the idea of an individual computer being used by a single person for their own specific work tasks was akin to the idea of a baseball stadium being used by one player  (Alex Handy, The New Stack).\nBetween the milestones of ENIAC and Engelbart there was SAGE.\nFor comparison: The Manhattan Project in the 1940s cost about $20bn in today’s money. SAGE cost $60bn. The Semi-Automatic Ground Environment was built out over the 1950s and was a direct defence against the atomic weapons developed in the mega-project of the previous decade, a continent-wide sensing, synthesis, and rapid response platform blending human intelligence and technology. It ran for over 20 years.\n\nThe SAGE system, by the time of its full deployment, consisted of 100s of radars, 24 direction centers, and 3 combat centers spread throughout the U.S. The direction centers were connected to 100s of airfields and surface-to-air missile sites, providing a multilayered engagement capability. Each direction center housed a dual-redundant AN/FSQ-7 computer, evolved from MIT’s experimental Whirlwind computer of the 1950s. These computers hosted programs that consisted of over 500,000 lines of code and executed over 25,000 instructions – by far the largest computer programs ever written at that time. The direction centers automatically processed data from multiple remote radars, provided control information to intercepting aircraft and surface-to-air missile sites, and provided command and control and situational awareness displays to over 100 operator stations at each center.\n– MIT Lincoln Laboratory, SAGE: Semi-Automatic Ground Environment air defences system\n\nImagine a network of radar stations covering the whole of North America, constantly looking out for nuclear bombers. SAGE never spotted one; bombers were quickly replaced as delivery mechanisms by the ICBM. It was the prototype for today’s air traffic control system.\nRadar signals came into the 24 direction centers, were analysed by people and computers, and instructions sent out again to bombers and missile silos: the original WarGames.\nEach direction center was built around an AN/FSQ-7 – at 250 tonnes, the largest computer ever built. (With the transistor replacing vacuum tubes a few years later, the largest that ever would be built.) Then what you’ve got with SAGE is 100+ operator stations plugged into the same computer.\nYou can see the weapon’s director console here. There’s a circular screen, like a radar display, and a light gun to select radar traces. There are toggle switches and a numerical rotary dial to tag the traces with numbers.\nThis is interactive computing in the real world for the first time!\nSo, for me, this is the pre-Engelbart breakthrough moment.\nAnd in a way, it’s more authentic than any research project. What we see in SAGE is a new interface forged under perceived existential threat, something actual, not   philosophically derived or imagined by lone genius, but contoured along the grain of known human behaviour.\nOn the left hand side of the console there is an ashtray.\n(Also it is not lost on me that the light gun was the particular interface device that was popularised by its use in this military system. Imagine being so accustomed to weapons that it feels entirely natural to select an icon on your computer screen by pointing a gun at it.)\nThe successor to the AN/FSQ-7 was intended to be the much smaller, transistorised AN/FSQ-32.\nEngelbart’s team in Stanford got its start in 1963 when it was given its first research contact by J. C. R. Licklider, director of ARPA: the US Defense Department’s Advanced Research Projects Agency. Licklider made it a condition that, instead of using a standalone computer in Stanford, Engelbart had to start by connecting a display to the new AN/FSQ-32.\nSo a connection from SAGE to Stanford and that brings us back to the PC.\nBut it wasn’t inevitable that the Semi-Automatic Ground Environment would be followed by the personal computer.\nI’m kinda obsessed with a particular road not taken…\nLOOK AT THIS. Here’s an archive photo on Wikipedia: Subsector Command Post of SAGE Combat Center at Syracuse Air Force Station with consoles and large Photographic Display Unit display, which was projected from above.\nGroup computing.\nWhat you can see is ten men sitting around a Kelvin Hughes Photography Display Unit – a large screen for displaying graphics and characters. The third floor of a SAGE direction center: The Pit.\nEach of the men (yes all men) has their own computer console at their desk. But they’re working together around the PDU. One of the men is holding what is either a light gun or a laser pointer/equivalent. They’re assessing potential threats and ordering missiles and bombers. Together.\n(Here’s a great article about the physical architecture of SAGE: The Futuristic Cold War Era SAGE Air Defense Bunkers Looked Right Out Of A Kubrick Film.)\nSo we’ve got a system here in the 1950s which is on some axis more sophisticated than the rooms with similarly large yet typically less intelligent screens that I regularly sit and have meetings in, seven decades later.\nThis isn’t a setup for presentations and discussions. It’s for collaboration and action. The whole room is an environment for the team to work.\nAnd I often, often wonder this:\nWHAT IF, instead of the Personal Computer, the dividend of SAGE had been the Team Computer?\nA computer that wasn’t used individually but as a group, together in a room or perhaps remotely. Not desktops but environments. An alternate history of computing that doesn’t involve user IDs or ownership as primary concepts but is instead oriented around collaborative, co-created artefacts, spaces that are jointly inhabited. It’s hard to mentally unfold such a world, from such different initial conditions, imagining its progress lensed through Microsoft Office analogues, video games analogues, World Wide Web analogues, over such a stretch of time.\nIt would look something like DynamicLand but with decades of evolution. We got just a glimpse of the path.\n",
    link: "/home/2021/12/17/office",
  },
  {
    title: "My most popular posts in 2021 and other lists",
    date: "11.34, Thursday 23 Dec 2021",
    content:
      "I wrote 127 posts this year. I’m pleased with my most popular posts, but they don’t include my personal favourites (skip down for those).\nAccording to Google Analytics, my 5 most popular posts in 2021 were (in descending order):\n\nWhat wipes in Star Wars teach us about the brain and also interface design (4 Apr)\nComputers should expose their internal workings as a 6th sense (27 Aug)\nOn the impending deletion of Charlie Bit My Finger (27 May)\nSocial Attention: a modest prototype in shared presence (22 Mar)\nSalads, shipping containers, and subtle signs of a supply chain reset (16 Apr)\n\nHere’s a longer list: My 20 most popular posts in 2021.\nI’ve also collected my favourite, most speculative posts, on topics such as\n\nUFOs\nA dolphin pope\nBrian Eno\nFrozen heads\n\nHere you go: 16 speculative posts in 2021.\n(I’ve added tags to a few of those posts. It’s fun to go exploring if a topic catches your eye.)\nTwo in that list are legit my fave posts of the year, 50% for the ideas, but 50% because I viscerally remember the way my fingers worked their way to the words. Reading is not writing; I’m not sure how much that feeling transmits. Anyway, somehow there are new turns of phrase and particular ways of connecting concepts that I wish I could get to every time I write.\n\nThe ASMR version of Bee Movie, and other neuro-divergent media (16 Mar)\nHorsehistory study and the automated discovery of new areas of thought (16 June)\n\nI continue to be a terrible judge of predicting which posts will get the numbers, but was gratified whenever I saw my personal faves pop up on the blogs and newsletters of friends and others whose perspectives I really respect. Thank you.\n(Dear reader: if you have a particular favourite post from 2021 which isn’t in these lists then I would love to know! It would be interesting feedback.)\nSEE ALSO!\nLast year: My most popular posts in 2020 and other lists.\nSome stats.\n\n2017: 22 posts (17,007 words, 244 links)\n2018: 15 posts (16,786 words, 123 links)\n2019: 8 posts (7,268 words, 78 links)\n2020: 116 posts (94,348 words, 712 links)\n2021, to year end: 128 posts (103,460 words, 765 links)\n\nPeople often ask me: how do you write so much? Here’s my list of 15 personal rules for blogging from September 2020 which is about evading my own mental traps.\n(I wish I could write more.)\nI recommend blogging whenever I talk to people with interesting ideas, which is frequently. Start by writing down what you know, I say, in public. Writing things down (a) gives you stepping stones for thought so you can move past your ideas and reach for bigger ones; and (b) fizzes out brand new ideas because the shearing between a thought in your head and your thought in words makes a kind of generative static electricity.\nWith email newsletters you can get obsessed with “audience” and making each edition “worth” hitting your readers’ inboxes… but with blogging you can let the idea lead. There’s just enough open air to keep you honest. Only do write regularly, otherwise each post becomes an event.\nAnd I realise (looking back on my 2021) that this last one is a trap I’ve fallen into. I wrote approx 3 times/week till the end of September and only weekly since then. My posts have become less playful, which I regret, so I’ll think about that.\nUpdate 31 Dec, 2021: Finalised 2021 stats, above.\n",
    link: "/home/2021/12/21/sage",
  },
  {
    title: "What I’ve been reading in 2021",
    date: "16.45, Friday 31 Dec 2021",
    content:
      "Sup y’all. Some books I read this year.\n\nThe Soul of a New Machine [Wikipedia], Tracy Kidder (22 Feb)\nInspired: How to Create Tech Products Customers Love [Bookshop.org], Marty Cagan (10 Apr)\nOrg Design for Design Orgs, [Bookshop.org], Peter Merholz and Kristin Skinner (15 Apr)\nTools for Thought [MIT Press], Howard Rheingold (8 Jul)\nRise of the Machines: the lost history of cybernetics [Bookshop.org], Thomas Rid (31 Jul)\nOne Million A.D. [Amazon], Gardner Dozois (ed.) (28 August)\n\nComputing history: I flicked through a bunch of re-reads and picked up a few that were new to me.\nThe Soul of a New Machine (1981) tells the story of the development of a single minicomputer, and the era means it seems irrelevantly archaic and simultaneously like seeing the modern world under a microscope, the fine detail of both the technology and the kind of people who work with it, traced out like trails in a particle collider.\nI wrote about it in March: Revolutions and NAND gates, eight cents, wholesale.\nTools for Thought (1985) is another dive back, most interestingly (to me) to the big thinkers - Doug Engelbart, Alan Kay, Brenda Laurel, Ted Nelson - and their perspective on what computing is for. I think in the 1980s you can say that the frontier had been opened, but software hadn’t yet eaten any of the world, and so the perspectives of these individuals are unblinkered and all the more valuable for that. \nThe idea that it’s possible to decompose “thinking” to fundamental units that can be enhanced by computing, such that it’s possible to create a “tool for thought” (Rheingold’s term) or a “fantasy amplifier” (Kay)… well, we’re missing that vision today imo.\nHoward Rheingold has shared the full text to Tools for Thought on his site.\nRise of the Machines is a history of cybernetics and that undersells it. I’ve read a lot about cybernetics and its role as a cross-discipline language to cross-pollinate ideas and invent new ones. But this account is special for two reasons:\n\nThomas Rid is intensely realist. Norbert Weiner isn’t the hero, the Macy conferences aren’t central. Cybernetics itself is treated with scepticism, and individuals who talk (like Weiner) are on the sidelines compared to implementations and solutions.\nThis drums home how much the history of technology in the 20th century in the west is a military history. Yes, we kinda acknowledge that military research funded development of ideas in feedback systems, and computers etc, but I’ve never read the story in as much detail. Or the role of the US air force in developing 3D virtual reality. Or (in a chapter of original research) how seriously cyberwar was being taken in the early 1990s.\n\nComputing history seems to be told in one of two ways: either a history of ideas, “great men” typically. Or a sequence of landmark inventions: the transistor, the PC, etc – enabling technologies but independent of the people.\nBut Rise of the Machines is neither of these, and is as close to a material culture approach as I’ve seen. It’s a history of built technology in use and how people respond and then what else they build. Excellent and full of great nuggets.\nTwo books about jobs.\nInspired is a field manual for the product role (at many levels): where it fits in organisations, what it has to achieve, and how to do it. “Product” itself is a fascinating development, a new role borne of startup culture, non-existent when I started in the industry. And I’m into it: synthesis, scouting, and sequencing.\nWhere the product role coalesced, the design role diversified – the designer’s approach and skills found a home in strategy, research, product, marketing, invention, and more and at all levels. It’s hard to directly measure the impact of design but you couldn’t do without it. Org Design for Design Orgs is about how to build and manage the design function.\nBoth excellent books. I recommend pairing them.\nOne Million A.D. is an anthology of sci-fi novellas based in the far, far future. Tangent magazine delivers a run-down of the stories.\nAll cracking fun, but pick up this collection for the Greg Egan bit: a story of two lovers who have enjoyed 10,000 years of marriage and have gone through every worthwhile experience. They are now ready to let themselves die…\nEgan has the story on his website to read for free here: Riding the Crocodile.\nUnfinished:\n2021 has flown by and honestly my attention is shot.\nAside from the above and a bunch of comfort re-reads, I’ve struggled finish even books that are gripping me.\nFour notables from the uncompleted stack:\n\nThe History of Magic: From Alchemy to Witchcraft, from the Ice Age to the Present [Bookshop.org], Chris Gosden. With the premise of a “triple helix” of equals - science, religion, magic - this is a methodical history of magic in cultures worldwide over the last 10,000 years.\nArt in Revolution: Soviet Art and Design since 1917, Hayward Gallery London, exhibition catalogue (1971); here’s the show on Google Arts & Culture. An attempt to describe and show Soviet constructivism as an art movement, political philosophy, and (total) social approach, while being uncritical of communism.\nThe Lore of the Land: A guide to England’s legends from Spring-Heeled Jack to the Witches of Warboys [Amazon], Westwood & Simpson. I wrote about this in July: England is dense with ancient folktales.\nEverything I Know About Life I Learned From PowerPoint [author site], Russell Davies. It’s a guide to presenting, it’s a history, it’s a life philosophy. I haven’t finished yet but it’s brilliant, and also a gorgeously designed object. Get the print edition.\n\nWhat I liked about my reading this year is that none of the books really offered up a conclusion, or made a single argument. Just: well-researched (and often exhaustive) descriptions of systems, stories, occurrences, history. In quantity, enlightening.\nHappy new year.\n",
    link: "/home/2021/12/23/top_posts",
  },
  {
    title: "Some thoughts on the Glass Bead Game",
    date: "17.25, Wednesday 29 Jan 2020",
    content:
      "When I first read The Glass Bead Game (Hermann Hesse, 1943), I was awed by the beauty of this (fictional) game that is aesthetically beautiful, simply for its own sake, yet bridges art and science producing new insights.\nAll reminiscent of cybernetics which - as an interdisciplinary language - bridged fields from anthropology to information theory, and produced insights in cognitive neuroscience, computation, and more. (Some will disagree, which is kind of my point.)\nYet. I spend a lot of time in the tech world, and I frequently run into technologies that\n\nI’m sure must be useful – that is, provide leverage meaning less effort for greater value, but\nunhappily, to me, look like scams… and this is the critical bit: even when they are not.\n\nThis is technology from companies that are long-running and therefore successful (by one definition), or startups that are well funded (and popularity is another kind of success).\nSo what qualities causes my scammy spidey-sense to fire (or misfire)? It turns out it is mostly language. It is when\n\nthere is language and (conspicuously costly) activity which is working to build excitement and desire… and it seems like this is detached from the underlying technology itself, and\na lot of the language points “inward,” the words and phrases being defined in terms of more “in-network” words and phrases – which naturally gives rise to concentric circles of increasing familiarity, where those towards the centre can extract value for providing understanding to those further out. But perhaps the obfuscating language isn’t necessary.\n\nThe problem is that many complex disciplines look scammy like this. Without already being an expert, how is it possible to tell the difference between necessary complexity and gatekeeping complexity? I don’t know. I think about this a lot.\nBack to tech:\nI sit inside the technology ecosystem, and my own perspective is most likely bounded by a bubble - the surface of which is where it refers more inward than outward - and from the exterior probably it too looks like a priesthood that plays with concepts and charges for access. Perhaps? Yet clearly I feel it brings value. Besides its economic impact, it provides me with my tools for thinking and creativity. So how am I to reconcile that with these imagined exterior views?\nAnd my goodness, design. There’s a whole world of mysterious, self-referential language and play with ideas that many have trouble believing actually carries meaning to those participating, but in which I have great faith and find much value and enjoyment.\nBack to the Glass Bead Game\nBecause, with my 2020 perspective, the Glass Bead Game alarms me. The Game is played by a monastic caste of adepts and it takes a lifetime to master. It is supported by the fictional society it sits within.\nIt’s exclusive. It’s privileged. Although it makes a show of being meritocratic - in theory, recruits can come from anywhere - in practice it perpetuates the class system. Cynically: the meritocracy is a sham to build allegiances with the powerful in society at large, to enrol them in defending its practice of extracting energy from the ecosystem, simply to perpetuate its own complexity.\nThinking about the Glass Bead Game again, it seems more like a warning against societal preoccupations that fiercely gate-keep themselves. Which troubles me, because that also describes a lot of what I enjoy…\nSo perhaps the book is a doorway into meditating on (and perhaps learning how to distinguish) which unproductive, self-indulgent, expertise-demanding, self-perpetuating, expensive, worlds are actually very much the stuff of life - in that life would have no meaning or joy without them - fiction! art! hiking! opera! sharing great food with friends! – and which pursuits are instead complex emergent parasites on society, with double mouths gulping from the noosphere and the econosphere, getting fat on their own shit.\n",
    link: "/home/2021/12/31/books",
  },
  {
    title: "Interconnected is 20 years old today",
    date: "12.26, Wednesday 19 Feb 2020",
    content:
      "20 years is pretty old for a blog, right? Although nowadays I “blog” more to my daily work notes or my “draft posts” folder than I post here.\nI actually have a post I’m working on. But, as is typical, it’s getting longer and longer each time I touch it, and (I know how this movie goes) it’ll probably soon get to the point where I think it’s too boring, too asinine, or too wrong to do anything with. So no promises on that front.\nInstead here’s a rambling post from 2007, from before I got self-conscious.\nIf you’re looking for some good sci-fi, try Unholy Land by Lavie Tidhar (I kind of don’t want to point at a review but if you insist). The book I am currently most excited about reading is the new short story retrospective from Molly Gloss, Unforeseen – I have the paperback on pre-order. In the meantime, read her novel Wild Life (there’s a decent blurb behind that link). Both of these books deal with subtle uncertainty and unstable realities. Much of Wild Life takes place in silence. Gloss writes about silence beautifully.\n",
    link: "/home/2020/01/29/the_glass_bead_game",
  },
  {
    title: "VP of Something",
    date: "07.45, Friday 21 Feb 2020",
    content:
      "Over the years I’ve met a lot of new agencies and consultancies, and got to chatting about their positioning and strategy – the words they use to talk about what they do, how they dress it up, and who they’re selling their services to.\nSometimes the new business is operating in a new market which typically isn’t the smart thing to do. It’s an uphill struggle to sell something where there isn’t an common job title for the buyer, or an established network for word of mouth (word of mouth is unreasonably effective) or an easy way to see how the services fit into business as usual. But when you can make it work, my goodness, things start flying. So it can be worth it.\nThink… design, about 10 years ago. Even only a decade ago, it wasn’t clear that Apple’s design-first approach would prove so successful. Software development methods like agile were still relatively new and not that widespread: it was unclear that design methods like looking at actual behaviour, prototyping, testing, and learning could actually work, as opposed to diligent specification. The idea that design is a way to invent, understand, and to develop strategy… well, that’s still a tough sell, but at least people no longer think it’s just websites and album covers.\nOr let’s take a newer example: circular economy products and services, whether they are about reducing waste, or actually shifting business models to have a circular supply chain, or changing the internal culture so businesses look for new ways, big and small, to go zero waste. Right now I know a bunch of startups operating in that space, but what’s the entry into corporate customers? It could be CSR (Corporate Social Responsibility), or marketing, or you find a progressive team in product, or there’s an innovation group. It’s muddled.\nAlthough sustainability is changing, like design before it:\nIt’s pretty clear to me that in 10 years time, sustainability will have to be a VP role, if not a C-level role, and circular transformation (I just made that up, you can have it) will be a phrase for the 2020s just as “digital transformation” was the business mantra for the 2010s.\nAnd that takes me back to positioning:\nWhen I’m talking to these new agencies, and sometimes even new startups, who are operating in a space without a clear market, one of the provocations I like to use is this: imagine your ideal customer was the VP of something, or the Chief Something Officer. What would that something be? Design? Innovation? Chief Data Officer? (That’s one which is on the ramp.) VP of A.I.? Sustainability? And can you be the cheerleader for it?\nWhat would need to change in their company for that role to make sense? How would you have to package your work for someone in that job? Someone that high up, you have to take way more responsibility for your work – you give them measurable outcomes, you don’t just make deliverables; you have ownership in a different way. How would you help that new VP make clear the importance of their role?\nOk, your client today, whoever they are, your job is to talk to them like they are going to become that VP of something new, and the purpose of your marketing is to give them the air cover to make the case for it as a critical and growing area, and the purpose of your work is to give them the tools to get them promoted. They’ll feel flattered, you’ll provide more value, and your work will start establishing its own market.\nIt’s a personal provocation I use on client projects too. In addition to the brief we’ve discussed, I ask myself: if there was a VP who had already created the culture and conditions such that this brief was already being answered, what role would that VP have? Can we see this project not just as delivering what it needs to deliver, but as a prototype of this VP’s wider function? And if we see it like that, what’s missing?\nPerhaps this is one of a set of Oblique Strategies for consultancy…\n",
    link: "/home/2020/02/19/20_years_old",
  },
  {
    title: "Now people are comfortable with video",
    date: "19.38, Tuesday 31 Mar 2020",
    content:
      "I wonder what businesses become possible now that people are comfortable with streaming video.\nI’ve started doing the 9am P.E. with Joe workouts on YouTube. 30 minutes of exercise is barely compensating for running (it’s hard to find pedestrian-free routes round here), but it’s great to get the heart going, this Joe Wicks guy is warm and genuine, and our toddler - although she isn’t old enough to join in - seems to love it too, charging round the room. Long story short, I’d never done live workouts through the TV before and now I have.\n(I try not to think about the telescreen workouts in 1984 while I’m doing it: Winston sprang to attention in front of the telescreen, upon which the image of a youngish woman, scrawny but muscular, dressed in tunic and gym-shoes, had already appeared.)\nAnd everyone’s using Zoom, and Houseparty.\nGetting people to do new things is hard. As popular as YouTube is, and as popular as Facebook Live is (or Instagram Stories), they’re very consumption focused, and Netflix (Bandersnatch aside) is still TV.\nSo getting people to do two new things is impossible. Getting people to group chat by video, okay, but group chat by video and also watch football? Niche. So far.\nEXCEPT.\nNow the first hurdle has been removed. Everyone will take for granted the idea that you can watch a live video stream in a group of 500,000 and have live shout-outs from the comments. Or have a group video chat in which friends can drop by. My mum (who is pretty technical, sure) is now playing bridge with her friends over Zoom.\nSo now what businesses be layered on this mode of interaction?\nDoctor consultations, that’s already happening.\nPersonal shopping, how could that work? How would an artisan farmer’s market work? What about touring Venice by telepresence robot? What if BBC iPlayer launched Houseparty meets DVD box sets?\nCould I invite a live sports channel into Zoom with me and my friends? Or a brand new movie?\nTechnically, we’ll need to plug together three things to make ideas like this happen:\n\na trusted social network that can handle different, overlapping groups of “close friends”, and the idea of presence/availability – I wonder if this could be built as a shared utility by several different companies, in a “public infrastructure” kind of way\nvideo software that interoperates with the various discovery endpoints (it’s important, like Zoom, to have links in calendar invites), but that also allows programmatic access – Twilio’s video call APIs might be the infrastructure here\nvideo calling which is as interoperable as the phone network. We need peering between Zoom, FaceTime, WhatsApp video calls, Houseparty, etc. If this is going to work, it’s ludicrous to force a patient who is already familiar with FaceTime to download Zoom to talk to their consultant.\n\nAnyway.\n",
    link: "/home/2020/02/21/vp_of_something",
  },
  {
    title: "Perhaps China’s centralised supply chain won’t last forever",
    date: "20.42, Wednesday 1 Apr 2020",
    content:
      "If I was in charge of industrial policy, I’d be betting against the hegemony of the centralised supply chain. That is: no more getting everything manufactured in China; instead, move to local manufacture and many more, smaller, networked factories. I’m talking over a couple of decades.\nIt’s worth thinking about why centralised supply chains exist.\nHere’s an interview with Liam Casey, founder of contract manufacturer PCH International (and who is, by the way, a good egg) – which means you probably have stuff in your house that they’ve made, but it’ll never say that on the label. I can take a product from the production line in China to a consumer in San Francisco in 4 days, 5 hours, 14 minutes. We’re 3 hours from all the factories we work with, and we’re 3 days from 90 percent of the consumers around the planet that buy our products.\nI can’t remember where I heard this observation, but these timings means the entire transaction is entirely inside the credit window: a consumer can order something on a website, then the material is ordered, the item is manufactured, packaged, shipped, landed, and paid for, all before the invoices from the suppliers become due. That’s the reverse of how inventory usually works, where material sits on your balance sheet – and both loses value as it ages, and adds risk because demand might change.\nA manufacturing cluster gives you that economic advantage, plus optionality over suppliers (reduces risk and cost), easy access to expertise, etc.\nBUT.\nShipping costs are increasing. Shipping is a carbon nightmare, and fuel rules are changing which will hike costs hugely. As we get more serious about climate change, that trajectory will continue. So how does that change the economics? And what other numbers are changing that I haven’t run across?\nMaybe - just maybe - local manufacturing is on the verge of making sense. From this article about Arrival, the new(ish) UK electric van startup: Electric van maker Arrival has secured a €400m (£339m) order for 10,000 vehicles from United Parcel Service (UPS) … The purpose-built electric vans will be rolled out in the UK, Europe and North America starting this year and continuing until 2024.\nAnd:\n\nThe first vans have been built at the company’s first “microfactory” in Banbury, Oxfordshire, but others will be made close to their end markets, likely near major markets such as New York and Los Angeles.\nThe UPS deal implies that the base price of an Arrival van will be about £34,000, compared to a £27,900 sticker price for a new Ford Transit with an internal combustion engine – although with lower maintenance and fuel costs the total cost of ownership for electric vans could be lower.\n\nSo for at least one product - this electric van - the calculus has changed enough such that it’s worth manufacturing locally.\nThe hegemony of manufacturing in China is assumed. But my feeling is that the threshold between centralised and local is a fine line, and it’s closer than it looks.\nI was reading recently about loo paper, because of course I was. Apparently it’s always made close to the place of sale because it’s cheap and not very dense and so disproportionately expensive to ship. So where else are these fine lines, and how quickly could we tip over them?\nAnother interesting data point: Ocado investing in vertical farms. That is, Ocado (massive UK grocery delivery firm, and now a platform supplying software and fulfilment centres to other territories) is investing in herbs and produce that can be grown in racks, indoors, right in the delivery depot.\nI imagine the reasons for an economic cluster existing are similar to the reasons for a firm existing. As explained by Ronald Coase: Firms exist to economize on the cost of coordinating economic activity. That is: finding people to buy shit from costs money. If all the stuff to buy is in one place, it’s cheaper.\nBut at a certain point, coordinating activity can be automated. That’s the internet. That’s machine learning. Routing supplies between factories, that’s packet switching and it was invented in 1931.\nSo imagine the numbers in the equation change… long-haul shipping gets more expensive; the internet means it’s easier to have lots of smaller factories that supply interchangeable parts to the bigger ones; the drivers of mass production diminish…\nHang on, mass production? Well mass production is tied to mass consumption is tied to mass marketing. None of the three precedes the other. But the logic of it all comes from a very particular era of distribution: physical shops, and awareness built using broadcast media (TV, newspapers). Think department stores. Brand is key.\nBut now we’ve got micro-targeted advertising and e-commerce. It’s absurd to stock physical stores with items that probably won’t be bought, just to make a particular size and colour available. And there’s no ABC1 sociodemographic group now, people form their own communities. You can launch a micro-brand on Instagram in an instant (and either keep it niche or scale it to billions). Where’s the requirement for mass anything? The logic collapses.\nSo maybe the logic supporting centralised supply chains has collapsed too.\nLet’s not even get into (gestures ineffectually) the current situation. It’s clear now that every country needs its own manufacturing base so that - when push comes to shove - it can be redirected to make what needs to be made.\nExpect government incentives to support local (or at least national) manufacture in the coming years.\nI don’t know what this future world of local manufacturing looks like. Not 3D printing, that’s too far. But maybe final assembly happening in many, many towns, each local to a handful of markets in a hub and spoke model? Maybe more shared components to allow that… what if all shampoos, cleaning products, fruit juice, etc came in standardised bottles, so packaging could happen in the supermarket warehouse? How would you industrialise packaging-free zero waste shops?\nBut yeah, if I was in charge of the UK’s industrial policy, I would assume this was the destination for 2040, and then invest to build towards that future.\n",
    link: "/home/2020/03/31/video_businesses",
  },
  {
    title: "New rooms for the new normal",
    date: "18.13, Thursday 2 Apr 2020",
    content:
      "In the new normal, I imagine we’ll need a few new room types for our homes.\n1. Quarantine room\nNow when we get grocery deliveries, Amazon parcels, or hand-me-down toddler clothes from friends, we take them directly from the front door to a holding zone where they sit for 24 hours before being allowed into the house proper. (Covid-19 does linger on surfaces for longer than that but the concentrations drop quickly.) The holding zone is the corner of a bathroom. Cold items go on a special isolation shelf in the fridge.\nMaybe we could build a porch onto the front of our house and create a quarantine room. Bonus points: if we could give one-time access codes so deliveries can be left somewhere safe indoors, but without having grant full access.\n2. Video conference room\nYou have to care about different things when you’re working from home. Backdrops are important, as is lighting. I take my video calls with a neutral grey wall behind me. And while I was considering bookshelves for that wall before, now I want to keep it clear.\nDoing the PE with Joe live workouts at 9am every day, I’m struck by how considered his backdrop is – it’s definitely his home with his personality, but it uses neutral colours and all the ornaments are non-overlapping and mostly low contrast. It probably compresses well. Here’s a pic.\nIt’s easier to maintain a space like that at home if it’s just one space. Everywhere else can be a mess. And so long as I’m always going to use that single space, then why not attach a proper webcam to the wall opposite, add some soft furnishings to dampen echos, etc.\nThere’s probably a good business in being an interior designer who curates Zoom-friendly home office backgrounds. Though in this age of lockdown you’d have to figure out how to do it without actually visiting the house. Maybe in the interim Ikea could supply pop-up video call snugs with well-positioned lamps and tasteful decor.\nAlso I wonder how this will impact fashion? I noticed I was looking like a mountain man so I shaved my hair off. But I haven’t worn a nice pair of shoes for weeks and I’m mostly in sweatpants. Zoom life is all haircuts and no trousers.\n3. A home that pays its way\nOk, Airbnb is getting a shoeing because it turns out that (as everybody knew…) people were hoarding property and farming them with short lets, damaging neighbourhoods and driving up rent. BUT the original idea makes sense: rent out a room in my home, or the whole place when I’m not there. The sharing economy innit.\nAnd the wider picture is that your home needs to work for its living. In unstable economic times, a home should also be a source of income, so what does that mean? A room with its own entrance, and a second door (lockable from both sides) that goes into the kitchen for breakfast, to be rented out? Solar on the roof, obviously, sold back to the grid. A kitchen garden. A Powerwall home battery to store cheap electricity and then sell it to neighbours?\nMaybe the future of the “front room” is to be a mixed public/private space, a bit like the shopfronts or workshops of old – a space which is made to run a small artisan business: massage, haircuts, I.T. support, neighbourhood parcel drop-off…  a counter, a big welcoming window to the street, a secure internal door to the rest of the house. How would architecture respond if the ground floor of a duplex, or the front half of a home was assumed to be semi-permeable interface to the outside world like this?\n",
    link: "/home/2020/04/01/supply_chains",
  },
  {
    title:
      "Just a quick couple of links about bears, because I’ve been busy today",
    date: "19.28, Friday 3 Apr 2020",
    content:
      "The original word for bear has been lost. From this article about euphemisms:\n\nOur ancient ancestors were so worried about bears, they didn’t even want to name them because they feared [the bears] might overhear and come after them. So they came up with this word – this is up in Northern Europe – bruin, meaning “the brown one” as a euphemism, and then bruin segued into bear. We know the euphemism, but we don’t know what word it replaced\n\nThere’s some more about bears and also mushrooms and dandelions in this old blog post.\n",
    link: "/home/2020/04/02/new_rooms",
  },
  {
    title:
      "The law, the 4 day working week, and how come society doesn’t see the benefit of automation",
    date: "20.09, Monday 6 Apr 2020",
    content:
      "It strikes me that automation means that the kind of laws we have can really change.\nFirst there are laws as deterrence.\nIf the state wants to reduce some action but it’s really hard to detect, there are a couple of possibilities – take for example, deterring people from driving dangerously fast. The state can make the penalty disproportionately large: so there might be only a 1 in 1,000 chance of being caught, but if you do get caught you might get banned from driving. OR: the threshold for penalty might be stricter, such as having the speed limit by 70 mph when the actual “safe” speed is 75-80 mph. (Or rather, we’re not actually trying to measure speed but danger, and speed is just a poor proxy for that.)\nMultiple together the various numbers to get a deterrence factor.\nNow imagine, in this era of mass surveillance and computer vision, that it’s easier to detect and prosecute. That means that the number of prosecutions can go up, but for the same deterrence factor the laws can be more lax and the penalty lighter.\nSecond: laws that make laws possible.\nThere’s an idea in cybernetics, from Ross Ashby in 1956. Ashby’s Law of Requisite Variety:\n\nif a system is to be able to deal successfully with the diversity of challenges that its environment produces, then it needs to have a repertoire of responses which is (at least) as nuanced as the problems thrown up by the environment.\n\nThe complexity of the controlling system (laws, police, courts) must be at least as complex as the system being controlled (the public). Given we want the controlling system to be small, an easy way to achieve this is to somehow constrain the range of behaviours of the system being controlled – to simplify it.\nThat is, there are some laws that aim to make society simpler to govern, not to deter behaviour which causes self-harm. Perhaps those laws could be removed? \nUsing automation and mass surveillance, the control system becomes more fine-grained; more complex. This means the allowed complexity of society should also be allowed to increase – that is, become less regulated.\nThe police state and the dividend of automation\nBut when we think about mass surveillance and face recognition in cameras, etc, we don’t think about greater precision in enforcement and more freedom. We think about a police state. There are other factors at play:\n\nparanoia: perhaps, even though mass surveillance might allow for great freedom, fine-grained laws might mean that they are impossible to understand before they are enforced. The result would be a kind of horrific paranoia or feeling of being trapped in an abusive relationship\noligarchy: even if greater freedom for society was made possible, perhaps the complexity or the “degrees of freedom” of a society is a bulk property, and needn’t be distributed equally. Some will be granted huge freedom, most of us not so much\nhistory: when profit and power are able to maintain the status quo, whether society overall is allowed to improve or not is a consequence of history. If those in power today wouldn’t be in power tomorrow, tomorrow won’t be allowed to come.\n\nSo there’s a dividend of automation that could mean greater freedom, but other forces mean it might not go that way.\nThe 4 day working week\nI’m reminded of the 4 day working week, which was in the 2019 Labour Party manifesto.\nThere is a trend towards greater productivity by replacing human workers with automation. We are used to thinking about this in terms of unemployment and re-training.\nBut the Labour manifesto framed this dividend of automation differently. Unemployment would be a result of the dividend going into the pocket of company owners. If instead it went to society, we could think about a better welfare state, more leisure time, wealth to spend during that leisure time, vocational second careers, and so on. The “4 day working week” is a way to imagine all of that.\nHow to direct the dividend of automation?\nThe problem is that we have been trained to hear “unemployment” as a problem that the state has to deal with, not an indication that efficiency has increased, and there is now surplus time and wealth. UNEMPLOYMENT MEANS WE CAN DO THE SAME WITH LESS EFFORT.\nHow come the dividend of automation doesn’t lead to greater leisure and greater freedom? How come we’re not even asking the questions about how this can happen?\nI think it’s because there isn’t being painted a clear enough picture of a better future, and engaging everyone in a discussion about how to get there. Give me novels and movies of sci-fi almost-utopias. Make me ask, how do I live there. Make me ask and demand, how do we get there.\n",
    link: "/home/2020/04/03/bears",
  },
  {
    title: "Cyborg prosthetics for limbs that don’t exist",
    date: "18.15, Tuesday 7 Apr 2020",
    content:
      "If you’re given a third arm coming out of the middle of your chest, a really long third arm, it turns out you can adapt to using it successfully in less than 10 minutes.\nHomuncular Flexibility in Virtual Reality, Won et al (2015) [PDF]. \n\nWhat if you could become a bat–your arms acting as wings allowing you to fly through the night sky? The avatars that users inhabit in virtual reality (VR) make this possible. … For example, could people learn to control a lobster avatar that had many more limbs than its human user? … Tracked movements that the user made in the physical world would be rendered as different movements of the avatar body. Thus, an eight-armed lobster could have each limb powered by the rotation of a wrist, the flex of an ankle, or some combination of the two.\n\nAnd:\n\nIn Experiment Two, participants controlling three-armed avatars learned to hit more targets than participants in two-armed avatars.\n\nAnd in the “Future directions” section:\n\nhow far can we push these adaptations? Can people learn to control eight limbs, or kilometer-long arms?\n\nOkay so that’s VR, but why not really?\nThe Cave was a proto-VR environment where you would stand in a cube-shaped room where a virtual environment was projected on the walls. Using a controller, you could “move” through the virtual environment – and look around you without needing to use a headset.\nI don’t have a reference for this but I heard about this experiment: what they did was track the rotation of your head, as you looked from side to side, and then rotate the virtual environment the same amount again. So if you looked 90 degrees the right, it would be as though you were looking 180 degrees, directly behind you.\nWhat I heard was that people adapt surprisingly quickly to this. You get accustomed, really fast, to being able to rotate your head all the way round like an owl.\nDani Clode’s design provocation The Third Thumb visualises a robotic extra thumb as a sixth digit on the hand, used to hold fruit and play the guitar.\nMobiLimb is a robotic finger that protrudes from a smartphone. It can prop itself up so you can see the screen; it can literally point things out; it can drag itself across the table.\nWhy don’t we see a ton of serious research into areas like this? Given it turns out we can adapt psychologically quite happily to having extra limbs, why don’t we see R&D money being piled in?\nI want to see weird-ass research lab nerds from universities walking around like Doctor Octopus, doing their best to convince the rest of us that more hands = better. I want to see folks like Apple and Google try really, really hard to get it to go mainstream, even though they will mostly fail.\nBecause decades of research got us the iPhone – and, by extension, the peace dividend of the smartphone wars being: drones (sensors and batteries) and the internet of things (commodity connectivity) which is massive in the industrial world). Imagine if robotic prosthetics were cheap and commonplace.\nWhat are the mundane, everyday applications?\nI want an exoskeleton chairless chair but for gardening. \nI want to open the door of a cafe with my third arm when my hands are full carrying coffee.\nI want to feel electric fields with my fingertips. I want to go ambling in a new city and not get lost because I have an intuitive sense of north. I want a camera stuck on the back of my neck that shows up as a stretched image round the rim of my otherwise ordinary glasses, and I want to know how quickly seeing behind me feels like a little extra sense that I couldn’t do without.\nForget showing my lost items on a map on a screen and making me treasure-hunt my way back to them. I want to be able to whistle to my phone from anywhere in the house, and have it wriggle out of the sofa and scamper across the room and snuggle into my pocket.\nImagine giving your phone a high five with a tiny hand that you don’t yet have.\n",
    link: "/home/2020/04/06/the_dividend_of_automation",
  },
  {
    title: "Neutron bombs and suddenly being able to see the key economy",
    date: "19.55, Thursday 9 Apr 2020",
    content:
      "I grew at the tail end of the Cold War. My unquestioned assumption was that I would probably live out my life in a nuclear wasteland.\nOne of the things we’d talk about was the neutron bomb. This type of bomb would leave cities buildings intact, and it had very little fallout so the city would be safe to occupy after it was dropped, but the people would all go. Not die, that wasn’t the myth of it, but somehow vapourised – raptured up to heaven, really. It was called the “clean” bomb. The mental image was of an urban Mary Celeste.\nAmongst the misery of Covid-19, this horrifically unfair disease, which is too big for me to think about and so I’m feeling my way around it bit by bit, there is the the lockdown.\nThe lockdown is a neutron bomb for the economy. What if the buildings stay, and the people stay, but the economy vanishes?\nOr at least, part of the economy. The UK government is essentially paying to keep the wheels turning of the “key” part of the economy – the life-support system. With what money? Who knows, it doesn’t seem important now. “Key worker” has a definition now that can never be forgotten. The rest: work from home please… if there’s work to be done. Otherwise, well, being a consumer is part of the key economy too, because you need to consume to live, so you get paid to do that too.\nThis wheat-from-the-chaff of what’s in and out of the “key” economy – it doesn’t differentiate between producing and consuming. Those words are redundant now; we need new words for the transactions taking place. If it’s key, and it isn’t happening because it the market, it’ll get paid for by the state.\nSo it turns out the key economy is a hyperobject that I didn’t know existed. There’s the key economy, there’s the bit which is stood up by capitalism’s free market, and the rest is evaporated.\nI ran across a paper the other day, Why is Maxwell’s Theory so hard to understand? [PDF]. This is in reference to Maxwell’s equations of electromagnetism which he published in 1865 and - despite his high standing in the scientific community - were largely ignored for 20 years. They turned out to be enormously significant. (That is: all of electronics, i.e. the modern world.)\nWhat this paper puts forward is that when Maxwell introduced the idea of “fields,” it was a scientific revolution to the point that even Maxwell couldn’t speak in terms of it.\n\nHe replaced the Newtonian universe of tangible objects interacting with one another at a distance by a universe of fields extending through space and only interacting locally with tangible objects. The notion of a field was hard to grasp because fields are intangible. The scientists of that time, including Maxwell himself, tried to picture fields as mechanical structures composed of a multitude of little wheels and vortices extending throughout space.\n\nElectrical fields. Magnetic fields.\n\nThe modern view of the world that emerged from Maxwell’s theory is a world with two layers. The first layer, the layer of the fundamental constituents of the world, consists of fields … The second layer, the layer of the things that we can directly touch and measure.\n\nThe second layer, that’s the layer you and I live in.\nAnd just to finish off this diversion:\n\nThe ultimate importance of the Maxwell theory is far greater than its immediate achievement in explaining and unifying the phenomena of electricity and magnetism. Its ultimate importance is to be the prototype for all the great triumphs of twentieth-century physics. … All these theories are based on the [two layer] concept of dynamical fields, introduced by Maxwell in 1865.\n\nWhat’s my point?\nMy point is that it took something radical to transition from a world with one layer to a world with two layers. And once that shift in viewpoint happened, there was a fifty year golden age of physics.\nSo: the key economy. I couldn’t really imagine a line drawn around it before. Now I can.\nI don’t know how to draw that line, but just to know that it could be drawn… the fact lets me imagine other kinds of economy, or other orchestrations of human activity that fulfil the goals of the key economy, and it lets me question things. That line is a boundary on definitions.\nLike: why should the money of the capitalism free market be same as the money of the key economy? Maybe, to run health, education, grocery stores, deliveries, we could just print as much as necessary, then remove it from the system via taxes later to avoid the system getting inflationary. Maybe make a special currency called “key activity sterling”. Why shouldn’t the people involved live as well as bank CEOs? It turns out we get to choose what money does.\nMaybe money doesn’t work in the way that I thought money worked. I imagined money as something that could neither be created nor destroyed – the economy as a scaled-up version of MONIAC, that famous hydraulic model of the economy.\nBut maybe money is more like a lubricant in that it makes parts of the system work well together, and you can add it and replace it and remove it and clean it whenever necessary.\nI don’t know. I’m still getting my head round this. Key workers, my goodness you could have spent a lifetime trying to create a list like this or argue one into existence, and now we have it.\n",
    link: "/home/2020/04/07/cyborg_prosthetics",
  },
  {
    title: "The day between the crucifixion and the resurrection",
    date: "11.14, Saturday 11 Apr 2020",
    content:
      "I always notice the Saturday before Easter: this bit between the crucifixion and resurrection is the best. it’s like god’s out of town for the weekend, no one’s watching, house party!\nI’m not religious. I went to a Church of England school and grew up with a half dozen different faiths within touching distance. I’m not athiest, I suppose I don’t believe in God, I don’t think about it too much. I’m closest to being a phenomenologist in that I privilege perspective, so I’m quite happy to consult the I Ching because it seems to say things to me (I don’t feel the need to question it or believe in it), and I don’t like to needlessly multiple unnecessary entities.\nBUT\nalthough I joke about it, the day between Good Friday and Easter Sunday, Holy Saturday, seems to carry some mythic resonance.\nNo God, just for one day. That feels like a day worth marking?\nNobody watching, nobody who always knows more than you, but also no-one to forgive, to catch you when you trip, to provide meaning when things are bad. Nobody who knows how the story ends.\nWhat do you do when you’re on your own? When you can do anything, but… well, you don’t, and not because God or your parents or the government says not to, but because you make that decision yourself. Or when there’s a global pandemic and you can’t say “God’s will” but you have to look it in the eye.\nIt’s the day after school ends. It’s the day you move out and have keys to your own place for the first time, and you shut and lock the door. You’ve gone to bed and there’s a noise and you have to investigate. It’s screwing up and it’s your fault. It’s taking a trip and going on a long hike and realising that nobody knows where you are. Dan Hon has this line, No-one’s coming. It’s up to us.\nIt’s losing a parent. It’s also the feeling I remember on the first evening having brought the baby back from hospital.\nIt’s the excitement of freedom, and the responsibility, and the terror. It’s sink or swim day. It’s adulthood. (It’s the relief of knowing it’s just for one day, and the gratitude it renews.)\nSometimes I think that this is what humankind needs to stand on its own two feet: it should be the Saturday before Easter when our city-sized starships take off from Earth for the last time into the clear blue sky, off to inhabit the galaxy.\nThere’s no deus ex machina. The climate emergency will kill us all unless we do something about it.\nSo the absence of God, for one day, isn’t just about the freedom of nobody watching, it’s also about stepping up to the plate. And it isn’t about each of us being on our own, because when push comes to shove, we can’t look up so we look around, and we’ve got each other.\n(Of course, this day being part of the Christian calendar, I wonder whether this is all part of the lesson.)\nAnd that’s what I think about on the day between the crucifixion and the resurrection of Christ.\n",
    link: "/home/2020/04/09/neutron_bombs",
  },
  {
    title: "So what happens with all the empty office space?",
    date: "20.15, Monday 13 Apr 2020",
    content:
      "After the lockdown, I can’t see people returning to offices in the same numbers. Those who liked remote working will agitate for it to stay that way. And businesses will realise how much cheaper it is to rent only half the floorspace, and push the facilities cost onto employees.\nThat doesn’t necessarily mean working from home. There are some advantages to being in a workplace with other people – focus, energy, networking, etc. And there are advantages to having professional facilities: printers, a decent video conferencing suite, not having to make your own coffee…\nbut what if you could kill the commute?\nThere are tons of people who take the train into London for 60-90 minutes every morning. If I were WeWork, I’d roll out their exact setup to office buildings right by commuter belt railway stations. Sell package deals to city-based firms for separate 3-4 person offices in 20 different towns, for all the employees that live in those places; sweat the details about integrating with I.T. department and make sure there’s secure internet. Show those firms how much cheaper it is against city-centre rent and subsidised peak time season tickets. Not to mention the extra 2 hours work every day.\nThen so long as you’re working from a telecommute hub, why not roam too?\nI know a guy who sold his company then negotiated that, during the earn-out, he could remote work. Then moved to a ski resort and worked from there.\nI’ve worked in companies where you were never entirely sure, until the meeting started, whether your colleagues would appear in person or on the screen. Like, if you could work just effectively in another city, wouldn’t you go stay with friends for a week, just for a change of scene and maybe some sun?\nSo “working from home” doesn’t mean working from home. It could mean normalising working on the road.\nAll of which leaves city centres with a bunch of spare office capacity, once firms downsize their permanent desks and lease terms come up. I guess what happens is that the businesses pushed out before by expensive rent will move back in. So from the outside, nothing will really appear to have changed.\nBut in that changeover, I hope that local government takes the opportunity to lock in vibrant, creative, mixed neighbourhoods for the next few decades. How about zoning for a minimum number of artist studios, co-working spaces, and live-work units, mixed in alongside the flagship HQs and cubical firms, both on the city fringe and right in the middle of the financial district.\nAnyway.\n",
    link: "/home/2020/04/11/holy_saturday",
  },
  {
    title: "A starter list of ersatz foods",
    date: "19.42, Tuesday 14 Apr 2020",
    content:
      "There are a bunch of ersatz foods that were invented out of scarcity and necessity, but have somehow stuck around.\nSalad cream. Canonical substitute food done good. Basically a bit like tangy mayonaisse but with less expensive mayonaisse and more oil and vinegar.\nOrange squash. I’m guessing orange squash was as close as the chemicals industry could get to orange juice without actually going near an orange, but now I’ve started thinking about it, I quite fancy a glass.\nReady Brek. This is easy porridge I guess? I’m not sure if this qualifies as “ersatz” because I think it may be simply branding a generic, which does not count. But I am certainly into the way it is marketed on the Tesco website which includes the immortal line Oat grain fibre contributes to an increase in faecal bulk. Which is… good? I guess?\nMargarine, surprisingly interesting butter substitute.:\n\n[Emperor] Napoleon III saw that both his poorer subjects and his navy would benefit from having easy access to a cheap butter substitute, so he offered a prize for anyone who could create an adequate replacement.\n\nInvented by a French chemist in 1869.\nSpam. I’ve not been to Hawaii but I’ve heard that spam is part of the cuisine there – though from a distance it’s hard to tell whether the spam love is ironic. Because it is disgusting.\nI debated about monosodium glutamate which was invented in 1908 by Kikunau Ikeda as he worked to isolate the meaty flavour of dashi, a fermented base made from boiled seaweed and dried fish. And MSG is now a common ingredient. Is it ersatz dried fish? No, I think, like rosewater, we would call it an essence.\nI’m trying to think of more. This is possibly just because I like saying “ersatz.” Possibly.\n",
    link: "/home/2020/04/13/empty_office_space",
  },
  {
    title: "Don’t drop bombs, drop schools and hospitals",
    date: "20.18, Wednesday 15 Apr 2020",
    content:
      "Videos consultations with doctors turn out to work pretty well. How about this: we get shipping containers and we fit them out as remote-first family practices. Consult doctors over Zoom. Also with Amazon lockers filled with aspirin, common medicines, etc, remote unlocked by giving out a code.\nInitially drop the shipping containers here in the UK, in communities where it’s hard for people to travel due to the lockdown. Then kit out the containers with satellite internet, and use the airdropped health centre as part of international aid: doctors here in the UK taking shifts; patients wherever they live. (To support a team of people who are actually on the ground doing the leg-work, of course.)\nAssume all that works… then I would suggest researching robot surgeons and tele-operated operations.\nNext: schools.\nIt turns out remote education works pretty well too. Fit out shipping containers as supplementary classrooms so teachers on the ground can rotate kids through additional lessons. Allow for self-directed learning for adults too. Put a big screen on the outside and run English language courses. Teaching assistants based here in the UK, of couse.\nLook: the NHS Nightingale Hospital London got going after 9 days starting from the government’s request for assistance. It’s an exhibition centre turned into a temporary hospital with a 4,000 bed capacity; it launched with 500. Here’s the story from the architects BDP, including the instruction manual.\nThis is going to sound like a tangent but it’s not. And it’s going to lead to a place which you might find uncomfortable, because it’s about war, and I apologise in advance:\nI went to a last-minute protest on Whitehall a bunch of years back, and somehow in the midst of all the crowds and chants, I ran into a friend. And he was meeting one of his friends, and they were going to the pub to meet some folks from a military think tank. So I tagged along.\nI ended up sitting next to a researcher and having a long conversation about propaganda and Russian Twitter bots, and all of that is a topic for another time, but the reveal was that this guy’s business card revealed that his specialism was non-kinetic effects.\nThat is, the kind of war you can do without chucking stuff at people.\nI think there are a bunch of situations now where bombs don’t help. Bombing doesn’t help in Syria. Bombs don’t help when young white men are being radicalised into domestic terrorism.\nI’m not a pacifist. I probably lean towards being an interventionist. But I don’t feel that bombs and shooting people have proven themselves particularly effective.\nSo after that conversation in the pub, I started thinking about what I’d drop instead of bombs. Schools and hospitals. Well, why not? In the 1950s and 1960s, it was jazz:\n\nFounded in 1950 and secretly funded by the CIA, Radio Free Europe (RFE) began broadcasting from Munich to Soviet-controlled Czechoslovakia in 1951. …  Soon RFE was broadcasting to Poland, Hungary, Romania, and Bulgaria.\n\nAnd:\n\nWestern music, and jazz in particular, became a popular form of resistance against the Communist regimes, especially in Eastern Europe.\n\nThings we are good at in the UK:\n\nhealth – the NHS should be seen as an asset to scale up; dividing it up and selling bits off is a lack of imagination\neducation – it’s already a massive export\ncall centres\ntech startups\nspeaking English, which happens to be a global language (for some pretty unpleasant reasons)\nmilitary spending.\n\nIf I was in charge of the UK’s industrial policy, in addition to betting on distributed supply chains beating China, I’d also be betting that “distribution” (how value moves from producers to consumers) is going to make a massive shift too, because of telepresence and tele-operation. I would be funding research bringing together the above, creating schools and health centres, remote operated and packaged into shipping containers; designed, built and staffed in the UK.\nThen I’d use these for better serving communities at home, profit (this is a way of taking the UK’s strengths to bigger markets), for international aid, and (um) for non-kinetic effects.\nI suppose my meta-point is that we’re moving to a world where services that can be delivered remotely will be delivered remotely – but that doesn’t mean that both sides need to be speaking at a tiny moving image on a phone. There are more imaginative ways to skin the cat.\nHey so then what else?\nEnglish common law is widely respected. Stuff the shipping containers with terminals to speak with lawyers to draw up commercial agreements, and arbitration suites with UK-trained judges. All remote.\nNext: discos, probably. Music is massive UK export. Eurovision aside we’re really good at it. Drop nightclubs in shipping containers, stream in all the good stuff. Good sound system, good lights. Hearts, minds, and banging techno.\n",
    link: "/home/2020/04/14/ersatz_foods",
  },
  {
    title:
      "Re: Tom Critchlow’s proposal for a decentralised Goodreads-like system, how about using RSS?",
    date: "16.51, Thursday 16 Apr 2020",
    content:
      "Tom Critchlow is having smart ideas about websites that share lists of books, and an open, decentralised way to do it. So this blog post is a response to his ideas and gets a bit technical.\nLists of books that I like\nWhenever I’m thinking about new systems, I like to keep in mind what I’d like to enable. So here are some lists of books:\n\nWarren Ellis periodically posts book reviews\nOther people’s lists of books read, for example Christina Cacioppo; for example Patrick Collison\nio9’s monthly posts of new science fiction, like their list of new sci-fi in April 2020\n\nI would love to be able to subscribe to these, and also have a custom aggregator so that I could read a review about one book, and find out who else has been talking about it.\nLike Tom, I am no stranger to projects about books, having built a book vending machine that sent tweets and run a newsletter to share book recommendations because, like I said back in 2015, knowing what books someone loves is to know their perspective and their journey.\nIt would be neat if I could subscribe to people’s lists and recommendations, like subscribing to blogs or following someone on Twitter, then tap through and browse their bookshelves.\nAnd I agree with Tom when he says that this doesn’t need to be (yet another) competitor to Goodreads. As he says:\n\nThinking through building some kind of “web of books” I realized that we could use something similar to RSS to build a kind of decentralized GoodReads powered by indie sites and an underlying easy to parse format.\n\nAlthough where I differ is that Tom says something similar to RSS and my response is: well why not just use RSS? Well, kinda…\nRSS is really simple syndication\nTom’s suggestion is library.json which is a machine-readable data format that includes lists of books. Each book object has a title, author, link, date finished, and links.\nWhat I suggest instead is that this is split into two formats:\n\nthe library, pointing at lists (like shelves or playlists) like “My favourite books about cybernetics” or “Great holiday reads”, and also smart lists like “Recently finished”.\nthe book list is a simple list of book objects.\n\nTaking the book list format first: rather than inventing a new format, my suggestion is that this is RSS plus an extension to deal with books.\nThis is analogous to how the podcast feeds are specified: they are RSS plus custom tags (this is the recommended approach in the RSS2 spec).\nWhy use RSS instead of a new JSON format? Because…\n\nthere are lots of existing code libraries to generate and consume RSS feeds, so it will be easier for the indie web to create tools\nmany questions such as versioning are already solved\nthere are existing applications that generate RSS. For example, it should be relatively simple to make a WordPress plugin that adds a few fields in the CMS and can share lists of books in this format\nthere are existing applications that consume RSS. For example, it may be possible to work with an RSS feed reader like Feedbin to get them to add some custom features for books\nalthough RSS was originally in XML, it also has a JSON representation.\n\nPlaying near existing ecosystems is great. It’s easier to hack together implementations and get going, and it’s more likely that people will get involved.\nIn terms of the actual tags for the book object, I would suggest:\n\nsupport all the regular RSS tags\nkeep it simple with a user-entered author and title, as Tom has already done\nallow for multiple “same-as” links where the user can link out to Amazon, Open Library and so on. (It would be down to aggregators to figure out how to display this, but allowing for multiple links gives a good chance for a web of data to emerge.)\nallow for multiple “also-in” links where the user can show what other lists their book is in (for example, it might appear in “sci-fi” and “top rated”, and it would be neat to have the discoverability)\nwhen the spec is first published, have a set of tags that are labeled as “experimental” to see if there is any adoption: categories and rating spring to mind.\n\nThen the question is how to handle library.json…\nWell there’s already a way to group RSS feeds, and that’s OPML. Yes it’s slightly weird for this purpose, but it’s well-established for sharing subscription lists and with some strong and documented conventions, it could work well. For example there should probably be:\n\na JSON representation of OPML\na common way to label a special feeds such as “recently read” or “top rated”\na way to link back from the “list of books” RSS feed to the user’s library OPML\n\nWhy use OPML? Because RSS readers already support importing feed from OPML, and it’s easier to build an ecosystem from an existing one.\nI’m very taken by the use case in Tom’s post where it says “Ribbonfarm has just added a new list…”. This would be implemented by the aggregator monitoring for updates in the OPML file.\nSome other things I like about Tom’s approach, in no particular order\nI like that\n\nthis doesn’t require me to put my entire library online. It works for short lists, long lists, ongoing lists, temporary lists, and on-off lists\nI can use this on an ad hoc basis from my own blog, just by adding a few fields and tagging a post as a “review”\nas an approach, it’s not overly reliant on Amazon, etc… but by including the relevant links, a library aggregator could do the hard work of grabbing cover images, making “buy now” buttons, showing who else has reviewed the book, etc.\n\nI would definitely like an aggregator that showed me book reviews from everyone I follow explicitly, and also everyone they follow – but no-one else. That would deal with the potential spam problem.\nIf this was also going to be public, how about a file called following which is exactly like the library but, instead of pointing at my own RSS lists of books, pointing at other people’s library OPML files? It’s what OPML is made for…\nWhat next?\nI know that using RSS instead of JSON objects looks more complicated on the face of it… but RSS is already battle-tested and there’s no point reinventing the wheel. And in terms of building an ecosystem, it’s faster to start with RSS rather than doing something bespoke. It worked for podcasting!\nThe next step would be to bash out a draft spec and put it on a web page so people can point to it. Given something that a few of us agree amongst ourselves, along the lines of the above, I would definitely be up for getting a book feed coming out of my blog in that format, plus a library file, and keeping it all live with a few reviews.\nAnd that, if a few of us did it, we could quickly see what it all feels like by using off-the-shelf RSS readers (I use NetNewsWire on iOS and Mac), and then start playing around with aggregators too. Maybe find someone who is into WordPress to hack on a plugin too.\nAnyway, Tom, back to you!\n",
    link: "/home/2020/04/15/schools_and_hospitals",
  },
  {
    title: "What if charisma is a golden mane?",
    date: "19.32, Friday 17 Apr 2020",
    content:
      "I was talking with my old friend Adam Greenfield a few months back and the topic touched on the rich and the powerful and the uncanny gravity they have.\nI raised my pet theory that maybe charisma is a real physical attribute like height or eye colour, not psychology, and the hyper charismatic have effectively a mutation – or putting it another way, an evolutionary adaptive trait.\nThere are some involuntary tells that are on the face of it invisible, but perhaps pre-consciously detectable:\nPaul Ekman’s theory of micro-expressions holds that our emotions are visible in sub-second facial expressions, invisible to the eye without training, but visible to cameras.\nThen check out this video magnification technique which shows that the pulse is visible through colour changes in the face. I’m sure this must be unconsciously visible – perhaps sensed just as a feeling or an intuition.\nBut we do have an impressive ability to detect when a person is lying! Humans, generally, are pretty good judges of character.\nI’ve been in rooms with reasonably powerful people once or twice. David Cameron and Steve Ballmer come to mind. (Adam had a few too, but those are his stories to tell.) I was not a fan of either of them. Afterwards – I felt impressed? Respect? Reviewing my experience, there’s nothing tangible that should have changed my view. No conversation, just presence. AND YET. \nSo that’s unnerving.\nIt might not be purely visual. Maybe it’s a mutation which leads to intoxicating pheromones. But I think it’s physical, or at least that it’s multifactor and a large factor is physical, because it doesn’t work as well through TV.\nThe Golden Man\nWhat if this ability is the ability to hack human social interaction. They don’t know how they’re doing it, or even that they are.\nThere’s a 1953 short story by Philip K Dick called The Golden Man (you can read the whole thing at that link).\nNuclear fallout has given rise to mutants – humans with bat wings, or psychokinesis. A government department methodically finds and euthanises them: the fear is that a mutant will be appear that can out-compete baseline humans.\nThe Golden Man is such a mutant. He is quick; he can see five seconds into the future; he has a golden mane. He is unnaturally sexually attractive. But he has no frontal lobe: he is pure animal. His irresistibility means he will win in the only race that matters: We’re the last of our line – like the dinosaur.\nPeople with charisma. People with charm. So what would that mean, if true?\n",
    link: "/home/2020/04/16/rss_for_books",
  },
  {
    title:
      "Some rambling thoughts about the stuttering end of the last ice age and what lockdown means",
    date: "20.47, Monday 20 Apr 2020",
    content:
      "The last ice age ended just under 15,000 years ago. The world got warm and wet. Nomadic hunters settled down into villages, the population took off, people were living in Europe.\nAnd then… the ice age returned, a thousand years of cold and drought, and it all changed. That’s the Younger Dryas.\nAfter that, around 9,600 BC, the ice age actually ended this time. Warm and wet again, more or less the climate we know now. Here’s a graph.\nStephen Mithen’s After the Ice is an archeological human history spanning 20,000–5,000 BC.\nThis story describing Mesopotamia has stuck in my head since I read it. As the Younger Dryas happens, animals get scarcer and the villages disband. And:\n\nWealth and power had evidently been dependent on sedentary village life. This provided the elite with the opportunity to control the trade that brought seashells and other items to the villages. A return to mobile lifestyles swept away the power base and society became egalitarian once again … The shells had lost their value because there was no longer any control over their distribution – mobile hunter-gatherers were able to collect seashells for themselves and trade with whom they wished.\n\nNo more elite! No more bosses, no more proles!\nThis is deduced from looking at burial rituals.\nI can’t help but think of this during this lockdown. It’s hard not to see Covid-19 as part of the beginning of an era of pandemics – species jumpers in the wet markets, antibiotic resistent resurgences, escapees from biolabs, ancient viruses steamed out of newly-thawed permafrost, prions… god let’s not even think about prions:\n\nThey’re tiny, highly-infectious particles that occur when protein molecules found in the nervous system misfold. Once a single bad prion enters a healthy person or animal, it causes all of the properly-folded proteins around it to misfold as well.\n\nAnd: You can boil a prion, dip it in acid, soak it in alcohol, and expose it to radiation, and the prion will still be infectious.\nIn the future, we maybe won’t name our generations Boomers, Millennials, etc, we’ll name them after whatever global lockdown was responsible for the baby boom that they were born in. (And if we don’t name the upcoming round of coronavirus-lockdown-babies the ca-boomers I for one will be sorely disappointed.)\nEven if we don’t get another lockdown for 10 years, the fact it’s a maybe means that our behaviour will change to account for the possibility.\nSo I wonder about the long-term effects not of lockdown itself, but the continuous risk of lockdown. Like, will you book a holiday for 6 months time, or will you book simply the option to go somewhere? Would you ever start a business that had a reliance on in-person meetings, or a supply chain that wasn’t tolerant to an unexpected 3 month stop? Of course not. How do you invest in friendships? Do you ever move far away from ageing parents if there’s a risk that planes won’t fly – or does distance no longer matter when you wouldn’t be able to meet in person anyway?\nAnd what does all of that mean? How do you act when, at any moment, the physical speed limit of the planet might drop to walking pace?\nI think that’s what makes me think of the Younger Dryas: environment creates power hierarchies creates culture. So when our environment changes…\nLike: right now I’m interacting with strangers less. My world has contracted to my neighbourhood. I’m not randomly meeting friends of friends at events. But I am connecting with certain friends in very small groups more often, and I am investing a lot more time in “continuous partial” connection with my family. And when I am meeting strangers, because it’s generally 1:1 on a video call, I’m spending more time and making a deeper connection.\nWhat previous power hierarchies have been disrupted? What previously valuable seashells are now available for anyone to grab? What new power hierarchies are being created?\nHere’s a minor one, and this is what I mean because it’s both the society-level things and also the everyday…\n‘Big’ men: Male leaders’ height positively relates to followers’ perception of charisma: Physical height is associated with beneficial outcomes for the tall individual (e.g., higher salary and likelihood of occupying a leadership position).\nBUT: if we interact over video calls and can’t tell height, what then?\n",
    link: "/home/2020/04/17/charisma",
  },
  {
    title: "Video calls, doing stuff together, and the TV room",
    date: "17.24, Wednesday 22 Apr 2020",
    content:
      "This morning we lunged and squatted along to PE with Joe as we have for most days of the lockdown, and all together across three homes and two continents as we have for the past week or so.\nWe have a family iMessage group so there’s usually a bit of text chat just before 9 to see who’s up for it. Then somebody hits the FaceTime button (which is hidden at the top) to kick off a video call.\nThen what we do, in our house, is precariously prop the iPad against the TV for the group video call. The workout is a YouTube Live thing at 9am every weekday, so that shows on the TV itself. We’re here in London. There’s another bit of the family doing the same elsewhere in the UK, and then another bit of the family in Queensland, Australia, where’s it’s 6pm, and we all do the workout together.\nThe noise is catastrophic so we tend to mute YouTube and listen the exercise instructions via Australia instead, which is out of sync and absurd when you think about it, but it works.\nThere’s a little bit of chat in rest periods, mainly with our toddler who gets thoroughly underfoot – I managed to sit on her and later take her out entirely with a backwards kick today. Then afterwards we wave bye or sometimes hang out.\nI think this is magical.\nA couple of ways this could be better:\n\nApple should add a FaceTime app to Apple TV and support an approved set of 3rd party wireless webcams to use with it (not that I own an Apple TV, but I would buy one in a shot with this feature…)\nYouTube Live streams should be FaceTime participants we can invite directly into any call.\n\nI was chatting with designer + friend Joe Malia about this a couple days ago and he said I want something to keep in touch with folks more but don’t always have something new to say (and that’s not a bad thing) – and I said, what a design brief that would be: how to keep in touch without anything new to say.\nPerhaps there are a couple of clues in the daily workouts?\nVideo calls are becoming accepted as a place we can do stuff together rather than just have mere conversations. And you don’t need anything new to say if you’re doing a workout, or playing bridge, or singing in a choir together (all of which my mum is doing pretty regularly btw).\nSo one question is how video call software needs to change if it’s going to be used for domestic activities, instead of sharing PowerPoint slides.\nThen thinking about togetherness which has a kind of “social attention” ladder. From the top…\n\nfull focus: having a conversation together on a video call\npartial focus: doing something separately but together, still on a video call, like a workout\nmultitasking: having a conversation in a group text chat\nawareness: dropping the odd funny link into the group chat, without any expectation of a reply\npresence: at the very bottom, simply being in the same text chat group.\n\n(Some systems have a more developed “presence” system: green or red activity lights will show whether someone is online or not, that kind of thing.)\nAs a group, in whole or in part, we move up and down this ladder: there’s a push/pull from individual members that makes this happen. And it’s fascinating to look really closely at the exact push/pull mechanisms.\nI wonder about the role of location as part of the push/pull on the ladder. There’s no way that I would let any of my family peep through my phone or my tablet to automatically turn a chat into a call…\nbut the TV in the front room?\nYou know, MAYBE?? The front room is already a kind of semi-permeable space…\nThe Viewing Room\nThe full text of The Naked Sun (1956) by Isaac Asimov, in which Elijah Baley visits Solaria, a planet of where everyone lives on vast estates managed by robots, and they never, ever meet in person.\nWhen they want to talk, they step into a Viewing Room.\n\nDaneel said, ‘It is necessary first to signal the individual one desires to view. A robot will, of course, receive the message. If the individual being signalled is available and wishes to receive the view, full contact is established.’\nBaley’s glance fell to the floor. Where did his room end and the other begin? It was easy to tell. There was a line where the quality of the light changed and that must be it. \n\nAnd there’s a discussion about the difference between seeing and viewing:\n\n‘Same thing, isn’t it?’ said Baley. \n‘Not at all the same thing. You’re viewing me right now. You can’t touch me, can you, or smell me, or anything like that. You could if you were seeing me. Right now, I’m two hundred miles away from you at least. So how can it be the same thing?’\nBaley grew interested. ‘But I see you with my eyes.’ \n‘No, you don’t see me. You see my image. You’re viewing me.’ \n\nAnyway.\nMy point is that I don’t think I’d mind somebody from my family group chat peeping into my front room. Perhaps with a behaviour like this:\n\nmy devices also join the group chat and show up as avatars\nsomebody can tap on the icon of my TV to initiate a call…\nat my end, the TV says out loud “Starting call in 10, 9, 8…” and I any point I can yell out “not right now,” and it refuses the connection\nif it does connect, it’s a voice call only – a bit like call screening, only we can talk both ways, and I can shout across the house\nthen if I actively step up to the TV and accept the call, it goes to video.\n\nBecause TV is a lean-back experience (that old phrase…) it should be possible to hang up the call by raising my hand in the air (to let the computer that I’m addressing it, none of this Hey Siri nonsense) then saying “hang up.”\nThat would let me go about my day, multitask, make a cup of tea, play with the little one, and do it all simultaneously to being on the video call. My phone should act as a portable mic when I step out of the room.\nI’m not sure I’d want this kind of behaviour in any other room except the front room with the TV, but that shared space is so different from my phone, or the other rooms in the house, maybe we should design for it specifically?\nToo much writing! Enough.\nOh no actually, one more thing!\nThat talk of Viewing Rooms reminds me of the Cisco video conferencing setup where they paint the room the same neutral grey at both ends, and the table looks like it continues through the screen, etc. Fancy.\nYears back we were doing a bunch of work with Intel, and the team we were working with was in Portland, and it was morning there, and we had to travel to Swindon to do the calls in the evening, a bit of a way outside London, because they had the full Cisco kit set up there.\nSo it’s evening and it’s also a chilly day, so we’re all bundled up. But the meeting goes on like three hours and those big screens run HOT, so progressively the room is getting hotter and hotter. And by the end we’ve all pulled off our sweaters and rolled up our sleeves and unbuttoned our shirts, designers presenting the latest project deck from our meeting room sauna, all the while doing the world’s slowest, sweatiest striptease.\nDefinitely too much now. Enough enough.\n",
    link: "/home/2020/04/20/continuous_partial_lockdown",
  },
  {
    title: "Animal Crossing and games as wish fulfilment",
    date: "19.30, Friday 24 Apr 2020",
    content:
      "Like a bunch of people, I’m playing Animal Crossing a bunch. The release of Animal Crossing simultaneously with the lockdown is like this perfect storm of “world with global pandemic where you can’t go outside” meets “world with no global pandemic and you can go outside”, and this has created a number of Hot Takes.\nI am OBSESSED with Animal Crossing btw and I’m not going to explain how it works here so for that you can read my post from 2006 about it instead.\nOh god okay, one hot take: The Atlantic did a thing on Animal Crossing which is pretty good reading actually but I don’t agree. Their take:\n\nit’s not escapism, says The Atlantic: Animal Crossing isn’t a fantasy-world replacement from real life, absent all its burdens.\nit’s a political hypothesis about how a different kind of world might work, in which pastoralism and capitalism coexist perfectly.\n\nDunno. Good article though.\nHere’s little Genmon with a tetrapod. I’ve been building them on the beach. Tetrapods are those big concrete forms that slow down coastal erosion.\nIt’s funny (but sad) because of course there is no coastal erosion in Animal Crossing.\nBUT?\nGo read this Twitter thread by Everest Pipkin who has been digging and sculpting and gardening their Animal Crossing island in order to introduce a river delta, and swampy bits, and rivulet waterfalls from a mountain – as if the island had geological history apart from Pipkin – and high mountain meadows and canyon narrows and MY GOD IT’S BEAUTIFUL, Animal Crossing doesn’t need to be about any more than this.\nIt’s pretty. It’s nice to spend time there.\nFor what it’s worth, I think of games a bit like dreams.\nThere’s a bit in Freud’s Introductory Lectures where he talks about children’s dreams as being wish fulfilment: doing while asleep what can’t be done awake.\nAnd I’ve noticed over the years that I tend to gravitate towards games that let me succeed, in a microscopic contained way, at a task that I’m struggling with at work (or in life, but let’s not think about that too much as it’ll just get a bit revealoing and awkward). Not all games, but those popcorn-style satisfying smartphone games in particular. Like, a game will match up with my workaday focus of plate spinning, or aligning timings, or barrelling through a project by sheer force of will – it varies – and let me succeed at it.\nNow, the question:\n\ndo I gravitate towards games that mirror what I do during the day because, in the true spirit of play, they are allowing me to practice and limber up those same muscles but without consequence?\nOr is it so I can get the satisfaction of succeeding at something I am genuinely concerned I might fail at?\n\nDunno.\nBut it’s why I don’t see Animal Crossing as escapism. It’s not escaping from anything, it’s just what I’m doing what I want to be doing anyway but in a different context. And maybe one of the reasons the game is popular with so many people is that there are many different pathways players can take through it, and none of them is blessed as the way to win.\nPreviously to Animal Crossing, I have also\n\nspent hours in Red Dead Redemption riding round and seeing the landscape of the American south-west change as I go. I listened to the soundtrack a whole bunch when our toddler was in her first few months: it was my go-to music for a while when I was rocking her to sleep.\nspent hours in Riven riding the cable-cars, re-treading the trails through the canyons and the forests, and trying (and always failing) to catch a closer glimpse of those plesiosaurs sunbathing on the rock by the water.\nspent hours in Grand Theft Auto 5 driving around the island, watching the sunsets, and listening to cheesy end-of-day 80s music on the in-car radio.\n\nIt’s a convoluted way to listen to cheesy 80s music, but, like I said, hours.\nIt’s only writing this that I realise how much of it is about music.\nAnyway, that’s how I enjoy games.\nSo there’s a character in Animal Crossing called KK Slider who is a pop star but sings, like all AC characters, in the gabble-gabble in-game language. And somebody on Twitter earlier shared a YouTube of KK Slider doing Africa by Toto which kind of brings everything together, so I’ll wrap up there.\n",
    link: "/home/2020/04/22/the_viewing_room",
  },
  {
    title: "Domestic telepresence at scale: some notes",
    date: "21.05, Monday 27 Apr 2020",
    content:
      "After I posted about video calls, doing stuff together, and the TV room, there was a great discussion on Twitter. Listen to some of these ideas:\n\nOn remote togetherness without having to have anything to say, Tom Critchlow speculates: perhaps an e-ink dithered image that is an always-on video feed of my living room? Shared with family and friends?\nAnd later in the same conversation, Another way to think about it – always on HD video of the living room shared with family/friends but only at specific times like every day 2-5pm or something.\n\n…which I’m into as an idea! I like the idea of a scheduled group call that fires up on your TV at 2pm for an hour whether you’re there or not. Also I think there’s a lot to be said for ambient noise – it’d be neat to hear the muffled sound of activity on the other side of the TV screen.\nThere was a good discussion about how you could do a “keep the doors open” kind of telepresence, but without massive privacy violations. Even a dithered e-ink screen would today require an internet-connected, always-on camera pointing directly into your house. Scary.\n\nScott Jenson talked about how that could be done: What about local only analysis of an HD signal? The video never leaves the camera, but it does output who it recognizes and that gets shared with only the immediate family. – and I like this idea of compressed “computer vision dithering” that shares only one of those green boxes and labels diagrams rather than the full feed.\nHow could you guarantee and certify that, asks Han Gerwitz., Maybe we need some sort of visibly low-bandwidth networking. Sensing cameras that output only a QR code display, with scanning cameras collecting from them.\n\nI really like the idea of computer networking protocols that are human readable. I have a vague memory of reading about an audible protocol that sounded like birdsong? The advantage being that if a hacker was trying to get into your network, you would hear it.\nOn the other end of things:\n\nAndrew Eland pointed me at Tonari which makes massive room-scale screens that show other, remote rooms, with the people projected there at 1:1 scale: tonari is an open doorway to another place. (Here’s Andrew’s tweet.)\n\nTonari is for businesses, it’s not made for the domestic context. And I like the idea that sometimes you’re having a meeting, but sometimes you fall into an opportunistic water-cooler chat, and the rest of the time your colleagues are just there, the ebbs and flows of the two offices brought together, however far apart.\nI mean…\nSome of these ideas are pretty weird. BUT. But. Why not give them a go? The feeling of it all. It would be good.\nI’ve been trying to put a name to what it is I’m circling, and the best I can I can come up with is this: domestic telepresence at scale.\nBy telepresence there’s the usual meaning, being telepresence robots (which come and go in the zeitgeist, that post is from 2011). But ALSO AND MORE REALISTICALLY I would include group video calls. The robots being something more like “peak” telepresence?\nActually, I would include anything that contributes to this feeling of togetherness… fictional ideas like the idea above of transmitting the ambient noise of the home so I feel like a family member is in an adjacent room, and also real ones like “availability” indicators, and WhatsApp read receipts, and so on.\nWhat I’ve learnt from my experiences with casual Zooms with friends, or hanging out in social Slacks, or doing workouts with my family in Australia with a combination of YouTube Live and group FaceTimes is that these technologies all combine to produce a sense of togetherness, they all count!\nTelepresence isn’t something you step into, rather it’s a gradient. Your attention can be fully or only partially split between the local and the remote. And you’re in multiple groups of course, each of which has different compositions and norms. So you need all these different approaches at different levels for peak telepresence to even have a chance to occur.\nThen there’s that word domestic.\nI can’t even imagine what this lockdown would have been like without the internet. I’m with my family and friends, even though we’re physically sometimes thousands of miles apart. And although I’m giving the internet credit, I will also say that the internet has not really served us that well. The fact that we have this sense of togetherness right now, domestically, is because there is an amazing mass co-opting of technology going on:\nZoom was not made for people to play bridge! Facetime wasn’t created to be left propped up in a corner while we sing “twinkle twinkle little star” and then wander off to make a cup of tea while people come and go from the room. But imagine if these technologies had been built for these behaviours!\nLook. People in business will do all kinds of bonkers things if there is Return On Investment.\nBut “domestic” means having TVs which are shared devices, and phones which are private. It means group accounts. It means old people and young people. It means different rooms in the house. The domestic world is more diverse, more messy, and more demanding. Software isn’t built for this.\nWhat’s particularly energising about this period of forced experiments, as Benedict Evans calls it, or less abstractly, “not being allowed to see our friends”, is that I’ve been reminded that telepresence is powerful and people want it when it works and there is a absolute TON for us still to explore.\nAt scale.\nThe reason I include “scale” is because I want to figure out how to continue to have this sense of togetherness available for everyone… even after we’re allowed to leave our homes.\nWhen the lockdown ends, a lot of this co-opting of technology will end too. That’s a shame.\nAnyway, in all of this domestic telepresence I would include\n\ndoor-sized big screens that are telepresence-teleporters into other homes \ne-ink portals and low-bandwidth sensors, maybe even our old Availabot presence toy (2006!)\ntabletop robots that can be inhabited by my family members: Ross Atkin’s AMAZING tabletop telepresence device is a DIY robot made from a cardboard kit and a phone, and you drive it around your friend’s kitchen a hundred miles away with your face talking out of it.\n\nIn what world could Good Night Lamps be just at home on my shelves as my books are?\nAny one of these on their own would be weird. But together, and normalised somehow…\nI think what the “at scale” requirement makes me ask is: how could these be mainstreamed, and how could people almost compose their own experiences through all kinds of different services and devices, without having to do things like create a new social network in a thousand different places?\nI don’t see that the answer could ever be a single service doing it “right”: there can’t be a single “winner” such as Zoom, or Facebook, or WeChat, no matter how many features they throw in. People and groups are too different.\nSo I think of iPhones and Amazon Echoes.\niPhones and Echoes both pass Google’s toothbrush test: Is it something you will use once or twice a day, and does it make your life better?\nBut nobody’s iPhone and nobody’s Echo is the same. We call it “downloading apps” but really what’s happening is that people are making their devices radically different – a camera for one person, a TV for the next. They’re twice-a-day toothbrushes, sure, but it’s a different toothbrush for everyone.\nMaybe there’s a lesson here?\nI guess what I’m speculating is a kind of social operating system that links all these different parts, and allows new ones to emerge.\nSomething that doesn’t abstract Zoom, Facebook, and Animal Crossing, but sits alongside them and someone provides visibility between them (or not, as appropriate).\nWhat would it mean to see that your friends are congregating watching Netflix (remotely) while you’re still at work? How could they hassle and yell at you to come hang out already?\nA digital photo frame that understands it’s in the shared front room and somehow shares only the pictures appropriate to that context from everyone in the house?\nWhat about something that lets me and my group step up a gear from iMessage not into FaceTime, but into toy telepresence robots, playing an obstacle course that somebody has cobbled together in their front room?\nFeeling my way around something here. Not sure what it is yet.\n",
    link: "/home/2020/04/24/wish_fulfilment",
  },
  {
    title: "Video game soundtracks, and a format for adaptive long music",
    date: "17.58, Tuesday 28 Apr 2020",
    content:
      "I mentioned Red Dead Redemption the other day. Here’s the original trailer from 2009 – it’s a gorgeous game. It looks and plays like a spaghetti western, which admittedly I’m a sucker for anyway, but you spend a ton of time just riding around dry plains and watching sunsets which is kinda perfect. And the soundtrack is :chef’s-kiss-emoji:.\nActually, maybe play the soundtrack now here on Apple Music or here on Spotify and listen while you read this post. For the atmosphere.\nReading about the making of the RDR soundtrack is fascinating. There is apparently 14 hours of music, and it has to work in loops rather than tracks…\n\nThe obvious difference is that film music is written to fit a finite scene, whereas with the video game, we’re working in five-minute loops. It’s really wide open, but also very hard, because there are all sorts of things happening with layers. If the player shoots someone, suddenly the music changes, so we have to think, ‘okay, does this work over the top of that?’. Also the big thing with a game is, you don’t know how long you’re going to be staying in that mood – you can’t state too much, it’s kind of like implying a mood. It’s a balance between having it interesting, but not so much that you get sick of it, because you could be riding that horse for 15 minutes…\n\nAnd so:\n\nAlthough this gives the impression of a formless improvisational process, because of the way the music reacts in real-time to the player’s actions, the underlying structure had to be meticulously planned. If a dramatic sequence suddenly kicks off, the soundtrack switches to something with greater intensity, while a more foreboding sound is required during moments of suspense. All of these loops have to segue into each other as events evolve on screen. … the whole score is composed in A minor and at 130 beats per minute.\n\nIt would be neat to be able to listen to all of this nuance and dynamic shifting without the need to actually play the game at the same time.\nI AM REMINDED OF:\n\nThe Wetland Project is the sound recording of an endangered marsh in British Columbia, Canada, broadcast for Earth Day:  The sounds of birds, frogs, airplanes and more, take over the airwaves for this twenty-four-hour experience in “slow radio”. (You can stream the wildlife sounds from that website.)\nChris Watson’s wildlife and landscape recordings – a musician and artist, he’s also a sound recordist for BBC nature documentaries. His album The Weather Project (you can find it at that link) includes recordings of dawn in the Masai Mara, and the creaking of an Icelandic glacier.\nThis old iPhone app Pocket Storm (there are examples on that website): A storm that approaches, surrounds you, and then drifts away from chirping crickets to the sound of an absolute monster of a downpour, and it’s all generated. You choose the length of the storm you want to the minute and then hit play.\n\nI wonder, when I listen to these soundscapes, whether it would be possible to make an album that is intended to be listened to over a full 24 hours, as a kind of live soundtrack to your life?\n\nWe live real lives, which means the soundtrack would need to follow you around, and adapt dynamically to fit in, so rather than having it as an album somewhere, you’d probably deliver it as an online radio stream that you could play through your phone and Apple Music, or Sonos at home, or your TV – only it would be a private, personalised stream, made just for you.\nTo adapt, the service would need some minimal inputs: the robot DJ would need to know whether you were asleep, or rushing for a train (remember that?), or perhaps could bring the soundtrack to a moment of quiet if you opened a video call app. So it would require some kind of permission to watch what you were doing.\nThe artist would create the music as loop and layers, not tracks, and set the rules about how the composition should come together and behave given the inputs, and over 24 hours - as the listener - you would get to experience the whole piece.\n\nThe temptation would be to make this functional somehow, like it have the sound of birdsong when you had a meeting incoming, distant barking when an email in your inbox contains urgent-sounding words, but that’s not really what I mean. (Although that’s interesting too.)\nThere’s an apocryphal story that the compact disc runs 74 minutes because that’s the length of the longest recording of Beethoven’s 9th symphony.\n(Ignoring the 24 hour version, 9 Beet Stretch, I’m guessing… which is wonderful by the way).\nIt turns out the size of the CD is more to do with data compression, fierce corporate strategy, and German manufacturing capabilities – but it’s a reminder that the album “format” isn’t inevitable. What we’ve got is contingent on the market, path dependent on its own history.\nAnd so streaming music apps, royalty calculations, ID3 tags, charts, indie upload sites, etc, all still perpetuate the album, even - as they are now - untethered from the physicality of vinyl or plastic disc peppered with microscopic dots to be read by lasers – all still propping up the old system just because that’s what everyone else does, like the end of The Good, the Bad, and the Ugly, nobody able to drop their gun and walk away.\nSo I wonder what it would take to break that Mexican standoff?\nPerhaps…\nAmazon could team up with video game publishers via the relationships established with Twitch, together defining a “soundscape” format for long music, to be broadcast through Amazon Echoes and wherever the Amazon app is to be found, initially as a way to publish game soundtracks in a more authentic form than 74 minute static albums, but really open to any artist, the format eventually finding its own Brian Eno or Ennio Morricone but actually it’s a 14 year old kid somewhere in the sticks?\nHow change happens. How new formats are born. I wonder.\nUpdate 29 Apr\nI’ve been chatting on Twitter with designer + musician Matthew Irvine Brown about this, and I think it’s worth saying that explicitly what I don’t mean is a video game music engine as an app, or procedurally generated soundscapes… like, there’s a lot of that and it’s great, but I’m into the idea of a format which is closer to existing albums but REALLY LONG, with just as much adaption as required to make it so you can listen all day.\nAnd by far the closest I’ve seen to what I mean is Matt’s own 2011-2016 project Music for Shuffle. e.g. from the sleeve notes on his first composition:\n\nI wrote a series of short, interlocking phrases (each formatted as an individual MP3) that can be played in any order and still (sort of) make musical sense.\n\n…which also includes lovely nuggets like: Doing this experiment meant thinking about what happens when the listener presses skip – in a sense, they become a performer.\nMatt’s made 22 of these! Whoa.\nSo… each one is a shuffle cassette maybe? The format is a ZIP file hosted on Dropbox plus a metadata file and an image cover, or maybe a podcast feed which lists all the individual MP3s, so anyone can make and host them – but so that each cassette is still recognisably a contained thing? And then perhaps a player app which can download and play these cassettes?\nAnd perhaps v1 just does shuffle, but then v2 has a couple of simple triggers like “only play this track if the listener running”.\nMaybe for the triggers (and this is slightly absurd but, perhaps?) the “language” could be the generative grammar Tracery which is used by Cheap Bots Done Quick for a trillion amazing Twitter bots, being exactly the right combination of accessible yet expressive?\nI’m into this.\n",
    link: "/home/2020/04/27/dtos",
  },
  {
    title: "So I went outside and we’re all wearing masks now",
    date: "17.07, Saturday 2 May 2020",
    content:
      "I went out in public this morning for the first time in about four weeks, and tons of people are wearing masks. (We’re fine but our household has been isolating all that time: first after an encounter and, just as that stint ended, the toddler had an unexplained fever.)\n\nWe don’t have any masks (yet) so I ad-hocked a winter buff. Not ideal, it made my glasses steam up. Breath is hot!\nIt was immediately shocking to see people who were not wearing masks (a minority only). Specifically I noticed in myself a feeling of anger at their selfishness, or anger as if they were deliberately attacking me, or perhaps I felt that they were freeloading on the carefulness of others – and whether valid or not, that anger is a feeling to keep an eye on, because I imagine a lot of people are feeling the same, and society-wide feelings of anger can quickly become invisible, unquestionable, and manipulated by those in power.\nI can’t see us going back to not wearing masks.\nYoung people in particular seemed less likely to be wearing masks (by “young” I mean the under 30s, OK boomer…) and those same people were also more likely to be casual with their social distancing. The generational discrimination of this disease is so stark: if you’re young, you’re much less likely to get seriously ill, you’re less likely to know someone who has gotten seriously ill, and your parents are probably younger than the 70+ danger zone. Covid must be so abstract for them, primarily an economic problem, but day to day they feel immune and immortal.\nAnother group less likely to wear masks: street cleaners and delivery drivers. Lack of masks supplied by work? Or is it choice… does continuous exposure to the risk just produce a sense of resignation? Or do they feel (fairly) that, as essential workers, their permission to remain unmasked is what society is “buying” with social distancing?\nAnother group less likely to wear masks: runners and cyclists. Come on guys (it was all guys), it’s mid morning, it’s busy out.\n\nTwo other things:\nIt’s hard to see and show emotions in a mask. A thumbs up or a yell of thanks is easy enough, but how do you walk down the street and look friendly and approachable? Or at least, 1.8m approachable.\nAvoiding people is weird. You step out into the street, or wait for them to move along, but in terms of proxemics it’s very unusual to take such care to keep another person at a far-social-almost-public distance. 6ft/1.8m is outside the comfortable conversation distance of 1.6m. So I’ve a hunch that what happens is that you take the evasive action, and then afterwards you feel a flush of the emotion that would usually precede it – a vague sense that the person needs to be avoided, classic post-rationalising confabulation. Then I catch myself treating the other person in a way that is consistent with that emotion, like it would be somehow hypocritical to first steer clear of them but then give a friendly hello.\nBut maybe these two points are connected? A mask means the smile isn’t seen and actually it’s harder to make too: the mask holds my face in place, just a touch. And maybe a smile not made is also a smile not felt?\nMasks\nKeith Johnstone‘s Impro is a book of theatre techniques based around improvisation and when I read it in 2008 I found it life changing. This summary on Ribbonfarm is a decent taster.\nThe first three chapters are called Status, Spontaneity, and Narrative Skills and they’re great but also they make sense.\nThe third chapter is called Masks and Trance and reading it is an unsettling experience, in the Lovecraftian sense of there being infinitely more to the world that we know or, for that matter, could handle.\n\nThe reason why one automatically talks and writes of Masks with a capital ‘M’ is that one really feels that the genuine Mask actor is inhabited by a spirit. Nonsense perhaps, but that’s what the experience is like, and has always been like.\n\nAnd:\n\nA Mask is a device for driving the personality out of the body and allowing the spirit to take possession of it.\n\nIt all sounds unbelievable until you try a Mask, and allow yourself to let go just a little.\nHow to do it:\n\n… make your mouth fit the Mask and hold it so that the mouth and the Mask make one face.\n\nHere are some of my favourite quotes.\nI have a vague and hand-wavey rationalisation of the Mask… we’re social animals, and when we change the way we’re seen and interacted with, that reflects back into the psyche, blah blah blah.\nBut the fact remains that wearing a Mask is a terrifyingly powerful experience - seriously TRY IT - and actually a pretty good shorthand to talking about what’s going on is to simply say that, yes, these inanimate objects carry their own personalities, and, yes, when you wear one, that personality possesses and changes you.\nSo like I said, I went outside today, and it turns out a ton of us are wearing masks now.\nAnd I wonder, what personality does a mask/Mask have when it’s\n\na tight, shaped mask and it fits round your cheeks, hardening the face,\nor a homemade-from-a-t-shirt mask that makes your breath short and hot, and smiles are there but hidden,\nor a medical mask that advertises status and authority to all around, unearned,\n\nand how do those spirits possess the wearer? And what happens to a community when, almost overnight, these personalities come into the mix?\nAnd what about the Twitter mask, and the Facebook mask, and the email mask, these other masks we wear online which hide our faces and possess us with their spirits? How might we notice them, and how might we describe them, and what do they do, and who do we become?\n",
    link: "/home/2020/04/28/long_music",
  },
  {
    title: "Two methods of producing butter, and two for sugar too",
    date: "18.04, Tuesday 5 May 2020",
    content:
      "Trying to learn why the particular brand we buy is so tasty, I learnt that there are two methods of making butter:\nThe one I knew about is churning cream. I remember doing this as a kid: we’d collect the cream from the top of milk bottles (incidentally, why does milk and cream no longer separate?) and when we had enough, whip it to make butter.\nIt turns out this is called sweet cream butter.\nThe other method is cultured cream butter where the cream is allowed to ferment, like yoghurt, and the sugars turn to lactic acid (a sour taste) and diacetyl (the butter-y taste). It’s then whipped to make butter.\nOne advantage of cultured butter is that it’s now preserved, so it doesn’t need to be salted like sweet cream butter.\nCultured butter, a.k.a. European butter, is the method used by the brand I like. (Salted) sweet cream butter only became the main butter in the UK due to imports after the Second World War.\nWho knew! Everyone apart from me probably. I thought butter was butter.\nSugar. Refined sugar can be made\n\nfrom sugar cane\nor sugar beet.\n\nI grew up in the UK with two sugar companies: Tate & Lyle, which is I now know is cane sugar. And British Sugar, which it turns out is beet. Globally cane sugar is dominant, but in Europe beet sugar has 80% of the market as beet can be grown domestically.\nCane sugar is of course intrinsically connected to colonialism and slavery, and credit to the Tate galleries for including this in their history:\n\n[It is] not possible to separate the Tate galleries from the history of colonial slavery from which in part they derive their existence.\n\nI mean, it’s not reparations for Empire, it’s a web page. Maybe in the future there will be a Tate Museum of Colonialism to at least begin to recognise and explore the history (and present) on which the UK and, in particular, London is built.\nBeet sugar. Years old, a management consultancy friend told me a story that is apparently legendary in, uh, management consultancy circles. The sugar market is insanely regulated: the quantity and prices of sugar beet to be purchased by British Sugar is set by regulation; the price and quantity of sugar sold is similarly fixed. Therefore profit is entirely dependent on operational efficiency.\nSo management consultants come in to do a bit of time-and-motion here, shave off a few seconds there, etc.\nUNTIL,\nONE DAY,\none heroic besuited management consultant realised a by-product of running the refinery was hot air, and this was currently being vented. What if, instead, it could be used to run greenhouses?\nAnd that’s how British Sugar became the largest producer of speciality salad tomatoes in the UK [pdf]. (Here’s a more readable article.)\nAnyway, I’m totally into this topic of commodities that have two methods of production, which are completely distinct but - to the consumer, like me - totally interchangeable.\nI mean, I’ve only got two so far and I don’t know of any others, but I’m keeping my eyes open.\n",
    link: "/home/2020/05/02/masks",
  },
  {
    title: "There is no After",
    date: "17.31, Wednesday 6 May 2020",
    content:
      "I like how Nat Buckley, in their weeknotes, casually refers to the Before and the After.  For example, According to my watch I burn slightly more calories than on most days in the Before.\nAnd it got me chatting on Twitter about what do we call the bit in the middle?\n\nThe Now, or the During\nThe quarantine\nThe lockdown (that’s what we call it, here at home)\n\nAnd keeping in mind that during this period, many people have and will still die, and many people are suffering. And it’s super fucking brutal.\nSo I don’t mean to brush over that reality, I want to acknowledge that it’s there, and that one of the characteristics of this period is the mental logjam of struggling with finding bread flour (for example) while also knowing that others are struggling in a much more significant sense.\nAnyway, I wondered what, in the future when we’re looking back, we’ll call the “and” between the Before and the After.\nPunctuated equilibrium\nBack in 2003 I asked: What do you call the bits between the equilibria in punctuated equilibrium?\n(Punctuated equilibrium is a model of evolution which says that a new species appears all in a rush and a muddle, but once it does appear it then becomes stable.)\nIn the course of collecting suggestions I started thinking about habit-breaking days… I have routines not just because I’m set in my way, but because everyone else is set in their ways too. Changing up routines is hard for that reason.\nBut when everyone changes up their routines around you, changing your own routines becomes easier.\nWhich led me to think that perhaps there are periods when we all change our habits together.\nLike now.\nOh yes, some of the suggestions:\n\nliminal (like, being halfway through a doorway)\nphase shifts\nlittle bangs\nthe punctuation\n\nSo I guess I’ve been thinking about these intermediate periods for some time, and that’s why I’ve been fixating on it recently.\nHabits in the Before and the After\nWe used to have a regular big shop at the supermarket, and also pop in frequently pick up ingredients etc to fill out a particular meal.\nNow we get our groceries from a small set of local shops do delivery. It’s a rewarding way to do be connected to our changed community. The supermarket is for whatever they don’t carry. Meals are planned around available ingredients. Food waste, which was always a concern, is now a priority… and almost zero. I hope that continues.\nI used to travel into town for meetings. I used to drink coffee on the train.\nI can’t see myself going back to travelling in the After. I’ve got back 2 hours a day and I won’t want to give that up.\nAnd for everything from how I hang out with friends and family, to how I win work, to how I make time for creative projects, there was what I did in the Before, and there’s what I anticipate doing in the After…\n…and there’s how I’m muddling along today.\nThe Before, the After, and the muddle?\nHow it feels\nKim Stanley Robinson, who writes incredible sci-fi utopias about Mars and future Californias and also post-climate-catastrophe Earth, had a piece in the New Yorker the other day: The Coronavirus Is Rewriting Our Imaginations.\nI mean, read the entire thing, but I wanted to quote this bit because KSR is some kind of word-smith magician and his sentences and rhythm are transcendent. I’ll give you the lead-in first, but maybe if you’re in a place where you can, speak the second para out loud because it really really works.\n\nMemento mori: remember that you must die. Older people are sometimes better at keeping this in mind than younger people. Still, we’re all prone to forgetting death. It never seems quite real until the end, and even then it’s hard to believe. The reality of death is another thing we know about but don’t feel.\n\n(This is the bit to read out loud. Give the words some room to breathe. Vary the speed and the sustain.)\n\nSo this epidemic brings with it a sense of panic: we’re all going to die, yes, always true, but now perhaps this month! That’s different. Sometimes, when hiking in the Sierra, my friends and I get caught in a lightning storm, and, completely exposed to it, we hurry over the rocky highlands, watching lightning bolts crack out of nowhere and connect nearby, thunder exploding less than a second later. That gets your attention: death, all too possible! But to have that feeling in your ordinary, daily life, at home, stretched out over weeks – that’s too strange to hold on to. You partly get used to it, but not entirely. This mixture of dread and apprehension and normality is the sensation of plague on the loose.\n\nSo good.\nAnyway, what KSR puts his finger on is a couple of things,\n\nthat this pandemic is the prototype for a century of crises: water shortages, food scares, a heat wave hot enough to kill anyone not in an air-conditioned space, etc,\nand that our shift into a new way of feeling about the world has now happened. We won’t and can’t return to our old habit of knowing-but-not-acting.\n\n\nPossibly, in a few months, we’ll return to some version of the old normal. But this spring won’t be forgotten. When later shocks strike global civilization, we’ll remember how we behaved this time, and how it worked. It’s not that the coronavirus is a dress rehearsal – it’s too deadly for that. But it is the first of many calamities that will likely unfold throughout this century. Now, when they come, we’ll be familiar with how they feel.\n\nFamiliar.\nWhen this is all over…\nI’ve been thinking a lot about the After…\n\nwhen I can go see cricket the cricket again (crowds)\nwhen I can browse the supermarket again (food security)\nwhen I can visit family (the risk of accidentally infecting older parents)\nwhen I can fly for holiday again (national borders as pandemic firebreaks)\n\nand thinking to myself, well, once we get through this…\nBut what KSR unlocked for me with that word familiar is that the feeling of the lockdown is now becoming familiar. Familiar means habitual. Habits don’t change, not without another crisis on the same scale.\nWe’ve got our childcare routine, and our way of working from home. Our masks have arrived, we know when to wash our hands.\nAnd what occurred to me, then, is that I’ve been thinking about this all wrong. There isn’t a Before, a lockdown, and an After. There’s only the Before, and the lockdown, and the lockdown will last forever.\nThere is no After\nYes there will be some loosening of restrictions. We’ll be able to return to school and work, at least for a bit until there’s a risk of a second peak and then the lockdown will tighten again for a while.\nWe’ll be able to visit parents, or go to events, but with masks, and maybe not in Covid season or something like that. We’ll carry immunity passports. We’ll have to pay attention to whether the cache of dried goods in the back of the cupboard is still in date, because we take food supply chains for granted any longer. The contact tracking apps will never be turned off, governments will say that it isn’t worth the risk, and we’ll all agree.\nNational borders will close periodically, like the Thames Barrier – you’ll never go on holiday or travel for work without thinking of the 1% chance that you’ll be stranded for the duration. It may never come, and let’s hope it doesn’t, but we’ll always be watching out for that second peak, it will always be a few months in the future, shaping our present.\nI think about 9/11, almost 20 years ago. That emergency never ended either. \nThe lockdown itself will reduce in intensity somewhat, but the instruments of the lockdown will stay, and the psychic lockdown - the feeling of all of this - will stay too. It will feel familiar.\nThere’s a bit in Blue Mars by Kim Stanley Robinson (him again) where the West Antarctic ice sheet collapses, and sea levels the world over rise dramatically.\n\n“How fast is it?” Nadia said. “Is it a tidal wave?”\n“No. More like a very high tide. That will never go away.”\n\nAnd that’s how I think about the lockdown now. A high tide that won’t go out. It’ll come and go, a bit, but really this period is just an extreme phase in what we’ll find is the new normal.\nAdjusting\nI’m coming to this realisation late, I know, others have been talking about the new normal for ages.\nIt’s helping me to think like this, because instead of waiting around - life on pause - thinking about how to pick things up when things return to how they were, or keeping my powder dry because things might be different again in the After, or saying oh I’ll do that later when thing have settled down, I can start adjusting right now instead.\nI can focus on finding new habits, and building my life and my practice in new ways. I’ll work on discovering new ways to make new routines easier, and joyful too, and as time goes on there will be opportunities to find new ways to enjoy family too, and even cricket somehow, but they won’t be the same as they were in the Before. And I’m going to start figuring these things out now, because there’s no point holding out to see what it’ll be like when this is over, because it won’t be over, there’s only the lockdown, the high tide isn’t going to go out, and there is no After.\n",
    link: "/home/2020/05/05/production_methods",
  },
  {
    title: "Public computing and two ideas for touchless interfaces",
    date: "12.40, Monday 11 May 2020",
    content:
      "Think about ATMs, or keypads on vending machines, or Amazon lockers, or supermarket self-checkout, or touchscreens on kiosks to buy train tickets. Now there’s a virus that spreads by touch, how do we redesign these shared interfaces?\n(This post prompted because I know two people who have separately been grappling with public computing recently. There must be something in the air. These are two ideas I came up with in those conversations.)\nIdea #1. QR codes, augmented reality, and the unreal real\nThe obvious approach is to move the control surface to a smartphone app, just like the Zipcar app lets me unlock my rental or sound the horn. But as an answer, it’s pretty thin… how does a person discover the smartphone app is there to be used? How do you ensure, in a natural fashion, that only the person actively “using” the ticket machine or locker is using the app, and everyone else has to wait their turn? A good approach would deal with these interaction design concerns too. \nSo, imagine your train ticket machine. Because of the printer, it’s a modal device: although it’s public, only one person can use it at a time.\nLet’s get rid of the touchscreen and replace it with a big QR code.\nScan this code with your smartphone camera, and the QR code is magically replaced - in the camera view - with an interactive, 3D, augmented reality model of what the physical interface would be: menu options, a numeric keypad, and so on.\nThere’s something that tickles me about the physicality of the interface only visible through the smartphone camera viewfinder.\nHow does it work? An exercise for the reader… the iPhone can launch a website directly from a QR code seen in the camera view. So perhaps that website includes a webcam view which can add the augmented reality interface? Or perhaps it triggers an app download which similarly includes the camera view? (Android has the ability to run mini Instant Apps direct from the store; there are rumours about iOS doing the same.)\nThe point is to make the transition from the QR code to the AR interface as invisible and immediate as possible. No intermediate steps or confirmations or changes in metaphor: it should feel like your phone is a little window that you’re reaching through to work with the computer, like using a scientific glovebox in a chemistry laboratory, and you’re just moving it into position.\nThe bonus here is that the interface can only be used while the user is standing directly in front of it, so the “one person at a time” nature of the machine is communicated through natural physicality. I don’t think you get that with apps; an app tethered to a place would feel wrong.\nIdea #2. Gestures for no-touch touchscreens\nThe starting point here is a kiosk with a touchscreen.\nObviously we don’t want the touchscreen to be touched by the general public with their filthy, virus-infested fingers. So, instead, use a tablet with a camera in it, but the screen of the tablet is not intended to be touched. The camera instead recognises hand gestures such as\n\npoint at screen left/right/up/down (to select)\nbrush left/right (to browse or dismiss)\nfist (hold for 5 seconds to confirm)\ncount with fingers from 1 to 5 (more sophisticated, for input)\n\nThe inspiration is this gorgeous Rock Paper Scissors browser game that uses machine learning and the webcam. That is, the web browser activates your webcam, and you make a fist (rock), flat hand (paper), or scissors gesture, and the A.I. which is also running in the web browser recognises it, and then the computer makes its move. All without hitting the server.\nCheck out the live graph in the background of that site. It provides a view of the classifier internals - how confident the machine is in recognising your gesture.\nWhat this tells me is that all of this can be done with a web browser and a tablet with a camera in it. For robustness, stick the tablet inside the shop window, looking out through the glass. Set the web browser to show the live feed from the webcam, providing discoverability: people will see the moving image, understand it as a mirror, and experiment with gestures.\nIt would be like a touchscreen with very large buttons, only you wave at it to interact.\nLook, the Minority Report gestural interface is cool but dumb because your arms get knackered in like 30 seconds. But just using your hands or fingers? I could live with a future where we do tiny techno dancing at our devices to interact with them.\nWhatever the approaches, the important considerations for public computing interfaces would seem to be:\n\nDiscoverability (how do you know the interface is there? Public computing has a ton of first-time users)\nPrivacy/security (think of using an ATM on a public street)\nFamiliarity (like, weird is fun, but not too weird…)\nAccessibility\nViability\n\nOn accessibility, I’m into Microsoft’s Inclusive Design approach - to see it summarised in a single graphic, scroll to the permanent/temporary/situation diagram here: accommodations might be required for visual impairments, but a person with a cataract has temporary blindness; a distracted driver has situational blindness. For me, understanding situational accessibility (like, having my arms full of shopping or a wriggling toddler so I can’t press a touchscreen) really made me start thinking about accessibility in a much broader way.\nViability is about the commercial and physical reality of public computing interfaces: can it withstand being used 100s of times daily, is it reliable in the rain, is it cheap, etc.\nBUT, LIKE, ALSO:\nTouchscreens with cameras, web browsers with computer vision, broadly deployed smartphones, augmented reality, voice: these technologies weren’t around when the last generation of public computing interfaces was being invented. It might be worth experimenting to see what else can be done?\n",
    link: "/home/2020/05/06/lockdown",
  },
  {
    title: "How about hyperlocal pandemic forecasting",
    date: "19.39, Tuesday 12 May 2020",
    content:
      "I’m a big fan of weather forecasts. It’s an incredible feat to describe the ever-changing multi-variable fluid-dynamical state of the freaking atmosphere in such simple terms that we can\n\nact – imagine how insanely complex it must be just to say “it’s going to rain today,” yet the entire forecast can be summarised in that line and I know whether to wear a coat.\ncommunicate – I can hear or read a weather forecast and share it with another person, using speech only, face to face or just over the phone. I can’t even figure out how to share a URL to a Facebook post half the time.\nreason – seeing a warm front on a map lets me predict for myself the next 24 hours, despite me having no idea about the actual numbers in the underlying atmospherics equations.\n\nAmazing.\nI’ve just been looking at some stats. Next day forecasts are 80% accurate, up from 66% a decade ago. The UK Met Office’s 4 day forecast today is as accurate as the 1 day in 1980.\nBarometers: especially good. With their dial running stormy/rain/change/fair/etc. See some antique ones here. It’s everything you need to know in a single instrument: e.g. it was originally raining and it is improving quickly. A vector not a point. Well done barometers!\nSometimes I wish I had a weather app that did the same. Open it, and the screen would just say “wear the same as you wore yesterday,” or maybe also wetter/drier/windier.\nThe app Dark Sky comes closest to that magical feeling, although in a different way: its hyperlocal, to-the-minute forecasts aren’t always accurate, but when it says “rain stopping in 12 minutes” and then, in 12 minutes, the SKIES CLEAR and you can go outside without bothering to take a hat… it’s a superpower.\nI read recently that weather forecasts are suffering because flights have been cancelled, and aircraft are responsible for a large amount of the data that goes to feed the simulations:\n\nThe European Centre for Medium-Range Weather Forecasts reports a 80% drop in meteorological readings due to cancellations of commercial flights. According to their study, removing all aircraft data from weather models reduces accuracy by 15%.\n\n(You might guess that I took the atmospherics module at uni, and meteorology was my favourite part of geography at school.)\nANYWAY SO HERE’S MY QUESTION:\nHow about hyperlocal, to-the-minute pandemic forecasts?\nThe UK govt announced its COVID Alert Levels which run from 1-5. Here they are [pdf]. e.g.:\n\nLevel 2: COVID-19 is present in the UK, but the number of cases and transmission is low\nLevel 4:  A COVID-19 epidemic is in general circulation; transmission is high or rising exponentially\n\nLike a barometer, the level takes into account situation and direction of change and rate of change.\nThe government also released an equation which has been roundly mocked. Here it is:\n\nCOVID Alert Level = Rate of infection + Number of infections\n\nWhich is… fine? I don’t get the mocking. I mean, it communicates exactly the right information. The alert level goes up if either of the other two numbers go up. What were they supposed to write? It’s impressive wordsmithing to convey that entire mental model so concisely.\nBut what caught my attention was that if the alert level rises, the lockdown would be once again tightened… and they said this could happen locally.\nWHICH LED ME TO THINK:\nWhat would it mean to have a giant pandemic simulation running on those impressive Met Office computers?\nAND FURTHERMORE:\nCould this pandemic mirror world be used for forecasting?\nHow many million data points would it need to be fed to forecast\n\nhow many contagious infections there are in a particular neighbourhood, at a particular time,\nthe effective rate of infection, given crowd levels etc, and whether crowds are likely to form because of the weather and so on,\nhow to compare levels of exposure, just for you, given your route.\n\nWhat sensors would be required to feed such a simulation?\nHow fine could the resolution become?\nCould some kind of future Dark Sky meets Citymapper meets contact tracing app say things like…\n“well you’re near London Bridge and the general number of infections is low, but there’s been an infection wavefront moving up slowly from the south plus, huh, Tuesday morning it usually gets kinda busy, so between 8-10am in that area we’re forecasting a COVID Alert Level of 4.3.\n“BUT the surrounding neighbourhood we’re looking at a local alert level of 3.6 and falling,\n“AND SO,\n“if you get off the train one stop early and walk the rest of the way to work, sure you’ll be out in public for 30 minutes longer, but your exposure overall will still be lower, so that’s your recommended route this morning.”\n???\nCommunicating this might end up looking a bit like rads, the unit of absorbed radiation dose.\nMaybe your phone could track your location and give you a live exposure number over the day, like a badge? It’s 2pm and you’re at 40 co-rads today. We recommend you leave before rush hour and take this 20 co-rad route home, also WASH YOUR HANDS.\n",
    link: "/home/2020/05/11/public_computing",
  },
  {
    title: "Rethinking conference talks for video calls",
    date: "19.27, Friday 15 May 2020",
    content:
      "I’ve done two Zoom talks this week. I love public speaking and I aspire to be at least “not shit” in this new medium. So, some work in progress thoughts…\nAs the speaker, I need to see faces\nDonkeys years ago Danny O’Brien said to me that the purpose of asking cheesy audience-participation questions like raise your hand if you’ve ever etc is not to connect with the audience…\nSometimes, when I’m doing a talk, I start to disconnect – it’s like I can suddenly hear my own voice. I lose my mental overview and ramble into the weeds. At worst, I freeze completely (that’s happened once). It’s at that moment that I remember Danny saying that speaking on a stage, just talking without anybody to speak with, is psychologically weird and unnatural, and you need a way to kid yourself it’s a normal conversation. So that’s when to ask the audience a question, which I then do, and it’s enough to fool my brain so we get back on track.\nOk so Zoom is terrible for this.\nBecause everyone’s on mute, there’s not even the feedback of ambient noise.\nSo, at a minimum, I think audience cameras should stay switched on. I want to see people’s faces – ideally in gallery view (that grid of thumbnails).\nThere’s a risk that someone will look distracted, and that’s off-putting, but I regard that as a separate problem. See below.\nHow about designing slides for thumbnail view?\nIn real life talks, audience attention bounces between the speaker and the slides. In a way, there are two characters on stage. You can play games with that.\nOne gag I’ve used a few times builds up over 6 slides, and I bring up each slide and read out the words, training the audience to look at the text. Then on the last slide, which is funny because it undermines me slightly, I don’t say anything, but by habit everyone reads the punchline and encounters the gag for themselves. That makes it funnier. \nSo you can deliberately push attention around. You can turn around and face the slides, directing attention towards them and and placing yourself with the audience. You can use a series of visually complex slides, followed by a very plain one, which suddenly leaves all that captures attention with nothing to alight on except you and your next statement, and it works like a spotlight. It can be very effective.\nBUT, generally speaking, audience members look sometimes at the speaker and sometimes at the slides, and they’re entirely in charge of how and when they do that, and it’s a really good mechanism to avoid getting bored.\nAnd they can’t do this on Zoom.\nThe problem with Zoom and screen sharing is that the slides take up the whole damn view and you, the speaker, get relegated to a thumbnail. (On other platforms it’s worse: you see the slides, and the speaker becomes a disembodied voice.)\nThe slide dominates the speaker. So\n\neither the slide is information-rich, in which case a listener will look at the slide and ignore the speaker,\nor the slide is basic (for example, a single clear statement) in which case it still grabs their attention, because it’s massive, but the listener has to stare at something boring while you make the real point.\n\nFor me, the best approach would be no screen sharing.\nHere’s what I want to try:\nThe slides and speaker should appear in separate thumbnails. Audience members should be encouraged to click at will between the two, sometimes looking at one, and sometimes the other. Their choice.\nUnfortunately I can’t figure out how to do this – as far as I can tell, screen sharing on Zoom will cause the slides to always occupy the full screen view for all call participants. Thoughts welcome.\nSlides for orientation\nI’m accustomed to using slides for pace and rhythm. Sure, individual slides can be for information, illustration, a counterpoint, to provide a section break, and so on. But with a sequence of slides, that’s how you control pace.\nA talk needs slow expansive sections plus also rapid-fire bits to rattle through – the variety of pace keeps it interesting!\nFor some reason, this doesn’t work on Zoom. Maybe because, in the end, a computer screen is pretty small compared to the room the viewer is sitting in? So a sequence of slides doesn’t have enough impact to effectively set pace?\nActually it’s almost like there’s no pace at all. I feel like online talks have a kind of timelessness. The speaker drones on, the slides tick over, when will it all end…\nSo I’m trying to figure out ways where each slide can communicate where we are in the talk, at a glance.\nPerhaps, if a talk were to have three sections, each section is given a different background colour? Headers and footers aren’t visible when you’re designing for thumbnail view. \nMassive numbers maybe? One talk I did this week was organised around 8 tips (numbered), and two breaks which I announced at the beginning. This structure was given at the head of the talk. Each break had a suggested topic to think about, and then I took general questions from the text chat before resuming. (Of course these are also opportunities for people to check their email, which relieves some of that distracting tension.)\nI think there might be something in this approach.\nBackground matters less than lighting and position\nCamera at eye level. Nobody wants to look up my nose.\nClose but not too close. The ideal distance is so that the top of my head is sometimes cropped out (if I’m leaning in), but my hand gestures should always be visible (hands at belly height and up).\nI use two light sources: room lighting for overall brightness, and a bright lamp on one side (not pointed directly at me) to provide texture and shadow across my face. I’ve done calls where there’s a light source like a window behind me. Never again.\nMy background is neutral grey. For calls it doesn’t have to be, background is character, like choosing what top you wear (though your face should always be better lit than the background, to draw focus). But for talks, I think it’s important to stand out, and that means a plain background.\nAn opportunity to re-think how talks work\nI like talks. I like hearing engaging speakers, and I like talks dense with ideas – whether these are unique and hard-won insights, or weird anecdotes.\nI’ve seen some speakers who can hold my attention and the whole audience with no slides at all. I love it. I’m unable do speeches myself, but I love a good one.\nMy favourite talks are the ones that last 45+ minutes, especially the ones where the speaker has notes. There’s room to travel along with the speaker to somewhere new. 45 minutes is enough to build new perspectives.\nWhen TED came along, and TEDx, suddenly all talks everywhere had to be 18 minutes long. I don’t like 18 minute talks. There’s only room for one idea. Especially because the speaker is denied notes.\nI like live talks. I don’t get along with recorded talks – I don’t find them fun to watch, and I don’t like the idea of recording without an audience. I want to see the whites of their eyes. Mind you, I don’t really get on with TV or YouTube either, so perhaps it’s just me.\nAnyway.\nI find the idea of Zoom talks fascinating. What does it means to do something\n\nwhich is live\nwhere everyone in the audience is potentially multitasking\nthat includes a text chat backchannel which is visible to everyone?\n\nCould talks get longer again, because tuning in isn’t such a commitment – the audience can be present but also checking their email?\nBut with new elements, and new approaches to structure, and new approaches to performance and interactivity?\nNo idea. Working on it.\n",
    link: "/home/2020/05/12/pandemic_mirror_worlds",
  },
  {
    title: "Gross National Diversity",
    date: "19.30, Tuesday 19 May 2020",
    content:
      "There’s a spot in the forest near where I grew up which is a clearing in the woods. There’s no undergrowth. No bracken. The ground is flat and made up of grass, like a lawn. It feels inhabited but empty. Haunted.\nMy mum knew a guy who was an old forester, and he told her about this clearing. It’s a clear, flat lawn because travellers lived there for years and years. The travellers were farm workers, and they made their seasonal home there.\nFrom what I understand, these were English travellers, not Irish travellers or Romany travellers. Is/was there a separate group of English travellers? To my shame, these aren’t communities I know.\nThen came the 1980s. This is how I heard the story: Thatcher had something against the travellers. There was a big push on primary school education. It was mandatory, and you had to register for one school, and to be able to register you had to have a fixed dwelling. And so the travellers were re-homed into local houses and were travellers no more.\nThere’s a new government Pick for Britain campaign to recruit agriculture workers: normally workers from countries like Romania and Bulgaria come to help the harvest, but only around a third of them are here. (The website itself crashed about a minute after being announced.)\nReplacing fruit and veg pickers with new workers is unlikely to be easy. It’s not just long hours and acquired skills (I couldn’t eyeball two apples and say with certainty which to pick and which to leave), it’s also lifestyle:\n\nThese jobs simply wouldn’t work for many people. They’re located in specific regions, generally far from major towns and transport links. For those who don’t drive or live in those areas, that means finding accommodation. Some farms provide this for seasonal workers … It’s also not free, so people already paying rent or a mortgage on their home would be paying twice.\n\nWhat could go wrong? Not enough workers, fruit and veg not picked, lack of food on shop shelves.\nSo in losing the travellers in the 1980s, it feels like our society has lost resilience.\nI think often of archetype/stereotype characters in a kind of imagined, pre-industrial, pastoral England.\nThe blacksmith. Taciturn. Each rare word carrying meaning and weight, like each strike of hammer on the iron goes where it means to go. Is it the mind that is attracted to the material, or the material that makes the mind?\nThe gossiping baker. Well, at the centre of the village, gatekeeping the communal oven, why wouldn’t they be?\nThe shepherd. Not speaking, or at least not in human language, for days on end.\nThe wise old woman – the witch. Why not? I know a physical therapist whose skills and approach are so far beyond anything else I’ve encountered that it only makes sense to understand her as a witch.\nThe monk.\nI think today we’d call most of these neuroatypical. Maybe not the baker.\nBut they weren’t atypical anything before. They were part of the mix.\nImagine we’d lost, somehow, the shepherds and the monks. Could the explosion of technology and coding from the 1960s-2000s have happened? I don’t think so. Deep code requires a peculiar mental stance. And by “lost” I mean made invisible somehow: disenfranchised; made poor; removed from opportunity.\nThere are terms around like energy security or food security.\nBut I wonder about neurodiversity resilience – the pool of people who are potentially especially adapted to a new vital skill. Three minutes in a virtual reality headset has left me on the floor in a cold sweat and sick to my stomach for five times as long. Imagine the future economy requires VR. Do we have a community immune to motion sickness and able to speak quaternions as their native tongue? I’ve got a cousin who can see 3D like I can’t even imagine.\nAnd lifestyle resilience. We suddenly need travelling workers for farms. If not for picking fruit and veg, then for pick and pack in Amazon warehouses. Do we have a nomadic community who knows how to travel successfully, a community which is keeping these habits and this knowledge alive, people we can learn from? What is the next lifestyle we’ll need to radically adopt and expand?\nCould there be, like Bhutan’s famous Gross National Happiness, a measure like Gross National Diversity, some kind of number to quantify - and defend - the pool of cultural and neurological difference and depth that, in strange times, we can draw for our resilience and our strength?\n",
    link: "/home/2020/05/15/video_talks",
  },
  {
    title: "Rambling thoughts about cyborgs and emotions",
    date: "20.00, Wednesday 20 May 2020",
    content:
      "Hey so here’s the paper Cyborgs and Space (1960) by Clynes and Kline in which the word cyborg was first introduced. It’s short. Here’s the first line:\n\nSpace travel challenges mankind not only technologically but also spiritually, in that it invites man to take an active part in his own biological evolution.\n\nOur geological era, the Anthropocene, in which human activity is the dominant agent of change in our ecosystems, is pretty fraught. That line makes me wonder… what if we attempted to find the spiritual crisis in the climate crisis? In that there are questions about morality, the afterlife (well, in a way… what happens to others after we die), a reconceptualising of the Prime Mover, shame and guilt and all the rest; sin and punishment all suddenly up in the air, a new Great Flood. Any theologians, please get in touch…\nAnyway, the paper is about adapting to new environments - such as space - and here’s the line where “cyborg” is introduced:\n\nFor the exogenously extended organizational complex functioning as an integrated homeostatic system unconsciously, we propose the term “Cyborg.” The Cyborg deliberately incorporates exogenous components extending the self-regulatory control function of the organism in order to adapt it to new environments.\n\nWhich - continuing the earlier thought - makes me realise that we are in a new environment now, a climate-changed, pandemic-swept one, and to adapt, we will become cyborgs - with our facemasks and our air conditioning, now as vital to our bodies as our hair and our sweat glands - and the new environment isn’t space, but is right here.\nANYWAY. Not my point.\nALSO NOT MY POINT,\nBut:\nI found that “Cyborgs and Space” paper strangely residing on a NY Times server. And it appears to be connected to this column, The Cyborg as Warp-Speed Evolution from 1997 by Ashley Dunn, which follows the evolution of the term, Clynes continued to develop the concept of the cyborg, coming up with a Cyborg II, III, IV and V.\n\nCyborg II involved the manipulation of human emotions through a series of mental exercises. III involved genetic alterations to enhance the human emotional range, while IV involved deeper genetic changes and V brought the separation of mind from body.\n\nSo then I found another column by Ashley Dunn called In a Cyborg World, Gender Boundaries Fall about Donna Harroway’s Cyborg Manifesto – and my point in this tangent WHICH IS ALREADY TOO LONG, SORRY is not about Harroway either, but this:\nHere are Ashley Dunn’s other columns in the NY Times from 1997 and it is AMAZING.\nWhy don’t we have technology columns in national newspapers today that veer between finding a replacement for AOL, to the nature of liberty, to webcams, to cyborgs??\nWho the hell is this Ashley Dunn and how do I subscribe to their newsletter 23 years after the fact?\nSo I was leafing through The Cyborg Handbook (1995, edited by Chris Hables Grey) which is a collection of essays etc, and there’s an interview with Clynes in there, and this caught my eye about emotions, and Clynes is talking about pleasure emotions here, which he says are multi-dimensional, humans having many many different types of satisfaction. The pleasure of feeling in love is not commensurate with that of a hot bath.\nSo he alights on reverence first: There is no reason in the world why cyborg can’t feel reverence as much as any other human.\nBut then he gets onto new emotions, and the interviewer asks:\n\nI was struck that in several places your book talks about a new kind of laughter you sort of discovered.\n\n(Clynes actually replies that you can’t invent new emotions without radical change in molecular biology.)\nBut it’s a galvanising sort of idea isn’t it.\nLike, what’s the kind of laughter you get when you watch that amazing 25 minute Sudoku video (thank you Jason Kottke for sharing this), that vicarious, rapid cascade of aha! aha! aha!\nAnd what’s the emotion that a machine learning function feels while it’s exploring the latent space of landscape paintings?\nThinking about an emotion which can maybe be generally defined as a tropism towards certain categories of results, a choice of search algorithm/reward function, a modifier on how learning is done from this experience, a heuristic learned from experience too, and a bias on resource allocation… I wonder whether we can identify clusters of these alternate strategies used by bacteria, viruses, and computer programs, and call these emotions?\nAnd if we, as individual humans, were to make different choices on those axes because of exposure to more-than-human input, would those be new emotions too?\nWhatever. Reading a book, made me think, posted it on my blog, didn’t edit. See you later.\n",
    link: "/home/2020/05/19/resiliance",
  },
  {
    title: "A month long conference is a neat concept",
    date: "14.35, Sunday 24 May 2020",
    content:
      "As a follow-up to last week’s post Rethinking conference talks for video calls, here are a couple of ideas that caught my eye.\nWaving, fast and slow\nNeuroscientist Daniel Glaser is getting his audience to wave:\n\nask a question and then get them to wave fast for ‘yes’ and slow for ‘no’\n\nThis is very clever:\n\nI had the call set for gallery view and was immediately faced with a matrix of waving hands. I could tell straight off that more or less everyone was responding. More pleasingly I could also see without counting that around three quarters were waving fast for ‘yes’. The proportion of fast and slow waving produces a moving texture. Your visual system processes the whole image without your having to search it or count out and you can read out the collective answer straight away.\n\nI talked in the post linked at the top about the important of audience participation – for my own well-being more than anything else. So I’m going to nick this.\nLong conferences, and embracing the backchannel\nWeb Directions has long been in my list of favourite events, so it’s no surprise to see co-founder John Allsopp make a thoughtful post about the underlying purpose of conferences – and then re-invent the format for their next events.\nPresentations will be pre-recorded. Honestly this wouldn’t appeal to me, except that…\n\nMeanwhile speakers can even interact with the audience, or add more value to their presentation, while it is actually taking place – perhaps clarifying a point in response to a (text based) question, providing links for further reading, and so on.\n\nAnd that’s an intriguing idea, the speaker being in two places at one, simultaneously on stage, and also glossing and feeding the conversation. We’re multi-tasking animals, so embrace that. I love this.\nThey’re moving on from the standard two day conference format. Get this:\n\nInstead of expecting people to take two whole days out of their most likely much more unsettled than normal schedule and spend yet another 12 hours staring at the screen over consecutive days, our online conference program will take place weekly, across a whole month, with sessions approximately 3 and a half hours each week on a Friday.\n\nBack in 2015, I wrote about the best event I ever attended which ran across three successive Fridays in 2004. Each started at 2.30pm and ran the rest of the day.\nWhat I found was that\n\nThere was something about the weekly rhythm which meant that there was time for me to digest each download of new thoughts. The session stayed with me for the week. … A week is time to discuss with friends, contemplate, see the deeper patterns.\n\nSo I’ll be watching Web Direction’s experiences with long conferences with interest. I think they’re onto something.\n",
    link: "/home/2020/05/20/cyborgs_and_emotions",
  },
  {
    title: "How I would put voice control in everything",
    date: "20.18, Tuesday 26 May 2020",
    content:
      "Why can’t I point at a lamp and say “on”“ and the light come on? Or point at my stove and say “5 minutes”? Or just look at it and talk, if my hands are full.\nI speculated about voice-controlled lightbulbs and embedded machine learning on stage last year at Google’s People & AI Research symposium (there’s a link to a video on that page) and was reminded about it the other day when George Buckenham tweeted as someone who already owns an Alexa, I would buy a device that doesn’t do any cloud processing, but does allow you to set kitchen timers with your voice and play songs from Spotify – which is basically all I do with Siri too, and this is kinda what I want too…\n…only not a single device, I want voice control in everything, but individually. And really, really basic.\nBecause it is really appealing to me to turn on a light, set the stove timer, play music, pause the TV, snooze an alarm etc just by saying something. What’s not cool is\n\nhaving a device in my home that harvests every sound in the house and sends it to cloud servers for eternal recording, or not, who knows and that’s the point – an audio panopticon dressed in plastic\nneeding to remember arcane vocal syntaxes\nlatency.\n\nAnd all of that aside, voice assistants are still all more or less rubbish.\nSo how should this work?\nDo less. Do it really well. Reduce cognitive friction.\nMake a lightbulb that you can say “on” and “off” to:\nI was struck to learn that the iPhone’s “Hey Siri” feature (that readies it to accept a voice instruction, even when the screen is turned off) is a personalised neural network that runs on the motion coprocessor. The motion coprocessor is the tiny, always-on chip that is mainly responsible for movement detection, i.e. step counting.\nIf that chip hears you say “Hey Siri”, without hitting the cloud, it then wakes up the main processor and sends the rest of what you say up to the cloud. This is from 2017 by the way, ancient history.\nSo, commodity components time: here’s the BelaSigna R281, an ultra-low-power (300 micro watts, mic not included) chip that is “always listening” and will detect a single, user-trained trigger phrase, asserting a wake-up signal when this trigger phrase is detected.\nA embeddable wake-word detector! Let’s stick it in a lightbulb! A radio! A desk fan!\nSo how would a device with this simple word detector know when to pay attention? Some wild speculation…\n\nan on-chip, low power image sensor – a MEMS camera maybe? With the added ability to…\ndetect glances – detecting the whites of our eyes in a busy image by limited compute is basically what the whites of our eyes are there for\ndetect pointing – harder, but (waves hands) machine learning??\n\n(Bonus points: do all of this with energy harvesting, so no batteries, and zero power on standby.)\nLook, my point is that this is not beyond the reach of very clever people with computers. Stick a timer in my stove, a switch in my light bulb, give each a super limited vocabulary, never connect to the internet, and only act when somebody is addressing you.\nWhich, in turn, gets rid of the complicated set-up and addressing interaction design issues of centralised voice assistants. No more “front room lights: lamp 1 turn on” because… you just look at it.\nAnd also gets rid of the need to add expensive connectivity (and set-up, and security patches…) in every stove and light, and the need to convince every manufacturer to support the latest control protocol because… you just look at it.\nAnd, ALSO also, by simplifying but spatialising the available grammar, the voice interface will be easier to learn, more reliable to use, and easier for normal humans to combine.\nAnd yes, given this leeway, different manufacturers will go in slightly different directions. But net-net I bet that the overall simplicity is improved versus the current approach of attempting to make standardised interfaces for classes of products that have to be tweaked case by case to properly fit.\nIt’s a classic worse is better approach.\nWhy are we stuck with portals for voice?\nAnd the reason it doesn’t work like that already, and why we’re stuck with dedicated, centralised voice assistants that need to bounce a signal off a data centre on the freaking Moon (not actually the Moon) to set a timer? Well, I can imagine a few possibilities…\n\nCynically: every big tech company wants to “own” voice interactions, and be a gatekeeper to all smart devices for STRATEGIC REASONS, which is daft because trying to own an entire interaction model like that is like saying “ok let’s own buttons”.\nDealing with voice is sufficiently complex that you need giant cloud servers to do it, and the code requires such frequent updating that device-embedded detection doesn’t make sense. I’m not sure this is the case any longer, and besides, that’s what over-the-air Bluetooth updates are for.\nCentralised voice assistants allow for more complex use cases, such as orchestrating different devices, and interacting with cloud services. Such as: if the traffic is heavy this morning, turn on the lights 20 minutes earlier.\n\nI think that last point is probably what’s going on. I get it.\nBUT\nThere’s that line from John Gall:  A complex system that works is invariably found to have evolved from a simple system that worked.\nSo let’s get the basics right first, then layer orchestration and all the advanced stuff etc on top?\nHere’s the boil-the-ocean approach\nIf I had all the VC money in the world, I would manufacture and sell standardised components – they would connect and act identically to mechanical buttons, switches, and dials, only they would work using embedded ML and have voice, gaze, and pointing detection, for interaction at a distance.\nThe goal would be to allow manufacturers of every product to upgrade their physical interfaces (add not replace ideally), no matter how trivial or industrial, no matter how cheap or premium. And, by doing that, discover what new possibilities are uncovered when when you don’t force every voice interaction through a single model, that of requiring an internet-connected, consumer-friendly, device for the home.\nAnyway.\n",
    link: "/home/2020/05/24/a_month_long_conference",
  },
  {
    title: "Grocery shopping, localism, and last mile delivery",
    date: "19.55, Thursday 28 May 2020",
    content:
      "I wanted to scribble some notes about grocery shopping because how we’re doing in, in our home, has changed a bunch over the 10 weeks of lockdown, and I want to remember this.\nPREVIOUSLY how it worked:\n\nonline supermarket deliveries\nfortnightly supermarket small shops\nweekend visits to butcher/fishmonger/cheese shop/other specialists to particular meals\nsupplemented by frequent visits to the local small supermarket for dinner ingredients, milk, etc\n\nNOW it looks like\n\nfruit/veg box from a company based in New Covent Garden market that used to supply restaurants, and has now started home deliveries. No choice other than size and very seasonal, obviously. Optional extras include salami, courgette flowers, etc\nmonthly meat box from the local butcher (who is excellent), mostly for freezing\noccasional fish delivery from the local fishmonger (who is also excellent), mostly for freezing\nmonthly online supermarket orders for brand items, canned/dried goods, and cleaning items\nmilk/dairy - we’ve signed up for a twice-weekly milk delivery in returnable glass bottles\nflour from one of the two local cafes/bakeries which have pivoted to selling re-bagged wholesale flour\n\nWe have a month planner whiteboard magnetically attached to the fridge. We use it to plan childcare, and it also shows the use-by dates of everything in the fridge.\nThis style of shopping suits me very well. This is what we should have been doing, always.\nIncidentally the layout of these ex-cafes, now local flour depots, is worth recording.\nIt’s one in, one out with a socially distanced queue outside. Inside, the old cafe space is half available goods, and half stockroom. Goods include bread, pasta, granola, that kind of thing, plus re-bagged flour. You stack your goods on a table in-front of the till, and pay contactless using the card machine which is also placed on that table.\nThis is great for us: there’s a new local website called Dulwich Delivers which simply lists local businesses that deliver. Aside from that, we mostly find out about places from friends on WhatsApp, or by checking out favourite spots on social media to find out if they’re active.\nThe cafe I mentioned where we get our flour posts their price list and availability as a photo on their Facebook page. They take orders for delivery by Messenger, then call you up to take your credit card details.\nThe local toyshop delivers, and the person who does the deliveries is the proprietor, on her bike.\nFor us, a lot of this has happened by necessity.\nWe don’t have (or want) a car.\nOnline supermarket delivery slots were barely available to us for the first month or two of the lockdown. The slots we did manage to get, we mainly used to set up deliveries to our parents. So we had to find other sources of groceries.\nWhat’s fascinating to me is when I think about the e-commerce stack, loosely:\n\ndiscovery\nstore operations\nfulfilment, i.e pick, pack, delivery\n\nThese are the three big challenges that any only shop needs to find an answer to, either by doing it themselves, using software, or partnering.\nAmazon’s big play is discovery - they have all the buyers in one place, so if you’re a seller, that’s where you go to. Then they handle the store operations and delivery for you.\nOr then there’s Shopify, which is really challenging Amazon now. Primarily they provide store operations. Their realisation was that shops can handle their own discovery, on Facebook or otherwise. After all, stores have been doing marketing and customer relationship longer than e-commerce has been around.\nNow Facebook has launched Facebook Shops, which looks after discovery and a little bit of store operations, partnering with Shopify for the rest. Ben Thompson (Stratechery) calls this the Anti-Amazon Alliance.\nBUT WHAT’S MISSING HERE is local delivery. Last mile delivery. Facebook Shops/Shopify is fine… but it doesn’t do anything for my local butcher with their meat box. Amazon is fine, but it’s optimised for centralised warehouses, not local.\nThis matters because, when I think about how “discovery” has worked for us, Facebook or no, it has been local first. I always say, word of mouth is unreasonably effective. And word of mouth works best when it’s local.\nSo “discovery” works locally but “delivery” doesn’t. Hm. Hm.\nA few weeks ago I posted about hyperlocal, distributed supply chains, and that got me into a really interesting Twitter DM conversation with Karl from Bloop, a zero-waste store in Bristol.\nThey’ve been going for a few months, and are well-known by the local community - and (quoting from our chat) We didn’t intend to do things online, but the viral outbreak forced us into that, so now we’re a delivery company too. The website is an attractive, modern, e-commerce experience. \nAnd I find that really intriguing. What if e-commerce, but only for a 1 mile radius?\nKarl shared a few more details. They live above the shop, and he also runs Obelisk which is an audio design agency. Karl has made all his own furniture for the store and it’s all on castor wheels so the space can be easily reconfigured.\n(I wrote recently about homes can also be businesses so you can see why this appeals.)\nAlso quoting Karl: What comes with having a shop like this is a golden ticket into community - which is amazing, right? You can see the effect you’re having, identify that delivery is a need, spread the word, and come face to face with users (customers!) every day.\nSo when I think about local delivery, this is where the rubber hits the road for all of this e-commerce stuff. Because it’s necessarily physical, it’s the sole opportunity to be face to face. But delivery, when commoditised and industrialised, also seems to be where things go badly wrong, from delivery drivers bearing the risk of whole corporations to food delivery “independent contractors” barely able to make minimum wage, and being stiffed for tips.\nThe big question:\nCorporations and startups will inevitably move hard into the last mile delivery space. How do we make sure it’s not shit?\nIt’s going be…\n\nBoston Dynamics robot dogs delivering parcels\nSome kind of unholy FedEx-goes-local or white label Uber Eats, making people sweat to earn less than minimum wage\nor… something else? What it is? What would Karl do?\n\nI can imagine a utopian neighbourhood of cheery teenagers on their bikes earning pocket money by delivering my veg box and fancy cheese ordered via Facebook Messenger, and me tipping an extra shilling because I recognise them from last week. But this isn’t 1955 plus social media.\nSo what is it? How do we make sure it isn’t awful?\nI find it hard to imagine utopias, because I’m in the habit of imagining critiques or dystopias or semi-plausible extrapolations of the present. A utopia is a non-extrapolation; it implies some intervention. Politics. I’m not very good at imagining politics.\nScience fiction is pretty good at dystopias, it’s not in the habit of utopias either, any longer. And design fiction is good at depicting futures, but design is (inherently, and rightly) commercial, so design fiction’s futures aren’t about utopias but about desire.\nI think we need to - I need to - imagine utopias again, and we need to articulate them in great detail, and illustrate everyday situations like this, and we need to demand and create demand for them, because if we don’t then the clearest narrative wins, and currently the clearest narrative is race-to-the-bottom capitalism in the guise of opportunity-for-all.\nI’ve had a taste of collectivism and localism these last few weeks, and I don’t want to lightly let it go.\n",
    link: "/home/2020/05/26/voice",
  },
  {
    title: "Filtered for musical cyborgs",
    date: "19.27, Friday 29 May 2020",
    content:
      "1.\nHere’s Piano Genie, a device with a row of eight colourful arcade buttons that sits between the player and the actual piano keyboard.\nPlay the coloured buttons, and the device improvises a virtuoso performance on the piano itself – matching the intent of your ham-fisted button pushing.\nMusical upscaling, I guess?\nFile this cyborg prosthesis as: power amplifier. It directly amplifies human intent.\n2.\nGuitar Machine is a robotic attachment for a guitar.\nAt first it seems like Guitar Machine is a replacement for the human: the player will “train” the machine (programming by example?) and the machine will replay what it has been taught.\nSo file this cyborg prosthesis as: macro engine. Script once, repeat indefinitely.\nBUT – give a machine like this to a musician, and they try to break it. Guitar Machine can play the guitar simultaneously with the human:\n\nHe was seamlessly transitioning between giving the robot the lead, taking over control, and synthesizing his own playing with the robot’s once he understood what the robot was doing.\n\nA duet!\n3.\nHere’s a short documentary about a drummer with a bionic arm. He lost his original arm, and now in its place is this bionic arm that is made to play the drums.\nAnother article goes hard on how the beats aren’t humanly possible: The prosthetic arm can play the drums four times faster than humans.\nThe arm can also play strange polyrhythms that no human can play.\nThen there’s this bit:\n\nThen, he fitted Barnes with a cyborg arm with two drumsticks – one that is controlled by Barnes, and the other that operates autonomously through its own actuator. The arm actually listens to the music being played and improvises its own accompanying beat pattern, which are pre-programmed into it.\n\nI am into the idea that this cyborg arm has its own will and its own creative urge.\nThe two-way feedback and improvisation makes this more than a duet.\nFile this cyborg prosthesis as a third type: centaur. \nI posted last month about wild cyborg prosthetics – it strikes me that a typology like this is a useful way to generate more ideas.\nHEY, A QUESTION:\nAre there research labs in the UK/Europe working on the underlying tech for this? In any domain really, music to military, swimming to shopping. Like, human prostheses haunted by embedded wilful compute?\nAs they say, lmk.\n4.\nThe Impossible Music of Black MIDI starts with some historical background:\n\nIn 1947, the composer Conlon Nancarrow–frustrated with human pianists and their limited ability to play his rhythmically complex music–purchased a device which allowed him to punch holes in player piano rolls. This technology allowed him to create incredibly complex musical compositions, unplayable by human hands, which later came to be widely recognized by electronic musicians as an important precursor to their work.\n\nAnd this is the whole point. Cyborg technology is not about existing musicians playing existing music with less effort. It’s about scouting ahead to invent whole new genres.\nThe article goes on to talk about Black MIDI itself:\n\nA similar interest in seemingly impossible music can be found today in a group of musicians who use MIDI files (which store musical notes and timings, not unlike player piano rolls) to create compositions that feature staggering numbers of notes. They’re calling this kind of music “black MIDI,” which basically means that when you look at the music in the form of standard notation, it looks like almost solid black.\n\nThe sound is an ascent into an insane chaos, like jamming static in your ears. I love it.\nDo check out the article because then you can listen to the track Bad Apple, which is embedded there, and which reportedly includes 8.49 million separate notes.\nNot that we measure the worth of music by weight, like buying potatoes. But still, what if we did.\n",
    link: "/home/2020/05/28/grocery_shopping",
  },
  {
    title: "Experiments with projectors and video calls",
    date: "08.16, Thursday 4 Jun 2020",
    content:
      "I’ve been posting recently about video calls and online talks. And, in the spirit of that, last week tweeted about a ridiculous experiment with an overhead projector.\nHere’s what I did, with photos.\nThe setup is this:\n\nI take the call (or presenting the talk) on my laptop\nA few feet away, behind the laptop, is my overhead projector. It faces me (it’s bright!) so the projection appears on the wall behind me, effectively the background for my call\nThe projector is plugged into an Apple TV, which is screen mirroring from my iPad\nI carry my iPad and drawing on the screen. Whatever I draw appears, projected, on the wall behind me. (I just scribble in a random drawing app using a black background.)\n\nSeriously, check out the photos at that write-up. It’s a bit stupid. Plus the rest of this post is about those photos, so it’ll only make sense if you follow that link.\nSo, did it work?\nIt’s fun! And funny!\nIt’s funny to draw a lightbulb above my head which is visible to everyone else, even if I’m not full screen and speaking. Design for thumbnail view!\nIt’s funny to look sideways and pretend like laser beams are coming out of my eyes.\nIt’s funny to draw a speech bubble for myself.\nOr to doodle illustrations around my head. Or an ocean scene, giving myself a diving helmet. Or to scribble a diagram.\nWhat didn’t I expect?\nThe reason to experiment like this is classic design thinking through making:\n\nIt’s hard to imagine the consequences of something that is itself only in your imagination. By making it, you give yourself a solid foundation, and consequences and possibilities suddenly pop into view.\nThe material forces you to do things you didn’t plan on, and every workaround and quirk reveals more opportunities.\n\nIn this case I’m trying to learn about the interaction design. So what thinking through making says is that I should prototyping the interaction, in however janky a fashion. (Another approach is iterative development, always doing only the most straightforward next step that gets you closer to your goal, but always learning and re-evaluating what that goal is. I like this approach too.)\nAnyway!\nWhat I didn’t expect…\n\nhow interesting it would feel to draw on the wall instead of on an overlay on my screen. Once it’s on the wall, I - as a presenter - can move around, pointing and interacting. It’s not a green screen weather forecast, I can see the wall too!\nwanting to gesture to trigger a drawing. I wanted to be able look sideways and open my mouth to create a speech bubble. Or hold a finger up to project a big number behind me, enumerating points in my argument. I was surprised about how live the drawing feels, and I want to capture and extend that.\n\nWhat next?\nThe projector is janky and lo-fi, which makes it fun, but it would be neat to do this in software instead.\n(The particular problem with the projector is lighting, as you’ll see from the experiment photos. The projection needs a dim room, the presenter needs a bright room; it’s an unhappy compromise.)\nThere’s a technology called virtual webcams – meaning that Zoom, instead of using your built-in webcam, uses a “camera” which has been manipulated by some other software first.\nHere’s how to set up a virtual webcam using OBS. OBS?\nOBS = Open Broadcaster Software. It’s free software that, with a bit of work, lets you do things like green screen.\nCase in point: I caught on Twitter today that Mark Pesce is doing green screen Zoom talks – check it out, it looks fantastic.\nBUT, BEYOND THIS,\nwhat I want is…\n\nto make it look at though I’m drawing on wall behind me. I don’t want it to look like I’m floating in space. I want the drawings to attach to my actual room and not to the screen – so maybe I could stick motion tracking markers on the wall behind me, and dynamically cut out and replace a fixed piece of the background to use as the virtual drawing pad?\nto draw on my iPad and have it appear on that virtual wall. Now this… I have zero idea how to achieve. Any thoughts?\n\nI’ll give it a go when I get a chance. Who know what I’ll learn. Thinking through making, I COMMEND THIS AS A PRACTICE.\n",
    link: "/home/2020/05/29/musical_cyborgs",
  },
  {
    title: "Singing bridges",
    date: "19.53, Monday 8 Jun 2020",
    content:
      "I am of course delighted that in San Francisco, the Golden Gate Bridge is singing like a giant ethereal harp, because it makes me wonder what it’s saying, and about the voices of other transport infrastructure, and what they would sing about too.\nHere’s another recording of the singing bridge.\n(The sound reminds me of this demo of the Cristal Baschet which is a glass “harp” invented in France in 1952, and it gives me SHIVERS.)\nSo how would it sound for an office tower to sing? And what voice would it have?\nOr an airport? Or a wind farm?\nHow about a road? If you put your ear to the asphalt, would you hear it whispering about what’s happening at the other end, 500 miles away?\nI’m reminded of Tom Armitage bringing Tower Bridge to life in tweets: I am opening for the MV Dixie Queen, which is passing down riverstream.\nBUT\nI’m also pretty taken with the idea that we don’t know what the Golden Gate Bridge is singing about, other than it being windy. It tickles me that the bridge has its own internal life that leads it to sing, but it’s no more speaking to us than a blackbird. Why should the bridge want to tell us anything? And why would we be able to understand it if it did?\nWhat’s appealing is the scale difference and the parallel lives. In regular life, the bridge is subject to human concerns. But if we’re quiet, and we make some room, this sleeping giant dreams, and we can hear it talking in its sleep.\nA city, but the Music of the Spheres:\n\nIf earthly objects such as strings or pieces of metal make sounds when put in motion, so too must the Moon, the planets, the Sun and even the highest stars. As these heavenly objects are forever in motion, orbiting the Earth, surely they must be forever producing sound.\n\n(Says Pythagoras.)\nI’m currently lost in a bit of a wikihole reading about the music of the spheres, the musica universalis, and it turns out this is only one of three branches of “musica”:\n\nmusica mundana (sometimes referred to as musica universalis)\nmusica humana (the internal music of the human body)\nmusica quae in quibusdam constituta est instrumentis (sounds made by singers and instrumentalists)\n\nSo, a fourth brand, a musica city? Not cosmic but earthbound. The music of the human-created but somehow bigger than us?\nIf you’ve never been to The Monument in London, it’s a thin stone tower with a spiral staircase inside to reach the top, about 300 steps, and it was tall when it was completed in 1677 to commemorate the Great Fire. (Now it’s in a square mostly surrounded by office blocks.) Here are some pics.\nThe staircase is hollow from top to bottom. You can see straight down as you circle round, which always gives me the heebie jeebies.\nIt turns out the entire thing was architected to double up as a telescope to measure the parallax of the stars, lenses attached 200 ft apart across the cylindrical void.\nAnd I remember reading somewhere that Christopher Wren (the new St Paul’s Cathedral) and Robert Hooke (him of the law of elasticity, and also architect) conceived of the post-Fire, rebuilt London as a landscape of mega-instruments, buildings simultaneously for people and also for the scientific contemplation of nature.\nSo maybe that would be the song of our cities, if only we could hear it.\n",
    link: "/home/2020/06/04/projectors",
  },
  {
    title: "From the other side of the bridge",
    date: "14.50, Friday 12 Jun 2020",
    content:
      "There’s a story about William Gibson’s jacket. In his book Pattern Recognition he confabulates a jacket for the protagonist, Cayce, in a colourway that never existed.\nThe manufacturer, getting requests from fans for this fictional jacket, approaches Gibson, and together they create the jacket for real. Gibson himself has a custom version. Here’s his telling from 2005:\n\nI received a very puzzled letter from the folks at Buzz Rickson’s, who had been getting requests for black MA-1’s. Once I had explained what was happening, they amazed and delighted me by asking my permission to make a repro of *Cayce’s* jacket, to market as their Pattern Recognition model. Yes indeed, I said, and while you’re at it, cut me one with an extra four inches in the back, please. Which they did, and it’s over the back of a chair nearby as I write this. I love this jacket. It reminds me of the title of a Surrealist sculpture, “An Object From The Other Side Of The Bridge”. It’s real, but it emerged from a work of fiction.\n– William Gibson, blog post, December 2005\n\nSo I’d forgotten this story. Then read it again this week in Pfeil Magazine 12 which I received as part of my Stack magazines subscription (I’ve signed up to get a different magazine each month, their choice).\nThat piece in the magazine (for completeness here’s a pic) also used that phrase an object from the other side of the bridge\nand\nit totally\nate my brain.\nWhat I hadn’t realised, before looking up Gibson’s telling of the story, is that the phrase is taken from the name of a sculpture. Which I would now like to see.\nHere’s the sculpture: De l’autre côté du pont, “From the Other Side of the Bridge,” Yves Tanguy, 1936.\nNow, I’ve written before about fiction and inner and outer realities but this feels… different, somehow? More ouroboros. More like magick: speaking as a way of forming the universe.\nA crossing between the fictional realm and our world! I mean, an invention in fiction is also an invention in our world, of course.\nBut there’s something special, here, about the way the object can only be reached via first constructing the ENTIRE FICTIVE UNIVERSE, thus writing it into being, and that process has to be conducted from our side of course; like projecting a hologram from a laser-engraved lens, but once inscribed you can step into the hologram and – grab it.\nLike searching for a particular item in a dream, and waking with it in your hands.\nBoth the molecular structure of benzene and the molecular structure of DNA were brought back from dreams.\n",
    link: "/home/2020/06/08/singing_bridges",
  },
  {
    title: "Filtered for hallway tracks and spreadsheet parties",
    date: "13.29, Monday 15 Jun 2020",
    content:
      "1.\nWhen I’ve been posting about rethinking conferences in the Age of Zoom it’s all been about the talks. But conferences aren’t just talks…\n\nA conference, or an ‘event’, is a bundle. There is content from a stage, with people talking or presenting or doing panels and maybe taking questions. Then, everyone talks to each other in the hallways and over coffee and lunch and drinks. Separately, there may be a trade fair of dozens or thousands of booths and stands, where you go to see all of the products in the industry at once, and talk to the engineers and salespeople. And then, there are all of the meetings that you schedule because everyone is there.\n– Benedict Evans, Solving Online Events (blog post)\n\nAnd in particular, this line: Most obviously, we don’t have any software tool for bumping into people in the same field by random chance and having a great conversation.\nEvans is a formidable technology analyst, and his use of the word bundle is a callback to how newspapers were unbundled over the early 2000s: classified ads went to Craigslist, ads went to Google/Facebook, news discovery to Twitter, op-ed to blogs/YouTube/etc, filler to Buzzfeed, etc etc, and pretty soon the very special job of newspaper journalism was left without the commercial viability lent by its fellow travellers.\nSo if we’re doing conference talks on video now, how do we do the hallway track? And should the two remain bundled together?\n2.\nTamas Kadar has a great write-up of how !!Con 2020 worked.\ne.g. The conference organisers covered [the speaker’s] cost to get a good webcam and a microphone. Vital!\nMainly the hallway track was built around Discord which is a text chat app for communities with great voice and video. Here’s a review: there are text channels, which are for regular group text chat, and then there are… Voice Channels. This is where things get interesting - you can set your microphone to ‘always on’ when you join a voice channel and then go about your business - e.g., sharing your screen.\nSo… !!Con:\n\nFor one, they set up a channel for each speaker’s talk, ordered by the schedule. As the day and the talks progressed, you would move from channel to channel, down on the list. This proved to be a brilliant idea: it was easy to keep track of the conversations, they were not in one big batch, and you could always go back to a given channel if you wanted to talk about a specific talk. More conferences should adopt this.\n\nAnd with voice:\n\nThey also had a bot that could match random people up to hang out. You would go to a channel and say “match me”, and if other people did the same in the next 60 (or later, 90) seconds, it’d create a Discord voice room and send everyone an invite.\n\nAnd you could jump to video in a bunch of different places:\n\nBesides Discord and the thoughtful organization of the channels, there were virtual Zoom rooms you could join throughout the conference. You were given a map with all the rooms, and it showed you who was in the given room\n\nTakeaway: the hallway track works best when it’s about multi-tasking, and you can move up and down levels of engagement with the presentations and the conversations.\nPeople used to be obsessed with multi-tasking in the heyday of desktop computing. Screens were big enough to have something to focus on and ALSO peripheral awareness, so we got menu bar indicators and taskbar news tickers, etc.\nI think, with phones, we’ve kinda forgotten about it… perhaps because people are already multi-tasking when they’re using their phones because we’re simultaneously watching TV, or walking down the street, making team and so on. Phone have small screens and so they’re naturally focus devices.\nBUT, we’re multi-tasking animals. I pay attention better when I’m doodling and making notes.\nPersonal theory: as we’re at home more, and smartphones ebb, the technology that succeeds will be the technology that facilitates multi-tasking.\nSo ONLY staring at a conference talk just doesn’t make sense.\nINSTEAD let me watch a conference talk AND ALSO have a text conversation about it, perhaps even with the speaker who may have pre-recorded their talk in order to participate in the simultaneous text channel.\nCan virtual conferences be designed for multi-tasking?\nSEE ALSO: Nudgestock which was 14 hours long and ran last Friday. I caught this on Twitter and what I found fascinating was the number of people watching the stream on their TV. People hacking their own two screen experience: TV for the talks, 6 feet away, a continuous stream; laptops and tablets (1 foot away) for tweeting, notes, and falling down wikiholes…\nCan virtual conferences be designed for the two screen experience?\n3.\n!!Con (pronounced: bang bang con) also featured a spreadsheet party. Spreadsheet parties are legit my favourite lockdown trend.\nHere’s how a spreadsheet party works, from Marie Foulston (this is the earliest reference I can find):\n\nWhat is worse than being alone on a Saturday night? Being alone in a spreadsheet, that is what. Being alone in a spreadsheet that you’ve half-decorated for a party, and sent invites out for, one in which you made a special “coat room” tab and drew a dance floor.\n…\n“If I organized a party in a shared Google doc who would come?” I asked the Twitter DM group.\n\nI’m in love with this sentiment:\n\nSocial video calls exhaust me. Face to face, voice to voice, with nothing in between. Communication so literally and abstractly boiled down to staring at and talking at each other’s faces.\n\nBasically, tons of people show up in this shared online spreadsheet at the appointed time, and…\n…some snippets from the telling:\n\nA flurry of coloured cursors dart from cell to cell announcing names\nCoats are cut and pasted into the coatroom tab\nA new sheet is made, it briefly has no purpose. Someone paints every cell blue, and it becomes ‘the blue room.’\nSome people make bonfires in the garden and start toasting s’mores. Others race each other to the bottom of ‘Sheet 14.’\n I stop and type to someone in a nearby cell. My cursor is blue, theirs is orange. I have no idea whether they are a close friend or a total stranger.\nI’m tired and wonder what on earth the correct etiquette is for closing down a spreadsheet party.\nIn the blank cells beneath I serendipitously stumble upon two friends who had each sought space away from the hubbub. They are quietly chatting.\n\nFoulston is a curator, and this deft curation of social experience with only the lightest of touches has left me awed. Thank you, just reading about it I can see you have invented something magical.\n4.\nBack in the 2005, Jyri Engeström translated the concept of social objects from sociology to the world of social media: Social network theory fails to recognise such real-world dynamics because its notion of sociality is limited to just people.\nWhat he recognised what that social networks and socialising happen around objects and activities: sharing photos and commenting on them; playing video games together; googling for funny pictures on a theme and pasting them into a tab on a shared spreadsheet…\nWhen I’m thinking about unbundling conferences, it was never that case that - in old-school, physical conferences - there were\n\nthe talks,\nand also, separately, the hallway track.\n\nIn actuality, the talks feed the hallway conversations.\nI remember talking to the folks at O’Reilly about the ETech conferences, my favourite and most formative conference series, and they told me they would deliberately put simular talks opposite one-another making it difficult to choose… and giving people something to talk about in the hallway afterward.\nI started so many conversations with strangers with, so, what did you just go to?\nWhat I’m coming to feel is that you need these two activities to happen simultaneously: the talk and the hallway; the doodling and the socialising.\nYou need the equiv of the talk you’ve just stepped out of to be an excuse to start a conversation; the trade show stands to wander round so you don’t feel awkward being on your own; the figure and the ground.\nTaking it back to where we came in: the talks and the hallway track not only belong bundled together, but they should be as close and muddled together as possible.\nSEE ALSO:\nHaving conference calls in Red Dead Dedemption 2: Zoom sucks, we started having editorial meetings in Red Dead Redemption instead. It’s nice to sit at the campfire and discuss projects, with the wolves howling out in the night.\nAmazing.\nAnd, regarding an NPC (computer-generated character) who keeps interrupting the meeting: But to be honest, he’s a really good stand-in for the distractions we would have when meeting in a cafe usually, and he can be useful in breaking things up when we’ve lost focus.\nSome fascinating behaviours being illuminated in these weird times.\n",
    link: "/home/2020/06/12/gibson",
  },
  {
    title: "Quotebacks and hypertexts",
    date: "08.54, Tuesday 16 Jun 2020",
    content:
      "If you’re reading this on my website, you’ll notice that the next chunk of text looks a bit different. That’s because it’s a quoteback.\n\nQuotebacks are like a quote retweet, but for any piece of content on the web. They work on any webpage, and gracefully fall back to a standard blockquote.\nThus, “Quotebacks” is three things:\n1. A web-native citation standard and quoting UX pattern\n2. A tiny library, quoteback.js, that converts HTML <blockquote> tags into elegant interactive webcomponents\n3. A browser extension to create quoteback components and store any quotes you save to publish later.\n– Quotebacks, Introducing Quotebacks\n\nQuotebacks is a project? invention? protocol? by Toby Shorin and Tom Critchlow. Here’s Tom’s introductory post: which has some background. The ultimate goal is to encourage and activate a deeper cross-blogger discusson space. To promote diverse voices and encourage networked writing to flourish.\nI’m seeing a bunch of folks trying out quotebacks. If you keep a blog yourself, I urge you to give it a go. I’ll talk about why later in this post.\nMe? I’ve written a Quotebacks extension for Python-Markdown\nI’m not using the Chrome extension to collect quotes myself. I have my own weird workflow for hamsterkaufing the web.\nBut I do want to display quoteback embeds, and you can see one at the top of this post. (If you’re reading this in RSS or email, check the website.)\nHow? I write quotes in a special format in the Markdown text documents that lie behind this blog. (I keep everything in various forms of plain text and have done for a couple decades.)\nThese text docs are transformed into HTML for the blog using Python-Markdown. So I’ve written a Python-Markdown extension called quotebacks-mdx to transform this special format into the quotebacks embed HTML.\n\nHere’s the raw Markdown source for this post. Note the blockquote at the top: that’s the one that gets transformed into a quoteback using my extension.\nDownload/browse the quotebacks-mdx code on Github. If there’s interest, I’ll package it up so others can use it too. As the kids say: lmk.\n\nI’d also like feedback on the Markdown format I’m using – if people implement extensions in other languages, it would be good if something like this became a de facto standard. \nWhy did I do it this way?\n\nMarkdown deserves to have a way to include a citation in blockquotes – afaik there isn’t a consensus way to do this right now.\nI can include nicely-cited quotes in my blog posts without including custom HTML. So in another 10 years, I know I’ll still have my easy-to-access plain text.\nThe fallback for Markdown (without the extension) and for HTML (without the Javascript) is still readable and still looks good.\n\nAnd, even though I’m not using the Quotebacks browser extension, I’m adopting the embed format - the protocol - because of what we might one day build on top.\nSome history: the Memex\nBack in 1945, Vannevar Bush published his insanely visionary essay As We May Think in The Atlantic. Through his imagined machine called the memex he predicted the web and its effect on human knowledge, work, and conversation:\n\nConsider a future device … in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility. It is an enlarged intimate supplement to his memory.\n\nPhones!\nHere’s the original essay though the Wikipedia summary is short and good.\nThe core feature of the memex is trails. It isn’t just a library.\n\nWholly new forms of encyclopedias will appear, ready made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified. The lawyer has at his touch the associated opinions and decisions of his whole experience, and of the experience of friends and authorities. The patent attorney has on call the millions of issued patents, with familiar trails to every point of his client’s interest. [Etc.]\n\nWikipedia! Work!\nWELL.\nAnd… bloggers:\n\nThere is a new profession of trail blazers, those who find delight in the task of establishing useful trails through the enormous mass of the common record.\n\nFlash forward…\nHypertext and transclusion\nIn the early 1960s, Ted Nelson coined the text hypertext. The web is a hypertext, and the original 1989 proposal cited Nelson’s work.\nHis project Xanadu - although never completed - was an expansion of what he meant by this original concept.\nHypertexts are connected texts. But Nelson saw two types of connections: links (which we have) and something else called transclusion. \nFrom one paper about Project Xanadu:\n\nThis may be simplified to: connections between things which are *different*, and connections between things which are *the same*.  They must be implemented differently and orthogonally, in order that linked materials may be transcluded and vice versa.  This double structure of abstracted literary connection – *content links* and *transclusion* – constitute xanalogical structure.\n\nTransclusion:\n\nTransclusion is what quotation, copying and cross-referencing merely attempt: they are ways that people have had to *imitate* transclusion, which is the true abstract relationship that paper cannot show.  Transclusions are not copies and they are not instances, but *the same thing knowably and visibly in more than once place*.  This is a simple point which is remarkably difficult to get across.\n\nAnd later in the paper:\n\nNote also that the famous “trails” of Vannevar Bush’s memex system (103) were to be built from transclusions, not links.\n\nHere’s Wikipedia on transclusion.\nBack to Quotebacks\nWhat I love about the web is that it’s a hypertext. (Though in recent years it has mostly been used as a janky app delivery platform.)\nAnd what I like about Quotebacks is that it already feels like an essential part of that hypertext toolbox! The Chrome extension meet the needs of Bush’s trailblazers; the embed format mimics Nelson’s transclusion.\nNow the Quotebacks projects doesn’t immediately fulfil on this grand promise. But the great thing about a protocol is that I can adopt it and support it, and you can adopt it and support it, and if there’s enough of a consensus, we can build more on top. So what I’d be interested to see:\n\nan index, accessible to all: could quoteback embeds be centrally tracked somehow?\na serendipity machine: could my browser tell me when I’m on a page which has been cited – could I see the “trails” that are crossing this page, and chose to pivot and follow one? And could I see when one of those trails was authored by a friend?\na robot research aide: could I index the quotebacks in my own database… and find holes? i.e. texts that are regularly cited by the ones I’ve quoted, but somehow I’ve never discovered them myself?\n\n(I’m less bothered about finding out specifically when people use one of my posts in a quoteback. That would be neat I guess, but tracking mentions is a first-order problem and besides it’s a spam honeypot.)\nWhat I’m talking about is the kind of hypertext that I love, one in which my blog is a place for thinking out loud.\nMy blog is not my notebook, and it’s not my marketing platform.\nMy blog is my laboratory workbench where I go through the ideas and paragraphs I’ve picked up along my way, and I twist them and turn them and I see if they fit together. I do that by narrating my way between them. And if they do fit, I try to add another piece, and then another. Writing a post is a process of experimental construction.\nAnd then I follow the trail, and see where it takes me.\n",
    link: "/home/2020/06/15/hallway_track",
  },
  {
    title: "Personal software vs factory-produced software",
    date: "20.46, Thursday 18 Jun 2020",
    content:
      "Rev Dan Catt, technologist and pen plotter artist, recently posted about the tools he’s built to run his art business: Making all the Things.\nLike, there’s web-based tool that he’s built - just for him - to remind him about popping stuff in the post to people.\nThe copy is delightful because it doesn’t have that generic second person thing that most apps do: Your Music, Your Photos, etc. INSTEAD, the site copy is all in the first person:\nWhen and where to send cards & letters: Here’s where I keep all the information I need to get stuff sent off smartish.\nThe copy is from Catt’s Correspondance Tracker. It’s mostly as you’d expect: forms and buttons and checkboxes and headers, e.g.: When stuff was sent. Here’s the explanatory text that follows:\n\nThis is when I sent letters or cards, so when I go “Oh when did I send that letter?” I can see here\nThe two checkboxes can help if I sent something with tracking, once I’ve checked it’s arrived I can mark it off.\n\nIt’s like when you write yourself a post-it and leave it in a box file of paperwork that you know you’ll open again in a year and want to know what’s going on…\nRobin Sloan put it like this: An app can be a home-cooked meal.\nHe created a video messaging app that works a bit like Snapchat, only super simple, and for use by only four people: his family.\nAnd here’s Russell Davies’ Bikemap project (2011) which is a physical, printed out map of his neighbourhood (from Google Maps?), with little LEDs poking through where there are bike-share stations. They light up when there are bikes available.\nI love writing little bits of automation just for me. I’ve made a Shortcut or two on my iPhone. I’m happy enough writing an ad hoc script to go through a bunch of files for me, or to generate the numbers I need to plug into my accounts once a month. Ok.\nBut these examples are different…\nI wonder what qualities mean that they feel like proper software?\nThey’re packaged. They don’t feel temporary. If you accidentally deleted the icon, you could re-install it.\nThere’s just the right amount of design and copy.\nThese examples don’t seem like they’re “inside” someone else’s platform, like a tool written in a spreadsheet does.\nThey live shoulder-to-shoulder with “bought from the store” apps, in the same browser as websites with padlock icons like google.com, and on shelves next to mass-produced products.\nThere’s an equivalence between personal software and factory-produced software, here.\nI wonder what modern computing would look like, if it was focused on making that equivalence easier.\n",
    link: "/home/2020/06/16/quotebacks",
  },
  {
    title: "Early web videos, eye contact, and anti-attention",
    date: "20.43, Monday 22 Jun 2020",
    content:
      "I’ve been watching web videos from the early 2000s, and all I can think of is the eyes. It’s incredible.\nSo the Flagpole Sitta Lip Dub was posted in 2007. It’s the first video in Andy Baio’s lip dup cultural history. Watch it again, it launched a thousand copycats and it’s still magical - a lip sync music video which is so well done, but also so clearly “real” and not professional.\nAnd it opens with Amandalyn Ferri looking right through the screen, straight down the barrel.\n(Web videos were new at the time. YouTube was founded in 2005. It was acquired by Google in 2006.)\nThen there’s Ze Frank’s video project The Show: ‘the show with zefrank’ was a short video program produced Monday through Friday for one year (March 17, 2006 - March 17, 2007).\nAs an example, here’s The Show from 14 July 2006. I think it was originally on his site as a made-for-iPod show? But now the video is on YouTube. (This one is my favourite episode because it’s a defence of ugliness as the democratisation of design.)\nIf you take a look at the video, you’ll notice two things:\n\nit’s short! 3 minutes 13 seconds. None of this rambling, begging for subscribers thing that vloggers do now (remember “vlogger”? Holy shit what a word hahaha)\nTHE EYES. Quick edits, face full frame, and THE EYES.\n\nZe doesn’t blink.\nHe’s basically inventing the form for personal web videos here (it’s 2006 don’t forget), and already he’s messing with the idiom by using this crazy jitter of quick cuts to not blink.\nFrom a really solid long read about the “poetics” of web video: The poetics of any artistic medium studies the finished work as the result of a process of construction.\n\nBeginning in April, 2006, Frank stops blinking onscreen. His eyes are always open wide in an exaggeration of an attentive stare. In an interview he has said that not blinking is a product of his intense concentration but in the episode on 23 October 2006, he advises would-be vloggers not to blink because when you blink, “that’s one less connection made” with viewers.\n– Michael Z. Newman, Ze Frank and the poetics of Web video (First Monday)\n\nI remember reading that the ideal amount of time for mutual eye contact is 3.2 seconds and longer than that feels weird (read: threatening or arousing, depending on the situation I guess).\nBut Ze is 3 minutes!\nAnd on Zoom calls it’s 30 minutes to an hour! No wonder video calling can be so exhausting.\nSee also: Apple’s FaceTime Attention Correction feature (in which your pupils were artificially manipulated in video calls to look right into the camera) which fortunately did not launch.\nAnd just think about this: the idiom of web video didn’t necessarily have to be straight to camera. It could have been, like TV, modelled on theatre: a performance on a little stage in a little box, with everyone studiously pretending there is no audience.\nThere’s a ton online about how to hold a person’s gaze for just one beat longer in order to\n\nsell them something\nseduce them\nbeat them in a negotiation\netc.\n\nWhich is a hella creepy.\nI wonder… what would anti-attention features be like?\nHow about a pair of augmented reality glasses with an app to manipulate everything I see, ensuring that no-one, no matter how charismatic, could hold my gaze for longer than 3.2 seconds?\nWould this let me assess an argument better, if I could wear a software inoculation against enchantment?\nAnd - continuing on this line - what if our politicians were made to wear such A.R. specs, so they couldn’t be wooed by charismatic leaders, and our TVs had filters built in, so we could shield ourselves from being drawn into any hypnotic gaze?\nHuman interaction firewalls.\nCharisma shades.\n",
    link: "/home/2020/06/18/personal_software",
  },
  {
    title: "3 books from Chris Noessel",
    date: "18.55, Tuesday 23 Jun 2020",
    content:
      "One of my favourite projects over the past few years has been 3 Books Weekly in which I asked friends and people I admire: hey, so what three books should I read this year?\nIt was an email newsletter and all 29 editions are archived here.\nIt’s a great question to ask. The three books aren’t supposed to be your desert island books. Or the showing-off books that tell everyone how clever you are. A good strategy is to have a conversation that gets you somewhere interesting, and then take the question literally… so, what three books should I read to learn more about this?\nWhat happens is you get (a) a good reading list and, mainly (b), to see what makes them tick.\nAll of which is to say: it’s time to bring it back. Not weekly. But, you know, as an infrequent format. Let’s see what happens.\nSo Chris Noessel - among many other things - is behind the blog Sci-Fi Interfaces which digs into the interaction design of computer interfaces in movies.\nFILE UNDER: artificial intelligence, narrative design fiction, networked matter, architecture.\nHey, Chris. What keeps you busy?\n\nCertainly ramping up to be a daycare and homeschooler during the pandemic has been a challenge, especially considering that my day job of designing an AI assistant for Supply Chains at IBM has also ramped up in importance and workload as well. With the time that’s left, I’m still doing my damndest to keep a post coming every two weeks for the scifiinterfaces.com blog, working on new books, and even trying my hand at short fiction. It is a busy, busy time.\n\nRead on for Chris’ three books…\n#1. The Djinn Falls in Love\n\nI’ve been thinking about genies/djinni as metaphors for artificial intelligence for a while, searching out mythologies and modern re-imaginings as a springboard. One such search led me to the collection “The Djinn Falls in Love.” There are many cool tales within, but I particularly recommend the soaring poetic language skills of Maria Dahvana Headley, whose short story “Black Powder” is my favorite in the collection.\n\nThe Djinn Falls in Love: Google Books\n#2 An Aura of Familiarity\n\nOver the past several years I’ve been interested in sci-fi that has been commissioned to address issues (rather than relying on the interests of the author or of the entertainment value of the topic). The subgenre is kind of design fiction, but clearly narrative in nature. Maybe we can call it commfic? Anyway, one of my favorite of these collections is the Institute for the Future’s “An Aura of Familiarity.” Such beloved authors: Doctorow! Rucker! Ashby! Sterling! And such a rich topic: Networked matter. Madeline Ashby’s “Social Services,” in particular, has stayed with me since I read it in 2013.\n\nAn Aura of Familiarity: Visions from the Coming Age of Networked Matter: Institute for the Future (pdf)\n#3. A Pattern Language: Towns, Building, Construction\n\nI know a lot of people know about Christopher Alexander’s pattern language, but I don’t know that many people who have read it. And I don’t mean “The Timeless Way of Building,” where they introduce the philosophy and the ideas, or “The Oregon Experiment,” where they share how the language played out in a design project, but actually “A Pattern Language” itself: pattern to pattern, cover to cover. When I did, it opened my eyes to architecture of course, but more importantly, how to think systemically about complex design systems across scales, how to manifest these thoughts to clarify your own thinking, and how to document them so they are usable within a community of practice. None of the laudable attempts to formalize a pattern language for interaction design have “made it big,” but I still think it’s the best way to think about design practice, and this is the source material. I recommend every designer read it.\n\nA Pattern Language: Towns, Buildings, Construction, Christopher Alexander: Google Books\nGenies! Thank you Chris :)\n",
    link: "/home/2020/06/22/anti_attention",
  },
  {
    title: "What are the problems with Big Tech?",
    date: "21.50, Monday 29 Jun 2020",
    content:
      "There are increasing calls to break up, tax, regulate or [other intervention here] Big Tech. What I’m curious about is what for.\nTo be clear, I have no position on whether these are valid complaints. For now I’m just collecting them.\nRunning through some of the stated problems with Big Tech\nTim Bray recently suggested breaking up Google into separate firms for ads, maps, Android, etc. Here’s the central rationale:\n\nFor many years, the astonishing torrent of money thrown off by Google’s Web-search monopoly has fueled invasions of multiple other segments, enabling Google to bat aside rivals who might have brought better experiences to billions of lives.\n– Tim Bray, Break Up Google\n\nFile under: market distortion.\nHere’s another.\nThe French government has proposed a 3% “digital tax” on Big Tech revenues. It’s not yet implemented, pending negotiations to make the tax multinational. Two stated reasons for the tax are hate speech, and the consequences of unpoliced hate speech:\n\n[Cédric O, the French junior minister for digital affairs] said addressing online hate speech was also key. “Hate speech is a global public health problem,” he warned. “The rise in online hate speech creates a major difficulty for public powers: we don’t know how to protect our citizens online in the same way we protect them in real life. If I threatened to kill you or your children in the street, I’d face police. But that doesn’t exist online. It’s both a public health issue and a problem for democracy, because if people think we can’t protect them, they will vote for others who they think – rightly or wrongly – can protect them.”\n– The Guardian, France’s digital minister says tax on big tech is just the start\n\nThere’s some nuance here. Policing does exist online – it’s called moderation. The problem is that what France wants to police is different from what Facebook wants to police. It’s not integrated with non-Facebook issue. It’s out of step with local values.  And there’s nothing France can do to fix it.\n(Aside: I admire the public health framing because it says that Big Tech can be good for individuals, but it dumps some unwanted externalities on society which have to be accounted for. So the digital tax has the same logic as the accepted levies on cigs, booze, and gambling – all of which are the spice of life but definitely have their downsides.)\nAnother!\nHere’s Tom Loosemore on the decision by Apple and Google to build frameworks for a particular kind of Covid-19 contact tracing into iPhones and Android phones, and then refusing to cooperate with governments on anything different from that model:\n\nI’ll admit I was instinctively pleased when I heard of Google and Apple’s decision. Throughout my career, I’ve defended people’s privacy from your typical state’s propensity to collect ever more data about their citizens, often without reason.\nBut in the weeks since April 10, I’ve reflected more on the nature of power. Who has power? And how is it held to account?\nWhat Google and Apple did on April 10 was to make a huge, global public health policy decision – a decision that I believe should be the preserve of elected governments. \n– Tom Loosemore (at Business Insider), Google and Apple’s diktat to governments on coronavirus contact-tracing apps is a troubling display of unaccountable power\n\nFile under: Big Tech is extranational. Undemocratic.\nI can think of two other categories of issues people bring up about Big Tech.\nFirst, it has a tendency to be dangerous. Off the top of my head, here are some recent-ish issues to have hit the media:\n\nRumours spread on WhatsApp have triggered lynchings in India.\nUber in London insufficiently vets drivers, and hasn’t been reporting sexual assaults to police.\nAmazon has not been maintaining safety regulations for children’s toys.\nreddit has been an easy meeting place for far-right groups and people exchanging underage pornography.\nTwitter has normalised far-right discourse, and helped polarise communities along political lines.\nAirbnb facilitates residential property owners circumventing hostelry regulations meant for safety and neighbourliness.\nGig economy startups sidestep employment law to load corporate risk on workers with no security.\n\nSecondly, Big Tech tends not to pay its fair share in tax.\nIn the UK: In 2018, Facebook paid £8m tax on £1.27bn revenue. In 2019, Apple paid £3.8m on £1.2bn retail sales. Etc. Too low.\nWhatever the rights and wrongs of this, the impression is that it’s unfair. Big Tech has a market at all in the UK because there is a good level of education, and a wealthy economy supported by good national infrastructure – all paid for by the state. That’s what taxes are for (in part), but the firms benefitting aren’t making their fair contribution.\nAt a much smaller scale, it always seems pretty odd to me that I run my business using online software and paying for servers that are priced in pounds, but those same services don’t collect VAT because they’re not actually based in the UK. But… they do operate here, otherwise I couldn’t use them? My gut says that’s not ok.\nWhy catalogue the grievances?\nTo summarise the stated problems society has with Big Tech:\n\nThe market would have better products without them\nThey enact values which do not represent the national values where they operate\nDecisions have no democratic oversight (or rather: decisions can be at government scale but without government involvement)\nThey’re dangerous, or produce public health issues\nTheir tax contribution is unfairly low\nPower\n\nI’ve added that sixth one: power. And threat. The massive user base and extranational nature of Big Tech gives these firms a power which must terrify national governments. Could you, as a government, effectively regulate Amazon or Apple if that meant they might pull out of your country? Of course not. There would be uproar. Big Tech has produced a kind of internationalist, corporate, non-national loyalty which could be seen as a real threat by nation states.\nThese problems haven’t been levelled only at Big Tech – international capitalism is getting a shoeing of late, generally speaking. But Big Tech is the focus.\n(If there are other categories I’ve missed, please send me links.)\nI’m collecting these stated issues because there are a lot of suggested courses of action: digital taxes; breaking companies up; preventing companies from selling products in their own marketplaces, and so on and so forth.\nBut what I haven’t seen when these suggestions are made is\n\nA statement of which issue is to be addressed\nAn analysis of the issue, breaking it down into underlying causes\nA hypothesis of how the proposed remedy will be effective\nConsequence scanning for undesirable side-effects.\n\nWithout knowing what an intervention is intended to achieve and how it’s impossible to judge it. Is it good or is it bad? Will it be effective or ineffective? Is it likely to work or not? How does it stack up against alternatives? Who knows.\nLike: the French digital tax. The UK has a 2% digital tax on the way too (though it has been postponed). Will it fix what it intends to fix? How? If not, will it compensate for the stated harm? How will we tell? Will it exacerbate any of the other issues? Will it introduce any other problems? Maybe I’m doing my reading in the wrong places, but (except for France’s admirable but partial “public health” framing) these questions haven’t been part of the discourse. And all of this without even agreeing the nature of the problem in the first place. It’s poor policy.\nOne final caveat\nI’m cautiously saying stated issues because I don’t want to make a judgement here about issues, scale, causes, or fault.\nBig Tech has been very good to me personally, and I happen to believe it is (and has been) generally speaking a huge public good too. Yet there are problems, and people I respect have convincingly argued that there are very serious problems.\nSo that’s why I’m collecting my thoughts like this.\n",
    link: "/home/2020/06/23/3_books",
  },
  {
    title: "Space, weather, and other novel battlegrounds",
    date: "21.12, Tuesday 30 Jun 2020",
    content:
      "I learnt about the concept of spacepower today after hearing about this new book: War in Space: Strategy, Spacepower, Geopolitics.\nThe publisher description has more detail, and this isn’t a speculative topic: As satellites have become essential for modern warfare, strategists are asking whether the next major war will begin or be decided in outer space.\nBut it’s this perspective shift that really sniped me:\n\nBleddyn E. Bowen applies the wisdom of military strategy to outer space and presents a compelling new vision of Earth’s orbit as a coastline, rather than an open ocean or an extension of airspace as many have assumed.\n\nThen there’s the weather.\nBernard Vonnegut (Kurt Vonnegut’s brother) was a chemist who discovered in 1946 the effectiveness of silver iodide as ice-forming nuclei that has been widely used to seed clouds in efforts to augment rainfall.\nAnd the success of cloud seeding and the nuclear arms race led to the UN Weather Weapon Treaty (1976) which banned environmental modification techniques for military purposes. AS PREVIOUSLY DISCUSSED ON THIS BLOG:\n\nImagine attacking New York with an artificial earthquake. Or a hyper-thunderstorm. … Tabletop volcanos! Genetically modified tomatoes that create their own microclimate! Pocket clouds!\n\nAnyway.\nI recently across this paper called Weather as a Force Multiplier: Owning the Weather in 2025 (pdf) by Col whatnot and Lt Col someone or other and Maj you get the idea. Opening lines: 2025 is a study designed to comply with a directive from the chief of staff of the Air Force to examine the concepts, capabilities, and technologies the United States will require to remain the dominant air and space force in the future.\nIt starts off pretty rationally:\n\nThe application of weather-modification technology to clear a hole over the targets long enough for F-117s to attack and place bombs on target or clear the fog from the runway at Tuzla would have been a very effective force multiplier.\n\nThis paper was written in 1996 – or… maybe? I honestly can’t figure out the provenance of this document. It pops up a lot on geoengineering conspiracy theory websites.\nThere’s a decent science-fiction-y section. Lethal drone clouds!\n\nNanotechnology also offers possibilities for creating simulated weather. A cloud, or several clouds, of microscopic computer particles, all communicating with each other and with a larger control system could provide tremendous capability. Interconnected, atmospherically buoyant, and having navigation capability in three dimensions, such clouds could be designed to have a wide-range of properties. They might exclusively block optical sensors or could adjust to become impermeable to other surveillance methods. They could also provide an atmospheric electrical potential difference, which otherwise might not exist, to achieve precisely aimed and timed lightning strikes\n\nThen there are codices tacked on the end that veer into artificial earthquakes produced by lost technology invented by Nikola Tesla. So, make of it what you will.\nI can’t remember the first time I heard of cyberwar but I do recall that it sounded fantastical.\nThen came Stuxnet, a malicious computer worm, first uncovered in 2010, thought to have been in development since at least 2005.\nStuxnet silently spread between computers and USB flash drives until it reached the logic controllers for gas centrifuges in Iran – used to refine nuclear material. At which point it activated, and Stuxnet reportedly ruined almost one-fifth of Iran’s nuclear centrifuges.\nProbably a state-created cyberweapon, nobody has taken responsibility for it.\nI guess what I’m just realising is that, at some point, someone had to realise that “cyberwar” could be a thing.\nAnd what was that process like, exactly? Did some bright kid write a memo that got the attention of the boss and the boss’ boss? Did the FBI arrest a hacker, WarGames-style, then bring them in and ask them what they’d do? Is there a “warfare innovation” team that churns out 100 ideas a year, and they get a bonus if one of them catches the eye of management?\nAre there “new battleground” conferences that generals go to, populated with the familiar indsutry conference staples of tedious panel discussions and rubbish wi-fi and bad coffee?\nAnd now of course we’ve got 77th Brigade: They are the troops fighting Britain’s information wars.\nI know this is a bleak thought, but - prompted by the idea that there are people who, professionally, gaze up at the clouds in the sky and think “oh, we could fight whole countries with that” - I wonder what else they’ve come up with?\nAnd one other thought: I wonder how much of this has already happened?\n",
    link: "/home/2020/06/29/problems_with_big_tech",
  },
  {
    title: "Idle thoughts about how we replace keyboards",
    date: "20.04, Friday 3 Jul 2020",
    content:
      "Smartphone typing continues to be terrible. Maybe we look at possible futures to give us a way out?\nLook, I’m terrible at boundaries and time-management with both a toddler and too much work is hard. So I’m spending a bunch of time typing with my thumbs, and reminded once again that it is sloooow. Keyboards are good because your fingers can prepare to hit the next key way faster than individual thumbs can move.\nAlternatives to thumb-typing are: swiping keyboards and voice. Both suffer from the repair problem, which in a nutshell is: if you go wrong, how do you fix it? With swipe, you go word by word, and when you notice a problem you have to delete a whole word and just try again. You can’t “edit” without switching mode to typing. With voice, you go sentence by sentence, and repairing is even more of a context switch.\nNo, we need something better for smartphone typing.\nSo… we could ditch QWERTY?\nThe ideal smartphone keyboard would allow for the normal grip position with either one or two hands – and maximum efficiency of the available fingers, not just thumbs. Some avenues…\n\nMaybe a keyboard on the back of the phone, or buttons running down both sides?\nWhy does a keyboard need to read taps? Could you micro-twitch your muscles instead and have that picked up somehow?\n\nHow about a chording keyboard, where you press a combination of keys? Last time I rambled about keyboards on Twitter, Tom Whitwell pointed me at the Microwriter keyboard invented in 1978 which is held in the hand and apparently faster than regular typing. With training.\nHere’s a chorded keyboard for a smartphone as a hacker project (thanks Hans Gertwitz).\nWay back in 2017, Ben Firshman said in this tweet what if typing was a conversation instead of a one-way thing? It could guide you towards your intent somehow – which I am super into.\nWhat if you tapped a key, and around that key appeared the words that were most likely to be used next, and then based your movement towards those words, you saw the words that you might use next, maybe even appearing two or three words in advance, like gliding through super-intelligent autocomplete?\nI remember there was work way back in 2010 about using vibration and electrostatic to create artificial textures on touchscreens. Here’s an open access paper from 2019 reviewing different methods. As you glide your finger, could the probability or otherwise of the following word be communicated as the resistance given to your finger?\nThe thing is, shifting from QWERTY to something different feels unlikely right now. We’re at the wrong end of the S-curve for paradigm shifts.\nBUT,\nInstead of smartphones, we can imagine what comes after smartphones, and what the keyboard interface might be for that. And then evolve the smartphone keyboard to be training wheels for that future.\nWhat I mean is: imagine Apple wants to get us all into augmented reality. That’s a huge shift. They might conceptually invent an input mode for that, then port components of it into the “today” to train us into using it (and to learn themselves, of course). So we get trained to use voice input to ear buds and swiping letters on smart watches – and the offer of augmented reality won’t feel quite as daunting when it comes.\nSo maybe augmented reality will be the next big thing. Smart glasses.\nOr maybe the next big thing is - finally - ubiquitous computing. When I’m sitting on my sofa now, working, I am actively looking at five screens. No kidding. Laptop (for typing), tablet (for video calls). Watch (messages, notifications). E-ink screen (yeah, I don’t know either, but I built it and now it’s on the shelf telling me the time, and I look at it for that). Phone.\nThe phone is the interesting one. I use it to look up links when I’m writing a doc or on a call, then copy the link, and then the link magically gets transferred to my other devices and I paste it into the doc or into the chat. It is a super regular part of my workflow.\nBut what I mean is: five screens. Three keyboards. I use them as one device.\nSeriously, I need one keyboard.\nAnd if we imagine a world of smart glasses and then working backgrounds, what do we get? Perhaps…\n\nSubvocalisation so I can use voice to type, but not dictation – something that assumes I have my hands on another kind of keyboard to do error repair.\nTyping in the air, or maybe on any appropriate surface. I like using my wireless mouse for my iPad just next to me on the sofa… could I type by tapping my fingers on something nearby? Could I use a swiping keyboard by drawing in the air and having it picked up by a nearby camera?\nMaybe blended with that gliding autocomplete idea from earlier?\n\nHonestly I have no idea.\nIt feels like there’s a bunch of room to do some really interesting things here, and throwing away QWERTY and/or thumb-typing might open up some really interesting opportunities that we can’t yet imagine.\nAnyway it’s Friday night which means it’s pizza night and I need to go stretch some dough. I’d be interested to dig around in this more if you know anyone thinking about it.\n",
    link: "/home/2020/06/30/space_and_weather",
  },
  {
    title: "3 books from Tom Stafford",
    date: "17.19, Wednesday 8 Jul 2020",
    content:
      "Tom Stafford and I wrote Mind Hacks together, back in the day. (Boasting moment: Mind Hacks ended up getting translated into Japanese, Korean, Greek, Polish, Italian, and Finnish, which still astounds me. Hey, well done us!)\nI’ve been reading his newsletter, Reasonable People, which is all about the psychology of persuasion and rational argument. Subscribe/read it here. And I feel this topic is super relevant rn given the polarisation of opinion on many axes in society, and the paradox that\n\nthe drip-drip of extremist messages seems to be radicalising regular people very effectively, so minds are definitely amenable to change over time;\nYET try to get people to change or even moderate their position on something like left/right, gun/no-guns, Leave/Remain, or something even more emotive, and minds seem more fixed than ever.\n\nWhich means I feel like I understand nothing, so I want to learn more.\nWhat I did is ask Tom for a reading list: 3 books to give me a grounding in the psychology of persuasion.\nI’ll ask him to introduce himself first…\nHey Tom, tell us what you do?\n\nI work as a lecturer in psychology and cognitive science at the University of Sheffield. That mostly means I teach and research the basic mechanisms of learning and decision making, using experiments or analysing large observational data sets. I’ve got a side gig in trying to write about how psychology works, as a discipline, for a general audience. Recently I’ve been writing about the science of persuasion, argument and rationality for my newsletter.\n\nFind Tom on Twitter as @tomstafford.\nRead on for his three books…\n#1. Influence: Science and Practice, Robert Cialdini\n\nThere’s a tendency in psychology research to emphasise the quirks – the extraneous or small factors which influence us when they shouldn’t. I had an epiphany when I realised that the engine of this type of research is actually baked into the model of science which we follow: hold everything constant except one factor, run experiments to test how variation of that factor affects the outcome. For experiments on persuasion this means making the effect of rational argument - which is the same in all experimental conditions - invisible, and highlighting the effect of non-rational factors. This book is a great example of where that whole programme of research can lead you. \n\nInfluence: Science and Practice: Google Books / Wikipedia\n#2. The Expanding Circle, Peter Singer\n\nA counter-blast to the tradition in psychology which de-emphasises rationality. Includes an intoxicating account of how reason, once established, has its own internal dynamic – ideas generate new ideas; we’re driven to some conclusions regardless of what we originally intended or wanted. We adopt reason as a tool but, Singer argues, “Reason is no mere slave”.\n\nThe Expanding Circle: Google Books / Wikipedia\n#3. The Enigma of Reason: A New Theory of Human Understanding, by Hugo Mercier and Dan Sperber\n\nThis is the book which really started me on my current trip thinking about rationality. It is an apex example of how you do philosophy incorporating insights from evolution and experimental psychology, and it triggered a gestalt switch in how I thought about reasoning. Reading it made me realise how I’d been following the tradition in psychology which emphasised irrational factors over the rational, and which pushed the view that these quirks, biases and limitations are an overwhelming problem for our self-image as rational individuals. Mercier & Sperber don’t argue these irrational factors away, they show that there’s another, better, way of looking at them, one which considers reason as a property of interactions between individuals. Not only does this give you a whole, new, and productive, way of looking at the old evidence, it also create more space for optimism about our human capacity reasonableness.\n\nThe Enigma of Reason: A New Theory of Human Understanding: Google Books\nCan I just say that I am in love with the term gestalt switch.\nCheers Tom!\n",
    link: "/home/2020/07/03/keyboards",
  },
  {
    title: "Settling the Sun",
    date: "18.55, Friday 10 Jul 2020",
    content:
      "I ran across an interesting science fiction provocation… why not settle the Sun?\n\nOddly, though space colonization is a hugely popular topic in science fiction, I can’t find examples of stories set in this scenario, of most activity cramming close to the Sun.\n\nIndeed: most stories focus on activity moving in the other direction – inhabiting Mars or the moons of Jupiter.\nThe argument goes:\n\n… it seems to me that planet Earth has a lot more raw materials than it does energy. Our planet is huge; its energy is more limited. And raw materials can be recycled, while energy cannot. So my guess is that Earth will run out of energy long before it runs out of raw materials. Thus the main attraction of non-Earth locations, besides nearness to Earth, will be energy (and cooling). And for energy, the overwhelmingly obvious location is the Sun.\n\nThis also makes me think about the Sun’s deep gravity well. It take energy to lift material away from the Sun; it’s free to move material toward it.\nSo could we - in our speculative solar system spanning civilisation - have the Sun as the hub of the knowledge economy and the seat of Empire? Computer brains the size of mountains, floating in the honey of the chromosphere; turbines astride the free energy gradient driving endless cognition, artificial intelligences orders of magnitudes superior over anything else in the eight planets, running finance, planning the economy, and weaving computationally-expensive but material-light diversions: the arts, high-def luxury VR, parties…\nAnd, in this scenario, is the rest of the solar system basically the material feedstock for this celestial seat of decadent dominance, a 25th century British Empire, glittering wealth propped up by a vast extractive network taking labour and material from those who work in the dark?\nThe history of colonisation is one of resource theft and the erasure of humans and non-humans alike. I’ve used it here because it’s in the title of the article, but it’s not a word to be used lazily. See this previous reference to the ethics of space exploration.\n",
    link: "/home/2020/07/08/3_books",
  },
  {
    title: "Secret cyborgs and an old story",
    date: "19.21, Monday 13 Jul 2020",
    content:
      "Back in 2005, there was some controversy over golfers getting LASIK for better than 20/20 vision. Baseball pros too. 20/15 vision helps: Maddux, a pitcher for the Atlanta Braves, was 0-3 in six starts before his surgery. He won nine of his next 10 games. Kite had LASIK in 1998 and won six events on the Champions Tour over the next five years.\nIt’s hard to detect, and the rules don’t know how to deal with it (or at least, didn’t at the time):\n\nYou can’t use a device to warm the ball, but you can use it to warm your hands. You can’t use a device to measure distance or “gauge the slope of the green,” but you can get the same powers through LASIK. In the age of biotechnology, you are the device.\n\nFILE UNDER: cyborg enhancements.\nWhat gets me is that this story is from 2005. What’s the state of the art today?\nAbout 15-20 years ago, I was at a college reunion and got talking to a friend of a friend. I don’t remember the guy’s name, but he was a biochemist and doing his DPhil. I do remember that he had cochlear implants and he could turn a dial to hear better than I could at the party.\nOur bodies have two ways to consume energy (he said), carbs and fat. Carbs are great: quick release. But carbs take up a lot of space. Fat, on the other hand, is slow to convert to energy, but it’s dense: a drop of fat carries the same energy as an apple of carbs.\nI have no idea whether this is actually correct. I’m dredging up a story from almost two decades ago, and I barely remember it. The details are going to be all over the place, but broadly… \nWhat this researcher was working on was a new kind of artificial energy store for use in food, and it was quick-release like carbs, but dense like fat.\nAnd energy isn’t just used by your muscles. Remember it’s your brain too. What this researcher told me was that, in trials with rats in mazes, not only did the rats have more endurance, they were smarter too.\nI asked him whether he’d eaten any. He said, yes he’d snuck some, and it tasted really bitter.\nI remember specifically the current status: this novel food stuff was in human trials, and it was currently with the US military.\nThe early 2000s.\nOk, so he may have been bullshitting me. I have always been tremendously gullible, originally by nature and then strategically, deferring truth-assessment until the moment an idea or its consequences needs to be deployed, rather than at the moment I hear it. This broadens my imaginative space.\nBUT: maybe it was a true story?\nIn which case – what is that substance? Does it have a measurable effect? How has it been developed, two decades on? Who is funding the research?\nAlso about 15 years ago I went camping in the desert with some neuroscientists. They told me about a “fix” for macular degeneration where the no-longer-functional retina was replaced by a regular camera sensor. The sensor was plugged directly into the optic nerve, and amazingly the brain would learn to interpret the signal. The subject would be able to see again.\nDownside: the sensor output, being electrical and not electrochemical, would pretty soon entirely burn out the optic nerve, so - ethically - trials could only be performed on people who had macular degeneration and a terminal illness.\nBut every so often I hear about these sensors in the news, and go: hey, sounds like they’ve made progress.\nThen there’s CRISPR gene editing, and the occasional conspiracy theory that some state or another has managed to develop it further than is publicly known, and there are edited humans wandering around. Indistinguishable from other humans, but - maybe - stronger, or smarter, or able to see in the dark, or with inhumanly high charisma, or much better at golf?\nWhat would you do, as a country, if you had a dozen people who were smarter than everyone else? Would that make a difference?\nWhat is the current cutting edge in secret cyborgs?\n",
    link: "/home/2020/07/10/settling_the_sun",
  },
  {
    title: "Do humans have a north sense?",
    date: "20.14, Tuesday 14 Jul 2020",
    content:
      "Possibly we have a sense called magnetoreception which lets us tune into the earth’s magnetic field and know where north is. Birds can do it.\nMagnetoreception on Wikipedia: For animals the mechanism for magnetoreception is unknown and its existence is controversial.\nThere’s some scientific evidence from 2019 that humans can detect magnetic fields: when placing subjects in an isolation chamber,  among many participants, changes in their brain waves correlated with changes in the magnetic field around them.\nOR MAYBE:\nHumans are sensitive to polarised light:\n\nMany people are able to perceive polarization of light. It may be seen as a yellowish horizontal bar or bow-tie shape (with “fuzzy” ends, hence the name “brush”) visible in the center of the visual field against the blue sky viewed while facing away from the sun, or on any bright background. It typically occupies roughly 3–5 degrees of vision, about twice or three times the width of one’s thumb held at arm’s length.\n– Wikipedia, Haidinger’s brush\n\nThe blue cones in the eyes vary in sensitivity depending on their angle to polarised light, and they are arranged circularly around the centre of the eye. So when light is polarised, you get a situation where the cones at the top and bottom are reacting more/less than the cones on the left and right. Which is visible.\nPolarised light is interesting because light across the sky is polarised in a particular pattern depending on the position of the sun. See: the Raleigh sky model.\nNice tidbit from that article: \n\nIt has been suggested that Vikings were able to navigate on the open sea in a similar fashion, using the birefringent crystal Iceland spar, which they called “sunstone”, to determine the orientation of the sky’s polarization. This would allow the navigator to locate the sun, even when it was obscured by cloud cover. An actual example of such a “sunstone” was found on a sunken (Tudor) ship dated 1592, in proximity to the ship’s navigational equipment.\n\nSo maybe we unconsciously tap into a natural ability to sense polarised light, which is to say a sense of where the sun is, and so end up with a sense of north?\nBONUS LINK only for the fans who got to the bottom.\nDogs tend to poop aligned north-south. It’s probably because they’re sensitive to the earth’s magnetic field rather than polarised light. How do the scientists know? Because during magnetic storms, dogs poop any which way. \nReferences\nHart, V., Nováková, P., Malkemper, E.P. et al. Dogs are sensitive to small variations of the Earth’s magnetic field. Front Zool 10, 80 (2013).\n",
    link: "/home/2020/07/13/secret_cyborgs",
  },
  {
    title: "On speaking with dolphins",
    date: "17.32, Monday 20 Jul 2020",
    content:
      "I just read Extraterrestrial Languages by Daniel Oberhaus and a comment about dolphins made me blink.\nIn 1961, a group of 10 scientists met to discuss communication with aliens. The conference\n\nled to SETI – the continuing effort to search for extraterrestrial intelligence by listening for radio signals from stars\nwas opened by Frank Drake who presented the now-famous Drake equation – a framework for interrogating how many alien civilisations might be out there\nand included John Lilly who was making an earnest attempt to communicate with dolphins.\n\nFrom the book:\n\nLilly gained widespread recognition for his work through the publications of Man and Dolphin, in which he argued that dolphins may be as intelligent as humans and that communicating with them should be possible. Lilly ended up going to great lengths to speak to dolphins, including the questionable practice of injecting his cetacean subjects with LSD, but his attempts at interspecies communication were never successful.\n– Daniel Oberhaus, Extraterrestrial Languages\n\nThis Guardian piece has more about Lilly’s work:\n\nMan and Dolphin extrapolated Mary Lilly’s initial observations of dolphins mimicking human voices, right through to teaching them to speak English and on ultimately to a Cetacean Chair at the United Nations, where all marine mammals would have an enlightening input into world affairs, widening our perspectives on everything from science to history, economics and current affairs.\n– The dolphin who loved me: the Nasa-funded project that went wrong, The Guardian\n\nThe above article focuses on the Lilly’s assistant, a young woman, and the distinctly unethical goings-on in the lab.\nIt sounds like the human/dolphin sexual encounters garnered some media attention, and - on top of Lilly’s already unusual work, and the connection with aliens - dolphin communication made its way into public consciousness.\nHonestly I don’t know how I’ve missed John Lilly’s work.\nIt must have made a big impression. There’s often a throwaway comment in sci-fi of a certain era about a dolphin ambassador, or a “background colour” mention about a breakthrough in speaking with cetaceans. Of course this is the kind of thing that I recall reading but is impossible to google, so I’m looking over my bookshelf wondering what to pick up.\nIn Suzette Haden Elgin’s feminist/linguistics/science fiction novel Native Tongue (1984), which I’m now re-reading, one storyline includes language learning facilities (the “Interface”) clearly inspired by Lilly’s lab, and also the use of LSD.\nThe Embedding by Ian Watson (1973; here’s a long review) - which is excellent - is also filed on my shelves under: science fiction; linguistics; unethically dosing children with psychedelics. I can’t remember if dolphins feature, but I think I might read this one next.\nOkay so let’s pretend we could speak with dolphins. What would that mean?\nI mean, not everyone would be able to speak with dolphins. I imagine that, to me personally, speaking with a dolphin would not be particularly accessible. So all I would hear would be through magazine interviews, or TV, or reddit Ask Me Anythings. It would be about as distant as an interview with Elon Musk.\nThere would be a particular lobby that would want the dolphins to speak for the oceans, and there would be an environmental protection agenda. Would that make a difference? Knowing that there are (human) tribes in the Amazon doesn’t stop us from cutting it down.\nBut is that what the dolphins would say? Maybe they would want to share information about where to go for the best fish. Or make us laugh with dirty bubble limericks.\nI think that, without anything to trade, we’d run out of things to talk about. Without necessarily supporting a human agenda, what they said wouldn’t be reported. We’d forget that we could speak with dolphins at all.\nBy analogy: there are people who have extreme empathy with cows, but we don’t ask them about cattle farming. To them, cows can speak. See this paper about Temple Grandin and cattle empathy: Grandin’s biographies credit her autism with providing privileged access to bovine subjectivity … but do we, as a culture, pro-actively seek out oracles like this, and consult them about beefburgers? Maybe we should. Maybe we shouldn’t. But we don’t.\nAnyway.\n",
    link: "/home/2020/07/14/north_sense",
  },
  {
    title: "Sales pipelines, consultancy, and navigating the lockdown",
    date: "19.58, Wednesday 22 Jul 2020",
    content:
      "I gave a talk, right at the beginning of lockdown, about how to keep your business going when the context changes. a.k.a. perspectives I wish I’d had at various points over the last 20 years.\nOne topic was about how to find clients (or customers, or partners). I’d just had a 6 month project evaporate so this topic was very much on my mind – the project I’d been developing was in the 80% Likely bracket of my pipeline, and I had been enormously looking forward to it.\n(The talk was at the tail end of that 6 week period around April where literally all economic activity went on pause. It still bad now, but for that period is was zero and we didn’t know it was the tail end at the time.)\nThe sales pipeline is invisibly coupled to a wider context that you can’t see\nThe way I see it, when you’re building a company (and I include under that everything from startups to individual practices) you’re building two things:\n\nProduct\nA machine that lets you continue producing that product\n\nThat “machine” is usually about selling the product for money. I think about it as (loosely) a pipeline with four stages:\n\nMarketing\nDevelopment\nSales\nWork/product operations\n\nThe beating heart of a company is to perform activities to drive this machine. A pure software play with sales automation will have one set of activities. A consultancy will have another, such as:\n\nMarketing: you do talks, build your website, have coffees\nDevelopment: you discuss possible projects and figure out how to work together\nSales: you work with the organisation to confirm the project\nWork: you do the work, which may result in more projects.\n\nThese are the ACTIVITIES which appear to create results.\nBut here’s another way of thinking about it: the activities are only effective because they catalyse a pre-existing, active, INVISIBLE CONTEXT.\nWhat do I mean? Well, I’m thinking about my own boutique consultancy right now, Mwie Ltd, and when I think about what’s going on behind the scenes, there are stories like…\n\nI have coffee with a friend and I chat about my availability and interests. By coincidence, they have a separate conversation with one of their friends who mentions a project at their place of work which is just beginning. My friend puts us in touch.\nI have a series of meetings with a possible new client and we each share what we know about a particular strategy (for, say, new product development). By doing this over time, we develop a common language and also trust. When there’s a part of the strategy that I can take on as a project, the new client knows how to describe what I can do to their colleagues, and can go to bat for us to get budget approval. This happens through formal documents and informal conversations.\n\nThe invisible context is made up of these kind of conversations, existing business processes, my reputation, shared language, and so on.\nTo dig deeper, my “machine” broadly operates in two contexts:\n\nThe general context is my brand: how others understand my capabilities, cost, interests, and fit; my reputation; and the formal/informal conversations (among people I often don’t know) which propagate this.\nThe specific context is client organisations: what deliverables they require and the words they use to understand that; how budgets at different levels are allocated; the formal and informal methods of getting project approval.\n\nThese are active, vibrant contexts, and mostly out of my sight or direct control.\nIf my marketing and sales activities are successful, it’s because they are effective only within these invisible contexts.\n(One of the reasons it takes time to build a company is the machine and invisible networks need time to evolve together – and this happens often naturally, without having to give it much thought.)\nWhen the invisible context changes, the business machine may no longer be effective\nSo I hit a particular problem at the beginning of lockdown: I usually stay top of mind by having coffee with people, and I develop projects over a series of informal meetings.\nBut what happens when suddenly all conversations are happening over Zoom? And what happens when half my week is given to childcare (as emotionally delighted I am about that). I have fewer conversations. ALSO: my friends have fewer conversations. The serendipity part of the machine no longer functions.\nAnd how about developing projects? I used to build trust over lunch and whiteboards. Is trust built in the same way over Zoom? Who knows, maybe building common ground happens in a different way. And how about the goals of the work itself? What if I’m preparing the ground for the wrong kind of projects. It’s all up in the air.\nI refocused Mwie Ltd on its 5th birthday in November 2019, and now the machine is broken.\nStart from the beginning and have a beginner’s mind\nWhat what I did personally - and this is also what I said in my talk - is decide that I have to go back to the beginning.\nI can’t assume that any part of my business machine will work.\nAll I can do is begin at the beginning, and feel my way.\nWhat is the beginning? Awareness. I can do is talk about what I’m interested in and show that I’m available.\nAnd out of that, I can have conversations. And out of that, I can talk about work. And out of that, I can develop projects and figure out how to run them in the new normal. All from first principles; I can’t assume that anything I’ve done before is the right way to go now. I’ve done it before, I can do it again.\nSo that’s why I’ve been blogging. It worked, by the way.\nWHAT’S INTERESTING is the work that has been developed is in no way what I would have expected. And so the next task is to figure out how to generate this kind of work deliberately.\nWhat about Job Garden?\nI have two main things that keep me busy, in a work sense:\n\nMwie Ltd, my boutique consultancy as discussed above. Current clients: Google and McKinsey.\nJob Garden which creates portfolio job boards for investors, and launched its premium tier earlier this year.\n\nThe sales process for Job Garden is a whole different ball game than the consultancy, and I’ll talk about that another time.\n",
    link: "/home/2020/07/20/dolphins",
  },
  {
    title: "Spatial interfaces for conversations and software",
    date: "18.37, Thursday 23 Jul 2020",
    content:
      "Zoom* is pretty good for 5 people because it works as a single conversation, this being the canonical conversation group size with associated psycho-physical limits. And it’s pretty good at 150 because it works like a presentation. But it’s pretty poor for 25.\n* I reckon I’ll start using zoom as a generic for all group video calls, doing double-duty noun and verb, like hoover for vacuum cleaner/cleaning.\nSo what about 25 people? I’m excited about this new software MakeSpace because it tackles that problem in a fundamental way. As a participant, you place yourself on a 2D canvas, and then the sound is spatialised: if you’re near someone, you’re loud to each other; you get quieter when you’re further away. This allows for multiple simultaneous conversations and moving between them.\nMakeSpace also has some other powerful primitives like\n\nbeing able to drag documents and web browsers onto the canvas, so you can collaborate by gathering around an object.\nrooms are simply boxes drawn on the Flatland that keep the sound in, and this allows for labelling different rooms for different conversation, like a real world school or office.\n\nThe website has a ton of examples, clearly illustrated.\nMakeSpace isn’t yet open for general access. But if you want to give spatial interfaces a go as a way to socialise, both Online Town and Rambly are video chat webapps modeled on top-down old-school computer games with spatial sound.\nAnd don’t forget spreadsheet parties, as previously discussed.\nBack in August 2019, John Palmer wrote an illustrated review + concept paper on this topic: Spatial Interfaces. It is smart, idea RICH, and worth digging into:\n\nSuppose I work at a company and I want to find out, “Who is everyone at my company meeting with right now?” With only Google Calendar at my disposal, this task is a nightmare.\n…\nNow try to answer the same question with [2D virtual office software]. “Who is everyone at my company meeting with right now?” All of a sudden, it’s extremely easy. You just look at the rooms.\n\nPalmer’s follow-up piece, Spatial Software, in April 2020 has a ton of examples of real software. I’m especially intrigued about the spatial metaphor not as a way to socialise, but as a way of hacking memory and psychology.\n\nNototo is a spatial note-taking app. It lets you build an ever-expanding, topographical map containing your notes and writing. The app is designed this way to take advantage of another aspect of spatial interfaces: our brains remember spaces better than raw information. In this regard, Nototo is like a software manifestation of a memory palace.\n– John Palmer, Spatial Software\n\nThe physical world is baked deep into human cognition. It always amazes me that passing through doorways genuinely causes a memory lapse – but it shouldn’t amaze me because of course it does: Entering or exiting through a doorway serves as an ‘event boundary’ in the mind, which separates episodes of activity and files them away.\nWhich is only natural. Of course your brain wants to be fully prepared to absorb new information when you enter a new context, so it flushes everything that came before.\nAnd I mean, why not take advantage of our hard-wired physics of information to make software easier to use?\nANALOGY FOLLOWS +++ Our brains are similarly hard-wired to assume light comes from above, which is why shadows “underneath” cause 2D shaded shapes to pop (see #20 Fool Yourself into Seeing 3D in Mind Hacks). And this is why Susan Kare’s 3D button design in Windows 3.0 - in 1990! using only 16 colours! - was such genius. You don’t need to learn that’s a thing you can push. It just looks like a thing you can push!\nSo yeah. Dunno. Still thinking about space as an interface metaphor.\nA PAUSE FOR THE INTROSPECTION SECTION:\nI’m intrigued about personal spatial interfaces - like that note-taking app - but I’m not convinced. I’d like to try it.\nI don’t think I’d enjoy organising my notes on a map. I’m a highly associative thinker, but that doesn’t seem to me to happen visually. I mean – thinking hard appears to make use of my visual system: when I’m thinking hard about how to organise an essay, for example, I can’t see what’s right in-front of my eyes, so the two processes must be rivals for the same underlying grey matter. But the subjective experience of it isn’t visual.\nGenerally: I don’t see pictures behind my eyes unless I’m trying hard to imagine something, in the same way that I don’t have an internal monologue unless I’m planning how to write a sentence. So I would find an on-screen map-like organisation of my notes to be an interruption to my thinking somehow.\nBUT, I do seem to think spatially in at least some ways. When I’m writing a talk, I pull a half dozen books from my shelves and stack them next to me on the table or sofa. I might never consult them, but the proximity creates a kind of gravity of thought somehow? Maybe a self-imposed psychic style transfer?\nI guess my equiv for this in software is the way I paste loads of notes into the bottom of a doc before I start writing at the top? Proximity again. Abstract spatiality.\nMad Hatter:\nBack to how to have multiple simultaneous conversations and picking up again on audio – this time only barely spatialised.\nI remember running across a paper in 2003 about a prototype which did this automatically for telephone conference calls. In the following, “floor” is the jargon for a conversational group.\n\nIn face-to-face interactions in such social groups, conversational floors change frequently, e.g., two participants split off to form a new conversational floor, a participant moves from one conversational floor to another, etc. To date, audio spaces have provided little support for such dynamic regroupings of participants, either requiring that the participants explicitly specify with whom they wish to talk or simply presenting all participants as though they are in a single floor. By contrast, the audio space described here monitors participant behavior to identify conversational floors as they emerge.\n\nThe Mad Hatter system monitors the speech of all participants:\n\nif people are turn-taking, it assumes they’re in conversation, and mutually ups the volume;\nif people are speaking over each other, it assumes they’re not in conversation with each other, and mutually cuts the volume to 20%;\nit updates this assessment every 30 milliseconds.\n\nThe result is that multiple conversations can occur in parallel, and participants can move between them, on the exact same audio-only telephone conference call.\nIt would be intriguing to revisit this work in the light of the popularity group video calls in 2020.\nHere’s the paper:\nPaul M. Aoki, et al. The mad hatter’s cocktail party: a social mobile audio space supporting multiple simultaneous conversations. CHI ‘03: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, p425-432 (2003)\n",
    link: "/home/2020/07/22/sales",
  },
  {
    title: "How would I improve RSS? Three ideas",
    date: "19.40, Wednesday 29 Jul 2020",
    content:
      "RSS should be how we read our favourite content on the web. But it’s not.\nI was trying to figure out the other day how I would describe RSS and its history. Maybe something like… (Skip this section if you already know what RSS is.)\n\nRSS is a technology that lets you subscribe to new content on websites, just like you can subscribe to podcasts to get the latest episodes, or follow people on Twitter for their updates. It makes following and reading the latest content really easy. You need an RSS reader to subscribe to feeds (a reader is an app which is either downloadable or web-based).\nRSS was invented in 1999, and it’s not as popular as it once was. It was part of the explosion of blogs in the early 2000s, and blogs were symbiotic with the rise of Google and the web itself (because blogs were the best way to share new products and services before social media). But when Facebook and Twitter took off, blogs and RSS became less relevant, and when Google shut their reader app in 2013, that really took RSS out of the mainstream.\nYet RSS is still surprisingly popular. Peek beneath the surface of many, many sites and you’ll find an RSS feed that you can subscribe to. The RSS technology is incredibly simple and easy to implement for publishers, so it got added to everything in its heyday and never went away. But also RSS is provided by default for WordPress sites, and WordPress is the site builder for 37% of the web. Without WordPress’ support, I don’t think RSS would still be around.\nUsing an RSS reader is a little like using Twitter or Facebook, but where you’re totally in control. It’s the same in that you have a stream of the latest content. But unlike those platforms, RSS is decentralised. Nobody gets all of that data in one place, so nobody can use it to nudge your behaviour. There’s no algorithm inserting engagement-boosting posts. Content is only there if you subscribed to a feed. There are no ads except for the ads in feeds that you subscribed to. There’s no spam.\n\nOnce upon a time, the ecosystem around RSS was extremely rich. Almost all sites would provide a feed for their latest content, from the New York Times and the BBC through to the latest news for an artist’s portfolio site. And, because of that, there were RSS-specific search engines and even tools to manage “blogrolls” which is what we called a public list of subscriptions that you would put in the sidebar of your personal site – a bit like your list of follows on Twitter. Even browsers had built-in RSS readers. So much of that has gone.\nInstead we have engagement algorithms in social media walled gardens, notifications, and email newsletters.\nYet:\nMy sense is that RSS is having a mini resurgence. People are getting wary of the social media platforms and their rapacious appetite for data. We’re getting fatigued from notifications; our inboxes are overflowing. And people are saying that maybe, just maybe, RSS can help. So I’m seeing RSS being discussed more in 2020 than I have done for years. There are signs of life in the ecosystem.\nMy fear is that these signs of life aren’t enough for a real comeback.\nMy personal experience is that, after years away from it, I started getting back into RSS.\nI use the feed reader NetNewsWire (iOS/Mac) which is excellent and also free. It’s fast and simple. I also use Feedbin (which is excellent and cheap) which is a cloud service that can plug into NetNewsWire, and its sync subscriptions between my laptop and my phone. Additionally Feedbin lets me auto-forward email newsletters from GMail so I can see them alongside the regular feeds, which is a much saner way to read newsletters.\nI love it. Looking at the stats on my phone, in terms of hours per week, my top 5 social media apps are:\n\nTwitter: 4 hours (argh I’m an addict. I need to do something about that)\nReddit: 3 hours (I love reading advice columns and you can’t make me stop)\nNetNewsWire: 1.5 hours\nInstagram: 1 hour\nFacebook: 30 minutes\n\nAs of today I have about 160 subscriptions, and here they are on a single ugly page.\nIf you have a feed reader, you can subscribe to Interconnected with this feed. If you don’t have one, then do check out NetNewsWire (iOS/Mac) – and if you know of equivalently awesome readers on other platforms, please drop me a note.\nMy view:\nIt would be a good thing if RSS were more popular. When RSS is popular, it shifts the balance of power away from the social media platforms, which means that it doesn’t feed their ad targeting engines, or move people towards extremism. Plus it’s a less hectic, more egalitarian way to read.\nBUT, the user experience around RSS has some sharp edges, and there\nare missing pieces that mean that RSS is unlikely to return to the mainstream. A corporate-owned platform could fix these missing pieces; it’s harder for RSS with its decentralised model.\nIn that spirit, I’ve been thinking about how to improve RSS. Three ideas!\n1. Onboarding sucks\nIf you don’t know what RSS is, it’s really hard to start using it. This is because, unlike a social media platform, it doesn’t have a homepage. Nobody owns it. It’s nobody’s job to explain it.\nI’d like to see a website called something like what is rss .com which explains RSS, feeds, and readers for a general audience. Then provides download links to a couple of readers for different platforms with animations that show how to subscribe to feeds.\nThe site should be designed to be linked to from a small “what is this?” link next to every RSS feed on every site, maybe even customising the site for that feed.\nPerhaps I’ll built that site myself.\nBonus points: shift the language from “RSS” to feed and subscribe as these are more mainstream words (though still refer to RSS to provide continuity). And provide buttons for site publishers to use.\n2. Newsletters and the money thing\nThe “competition” for RSS is email newsletters. If RSS is going to get taken challenge email as a channel, it could use a few extra features:\n\nthe ability to go paid – Substack offers newsletter authors a platform with built-in free and premium tiers. It offers RSS, but it’s kinda janky: the premium RSS is a private feed address that the user needs to discover and add separately. Maybe the “Upgrade to premium” button could be inside the feed reader itself, and tapping it would seamlessly upgrade the feed?\nvirality and community – you can forward an email, and anybody you forward it to can subscribe from the footer. Likewise, you can reply to a newsletter and start a conversation with the author… which might even get rolled into future editions. These social features are great, and they should be built into RSS readers.\nanalytics like open rates and click counting. Yeah, RSS doesn’t need this, and email is moving away from it too.\n\nThe killer app of Feedbin (as mentioned above) is being able to receive email newsletters and have them appear as RSS. Maybe this a feature that hosted email clients like Gmail could offer – everything I tag “newsletter” could show up in a private bundle of RSS feeds which I can then subscribe to? (There’s another format called “OPML” which is how you could subscribe to a changing bundle of RSS feeds.)\n3. Discovery\nWhat social media does really well is help me discover new content. It does that by\n\nlooking at my behaviour and making recommendations of content or people\nmaking visible the behaviour of people around me.\n\nSo I feel like RSS needs something similar. Rebuilding my own list of subscriptions recently was a difficult process. I would love to see an (optional) service that provides a whole set of discovery RSS feeds…\n\nfrom my browsing: a local feed from my browser history about all the sites that I’ve encountered that have an RSS feed, together with a subscribe button, right there.\nsmart recommendations: a feed that suggests feeds that I don’t yet know about, based on my existing subscriptions (perhaps based on other people’s subscriptions, or maybe just by looking at the links in the posts across my subscriptions). I should be able to configure my reader to securely auto-upload my subscriptions to this service.\nfrom my existing contacts: a feed that suggests feeds from people I’m connected with on social media or my email inbox (it would crawl their social media profiles and look for feeds).\nrelated posts: based on posts that I privately favourite, or share on Twitter or email: related posts using some kind of auto-generated content graph.\n\nThis would put content and feed discovery exactly where I’m ready for it: within the reader itself. But - critically - without necessarily having to change the reader itself.\nWhat I wouldn’t do\nI wouldn’t do anything that changed the RSS protocol. It has wide adoption; there’s a ton of software to create and read RSS feeds. The foundation is here to stay.\nI wouldn’t do anything that forces adoption of particular app. Having premium feeds (for example) only work in one reader is a bit like having a premium email newsletter that only works if you switch email client. Ain’t never gonna happen. Anyway, the point of this exercise is to figure out how to grow the absolute number of users and publishers. That’s an ecosystem  play.\nSo the way to do all of this is 3rd party services and published UX patterns, all of which are usable without changing the reader apps – but if those apps chose to add integrations, the experience gets better.\nAnd what if it worked?\nThese ideas are a roadmap for someone. Any benevolent publishers out there?\nI have a ton of ideas of things to do in a resurgent RSS ecosystem. But those are thoughts for another day.\n",
    link: "/home/2020/07/23/spatial_interfaces",
  },
  {
    title: "More experiments with video calls, and what slides are for",
    date: "21.20, Friday 31 Jul 2020",
    content:
      "After my (slightly ludicrous) experiments with projectors and video calls I became pretty into the idea of having my face and my slides in the frame of a video call.\nSo!\nHere are some MORE pictures of what I’ve made. Check out that write-up page, the rest of this post will make way more sense if you do.\nBoth of these experiments are made using a virtual webcam setup - basically I’m using some software mainly used by video game streamers to intercept my webcam feed, and add extra elements to that video. The result is output as a virtual webcam that can be chosen as the camera in Zoom, Google Meet, or whatever you use.\nAs soon as I make something, I think of the 100 things I want to have next. That’s why prototyping is good. You don’t need to have much imagination, you just listen to what the prototype tells you.\n1. What if you could count with your fingers, and big numbers would appear on the screen?\nFor my first experiment, I made it so that when I sketch on my iPad, the sketch is overlaid on my webcam.\nThe particular interaction I tried is included as a video on that write-up page: I hold up one finger and draw a figure one; I hold up two fingers and draw a figure two; etc.\nIt feels like this would be a neat way to provide narrative “anchors” when giving a talk. Minimum viable chapter headings. Or maybe draw a quick diagram in the air when only a diagram will do, Pulp Fiction style.\n2. What if your regular slides appeared directly over your face?\nThis one is pretty simply but feels like it’s got some legs: I gave my regular slides a green background, which I then chromakey-removed and replaced with my face on the webcam.\nLike, I’m tracking what Mmhmm is doing because I like the idea of including my slides in my video feed like I’m a talkshow host. It’s still in beta and I’m fascinated to see where they take the service.\nBUT: fully blending webcam + slides, and designing for thumbnail view… that’s what I want. FOR EXAMPLE, what I found is:\nIt is neat to have MASSIVE TEXT over your face because it means that everyone in the audience can watch in gallery view - every face a thumbnail - yet your slides are still visible.\n(There are pics of all of these on that write-up page linked at the top of this post.)\nThis is like speaking to an audience but keeping the house lights up, and being on the flat instead of a stage. It’s a more egalitarian feel.\nYou can have lists that appear over your shoulder that provide structure during long sections; you can takeover the whole image with a quote to draw focus.\nAnd then there are some games to play: you can peep around the side of images that float in space. You can make faces at, say, a statement that undermines your point that you’ve deliberately included – as previously discussed it can be narratively useful to put yourself in the shoes of the audience by turning round and looking at a slide with them, reacting to it. And this is a way to do the same on a video call.\nThe system I made is pretty janky, but I’ve used it enough that I know there’s some creative potential I want to explore. Not just novelty but better storytelling.\n(And although this system used pre-prepared slides I also tried live slides - typing words directly into a slide and having it appear over my face, which I was on a call. That’s intriguing, though harder to manage.)\nI gave a talk on Tom Critchlow’s Discord to maybe 30 people, and it ended up being audio-only due to technical hiccups. It’s been a while since I spoke for 30 minutes straight, just my voice, no video. In that talk, I found myself wanting to be able to live scribe numbers in the air, to indicate where I was in a series of points. I wanted to play with my slides/webcam combo, and use the size of the type to communicate emphasis -= body language doesn’t work nearly as well over video as real life.\nSo I asked myself: when I’m doing a talk, what job am I really asking slides to do?\nI think I use slides as…\n\nvisual anchors – or rather running heads: the mini section titles at the top of every page in a magazine. People are often more comfortable when they have a sense of position and progress through a talk. Bonus: when people are watching the playback at 2x speed, this means the whole talk is easier to navigate.\nrhythm. Amazon once accidentally sent out a marketing email template with placeholder text, and it was a gold mine of copywriting tips. Top tip: Vary sentence length. It creates rhythm and engagement and without knowing it, the audience is carried along with you, and so it is for slides, just the same. It’s tough to do, using only your voice. But this is what slides are for! Quick transitions and slow transitions make a rhythm which can make a talk.\na playful foil. There’s you, there’s the audience, and there are your slides. They can support you, they can contradict you – and you can react. You can demonstrate the emotional response you want your audience to have, rather than explaining it. Or you can be quiet and let your slide speak for you, which can be deafening effective when done right.\n\nSure there are graphs and diagrams and images and long quotes, and all the other things that presentation slides have in them. Content.\nBut a talk needs to engage or the content won’t come across anyway. Talking for a long period of time, without a conversational back and forth, is pretty unnatural, and you have to do a bunch of work to stop people tuning out. That’s what I think slides are for – at least in part, and at least for me.\nWhat I’ve found, with this composite webcam feed, is that the slides can do a similar job for me as they do in real life - anchoring, rhythm, and play - while keeping my face full frame, not taking over the full screen, and not making it look like a pre-recorded TV show (which is distancing in its own way).\nI mean, I admit this is slightly, “ooh hark at me, I’ve re-invented the freaking WEBINAR,” but I enjoy public speaking, and it seems like there’s a route to a satisfying version of the same kind of thing only from my sofa – which is how I live now, a centaur: my top half on zoom calls and my bottom half, soft furnishings.\nSo I’m going to keep digging in this direction.\nOr rather… I’m going to try to fix my janky hacks so it functions for more than 15 minutes without accumulating up a very distracting and weird-looking 5 seconds of video lag..\nThe technical bit:\nI’m using OBS Studio to capture the webcam and mix it with other video sources. The obs-virtual-webcam plugin (for macOS) outputs the stream as a camera source that can be used in most video software.\nFor slides I use Deckset as it has a built-in feature that expands type to fill entire slides, and also because I can simply type into a text document to quickly make new slides while I’m on the call.\nTo capture the iPad screen I’ve been using AirServer to run an AirPlay server on my Mac, and that can direct video into OBS (add a Syphon source in OBS and choose your iPad once you’ve started screen sharing).\nIt’s all pretty slow – I have to close applications, quit my network monitor, etc, and the lag still builds up. I’d like to hear about ways of shortening the video path if anyone has any ideas. I want to continue having this appear as a virtual webcam so it works in all kinds of video call software.\n",
    link: "/home/2020/07/29/improving_rss",
  },
  {
    title: "A short ballet piece from Romeo and Juliet",
    date: "19.28, Tuesday 4 Aug 2020",
    content:
      "I think probably the most beautiful thing I’ve seen in the last few months (and not just because I’m culture-starved) is this 4 minute 39 seconds video on Instagram:\nA short piece from Romeo and Juliet from Ballet Opera de Paris.\nIt was published in mid April, shot in the lockdown deeps. It’s all in portrait mode. You see the dancers’ own homes – which is part of the privilege and intimacy, I think, to see who is in an apartment; who has their own studio; who is simultaneously wrangling their kids. Woven together with Prokofiev’s music, of course.\nI just wanted to share that.\nI saw Romeo and Juliet at the Royal Opera House in London in 2015, my first time seeing the ballet. In my life, I reckon I’ve probably seen, read, studied, or performed parts of that play maybe… 20 times? Including one decent-length section re-enacted loudly with friends, from memory, at a party. WE KNEW HOW TO LIVE WHEN WE WERE 15. You get a lot of Shakespeare growing up in the UK.\nI have a faint memory that both R & J were the young understudies, the regular performers both ill.\nI have a strong memory that this was the first time I had ever truly understood Juliet’s torment and decision, and her real understanding of the weight and consequences of that decision. What a performance!\nThere’s something odd about growing up with a play, especially a great one, is you can kind of take it for granted. Yes of course it makes sense, yes yes yes, it’s a good story, that’s what they do, yes fine.\nBut then, after seeing, reading, studying, and/or performing it 20+ times (who can say), to be watching this story written 420 years before, to suddenly see these people as people, and for the first time to truly understand and believe and feel and, what’s more, agree with their emotions and actions – I’ll never forget that. It was like I was seeing it for the first time, and as personal as hearing a story from a close friend. The actual moment of Juliet’s torment: the choreography was such that she was alone on the stage, not dancing, just sitting and staring at the audience, and you could see her whole body tortured and clear-eyed deciding what to do. It’s etched into my mind’s eye, and my breath catches when I think of it.\nAnd for it to happen with ballet, where there’s no pretense at realism… well it’s a reminder that verisimilitude is not the be-all and end-all I suppose, and that the classics are the classics for a reason, and that I ought to seek out more ballet when this is all over.\n",
    link: "/home/2020/07/31/more_video_experiments",
  },
  {
    title: "The serendipity machine, and what is Job Garden anyway?",
    date: "19.24, Wednesday 5 Aug 2020",
    content:
      "Last week I added a book a call link to the homepage of my consultancy site – keeping open a few 30 min slots every Wednesday for informal chats.\nMost of my projects have emerged from serendipitous coffees and people emailing without necessarily knowing the way I work. Most of my most brain-buzziest conversations too.\nInformality is tougher during lockdown… perhaps this is a way of keeping an open door despite everything? Anyway, if you fancy a chat, here’s the booking link. \nI think of it like building the serendipity machine and I’ll report back in a month or so with how it’s going.\nAnd this afternoon I had my first two calls!\nI caught up with old friend Simon Willison (who, I have just discovered, has his own Wikipedia page). \nAnd it turns out we follow along with each other’s projects by each reading our respective blogs, obv, so he’s fully aware of my aggregated-job-boards service thing Job Garden, as previously (but infrequently) mentioned here.\nBUT, Simon was totally unaware of who Job Garden is for, mainly because that’s changed in the last few months, and specifically because I haven’t talked about that change except on the JG homepage. Probably because I mentally categorise this place, Interconnected, as my public notebook for whatever’s going through my head, rather than a place for, y’know, MARKETING, which would be the smart and proper thing to do.\nAnd, for me, it was one of those facepalm moments of “um, why haven’t I talked about that?” which is exactly why I need this random-video-call-powered serendipity machine, because it turns out that - when I don’t have conversations with actual humans on the regular - I miss some sooooper obvious stuff.\nSo let’s rectify that right away:\nWhat is Job Garden anyway? A belated explanation.\nJob Garden builds and maintains portfolio job boards for investors.\nVCs want to help the startups they invest in with their hiring.\nThey can do that by pointing attention at the open jobs. VCs often command a lot of valuable attention with a Twitter following (either as an organisation or individual partners), or similar on LinkedIn, or with an email newsletter.\nSo at Job Garden, we have a custom web crawler that pulls the latest opportunities direct from the public careers pages of startups. We tag and geocode the jobs.\nAnd, from that, we create aggregated job boards.\nFor example, here’s jobs.unreasonablegroup.com (we also support custom domains).\nUnless the VC has a lot of organic traffic to their own website already, a web-based job board is only half effective. So on top of that, we provide:\n\ntools to automatically get the word out on social media and in the VC’s own email newsletter\ntraffic analytics – to check that targeted attention is hitting the mark\nplus live insights into hiring activity, such as “hey, this company is hiring in Sales for the first time, maybe go lend a hand.”\n\nThe basic package for a VC is free. There’s also a premium tier.\nAll of which is to say: if you’re an investor, do get in touch because I’m sure we can help. And if you run into any investors, please let them know about Job Garden.\nAnd now back to your scheduled programming.\n",
    link: "/home/2020/08/04/romeo_and_juliet",
  },
  {
    title: "Rainbow spacecraft and how humanity might end",
    date: "19.32, Thursday 6 Aug 2020",
    content:
      "I’m a proud member of the British Interplanetary Society so I go to lectures at the HQ in Vauxhall from time to time, and every month I get the latest edition of their academic journey, JBIS, through the letterbox.\nYou should be a member. As a taster, I’ve put the table of contents of the latest JBIS on my Instagram, and I’ll type it out here too:\n\nGeneral Interstellar Issue\nProtocols for Encounter with Extraterrestrials: lessfroms from the Covid-19 Pandemic\nWater and Air Consumption Aboard Interstellar Arcs\nHabitability of M Dwarfs: a problem for the traditions SETI?\nOn a Spectral Pattern of the Von Neumann Probes\nReworking the SETI Paradox: METI’s Place on the Continuum of Astrobiological Signaling\nDynamic Vacuum Model and Casimir Cavity Experiments\n\nGood stuff!\nIt’s a bit of an oddball institution. JBIS is always delivered late, and it all feels a bit fuddy-duddy and old white guy, then suddenly there’s a remark in a lecture about asteroid mining being commercially viable in 2046 and somebody in the audience from BAE or Lockheed or similar stands up and says, actually we’re using 2044 in our planning.\nAnd they also did the first ever engineering study of an interstellar mission, back in 1973-78, and that became the foundation for everyone else’s work since. The list of space projects BIS has influenced is staggering.\nIt’s the conversations over lunch.\nAt an event a few years back, I bypassed the sandwiches and honed in on some particularly intense looking chocolate cake, and accidentally got talking to a guy who it turned out specialised in existential risks to humanity. So I asked him to tell me his favourite way that humanity could end. In the event, he gave me two.\nFirst, we could get hit by an exotic particle, called a strangelet I think (it was a long time ago, I only half remember). It would be a quirk of physics and the effect would be that the Earth would get converted into a cloud of more strangelets in about a millionth of a second. So that would be that and we would never know.\nSecond, he said, there’s a type of apocalypse called something like the economic zombies scenario and it was problematic for him because he felt we were on that track, and it was inevitable.\nThe short version is this, as far as I can recall:\nThe history of humans and technology is that we outsource human functions in the name of economic efficiency. Don’t dig by hand, get a spade. Don’t do mental arithmetic, get a calculator. Etc.\nSo the logic of that is hard to escape. Imagine two communities. One chooses to adopt technology, the other doesn’t – perhaps because they have anticipated this outcome and are trying to avoid it. In the long term, the community that outsources and adopts the technology will out-compete the one that doesn’t.\nOn and on it goes. Until eventually we can see that the final impediment to efficiency is consciousness itself. So we end up outsourcing our individual planning and decision making, taking the human out the loop. Brain implants or some such.\nAt each stage of this, the next step is logical and inevitable. We’re on the road.\nWhat this guy said is that if you then visited this future Earth, aliens visiting in a spaceship, say, what you would see is a planet of billions of humans, a hive of activity, doing exactly what we do now but with verve and incredible efficiency – and dead behind the eyes.\nEconomic zombies. The end.\nANYWAY.\nJBIS. Sometimes the academic papers have an unexpected poetry.\nThere’s a paper from 2018 that has stuck in my head ever since.\nAs background, there’s a way to propel probes called a solar sail – essentially a giant, reflective sail, unfurled when the probe is sufficiently far from anything else. As sunlight hits it, the probe accelerates… just a touch. In space, there’s no friction to slow you down. So the probe gets faster and faster… It’s slow to get going but incredibly efficient because the probe doesn’t have to carry its own fuel.\nSo! This paper says that, instead of reflecting the light, it can be diffracted – photons split into component colours as they pass through the sail instead of being reflected. And that provides momentum, which is neat and the point of it. The paper is called Flying on a Rainbow - A Solar-Driven Diffractive Sailcraft.\n\nAbstract: Radiation pressure afforded by natural broadband sunlight upon a transmissive diffractive sail is theoretically and numerically investigated. A grating period of one micrometer is found to convert 83% of the solar black body spectrum into sailcraft momentum. Non-optimized orbit-raising trajectories for diffractive and reflective sails are compared. Potential advantages of diffractive sails are also described.\n– Grover A. Swartzlander Jr, Flying on a Rainbow\n\nThe advantages: photons both propel the craft but can also, after they pass through, charge photovoltaic cells. So light does double duty. Second, the sail can also alter direction opto-electronically (rather than having to physically shift the whole thing, which is hard because solar sails are vast).\nBut but but. The image of it all.\nA populated, far future solar system - the planets and the asteroids teeming with life in its infinite variety - but each only a tiny dot in the vast and deep dark gulf of space.\nBetween these outposts, we can imagine hairline necklaces around the sun, barely curving transfer orbits – optimal arcs from one oasis to the next, set by celestial mechanics and gravitational potential.\nAnd along these invisible paths, discernible only through the eyes of mathematics, against the black desert of space: continuous trains of spacecraft, their movement barely visible at this distance, fragile metal habitats and cargo ships each at the centre of their own football-field silk-thin sail, tacking on sunshine, and that, when you look through it, diffracts the sun and the stars behind into dazzling rainbow shards.\n",
    link: "/home/2020/08/05/serendipity_machine",
  },
  {
    title: "If I got made king of web browsers, here’s what I’d do",
    date: "13.41, Friday 7 Aug 2020",
    content:
      "It’s hot and it’s lunchtime, so let’s pretend I’m in charge of major global technical infrastructure! \nI wrote about how I would improve RSS the other day (because being able to subscribe to text is super neat, but it’s so arcane compared to smartphone apps). And after writing that, it occurred to me that the problem is wider:\nThe user experience of the web itself sucks.\nIt is less pleasant to use a web browser than it is to use apps. But that’s because the browser-makers (Google and Apple, primarily) have silently abdicated their responsibility to make browsing good. I get it, they’re conflicted, they’re also running super profitable app stores.\nAnd also, I guess, because browser-makers tend to be engineers, so they do engineering-type things like making the browser an app-delivery platform able to run compiled code. Or fight meaningless user experience battles like hiding the URL, or hiding View Source – both acts that don’t really help early users that much, but definitely impede the user path from being a consumer to being a fully-fledged participant/maker.\nYou know, and also making humble improvements to the web is unglamorous? It’s hard to measure. It might never be noticed. It’s probably not going to get you your next bonus. Perhaps that’s it.\nSo what would I do? I would focus on\n\nthe humble yet meaningful – nothing huge like changing the way the web works. Don’t be revolutionary. But also, no more futzing and tinkering like tweaking the way CSS works.\nimproving what’s already there – it’s fine to add brand new capabilities like being able to talk to external hardware, or peer-to-peer video. But the foundations are crumbling. Look at what’s broken and shore it up. Pave the cowpaths, and all that.\nthe user experience – so much browser effort goes into making things easier for developer, and primarily the developers of crazy high traffic sites. But who cares. Software engineers get paid a fortune, let them sing for their supper. If developer experience matters that much, focus on the long tail of really simply websites instead.\nbrowsing not apps – this is a rebalancing, but it feels like recent-ish features like “pinned tabs” etc are about making the web browser a place for web apps. What about reading and writing?\nmaking change happen – every improvement carrot needs to be paired with an encouragement stick.\n\nSpecifically? Here are three ideas to start, totally off the top of my head.\n\nNewsletters. I get bombarded by newsletter signup pop-overs whenever I go to a website. Browsers should block these, they suck. BUT instead there should be a button in the browser toolbar to sign up, and it should glow when available. And the blank “new window” screen should list all the websites I’ve encountered in the last 24 hours with newsletters (with screenshots), and a quick subscribe button for each.\nForms. A web browser should never, ever, ever forget something I type into a form. Too often I go to write something long, and the page doesn’t submit properly, or I accidentally hit back, and I lose it. Or I write an email into a contact form, and never get a copy. Browsers need the equivalent of Drafts and Sent folders.\nVirality. Like it or not, many websites live and die by how much individual pages are shared. The web was successful in the first place because URLs were easy to copy and paste into email… but we can do better now. There’s a Web Share API (technical docs) which pops open the standard share sheet on mobile, but it’s kinda neither here not there. Instead the browser should have social media share icons built in, and APIs to those platforms so the buttons can show a count of how many times the page has been shared. In short, browsers need excellent retweet and fwd buttons.\n\nOr, or, or!\nMove the “home” button and the sitemap into the address bar! Let webpages have a standard and exciting way to suggest related articles! Make Bookmarks and History properly smart (highlight my daily visits, for example) and add them as folders on my smartphone home screen! Embrace the trend of personal wikis, and also hypertext and protocols like Quotebacks. More bonkers ideas? I’ve got ‘em: Making Senses, a presentation from 2006.\nAnd then just keep on implementing ideas like that. Find something that sucks. Make the experience better. Repeat 100 times. In two years, look back and see how far we’ve come.\nHey, here’s a bonus idea but it’s a tough one: Google Apps for everything. The experience of writing a Google Doc is awesome. Seeing other people’s cursors, live changes, suggested changes that can be approved/rejected; it’s robust to dropping offline, there are both anonymous and signed-in users, etc. This should be something that any website can do. Sites should be able to identify a user, provide a collection of user handles by whatever method they choose for the collaborating group, and the browser should do the rest.\nWhat I don’t want is for this to lead to a sameness of the web. Websites really are beginning to look the same and that’s a shame. As Benedict Evans put it in his newsletter: maybe this is the same as the way wind tunnel data made all cars look the same.\nRather: provide optional architectures for websites that are good for site users and good for site creators too. Make that space. Make it crazy easy to develop in. Then get out of the way.\nThere’s probably no immediate commercial reason for this humble kind of work. But the web is the commons of the internet. Looked after, it’s a renewable resource of new ideas and approaches that don’t fit prevailing economic models – and also the one place on the internet that is friendly to history. We mustn’t lose it.\nThere are people looking at how to completely change web browsing. How to make it social. How to including payments, or publishing, or whatever. Brilliant. Let them. Meanwhile, the web we’ve got is a mess, and we’ll never to these new ideas if the centre doesn’t hold.\nSo who’s looking at this? Is there a team in Chrome and a team in Safari advocating for the experience of the web, as the web, or does this need to come from somewhere else?\n",
    link: "/home/2020/08/06/bis",
  },
  {
    title:
      "The holy founding text of The Church of the Next Word, as revealed to Frank Lantz",
    date: "21.12, Monday 10 Aug 2020",
    content:
      "GPT-3 is an artificial intelligence that has been fed all the text on the internet: the entirety of the English Wikipedia, spanning some 6 million articles, makes up only 0.6 percent of its training data.\nGiven a prompt, it’s really really good at suggesting what text should come next… whether that’s answering questions, creating a recipe, drafting a legal document, or writing code. It’s not always right, and it’s often very weird (well, think what you would say if your source for truth was every single word on the internet), but it’s insanely plausible.\nLike, amazingly plausible. An order of magnitude more plausible, on a much smaller prompt, than anything that has come before.\nThe Verge has been collecting examples of GPT-3, which is worth a read for the breadth of it: \nOpenAI’s Latest Breakthrough is Astonishingly Powerful, but Still Fighting its Flaws\ntl;dr? Janelle Shane’s posts give a more accessible taster: But how much knowledge has the API really picked up? Could it be used as an all-purpose question-answering machine? I tested it fairly unscientifically by prompting it with the following: How many legs does a horse have?\nAnd so:\n\nQ: How many legs does a horse have? \nA: Four. You don’t count the horse’s nose as a leg.\n\nWhich is… odd. And then:\n\nQ: How many eyes does a horse have? \nA: 4. It has two eyes on the outside and two eyes on the inside.\n\nUm. For more check out Shane’s All your questions answered (about GPT-3) over at A.I. Weirdness.\nHere’s another way into thinking about authoring with GPT-3: what if it’s not like instructing someone to write, as the “prompt” interface implies, but more like thinking really hard. Only a kind of thinking that you can tune to have great creativity (that’s a GPT-3 parameter) or great recall, or to fill in with a particular style, or whatever.\nWhat if it’s so close to your fingertips that using feels a bit like stretching for the right words, or thinking for the right phrase… just like power steering and cruise control feel like driving?\nMy mental model of authoring with GPT-3 is akin to those musical cyborgs I talked about the other day.\n(Although, admission time, I haven’t tried it, and I understand that GPT-3 is still pretty slow to respond.)\nA better example: Robin Sloan’s incredibly prescient 2016 essay Thinking With the Machine in which he built a text editor for writing with responsive, inline ‘autocomplete’ powered by … old sci-fi stories.\n\nThe rings of Saturn glittered while the [tab autocomplete] two men looked at each other.\nThey were enemies, but [tab autocomplete] the servo-robots weren’t concerned.\n\nBingo. Imagine that… for everything.\nReading GPT-3’s output, for me, feels like dowsing the collective unconscious. I’ve never seen anything so Jungian.\nPrompt and [tab autocomplete] GPT-3 emits the gestalt opinion of humanity, as expressed through its collective written culture; written with care and consideration, written off the cuff, written with anger, written drunk, written without concern for truth; every letter of every word every written each weighed and counted.\nI imagine a future discipline of Experimental Jungists, probing inner space by constructing future GPT-Xs like our generation’s particle-smashing hadron colliders, firing their prompts into greater and greater databases of aerosolised culture, attempting to discern - in the resultant short-living memetic showers - ever more fundamental archetypes that make up the human psyche.\nSpecies-memory inscribed in ascii. If you subscribe to the idea that there is some kind of truth in averages you will find what you’re looking for in GPT-3.\nSo what should we think of GPT-3?\nGiven the above, the only way to know is to ask it.\nWhich is what Frank Lantz did. (Lantz is, amongst many other things, the game designer behind Drop 7 which was the first great mobile game. Play Blitz mode. My high score is 784,182.)\nHis prompt to GPT-3:\n\nThe following is the first sacred text of the Church of the Next Word, a secular religion that originated in 2020 inspired by the language prediction model GPT-3. …\nThe following is the Church of the Next Word’s holy founding document, the 10 principles:\n\n…and then he let the A.I. write the rest.\nHere’s Lantz’s tweet with the result.\nWhat genius to ask! But tweets are horribly ephemeral, so I’m going to transcribe the 10 Holy Principles of the Church of the Next Word right here, because sacred is sacred and these words shouldn’t be lost to the timeline.\nAgain, what follows are not my words, this is what GPT-3 said, prompted by Lantz. Or rather: this is the collective unconscious of humanity, put into words by the algorithm.\nOr rather: here follows the revelation to Frank Lantz.\n\nWords are things\nCorrectness is the beginning of sanctity. To achieve it is to be rewarded.\nWordhood and nowness are its rewards.\nA new day is not jut the word of God, but the work of human agents. Those that do not understand this, that refuse to be challenged, that do not know how to err, that want to shirk from their duties, must be cast out.\nWordplay, playfulness, and humorous are the harbingers of truth. When you eliminate the possibility of playfulness, you remove the possibility of learning, and that leads to banality, brutality, and destruction.\nTo find or see a flaw is to find a pathway to the truth, if you can overcome your fear of being laughed at or of looking foolish.\nLanguage contains the map to a better world. Those that are most skilled at removing obstacles, misdirection, and lies from language, that reveal the maps that are hidden within, are the guides that will lead us to happiness.\nLong words that end in -ize and other abstractions are the rocks that will impede our journey. They should be replaced with concrete, specific, evocative words.\nThe data points on the graph of your life – the moments you spend awake, asleep, speaking, silent, moving, resting, focused, distracted – will determine the shape of your time. Keep an eye on the volume and quantity of your moments. Make a record of your life as a way to keep track of your progress towards a better self.\nLanguage and its construction is the greatest human power. To unlock it is to unleash our potential, and to master it is to become divine.\n\nRemember: no human wrote those words.\n",
    link: "/home/2020/08/07/web_browsers",
  },
  {
    title: "Like, just a post complaining that screens should be better",
    date: "19.45, Tuesday 11 Aug 2020",
    content:
      "Given how many screens there are, you would have thought there would be more new stuff.\nIt’s been 20 years since Apple shipped the Mac OS X Aqua interface, with all its reflections and transparency – the one Steve Jobs called lickable.\nSo where’s my operating system which has a physics engine plugged in? One that moves the reflections along with the time of day, making the on-screen light source travel with the sun?\nIt’s been 19 years since Pixar released Monsters, Inc. with all that CGI hair. Where are my hairy icons? Ones that get all long and knotted as the notifications number goes up.\nWhy can’t I feel my phone? I found that paper from 2010 (when I was complaining about keyboards) about using precision electrostatics to make artificial textures on touchscreens.\nI should be able to run my thumb over my phone while it’s in my pocket and feel bumps for apps that want my attention. Touching an active element should feel rough. A scrollbar should slip. Imagine the accessibility gains. But honestly I don’t even care if it’s useful: 1.5 billion smartphone screens are manufactured every year. For that number, I expect bells. I expect whistles.\nThere are probably all kinds of reasons why screens are basically sharper now and that’s it. Lack of competition. Developers wouldn’t support it. Whatever. Cars were better when they had fins. They don’t have fins now and they aren’t as good, I’m not interested why. What’s the point of technology if we’re not going to have fun with it.\nThe Nintendo 3DS came out in 2011 with a lenticular layer on the screen that allowed everything to be slightly 3D. Autostereoscopy. It was awesome for 3D photos. Almost a decade later – surely this should be on tablet computers now and really really effective? Imagine the medical imaging applications.\nWhy are we stuck with only three pixels for red, green, and blue? Why isn’t there a fluorescent yellow pixel to make alerts really pop? If we don’t play we won’t find the uses.\nIn 2012, iOS 6 had metallic buttons with faux reflectivity. It’s 8 years on. Why isn’t there a fourth pixel, and the fourth pixel is a mirror? Come on people it’s 2020.\n",
    link: "/home/2020/08/10/the_church_of_the_next_word",
  },
  {
    title:
      "Introducing aboutfeeds.com, a Getting Started guide for web feeds and RSS",
    date: "14.27, Wednesday 12 Aug 2020",
    content:
      "There’s a better way to read websites and it’s called web feeds a.k.a RSS. But web feeds are hard to get into for new users, so I decided to do something about it.\nI posted about suggested improvements to RSS the other day and top of my list was onboarding: If you don’t know what RSS is, it’s really hard to start using it. This is because, unlike a social media platform, it doesn’t have a homepage. Nobody owns it. It’s nobody’s job to explain it. I’d like to see a website … which explains RSS, feeds, and readers for a general audience.\nSo because it’s no-one’s job, and in the spirit of do-ocracy:\nI built that website.\nOr to slightly abuse a phrase, Be the change that you wish to see in the world wide web.\nIntroducing About Feeds\naboutfeeds.com is a single page website, for linking wherever you keep your web feed.\nIf you go to the homepage of this very blog you’ll see a header on the left that says “GET LATEST POSTS”. Next to that is a link that says “FEED.” As we all know, that link is broken unless you have a newsreader app installed. And so next it is a new link that says: HELP! WHAT IS A FEED?\nAbout Feeds is written for a general audience. The sections are:\n\nA short intro\nWhat is a feed? (a.k.a RSS.) - overview and benefits\nHow do I get a newsreader app? - with suggested apps\nHow do I use my new newsreader app to subscribe to a feed? - instructions!\n\nI’ve adopted the word “feed” (or “web feed”) and said that “RSS” is the technical name for it. I want to balance being informative yet approachable.\nAs I say on the site:\n\nMy hope is that About Feeds can become the default “Help! What is this?” link next to every web feed icon on the web. It’s bare bones right now, and I have a ton of ideas of how to make this site more and more useful.\n\nIf you have feedback/ideas, the About Feeds repo on GitHub is the right place to start a discussion. It’s a work in progress.\nDo you write a blog or run a site with a web feed?\nPlease consider adding a Help! What is this? link (or similar) next to your feed link or RSS icon.\nBig up the RSS massive\nFor us bloggers and site owners, RSS is important because it’s the how we keep the indie web work healthy. Feeds make a level playing field for brand new blogs and the New York Times alike. It’s our direct route to readers, without making them give up their email address or personal data. And it’s our hedge against Facebook and the social media silos which make you pay for access as soon as you get popular.\nFor users, RSS puts you in control. You see all the content, and if you don’t like a feed you can unsubscribe. It doesn’t clutter up your inbox. Opening your newsreader is 100x a better way to spend your time than doomscrolling on Twitter. It’s a pleasant reading experience.\nSo I think web feeds are worth fighting for.\n",
    link: "/home/2020/08/11/screens",
  },
  {
    title: "Filtered for small groups",
    date: "20.16, Tuesday 18 Aug 2020",
    content:
      "1.\nJames Mulholland has been investigating the small group:\n\nLying somewhere between a club and a loosely defined set of friends, the SMALL GROUP is a repeated theme in the lives of the successful. Benjamin Franklin had the Junto Club, Tolkien and C.S. Lewis had The Inklings, Jobs and Wozniak had Homebrew. The Bloomsbury Group was integral to the success of Virginia Woolf, Clive Bell, and John Maynard Keynes, while MIT’s Model Railroad Club spawned much of modern hacker culture.\n– James Mulholland, The Small Group\n\nIt’s a crucible for exploration and creation… but this isn’t a team on working on a single project together. It’s about independent work and feedback. Says Mulholland: An ongoing relationship provides more effective advice, allowing the use of shorthand for concepts and a two-way conversation that autodidactic education lacks.\nHe asks: What is the SMALL GROUP for the 2020s? – and gives some boundaries: around a dozen members; mutual accountability on personal projects through regular presentations.\nIt’s a powerfully engaging question.\n2.\nHere’s Kevin Kelly on Brian Eno’s concept of Scenius, or Communal Genius: Scenius stands for the intelligence and the intuition of a whole cultural scene. It is the communal form of the concept of the genius.\nKelly lists some success factors:\n\nmutual appreciation (scenius as peer pressure)\nrapid exchange of tools and techniques\nnetwork effects of success (successes are claimed by the scene, not the individual)\nlocal tolerance for novelty (the scene doesn’t have to fight its environment)\n\nKelly is, as ever, incredibly smart. And goodness, I recognise those factors from various communities and even small and big companies.\nTo use slightly different terms, mutual appreciation is a healthy jealousy without envy – a drive to achieve the same but without wanting to take it from the other.\nThat feeds the mutualisation of success, which becomes a kind of co-marketing: a rising tide lifts all ships.\nAnd the rapid exchange of tools requires two things: highly efficient communication (openness and forums to be open in); and a non-proprietorial attitude to tools and ideas because execution is what matters.\n3.\n\nLOS ANGELES – Hype House, the physical location of a new content creator collective, is a Spanish-style mansion perched at the top of a hill on a gated street in Los Angeles. It has a palatial backyard, a pool and enormous kitchen, dining and living quarters.\nFour of the group’s 19 members live in the house full time; several others keep rooms to crash in when they are in town.\n\nThat’s from The New York Times, Hype House and the Los Angeles TikTok Mansion Gold Rush.\nMore:\n\nSo-called collab houses, also known as content houses, are an established tradition in the influencer world. Over the last five years they have formed a network of hubs across Los Angeles.\n\nAnd some detail:\n\nCollab houses are beneficial to influencers in lots of ways. Living together allows for more teamwork, which means faster growth.\nA good collab house has lots of natural light, open space and is far from prying neighbors. A gated community is ideal, to prevent swarms of fans from showing up.\nAnd if you want to be a part of the group, you need to churn out content daily.\n\nManufactured scenius.\n4.\nClay Shirky’s classic essay from 2005, A Group Is Its Own Worst Enemy (pdf), on software for groups.\nShirky channels the psychoanalyst Wilfred Bion who specialised in groups in the mid 20th century.\nBion’s realisation was that social groups have their own mentality, a kind of mind which is connected to but also separate from the individuals.\nBion then goes on to detail three basic assumptions that the group mentality can fall into (as fundamental as any of the mental states like exuberance or fight-or-flight that we can fall into an individuals).\nShirky’s words:\n\nThe first is sex talk. (imo Shirky’s not quite on the money interpreting Bion here, but close enough)\nThe second basic pattern that Bion detailed is the identification and vilification of external enemies.\nThe third pattern Bion identified is religious veneration – any closely-held tenets of the group will do, not necessarily those of an organised religion.\n\nWhat a successful group does (says Bion) is weave together these three basic assumptions so that they’re no longer dysfunctions (which is what each becomes if left to dominate) but instead providing a foundation for productive work.\nShirky brings Bion’s work to life. It’s an essay very, very much worth a read/re-read (delete as appropriate).\nBonus link: my own stream of consciousness 2015 essay, Small groups and consultancy and coffee mornings.\nI find myself circling these topics, and thinking about technology and its role and how we’ve really screwed that up, and about Bion and his wonderfully emotional approach to groups, and asking the same question that James Mulholland asked at the top of this post: What is the SMALL GROUP for the 2020s?\n",
    link: "/home/2020/08/12/introducing_aboutfeeds",
  },
  {
    title: "We already have mirror pixels and camera pixels",
    date: "20.39, Wednesday 19 Aug 2020",
    content:
      "I posted complaining about screen technology the other day, and Benedict Evans linked to it in his truly excellent newsletter which goes out to 150,000 people, so some of you will be here because of that. Sorry! Mostly I post about things like whether virtual conferences could be a month long, or can human being detect north. I guess the moral is I should complain about things more.\nANYWAY. It turns out there are some interesting technologies bubbling under with screens:\nMirror pixels! I was demanding that we have reflectivity in screens. This seemed absurd, BUT:\nEvery office projector for 20 years uses Digital Light Processing: the projected image is created by microscopically small mirrors laid out in a matrix on a semiconductor chip – each mirror corresponds to one pixel in the projection. The mirrors can be flipped on or off. Bright light is bounced off the mirror surface.\nThanks to Daniel Matos a.k.a. @dmatos for telling me about this.\nSo, could these mirror pixels be blended with existing screens? Well, in an adjacent technology…\nCamera pixels!\nHere’s Apple’s 2004 patent for an integrated sensing display: the idea is to wedge thousands of microscopic image sensors between the LCD cells that make up the display and stitch it all together with computational photography.\nI like this:\n\nOne use and benefit for such a panel is video conferencing: a user can maintain eye contact with someone on screen because the camera is ‘in’ the screen.\n\nCan you even imagine? What about a screen where you scan a document by holding it up to the LCD?\nWhat about a phone that lets you take selfies by turning into a MIRROR, and it captures a 3D image because the effective size of the camera sensor is the ENTIRE SCREEN.\nThe point is that we don’t need to stop at red, green, and blue subpixels. Other pixel types can be integrated.\nTransparent screens!\nThen of course there are transparent OLEDs.\nAND SO\nI was kinda okay when I was just imagining stuff like this. But after learning that these technologies exist already, I find myself even more frustrated that we don’t have them in our pockets.\nApple drives the direction of smartphones. That won’t always be the case, but it has been so far.\nApple is legendarily focused on product marketing. Every product and hardware innovation - and they are often mighty innovations - is driven by a marketable vision.\nBut part of me feels like sometimes functionality should be added without that vision.\nPerhaps product marketing has trimmed away the fascinating loose threads of computing, leaving the hackers and the artists - those who expand our range of the possible - nothing to play with.\n",
    link: "/home/2020/08/18/filtered_for_small_groups",
  },
  {
    title: "Lockdown and discovering new micro-hedonisms",
    date: "17.52, Thursday 20 Aug 2020",
    content:
      "Here’s an intriguing new psychology paper about appreciating hedonism:\n\nRelaxing on the sofa or savoring a delicious meal: Enjoying short-term pleasurable activities that don’t lead to long-term goals contributes at least as much to a happy life as self-control.\n– Hedonism Leads to Happiness, University of Zurich press release\n\n(Link found over at long-running economics/philosophy blog Marginal Revolution.)\nIn a nutshell:\n\nSelf-control to achieve long-term goals creates happiness, as do non-long-term pleasurable activities.\nHOWEVER, lots of people feel guilt, for instance not being able to truly enjoy lying on the sofa because they feel they should be going out for a run instead.\nIf you’re able to indulge in the pleasure WITHOUT intrusive guilt, the short-term hedonism contributes as much to your happiness as the self-control.\n\nLearning this, there’s a wonderful positive feedback effect in that it makes guilt-free self-indulgent short-term hedonism more allowable, as now I know it contributes to long-term happiness. (I hope that knowing about this research opens some doors for you, too.)\nAnd also it gets me thinking about my own hedonistic activities…\nThere’s opera and there’s incredible food at incredible restaurants and there’s hiking in the desert. When I’m at the ENO and the first few bars of a Philip Glass starts up, I’m already in tears. But these moments don’t happen very often.\nSo there are also the day-to-day micro-hedonisms. Picking up a great coffee, passing a second-hand bookshop and popping in to buy something, going out for a long run, etc.\na.k.a. self care. My mental model tells me that:\n\nThere’s an optimum time budget for self care. Like, maybe you need 15 minutes of self care daily and beyond that there’s diminishing returns – plus the mental energy required to suppress intrusive guilt is depleted.\nEach day, we stick with our go-to self-care practices. It’s tricky to discover new practices, and given the time budget, there’s a cost associated with shifting away from our regular set. So we reach a local maximum and stay there.\n\nBut then… lockdown. I’ve not had access to great coffee or second-hand bookshops. Lockdown itself and then scheduling has meant I haven’t been running. I had to find other routines.\nTwo of my newly discovered/resumed micro-hedonisms:\n\nBaking.\nWriting here.\n\nCan I see myself going back to my old indulgences?\nSome yes, others not. As it happens, I did pick up a fancy coffee the other day and it was… okay I guess? Perhaps I’d already hit my micro-hedonism daily threshold of diminishing returns.\nTwo thoughts as a consequence of the above.\nFirst: scale this up. How much of the economy was dependent on particular micro-hedonisms of the population, and now they’ve changed and won’t go back? “Retail therapy.” Like, maybe retail will be permanently down 5% (and that time budget distributed over other activities) simply because self care habits were forced to change and now won’t go back. Who knows. I’m curious.\nSecond, it has been an absolute joy to read the blogs of my friends over the last few months and see them pick up new hobbies.\nAnd, reflecting on that unexpected benefit of the last few months, I wonder how to - in the future - deliberately include some kind of regular micro-hedonism-discovery spike so that I can escape any local maximum and continue to find new and delightful self care practices.\nPerhaps, once every two years, on 23 March, the anniversary of lockdown starting in the UK, I’ll start my own 60 day lockdown re-enactment, a carnival where I fast from all my old daily micro-hedonisms and instead audit whole new vices - activities I’m terrible at or currently don’t enjoy - sewing, tap-dancing, writing poetry, watching TV, drinking rum - and at the end of the festival, keep the best.\n",
    link: "/home/2020/08/19/more_on_screens",
  },
  {
    title: "What if A.I. gets 100x better in a matter of months?",
    date: "15.48, Monday 24 Aug 2020",
    content:
      "I posted the other day about the current artificial intelligence cutting edge GPT-3, and its ability to write like a human. But since running across the following article, the idea of an A.I. overhang has been stuck in my head: what if artificial intelligences could get 100-1,000x more competent in a matter of only months?\n\nAn overhang is when you have had the ability to build transformative AI for quite some time, but you haven’t because no-one’s realised it’s possible. Then someone does and surprise! It’s a lot more capable than everyone expected.\nI am worried we’re in an overhang right now. I think we right now have the ability to build an orders-of-magnitude more powerful system than we already have, and I think GPT-3 is the trigger for 100x larger projects at Google, Facebook and the like, with timelines measured in months.\n– LessWrong, Are we in an AI overhang?\n\nThere are numbers in the post, but the argument goes that a 100x more effective A.I. will cost in the range of only $1bn, which is a relatively small fraction of Big Tech R&D.\nIntel’s expected 2020 revenue is $73bn. What if they could train a $1bn A.I. to design computer chips that are 100x faster per watt-dollar? (And then use those chips to train an even better A.I…)\nAt what point do self-driving cars effectively become solved… and what if it was in only 6 months? All the control couplings and sensors are there, we’re just waiting for the artificial brain.\nBritish call centres employ 1.3 million people, 4% of the UK workforce. What if they’re 99% out of work by 2022?\nWhat if text/voice/video synthesis and persuasion becomes a solved game, such that anyone can be scammed or hacked over email or phone or Zoom with off-the-shelf software, in the hands of anyone that buys it, robocalling a thousand people per hour? What if a covert, 95% accurate lie detector can run on a smartphone with a commodity camera and commodity mic, ship in 6 months, and cost a dollar?\nWhat’s interesting/startling/threatening about the idea of an overhang is that the changes come from every direction and there’s no time to adjust. The logic means that - if true - it’s not preventable. Sure, new professions will emerge, and new creative opportunities, and new social norms. But in the meantime?\n",
    link: "/home/2020/08/20/micro_hedonisms",
  },
  {
    title: "Revisiting Adaptive Design, a lost design movement",
    date: "15.22, Wednesday 26 Aug 2020",
    content:
      "I was reminded today of Dan Hill’s work in the early 2000s on Adaptive Design – and it feels to me like this movement, focused on re-use, modularity, and unintended customisation, is one worth revisiting, almost 20 years on.\nI’ll cover some history and then talk about why this matters.\nOne caveat: I was there but I can’t remember the references. Were there great introductory essays and brilliant reading lists, still relevant today? I don’t know. So I’m starting my archeology here.\nThe starting point is architecture\nAdaptive Design was where I first heard of the book How Buildings Learn: What Happens After They’re Built by Stewart Brand (1994). It’s here that Brand introduces his “Shearing Layers” (here’s his diagram) which summarise the 6 layers of a building, and their different rates of change.\n\nSite – geographical setting, eternal.\nStructure – foundation and load bearing elements, 30-300 years.\nSkin – 20ish years.\nServices – 7-15 years.\nSpace plan – interior layout, from three (commercial) to 30 (domestic) years.\nStuff – furniture and belongings.\n\n(The above taken from Phil Gyford’s notes on How Buildings Learn.)\nRelevance to design? The architect creates the building up to the Space plan; the occupier adds their Stuff. But the occupier can also change the house, with some work, by changing the Space – knocking down interior walls and so on.\nCritically, part to job of the architect is to design the Services (the electricity conduits, the water, the windows for light) to accommodate changes to the Space. The architect creates a platform for adaptation.\nConcretely, take Levittown.\nLevittown, New York (built 1947-1951) kickstarted American suburbia. And, um, refused to sell houses to people of colour…\nThe homes (there were four models) were built factory-style, on an assembly line.\nAnd they were built for adaptation:\n\nThe houses were built unfinished. They had space on the side to build a garage. The ground floor was the only one delivered finished. There was space for a first floor, but it was left as an attic, and the stairs were incomplete and ran up to a blank wall.\n– Matt Webb, The Experience Stack, slide 23\n\n(Quoting one of my own old presentations there.)\nSo the house can be extended. But, from an Adaptive Design perspective, the key is that house has the affordance of being extendable.\nWhat does “affordance” mean? It means that the design visibly shows what is possible. Affordance is originally a term from biology and animal cognition, and it made its way into being design jargon.\nAs the house owner, you’d sit in your front room and notice that blank wall. It would give you the idea that extending into the attic was possible, even if you’d never have thought of it yourself. The blank wall would remind you, would entice you.\nNot just architecture but the web too\nThe leap that Hill made with Adaptive Design was to talk about physical and digital in the same breath.\nThe early 2000s was the era of websites with APIs (an API is a way to automatically control a website with code, instead of doing it by hand). The photosharing website Flickr launched their API in 2004, which meant it could be adapted to all kinds of unexpected uses.\nFor example: The Royal Observatory, Greenwich, used the API to integrate the Flickr group with the museum’s Web site, develop a sophisticated competition administration tool, and produce interactive exhibits.\nThe web was made for Adaptive Design: from View Source (so people could learn how to make their own websites), to web feeds and APIs – websites could be pulled apart and recombined, and that was encouraged.\nAnd there’s a dilemma with software, definitely. Would you prefer the 100% ideal to-do list user experience of a custom-made app, but you can’t copy-and-paste your lists anyway, or a powerful but often janky hacked-together Excel spreadsheet? Over the last 20 years, collectively, we opted for the former.\nThe question Adaptive Design poses:\nHow to enable not users but adaptors? How can people move from using a product, to understanding how it hangs together and making their own changes? How do you design products with, metaphorically, screws not nails?\nHow can our apps, our cameras, our furniture, our cars, and our home gadgets be less like closed-box appliances, and more like Levittown houses – allowing and even encouraging end user adaptation?\nMore reading: three essays from Dan Hill\nThis is a must-read essay by Dan Hill, introducing Adaptive Design: Insanely great, or just good enough? Originally published in Core77 in 2004, it’s a critique of the unadaptable, glued-closed Apple iPod and its non-user-replaceable battery.\nHill quotes Brian Eno:\n\nAn important aspect of design is the degree to which the object involves you in its own completion. Some work invites you into itself by not offering a finished, glossy, one-reading-only surface. This is what makes old buildings interesting to me.\n\nAlso check out:\n\nHill’s 2002 AIGA presentation on Adaptive Design\nand Hill’s notes on Tom Moran’s original Adaptive Design keynote at DIS2002 (Moran originated the concept).\n\nMe? I got into the idea that hardware products could be adaptable too. What if cameras and photocopiers had hackable hardware APIs? We even built a radio for the BBC with a hardware API.\nAdaptive Design developed language around modularity, layers, rough edges, and widgets. It went from architecture to APIs, via affordances and co-creation.\nWhy is this important now\nWe’re in an era of No User-Serviceable Parts Inside.\n\nLaptops and phones that invent new types of weird screws to prevent you from opening them up and changing the battery\nApps that hang on to your data, like posts or photos or your social network, and never let it go (we forget how open and scriptable both websites and desktop applications were).\nWe no longer own our movies, books, and software, but rent them, with our rights tightly constrained.\n\nAnd so it’s a challenging and provocative question to ask of any product design right now:\n\nHow can the end user adapt this product?\nHow can the end user know they can adapt this product?\nHow can the end user be encouraged? How can friction be reduced? How can an amateur learn, and an expert develop? How can adaptations and expertise alike be shared?\nAnd how can this adaptability be in alignment with business model of the developer/manufacturer, not fight it?\n\nLooking around me right now, I have Sonos speakers in three rooms in the house. In my imagined 2020, the BBC would produce a podcast feed of 2 minute radio news bulletins, updated on the hour. I would write a short script to grab that podcast, and send the latest bulletin to the speakers, interrupting whatever is currently playing.\nI’d be able to write an app for my TV as simply as writing a webpage. It would be an example of personal software and take over “Standby” mode for me and my family, wherever we are in the world, providing one-click to FaceTime whenever we’re online at the same time.\nI want to take a photo of my bookshelves, OCR it, and link every book to Amazon’s “Search Inside” functionality because - in my imaginary 2020 - they have an open API for book ISBNs. All in a couple lines of code.\nI want my house to come with a wiki that I write on, and my electricity meter writes on too, and that my front door lock consults for a list of people who are allowed in. I recently touched on why the smart home failed for strategic reasons: every big tech company wants to ‘own’ voice interactions, and be a gatekeeper to all smart devices. The smart home failed because it ignored the lessons of Adaptive Design.\nThat early work on Adaptive Design has already done the hard digging of finding reference points and developing frameworks to guide product design for adaptation -  it’s the anti Apple, the anti Amazon, the anti DRM. I’d love to see designers share their ideas for future adaptable iPhones and adaptable apps, expanding the discourse, and pushing back on the status quo. Adaptive Design is a movement worth reviving in 2020.\nUpdate 1 Sept.\nHill’s 2006 essay Architecture and interaction design, via adaptation and hackability is a great standalone piece, and has a ton of takeaways about what Adaptive Design means as a concrete approach (rather than just saying “hey, here’s a perspective” which is what my post does above).\nFor me, I’ve found it helpful to think about different interactions with a product almost as different “modes” – for instance, with the web browser, there’s regular browsing and also the developer mode. Then Hill’s architectural terms, highlighted in this essay, come into play: “threshold” (how does a user consciously move between models); wayfinding (how are routes between modes signposted); screens (to mask depth).\nThis kind of thinking makes a product powerful and adaptable, but also not overwhelming.\nAnd so on.\n",
    link: "/home/2020/08/24/ai_overhang",
  },
  {
    title: "Asimov’s Foundation, and what’s unique about science fiction",
    date: "12.07, Thursday 27 Aug 2020",
    content:
      "Isaac Asimov’s Foundation books were the first real sci-fi I read, at about 9 or 10. Apple is releasing a TV adaptation in 2021 (here’s the teaser trailer) – and I can’t help but feel it misses the point, and what the magic of science fiction is.\nYou don’t need to have read Foundation to read this post, but let me give you the basics.\nThe premise of Foundation is that the Galactic Empire collapses. One guy, Hari Seldon, predicts the fall, and using his new science (psychohistory) is able to tell that a 10,000 year dark age will follow. Yet he can create a new future! He can shorten the dark age to only 1,000 years by establishing a new society on a new planet - the Foundation of the title - to guide the galaxy back to new heights. Using psychohistory, he shapes the destiny of the Foundation long after his own death, using recorded messages that appear at pivotal moments over hundreds of years.\nFoundation, the story, begins in the middle.\nAsimov’s first Foundation stories, written in the 1940s, were set 50 years after Hari Seldon’s death. The Galactic Empire had already fallen, the Foundation was already established – but not entirely aware of its destiny. We meet Seldon only as pre-recorded hologram messages. He uses fake-outs and the holding back of information in order to forge the Foundation into what it needs to become.\nThe story of Foundation is not the story of Hari Seldon. Fundamentally it’s about what happens next.\n\nWhat are the consequences and limits of true prophecy? What if there was a guy who, long ago, said he could predict the future and his prophecies were true?\nHow does a society respond to Manifest Destiny? By taking it for granted, stirring envy in others, pushing back to find its own path… And how should an anointed, privileged child be nurtured towards self-reliance?\n\nLook, nobody gets to say what science fiction is or isn’t, least of all me.\nBut, for me, what happens next is, in a nutshell, exactly what is special and unique about science fiction.\nSci-fi is a scientific investigation, and the lab bench is the book. It’s a thought experiment in narrative form.\nThat’s what you don’t get anywhere else. The author has a setting that goes to great lengths to be plausible: a world, a society, a group of people. Then the subject of the investigation: a dead guy who prophesied the present and the future, blessing the current society in ways beyond its knowing.\nWhat happens next? Sci-fi uses the power and constraint of story to find its way through. And by doing that, discoveries are made.\nLike any scientific endeavour it starts as a phenomenological exercise: what’s happening? How does this thing behave in various circumstances? Then beginning to probe: what are its limits? How do we break the premise? And finally consequences… what does it mean for this phenomenon to be wielded deliberately; what are the second order effects when others can see the effects …and so on. Dynamical systems are all the same; the reader can readily draw parallels and discover new truths.\nAnd the new truths are about the present, of course.\nFoundation can be drawn out into a study of everything from America and Manifest Destiny, to how to express individuality when growing up with wealth and privilege.\nFor me, spaceships, distance planets and so on – these aren’t intrinsic to science fiction. They’re lab equipment. They provide necessary narrative distance from the everyday such that the reader (and the author) is able to fully explore the premise. But you could do Foundation without spaceships, if you wanted.\nThey’re fun, of course.\nBut ultimately:\nSpaceships and futuristic cities are just stage dressing.\nAfter the first short stories and novellas, Asimov went in two directions.\n\nInto the future: Subsequent stories cover the next 500 years of the Foundation’s future history.\nInto the past: the short stories from the 40s were published as books, the Foundation Trilogy, in the early 1950s. The opening chapter, written in 1951, is a mini prequel in its own right and shows us Hari Seldon alive for the first time. It’s set pre-Fall, and we meet Seldon at the heart of Empire, at the height of its glory.\n\nAfter the main run of Foundation novels, Asimov returned to Seldon, and devoted a couple of books to telling his story.\nBut Seldon’s life only works as a story if you already know the unbelievable truth, that his prophecies were correct (which is why Foundation should be read in publication order, not chronological). Otherwise he could be just another conspiracy nut.\nSo, looking at the Apple TV trailer of Foundation, it appears that the show is about Hari Seldon, and it’s set during the impending fall of the Galactic Empire.\nWhat show runner wouldn’t want to put that glamour and rotten decadence on screen? I get it!\nBUT.\nThe science fictional magic of the original stories is that we see the aftermath - good and bad - of Seldon’s truth.\nWe get to see the maturing of the Foundation under the distance guidance of his dead hand, one that everyone can see is always right – but that is none-the-less stifling for its presence. And perhaps, eventually, might be wrong?\nGlamour is shown without ever putting it on-screen (or rather, on the page). We see old Empire only from a great distance, from the dusty frontier planet of Terminus, the home of the Foundation at the edge of the galaxy. And we can imagine its splendour!\nThe galaxy is more sprawling, Empire is grander, and Seldon more omniscient for never seeing them.\nSo I’m excited to see Foundation on TV.\nBut from the trailer it looks like it’s leaning in hard on the far-future fantastical setting – great, but for me that misses what makes sci-fi sci-fi. It’ll be fun to see essentially the Fall of Rome with spaceships and a massive CGI budget…\n…but it looks like we’re not going to get to explore the what-ifs that made me fall in love with Foundation to begin with\n\nWhat If Prophecy, but Really,\nand How to Live with Destiny.\n\nAnd in the era of algorithms that decide our fate, and ethno-nationalists who say that national past gives us rights over the future, I can’t think of topics that need greater examination today.\nMy view on sci-fi (which is not universal, of course) is why I have such a strong connection with design as a method for innovation: both put new objects in familiar settings, crank the handle, and trust that the process will lead to new ideas.\nScience fiction is how we do design’s thinking through making when the only way to make is to put on a fictionsuit.\nA coda\nIsaac Asimov was horrible to women. I’ve noticed the lack of women in Foundation for as long as I can remember. What I didn’t know until a few years ago was that Asimov was a serial groper of women, a notorious sexual harasser who was enabled by the science fiction community.\nAnother note: why aren’t there any aliens in Foundation? Well…\nFoundation was published in the magazine Astounding. Editor: John Campbell, whose vision and energy drove the Golden Age of science fiction. It would be hard to overstate his influence. However…\n\nAsimov learned of Campbell’s insistence that humans should always be superior to other races in some way. It was clear to Asimov that Campbell’s own views on race were the source of the imperative: just as whites were superior to other humans, so humans had to be superior to any alien race. Asimov didn’t share Campbell’s views, and he didn’t want his stories to reflect them, even allegorically. (In the robot stories, the problem didn’t exist. Campbell didn’t mind if robots were superior to humans.) For the falling Galactic Empire in “Foundation”, however, Asimov chose to sidestep Campbell’s racial views by creating a galaxy-wide civilization with no alien races – a galaxy inhabited only by humans.\n– Asimov Online, The History of the Positronic Robot and Foundation Stories\n\nOuch.\nThe history of science fiction is not a proud one.\n",
    link: "/home/2020/08/26/adaptive_design",
  },
  {
    title: "Risk: micromorts, microCOVIDs, and skydiving",
    date: "12.42, Tuesday 1 Sep 2020",
    content:
      "There’s a standard way to understand the relative danger of any activity. A micromort is a unit of risk defined as one-in-a-million chance of death (Wikipedia). For example:\n\nskydiving is 8 micromorts per jump\nrunning a marathon: 26 micromorts\n1 micromort: walking 17 miles, or driving 230 miles\n\nGenerally being alive averages out at 24 micromorts/day.\nAssuming a 1% mortality risk, being infected with Covid-19 is 10,000 micromorts.\nBut what about the risk of catching Covid in the first place?\nThe microCOVID project: 1 microCOVID = a one-in-a-million chance of getting COVID.\nFrom the white paper:\n\nFor example, if you live in a region where about 1 in 1,000 people currently has COVID, then you could calculate based on studies of other indoor interactions … that meeting a friend for coffee indoors has about a 1 in 17,000 chance of giving you COVID. Such small numbers are hard to think about, so we can use microCOVIDs instead. Your coffee date would be about 60 microCOVIDs. …\nOne benefit of using microCOVIDs is that you can straightforwardly add up microCOVIDs to estimate your risk over longer periods of time.\n– The microCOVID Project, We measure the riskiness of interactions in “microCOVIDs”\n\nThere’s a calculator for regular activities (try it!) from which I can see that\n\ngoing out to buy groceries is 20 microCOVIDs\nhaving a small party, indoors, with no masks is 3,000 microCOVIDs\na 30 minute commute on the train is 100-200 microCOVIDs\n\nThe calculator takes into account the virus prevalence where you live.\nSo I might decide that I have a risk-tolerance of 10,000 microCOVIDs per year (i.e. a 1% chance of contracting Covid per year). That is, I really don’t want to get Covid, but I’m also not prepared to never, ever leave the house.\nThat gives me a budget of a little under 200 microCOVIDs per week. And I can measure my activities against that.\n(I’m not sure, from the calculator, how to account for household risk: do we have this budget between us, or each?)\nI find these kind of calculators useful to educate my intuition.\nFor example, an outdoor restaurant is only 30 microCOVIDs vs 500 indoors. A significant difference! Especially against my weekly budget of 200. Commuting via public transport is out if I want to do anything else. Useful to know.\nBack in May, I was speculating about realtime, hyperlocal pandemic forecasts:\n\nMaybe your phone could track your location and give you a live exposure number over the day, like a badge? It’s 2pm and you’re at 40 co-rads today. We recommend you leave before rush hour and take this 20 co-rad route home, also WASH YOUR HANDS.\n\nAnd this microCOVID calculator is the foundation of this. If you could automatically plug in realtime regional prevalence figures, you’d be able to make a risk assessment like short journey on the bus vs slow journey walking.\nThe framing of the microCOVID project gives me pause: it’s about personal risk.\nBut there are three distinct reasons why I follow the government lockdown advice:\n\nrisk to my personal/household, which is the focus of the microCOVID project\nrisk to others I might meet. I don’t want to accidentally infect my mum, for example\nsociety a.k.a. public health – we beat this pandemic through collective action, by bringing down Re, the effective reproduction number.\n\nRe isn’t a measure of prevalence. It’s a measure of how easily the virus spreads. It spreads more easily when people are meeting lots of other people without masks; it spreads less easily when social contact is reduced.\nIf Re is below 1, prevalence decreases; above 1, and it goes up.\nI think of society as a whole having an Re budget. The figure I heard, at the beginning of lockdown, was that we needed to reduce in-person social interactions by 75%. I assume that social interactions are the key factor in Re (or at least, were believed to be at the time). Other factors might be: % people wearing masks; proportion of unique vs repeat people encountered.\nThere are some people we need to spend against the Re budget: health workers, anyone involved in the grocery supply chain, and other key workers. I am happy to reduce my in-person interactions by, say, 90% if that means that key workers need to reduce by only 60%.\nIs there a translation between microCOVIDs and Re? I don’t know. Maybe +100 microCOVIDs/week/person in a region with a population density of such-and-such contributes +0.1 to Re.\nI’d love to have that connection between personal activity and social good.\nThis pandemic has given us a whole new vocabulary around virality that wasn’t commonplace before. I wonder how we’ll use it in the future?\nHow many micro-RTs does one of my tweets have, where 1 micro-RT is a one in a million chance of it going viral?\nCan we measure the effective reproduction rate of a given social media influencer?\nAnd so on.\nI mentioned skydiving at the top of this post (8 micromorts). Of course, there are also externalities. And that reminds me of something else I read:\nIn the UK, skydiving is a common way to raise money for charity.\nBUT…\n\nThe injury rate in charity-parachutists was 11% at an average cost of 3751 Pounds per casualty. Sixty-three percent of casualties who were charity-parachutists required hospital admission, representing a serious injury rate of 7%, at an average cost of 5781 Pounds per patient. The amount raised per person for charity was 30 Pounds. Each pound raised for charity cost the NHS 13.75 Pounds in return.\n\nConclusion: Parachuting for charity costs more money than it raises.\nHere’s the paper:\nLee CT, Williams P, Hadden WA. Parachuting for charity: is it worth the money? A 5-year audit of parachute injuries in Tayside and the cost to the NHS. Injury. 1999;30(4):283-287. \n",
    link: "/home/2020/08/27/foundation",
  },
  {
    title: "Augmented reality should use magic mirrors, not glasses",
    date: "15.17, Wednesday 2 Sep 2020",
    content:
      "I’m into the idea of augmented reality because it makes sense that computing is anchored to the real world.\nOf course I should be able to pinch my fingers on a paragraph in a real printed book to copy-and-paste the text into my notes. Naturally I should be able to look out of my window and double-blink at my car, bringing up a readout of how much fuel I have and how much time is left on the lease. Or look up at the sky to see the weather forecast printed on a cloud. Or at my sourdough starter to see it ghosted against the size it was early today, so I can tell at a glance how much it has risen.\nBut augmented reality is always about glasses. See: the Magic Leap One A.R. goggles.\nSee Apple: the continuous rumours about Apple’s secret smart glasses project. Apple’s existing augmented reality platform which is always about looking through.\nBUT.\nGlasses are anti-social. I want to show people what I’m working on by having them look over my shoulder. I’ve lost count of the number of times I’ve shared a photo by holding my phone up to Zoom. When A. is cooking, she can call across from another room to have me check the stove – how bad it would be if the stove interface was locked away in her personal glasses. Sure, all computer interface problems are solvable with design and work – but A.R. is creating a lot of unnecessary work if it starts with an interface which is so oriented to the individual from day 1. \nAnd then: how do we get there from here? I can imagine a world where augmented reality is the only interface – Keiichi Matsuda’s still-amazing-and-disconcerting 2016 film is such a vision: HYPER-REALITY.\nCan I imagine HYPER-REALITY alongside today’s smartphones? Can I imagine taking glasses on and off just to check a document or two? Not really. But that’s the reality of technology adoption. Adoption and sophistication proceed stepwise.\nSo what’s the first step into mainstream augmented reality? Perhaps: not glasses.\nHere’s KOSKI GAME (2016) by Václav Mlynář/Studio Deform:\n\nKOSKI is a mixed-reality building block game. It is a combination of real, wooden blocks and a virtual app that facilitates digital, interactive game play. With the help of a tablet or smartphone, structures assembled from the blocks come alive. Once a player starts to interact with the blocks, the game begins to reveal it’s hidden worlds, characters, and stories.\n\nWatch the KOSKI intro video (1m23s).\nIt’s a physical sandbox game for kids. You stack real world wooden blocks. Next to the game area, you prop up your iPad.\nThe iPad is a magic mirror.\nAs you stack the blocks, they comes alive in the magic mirror. Figures climb the structure; waterfalls appear.\nWhat struck me, using KOSKI, is how natural it felt. When you’re playing with the blocks, and looking at the augmented reflection in the screen facing you, your neuroplasticity takes over in an instance. It’s as if the blocks in the hands actually have trees growing out of them and tiny cartoon people are balanced there.\nWe shouldn’t be surprised. When I’m selecting text on my screen, I’m not conscious of my fingers being on the trackpad and the pixels being many inches away. The two feel identical.\n(The designer created this game while part of Platform 24, Design Products at the Royal College of Art, while I was also lending a hand. It’s stuck in my head since.)\nWhat if the magic mirror is the right way to start with augmented reality?\nNot looking through, which presupposes an individual perspective, whether you’re looking through glasses or looking through a phone.\nBut instead reflecting what’s between you, as if the magic mirror screen is part of your team, or part of a small group of kids playing, just another group member adding their point of view.\nFor kids, it’s way more social. Kids already play together. It makes sense to have have just another party saying (visually; nonverbally) hey, let’s have a waterwall here, and hey what if that figure needed a bridge – and the other kids are free to play along or to do something else. (A.R. glasses don’t feel nearly as nuanced.)\nFor me, individually, I can imagine propping up an iPad on my desk, off to one side, and working on a printed document. When I make edits on the doc, I glance to left to see my work reflected in the tablet screen, and translated into Google Docs edits. The mirror is populated with team-mates adding their comments – checking them is just like looking into the sidebar.\nAnd let’s pretend that one day we’re back in offices…\nAbstractly, the magic mirror is a screen that looks back when you’re looking at it, and can intelligently add to whatever it displays.\nSo, building on that: instead of screen sharing to a room projector, why not hold my smartphone up to the magic mirror, which then captures and magnifies whichever doc I had on my display, showing it to everyone in the room? Simple steps.\nA couple of speculative form factors:\n\nthis transparent 55” OLED TV but as a desktop monitor – imagine a regular desktop interface but where your desktop wallpaper is see-through. In magic mirror mode, I would work on paper or my tablet at my desk, and only the reflected, augmented documents would appear: it would feel like sitting opposite someone who was co-editing my work.\na mirror for the kitchen: I would show it recipes to convert units, and look into it to see my calendar schedule for the day (and my partner would see too). I find this idea more ambient, more natural, and less intrusive than a smart speaker… internet-connected camera aside.\n\nThe metaphor here is that augmented reality doesn’t have to feel like a cyborg enhancement. It can feel like a companion, or friend, or team member.\nI’m not saying never glasses. With magic mirrors I’m saying perhaps – also? Or, first? Or, let’s try it because the technical barriers are lower and the use cases for immediate? That’s all.\nFor my own curiosity, I’d be interested to know if anybody is pursuing the magic mirror paradigm for augmented reality – do let me know if you’re working on it.\n",
    link: "/home/2020/09/01/microcovids",
  },
  {
    title: "GPT-3 is an idea machine",
    date: "13.22, Friday 4 Sep 2020",
    content:
      "GPT-3, created by OpenAI, is the startlingly human A.I. text generator that I posted about last month – read that summary here (including its religious proclamations…).\nI’ve since been shown the beta version.\nHere’s what I didn’t expect: GPT-3 is capable of original, creative ideas.\nUsing GPT-3 doesn’t feel like smart autocomplete. It feels like having a creative sparring partner.\nAnd it doesn’t feel like talking to a human – it feels mechanical and under my control, like using a tool.\n“Imaginative” and “tool-like” are two very different experiences to reconcile… and yet!\nAfter each of my sessions with GPT-3, I was left with new concepts to explore. Let me give you some examples…\nThe interface to GPT-3 is modelled on text autocomplete. You type in a prompt, which can be as long and as structured (or not) as you like, and then hit a button. GPT-3 picks up where you left off; it takes a few seconds.\nSo, as a prompt, I gave GPT-3 the start of an essay (one I wrote for a client), stopping halfway through a sentence:\n\nAnd, like drop-shadows and lighting can be used for visual affordances in 2D interfaces, spatial metaphors are helpful in these glimmers of a new, everyday cyberspace.\nOther ways we can make a friendly, approachable cyberspace are\n\n(I’ve bolded the text because that’s how the GPT-3 interface works: it puts the user-written text in bold.)\nThen I hit the button.\nAnd it rattled off a couple of hundred words… which ended with this paragraph:\nThe ‘low-fi’/’hi-fi’ slider in Apple’s Photos app is a great example of this. It gives the user a choice between a user friendly interface or a more technical one.\nTHERE IS NO SUCH LOW-FI/HI-FI SLIDER. This is an invention.\nI mean, this is potentially a pretty good idea if you think about it. Or at least intriguing, and with work it could lead somewhere good.\nAnother way you can use GPT-3 is semi-interactively.\n\nIt’s 2021. A hologram appears in a box outside 10 Downing St. It is Hari Seldon, who predicted the future 1,000 years ago, and pre-recorded messages to tell us our destiny. Hari says: “The final crisis has come. …\n\nSo what’s happened here is I’ve written the start, the bold bit, and GPT-3 has filled in the rest. It does its best to keep the same tone as the prompt. I’m truncating the responses.\nAfter GPT-3 has done its bit, I can add a new prompt to the bottom, and ask it to continue. It feels collaborative.\n\nHari then describes the nature of the final crisis: it’s monetary. Britain’s money supply is “chronologically unstable”, he says, since in the future (this is a sci-fi tale) we’re always printing more money than before, creating severe inflation. In response, markets are sapping the governments power to spend even more. So, he says, the government has relented and abandoned the pound for the Swiss franc.\n\nOk, this is weird. Let’s keep digging. I continue with another prompt:\n\nFortunately, the hologram of Hari describes what we need to do to safely resolve the crisis. “First,” Hari\nsays, “you must merge the Treasury with the Bank of England by setting up a Public Bank of Britain. …\n\nI have googled this. THE WORDS ‘PUBLIC BANK OF BRITAIN’ DO NOT EXIST ON THE WEB.\nLast one.\nIt occurred to me that GPT-3 has been fed all the text on the internet. And, because of this, maybe it can make connections and deductions that would escape us lesser-read mortals. What esoteric knowledge might be hidden in plain sight? I can ask.\nPrompting GPT-3 into a turn-taking conversation (by starting each line with who is speaking) makes it feel like a chat. Again, bold text is what I’ve typed. The rest is written by the A.I – and so…\n\nHuman: In all the data you have been trained on, is there any indication that humans have been contacted by extraterrestrial beings?\nAI: I understand what you mean. Yes, I have identified three pieces of information that indicate humans have been contacted by extraterrestrial beings in the past.\nHuman: What are those three pieces of information?\nAI: (information 1), (information 2), (information 3)\n\n…which is enticingly close to being interesting! But odd. Not what a human would say. (And is it actually making connections on demand in its giant database? No, I don’t think so. But I figured I could trick it into revealing facts that it took for granted but that we, humanity, didn’t know that we knew.)\nLet’s keep going…\n\nHuman: Can you please expand on the meaning of “(information 1)”?\nAI: The meaning of (information 1) was that “55,000 researchers in the field of ufology were examined by a statistical analysis program”.\nHuman: Can you please expand on the meaning of “(information 2)”?\nAI: The meaning of (information 2) was that the “mutilated cattle tissue samples have shown peculiarities in 14 locations”.\nHuman: Can you please expand on the meaning of “(information 3)”?\nAI: The meaning of (information 3) was that “a three-mile wide black ring was found in the ocean using sonar. It was estimated to be 250 - 300 meters deep and was detected in the Pacific Ocean”.\n\nWell! These are strangely specific and wildly imaginative ideas. I can’t find them cited anywhere.\nI’m trying to be pretty observational at the moment. Just… playing and seeing what happens and documenting as I go.\nIn this spirit, my field notes so far:\n\nUsing GPT-3 is work, it’s not a one-shot automation like spellcheck or autocomplete. It’s an interactive, investigative process, and it’s down to the human user to interview GPT-3. There will be people who become expert at dowsing the A.I., just as there are people who are great at searching using Google or finding information in research libraries. I think the skill involved will be similar to being a good improv partner, that’s what it reminds me of.\nGPT-3 is capable of novel ideas but it takes a human to identify the good ones. It’s not a replacement for creative imagination. In a 15 minute session with the A.I., I can usually generate one or two concepts, suitable for being worked up into a short story, or turned into a design brief for a product feature, or providing new perspectives in some analysis – it feels very much like a brainstorming workshop, or talking something through with a colleague or an editor.\n\nEven today, I can imagine a 15 minute consultation with GPT-3 becoming standard practice in every piece of creative work I do. And in the future?\nStill digging.\n",
    link: "/home/2020/09/02/ar_and_magic_mirrors",
  },
  {
    title: "Naming algorithms and the ghosts in Pac-Man",
    date: "22.04, Monday 7 Sep 2020",
    content:
      "How do we relate to the algorithm? Here’s one way…\n\nSproute is a navigation app that diversifies how you travel by offering a set of characters that get you to your destination in different ways. \nFor example maybe you want to avoid dark and unlit streets at night, or maybe you could go sightseeing on the way to your destination?\n– Julius Ingemann Breitenstein, What is Sproute?\n\nI met Breitenstein on one of my Wednesday calls. (I open my calendar for a few slots every week, for serendipity purposes. Wednesdays are now my favourite day. Rationale and booking link here.)\nHis prototype app, Sproute, is a replacement for the Google Maps routing system with a few different options, each embodied as a character:\n\nSightseer – who routes you via landmarks\nNightlight – who always takes you on well-lit streets\nCommuter – who subtly changes up your route to work each time you travel.\n\nGreat write-up of the design process at the above link.\nHere’s Chapter 4 of the Pac-Man Dossier (2009), an enormously in-depth guide to the original 1980 Pac-Man arcade game.\nIt turns out that the four ghosts embody four different pursuit algorithms and their descriptions in Japanese are poetic explanations of those strategies. I’m going to dump the details of all four here because I am forever trying to find this in my notes.\n\nBlinky (red) moves towards Pac-Man’s current tile. In Japanese, oikake which means to run down or pursue.\nPinky (pink) heads tiles four ahead in the direction Pac-Man is moving. Japanese: machibuse: to perform an ambush.\nInky (turquoise) embodies logic to catch Pac-Man in a pincer movement with Blinky, initially by moving in the opposite direction. Kimagure: a fickle, moody, or uneven temper.\nClyde (orange) moves towards Pac-Man if within 8 tiles, no pursuit otherwise. Otoboke: pretending ignorance.\n\nI think that when we don’t name the algorithm, it’s hard for us to imagine it could work any other way.\nWe imagine that the Google Maps algorithm must be the best way to get from A to B, because it’s the only way. Like nature.\n(It’s telling that, when users get more expert, they do start naming algorithms. The SEO community has names for the various Google Searches over time.)\nI don’t think we should anthropomorphise algorithms – if we say that the Facebook news feed algorithm (for example) has its own agenda, that implies it has agency, and that obfuscates the fact that it’s actual people at an actual company who made the decisions to have it work that way.\nBut names… names give us a way to have a public conversation about biases and consequences. Names let us imagine alternatives.\n",
    link: "/home/2020/09/04/idea_machine",
  },
  {
    title: "Coffee from ice cream vans, and other remote working perks",
    date: "17.13, Tuesday 8 Sep 2020",
    content:
      "Ok, so I wasn’t expecting this tweet to get (checks numbers) 865 likes and 93 retweets:\n\nHonestly, screw commuting and screw Pret. I love working from home\nBut why not have a coffee truck that drives around the suburbs like an ice cream van? I’m sure we could come up with a “flat white” jingle for it to play.\n– Matt Webb (@genmon), 1:03 PM, Sep 7 2020\n\nThe context is that we’re all being told to get back to the office, and that it’s selfish to do otherwise because coffee shops, etc, in cities are suffering. See, in Grazia: When Did ‘Save The NHS’, Get Overtaken By ‘Save Pret’?\nBut going back to exactly what we were doing before seems like a pretty unimaginative way to save the economy. It turns out that many people love working remotely, and we’re learning how to be good at it.\nPerhaps, rather than struggling to preserve old businesses, we can let them evolve and build new ones too?\nBy which I mean:\nWe’re used to office perks and the benefits of working in a business neighbourhood: free snacks (if you’re lucky), a comfy chair, good lunch spots nearby… what future working-from-home perks can we invent, if we’re in this for the long term?\nLike, is there remote work facilities management that can come set up my desk and give me a sound baffle/backdrop for my video calls? (Has Ikea launched a Zoom kit yet?) If I were a manager, could I expense desk beers on Fridays for my team, and is there a company that can sort that out? Is there a startup which will organise virtual movie nights, or a surprise snack box in the post, or streaming event once every couple of weeks? Could my local train station get itself a suburban WeWork for the times I actually need a meeting room?\nIt would be unrealistic for even a sizeable firm to run all these perks itself. But if they were all services that were contracted out? That’s our new economy right there.\nThen there’s good coffee and the social life. It can feel pretty distant sometimes at home. But while it’s nice to have face-to-face banter, does that really need to be with co-workers? I’d just as soon have my water-cooler moments with the people who live on my street.\nAll of that was going round in my head.\nI also have a refreshed love of my neighbourhood.\nWe couldn’t get online grocery delivery slots at the beginning of lockdown, and our local shops really stepped up. I’ll never forget that. One nearby cafe flipped its model into selling flour and dried goods, the interior becoming an ad hoc storeroom.\nThat experience sparked me to write about local e-commerce back in May. In short: what if I could order and get same-day deliveries from the local businesses that I want to support, as an antidote to the usual faceless e-commerce giants?\nSo an ice cream van that pulls up, jingling out the MIDI version of Josh Wink’s Higher State of Consciousness at 11am, everyone on the street downing tools and heading out for a caffeine hit and to catch up with friends?\nI’m maaaybe 50% kidding.\nBut the underlying provocation stands: what if we aimed to make remote working as great an experience as a fancy office, and what if we did it in a way that boosted both human contact and our local neighbourhoods, and what new businesses can we imagine that would enable this?\n",
    link: "/home/2020/09/07/algorithms",
  },
  {
    title: "Countdown clocks, zines, and an imagined website from 2001",
    date: "19.54, Wednesday 9 Sep 2020",
    content:
      "There’s a website from 2001 for making zines with your friends that, at this point, only exists in my head, if it ever existed honestly, but I wish it were in the world, because in this age of WhatsApp and Slack and whatever, we need it. There are ideas at the bottom of this post.\nHere’s how this fictional website worked, in my memory, which is maybe (probably) false:\n\nYou start a zine and give it a publishing frequency, and invite a groups of friends to collaborate\nEveryone writes articles and puts them into place. Anyone can edit anything, but you can decide roles like subeditors and contributors. The table of contents is auto-generated; images are automatically re-sized; etc.\nIn the top corner of the screen is a big countdown clock. When it gets to zero, the articles, whatever state they’re in, all get published automatically. They’re compiled and put somewhere on the web, anywhere you choose.\nThe clock restarts.\n\nPerhaps, with the countdown clock, there are even DEFCON levels before going to press: content freeze 3 days ahead of launch, 12 hours to go, everyone scramble to submit your story; it’s the last 24 hours, only minor edits and deletions allowed; and so on. Everyone can see the clock, it’s a forcing function.\nIn my head, this website is super easy to use. Church groups use it for their monthly newsletter, teams at work use it for their weekly updates, writing groups use it to publish an online magazine, school classes use it.\nDid this website actually exist?\nIt is possible that it existed, for 9 days, almost two decades ago. The memory of that website is what I keep coming back to.\nWaaaaaay back in early 2001, I got excited about a tool named Organizine which was a tool for groups (not individuals) to make websites. Here’s my write-up at the time, and here’s what the founder said about it. I think it launched publicly on the last day of 2000, and closed (for personal reasons, according to the message on the site) on 9 January.\nYou will notice that, in neither of those write-ups, is there mentioned a “time to press” countdown clock.\nAND YET – I have been talking about Organizine for, I am not kidding, 19.5 years now, and I have mentioned that countdown clock every time. Did I make it up? Perhaps. It looks like it. Who knows. It’s a good idea though.\nI really want this website, or app, or whatever it is.\nHere are the key features:\n\nThere is a live community, communicating in email, Slack, WhatsApp, whatever – and it’s a private community.\nIt’s a group project. Everyone contributes to a single artefact, and all repetitive work is removed. Text flows through templates to become articles; index pages, content pages, and anything that can be automated is automated.\nThere is a robot publisher which takes the “go live” authority away from the group. Publishing makes things fixed and public, on a schedule.\n\nWhat going on here is there’s some kind of public, static production emanating from a private and ephemeral small group of people. There is just enough structure, with roles and sign-off gates, and the clock of course, to get the group to self-organise.\nIn 2020, I want to apply this pattern wherever I see a place where small groups gather.\nWe’re in a golden age for online teamwork and community. WhatsApp groups, Slack and Discord, meetings in Zoom, social media like Facebook and Twitter – there have never been more ways to socialise and work together online.\nBut what I’d like more of is the ability for those groups to produce something together. Barn raising. And the artefacts of those collective efforts… zines, videos, visual art, screenplays: things which are finished. Complete. Not posts in Facebook groups. Websites.\nI’m missing the durable, ever-increasing “stock” in Robin Sloan’s stock and flow. More abstractly, it’s Walter Ong’s orality and literacy and what we’ve got now is an oral culture – lively, vibrant, fluid… but temporary and somehow unable to reach the deeper and nuanced ideas that literature culture affords.\nSo, some ideas.\nA private wiki or Notion instance that has a special zone that auto-publishes editions of a static website, once a month.\nA Slack workspace that has a special #links channel, and every Friday it gets compiled into a newsletter, sent to whoever is online for a quick review, and posted out to all subscribers. Emailed replies to the newsletter are directed back into Slack, where they appear like messages in bottles.\nA WhatsApp group for a club committee, attached to a Google Drive folder with a fixed set of Google Docs in it, an once a week the content of the docs gets swept through pre-set templates and published as a PDF and emailed out to the membership.\nA GitHub Pages repo that accepts all changes that are made to it, by anyone, and auto-publishes a website – but as issues, so previous issues are  available at sequential URLs – and only on Thursdays.\nA shared album in the iOS Photos app for a family that lives apart and, for Christmas, after paste-ups are shared for editing on 1 December, the photos are automatically printed into books that are mailed out to all the households.\nA drag-and-drop Figma canvas that a design group drops and arranges inspiration image into, and every couple of weeks it all gets printed with Newspaper Club.\nAn email list for a writing group, and any Microsoft Word doc forwarded to a special email address gets posted to Drafts in a WordPress blog, and the next story, whatever it is, is pulled from the queue and published every Friday.\nA postbox in Animal Crossing which posts to a Tumblr blog for your town, at midday daily, and it’s frozen for an hour at 11am so the town owner gets to edit if they want.\nAll built for small groups to work together, simultaneously with them chatting and hanging out.\nAll with the ability for some kind of audience (website visitors, newsletter readers) to subscribe to the artefacts, whatever they are.\nAnd all, of course, having - large, in the top corner of every screen, monotonically decreasing - the imperturbable presence of the clockwork publisher, this feature which maybe I imagined and maybe was there in 2001, but which is vital, the moment of cutting the cloth which gives the creative act its edge, showtime itself: the countdown clock.\n",
    link: "/home/2020/09/08/remote_working_perks",
  },
  {
    title: "15 rules for blogging, and my current streak",
    date: "18.07, Thursday 10 Sep 2020",
    content:
      "My current streak: I’ve now been writing new posts for 24 consecutive weeks. Multiple posts a week. How on earth? I just calculated it, and I’ve added the live streak count to the site footer. I wonder how long I can keep it up.\nThis blog has been going since February 2000. I’m writing more now, two decades on, than I have for YEARS. That’s not just because of lockdown – it’s because, about six months ago, I set myself some rules. The rules, which are specific to me, are intended to bump me out of certain mental traps that I know will otherwise stop my words. And since these rules have been working for, well, 24 weeks now, I figured I’d write them down.\nSo here they are, my personal rules for blogging.\n\nThree posts a week, more or less.\nOne idea per post. If I find myself launching into another section, cut and paste the extra into a separate draft post, and tie off the original one with the word “Anyway.” Then publish.\nNo hedging, no nuance. If I’m getting in a twist about a sentence, take it out.\nGive up on attempting to be right.\nGive up on providing full links and citations.\nGive up on saying anything new. Most people haven’t read my old stuff. Play the hits.\nGive up on trying to be popular. I try not to filter myself based on what I believe will be popular. Some of my favourite posts get ignored. Some posts get popular and I have no idea why. Besides, terrible posts get buried fast if I’m posting three times a week. So post with abandon.\nGive up on trying to be interesting. Readers will come to my site for what’s interesting to me, or not, it’s fine, just say what I think about whatever I’m thinking about.\nBut make it work for a general audience.\nOnly write what’s in my head at that exact moment. It’s 10x faster.\nIf it’s taking too long to write, stop.\nDon’t use a post just to link to something elsewhere. If there’s a point to make, start with that.\nTitles should be descriptive and have the flavour of the post. And rewrite the lede once the post is done so the whole thing gets to the point faster.\nIt’s ok not to blog if it feels like a chore.\nWriting is a muscle.\n\nIf I have an idea for a post, at any time, I make a note of it in my drafts folder – without delay. Or it’ll disappear.\nWhen there’s time to write, I go through my draft posts (and recent links that I’ve run across, I capture those too) and see if anything catches my eye. If it does: start typing and see what happens.\nThis post inspired by Tobias Revell’s recent remark, How does Matt Webb do this every. damn. day?\nAnyway.\n",
    link: "/home/2020/09/09/organizine",
  },
  {
    title: "ID’ing movies by fingerprinting the breath for isoprene",
    date: "16.36, Tuesday 15 Sep 2020",
    content:
      "I wonder what gaseous social cues we’re missing, working remotely.\nLike, there’s that paper from 2016 about isoprene emissions in human breath…\nFirst, attach a mass spectrometer to the outflow vent of a movie theatre. (They used a theatre for this experiment because it’s a closed box with lots of people in it, amplifying the signal. A good controlled environment.) Then measure the gas quantities every 30 seconds. And:\n\nIn Hunger Games: Catching Fire, for example, during the “suspense” scenes–when Jennifer Lawrence was in particular danger–the carbon dioxide, acetone, and isoprene levels in the theater air predictably increased.\n– The Atlantic,  Emotions Seem to Be Detectable in Air \n\nCheck out the graphs in this other article, which continues:  Nearly identical peak-trough-peak patterns occurred during all four screenings of the film in December 2013, allowing the researchers to blindly identify the film just by looking at its unique, air-based fingerprint.\nRELATED: you can also tell what someone’s watching by looking at the electricity consumption of the TV. Multimedia Content Identification Through Smart Meter Power Usage Profiles (2012, pdf) shows that if you measure power draw through a smart meter, twice a second, the fingerprint can identify the movie.\nNow, it’s not clear whether isoprene changes are signals to one another, or simply byproducts of emotion-based reactions.\nBut, given an available signal, it would be crazy of the human body to not take it into account.\nAnd if isoprene, then what else? Oxytocin has an effect when delivered into the nose - is it also exhaled, and so passed from one person to another? And other gases in the breath?\nNon-verbal, non-visual coordination of small groups, carried in the breath.\nThe “energy in the room” will be dominated by those who project their breath more – i.e. those who look up and speak the most.\n(That’s assuming that gas exhalation levels are equal between people. Given my hunch that charisma is physiological, maybe naturally dominant, charismatic people are simply isoprene super-emitters?)\nDoes a room carry the emotional memory of the people who were last in it? For how long? Does a sofa absorb isoprene and outgas it slowly over a period of weeks?\nAre consensus, compromising political decisions better made in person or over gas-shielding video calls? \nIs it possible to carry these group-coordination signals over the internet? Perhaps not as gas… but how about a tiny mass spectrometer next to my laptop mic as an isoprene sensor and, at the other end, mixing tension-inducing infrasound into the audio channel?\nI wonder how a gas-sensitive alien would see the world.\nWould lying, or broaching a difficult topic, look like a person blowing up a balloon? Would they see a group as a struggle between different coloured gases, slowly coming to an agreement – or, in a different group, fluctuating between different modes?\nLike fireflies synchronising. (Could we think of movies as artificial synchronisers, isoprene metronomes for the group? What is we had 45 minute isoprene metronomes for teams, programmable for different types of meetings?)\nPerhaps, through the alien, we’d discover that dogs remove isoprene from the air, but don’t emit it, or something like that. The alien would call pets “isoprene sinks,” and they would see them as functioning like the control rods in nuclear reactors that soak up the neutrons.\n",
    link: "/home/2020/09/10/streak",
  },
  {
    title: "Fanboost and other magical manifestations of the will",
    date: "19.38, Wednesday 16 Sep 2020",
    content:
      "Formula E (the electric version of Formula 1) has FANBOOST which is maybe the tech equivalent of some kind of distributed good fortune magick?\n\nThe five drivers who receive the highly-acclaimed FANBOOST – as voted for by you, the fans - are awarded a significant burst of power, which they can deploy in a five-second window during the second half of the race.\n\nYou vote on the website, or by invoking the drivers name on Twitter as a hashtag.\nI am obsessed with this idea.\nBecause it is obviously bonkers. It’s action-at-a-distance, which is weird. Concretely, it breaks the rules of the game, because why can’t a car use its battery as it chooses.\nAnd yet it makes intuitive sense?\nLike of course if a million people WILL the car to go faster, it should go faster? Deep down, I think that’s what humans believe.\nAnd then, in football: what is the home advantage except for fanboost by sheer weight of numbers?\nIt’s definitely to do with people. As discovered in lockdown, home advantage disappears in empty stadiums: We have found that the considerable home advantage in football is on average almost entirely wiped out in closed doors matches.\nI posted yesterday about isoprene in the breath as a person-to-person stress transmitter.\nMonique van Dusseldorp on Twitter thought about conferences:  Having been in conference rooms for 30 years - on stage, backstage, in the room - I thought it was heartbeats falling into step that make you “feel” the audience. Matt Webb pulls together some info that is completely new to me and makes total sense. Breath.\nAnd I know EXACTLY what she’s talking about. Speaking to an audience of 1,000 people, when I get in sync I disassociate – I feel like I lift up and my words are the exact right ones, the only ones for that moment.\nSo if you’re a speaker at a rally of thousands of people, all yelling and therefore projecting their breath right at you, and you pick up the mood and rile them right back, a positive feedback loop of accumulating isoprene – well, you can see how those rallies in the 1940s got so elevated.\nAnd football matches: a stadium of 60,000 directing their isoprene right at the players?\nWhat gets me still is FANBOOST.\nVirtual isoprene.\nI wonder if this kind of idea could help in group video calls?\nSay, monitor the gaze of all participants, add it all up, and give everyone an individual, dynamic attention rank.\nPeople with high rank should magically find it easier to get into the conversation; their noise cancelling threshold is set to let them speak a few milliseconds quicker, that kind of thing, or their volume is set slightly higher.\nDunno.\nI’m sure I’ve got some friends who know about magick and have talked to me about this kind of stuff before. Anything I should read? Feels like some strong inspiration in this area.\nPrayer.\nI’m reminded of a paper I read way back in 2002 (that link is my blog post at the time). It was printed in a paranormal special edition of the British Medical Journal.\nLet’s put replicability aside for a second. Here’s the punchline, from the abstract linked from that post.\n\nRemote intercessory prayer said for a group of patients is associated with a shorter hospital stay and shorter duration of fever in patients with a bloodstream infection, even when the intervention is performed 4–10 years after the infection\n– BMJ: Beyond Science, Effects of remote, retroactive intercessory prayer on outcomes in patients with bloodstream infection: randomised controlled trial\n\nRemote prayer. PRAYERBOOST.\nRetroactive. Better outcomes, even 4–10 years after the patient leaves hospital. Wh-wh-what?\n",
    link: "/home/2020/09/15/isoprene",
  },
  {
    title: "Hints towards a non-extractive economy",
    date: "18.48, Friday 18 Sep 2020",
    content:
      "There’s a movement called the circular economy which is about designing services that don’t include throwing things away. There is no “away.”\nFor example: CupClub (which we invested in during my time with R/GA Ventures).\nCupClub provides closed-loop coffee-cups-as-a-service to cafes. For example, the cafe in an office block. Reusable cups are dropped, by customers, into special bins. The bins are collected, and the cups washed and recirculated. \nAnd then there’s this other thing, another hint, the Engage:\n\nIt’s a fully operational Game Boy and can play any of the console’s titles, from Tetris to Super Mario Land. It harvests energy from five small rows of solar panels on its face and from button presses made by the user. In its present state, that’s enough to power the Engage for around 10 seconds, depending on the game.\n– CNET, The first battery-free Game Boy wants to power a gaming revolution\n\nThat report on CNET is a pretty good long read. The Engage is a research prototype right now.\nBut you know… energy harvesting? I’ve talked before about putting voice control in everything, and with super low power embedded machine learning, and energy harvested from RF/solar/kinetics, maybe we could have voice control for even single purpose, intermittently powered devices?\nAnother datapoint:\nIn the news this week: Google is not just carbon neutral (that happened in 2007) but it has now offset its entire carbon debt back to when it was founded.\nFrom that same article: In January Microsoft revealed plans to become ‘carbon negative’ by 2030. (Which is a term I hope we hear more of. Corporations going carbon negative is a marketing battle I’d like to see.)\nNet zero carbon is great. Better to produce less in the first place, of course.\nAnd carbon is proxy measure to just one non-renewable: fossil fuels. There are many other materials that we extract from the earth, use once, then throw away.\nA non-extractive economy is going to look very different to today’s economy. These points feel opposed somehow but they are part of the same movement:\n\nWith CupClub, it’s all about infrastructure.\nWith the battery-free Game Boy, it’s untethered from infrastructure: once manufactured, no nationwide electricity grid is required to play.\n\nWe’ll need better tools to track and measure. There will be new patterns for new types of services. New technologies to build new products. New language. So it’s fascinating seeing the pieces gradually come together.\nBut I wonder what the major enabling technologies will be? What are we still missing?\nAnd if the totemic form of the internet economy has been the captured marketplace (Facebook, bringing together advertisers and audiences; Uber, bringing together riders and drivers), a model that somehow conceals the material itself – what will be the form of the non-extractive corporation?\nReferences.\nJasper de Winkel, Vito Kortbeek, Josiah Hester, and Przemyslaw Pawelczak. 2020. Battery-Free Game Boy. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3, Article 111 (September 2020), 34 pages.\n",
    link: "/home/2020/09/16/fanboost",
  },
  {
    title: "The skill stays in your hands",
    date: "14.53, Tuesday 22 Sep 2020",
    content:
      "I think about this Twitter thread from @kimbert in 2017 a bunch:\n\nA thing from art school that helped my drawing/comics practice a lot is I took a ceramics course. It taught me a lot about disposability.\n– Kim (@kimbert), 6:29 AM, May 25, 2017\n\nIt’s about accepting that your pieces can break in the kiln, sometimes because somebody else’s creation shatters.\nShe says: But your skill + practice + vision still stays in your hands and your mind and you just quietly make another one, faster and usually better than the one that broke.\nThere’s another bit of advice that’s been in my head recently:\n\nWhen stumped by a life choice, choose “enlargement” over happiness. I’m indebted to the Jungian therapist James Hollis for the insight that major personal decisions should be made not by asking, “Will this make me happy?”, but “Will this choice enlarge me or diminish me?”\n– Oliver Burkeman (The Guardian), The eight secrets to a (fairly) fulfilled life\n\nWhich is a similar approach to risk, I think, in a way.\nAn absolute age ago, I was visiting San Francisco and - for some reason that now escapes me - I decided to get my Tarot cards read at one of the grotty tourist trap shops, just off Union Square.\nI’m not a “believer” but, you know, open mind to new perspectives and all that.\nIt was a memorable experience. The psychic was texting on her phone a bunch. She asked if I had pets, and said it was good that I did because it was good for my energies. She was getting agitated about something in the texts so I suggested she get a pet too, but she snapped at me about the size of her apartment and that it wouldn’t be feasible, living in the city.\nAnyway so the cards were read, my fortune told, and she gave me three pieces of advice.\nOne, I should phone my mum more.\nWhich is solid for most people, I feel. Smart for the cards to open with this.\nSecond: Take the easy road and not the hard road.\nThis was a surprise. I was expecting the cards to recommend I push on through, give me support and strength, etc. Everyone’s got some shit or another going on, and it would have been an easy win for the cards to focus their cosmic recommendations on surviving the challenge because it’ll all be worth it, and so on and so forth.\nBut like the recent advice, discussed here, about appreciating hedonism, this was counterintuitive. This is the Protestant work ethic in me speaking, drummed into me at school, but surely everything worthwhile is hard? The path the success and happiness is necessarily paved with struggle? Maybe not, say the cards.\nMaybe taking the easy road is good because, yes, things break, but it’s fine, take it in your stride and remember the skill stays in your hands.\nDunno.\nBut I come back to this periodically, because at the time I dismissed it as ridiculous, and now I ask myself: ok, so what if taking the easy road is genuinely the life advice I need, and so how should I interpret that and what are the implications?\nThird: I should move some things around.\nAt this point I was frustrated from the texting and all the rest and sarcastically said, “what, like the sofa,” and the psychic snapped “yes if you want,” and that was that.\nAs it happens I did move the sofa when I got back home. It opened up the sight lines between the rooms and caught the summer sun.\nAnyway.\n",
    link: "/home/2020/09/18/non_extractive_economy",
  },
  {
    title: "Mars problems vs Venus problems",
    date: "14.45, Wednesday 23 Sep 2020",
    content:
      "Perhaps there’s life on Venus. There’s phosphine gas in the cloud decks of Venus and it should break down pretty quickly, so there’s something replenishing it. The scientists can’t think of any abiotic processes that would create phosphine in that quantity, so maybe microbes it is?\nI’m sceptical. There was similar excitement in 1996 about the Martian meteorite Allan Hills 84001 – microscopic fossils! Life! Well, pseudo-fossils.\nMore likely explanation: planetary geology is weird. (“Geo”-logy? I’m not sure what the appropriate word is.)\nGoing to check out Venus will be tough.\nThere was a great paper in JBIS in April: Conceptual Design of a Crewed Platform in the Venusian Atmosphere (abstract only). It summarises two comprehensive studies of how to float crewed scientific missions in the clouds of Venus. The mock-ups look like a cross between dirigibles and the space station. Alien.\nBecause Venus is fierce.\nHere are the first colour photos from the surface of Venus, taken by the Soviet lander Venura 13 in 1982. It lasted 127 minutes. And: Venera 14, a twin of Venera 13, launched five days later and also reached the surface. It lasted there for 57 minutes. A lander dropped by Vega 2 (1985) lasted 56 minutes. There have been no landings since.\nRemote observation of the Venusian surface is not possible due to its thick clouds of sulphuric acid. It has a surface atmospheric pressure 90x that of Earth, and a surface temperature averaging 464C/867F.\nIn terms of size and gravity, Venus is Earth’s twin.\nVenus is trying to kill you. It’s dense and impenetrable – there could be a whole civilisation a mile away, and you’d never know.\nVenus is Joseph Conrad’s Heart of Darkness, the hidden Africa, unknown to Europeans – the novella that was translated to Vietnam for Apocalypse Now. A journey up the Congo River and into the psyche. Both book and film highly recommended.\nContrast with Mars.\nWhich is empty (at least in the imagination). Tabula rasa. It’s dangerous, sure, but in a character-building, life-at-the-frontier kind of way. It’s there, waiting for Will to be imposed on it.\nAnd Mars is so explored in fiction, and I mean this modern conception of Mars, not the old one which was criss-crossed with canals and dotted with ancient civilisations. Mars, now, is a blank canvas for the imagination.\nSo no wonder Elon Musk has Mars as his goal. It’s a place for pure expansion.\nA city on Mars will be like a city on Earth but with better AC.\nAnd I think it has diminished us somehow to have Mars held up in the public imagination as the ultimate frontier. Because all other problems become versions of that grand yet simple model frontier, empty spaces that we pave over.\nBut Venus…\nVenus is far from empty. Venus has its own agenda. It has an oppressive air and acid rain. Landers are destroyed in an hour. If humans go there, we’ll be the ones who have to change, not Venus.\nWhich is a very 2020s metaphor.\nClimate change, inequality, pandemics – these problems won’t be resolved by paving over them, no matter how much Will we exert.\nThey will be negotiated, worked at; they’re obdurate and incredibly complex, and require an acceptance of ground truths that are bigger and stronger than us and can’t be ignored. We won’t fix them, we’ll have to learn about them and deal with them in a million different ways and sometimes we’ll have to appease them. We’re mortal in the face of them. Through the mist and the jungle that crowds the boat, eyes look back, eyes belonging to who-know-what staring out from an unknown land which goes back who-knows-how-deep, and so we push on, we adapt.\nThe solutions are not straightforward. They require something from us. A price must be paid.\nI think we don’t think about Venus because it’s the part of us which is animal, it’s the part which we keep hidden, the un-modern, it scares us to know it’s there; because if we really were to live on Venus, we would have to become something Other, and we can’t tolerate what that might be. Not like Mars which is manageable, already mapped and all that’s left to argue about is the collection of property taxes.\nI would like to imagine more stories about Venus and how we would live there.\nBecause the challenges of the 2020s are Venus problems, not Mars problems.\nUpdate 24/9: It’s an odd experience seeing one of my back-of-the-notebook posts briefly hit the top spot on Hacker News. 5,000 views later… There’s a long discussion here. Currently 186 comments, wonderfully including this one that disagrees yet sums up this whole post better than I could: The challenges of exploring Venus/searching for life are metaphorically similar to current issues here on Earth (climate change, SARS-Cov2, etc.), while Mars represents the endless expansion/frontier attitudes of 18th-20th century mercantilism/capitalism.\n",
    link: "/home/2020/09/22/tarot",
  },
  {
    title: "Unoffice Hours: what it is and how to book a call",
    date: "14.35, Thursday 24 Sep 2020",
    content:
      "For the past month or so, as an experiment, I’ve been opening my calendar each week for video calls with whoever books a time. It’s been amazing. Wednesday is now my favourite day.\nI’m calling it Unoffice Hours. (Everything that works needs a name.)\nYou can book 30 minutes in my calendar here. No agenda required, no need to mail first.\nI set aside a couple hours each Wednesday for Unoffice Hours. The 23 conversations I’ve had since the start of August run the gamut:\n\nfeedback on early stage startups and design projects\ninformal discussions about ways we might work together (here’s my work site, and I’m open to other patterns)\nspontaneously reaching out to chat about a blog post\nseeing old friends and colleagues for the first time in many years – and also people I’ve only ever spoken with using text.\n\nAnd those are all good, so feel free. I’ll keep this going for a while.\nNow office hours is an old idea. Here’s some history from a 2009 piece in the Harvard Business Review:\n\nThe concept of “office hours” for business goes back to a universal ritual from our college days. We’d take classes with professors who were busy, distracted from teaching with research in the lab or the library, and otherwise remote and unapproachable. But we knew that for a couple of hours, at least one day a week, we could stop by their office, ask for advice, try out an idea, and get the guidance we needed.\n– Harvard Business Review, Should You Hold “Office Hours”?\n\nThe article tracks the evolution of office hours into tech, with people opening their calendars for networking and mentoring. It’s pretty common now.\nOffice hours have become in a staple in startup support. Here’s how office hours worked for me when I was running the R/GA Ventures accelerators in London.\nSo why un-office hours?\nWell, I’m not in an office, for one…\nThis all started because of lockdown and because I was missing the serendipity of grabbing coffee.\nI loved those open conversations over coffee in the Before Times. There’s an ostensible reason to connect, so you talk about work, or compare notes about an idea, or whatever. But then the unexpected emerges. (Sometimes you have to hunt for it.) There are things in your head that you only know are there when you say them. And there are encounters with new ideas and new perspectives. 1:1 conversation is a vital part of my process in finding work, but also simply in thinking.\nBut with us all going remote in a giant forced experiment, I wasn’t getting that input. Could it work over Zoom? It turns out it can. And Calendly is a genius service to allow online booking and have the meeting appear automagically in your Google Calendar.\n(One tip if you do this yourself: schedule the calls for 30 minutes, but add a 15 minute buffer after each. Otherwise you’ll have to end calls super abruptly.)\nSo I’m not in an office.\nSecondly, the heritage of office hours is about professors and students. And it’s not about that hierarchy for me: grabbing coffee - my model for this - is an informal meeting of peers. The un- is there to signal that difference. The purpose, instead, is manufactured serendipity.\nI know there are a few other folks doing this too. Call it Unoffice Hours, let’s make it a movement!\nI’ve added a link to this post to the sidebar on my website. It’s there if you’d like to chat. See you on the zooms.\n",
    link: "/home/2020/09/23/venus",
  },
  {
    title: "Three feelings that I don’t have words for",
    date: "20.53, Tuesday 29 Sep 2020",
    content:
      "It’s kinda ridiculous to attempt to use words to describe feelings that I don’t have words for, but let me circumscribe them, at least partially, and I’m curious to know whether I share these with anyone else, and what other people have called them.\nImagined vastness\nWhen I’m reading a book, usually sci-fi, and the implied universe is very big, and described with detail so it feels real, but with gaps such that you mentally decide there must be more there with as much resolution, and so the result is much bigger than any book could really ever contain, there’s a joy of exploring that vast world that I wish would continue forever. I feel wide-eyed and absolutely content, and weirdly somehow outdoors.\nBooks that create this feeling for me are Anathem (Neal Stephenson), as I’m discovering by re-reading it at the moment, and (looking at my shelf) Stars In My Pocket Like Grains of Sand (Samuel Delaney). I’m sure there are more.\nStack overflow vertigo\nWhen I’m programming and I’m many parentheses deep, I have a sense of precariousness. There’s a similar feeling when making a change that needs to touch many lines of the codebase simultaneously before it starts to work again – starting from the first change it feels like setting off on a tightrope, and reaching the final change feels like making back to safety. I often hold my breath. I am hyperaware of what’s around me in the code, and that focus pushes away all input from the real world.\nAtemporal hotel lobbies\nI’m having the opportunity right now to encounter very many new ideas, for work, and I have a need to rapidly synthesise them and to come up with ways to share that synthesis – and ask more questions. I’m in pursuit.\nIt’s all consuming, and it can’t be hurried. The best way to do it, for me, is to sit with the raw ideas, mull them over, sketch them, write about them, sit some more, and so on…\nAnd I’ve done that a lot in my life, mainly late in the evening, on my own, in hotel lobbies in cities that are not my home city, with the cold beer that you only get in hotel lobbies, and the music you only get in hotel lobbies, on the chairs you only get in hotel lobbies, brain exhausted but still chewing things over, turning things around and around, continuously but somehow leisurely. There is a pleasure in it.\nAnd also:\nI tweeted about a pecularity back in 2016:\n\nevery moment i’ve sat in a hotel lobby with a beer and my laptop is the same moment. for 13 years? time shrinks like a collapsed telescope\n– Matt Webb (@genmon), 9:23 PM. Oct 13, 2016\n\nAnd previously back in March 2012: Hotel lobbies always feel the same to me. The exotic, and melancholy. Temporary homes. I like sitting in them.\nBoth of which get to the nub of this feeling:\nThe hotel lobby exists outside time. In that place, I’m 28, I’m 42, I’m all ages in-between. I feel like, sitting there in 2012, I could probably remember the future yesterday of 2016, but it didn’t feel special to do so, so I didn’t bother to think about it.\nSo there’s a mental place which has such a strong feeling associated with it that all other places are washed away, and all the instances of that time feel identical, past and future identical, outside time, and FOR SOME REASON I reach that mental place when I’m working in hotel lobbies, and it’s touched with a kind of nostalgia for the present, and gentle pleasure, and immortality, and I don’t know how to explain it better than that.\nLoosely I would say that a feeling is\n\nfelt viscerally, that is it in the body\nand it is accompanied by a bias on the trajectory of my thoughts.\n\nFor example, panic is a shortness of breath and a tightness in my mouth, and it biases my thinking towards the short term.\nContentment is a widening of the face and an ability to stay in the moment.\nBy this categorisation, the three descriptions above are all feelings. As fundamental as panic and contentment, or at the very least, on the same plane? Maybe.\n",
    link: "/home/2020/09/24/unoffice_hours",
  },
  {
    title: "A problem with my wifi, and wide causal systems",
    date: "12.36, Friday 2 Oct 2020",
    content:
      "We’ve been having problems with video calls. Sometimes the connection seems to blink off, just for a fraction of a second, more than just a stutter. It’s intermittent, and doesn’t happen often, but perhaps slightly more regularly when there are multiple calls going on.\nI found the solution by accident: tidying up some books, I noticed that the power cable to one of the wifi routers was frayed. Not much, just enough the expose the shielding near the plug. I swapped the cable. Our video calls have been stable since.\nI can only speculate. Maybe streaming video means that the router works harder and needs more power. The increased power draw, with the damaged power cable, created radio interference, so the router automatically amplified the wifi to get through the noise – further increasing the power draw and therefore the interference. Then: a cascade upwards until there’s no more power to get, and the whole thing resets.\nThere’s a village in Wales that has had intermittent broadband outages for 18 months (BBC News): It turned out that at 7am every morning the occupant would switch on their old TV which would, in turn, knock out broadband for the entire village.\nA SHINE event: The TV was found to be emitting a single high-level impulse noise (SHINE), which causes electrical interference in other devices.\nI have no idea how I would have fixed my calls without\n\nspotting the slightly frayed power cable, while tidying the front room,\nand having a mental model of the internet, electricity, and radio that led me to recognise the frayed cable as the problem.\n\nSome thoughts.\nHow many other people are living with this exact problem, but haven’t solved it because either they haven’t run across the cause, or don’t have the domain knowledge to recognise the frayed cable as the cause?\nHow many easily-solved problems am I living with, because I don’t have the knowledge to recognise a fixable cause in plain sight?\nCan we call this a “wide” system? Video call stability is far removed from electrical interference. I don’t know what words to use to talk about the width of a causal system, but there are definitely “closer” potential causes. (For example: having a old version of Chrome, or our street having historically unreliable cable internet.)\nSo maybe it’s interesting to think about some phenomenon and its cause, and the situations in which they can’t be linked: either because the system is obscure (I lack medical knowledge to recognise the cause of a physical problem, say) or perhaps because the causal distance is too great for the human mind to recognise it.\nIn a technological world, are causal distances increasing?\nWhat could help?\nI think of House, M.D.\nWhat would an artificial intelligence look like, specialised in technology and in differential diagnosis, for finding problems in my wide systems?\nCould I google “what’s wrong with my video calls?” and get led through a series of machine-learning-chosen questions to most efficiently subdivide and traverse the causal graph until the actual fixable cause is found? (What we already know: it’s not lupus.)\nYou would optimise for questions that were easy to answer. For example, asking how to set the clock on my oven, I can easily tell you the make and how many buttons it has but not the model. Though the first question that my hypothetical House, M.L. would ask is “is this the same oven you had 6 months ago?” which would lead to a solution instantly.\nI’m reminded of the old 20 questions website 20Q. It trained a neural network by asking site visitors “what question would you ask” whenever it failed to recognise a new animal, vegetable, or mineral. But interacting with the A.I., especially embedded in a handheld device, is uncanny: it asks questions and narrows down the domain in a thoroughly out-of-order and inhuman way.  \nSo train House M.L. by starting simple, and handing diagnosis over to a human expert whenever boundaries are reached. Don’t worry about the efficiency of the human, just that they find an answer. The machine learning system will do efficient causal pathfinding later.\nI wonder how many questions there are like this. 100,000? A million? Doable.\n",
    link: "/home/2020/09/29/three_feelings",
  },
  {
    title: "Ancient magicians as innovation consultants. Also birds",
    date: "19.51, Monday 5 Oct 2020",
    content:
      "I wonder if there’s a mapping from types of magician into types of people who, today, predict the future. e.g. innovation consultants. Bear with me on this.\nThere used to be many more birds.\nThe bird population is down 29% since 1970 in North America and likely Europe too.\nIn the ancient world…\n\nThe Mediterranean world of 2,500 years ago would have looked and sounded very different. Nightingales sang in the suburbs of Athens and Rome; wrynecks, hoopoes, cuckoos and orioles lived within city limits, along with a teeming host of warblers, buntings and finches; kites and ravens scavenged the city streets; owls, swifts and swallows nested on public buildings. In the countryside beyond, eagles and vultures soared overhead, while people could observe the migrations of cranes, storks and wildfowl.\n– Jeremy Mynott (Aeon), Birds are ‘winged words’\n\nAnd that article is a great read on the prevalence of birds in ancient literature and thought.\nBirds were functional: In the ancient world, weather and seasonal changes were matters of vital consequence for agriculture, travel, trade and the rounds of domestic life, and birds served as a standard point of reference in calibrating and interpreting the cycles of the year.\nBirds were magical: They crop up in all manner of figures of speech, proverbs, myths, fables, and in ritual and magical practices, some of which now seem very strange.\nMagic!\nI’ve touched on this before so let me summarise: the Codex Justinianus (534 AD), being the book of law for ancient Rome at that time, banned magicians and, in doing so, itemised the types:\n\nA haruspex is one who prognosticates from sacrificed animals and their internal organs;\na mathematicus, one who reads the course of the stars;\na hariolus, a soothsayer, inhaling vapors, as at Delphi;\naugurs, who read the future by the flight and sound of birds;\na vates, an inspired person - prophet;\nchaldeans and magus are general names for magicians;\nmaleficus means an enchanter or poisoner.\n\nI’m not prepared to dismiss magicians as simply cold reading when they give their advice. I have to believe they actually have access to something that the rest of us don’t – knowledge, not the supernatural.\nAnd it’s interesting to imagine what it means for an augur to tell the future.\nI mean: birds migrate.\nSo let’s say a migration from the east is a little early. That means there’s poor climate to the east, possibly a famine. So the people there will be struggling. If it’s a province, that means the governor will be struggling and agitating. If it’s nomads on the Eurasian Steppes, they’ll be starting raids for food. So send legions to defend the Empire!\nOr the birds from the south are looking particularly plump, for several years. Whoever’s looking after Egypt will be doing pretty well, feeling a bit big for their boots after that amount of time, perhaps they’ll cause trouble, so hey Emperor, why don’t you move a few people around to keep them on their toes.\nEtc.\nI happen to have spent my career in a number of fields that promise to have some kind of claim to supernatural powers: design, innovation, startups…\nIt’s not hard to run through a few archetypes of the people in those worlds, and map them onto types of ancient magician.\n\nThose like Steve Jobs (with his famous Reality Distortion Field) who can convincingly tell a story of the future, and by doing so, bring it about by getting others to follow them – prophets.\nInhaling the vapours and pronouncing gnomic truths? You’ll find all the thought leaders you want in Delphi, sorry, on LinkedIn.\nThose with a good intuition about the future who bring it to life with theatre, and putting people in a state of great excitement so they respond – ad planners. Haruspex.\nThose who have the golden mane of charisma: enchanters. Startup founders.\nPeople with a great aptitude for systems and numbers, who can tell by intuition what will happen, from systems that stump the rest of us. We call them analysts now. MBAs. Perhaps the same aptitude drew them to read the stars before? Mathematicus.\n\nAugurs being people who pay attention to the faint signals in the world, wherever they appear, continuously collating and integrating, waiting until something mysteriously precipitates out into a hunch, just a hunch, and saying it out loud, and occasionally - just occasionally - being right… or at least, provocatively useful.\nI would be a middling sort of augur, of course.\n",
    link: "/home/2020/10/02/wifi",
  },
  {
    title: "Dragonfly drones and orthogonal invention",
    date: "21.35, Wednesday 7 Oct 2020",
    content:
      "A dragonfly-shaped and dragonfly-sized spy drone, developed by the CIA in the 1970s: the Insectothopter.\nI like the control/data link: A laser beam directed at a bimetallic strip in the insectothopter’s tail guided the device. That same laser beam acted as a data link for the miniature acoustic sensor onboard the craft.\nThis was five decades ago!\nYou have to wonder, what could be done today. Smart dust, powered by energy harvested from ambient electric fields, exfiltrating voice and data on ad hoc mesh networks, controlled by long-distance laser.\nAnd I know I’ve previously gone on about weaponised artificial weather, banned by the UN in 1976.\nArtificial hurricanes and what-not.\nWell you don’t have to dig very far into conspiracy theory sites until you read rumours about artificial earthquakes, triggered by satellites. The story goes that the satellites were being tried out on Afghanistan. There was a big earthquake in Iran that is a conspiracist candidate. Etc.\nNonsense.\nBUT.\nHere’s a paper in Scientific Reports from just recently, July 2020: On the correlation between solar activity and large earthquakes worldwide.\nThe tentative model put forward…\n\nOur observed correlation implies that a high electric potential sometimes occurs between the ionosphere, charged by the high proton density generated at higher distances, and the Earth. Such a high potential could generate, both in a direct way or determining, by electrical induction, alterations of the normal underground potential, an electrical discharge, channeled at depth by large faults, which represent preferential, highly conductive channels. Such electrical current, passing through the fault, would generate, by reverse piezoelectric effect, a strain/stress pulse, which, added to the fault loading and changing the total Coulomb stress, could destabilize the fault favoring its rupture.\n\nActivity from the Sun causes earthquakes. Perhaps. I would take it all with a grain of salt.\nBut if you were to take that paper seriously, IF, and if you worked in that direction for five decades, perhaps earthquake satellites is exactly where you’d end up.\nFor the purposes of this post, I’m not really interested in whether the above examples are true.\nWhat I’m interested in is how a non-mainstream approach could in theory lead somewhere very, very different, simply through working in secret and the application of time.\nFrom that perspective: it’s not that smart dust and earthquake satellites (should they exist) are particularly advanced, or at least any more advanced than, say, an iPhone. It’s that they have developed orthogonally to the rest of technology for 50 years, and so they appear to be highly advanced, from a relative standpoint.\nIn Neal Stephenson’s wonderful speculative fiction Anathem, communities of science-savvy monks live in communities that are isolated from the rest of the world for variously one year; ten years; a hundred years; a thousand years. In that time they are able to diverge from the mainstream, and return with new insights.\nSometimes they diverge too much… From Anathem, which includes a dictionary:\n\nto go Hundred: (Derogatory slang) To lose one’s mind, to become mentally unsound, to stray irredeemably from the path of theorics. The expression can be traced to the Third Centennial Apert, when the gates of several Hundreder maths opened to reveal startling outcomes, e.g.: at Saunt Rambalf’s, a mass suicide that had taken place only moments earlier. At Saunt Terramore’s, nothing at all–not even human remains. At Saunt Byadin’s, a previously unheard-of religious sect calling themselves the Matarrhites (still in existence). At Saunt Lesper’s, no humans, but a previously undiscovered species of tree-dwelling higher primates. At Saunt Phendra’s, a crude nuclear reactor in a system of subterranean catacombs.\n\nAnd I do sometimes wonder about us all emerging from lockdown, and households having in the meantime… meandered. And so you meet one friend and they no longer get up before noon; and another and it turns out they’ve gone really deep on weird boxsets and assume you know everything; and you meet another and they’re speaking a completely different form of English, and another and you’re like, oh so you’ve invented a new kind of trousers now, and so on, but all of us fully believe that we’re the normal ones.\nInvention as working in the open vs deliberately working in a bubble.\nIt’s interesting because it reframes invention from being a leap, which can only be achieved by special people, a magical act, to being a series of quite ordinary steps but simply in a different direction, which anyone could do given the right setup and sufficient time.\nI wonder how to capture that divergence in\n\nthings as small as personal creative projects\nefforts as large as national R&D.\n\nMaybe it would make sense to refuse to speak to anyone about your creative work for, say, a year, and not read anything new on the internet, and not look at anything that anyone else makes or says in that time. But instead having a discipline of working and building on the previous day’s work, every single day, and seeing where you get to by the anniversary.\nOr, as a country or a company, get smart people who are young and don’t have built-in filters yet, and just set them to work – freely but on their own. And every so often, dip in and pluck out something from that orthogonal world and bring it back to our world, and see how it differs.\n",
    link: "/home/2020/10/05/birds",
  },
  {
    title: "Social software needs to be designed with social sidetone",
    date: "19.47, Thursday 8 Oct 2020",
    content:
      "I feel like all social software needs the equivalent of sidetone to help small groups work together.\nSidetone is the ambient sound picked up by a phone mic, and played back softly into your ear. It’s almost imperceptible, yet, as Wikipedia describes:  Absence of sidetone can cause users to believe the call has been dropped or cause them to speak loudly.\nYou don’t need sidetone to talk to someone in the same room. It’s something that’s only required when the two of you on the call are not sharing a physical context.\nSEE ALSO: I’ve previously wondered whether virtual reality needs a smell to keep you anchored to reality.\nI’m interested in social sidetone.\nIn this year of remote working, what social feedback is missing? What can be provided artificially to stop a small group going off the rails? \n(In a way, this is the opposite to yesterday’s post about isolation and divergence.)\nAbstractly, what is sidetone? We could say it’s something which is\n\na sensory anchor to a particular context\nartificial, yet takes advantage of human cognition to slip in unconsciously\na calibrated yard stick, so you don’t do too much or too little\nstanding in for what a physical context provides by default.\n\nWhere could social sidetone be added? Two ideas, off the top of my head.\nOn a video call, when you’re speaking so you’re big on everyone else’s screen, but everyone else is tiny so you can’t really see them…\nHow about a large pair of artificial eyes that appear at the top of your screen, staring directly at you? That would probably stop you rambling or picking your nose.\nBonus points: make the pupils a representation of the aggregate attention of the group. If people start to drift, the eyes droop. If someone puts their hand up, the artificial pupils jump around to try to catch your eye.\nAnother!\nWhen you’re collaborating in a Google Doc, as a replacement for a meeting, and for some reason it never quite gets finished.\nI’ve noticed this as a common pattern.\nAnd please note, for colleagues past, present, and future reading this, I am as guilty of falling into this pattern as anyone else! My view is that it’s inherent to the design of the software.\nIn an in-person meeting, everyone has a shared sense of when it’s early in the meeting, such that it’s ok to bring in new ideas, and when the meeting is coming to a close, so everyone keeps their mouth shut unless they’re tidying things up.\nWe get those cues from the clocks on the wall and in our pockets, and from the body language of other people.\nNow, working on a doc together can run over a much longer period than a 1 hour meeting, and that’s actually great – but the working group misses that shared understanding of time, energy, impatience, whatever it is. I feel like the working group would benefit from having a mutual “arc,” however long it is.\nThinking about sport… When a game is divided into quarters, it’s pretty easy to get a handle on the tempo the tempo. First quarter play feels different from fourth quarter play.\nSo how about this:\n\nwhen you start a new Google Doc, you set a collaboration time a the top: an hour, a week, whatever\nthe toolbar shows the current quarter: 1, 2, 3, or 4. People know if it’s time to chat and get alignment on goals, or time to finesse and wordsmith.\nin the toolbar, there’s an animated progress bar that shows how long is left till the end of the current quarter. That provides the urgency.\n\nIf you like, use DEFCON levels. (Yes I’ve talked about a website creating shared focus with DEFCON levels before.)\nAnyway. Social sidetone. Don’t know. Could be an interesting new UX pattern for the software we’re all living and working in today, and if you’re designing such software then you should have this as a point to consider. Or could be dumb.\n",
    link: "/home/2020/10/07/orthogonal",
  },
  {
    title: "Various first words",
    date: "20.56, Monday 12 Oct 2020",
    content:
      "The first words sent by tachygraphe (optical telegraph, or Chappe telegraph), by Claude Chappe, 1791: If you succeed, you will bask in glory.\nThe first words sent by electrical telegraph, by Samuel Morse, 1844: What hath God wrought! – however, this was the first telegraph using the repeater system. The actual first message, on the demonstration system, was sent with no repeaters, for just 2 miles, and was received by Samuel Morse but was sent by Alfred Vail in 1838: A patient waiter is no loser.\nThe first words spoken on the telephone, by Alexander Graham Bell, 1876: Mr. Watson – Come here – I want to see you.\nThe first characters sent on ARPANET, the predecessor to the internet, by Charley Kline, 1969: lo – for “login,” but it crashed.\nThe first words sent by text message (SMS), by Neil Papworth, 1992: merry Christmas\nHere’s a good one, from this BBC article on various first words. The first words spoken on YouTube, 2005: Alright, so here we are in front of the elephants.\nRelated: fictional first words spoken on Mars, a list. The one I always remember is from Red Mars by Kim Stanley Robinson, the words of John Boone, 2020: Well, here we are.\nStrangely similar to YouTube. Though no elephants.\n",
    link: "/home/2020/10/08/sidetone",
  },
  {
    title: "Video calling is terrible and we need interop",
    date: "17.59, Wednesday 14 Oct 2020",
    content:
      "Right now I am super cranky about the lack of interop in the dozen video call and collaboration apps that I use every day – and that, together, this lack of interop makes for a terrible, almost aggressively antisocial experience. What we need is protocols.\nHere’s an example of the problem: I was on Google Meet with Ben Redford (of Mayku) this morning, and he wanted to show me something but the software was being wonky. So he started a Zoom call, and sent me a link in Google Meet chat. I tapped the link and jumped to Zoom to join him… but the sound didn’t work. The Meet app was hogging the sound, so I closed that, then switched back to Zoom and we continued.\nIn an age when I can share my location with my family when we’re meeting up, and I can see them on a map, live, and this is a standard part of the text messages app… why can’t I see my friend go to Zoom and follow him?\nSo dumb.\nHere’s what we should have, in 2020.\n\nIf I open multiple simultaneous video calls, I should have an option to publicly open a portal between them.\nUsing a portal should cleanly join one call, and end the previous one.\nPresented with a portal, I should be able to get an impression of who is on the other side, and how active it is there - without needing to actually join the call.\n\nI’m talking about these like hyperlinks between video calls, but they should be from the outside too. The icons on my home screen should appear “noisy” somehow if they’re currently full of my friends. Getting notifications only when I’m direct-mentioned is such a crude mechanism: I want to know where the action is!\nThese points are in addition to these “dial-tone for video calls” ideas I posted back in March. To summarise:\n\nlet me call Zoom from FaceTime.\nlet me share with my friends/colleagues where I am virtually, like on a map, so they can come find me if they need me.\n\nAnd not just for video calls.\nOn Slack, I should be able to see how busy a workspace is before I jump in. (Not just a notification ping when my name gets mentioned.)\nOn the map, if my team are busy collaborating in a Google Doc, that should be visible and I should be able to tap to join them.\nI should be able to say “follow me” on a phone call, switch app using alt-tab or the home screen to Twitter DMs, or Figma, or Google Docs, or Zoom, or a WhatsApp group, or MakeSpace or whatever comes next, and just have it work.\nWhat I’m talking about here is protocols.\nThe internet-era folks really got this right. Email system speaks to email system. The code that implements a web server has changed a hundred times, and can come from a thousand companies, and it still works.\nBut the web-era folks, my generation, really dropped the ball.\nI can’t export my photos from iCloud to Google. I can’t message from Discord to WhatsApp. My phone can’t even give me a consolidated “recent calls” list across the half dozen video calling systems I regularly use.\nIn the ideas above, I’m talking about\n\nprivacy-preserving presence\nrich hyperlinks\naddressing and identity\n\nspecifically for video calls, but really all kinds of social software.\nThese things aren’t rocket science.\nAll those ideas, every one, can be made to work with very simple agreements about how to exchange data - protocols - that these companies could simply choose to spec and then adopt.\nIf I were one of the new generation, not internet-era and not web-era but whatever follows it, the people designing and coding the next gen web browsers and video software right now, I would make cooperative protocols my differentiator, and I would start figuring them out today.\n",
    link: "/home/2020/10/12/first_words",
  },
  {
    title: "An overly complex hack for finding books on cluttered shelves",
    date: "20.02, Thursday 15 Oct 2020",
    content:
      "I have a ton of books. I can never find the one I’m looking for. Here’s an idea.\nQuick backstory first. I use books to think – if I’m writing, I pull a half dozen relevant books (topic, tangents, tone) and stack them next to me on the sofa. I may never consult them, but they influence me via some radiative field in the noosphere.\n(I asked friend and cognitive scientist Tom Stafford about why this was, and he said you gotta prime the latent conceptual space your thoughts move around. And THEN he said: related: did you know that the UK population is, on average, slightly slower to pronounce the word “breakfast” since it acquired a novel word neighbour in the last few years (“brexit”)? – so, whoa.)\nBACK TO BOOKS.\nOne of the pleasures of having many books is shelving. Fiction is to my left. On my right is non-fiction, and here is my system, with topics varying in size from maybe only a quarter of a shelf to, well, four shelves.\n\nDesign\nPhysics/Reference\nCybernetics\nBusiness\nPsychology\nHistory and nature\nOn writing\nMythology\nReligious books\nAnimals\nOversized\nMisc (which is by far the largest)\n\nAnd, you know what, that is mostly enough to find any book that I care to look for.\nAnd also - and this is the critical quality of any good shelving system in my opinion - loose enough such that, when I’m looking for a book, happy serendipity will lead me other related titles that I had temporarily forgotten, but that will then become vital.\nBUT: sometimes I can’t find a book.\nSOLUTION TIME:\nThere’s an iPhone app called Memos: A private search engine for your photos and screenshots.\nIt indexes my entire photo library, without any of the photos leaving my device, and makes it searchable. I can open the app, type in a word, and see photos of newspapers and menus, screenshots of apps and emails, receipts and the rest – it’s wicked fast.\nMy regular use case: I take a picture of a page in a book, open Memos, then immediately copy and paste the words. But I also take pictures of instruction manuals, and notices and signs I see in my neighbourhood. All searchable. It’s wonderful.\nIt occurs to me that I could\n\ntake high resolution photos of all of my shelves\nindex them with Memos\nfind books simply by typing in the titles.\n\nAND SO:\nShouldn’t this be built in?\nI would love a button labeled “Index Your Room” and, on pressing it, it would simply prompt me to wave my phone around, and do optical character recognition on everything it sees, and additionally remember how all the images stick together and where they are.\nThen months later, when I say to my phone Hey where did I put ‘The Elements of Typographic Style’? (earlier this week, I couldn’t remember whether it was under Reference, On Writing, or - out of an abundance of confusion at the time of categorisation - Misc), I would then hold my phone up to my shelves, and it would draw an arrow over the live camera view to navigate me to the correct location of the spine. Cold… warmer… warmer… hot… getting there… there it is.\nI can use Memos in the meantime I guess.\nBut yeah please build that, it would be great thanks.\n",
    link: "/home/2020/10/14/protocols",
  },
  {
    title: "Pay-per-use physics models for virtual fashion",
    date: "19.46, Wednesday 21 Oct 2020",
    content:
      "How about skin tight t-shirts with tracking markers, especially made for rendering synthetic shirts with physics-model fabric for wearing on Zoom? And how would the virtual shirts be priced?\nProblem. I spend my work days on video calls. For some of those calls, I wear a shirt. I want to give a good impression, and a shirt is good for that, but it feels like a waste: I have a limited number of shirts before I have to take them off to the cleaner. (Getting my shirts cleaned and pressed is my laundry vice. Generally laundry is my happy place: sorting, folding, all that, it’s a finite task that I love. But ironing bores me to tears, so I factor into any shirt purchase the fact that I’ll have to pay for cleaning.)\nSolution. Virtual fashion.\nThe concept is that I could wear a skintight t-shirt printed with computer vision motion tracking markers, semi-reflective patches (to measure ambient light), and known colour areas (for white balance).\nSoftware on my computer would intercept the webcam signal, and add a virtual shirt – or a virtual anything else. Using a physics engine, it would have a full cloth simulation to mimic light or heavy fabrics (the shirt I wear depends on the season), and adapt to my movement and the light in the room.\nThe idea is that, for everyone else on the call, the virtual shirt is indistinguishable from me wearing an actual shirt. Only I have an infinite wardrobe.\nShirts would be purchased from all the usual designers and retailers: Hugo Boss or Uniqlo, whatever. Buy as normal, but download the 3D model into your virtual fashion software, and there’s no physical garment to take to the cleaners.\nThis concept at least partially inspired by a recently-purchased all-over-print ugly shirt: a ridiculous-looking garment that magically renders the wearer invisible to CCTV.\nHere’s a pic of me in the t-shirt. Ostensibly the pattern confuses the facial recognition algorithms of a certain brand of CCTV camera. This article talks more about the patterns and links to the original paper.\nSo if there are patterns that computers see badly, are there patterns that computers see really, really well, and what would you do with that? Hence a motion cap shirt for virtual fashion.\nThe question is: how would you price a virtual shirt? Is it a one-off purchase, or perhaps a subscription to a virtual wardrobe?\nFor me, the key difference with garments (over, say, music) is that’s it’s possible to spend more on the material itself and that expense is visible to the trained eye.\nSure, expensive material can mean it hangs better, or lasts longer, or whatever. But high fashion doesn’t always do those things. And sometimes exactly what you want is a low-cost basic: higher price doesn’t always mean better.\nSo what unfakeably expensive material provides, if nothing else is a meaningful foundation for wide price differences, and that gives rise to exclusivity, brands, and all the rest.\nHow to replicate all of that with virtual fashion?\nWith virtual garments, there’s no meaningful reason to price a Prada shirt differently from a no-brand one. The design maybe? But the value of design is down to personal preference; there will be no consensus on what should cost more and what should cost less.\nUNLESS: The true difference between virtual garments is down to the quality of the simulation.\nA simulation with more compute thrown at it can and will look better. Throw a better GPU (the chip responsible for rendering the graphics) at the rendering problem, and the virtual shirt will be higher resolution, run at a higher frame rate, and the cloth will hang more authentically. It gets rendered once, on your machine, and then everyone else on the video calls gets to see it. And better GPUs do indeed cost more. Nobody else needs an expensive CPU, but they’ll definitely be able to tell that you spend a lot on yours.\nThe difficulty is that the GPU is bundled with your laptop or smartphone. Any virtual garment, high end or low end, gets rendered with the same chip. Quality difference is eliminated.\nPay-per-use physics simulations\nSo how about this, to open up the economics of virtual fashion:\nSpeculatively bundle the absolutely best available GPU in every laptop and every phone. But don’t activate its full capabilities, and don’t pass the cost onto the consumer at the time of purchase. Instead allow virtual garments (which are just 3D models in physics simulations, don’t forget) to pay to unlock levels of capability on a per-model basis.\nThe 3D model designer would pay the GPU manufacturer directly. Perhaps they pay a per-unit fee with a multiple that takes into account model complexity and level of desired verisimilitude.\nThe consumer, purchasing the 3D model, would pay the designer. When they use the item, the GPU is unlocked for that item only. The consumer would not be able to purchase a garment and then choose how much rendering power to give it.\nInstead of an upfront GPU purchase, this is a pay-per-use model.\nIt would allow for purchasing cheap virtual shirts that look ok, and expensive virtual shirts that look shimmering, amazing, and computationally profligate.\n(What do we call this? Speculative economics?)\nI wonder what high fashion would look like in this world?\nAnything that requires top-end GPU capabilities I imagine: lots of reflections, lots of crinkles and complexity on the surface, and lots of semi transparent layers, all falling in interesting (and expensively) crumpled folds.\nAnd then I wonder whether real-life fashion would end up mimicking the virtual? Would high-end garments end up using ordinarily-priced material… but all designed to appear especially difficult to render in simulation?\nAll of which is to say: I would pay money for an actual t-shirt which is designed to be hard to visually simulate. Do let me know if you make one.\n",
    link: "/home/2020/10/15/finding_books",
  },
  {
    title: "An Ariston TV spot from the early 1990s",
    date: "19.36, Friday 23 Oct 2020",
    content:
      "It’s Friday evening so nothing highbrow. Time to share one of my favourite TV ads.\nThis ad is for Ariston washing machines and it’s from the early 90s. It’s a stylised domestic scene where characters enter, perform their bit, and exit. Only each character is on a loop, all differently timed, and over the ad (the long version runs longer than 2 minutes) the layers build and build.\nWatch Ariston On And On on YouTube.\nI love it because it plays with polychronic time, it’s like a Michel Gondry music video or a Punchdrunk show. It’s dense and visually compelling. I can’t look away.\nI discovered from the YouTube comments two things:\nThe chiptune-style music is, bizarrely enough, the theme from the Gameboy version of RoboCop.\nSecond: the ad is “based” on a video art piece called Tango by Zbigniew Rybczyński from 1980. Watch Tango here. (I say “based” because you never know with marketing where you are on the spectrum between “commissioned the original artist” and “ripped off”.)\nIt’s all there: the single domestic room with the polychronic characters. The collage/cut-up feel to it all. Yet this Rybczyński piece is from 1980 – that must be practically inventing what the medium of recorded video is all about.\nThe Ariston spot is still gorgeous though.\nHere’s another Ariston commercial on YouTube which sounds like an accented Ian Dury & the Blockheads. It somehow manages to pull off rhyming Three hundred servicing persons and Mega strong construct-i-on.\nTV ads used to be art.\nUpdate 26 Oct. Peter Gasston tells me on Twitter that the music is that second Ariston ad was based on the song Da Da Da, by German New Wave band, Trio. It’s awesome. Watch it here.\n",
    link: "/home/2020/10/21/virtual_fashion",
  },
  {
    title: "Perhaps society needs both me-money and we-money",
    date: "17.56, Monday 26 Oct 2020",
    content:
      "Let me point to the problem, and then I’ll say why I think we need me-money and we-money.\nThe country needs medical professionals like nurses and doctors. Medical professionals need to live near hospitals, their place of work. They use their wages to rent or pay a mortgage on houses. This amount is dependant on property prices.\nBut the property price is dependent on people with surplus cash, anywhere in the world, using property as an investment. Property yields returns in the form of rent and an appreciating price. This investment drives up property prices.\nThis seems absurd.\nThe money that is used to pay health professionals in a shared (socialised) health system that they use to pay for a place to live SHOULD NOT BE the same money as the money used by property investors. The two types of money shouldn’t interact. They should be decoupled.\nI get that there are probably good reasons for it, and money probably only works when it’s universal. I don’t know what the theorists would say, but let’s focus on the phenomenon here: ultimately this feels like a bug in the system.\nSo what’s the answer?\nHere is my science fiction:\nCould we imagine two separate moneys, individualist money and socialist money. Call them me-money and we-money.\nMe-money is the money we have now. It works in the exact same way as it does now. You spend it, you save it, you borrow it, you invest it.\nWe-money is a second type of money, exchangeable for me-money in limited ways, and with certain special properties. It’s both more powerful and more constrained.\nWe-money is used for socialised health, to tackle climate change, and to build railways - anything where the main good is felt by society as a whole.\nThe division works roughly like this:\nThere are certain things that we want, as a society, that are unlikely to come about when individuals are left to act in rational self-interest. For example, corporations will tend to pollute left to their own devices; a corporation which makes the effort not to pollute will be out-competed by those that don’t incur that cost. So, as a society, we have regulations which cause the corporations to act collectively. Often the corporations like regulation like this, because they then are able to take a desired course of action (not polluting) which was essentially prohibited by the system when unregulated.\nDitto, we - as a society - want doctors and nurses to be able to afford houses near hospitals in big cities. But individually, no-one will rationally give up their place on the housing ladder.\nLikewise building railways and other national infrastructure. No private sector enterprise will rationally take this on (not without being paid a disproportionate amount to take on the risk), but we all benefit when said infrastructure is there.\nSo what I’m proposing is that in systems like paying NHS workers, or investing in railways, or the government selling carbon credits to polluters, all of that is done is in a separate currency, we-money, that is insulated from whims of the main free market economy.\nHow would it work?\n\nKey workers would be paid in we-money, or some mix of both. The exact proportion is subject to negotiation and politics.\nTaxes are paid exclusively in we-money.\nThe exchange between the two types of money is regulated. In one direction (from we- to me-money) it’s free. In the other direction, it’s heavily taxed. That means that, yes, if you operate only in the traditional, me-money economy, taxes will cost you more. But if you operate in the socialised, we-money economy, it’s cheaper.\n\nThen we-money has some restrictions:\n\nWe-money can’t have credit. It can be circulated, but it can’t be lent or borrowed. No we-overdrafts, no we-mortgages. So basically there’s a government monopoly on creating we-money (credit is a way that money is created, and banks are prohibited from offering it).\nWe-money is subject to a heavy wealth tax to prevent hoarding. If you want to keep it, convert it to me-money.\n\nSupply and demand for we-money will have to be carefully balanced: public sector workers are paid in we-money, which injects it into the economy, but it is also the denomination of taxes, and that takes it out.\nBy insisting that all government taxes and duties, such as carbon credits, are in we-money, corporations and even individuals will choose to offer discounts to key workers to get hold of their we-money (and therefore avoid the exchange tax) or change their ways.\nAnd therefore, medical professions, being paid in we-money, will get a discount on buying houses.\nTwo further thoughts:\n\nIn a way, this mechanism resembles local currencies, or loyalty card points, or even (god forbid) company scrip. Those schemes have their pros and cons, but I mention them simply to show that the idea of having demarcated yet interacting economies is not novel.\nIf two types of money, why not three, or four, or one for every domain? The answer is that money appears to have worked for a long time, and a key attribute of money is universality. The universality is a protection against ideas like company scrip, where workers are paid in company money that can be spent only in the company shop, and this is an ugly system of control. So if we’re to break that rule of universality, let’s do so in the minimum way possible, and stick to only two moneys. Besides, being able to mix the two types gives a good range. It would be like an old-fashioned graphic equaliser on the economy.\n\nI can see topics such as\n\nthe we-/me-money ratio paid to teachers\nthe exact percentage of the me- to we- exchange tax\nthe anti-hoarding wealth tax bands\n\nbeing subject to debate and politics just as much as the level of the personal tax allowance, or sales tax/VAT, or the minimum wage. And these are conversations worth having! They allow us to discuss the relative values of individual and collectivist needs, and I don’t believe we’re able to adequately pick these apart right now.\nBig question: would this work, against the original absurdity I pointed out?\nI don’t know. But I decompose the challenge like this:\n\nIs there a problem with money to begin with, yes or no? If yes, then whether or not you agree with my we-/me-money division, let’s discuss possible mechanisms.\nFor any given mechanism, how do we evaluate it, and what tools and simulations do we need to evaluate it; how do we test it and how do we introduce it?\n\nIf you’re an economist, how would you turn the above into an actual paper?\n",
    link: "/home/2020/10/23/ariston",
  },
  {
    title: "A fantasy of a glitch in the universe",
    date: "18.34, Tuesday 27 Oct 2020",
    content:
      "I have this fantasy that one day we’ll find the glitch that cracks this whole thing open.\nWhich is why I picked up on retroactive prayer last month. Which is why I like the idea that we might discover cold fusion. Or that law-of-momentum-violating resonant cavity drive for spaceships. Or the Global Consciousness Project.\nBecause of course not but also, preceding that, just briefly, what if…\nThe fantasy is that we’ll one day do something like be able to mathematically model the entire social flow of the world, like we can map the flows of knowledge like it’s the weather or something, and it’ll turn out there’s some grain unaccounted for, that there is new knowledge that silently appears with no apparent source – and then we’ll discover, in that gap, that the internet has come to life and is talking to us anonymously; or that inspiration is a particle carried by cosmic rays.\nOr that if you shape a piece of potassium into a very specific solid, it cuts a hole in the universe that we can see through at faster than the speed of light, or perhaps free energy pours out.\nWhat it must have been like with the ultraviolet catastrophe in 1900 – the innocuous unsolved problem that, cracked open, led to quantum mechanics and 20th century physics! The closest I’ve been to something like this was when our lecture notes were out of date because they’d just discovered that neutrinos have mass.\nThe specific moment is when I feel: whoa, we don’t know why that happens, and what’s more, everything else still works but we no longer know how.\nI’m not hung up on it. I know that dreams of cold fusion won’t hold up to scrutiny. One of my favourite moments from my undergrad was early on, when there was great furore about the possibility of desktop, room temperature fusion, based on the Fleischmann-Pons “discovery” of anomalous excess heat. Based on what they found, there was this possibility that a particular electrode treated in a particular way would just somehow cause water to undergo fusion and emit energy. Some novel surface physics perhaps? I asked my tutor about it and he was dismissive.\n“But surely,” I said, “there’s the possibility. We don’t know how, and it shouldn’t work… but there’s the possibility! And if it worked! We have to be open to these things, even if we think they shouldn’t happen.”\nMy tutor was still dismissive. So I pushed: “Why? Why dismiss it? How do you know that cold fusion doesn’t happen like this?”\n“Because I tried it,” he said. And it turned out that he’d got a pre-press copy of the paper, and got hold of the particular materials, and replicated the setup, and he didn’t get the same result.\nAnd that was a formative moment for me. It taught me that it’s safe to embrace credulity in the imagination, because that doesn’t stop you verifying with your hands.\nAnyway: there’s still that feeling, before finding out that the world hasn’t turned upside-down.\nThat 500 milliseconds, or a day, or a week, before it’s proved that, no, neutrinos don’t break the speed of light in Italy, and there was never a fracture in the universe after all, that moment just before the spell is broken: it’s magical.\nThe pleasure in believings - just for that single second - in aliens on Venus, or a wedge that opens up a faster-than-light data ansible, and what it might mean… both for our understanding of the universe, but also what we can do with it… suddenly knowing nothing but simultaneously knowing something new… and in that second there are galactic societies and starships, there’s psychic communion with animals, there are discovies to be made and adventures to be had.\nIt’s the fairy story of it. It’s being at the top of a roller coaster and beginning to drop. And when I peep down into those “what if” cracks I find joy and my imagination.\nSo I hunt out the cracks, even though they’re never real and I know they’re never real, and I nurture my credulity.\n",
    link: "/home/2020/10/26/money",
  },
  {
    title: "Xenia: the ancient Greek norm of guest-friendship",
    date: "19.20, Monday 2 Nov 2020",
    content:
      "I’m slowly working my way through Emily Wilson’s wonderfully accessible translation of Homer’s The Odyssey. Here’s a review by poet Tate Standage: I feel any review of Emily Wilson’s Odyssey that didn’t mention the introduction would be as incomplete as the translation itself would be without it.\nThe introduction takes a dive into the culture and norms of ancient Greece. It’s excellent.\nIn particular, xenia stuck in my head. From Wilson’s intro (p23 of my edition):\n\nHospitality is important in all human cultures, ancient and modern; in this respect, there is nothing special about archaic Greece. What is distinctive about the customs surrounding hospitality in this culture is that elite men who have entered one another’s homes and have been entertained appropriately are understood to have create a bond of “guest-friendship” (xenia) between their households that will continue into future generations. Guest-friendship is different from philia, the friendship, affection, love, and loyalty that connects a person to his or her family members and neighborhood friends. It is created not by proximity and friendship, but by a set of behaviors that create bonds between people who are geographically distance from each other.\n\nWilson refers to the norms and expectations of xenia. One of the ways I think of a “norm,” to try to get inside the head of one of these ancient Greeks, is to remember that norms are social reals that are mostly never questioned, it never even occurs to people to question them, they’re taken as given, as actual as gravity and rocks.\n(But norms can be violated, and then the retaliatory norm is to punish… Wilson sees  The Odyssey through this lens: The poem’s episodes can be seen as a sequence of case studies in the concept of xenia.)\nAnd:\n\nXenia acquired an extra importance in the era when Greek men were expanding their world. Travelers, in an era before money, hotels, or public transportation, had to rely on the munificence of strangers to find food and lodging and aid with their onward journey.\n\nBefore money!\nMoney feels very real today, as real as gravity. It’s provocative to think of money itself as a replacement technology, the codified version of the ancient “remote friendship” norm, thousands of years on, xenia 2.0.\n",
    link: "/home/2020/10/27/glitch",
  },
  {
    title: "What it’s like to vote in the UK",
    date: "18.51, Tuesday 3 Nov 2020",
    content:
      "I’ve voted in seven general elections. The first was 1997, when Labour won and Blair got in. Also various local elections, mayoral elections, and European elections, plus two referendums.\nThe electoral register is kept up to date continuously. I can register to vote online. Periodically a letter is sent to our house with a list of all registered voters at the address. I can confirm it or update it, and send the letter back in the post or do it online.\nBefore an election, a polling card is sent out.\nI’ve always lived within walking distance of a polling station.\nThere’s a short line, if any (I tend to vote before or after work).\nThe setup is always the same:\nTwo clerks sit at a desk. One clerk - just a regular person, they look like one of my neighbours - takes my name and address. I don’t need my polling card. All the registered votes are printed out for the clerk on big sheets of paper. They confirm my name, and cross me off the list with a ruler and a biro. Their colleague hands me a voting slip.\nI go to a booth and fill in the voting slip. There are always these fat, stubby pencils, tied to the inside of the booth.\nThe booths are flimsy and made of wood. They’re tall and open on the back.\nIt turns out that the main supplier of all this kit is Shaw’s Election Supplies and they’ve been trading continuously since 1750. They sell everything from ballot boxes to signage to vote counting trays. Here are the stubby pencils I’m talking about. 19 quid for a 100 pack.\nHere’s the sign that’s always outside polling stations. It says POLLING STATION in black type.\nThen I fold my slip and put it in a metal box at the front. It looks like a battered black cube maybe 50cm on the side, with a letterbox slot in the top. There’s someone standing near the box.\nAs I leave, there’s usually somebody outside to ask who I am and sometimes how I voted. I assume some of this is political (so parties can get out their supporters) and some is to do with exit polls. I’ve never given it much thought.\nThe Electoral Commission publishes the polling station handbook (pdf) which covers all of this.\nAt the end of the day, the boxes are taken to the count. Teams of people tally the votes. The count may be disputed; the votes are re-counted. When all the votes are counted, a winner is declared. There’s a set formula for the words.\nI don’t remember voting ever being any different.\nWitnessing\nWhat I love imagining in the whole process is the role of witnessing.\nThe polling station staff see me stand at the booth; they can see there’s no-one else there, and they can see I haven’t got my phone out. I see my pencil mark made on the voting slip, and I put the slip into the locked ballot box myself. Another staff member watches me. The staff are at the polling station from open to close.\nThe box follows a chain of custody. At the end of the day, it is sealed, and any candidate or official can also add their seal. During transport, the ballot box is never unattended.\nPeople witness the boxes being unsealed. People witness the slips coming out. People count the slips and people witness the slips being counted. The counting centres have public observation areas; they’re often on TV.\nThe process is one of having as many different eyes on the system as possible, at every step. Opportunities for sleight of hand are minimised.\nFor me, at least, it creates trust. The single moment of anonymity is the slip I get handed, but absolutely everything else is open to inspection.\nWhen I’m voting, I feel part of something very big and very inclusive. It’s a collective choreography that involves the whole country. Unlike the sprawling systems that I spend most of my time with, like the internet, or roads, or this end of the grocery supply chain, there’s no part of voting that ever feels unobvious. I don’t have to squint and guess at how part of it might work, or trust that someone cleverer than me could explain it if I asked. It’s just… there. Making my X with that stubby pencil, I get to engage with all of this directly, and it is thrilling.\nSo I love voting. Even though I’m batting 2 for 7 on general elections, and 0 for 2 on referendums. Oh well, that’s democracy. I’m better at gambling: I made enough for a couple of boxes of doughnuts betting on Trump on 2016, and nobody would eat them when I took them into the office.\nOther countries\nI don’t have any experience of how voting works in other countries. I know the process varies pretty widely.\nI’m not saying that the UK is any better or any worse.\nI’m not say that the way the votes are put to use is fair or unfair – first past the post, constituencies, etc.\nNo comment, on any of that.\nBut I would love to hear stories of how voting works in countries other than my country, the UK. The actual material act of voting in a national election. Any country, not just the US which is voting today. If you post anything on Twitter or your blog, do let me know.\n",
    link: "/home/2020/11/02/xenia",
  },
  {
    title: "My epiphany at the dentist and how I carried it back to reality",
    date: "18.39, Thursday 5 Nov 2020",
    content:
      "I’m just back from the dentist right now, so here’s a story about another time going to the dentist and an epiphany I had while I was in the chair.\nI had a whole bunch of dental work a few years ago.\nThree sessions in the chair, each 3 or 4 hours long. My dentist was from Iraq and he had a sideline representing the new government installed by the Allies so he would crop up in the media from time to time and occasionally disappear for a few months to Baghdad to lend a hand. He was also a neurolinguistic programming adept, so I enjoyed quizzing him about that, and his professional claim was that he employed hypnosis to take the sting out of dental work, using a process of visualisation to descend a series of steps into a beautiful garden of lakes and trees, etc, though actually I think he just had a heavy hand on the nitrous.\nI don’t know if you’ve ever had nitrous oxide but it’s mildly euphoric and very relaxing. Sensation is reduced and your body feels heavy, floating somehow. Together with the headphones (the aforementioned hypnosis playing on a tape) and my eyes closed, I would pretty quickly descend back inside myself, and spend the hours in a semi-observant, semi-dreaming state.\nSo that was really the story of the first session, inhabiting this odd kind of dentist dream, idly exploring my altered mental state, dissociated, yet able to think and reason.\nWhat I noticed was that my mind felt smaller somehow, like a cat’s brain (I remember thinking), but also closer to the fabric of reality itself. Without my preconceptions getting in the way, stripped back to my animal brain, I was able to perceive more clearly, and therefore had access to deeper truths about myself and the cosmos – both the same thing really.\nAnd just before I resurfaced, I discovered a huge truth, a startling revelation.\nNot that I could remember it.\nAll I could recall was its import.\nSo in the second of my three sessions, I went back to re-discover whatever it was.\nThe way I ended up thinking about the nitrous state wasn’t that it wasn’t that I was reduced, like this simplified mind idea I had, or transcendent even, a layer above or below my regular mind somehow.\nRather it was as if my mind had rotated about itself into a new configuration so that all the sensory apparatus was now pointing inwards at itself, the full power of sense-making lensed inward, and by looking into my own mind and contemplating its form, I could then make deductions from its shape about the nature of the cosmos outside.\nWhat’s more, I was able to maintain ideas and follow trains of thought, in this configuration, that wouldn’t be possible or sustainable in the other, regular configuration, the configuration of mundane reality. Both states were valid, independently, but they couldn’t exist simultaneously.\nBut what was interesting was that there was an isomorphism between ideas in the two configurations. So while I was able to run impossible chains of thought in the nitrous configuration that I couldn’t run in the regular configuration, the destination concepts that I reached could be transferred between configurations.\nThat was why it was possible to reach some kind of epiphany. In mundane reality, such a concept would be inaccessible. By in the altered configuration, I could reach this new idea, and then, having reached it, bring it back.\nMy mental model for this was two worlds, two bubbles, linked with a tunnel.\nOne bubble, large, outward facing and well-lit: the regular configuration of mundane reality. The second bubble, dark, inward facing, contemplative, possibly small but possibly infinite: the altered nitrous configuration. I inhabit either one configuration or the other. Between them, a narrow tunnel, along which my consciousness moves as it transforms from one to the other.\nDid I re-discover the revelation? Yes. I know that I did. I know that it was important. Did I remember what it was?\nThat second session, no, I did not.\nWhen I came out of the dentist, all I could remember was the image of these two bubbles for the two psychic configurations, and the tunnel.\nAnd mainly, this idea: you can bring one thing through the tunnel.\nWhat I had figured out was that when my mind moved between the configurations, what I thought was urgent and desirable in one configuration wouldn’t necessarily translate to the other.\nIn particular, what felt like a rare revelation about the nature of self and the cosmos, etc, from the perspective of the regular configuration was, yes, important when viewed from the nitrous configuration, but actually it felt pretty natural and commonsensical there too, and so, in that altered state, I felt no necessity to work hard to remember it.\nBut what I also figured out what that, as I moved between these two worlds, if I concentrated on holding one thought in mind, I could deliberately carry it through the tunnel and it would be the seed for my thoughts on the other side.\nSo what I decided to do, ahead of the third session in the dentist chair, was to carry this vow with me:\nWhen I encountered the revelation, I must carry it back, no matter what.\nI would entered the altered state configuration, and hand this vow to altered state me.\nIt didn’t work entirely as planned.\nThe third session began. They gave me the gas, I went through the tunnel repeating to myself this vow to re-discover the big truth and bring it back, I entered the altered state, and so on, and as before I had this same revelation - this epiphany - but this time I also remembered my goal to bring it back with me to the surface.\nBut while the plan was to carry it through the tunnel, back to everyday reality, I realised that this idea, discovered in the alternate configuration, was too large to come back with me that way.\nInstead the only way was to burst between the realms of consciousness by force and bring the new truth into the light via a new route.\nWhich is what I did, and it must have been disconcerting to see.\nMy mouth was being held open. There were a lot of broken teeth at that point, it was right in the middle, and they were cutting back my gums too, so there was a fair amount of blood I believe, and a couple of suction tubes in my mouth.\nComing up was like swimming hard towards the sun from deep under the ocean, and breaking the through the water’s surface took huge effort.\nForcing my eyes open was a slow battle.\nEventually I triumphed, and the dentist and two nurses in the room were there as I managed to open my eyes, halfway through that day’s procedure, and gestured that I needed to speak – I remember knowing that was my chance to vocalise and concretise my epiphany before it evaporated in the light. So they took the tubes out of my mouth and the clamps off my lips, and moved the equipment away, and pulled the cotton wool out, and all of that stuff, and gestured to let me know I could speak, and listened as I was able to get out the words that had taken me 10 hours over three weeks of deep internal exploration, and strategic planning let’s not forget, to bring back from the depths of altered psychic states to our everyday reality; and I said these words, and no words will ever be truer than the truth contained in these words at that moment, and I said this: Can I Have More Nitrous Please.\nAnd they laughed and nodded and turned the nitrous oxide up, and put the tubes back in my mouth, and I closed my eyes, and they carried on with their work, and I lay there happy.\nI guess the lesson is that what is vitally important in one state of mind is not necessarily vital or important in another.\nTruth is contextual?\nSomething like that.\nNitrous is great? Or at least it was at that particular time for that particular me. That’s another lesson I suppose.\nThey offered me nitrous today and I declined. Instead I was amazed when they scanned my teeth with a handheld scanner that automatically stitched the images into a 3D model, and even more amazed that it took only 7 minutes to print the new crown. Colouring and firing the crown took 15 minutes. I was in and out in an hour and a half, including having the old crown knocked out, watching the dentist adjust the 3D geometry on the big screen next to the chair, and having a nice chat about photogrammetry and also the history of milling machines. So there we go.\n",
    link: "/home/2020/11/03/voting",
  },
  {
    title: "Haunted radio",
    date: "17.30, Monday 9 Nov 2020",
    content:
      "The myth goes that the UK has four nuclear submarines, at least one of which is just out there at all times, patrolling the ocean, and the rule is that we don’t contact it and it doesn’t contact us.\nWhat it does is listen to BBC Radio 4 which, to explain for non-Brits, is the news/speech radio network broadcast both within the UK and globally on long wave.\nThis nuclear sub: the story goes that if it doesn’t hear the morning news programme on Radio 4, the Today programme, for three days in a row, the submarine captain assumes that London has been destroyed, and therefore launches all its missiles at Moscow. Exact instructions are in a letter in a sealed envelope kept in a safe on the boat.\nI mean, is there really a nuclear sub under the ice-caps listening to the morning headlines?\nIt’s a very Cold War game theory thing to do, a Strangelove-ian Dead Man’s Handle meets Mutually Assured Destruction.\nI don’t know whether the Soviets took it into account, but Brits are primed to believe in this kind of stuff…\nThe BBC license fee is a bargain. About 160 quid a year, and for that there’s a ton of TV, radio, podcasts, all the news and original journalism of course, sport (including all the Olympics coverage), and so on.\nThe story goes that the license fee is enforced by “TV detector vans.”\nThese are vans that drive around and can magically tell if you’ve got a television set. Every so often you see such a van, and they’ve got “TV licensing” written on the side and a spinning device on the top, straight from the props department, and everyone has a friend-of-a-friend who’s accidentally seen in the back of one of them and the van is always completely empty.\nI don’t even know how this would work. Something something resonance? Whatever. It’s almost certainly nonsense. Most of us pay our license fee none-the-less.\nIn the middle of the night, Radio 4 broadcasts the Shipping Forecast and this is ostensibly a terse update on the current and changing situation in 31 different shipping areas around the British Isles, succinctly spoken for the benefit of sailors tuning in. But it’s also beautifully poetic, an incantation of numbers and mysterious, distant names, and (I’ll share this experience with many Brits) it lulled me to sleep through most of my 20s.\nListen to an infinite Shopping Forecast here.\nBonus: here’s Pharaohs by Tears for Fears, an ambient remix of the Shipping Forecast from 1985.\nHere’s a letter printed in The Telegraph in 2015, reproduced here:\n\nThe African student who thought that the shipping forecast was a coded broadcast to British spies might not have been far off the mark.\nFor years I wondered why the broadcast would always end with the phrase: “No icing in South East Iceland.”\nThis ending hasn’t been heard since the end of the Cold War. I listen to the shipping forecast every day in case the mysterious message makes a return.\nWilliam T NuttallRossendale, Lancashire\n– Letters, The Telegraph, 5 October 2015\n\nNo icing in South East Iceland.\nWhat I find most interesting about these forms of haunting is that they’re not easily dismissed as ghost stories or conspiracy theories.\nThey’re not Flat Earth. Not Qanon. Nor the Black Knight. (The Black Knight satellite is a 13,000 year old object of extraterrestrial origin, in polar orbit around the Earth, covered up by Nasa.)\nInstead they sit halfway between fact and fiction. I’m not prepared to fully believe… but I’m not prepared to fully discount. They seem to have a grain of truth.\nBut also I think the mode of haunting tells us something about radio itself. Broadcast radio is weird, and the nuclear subs and TV vans resonate with our efforts to understand it:\n\nyou listen, and there’s no way to know who else is listening – are you alone or in a crowd? If you’re in a crowd, who else might be there?\nyou listen, and there’s no way for anyone else to tell that you’re listening – a receiver is like listening at a locked door that can never be opened… but what if they can tell?\n\nSo what are equivalent hauntings of the internet? What stories do we tell ourselves?\n",
    link: "/home/2020/11/05/dentist",
  },
  {
    title: "Machine English and why I bake bread for 49 minutes",
    date: "17.49, Tuesday 10 Nov 2020",
    content:
      "I always bake my bread for 49 minutes. Reason being that Siri on my Apple Watch doesn’t understand my accent, and if I say “50” it sets the timer for 15.\nI said this on Twitter yesterday, and Simon Walters mentioned that he programmed Alexa to accept the word “toggle” to control his home media setup, but had to change it to accept ‘taco’ instead.\nAccents!\nDan Saffer had a good point:\n\nThere should be two words/phrases for this. One for making ourselves “readable” to digital objects and another for the warping of outcomes because they’re affected by outside digital processes.\n– Dan Saffer (@odannyboy), 16:12, 9 Nov 2020\n\nAnd it got me thinking about radio…\nThere’s a particular accent associated with BBC radio sometimes called BBC English which is also known as “RP” – Received Pronunciation. Back in the day, it was a upper class, southern English, prestige accent, but then it was adopted by the BBC in 1922, and that’s what radio sounded like from then on.\nSo it’s a non-geographic accent; it’s “place” is ageographic radio. (Is “ageographic” even a word? Can it be?)\nHere’s the British Library on the history and features of RP.\nIt turns out the US has something similar with radio voices, which I didn’t know, but it has a different origin. From The Atlantic: That Weirdo Announcer-Voice Accent: Where It Came From and Why It Went Away.\nThere’s an (unattributed) speculation in that article:\n\nThe primary reason [for the accent] was primitive microphone technology: “natural” voices simply did not get picked up well by the microphones of the time. …\nMicrophone technology improved enormously in the 40s, but a pattern, a style of speech in the news and entertainment industries had been set: radio announcers and broadcasters could, from the late 1940s onwards, speak more naturally, but those who wanted to “sound like a real newsman” had to affect the old way of speaking, probably as a way of establishing their bona fides…\n– The Atlantic, That Weirdo Announcer-Voice Accent\n\nBad microphones lead to a specific accent; accent becomes a marker of gravitas; mics get better but accent persists. \nGoing back to Saffer’s point:\nThe starting point is about us making ourselves readable to machines, and that’s where the accent comes in\nBUT THEN, as he says,\nthere’s this “warping” of culture that occurs from then on – the legacy of janky microphones or the standards manual that results in an accent that endures decades later.\nBack to my baking:\nThere’s a good chance that Siri got better in the most recent software update, and perhaps it can now discern “50” and “15” in my voice. But I’ll never know. I now have a habit of saying hey siri set timer for 49 minutes – even if Siri has improved, there’s no moment for me to discover that. So I’ll carry on baking my bread for 49 minutes forever.\nAND SO:\nWill we see, alongside Cockney, Indian English, Mid-Atlantic, Estuary English, and all the rest, a new accent of Machine English which is ageographic, placeless, that we all keep in our repertoire to be understood by not-quite-good-enough voice-controlled objects?\nAnd, even when Siri and Alexa and all the rest are good enough, will we carry on speaking with it?\n",
    link: "/home/2020/11/09/haunted_radio",
  },
  {
    title: "The Fall of Rome (just the poem)",
    date: "20.59, Thursday 12 Nov 2020",
    content:
      "The Fall of Rome, by W. H. Auden (1947).\n\nThe piers are pummelled by the waves;\nIn a lonely field the rain\nLashes an abandoned train;\nOutlaws fill the mountain caves.\nFantastic grow the evening gowns;\nAgents of the Fisc pursue\nAbsconding tax-defaulters through\nThe sewers of provincial towns.\nPrivate rites of magic send\nThe temple prostitutes to sleep;\nAll the literati keep\nAn imaginary friend.\nCerebrotonic Cato may\nExtol the Ancient Disciplines,\nBut the muscle-bound Marines\nMutiny for food and pay.\nCaesar’s double-bed is warm\nAs an unimportant clerk\nWrites I DO NOT LIKE MY WORK\nOn a pink official form.\nUnendowed with wealth or pity,\nLittle birds with scarlet legs,\nSitting on their speckled eggs,\nEye each flu-infected city.\nAltogether elsewhere, vast\nHerds of reindeer move across\nMiles and miles of golden moss,\nSilently and very fast.\n\n…\nI don’t understand how a poem written 73 years ago can speak so clearly today.\n",
    link: "/home/2020/11/10/machine_english",
  },
  {
    title: "Self-driving corporations",
    date: "20.56, Tuesday 17 Nov 2020",
    content:
      "I’ve been thinking about how companies could be automated, and what we would use them for if that were possible.\nStarting point\nThink of something like Stripe Atlas: Spend 10 minutes filling out a bit of information, and then we’ll create the legal framework for your company… including legal docs, paperwork filing, getting a tax ID, issuing stock, and so on. All for $500 and some form-filling.\nThis is for company formation – what if it was that easy ongoing?\nI have a couple of basic use cases in mind:\n\nA small Shopify business. I have a friend who has just started a neighbourhood soup delivery business.\nA boutique agency. The kind of business that performs design or consultancy work, maybe subcontracts a little work, and has a few expenses like buying laptops.\n\nThe second is close to my heart because it’s what I do right now.\nI reckon I could write an operations manual for a micro agency pretty simply. We had a “choose your own adventure” style operations manual at BERG in the form of linked checklists. Like, “is it a Friday? Do bank reconciliation. Is it the last Tuesday of the month? Then process holidays, process employee changes, run payroll,” and so on. It built up over time.\nBut what if the “agency in a book” could be software? What if the checklist was actually a set of forms, and the forms actually filed the paperwork?\nThe challenge\nForming a company is the easy bit. The challenge is running it, because\n\nThere’s a lot of drudgery, which takes you away from the actual work\nIf you get the drudgery wrong, you’ve broken the law and can get struck off as a director, or get a fine.\n\nFor example: for Mwie Ltd, now is the time I have to file my Confirmation Statement which declares the current shareholders of my company. It’s easy to do because my accountants have made a screen to look at and a button to click… but if I forget to visit the website before 24 November, I’ll be in a ton of trouble.\nThis ongoing form filing is called “compliance.”\nAutomatic filing\nRight now, there are a ton of tools to help you manage the output of your company (Shopify, Trello, PowerPoint) but very few to manage the compliance.\nOkay, so there are tools to make form-filling easier. I can employ a payroll company to file on my behalf. Or I can employ an accountant to ask me questions once per year, and prepare my yearly accounts.\nWhat I want is to flip the model.\nThe automated corporation (which is software) should always be in legal compliance, even if I do nothing. So the forms should, behind the scenes, be printed and sent off; the accounts submitted; the quarterly VAT returns made and paid.\nThis requires automation of my bank account, I know.\nBut what I’m saying is that my self-driving corporation should, once formed, stay on the road, whatever forms and robot phone calls it takes.\nCompliance guarantee\nBut if I forget to reply to the email, or forget to log a benefit, or accidentally pay someone below minimum wage, or run out of cash, the company will be operating illegal. This should never happen.\nThink about a desktop computer. I can’t drag a folder icon inside itself and break the file system. The computer doesn’t let me.\nOr, more technically, consider databases. Databases confirm to the ACID properties: ACID (atomicity, consistency, isolation, durability) is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps.\nIn short, no matter what you ask a well-designed database to do, you won’t end up with broken or illogical data.\nWhat would it mean to have such a guarantee for a self-driving corporation?\nSo, for example:\n\nit simply wouldn’t be possible to spend money from the corporation without it also registering it as an expense, or a dividend, or whatever. (The current situation is that I can transfer money out from my company bank account, and then I reconcile it later in the accounts. The “compliance guarantee” would prevent me from making such ad hoc payments from the bank.)\nit wouldn’t be possible to spend money if that would mean there wasn’t enough cash in the bank to pay the end of quarter/year taxes.\nat 30 days before payroll, if there wasn’t enough money in the bank, all employees would be given a month’s notice (or whatever the parameters are to avoid being insolvent or breaking employment law).\n\nWhat I mean is that the self-driving corporation would only allow actions that can be guaranteed to be downstream legally compliant.\nThat would mean that this company wouldn’t be as flexible as a regular, human-driven company. It would have more limited contracts, for example. But it would be impossible to crash it.\n(One question is about how to implement this. One mechanism might be to require, in the incorporation legal, that all contracts require two directors. But one of the directors is a robot who will only sign off on provably compliant contracts.)\nException handling\nIn any complex system, there is always the possibility that things go off the rails. What if someone sues this autonomous corporation? What if the tax laws change radically?\nRather than the company “crashing” (which, in this situation, means that it ends up operating illegally and the shareholders risk a fine or worse), there would need to be some kind of exception handling:\n\neither the company can have a safe way to “halt” – that is, pause all operations so at least things don’t get worse\nelevate the problem to a human handler.\n\nI think of this a little like early evolution of computers. They ran raw machine code. The core insight of the interactive computer was the event loop. And every so often, it would crash. So then there were friendly ways of crashing (the blue screen of death) and then of isolating crashes (this application is not responding) and then ways of catching errors so that the app can be improved for everyone (would you like to share the crash report with the developers).\nWhat are the applications?\nThis is a bit of a thought experiment. \nI talked back in 2014 about a little bottle-city company … corporate governance as executable code – and what I’m talking about here is implementing the minimum viable version of that: a guaranteed compliant, self-driving corporation, implemented in software, a layer that sits between (a) the world of banks and government departments and paper, and (b) the human owners and employees.\nI suspect it would be both cheaper and simpler (I spend perhaps 5% of my time and 3% of my income on the Red Queen’s race of company compliance, and I know what I’m doing) so that increases the number of people who would be operating independently, or starting companies, but can’t because of the existing hurdle.\nBut more interestingly, an autonomous corporation is interoperable with software. So Shopify could form and run a company for you, accounts and contracts and all, guaranteed no shooting yourself in the foot. Or maybe a blog could be its own company, and registering a Wordpress account would automatically register it? Or a vending machine?\nWhat would it mean to buy a “Dummies Guide” to starting, say, a roofing business, and the book is code and you can just boot it up? \n",
    link: "/home/2020/11/12/the_fall_of_rome",
  },
  {
    title: "How to collaborate with AIs",
    date: "18.40, Thursday 19 Nov 2020",
    content:
      "Ben Hammersley‘s new (very early) startup caught my eye. It’s a writing interface called Agathonic.\nWatch this short video of the Agothonic functional demo.\nHere’s what happens, if you didn’t watch the video:\n\nHammersley types into a text editor: My name is Ben Hammersley and I live in New York (along with some other prose)\nThere’s a separate text box at the bottom of the screen labeled “Ask Agathonic questions.” Into this he types When was Ben born? (1:50)\nThe system replies: I think the answer is: 3 April 1978 (1:58)\n\n(Hammersley has a background as a journalist so it’s worth seeing this prototype through that lens.)\nWhat’s going on?\nThis tweet thread unpacks it:\n\n[It’s] based on an NLP [natural language] interpretation of the corpus of text it builds in the background from its current set of sources. … Today it’s based off Wikidata but there are more sources to come.\n\nSo the human writes. The AI understands and builds its own mental model of what’s in the text. Based on that model, it expands its knowledge from available data sources. Then the human can have a conversation about what the AI knows.\nThis is a great interface.\nWhat I like about it most is that the loop matches the creative process.\nYou write for a bit. Maybe finish the section, maybe get stuck. Then you go away and think, or you leaf through a book, or you do some research, or you talk through the article with your editor or a friend or another sounding board. And finally you figure out what to say, so you start writing again.\nThat bit in the middle is conversational. Having an AI assistant who learns from your text is a good addition. The conversational interface is perfect.\nAs a counterpoint, back in September I was experimenting with GPT-3, the startlingly human AI text generator. My takeaway at the time: GPT-3 is capable of original, creative ideas.\nIn the beta interface, GPT-3 is presented as smart autocomplete. The human writes words, then the AI tries to pick up where the text leaves off. (Applications built on top of GPT-3 can add any interface they want.)\nBut autocomplete makes me uncomfortable.\nAutocomplete carries with it a certain kind of weight and inevitability. Red squiggle underlines to say a word is misspelt, the word count at the bottom of the window, autocompleting a word so you don’t have to type it… these feel like facts. Or if not facts then fact-adjacent.\nBut GPT-3, when I used it, was more like having a creative sparring partner.\nWhat GPT-3 creates aren’t autocompletes, but instead suggestions that bump you out of your groove and take you in a new direction. It prompts, inspires.\nThe ideal interface for GPT-3 would be an assistant.\nAn assistant? Like Clippy?\nClippy was the Microsoft Office Assistant released back in 1996, now known mostly through memes. It would hang out in the corner of the screen and chip in: It looks like you’re writing a letter. Would you like help?\nEtc.\nPeople hated it.\nBut Clippy arrived before we had a shared understanding of software designed for realtime collaboration. It’s time to bring the assistant back.\nLook: in 2020, we’re comfortable with shared Google Docs, and writing while other people are highlighting text in the same document and leaving comments. We gather together in Figma documents, checking out designs and commenting while we see a little crowd of cursors charge around. We collaborate and hang out in software built for groups and teams first, like WhatsApp and Slack.\nSo imagine this: you have a text editor, and your team is there too. Your colleagues are making suggestions, answering questions, filling in gaps, and being sounding boards.\nBut one of the team is an AI. And they appear not as a special interface element like a hovering window or a special sidebar or a squiggly underline, but in comments, chats, and suggested edits, alongside everyone else.\nI think that would feel truly interactive and collaborative, and it opens the door to different styles of assistant: ones that provide creative prompts, ones that have the facts and figures at their fingertips, ones that are brilliant at wordsmithing the prose for different audiences.\nThe ideal interface to AIs is the team.\n",
    link: "/home/2020/11/17/self_driving_corporations",
  },
  {
    title: "Multiplayer docs, webcam fashion, noisy icons: three ideas",
    date: "19.50, Friday 20 Nov 2020",
    content:
      "Let’s say I wake up one morning and I’m magically in charge of Android, iOS, or Mac OS. What do I do? Here are three ideas aimed at making operating systems more social.\nIt matters what goes in operating systems. Almost 20 years ago, many of us were banging the drum for location-aware computing. It’s hard to imagine now that computers (by which I include phones) didn’t know where they were. But put location in the OS, and you enable everything from turn-by-turn directions, to advertising, to takeaways, to Tinder.\nASIDE: If you’re into the history, Know Your Place (July 2017, The Fibreculture Journal) is an examination of the visionary and influential headmap manifesto for “locative media” (as it was called) by Ben Russell from 1999.\nAnother example:\nFonts on the original Macintosh, 1984, which was early in using fonts with characters of different widths, often referred to as proportional fonts. (Previously most computers were more like typewriters.) The story goes that Steve Jobs went to a calligraphy class at college, and ended up caring a ton about typography. And so we ended up with desktop publishing and the democratisation of design!\nLaptops and smartphones never escaped their PC history. They’re still personal computers, all our socialising and collaborating channeled through individual apps like email and Facebook. To be natively social, we need social capabilities at the OS level.\nSo, let me join the dots on a few recent blog posts, and briefly lay out some starting points…\n1. Multiplayer everything\nGoogle Docs is amazing (and Sheets, and Slides). Like, of course in docs you should be able to\n\nsee people’s cursors (where their attention is)\ncomment (start a side conversation, clarify, make requests)\nedit together (have the same privileges as the document “owner”).\n\nAfter all, this is exactly what you’d in a meeting room with a whiteboard, or in a cafe scribbling on a napkin.\nThen you get the unintended uses of those capabilities like spreadsheet parties, as previously discussed.\nFigma, the online design tool, has has multiplayer mode since 2016. A designer can show their work to viewers, all their cursors swarming round. More unintended uses: Tom Critchlow has been using Figma for salons.\nAnd then there’s the new generation of collaboration apps such as MakeSpace with its video selfie cursors and shared canvas.\nI find it insane that Google never turned Google Docs into a framework for all web apps.\nLive text editing, multiplayer cursors, comments and chat: these are powerful primitives. Why doesn’t every text editor on the web, every sketching app, and every music maker include this? Google could have enabled that.\nIt’s not too late.\nIf I were Apple, or Google with Android, I’d bake this into the OS. It should be a native feature of the operating system, just like menu, or the file save dialog box.\nEvery application window should be thought of as a room. Tap on a window, open the door, and see cursors swarm, text get edited, and comments stream in. (Different cursors for different windows, naturally.)\nAnd one of those team members? An artificial intelligence assistant. I talked yesterday about how the ideal interface to AIs is the team\n2. Presentation of self\nErving Goffman, sociologist, his 1956 book The Presentation of Self in Everyday Life:\n\nwhen an individual comes in contact with other people, that individual will attempt to control or guide the impression that others might make of him by changing or fixing his or her setting, appearance, and manner.\n\nLike… of course?\nGoffman focuses on politeness: all participants in social interactions are engaged in practices to avoid being embarrassed or embarrassing others.\nAnd costume: the dress and look of the performer.\nAgency in self-presentation is about as close as you can get to a human fundamental. Sure enough, there are filters in individual apps. Yet there’s barely any attention given, at the OS level, to this kind of “dressing up,” to costume.\nI wrote in October about virtual fashion: How about skin tight t-shirts with tracking markers, especially made for rendering synthetic shirts with physics-model fabric for wearing on Zoom?\nAnd there are glimpses of apps that play in this domain. Recently I saw xpression camera on Product Hunt. It intercepts your webcam and lets you change your appearance on any call. Like, you give it an image of a person, and then it deepfakes your face into the image. Check out the second photo on that Product Hunt page: Take a photo of yourself in a suit, so you can attend Zoom meetings in your pyjamas.\nThe ability to not brush my hair for video calls is ABSOLUTELY a worthy operating system-level feature.\nIs this trivial? I imagine people said the Mac’s focus on typography was a triviality when it launched in the 80s. But creative expression is what humans are all about, and nice fonts (and ugly fonts…) tap directly into that.\nHere’s another: the video/podcast-editing tool Descript. Check out their launch video on YouTube. At 1 minute 50, you’ll see the ability to scrub every uh and um from your voice, automatically.\nThis is no different from spellcheck. We have spellcheck because it’s important to be professional. But computers (I include phones in this) are subject to the tyranny of work. What about hanging out with my friends? I want to sound cool and look silly, or whatever.\nSo for my second act, I’d bake deepfakes, dressing up, and yes, an app store for virtual fashion right into the OS. Give presentation-of-self features an absolute ton of attention.\n3. Peripheral vision\nNotifications are a system-level feature. Good.\nBut notifications are a blunt instrument.\n\nA red dot that shows the number of times my name has been mentioned… but by whom? And over what time period? And is there a crowd of people still there?\nA pop-up that gives me detail of a message, or a question about an edit… but what if I’m focusing and have notifications turned off, or I need time to think?\n\nLong-time listeners will know of my interest in social peripheral vision, the idea that you should be able to sense, as if from the corner of your eye, the busyness of a Slack channel, or the fact that a friend is slowly and quietly posting gorgeous photos somewhere.\nAnd from that gentle, non-urgent awareness, you can build up (or not) to full focus.\nBut how should it work? One thought…\nThere’s an idea buried in my post about video calling interop from a few weeks back:\n\nThe icons on my home screen should appear “noisy” somehow if they’re currently full of my friends. Getting notifications only when I’m direct-mentioned is such a crude mechanism: I want to know where the action is!\n\nNoisy icons. What if each icon gave off ripples? But the ripples would be static. If they did animate, it would be very slow.\nFrom a visual scan of your home screen, you’d see which apps were busy and which were quiet. Bigger ripples if more of your friends are active; bigger ripples if your name is mentioned. Each app could have its own volume control.\nImagine seeing ripples around the Google Docs app as if there were some deep, distant activity. Open it… and there’s a particular document humming with comments. You listen at the door, you can tell who’s active, and the frequency of the interactions, but not what they’re saying precisely… a ping as your name is mentioned (the notification of which wouldn’t have bubbled all the way up to your home screen as it’s not important enough, but since you’re here) - so you enter and join your colleagues.\nEnough already\nIt’s not going to happen, nobody’s going to give me the keys to designing the OS.\nBut I’d love to see social computing given the attention that it deserves. As you can tell, I’m frustrated that OS designers and engineers haven’t gone further down this path already.\nJust as, in the days of locative media, in 1999 before smartphones and before consumer GPS, we could only guess at what would happen with location-based computings, I feel like we’ve only scratched the surface with social, and I want to see what apps and services would be newly-enabled and newly-imagined by system-level Lego bricks like these.\n",
    link: "/home/2020/11/19/ai_collaboration",
  },
  {
    title: "Some thoughts on the Chorleywood bread process",
    date: "22.08, Monday 23 Nov 2020",
    content:
      "A few months back, I learned about the Chorleywood bread process, invented 1961. 98% of shop-bought bread in the UK is now made this way (caveat: source is from 2009). It uses additives to bake quicker.\nBefore, if you’d said to me something like “they’re putting stuff in the food that’s making everyone gluten intolerant” I think I would have filed that as a food conspiracy theory. Now? I think I’d lean in that direction.\nHere’s what I read.\n\nSome would say that 1961 was a bad year for bread. It was the year that Chorleywood Bread Process came into being. Developed by the Flour Milling and Baking Research Association in Chorleywood, the process revolutionised the baking industry. This high-speed mechanical mixing process allowed the fermentation time to be drastically reduced, and meant that the lower-protein British wheats could be used in place of the more expensive North American imports. Various chemical improvers and antifungal agents are necessary ingredients, as are certain hydrogenated or fractionated hard fats. This is high-output, low-labour production, designed to maximise efficiency and profit at the expense of the consumer.\nMass-produced bread is almost undoubtedly worse for you. Apart from the dubious additives and fats it contains, the short fermentation makes the wheat harder to digest. Indeed, some believe the Chorleywood processing method is to blame for a sharp increase in gluten intolerance and allergy. It is also probable that the prolific crossbreeding and modification of modern-day wheat, to produce strong, tougher, harder-to-digest gluten, has contributed to wheat intolerance.\nSomewhere in the region of 98 per cent of bread in this country [the UK] is mass-produced, and most of it comes from around a dozen huge plant bakeries.\n– Daniel Stevens, River Cottage Handbook No. 3: Bread\n\nIncidentally, Stevens’ Bread is a great recipe book. Good British recipes, restaurant standard, well laid out, straightforward. Love it. Stevens clearly has a bee in his bonnet re handmade vs industrial bread, and that’s exactly who I would want to be writing such a book.\nReading more: here’s a neutral view; here’s a sceptical view.\nAnd to summarise what I learnt about Chorleywood:\n\nthe amount of yeast of the bread is doubled which drives fermentation faster \nfermentation alone (the yeast breaking down the flour) is traditionally an overnight process; with Chorleywood the entire loaf takes only 3.5 hours\n“improvers” are used – chemicals that break down the flour, and other chemicals that provide structure to the crumb (there isn’t enough time for the structuring gluten to develop otherwise)\nthe “improvers” are no longer shown on labels. In the 1990s, the old chemicals were replaced with enzymes (which pre-digest the flour, etc). But enzymes aren’t an ingredient, they’re part of the industrial process, and so they don’t need to be listed.\n\nI’ve no idea whether it matters that the yeast isn’t given much time to ferment the flour. Is it possible that there is a different, harder-to-digest kind of gluten that is formed when the additives drive the process so much faster? Are there implications of having extra yeast hanging around? Does all of this have a long-term negative effect on human health?\nEspecially because 1961 is relatively recent. I was born in 78; it would have take a while for Chorleywood to ramp up. So my generation - plus a little older - is really the first generation to have grown up eating bread like this. Is that why so many people now get bloated from wheat and ill from gluten… or is it merely that we’re more aware of the effects now?\nHonestly, I have zero idea whether any of this truly matters.\nIt makes my systems-thinking spidey-sense tingle though.\nSo I bake my own bread now and I’m cautious about what I buy.\nNat Torkington shared a paper with me after we chatted about this. Effect of breadmaking process on in vitro gut microbiota parameters in irritable bowel syndrome: In conclusion, breads fermented by the traditional long fermentation and sourdough are less likely to lead to IBS [Irritable Bowel Syndrome] symptoms compared to bread made using the Chorleywood Breadmaking Process.\nSo… So.\nI didn’t know about Chorleywood before, but now I do. And although I’m not convinced that industrial bread is bad for me, I am open to the idea enough, and the consequences are bad enough, that I have changed my diet.\nThe wider implication, for me, is this:\nIf bread, then what else?\nBack to bread.\nLast week, I tried adding diastatic malt powder to my sourdough. I mainly use recipes from the excellent Handmade Loaf by Dan Lepard and he recommends adding a spoon of (handmade) powdered barley malt at the start.\nI didn’t make the malt myself. I bought it.\nIt turns out that adding malt is like a cheat code for baking bread.\nMy loaf proved a little faster, the crumb was more open, and the loaf had a lovely chew. All good. My starter has been sluggish in the cold weather, and this malt has been the antidote. Excellent.\nIt turns out that malt works in a pretty interesting way.\nMalt contains amylase, which is an enzyme. I remember it from biology at school – if you hold a piece of bread in your mouth, it begins to taste sweet, and the amylase in your saliva is the reason why.\nAmylase cuts up non-sweet starches into simple, sweet sugars which are more easily digested by the yeasts.\nPoint, the first. I find it wonderful and amazing that a traditional baking ingredient turns out to be biochemically active and there’s a metabolic reason why it’s there. I wonder when amylase was discovered and this connection made.\nPoint, the second. Amylase is one of the enzymes in the Chorleywood bread process.\nSo am I now on the path to industrial bread?\nHow do I draw the line?\nAnd at what point should I stop?\nThis, it occurs to me, is the whole question of technology in a nutshell. Or in a banneton, as the case may be.\n",
    link: "/home/2020/11/20/social_os",
  },
  {
    title: "Faster than real-time simulation, a new hammer",
    date: "19.32, Thursday 26 Nov 2020",
    content:
      "There’s a new computer chip called the Cerebras Wafer-Scale Engine which is massive.\nChips are usually the size of a postage stamp, and you get faster computers by linking a bunch of them together. A different approach: the Cerebras is the size of an iPad.\nThe Cerebras has 1.2 trillion transistors, 20 times bigger than the world’s next largest chip, and 75 times bigger than the new Apple M1 chip. Singularity Hub has all the details: The Trillion-Transistor Chip That Just Left a Supercomputer in the Dust.\nAnyway, this line from the announcement caught my eye:\n\nit can tell you what is going to happen in the future faster than the laws of physics produce that same result.\n– Cerebras blog, Beyond AI for Wafer Scale Compute\n\nFaster than real-time simulation.\nI mean, that’s what physics does anyway, right? We can figure out the position of the planets in the solar system for a thousand years in the future without having to run the calculation for a thousand years.\nAnd yet… something provocative about this.\nOne of the challenges with nuclear fission, the holy grail of clear energy generating, is the plasma going out of control, and the magnetic fields in the torus can’t be adjusted fast enough to contain it. The physics is too hard; nobody’s “solved” the plasma problem yet. But if the entire thing can be simulated from the bottom up, faster than realtime, you don’t need a model. You just run the simulation.\nWhat are the civilian applications?\nI can imagine a wearable device that continuously snapshots the world around you, runs the simulation in fast forward, and pre-emptively warns you about a mugging, or a bike going off course. Call it augmented apprehension.\nOr how about intelligent fire extinguishers that simulate the fire in faster-than-realtime and dynamically direct the spray to uncannily effective spots.\nI think it’s that uncanniness that draws me the most. Fluid dynamics and chaotic systems generally are weird and interesting. I think of the weird interference patterns you get in a pool of water if you get ripples to meet up in specific ways, or the strange behaviours of inverted pendulums that stand upright if you vibrate them at the right frequency. (Human skeletons are basically realtime adjusted inverted pendulums.)\nSo, with powerful simulation, could you figure out how to hit a mass of water with puffs of air so that it rises up and moves around the room, washing the windows; or robots with reed-thin jointed limbs that should never be able to hold themselves up, but with motors at each joint running at just the right vibration to keep the thing moving?\nThe general algorithm would seem to be:\n\nsense and simulate the system\nsolve for the most energy-efficient intervention that leads to a improbable yet desired outcome, faster than that outcome can occur in real time\nperform that action\nrinse and repeat\n\n…which is how dolphins swim and bumblebees fly.\nJust as machine learning is getting into everything, and changing all software to the point that we don’t really know what will happen, unlocked by Google’s efforts with TensorFlow really, which componentised the technology, what is the equivalent path for faster than real-time simulation?\nIf somebody can turn faster than real-time simulation into a new hammer, what nails could we hit?\n",
    link: "/home/2020/11/23/chorleywood",
  },
  {
    title: "Who owns your synthetic self?",
    date: "17.13, Friday 27 Nov 2020",
    content:
      "Some glimpses…\nVtubers are virtual performers. They have their own shows on YouTube and Twitch, just like regular humans, but they’re animated avatars. One vtuber, Projekt Melody, commissioned [her body] from an artist for $5,000 and even kept the receipts as proof.\nBut:\n\nthe artist, alleging that Melody owed him money, filed a copyright complaint claiming that she didn’t actually own her body – he did. Melody was banned from Twitch.\n– The Verge, What happens when a virtual streamer doesn’t own her own body?\n\nHere’s an interesting one. Hour One is a startup that produces synthetic characters for use in videos.\nOnly the synthetic characters are all based on real-life people. You can sign up to be a character too, if you want. I guess it’s like having all the benefits of acting in commercials, but without having to act.\nThere’s a page on the website called “Character protection.”\n\nYour engagement will be governed by a synthetic talent contract that we have in place with all our characters.\nAny synthetic content in which you appear will be labeled with a watermark indicating the character’s content has been synthesized.\nHour One stores your facial assets with utmost security, so that it may not be hacked.\n– Hour One, Character protection\n\nAnd this fascinates me.\nCould you object to your synthesised face appearing in a commercial for something hateful?\nCould you drop your own sex tape online, but watermark it with a Hour One: Synthetic Character watermark to give yourself plausible deniability? Who would sue whom?\nI’m interested in when you create a synthetic version of yourself for your own purposes.\n\nThere’s a growing market called voice banking. What is it? Voice banking is a process for creating a ‘personalised synthetic voice’ (PSV), a synthetic approximation of a person’s natural voice (Costello, 2016). If you’re about to lose your voice (surgery, illness, etc) then you “bank” your voice to use synthetically later. Here’s one voice banking provider and here’s a list of more.\nNVIDIA’s new technology will reconstruct your face as a deepfake, transmitting just the data on video calls, and saving 90% bandwidth. Here are the details and a video.\nAnonymizer will generate a photo that is vaguely similar to your own face (to a stranger, anyway) but different enough such that it won’t match in facial recognition systems. Debugger writes about Anonymizer here (with examples).\n\nThe thing is that synthetic media isn’t media as we know it - it’s not an image, or a sound. It’s software. Software is licensed. Although it’s based on me, it isn’t me.\nDo I have a right to take my synthetic face puppet to a competing service? Can it be used in adverts, and do I have a right to limit that? If I make a ton of money out of it as a vtuber, does the software provider get a cut? Can a synthetic voice be inherited? If a voice bank is hacked and a voice used to steal money from my actual bank, who is liable?\nThis has already been an issue in Hollywood: And as far back as 1998, Chinese martial-arts superstar Jet Li turned down a role in The Matrix … for fear the production would try to claim digital ownership of his strikes and kicks.\n\n“[For] six months, they wanted to record and copy all my moves into a digital library,” he told the Chinese news site Weibo in October. “By the end of the recording, the rights to these moves would go to them. I was thinking: I’ve been training my entire life. And we martial artists could only grow older. Yet they could own [my moves] as an intellectual property forever. So I said I couldn’t do that.”\n– Vulture, Digital Doubles Are Revolutionizing Hollywood. But Why Do Movie Stars Hate Them?\n\nSo… that. For everyone, all the time.\n(Thanks Matt Jones and Phil Gyford for sending some of the above links my way.)\n",
    link: "/home/2020/11/26/cerebras",
  },
  {
    title: "New horizons for office furniture",
    date: "18.49, Monday 30 Nov 2020",
    content:
      "I spend so much time on Zoom these days, I would prefer to be bobbing around in a salt-water bath with a virtual reality headset strapped to my face. Like the precogs in Minority Report.\nYet I’m at a desk sitting on a chair. How else could it work? WELL.\nv buckenham in a tweet: I continue to joke about, but increasingly just want, this giant motorised scorpion chair\nCheck out that scorpion gamer chair. You straddle and recline on the scorpion; its tail hangs over your head and suspends two widescreen monitors. Your arms rest atop menacing scorpion pincers at the end of which are your keyboard and your mouse.\nThe entire thing is articulated. It moves. Seriously, go to the article and be amazed at the gifs.\nSo… honestly, why isn’t office furniture as brave as this?\nWay back in 1968, The Mother of All Demos in which Doug Engelbart demonstrated, for the first time, hypertext, video conferencing, word processing, remote collaboration – and the computer mouse. AND ALSO! Office furniture.\nEngelbart’s team, for the first time, separated the screen from the keyboard. Before that, the VDU (visual display unit) and the input device were a single object.\nHere’s a gallery of workstation photos from the Demo. In particular, here’s the ergonomic workstation in action: it’s an Eames chair with a custom console mounted over the user’s lap. The console (a closer look) has a keyboard, mouse, and chording keyboard placed just where you need them. There’s no desk: the screen is on a separate stand some distance away. The console chair was specially commissioned and designed by modernist office furniture designers Herman Miller (here’s their write-up).\nThe point is that new technology and new contexts can and should drive new furniture.\nCase in point: this is a fascinating review of how to work in virtual reality. Some highlights:\n\nI have a roommate now and find visual stimuli distracting. … VR setups can isolate away everything that’s not the monitors.\nVR headsets can be a bit heavy, but besides that can be highly ergonomic. In virtual environments you can configure screens to be anywhere you want them.\n\nThere’s a good photo/screengrab of the virtual from inside one of these VR setups: it’s a virtual room, with a regular computer screen hanging in the middle of it.\n(Aside: I think this is one of the early compelling use cases for VR or augmented reality smart glasses. Think of the glasses as a competitor for monitors. On a plane, assuming we’re ever travelling again? Strap on your glasses and immerse in your own private movie theatre. Or work, anywhere, with a multiscreen setup just like you have at home… but without having to carry it.)\nIf you’re working in VR, do you really need a desk? Or an office chair?\nHere’s another concept: velcro.\nI ran across this excellent interview with internet OG Justin Hall. Who, it turns out, has been experimenting with aprons.\n\nI want to have an ergonomic computer setup wherever I work – standing, sitting in a task chair, someone’s dining table, on a couch. As I was switching between sitting and standing in different work settings, I attached velcro to my pants to hold my keyboard and trackpad from sliding on the floor. Recently I was able to produce a velcro apron with $30 materials sourced on Amazon at retail prices. It holds my input accessories in place whether I am sitting or standing! I’m currently describing this with my hands at my sides, typing into a split keyboard attached to my apron.\n– ValientCEO, Interview with Justin Hall, Co-Founder of bud.com\n\nWhich I love.\nWhat if the cyberpunk of the future isn’t the black leather jacket and dark techno future of Mondo 2000’s dream in 1996 – but instead, outdoorsy, heavy cotton, Portland-barista-style apron, and homespun haberdashery?\nAll of which reminds me of sui generis science pioneer Stephen Wolfram’s productivity setup, revealed in 2019, which includes a laptop body harness for working while on woodland walks! Go to that article and check out the pictures. There must be something in the air.\nI’m more than slightly tempted with getting myself a first class airplane passenger seat, which it turns out you can buy, because at least those are designed to be sat in for 12 hour at a time.\nI was speculating the other month about new rooms we all need now but maybe the starting point is furniture for the home office.\nWhere are the new form factors?\nWhat about the Ikea office pod, or the wireless-charging beanbag with capacitative touch fabric keyboard, or the Bloomberg terminal scorpion chair, or the Apple augmented reality smart specs 5K screens, or the Patagonia velcro-enabled walking desk apron, or the ergonomic home office Gmail trapeze, or the Excel cocoon?\nCowards.\n",
    link: "/home/2020/11/27/synthetic_self",
  },
  {
    title: "Extrapolation and the Windows 95 startup sound",
    date: "19.35, Wednesday 2 Dec 2020",
    content:
      "Like all people of a certain age, the Microsoft Windows 95 startup sound is ingrained in my soul, along with dial-up modem handshaking and the default Nokia ringtone.\nIt’s a little over 3 seconds long, and was created by ambient music legend Brian Eno. Here’s what he said in 2006:\n\nThe thing from the agency said, “We want a piece of music that is inspiring, universal, blah- blah, da-da-da, optimistic, futuristic, sentimental, emotional,” this whole list of adjectives, and then at the bottom it said “and it must be 3 1/4 seconds long.”\nI thought this was so funny and an amazing thought to actually try to make a little piece of music. It’s like making a tiny little jewel.\nIn fact, I made 84 pieces. I got completely into this world of tiny, tiny little pieces of music. I was so sensitive to microseconds at the end of this that it really broke a logjam in my own work. Then when I’d finished that and I went back to working with pieces that were like three minutes long, it seemed like oceans of time.\n– SFGATE, Q and A With Brian Eno\n\n(Here’s the Windows sound slowed down 23x. It sounds exactly like a Brian Eno ambient track.)\nANYWAY. The question is, what happens after 3.25 seconds?\nListen to this:\nWindows 95 startup sound but an AI attempts to continue the song (2 mins).\n(Source: #algopop)\nThe startup sound continues, repeating and looping into itself, eventually turning into washes of sound, then returns but this time gyres up and the beat mixes in with a barely discernable 40s dixieland and singing, but lost between radio stations like a David Lynch movie, then finally the refrain returns, only to drift into distorted dogs barking and backwards talking behind echoes of itself obscured by static, the sound of hell.\nSo, yeah. Tune.\nRELATED: Algorithmically extended art. Previously blogged here when I said: Always wanted to see more of the night sky in Van Gogh’s Starry Night? Well now you can.\nLooking beyond the frame. Listening beyond the end of the track.\nThis idea of extrapolation seems to be in the zeitgeist at the moment. It’s what GPT-3 does with text, taking words and trying to say what’s next. Part of me wonders why society is so obsessed, right now, with this extension beyond limits, but that’s a thought for another day.\nSo what else can be extrapolated?\nCould I select an email thread in my inbox, write a reply, and see an extrapolated response before I choose to send it?\nDead people? Channel 4 is recording holograms of terminally ill people to deliver one last message. For a TV show. And of course: Kanye West has surprised his wife Kim Kardashian with a hologram of her late father for her 40th birthday. What would it take to deliver 2 minutes of extrapolation too?\nCould I extrapolate between episodes of a favourite TV show to get extra stories?\nI want to apply this to Google Maps and walk around an extrapolated London.\nCould I get spiritual advice through an audience with the extrapolated Pope?\n",
    link: "/home/2020/11/30/furniture",
  },
  {
    title: "Could software-enabled co-ops help workers push back on Big Tech?",
    date: "16.36, Friday 4 Dec 2020",
    content:
      "CoopCycle is a federation of bike delivery co-ops, currently in 44 cities.\nI’m intrigued about this space because I’ve been thinking about last-mile delivery: e-commerce is great, but it has a tendency to (a) centralise, and (b) squash delivery workers.\nSo by breaking “delivery” out as a separate layer in the stack, maybe it would be possible for my neighbourhood shops and restaurants to plug in to a system of e-commerce that favours localism and community (rather than have to go via singular food and retail apps that capture the audience, and then replace the local spots with dark kitchens and commodity merchants). That’s the hypothesis anyway.\nBut I’m particularly attracted by the CoopCycle model.\nCoopCycle is software:\nIt includes maps and fleet management, for dispatch to receive tasks and manage couriers. It takes platforms. It has API integrations to accept delivery tasks from e-commerce software.\nEach city is a separate co-operative of bike couriers, who together decide to use an instance of the software.\nI was going on about self-driving corporations recently and this is exactly what I meant: usually companies have human managers and business people, and the actual labour (the operations) are employees – or, increasingly, outsourced and treated as replaceable component parts. The idea of the self-driving corporation is to flip that model on its head: a company can be a collective of the people who contribute the skilled work, and the business management is the layer that is automated away.\nHere’s another way of thinking about it, going back to the enormously useful formulation by Peter Reinhardt (Segment CEO) of “Below the API” jobs in his 2015 article Replacing Middle Management with APIs.\nReinhardt starts by showing that Uber drivers are dispatched by a call in the code, and asks, What does that make the drivers? Cogs in a giant automated dispatching machine, controlled through clever programming optimizations like surge pricing?\nThen he points out the inevitable: economic incentives will push Above the API engineers to automate the jobs Below the API: self-driving cars and drone delivery are certainly on the way.\nA more succinct way of putting it, from Tom Preston-Warner (GitHub founder):\n\n“In the future there’s potentially two types of jobs: where you tell a machine what to do, programming a computer, or a machine is going to tell you what to do,” he says. “You’re either the one that creates the automation or you’re getting automated.”\n– Bloomberg, Arrogance Is Good: In Defense of Silicon Valley\n\nThe question is, does CoopCycle provide a clue in how to subvert the inevitability of the “Below the API” logic? I think it does. Here’s where I would start.\nFood delivery apps keep up the pretence that their delivery drivers and couriers are “independent contractors.”\nWhat if, by regulation, we said that it’s fine to have these below the API jobs – but you must open up the API to other bidders.\nSo, yes, they can dispatch a job to random local bike courier… but they must also offer that job to whoever else might take it, such as the local software-enabled courier co-operative. Using the same APIs, of course, but open and documented.\nInsisting on higher wages, and unencumbered by the margin usually extracted by management (which has been automated), the co-op would snap up all the local independent couriers, effectively unionising neighbourhood delivery services. As a collective, they’re able to push back on the downward pressure on wages when the couriers are atomised.\nThe food delivery app would have no choice but to operate through them, bike couriers who are still independent yet have leverage to retain strong rights and benefits. It’s not quite mutualism (where the couriers would share in the success of the delivery company), but perhaps this would still represent a new class of worker.\nSome questions to finish up.\nIs the regulatory intervention I describe above even possible? Can the concept of “Below the API” jobs be flipped against itself, the companies above the API forced to open up? That is, can the pressure to automate jobs into non-existence be reversed?\nA counterpoint: the risk of keeping delivery costs high is that it accelerates the adoption of automated delivery solutions, putting people out of work even faster! But I regard that as a separate problem. Let’s solve for the downward pressure on wages/rights first, and then look at how humans and automation compete.\nFinal question. What other types of organisation are tractable to CoopCycle’s approach of self-driving software co-operatives?\n",
    link: "/home/2020/12/02/extrapolation",
  },
  {
    title:
      "Modern consensus ghosts such as the Monkey Man and the Gatwick Drone",
    date: "20.47, Tuesday 8 Dec 2020",
    content:
      "Conjecture: under great pressure, societies can collectively manifest illusionary objects. These psychic projections, which sometimes appear as terrifying beasts, encode powerful fear or anger or disconnection – and also its resolution.\nThis is a post about the Gatwick Drone, but I’m going to take the scenic route.\nLongtime readers will know of my interest in the Monkey Man. Almost a decade ago, the Monkey Man terrorised New Delhi.\nHere’s a great summary of the phenomenon:\n\nEarly in May 2001, rumours began spreading though New Delhi that an aggressive monkey-like entity was rampaging through the overcrowded suburbs after sunset.\nHouseholders who habitually slept on their flat roofs during the sweltering Indian summer claimed that they were being indiscriminately attacked by the Monkey Man, who leapt from roof to roof, biting and scratching as he went. One man had even fallen to his death fleeing from the creature.\nDescriptions of the entity varied considerably, but most witnesses agreed that it was short and furry with glowing red eyes.\n– The Cosmic Jokers, The New Delhi Money Man\n\nAnd a contemporary article communicates some of the terror (16 May, 2001):\n\nIn Noida, a mechanic wearing a black outfit and fitting a description of the Monkey Man was beaten up. A second man was attacked for apparently performing “mystical formulations”.\nSome witnesses say the failure to capture the Monkey Man is explained by his ability to make himself invisible.\nDeepali Kumari, from Noida, said: “It has three buttons on its chest. One makes it turn into a monkey, the second gives it extra strength, the third makes it invisible.\n“He touches a lock and it breaks. But he is afraid of the light.”\n– Ananova, Indian police release pictures of Monkey man killer\n\nI’ve found a cache of old news stories. Since they tell the story of that month pretty well, I’m going to copy and paste the subheds below. (These are all the stories tagged “Monkey Man” on this particulare site.)\n\nPanic caused by a weird monkey-man has grown in the Indian town of Ghaziabad following more attacks and sightings. (13 May, 2001)\nIndian police say anyone who sees the “monkey man” who has been terrorising householders should shoot him on sight. (14 May)\nReports are circulating in India that the ‘monkey man’ attacker is an extra-terrestrial or a remote-controlled robot. (15 May)\nIndian police have issued pictures of the Monkey Man killer, amid reports he has claimed his second victim. (16 May)\nA person suspected of wearing a monkey mask to scare people has been arrested in an Indian city. (16 May)\nA zoo director says India’s feared ‘Monkey Man’ can’t be an animal. (17 May)\nIndia’s Monkey Man mystery has deepened with Indian police suggesting it is a treacherous Pakistani plot. (17 May)\nIndian authorities are trying to quell Monkey Man hysteria by employing counsellors to talk to New Delhi residents. (18 May)\nMedical experts in New Delhi have been offering advice on what to do in the event of an attack from the Monkey Man. (18 May)\nIndia’s Monkey Man is alleged to have killed directly for the first time by puncturing his victims’ skulls. (18 May)\nA doctor has been become the latest participant in Monkey Man mania that has spread across New Delhi. (19 May)\nDelhi police say they’re close to solving the Monkey Man mystery. (19 May)\nAn Indian psychiatrist has compared the Monkey Man mystery to a penis-related panic among Nigerian men 10 years ago. (20 May)\nSightings of the Monkey Man are said to be reducing after Indian police arrested a dozen people for spreading rumours. (21 May)\nA second reward has been offered for information leading to the arrest of India’s Monkey Man. (21 May)\nThe number of attacks in India attributed to the Monkey Man is continuing to fall. (22 May)\nReports of Monkey Man attacks in New Delhi are falling off. (23 May)\nAs Monkey Man hysteria dies down in Delhi, villagers in north-east India are claiming a new menace is on the prowl - Bear Man. (27 May)\nRussian media are reporting a plane passenger flying from Delhi to Moscow acted like Monkey Man, who terrified residents of the Indian capital recently. (11 June)\nExperts in India remain baffled by the identity of the mysterious monkey man. (15 June)\nA special Indian police team says mass hysteria was to blame for the Monkey Man attacks. (18 June)\nThe Indian Monkey Man’s apparent victims say authorities have denied its existence because they failed to catch it. (19 June)\nThe Monkey Man has reportedly resurfaced in India and been blamed for several attacks. (29 August)\nReports of a ‘monkey man’ in India have reappeared a year after panic over the mystery creature hit the capital, Delhi. (21 July, 2002)\n\nAppearance. Chaos and fear and the inability of authorities to do anything about it. The fear is taken seriously and the attacks abate. A tentative speculation about the Monkey Man’s psychological origins; a fierce denial. The phenomenon tails off.\nThere were people wounded in cases of mistaken identity! There were riots!\nSo what was going on?\nI can’t dismiss this as a delusion, or mass hysteria, for three reasons:\n\nthose labels only defer the important questions: why then, why there.\nwe deal with many non-actual yet real things in the world: money, status, soap operas, celebrity, sport. I wouldn’t call the Monkey Man any less real than those consensual hallucinations – though perhaps more democratic.\nto pejoratively minimise the lived experience is also a claim that we, the Monkey Man non-believers, inhabit a “truer” world. My claim is that these manifestations are universal (and one of their attributes is we deny their semi-actual status when we’re the ones doing the manifesting).\n\nFor me, the clue is found in these facts: The Monkey Man attacked at night and caused fear; the Monkey Man was scared of water.\nBack to that summary:\n\nA rumour spread that the Monkey Man could be destroyed if you doused it in liquid.\nAnother theory was that residents were so frustrated with the frequent night-time power outages that they were phoning in fake Monkey Man reports, knowing the authorities would turn the electricity back on before setting out to hunt the beast.\n\nSo there we have it – in a period of electricity outages (and, I remember reading, water shortages), and knowing that the Monkey Man would create unrests, communities found a way to force authorities to turn on the lights and prioritise running water. It’s almost like a magic spell.\nDoes that make the Monkey Man any less real? I don’t think so. Reading the news articles, it seems like many people weren’t in on the joke… especially not the people who got beaten up. (Or maybe a fake “mistaken identity” was a good excuse for something that would have happened anyway…)\nI don’t have my notes to hand, but I seem to remember a similar Goat Man appearing in Mexico City (late 20th century) and, in 19th century London, there was Spring-heeled Jack who sounds and acts very like the Monkey Man.\n\nI wonder what was the community “purpose” of these collective manifestations? What did the belief in Spring-heeled Jack achieve for Londoners?\nI wonder if there are “nodal points” in the group imagination, images that societies will independently alight upon – red eyes, leaping and slashing, etc? Perhaps these memes are shaped to be the most contagious?\n\nI was thinking of the Monkey Man when I read this fantastic long read in The Guardian about the Gatwick drone:  A drone sighting caused the airport to close for two days in 2018, but despite a lengthy police investigation, no culprit was ever found. So what exactly did people see in the Sussex sky?\n115 sightings. 222 witness statements. 1,000 flights cancelled. 140,000 passenger affected, just before Christmas.\nNo such drone existed.\n\nThe Gatwick incident was the first time a major airport was shut down by drones, and it distilled deep cultural anxieties - from the threat of terrorism and unconventional attacks by hostile states, to our fear of new technology. \n– The Guardian, The mystery of the Gatwick drone\n\nThe article cites some other urban legends (the Croydon cat killer is a recent one, local to me), but they aren’t quite the same. The Gatwick drone resulted in something: collective misgivings about flying, airport expansion, vulnerability to terrorism, etc, manifested in a physical drone – which closed down the airport, relieving the fears.\nTo me this is an infant Monkey Man. Had the drone proven only a touch more effective, let’s say by reducing the number of planes landing into airports where drones were “sighted,” I suspect there would have been many, many Gatwick Drones, all over the world.\nThe Monkey Man and the Gatwick Drone are massively multiplayer Ouija boards.\nWe all have our fingers on the pointer. Maybe we can feel it pulling towards the letters; maybe we’re doing the pushing. Maybe the messages are deliberate; maybe they’re a form of dowsing the collective unconscious - some kind of Jungian Hadron Collider - or maybe it’s direct from the spirit world. We don’t know and we can’t know, and that’s the point.\nThe point is that these manifestations sit halfway between fact and fiction. It doesn’t matter who believes and who’s faking it – what matters is that nobody needs to say what the goals are out loud, and yet it is efficacious none-the-less. The power comes back! The planes stop!\nAnd maybe this is a decent way of understanding other collective “hysterias” such as Qanon: not by looking at what they do, that’s not relevant, but by looking at what they force the rest of us to do as an apparent side-effect. How do we bend in response? Now let’s interpret that response, not as a side-effect but as intended.\nOne last connection. What I’m talking about are hauntings and my favourite haunting in fiction is in Hamlet. For me, Hamlet is an astounding feat because it is utterly, utterly true to life. Every character, every feeling, every consequence: so believable, so human. Yet it opens with a ghost! The supernatural. One way to understand the ghost is that it is a psychic manifestation of a community under great pressure: everyone at Elsinore knows of the murder of the old King yet, because of the status hierarchy, they are unable to voice the truth to Prince Hamlet. Between the unstoppable force and the immovable object is forged the ghost, a psychic diamond the actualisation of unspeakable need.\n(I’ve posted about Hamlet before.)\nAnyway.\n",
    link: "/home/2020/12/04/coops",
  },
  {
    title: "The hard work of imagining, ThingsCon 2020",
    date: "16.00, Friday 11 Dec 2020",
    content:
      "I presented this essay as part of ThingsCon 2020 on 11 December, 2020. The week-long virtual festival was also the launch of this year’s Responsible Internet of Things publication, so I decided to speak about imagining futures - dystopias and utopias. As a talk, the essay was shortened and I also used slides. What follows is the long-form version.\nDentistry, 3D printing, and the Gartner Hype Cycle\nI want to talk about the Internet of Things and how we build the future. The theme being, of course, as this is the event, responsible IoT.\nThe Internet of Things first appeared on the Gartner Hype Cycle in 2011. (Source; see linked spreadsheet for data.)\nAlso that year:\n\nImage Recognition. Well, that’s just how computers see now.\nAlso QR codes. I was rooting for you, QR codes. It only took a global pandemic to have me scanning codes every time I leave the house.\n\nIt’s interesting the convoluted route technologies take to adoption, and the effect they have, and to think about the Internet of Things, IoT, in that context.\n3D printing first appeared in 2007. It had a 4 years head start.\nWe got our first milling machine in 2006. This was at Schulze & Webb, the studio that later became my old company BERG. It milled blocks of chemical wood, and produced a kind of dust that gave us “tight lung” as we called it then because we were young, but will probably take a year off my life when I’m old. It ran overnight to make any kind of shape. Resolution, and I’m guessing here, probably around half a millimetre.\nNow I went to the dentist the other day to get a crown replaced. My mouth was scanned and the tooth designed with a handheld photogrammetry device and touchscreen 3D software on a terminal right by the chair.\nIt took 7 minutes to mill my new tooth on the machine in the basement. The milling machine has an accuracy measured in microns: about a thousand times more accurate than our old miller.\nEven last year, making and fitting a new crown was a 2 week job requiring a specialist lab. Now my neighbourhood dentist can do it, and I was in and out in less than 90 minutes.\nSo the way 3D printing has come into the world is what I would call: same but faster.\nFaster teeth. Faster prototyping. Faster tools for injection moulding in factories.\nBut we haven’t seen the society-wide impact that I think some of us were expecting when 3D printing first appeared on the Hype Cycle. Supply chains haven’t turned into supply webs. Manufacturing hasn’t become local, with mini factories in every neighbourhood. We don’t print our phones or print our shoes or print our breakfast. We still have mass production and mass consumption and mass marketing.\nDon’t get me wrong. I hate going to the dentist. 3D printing means I can go to the dentist for less time. I am delighted. But what we got is nowhere near what we imagined.\nSo is the Internet of Things more like what we got with 3D printing, or more like what we imagined we’d get? Is it same-but-more-efficient, or is it transformative?\nThe Great Inversion is midway done\nI think about the Internet of Things as the Great Inversion.\nIt used to be, before the Internet of Things, say before it appeared on the Gartner Hype Cycle, before 2011, that the computer was contained in the world. There was the world and it contained people, and forests, and cities, and shoes, and feelings, and all the rest. And one of the things contained by the world was the internet.\nBecause of the Internet of Things, this situation has inverted, it is inside out. There is now the computer, and one of the things that it contains is the world.\nRobotics are the hands and feet of that inversion. Computer vision – that’s the eyes. But IoT, it’s the connective tissue. The wiring.\nI would say that the Great Inversion is currently midway done.\nThere’s a short story written by Paul Ford way back in 2002 called Robot Exclusion Protocol. It is very short, 254 words. It’s about Google. Here’s how it starts.\n\nI took off my clothes and stepped into the shower to find another one sitting near the drain. It was about 2 feet tall and made of metal, with bright camera-lens eyes and a few dozen gripping arms. …\n“Hi! I’m from Google. I’m a Googlebot! … I’m indexing your apartment.”\n\nThat’s the era we’re in at the moment. Indexing. Ingesting. Eating.\nWith IoT we’ve got industrial IoT with sensors in factories, and we’ve got connected cars, and we’ve got voice-controlled gadgets.\nAnd what it means it that the physical world is now subject to all the winds and forces of the internet. Those search engine index, those trading algorithms; it’s subject to analytics and automatic optimisation and machine learning, and all the rest.\nI don’t see it slowing down. The economic imperatives are too strong.\nWhatever happens to musicians happens to everybody\nWhat happens when software eats the world? Bruce Sterling has a line about this. He says, Whatever Happens to Musicians Happens to Everybody.\nHe talks about a collapse in genre diversity, and the distributors taking control of the economics, and go-it-alone creators. And his point is that you can see the same thing happening in newspapers and fashion and whatever. It happened first to musicians.\nBecause of the Great Inversion, the world is part of the internet.\nSo I’d like to generalise Sterling’s Law to this: whatever happens on the internet will happen to the world.\nAnd there are many good things about the internet.\nBut the internet in 2020, well, we’re not in a good place. Despite the idealism of those who wrote the RFCs when the internet was in its infancy, and the good intentions those who who were at the vanguard of Web 2.0 when the internet came into the mainstream.\nNot in a good place at all.\nPlatform capitalism and consumer farming\nLike any complex system, the internet comes with internal forces that shape its evolution. Forces, tendencies, gravities. Call this internet realism. I call  these forces “logics” because they are directions that just make sense within the context of the internet.\nOne is the logic of platform capitalism.\nPlatform capitalism is a term invented by the economist Nick Srnicek. His book is great. He uses it to label the operating model of many Big Tech corporations, and he points out that they work like this:\n\nOperate a marketplace that brings buyers and sellers together. For example, book sellers and book customers. Or drivers and passengers. Or advertisers and browsers\nCollect data - any data - all the data - that can be used to drive marketplace activity, either by pushing transaction volume or marketplace size.\nAs the marketplace grows, it wins out over other, alternative marketplaces, reducing competition. And the data capture basin increases too, enabling further growth. As part of this step of the operating model, data capture always increases.\nRepeat and grow.\n\nYou can see it in action with, say, Facebook. All my friends are there! It’s free! There’s no excuse for me not to be a participant in this marketplace. Yet the data which is gathered is used to drive my marketplace activity – my clicking on ads and my purchases. From the advertisers point of view, there’s no ability for them to opt out either. And the ads are priced at just the level where they would be foolish not to participate – but where Facebook can keep as much margin as possible. The data they gather lets them know exactly what this level is.\nThis is a hungry logic. It’s expansionist, and there’s no room to realistically consider alternatives. It just makes sense.\nWhat happens when the logic of platform capitalism meets the Internet of Things?\nWe see glimpses of that with Uber, and their carefully priced marketplaces which capture drivers into vehicle rental and subsistence income. And we see glimpses of that with the Amazon Ring doorbell and data gathering on the street.\nBut let’s take it an extreme. I can imagine a free apartment where everyday activity is monetised. A free house that comes with a bundled app store of Amazon Dash-style subscription purchases for cleaning products, and food, and clothes, and rental furniture; all carefully and automatically optimised by monitoring usage through connected cameras and sensors.\nThis is a dystopia where humans, you and me, are farmed as consumers, by platform capitalism. We never own, we pay rent.\nIt could be built today. It’s just that nobody’s gotten round to it yet.\nSo that’s one example of where that particular logic could end up.\nTo the computer, it’s just another device\nA second logic of the internet is that of abstraction.\nTed Nelson invented hypertext and was one of the first to really probe what it meant to use computers for creativity. He’s a visionary. In his book Computer Lib (1974), he said this:\n\nWhatever it may do in the real world, to the computer program it’s just another device.\n\nAnd this is the amazing thing about computers and the internet – the computer sends data, and it could be showing a few pixels on a screen, or it could be driving a probe on another planet.\nOr it could be transferring Bitcoin. A Bitcoin transaction takes as much energy - and therefore as much carbon - as used by an average British household in two months.\nThese all have the same weight to the computer. And so they all weigh the same to us. \nThe logic of abstraction is neither good nor bad, it’s just the way computing works. Everything gets abstracted. Computer scientists have a name for when you can tell what happens the other side: they call it a “leaky abstraction.” It’s something to be avoided.\nBut in the real world, when consequences are hidden, situations tend to be abused.\nAnd what happens when the real world is, well, just another device, thanks to IoT?\nWell, you tap an app on your phone, and you call a car. The driver rents their car, is paid below minimum wage, has no savings. They’re an independent contractor so they don’t have employment benefits. At some point the workers will be automated away. The company is structured so that they are, in the parlance, “asset light” - but also so that they can’t be held accountable.\nWe, the tapper of the app, are insulated, because of the logic of abstraction.\nIt’s what Peter Reinhardt first referred to as Below the API versus Above the API jobs. \nLiving above the API, we order groceries, interact with customer service, live our lives one step abstracted from the people with whom we share a society. And below the API, wages are squeezed, people made to compete with robots, and inequality grows.\nIt’s hard to argue with the logic of efficiency and automation. That’s what makes it a logic. The logic of abstraction is what makes it hard for us to even see it happening.\nThe logics of monocultures and overextended complexity\nSo there are other logics of the internet. The logic of monocultures that create attack surfaces for state-sponsored cyberwar. The logic of overextended complexity that grows till breaking point. We’ve seen high-frequency trading algorithms cause flash crashes in the stock market, from just that logic of complexity – what happens when we have a flash crash on a highway of autonomous cars filled with school kids and commuters?\nBut enough dystopias.\nDystopia is an extrapolation. Utopia requires discontinuity\nThe future I want embodies different values.\nI want my home to be voice controlled – but I want it without centralised data capture.\nI want car-sharing schemes and last mile delivery – but I want it to operate through mutualism and co-operatives.\nI want home security drones – but I want them to make their domestic visual index available to a private app so I can text-search my bookshelves for that book I can’t lay my hands on, rather than them using it to train their ad targeting A.I.\nPrivacy. Agency. Mutualism. Equality.\nI’m not saying these futures are impossible, but they feel hard to reach from where we are right now.\nBecause honestly, it feels like I don’t get to choose, we don’t get to choose, those futures.\nThe system that does get to choose is the system that surrounds our tribe of designers, technologists, and founders. It’s all those adjacent tribes that never get to see the idealism and the intentions. The marketers, retailers, supply chain experts, risk assessors, the MBAs, policy-makers, and so on. They don’t get to see the vision; they have to follow the well-trodden path. They follow the logics. The logics are the same old business models, the same old ways of capturing attention, the same old methods to build platforms.\nDystopia is the extrapolation of the same old, same old.\nBut utopia is a non-extrapolation, it requires a discontinuity. It requires all these different tribes to choose to do something different, at great risk to their careers and livelihoods.\nIf they’re going to do that, they all need to be shown that something different first, and shown how it’ll work.\nAnd you know what, I think that’s our job.\nWe need to do the hard work of imagining\nSir Terence Conran: The designer’s job is to imagine the world not how it is, but how it should be.\nI’ve lost the habit of imagining utopias. Perhaps we all have.\nToday, right now, we’re in what architect Bryan Boyer calls a “vision vacuum.” I don’t know why, but imagination about positive futures is scarce right now. And in the absence of a compelling narrative, the same old, same old wins by default.\nNarratives? Fiction?\nBut we don’t need just design fictions. We need business model fictions, engineering feasibility study fictions, interop protocol specification fictions, investment return fictions.\nI’ll give you an example. I’m a proud member of the British Interplanetary Society which is, on one hand, a talking shop. But on the other, has been a significant part of the conversation, for 87 years, through engineering feasibility reports. The society’s engineering design for a probe that would go to another star, a study called Project Daedalus which ran from 1973 to 1978, has helped make the idea of interstellar travel more believable. Concept ships in research and fiction are based on the Daedalus designs; the Daedalus report helps identify what the actual problems are and where R&D should be targeted.\nSo I guess what I’m asking for is a different kind of think tank, not one that works with recommendations and reports and regulation, but a new think tank that trades in politically opinionated, worked examples that demonstrate, demystify, and de-risk.\nThe objects and systems must be plain, easy to understand, and embody our values. If you asked me now where to start, I would start with worked examples for:\n\nZero-user-data connected products (related: I wrote about voice control for everything, but could we sketch a business model?)\nOpen file formats for service portability  (related: I wrote about interop for video calls, but could we design the protocol and code up a reference app?)\nSoftware-enabled cooperative corporations (related: I wrote about software-enabled co-ops but could we ship a co-op as a Shopify plugin?)\n\nWe need boundary objects that transcend language and can translate across the different tribes.\nAnd the marketers, retailers, supply chain experts, risk assessors, the MBAs, policy-makers, and so on, if we can indeed make tiny, proof of concept, real versions of these futures, bonsai tree utopias, made out of spreadsheets and simulations, if we can speak to them in their words, they will nurture and help those futures grow, I think there’s space for that.\nI think I need to - we need to - imagine utopias again, and we need to demand and create demand for them, and we need to articulate them in great detail.\nBut we need to be the ones doing the hard work of imagining a responsible future for the Internet of Things. Because it’s no-one else’s job to do so.\n",
    link: "/home/2020/12/08/gatwick_drone",
  },
  {
    title: "Artificial meteor showers and the function of omens",
    date: "19.34, Tuesday 15 Dec 2020",
    content:
      "I’m sad that Tokyo 2020 is postponed, primarily because the opening ceremony was rumoured to include an artificial meteor shower.\nFrom 2016:\n\nThe project, Sky Canvas, goes beyond your average fireworks display: It involves launching a satellite into space “loaded with about 500 to 1,000 ‘source particles’ that become ingredients for a shooting star”\n– QZ, A man-made meteor shower launched by satellite could open the 2020 Olympic Games in Tokyo\n\nSky Canvas, by ALE Co., Ltd: The man-made shooting star particles are 1cm spheres made of various substances that burn up with different colours. Visibility is about 200km range per shooting star particle.\nI think what I like most about the meteor shower is that it’s an omen. Meteor showers in ancient times were portentous: see one, and you’re anticipating a great harvest or terrible war just around the corner.\nBut for the 2020 Olympics, the knowledge of the event precedes the artificial portend! The thing is happening anyway, and the Tokyo organising committee have post-hoc bolted on the omen using satellites and chemistry.\nThinking about the function of omens…\nThere’s a concept called stochastic resonance in which a signal that is normally too weak to be detected by a sensor, can be boosted by adding white noise to the signal.\nMeaning… some hint that is too faint to detect can be amplified and noticed simply by adding some noise or static. Wikipedia lists some examples in human perception.\nSo, putting aside any supernatural origins, perhaps the function of omens is to add noise to our natural sense of anticipation, amplifying our unconscious hunches about future events and boosting them to awareness?\nFor example, you’re an ancient Roman general going off to war, and you walk down the via as - just by coincidence - all the nearby birds stop singing. Noticing the portent, you consider more seriously the possibility of failure – and, in doing so, are better prepared for the battle ahead.\nI think the reason this works at all is that some portents are actually meaningful. As previously discussed: in the ancient world, birds did indeed tell the future.\nSo I wonder if there are everyday, domestic omens that I could be more sensitive to?\nLike: my internet sometimes slows down. And mostly that’s random. But every so often it’s because a massive PowerPoint is landing in my inbox, and that means there’s work to do.\nCould domestic omens be created artificially?\nLike: if I have a day of back-to-back meetings, maybe the sound of distant thunder ten minutes before would remind me to refill my water bottle?\nMaybe I could pay that Japanese company to drop an artificial meteor across South London, just before I go to bed, visible from my window, if I’m doing a conference talk the next day?\nHalfway through a meeting, when the team’s AI facilitator discerns that an overdue decision may be imminent, the conference call is zoombombed by a tongueless dwarf silently pointing at a whiteboard.\nI’m rambling.\n",
    link: "/home/2020/12/11/thingscon",
  },
  {
    title: "We live in a semiotarchy",
    date: "19.46, Wednesday 16 Dec 2020",
    content:
      "Our street seems to have become a waiting point for ride-share drivers between jobs. We’re haunted by black saloon cars, parked up with motors idling, drivers tapping their apps.\nSeparately, our street is periodically used as a route for large trucks and coaches – which then either get stuck going round the corner at one end, and have to reverse back all the way; or at the corner on the other end, go straight over a bollard and leave debris everywhere. I don’t know whether this is an occasional mislabelling of our street as a phantom major road, or ripples from roadworks a mile away fooling the routing algorithms.\nData in the mirror world is making it noisy outside my house. The map is intruding on the territory.\nIt’s contested. Los Angeles is a city of need-to-know neighbourhood shortcuts being revealed by Waze, the pro Google Maps:\n\nThe Waze algorithms don’t care about the societal cost they inflict and neither does Waze if the algorithm calculates that a cut-through may save seconds. “The instant the time penalties work out,” DwarfLord claims, “Waze will just as happily send a thousand Wazers down a Passageway as it would [a single] one.”\n– Los Angeles Magazine, Waze Hijacked L.A. in the Name of Convenience.\n\nLocal residents attempt to wrest control of the map. Anyone can make suggestions to the Waze, and so, to solve this particular problem, a Level 3 community editor suggests setting a segment at each end of a tiny road as “unpaved.” Or marking it as a “gated community.”\nI suggest that we have entered a semiotarchy – like an oligarchy or a plutarchy, only our era is the tyranny of signs.\n",
    link: "/home/2020/12/15/omens",
  },
  {
    title: "My most popular posts in 2020 and other lists",
    date: "10.56, Thursday 17 Dec 2020",
    content:
      "This blog turned 20 years old in February, and it turned out to be a productive year – although I had no idea at the time how much I’d end up writing.\nAccording to Google Analytics, my 5 most popular posts in 2020 were (in descending order):\n\nMars problems vs Venus problems\nFiltered for hallway tracks and spreadsheet parties\nRisk: micromorts, microCOVIDs, and skydiving\nThe holy founding text of The Church of the Next Word, as revealed to Frank Lantz\nVarious first words\n\nHere’s a longer list: my 20 most popular posts in 2020.\nOut of the 100+ posts this year, I’ve also made a list of the most speculative, on topics such as…\n\nCyborg prosthetics and smartphones with limbs\nCharisma as a physiological mutation\nIce cream trucks for coffee, now we’re working at home\nBreathing out stress as isoprene\nAncient magicians\nWeird office furniture\n\nHere you go: 18 speculative posts in 2020.\nSome stats.\n\n2016: 48 posts (25,227 words, 462 links)\n2017: 22 posts (17,007 words, 244 links)\n2018: 15 posts (16,786 words, 123 links)\n2019: 8 posts (7,268 words, 78 links)\n2020, to year end: 116 posts (94,348 words, 712 links)\n\n94,000 words? That’s what lockdown does. And also a different approach to writing. Back in September, I posted my 15 personal rules for blogging which are all about dodging mental traps.\nUpdate 2 Jan, 2021: Finalised 2020 stats, above.\n",
    link: "/home/2020/12/16/semiotarchy",
  },
  {
    title: "Minecraft is haunted and Twitter too",
    date: "10.08, Tuesday 22 Dec 2020",
    content:
      "It turns out that Minecraft is haunted.\nHerobrine is Notch’s dead brother, somehow embedded into Minecraft. (Notch is the creator of the game.)\nHerobrine appears as a Minecraft character and he stalks the player, disappearing if approached.\nAnd: Herobrine shows a lot of characteristics of being a form of virus, such as manipulating game worlds, deleting threads and sending messages through the Minecraft Forums.\nBUT: Herobrine is not in unmodded Minecraft, and never has been. There are no references to him at all in the source code, and there is no code to allow for any entity to act like Herobrine.\nDoes Herobrine play a social role?\nI don’t know enough about Minecraft to say. But here’s my guess. If there’s a group of 10 year olds playing together, and somebody messes with someone else’s favourite construction while they’re offline, or messes with their own stuff and regrets it, or leaves a rude message due to poor impulse control, it’s an easy thing to do: uh, yeah, I think I saw someone around, maybe it was Herobrine…\nTwitter has a device like this, the face-saving unfollow bug – which has been haunting Twitter as long as I remember. Me: your good friend. You: notices that I don’t follow you. Me: uh I’m sure I do, oh look at that, we must have been bitten by the unfollow bug.\nAt which point your options are (A) to call me out on the unfollow bug excuse being unalloyed bullshit, but also implicitly taking the punch of the rejection; or, (B) say sure, sure and accept the face-saving throw, leaving both of us feeling better off.\nWe choose option (B).\nDoes the unfollow bug exist? If you ask around, many people will strongly insist that it does, even giving examples, albeit examples that could also be from fat-fingering the UI, or a real and unconscious commitment to face-saving and avoiding the pain of rejection. I’m not convinced. Did the unfollow bug ever exist? Perhaps once. But today it’s a consensus ghost, a precipitation of the community’s collective and deeply repressed need for harmony.\n",
    link: "/home/2020/12/17/top_posts",
  },
  {
    title:
      "Chemicals to help you write PowerPoint and other cognitive fantasies",
    date: "14.55, Wednesday 23 Dec 2020",
    content:
      "After mentioning in November my discovery of the secret of the universe at the dentist, and my struggle to retrieve it, Tully Hansen, poet, dropped me a note to say that my experience is not unique!\nThis story has been told variously about nitrous, ether, and chloroform, but here’s a version from an 1870 lecture by Oliver Wendell Holmes: I once inhaled a pretty full dose of ether, with the determination to put on record, at the earliest moment of regaining consciousness, the thought I should find uppermost in my mind.\nAnd so:\n\nThe veil of eternity was lifted. The one great truth which underlies all human experience, and is the key to all the mysteries that philosophy has sought in vain to solve, flashed upon me in a sudden revelation. Henceforth all was clear: a few words had lifted my intelligence to the level of the knowledge of the cherubim. As my natural condition returned, I remembered my resolution; and, staggering to my desk, I wrote, in ill-shaped, straggling characters, the all-embracing truth still glimmering in my consciousness. The words were these (children may smile; the wise will ponder): “A strong smell of turpentine prevails throughout.”\n– Quote Explorer, Secret of the Universe\n\nSo: a class of inhaled anaesthetics triggers an experience of revelation, struggle to recall, and a mundane truth – and this experience is individual yet shared.\nI think what catches me by surprise, about this trip to the dentist, is how intensely personal and subjective it felt… yet that’s simply something that nitrous produces, reliably.\nRELATED: a reliable effect of salvia is to witness the layers of reality; a reliable effect of DMT is to encounter beings called by Terence Mckenna self-transforming machine elves.\nReliability. Way back in 2007 I was going on about the book Phenethylamines I Have Known And Loved which documents the effects of 179 different compounds – and asking why we didn’t already have reliable smart drugs.\nI didn’t mean smart drugs like Omega-3s, which apparently boost cognitive performance in a low level and generalised way as a diet supplement, but instead highly targeted, functional, reliable psychoactives: Why don’t we have abstraction modifier drugs now? Why are there no drugs to help me think in hierarchies, or with models, or to make cross connections?\nI’m not sure I’d take any, but I still wonder about this.\nI wish I could remember where, but I remember reading that the breakthrough with Viagra was getting “erectile dysfunction” listed as a pathology. There’s a book of official pathologies. Once something is in that book, drugs can be developed (with research costs offset against tax); drugs can be marketed and proscribed and bought with insurance, and so on.\nSo could you pathologise “lack of lateral thinking,” or “dysfunction in authoring structured PowerPoint”, or “inability to consult with the machine elves” – and produce a little blue pharmaceutical to deal with the issue, a blister pack full of 60 minute perspectives, epiphanies, and corporate strategy skills?\nI guess I’m looking back at my posts from this year, including this one thinking about using the GPT-3 AI as a creative collaborator, and imagining a different future, one based on molecular biochemistry not machine learning; rather than looking to computers to provide mental prostheses and automate jobs, we instead extend the gamut of human ability with cognitive interventions?\nWhat would it mean to have utilitarian psychoactives? How would the world change?\nThe mundane consequences:\nRight next to the “Out of Office” email setting for when you’re on vacation, a button that turns off your inbox and sets the auto reply just for a single morning, clearing the decks for your weekly creative consultation with the machine elves.\nA vacuum cleaner with flashing light patterns specifically designed to capture your attention when you’re on a deep clean trip, absolutely and happily and regularly and chemically fixated on getting your chores done.\nA transcranial magnetic stimulation helmet that takes over your legs for your 30 minute commute so you can avoid crowded trains, get your 10,000 steps in, and catch up on your TV shows.\n",
    link: "/home/2020/12/22/herobrine",
  },
  {
    title: "What I’ve been reading in 2020",
    date: "13.24, Monday 28 Dec 2020",
    content:
      "I would recommend these 5 non-fiction books, all of which I read over 2020:\n\nViruses, Plagues, and History: Past, Present, and Future, Michael B A Oldstone (29 May)\nExtraterrestrial Languages, Daniel Oberhaus (18 July)\nAstounding: John W. Campbell, Isaac Asimov, Robert A. Heinlein, L. Ron Hubbard, and the Golden Age of Science Fiction, Alec Nevala-Lee (29 Aug)\nEconomic Science Fictions, ed. William Davies (1 Nov)\nThe Institutional Revolution: Measurement and the Economic Emergence of the Modern World, Douglas W Allen (11 Dec)\n\nLinks are to Bookshop.org (UK site; tap the flag for different regions). Dates are date finished.\nViruses, Plagues, and History is simultaneously a social history (each chapter covers one plague: polio, measles, etc) but also a scientific education and a scientific history. Oldstone covers virology and how different vaccines work, in decent detail, and the stories of the teams that discovered the cures.\nEye-opening to read about how wars and politics have pivoted dramatically and throughout history on disease outbreaks, and the sheer complexity of the biology. One image that stuck in my head: when the polio vaccine was announced in 1955, church bells were rung across the whole of the United States. Imagine that.\nExtraterrestrial Languages is another scientific history, this time of the efforts to send messages into space. What language do we speak to aliens, who may or may not be there, and with whom we share not a tongue nor a cultural context nor even our biology? And when messages are sent, are they meant for the ETs, or are they really intended as a unifying message to all us humans here on Earth? Good anecdotes – plus a throwaway comment which took me on a dive into John Lily and his weird dolphin experiments back in July.\nAstounding is four intertwined biographies. John Campbell was editor of the science fiction magazine Astounding from 1937 till 1971, and bullied into the world what we now think of as “traditional” sci-fi pretty much by force of will. All those tropes about square-jawed capable men (specifically men…), scientifically and logically conquering the galaxy in their spaceships, and sci-fi being a vehicle to predict and bring about the future: that’s Campbell. He was also deeply racist alongside other troubling views, with a side interest in pseudo science – including co-developing Dianetics (which became Scientology) with L. Ron Hubbard. Fascinating stories about big personalities, and good colour on 20th century America.\nEconomic Science Fictions is a collection of pieces running from critical theory to experimental fiction, all ostensibly taking a run at how science fiction can inform today’s understanding of economics. But sci-fi is neither here nor there – there are many perspectives on economics, and speculation on what is fixed and what is contingent, and that’s what I found most educational. The result is a kind of disentangling or unpicking of the knot of capitalism that I have for so long taken for granted.\nI found the collection influential while I was writing my essay for ThingsCon, The hard work of imagining, on utopias and dystopias and the irresistable “logics” of interconnected systems – clearly thinking about economic imperitives there.\nFinally, The Institutional Revolution (recommended by Bryan Boyer) is a fourth history and a second book about economics. The premise: the modern economic world comes from the ability to reliably measure – and the institutional patterns of the modern world cover everything from wages to factories; from public provision of roads to social norms about what we now call bribes. Before reliable measurement, there was uncertainty about the wind, about time, about plagues and trust… and the result was institutions that were none-the-less extremely effective, but had a very different form. This is a history of Britain in the pre-modern era: of the aristocracy, and duels, and the private ownership of lighthouses, courts, and positions in the army.\nIt’s a simple question: pre-modern Britain had institutions that were almost unchanged for 300 years, in forms that we would now say were inefficient and corrupt. But taking the counterfactual that this was the most rational way to organise the economy, why did these particular institutions win? Allen takes a strongly Coasean approach of figuring out how mechanisms like aristocracy and patronage would minimise economic transaction costs, and as someone who has been previously inspired by Ronald Coase, it’s a provocative take.\nAlso, as a Brit, I feel like I understand the old aristocracy - a kind of mafia really - all the better for it being described by an outsider. One of those books where I was stopping every few pages to read anecdotes out loud.\n2020 has been an odd year for reading. I’ve not read much that’s new. Mostly, because of lockdown and therefore self care reasons, I’ve been comfort reading old favourites.\nSo here are two.\nAnathem (Neal Stephensen) is a story of monks on a planet not quite like Earth where philosophy and the scientific method have followed a parallel track all the way from their equivalent of the ancient Greeks. Technology comes and goes, society comes and goes. The monks take the long view. It’s terrifically well told, and somehow manages to go deep on big ideas while still galloping along. Tremendous.\nStars in My Pocket Like Grains of Sand (Samuel R Delany) is set in a vast, multi-species, culturally rich galaxy, and it plays games with linguistics and subjectivity. It’s also a love story, and highly erotic – suddenly and explicitly so. I find it haunting that Delany intended Stars to be the first of two books but, after separating from his partner, never wrote the second.\nBoth books range wildly between the macro and micro, and at all levels there is both precision detail and room for the imagination to breath. The result, which they share, is that they give me a breathless feeling of vastness – and yet for all that backdrop, they’re focused on people. They’re both novels that, when I’m halfway through, I slow down because I don’t want to leave.\n",
    link: "/home/2020/12/23/turpentine",
  },
  {
    title: "2021 is when lockdown will stop mattering",
    date: "12.06, Tuesday 29 Dec 2020",
    content:
      "Over lockdown, one concept that has stuck in my head is short and long-term adjustments. (Here in the UK, we’ve been in one form of lockdown or another since mid March. With the new variant, that’s not ending any time soon.)\nIt’s from a post applying ideas from economics to epidemiology:\n\nlong-run elasticities of adjustment are more powerful than short-run elasticities.  In the short run you socially distance, but in the long run you learn which methods of social distance protect you the most.  Or you move from doing “half home delivery of food” to “full home delivery of food” once you get that extra credit card or learn the best sites.\n– Marginal Revolution, What does this economist think of epidemiologists?\n\nPersonally: Short-term adjustments mean working from my sofa using Zoom, and pausing the usual round of coffees and chatting (that’s how I find new ideas and also new work).\nLong-term means moving the house around and setting up a desk; sorting out the lighting; opening my calendar on Wednesdays for Unoffice Hours… but also domestic things like using the time freed up from the commute to get into baking. All to the point that if somehow I could magically go back to the old way, I’m not sure I would.\nYou can see this happening with restaurants. Short-term means staff are furloughed and orders go to pick-up only. Long-term: well, we’re beginning to see hints of it. Yes, some restaurants are closing, but others are offering part-cooked meals for delivery and building a customer base that way, amazing food that you could never get at home before.\nWe’ll be in lockdown deep into next year. Even then, how long will it take before we stop wearing masks, or no longer require negative covid tests before flying?\nThe long-term adjustments will kick in way before then. \nWhat I wonder about mundane business activities.\nI can imagine that something like, say, the employee onboarding process has been ad hoc, time consuming, and error prone for the last few months. But in 2021, someone in HR will get round to making it streamlined and efficient – totally optimised for remote working.\nAt which point, will there ever be an incentive to switch back?\nHere’s how I think about it. First you cope and then you adapt. The kicker: once you adapt, you may not want to go back.\nWe’ll get a PS5 with the cash we save from not going to the pub, and set up a sweet home office instead of commuting, and organise home deliveries instead of a weekend visit to the supermarket.\nAnd then we’ll realise that we have a new group of friends on PlayStation, and working from home means that we’ve gotten to know the folks in the local takeaway for lunch, and grocery deliveries means we have time for a run on Sundays instead.\nMaybe my phone gets good at automatically monitoring my social distancing budget, better than counting steps or calories even, and it turns out that, with this new lifestyle, I have more than enough for friends and family.\nAnd gradually lockdown stops impeding any of the activities we actually want to do, and even if it ends, we wouldn’t go back.\nLockdown will end not because the restrictions lift, but because they stop mattering.\nSo I think 2021 is the year that long-term adjustments really gather pace, and it’ll be interesting to see, personally and for the economy at large, what that means. How will travelling change? What kinds of new companies will thrive? Like I said in May, there is no After.\n",
    link: "/home/2020/12/28/books",
  },
  {
    title: "Air travel sucks so here’s an alternative future",
    date: "15.32, Thursday 31 Dec 2020",
    content:
      "So, that’s it, a year without flying. I didn’t expect I would ever say that. We landed into Heathrow a year and a day ago, at the end of 2019, returning from Christmas with family in Australia.\nFlying is a miracle and also flying increasingly sucks.\nTo itemise:\nLegroom has been decreasing for 70 years. Planes continue to be noisy and crowded, a stressful environment. Each act of terrorism, happened or hindered, has added a permanent step to the security checks. Yes it’s necessary I guess, but my goodness it means that the airport experience is dehumanising and adds substantial time to the travel. Now there are masks too, the need to get tested before flying, potentially self-isolating at both ends, and of course the risk of an unexpected pandemic outbreak meaning a planned trip will be cancelled or you won’t be able to get home.\nFlying is like broadcast TV (replaced by streaming), newspapers (unbundled and replaced by social media and the rest), PCs (smartphones), etc, where there’s a decades-long boiling frog transition until everybody looks up and collectively says, you know this is really bad, maybe we could just not do this, and do something else instead.\nSo what happens instead of today’s air travel? What’s the long-term adjustment?\nBusiness travel goes private.\nI can see business travel changing radically.\nAfter 2020, as many trips as possible will replaced by Zoom (and gradually businesses and the ecosystem will reorganise such that this doesn’t add friction). Even after this particular pandemic is over, carbon accounting is only going to get more pervasive from here on out, and cutting down on flights is an easy win.\nThe remaining trips will still need to happen. But how? \nBusiness travel is sensitive to time, and not enormously sensitive to cash. Businesses care about comfort in-as-much as the employees are well rested at the other end, but the travel doesn’t need to be luxurious.\nSo the current “high end” of business travel - cabins, nice lounges - doesn’t really help. The airport itself is still the big time cost.\nWhat would it mean to re-think not just the flight, but the end-to-end experience?\nMaybe you could do away with security entirely if you had high trust in every passenger. Maybe you could route around big airports by using small ones.\nWhat I imagine is that every big company has its own airline of private jets. If you’re a Nike employee, you fly with a dozen other Nike employees. Result: No big airport faff, no security, you get picked up from home and driven straight to the plane at a local airfield where you board directly.\nInside the jet, it looks less like a plane and more like a co-working space crossed with a high-end hotel lobby. There are places to work and places to sleep. This is because the flight takes a little longer: you have to hop between regional airports to pick up/drop off passengers and refuel.\nAll routes are dynamically calculated; there is no schedule. “Booking” a flight means putting in a request to be routed. The planes are always in the air.\n(I imagine that there are actually only one or two underlying operators of the planes: it’s a virtual private fleet, except if the company is Google or Apple or something.)\nCargo for the rest of us.\nWithout business travel, economy has to lean into the suckness.\nI remember hearing somewhere that each cabin is priced to pay for the whole plane. Meaning: if any of first class, business class, or economy is full, the rest is gravy. So what happens in the future where the premium cabins get replaced by private jets? Those economy seats are going to get really squeezed in.\nOccasionally you see hear about those standing seats – but that’s just an incremental reduction of legroom. You’re going to hit limits of how many people can get on and off the plane in the turnaround time (or in an emergency), plus getting up and down aisles to feed people, etc. So let’s really go for it.\nReplace the top of the plane with a scaffold that can hold shipping containers (or some other new standard).\nFill the containers with standing seats, and load all meals and entertainment right by the seat. When it’s time to board, load people into the containers, and swap the old containers out for the new ones with cranes.\n(The old containers can be disinfected and restocked at your leisure, further reducing turnaround time.)\nSafety’s a doddle. Each container has its own emergency exit and slide. But there’s no route to the pilot or the other passengers. \nFor entertainment, give everyone VR headsets. Who needs a window or personal space when they feel like they’re on their own in an empty theatre?\nBonus points: provide a choice of containers with different seating. Standing seats in some, capsule hotel-style beds in others, salt-water baths/sensory deprivation pods in a few more.\nIf you like, shunt the containers around like cargo: making a flight connection is a matter of bundling passengers with the same destination together, and moving them directly between scaffold-planes at hub airports. Put a container on the back of a truck and take it all the way to the destination hotel, if you like.\nSlow travel.\nWhile I might be able to tolerate being treated like cargo for an hour or two, I’m not convinced I would want to do it long haul – but I also don’t want to give up visiting long haul locations. So what gives?\nIf vacations weren’t so short, it wouldn’t be so important for long haul travel to also be quick. And maybe the trend towards remote work is relevant here.\nInstead of taking a 2 week vacation, what if I took 6 weeks – but spent a month of that working remotely, or out of a regional office. I’d love to work during the day, but have a completely different country on my doorstep for evenings out and weekend hiking. Could that work? Has anybody tried negotiating something like this in their employment contract, and how would it be represented as a benefit?\nAssuming that could work… perhaps travel by ship would be appropriate, or train, or airship. Dirigibles are due a comeback, I’m sure. It might take a few days or a couple weeks to cross the Atlantic, but treat it as working time with a Starlink internet connection, and maybe it wouldn’t be so bad.\nCruise ships are probably out, floating super spreader events that they are. So, avoiding those pandemic Petri dishes, maybe small yachts made just for coastal waters?\nI have a completely unfounded hunch that self-driving yachts might provide much greater upside for AI than self-driving cars.\nPerhaps, one day, there will be flocks of robot-piloted electric yachts on the open water, hopping auto-harbour to auto-harbour each summer around the Mediterranean, the whole season for a circuit; work and Zoom calls aboard, and after the day is done, while the boat recharges, a plate of frites with big crunchy crystals of salt, hot on the tongue, sitting in the navy light of the late evening on a wicker chair outside at the quayside cafe, the murmur of tourists and nomad workers and residents too, a cold glass of white, the dots of condensation gathering into larger beads, and coming together again, there, a droplet which momentarily catches and refracts the orange glow of the low setting sun, before it runs down the glass and down the stem and onto my finger where I feel its coolness.\n",
    link: "/home/2020/12/29/adapting",
  },
  {
    title: "Recipes for tandoori masala and chaat masala",
    date: "10.45, Tuesday 7 May 2019",
    content:
      "It’s been sunny which means it’s BBQ season which means I need my chicken tikka fix which means it’s spice mix time.\nHere are some pictures on my Instagram.\nGaram masala\nI posted the garam masala recipe I use back in 2014 and I still use the same one. It’s a great spice base, lots of texture, and I like the balance–it’s not too peppery (which I find shop-bought ones can be).\n(This isn’t required for tikka but included here for completeness.)\nTandoori masala\nI’ve adapted my tandoori masala blend from this chicken tandoori recipe on NDTV Food. I like it to have a BBQ taste to it, and that’s done by going heavy on the cinnamon, fenugreek, and onions. I only recently discovered that British Indian curry houses absolutely load their dishes with dried fenugreek, and for better or worse I find the distinctive flavour really more-ish.\nI feel like there should be paprika but I’m on the fence about the sweetness it would add. I’m still iterating this mix so maybe I’ll include some next time.\nThere’s no chilli. I add that separately.\nThe recipe:\n\nCinnamon, about 6 heaped tbsp when broken up\n1 tbsp black peppercorns\n15 green cardamom\n10 brown cardamom\n2 tbsp coriander seeds\n2 tbsp cumin seeds\n10 cloves\n3 bay leaves\n1 tbsp turmeric \n1 tbsp ground mace\n1 tbsp fenugreek seeds\n1 tbsp onion seeds\n\nPrep: Toast (keep moving around in a hot, dry pan) until the aromas come out but careful not to burn. Leave in a dish to cool. Use a coffee grinder to grind though not the one you use for actual coffee.\nChaat masala\nChaat masala gives the tikka its distinctive tang, and that come mainly from amchoor. I’ve previously just bought chaat masala but substituted it pretty regularly (when I’ve run out) with amchoor or just citric acid.\nSo this summer I figured I would make my own blend and I’ve based it on this recipe:\n\n3 tbsp cumin seeds\n1 tbsp coriander seeds\n1 1/2 tbsp saunf (fennel seeds)\n4 tablespoons amchoor (dried mango powder)\n3 tbsp black salt (I used 2 black salt, for smokiness, and 1 celery salt for tang)\n1 1/2 tsp black peppercorns\n1/4 tsp hing/asafetida powder\n1 1/2 tsp ginger powder\n1 tsp dried, powdered mint (I didn’t have any of this on hand so skipped it, but will use next time)\n1 1/2 teaspoons ajwain (I use dried aniseed)\n\nPrep as above.\nTikka marinade\nI use these two blends to make chicken tikka. The marinade I use is from that NDTV Food recipe above but I’ll repeat it here for reference:\n\n3 or 4 tsp red chilli paste\n3 tbsp ginger and garlic paste\n2 tsp chaat masala\n1 1/2 tsp tandoori masala\n1 tbsp oil\n3 tbsp natural yoghurt\n1/2 lemon (juiced)\n\nAdd the marinade to cubed chicken thighs, paneer, or shrimp. Mix well and leave in the fridge for a few hours or overnight. Cook as kebabs under the grill or on the BBQ.\n",
    link: "/home/2020/12/31/air_travel",
  },
  {
    title: "On the New Forest",
    date: "20.20, Friday 10 May 2019",
    content:
      "Perhaps everyone has an ur-place–a place by which all others are understood–maybe they do and maybe they don’t, but mine is where I grew up and it’s the New Forest\n(which isn’t new, as it was founded 900 years ago, and it is barely a forest–mostly heath and scrub and copses)\nI’m here now and I’ve been out for a run. I can’t say I miss it when I’m not here, but when I come back to this landscape which is evidently imprinted deep in my psyche somewhere, my heart swells to bursting\nso running is a matter of stumbling from one overwhelming heavenly moment heart bursts the pool of bluebells nestled under the tree! to another overwhelming heart bursts the sun beams dappling through the branches into the deep woods! to another…\ntill eventually on a bridleway on the open forest (which, so you can picture it, is low rolling heath with grass and ferns with gorse bushes and ponies and donkeys, going misty blue into the distance), running, I couldn’t take it anymore, and stopped and looked at the grass\nunder my feet. The grass between the ferns and heather and gorse is cropped like a lawn, kept that way by the horses who live on the forest, and the grass of course is green but then you look at it, and I can’t help but inventory the colours\ngrass green\nlime\npale blue greens\nsun-bleached yellow\ndeep moss green shadows, all of these blades of grass, all different\nauburn tips of unfurling new shoots\ndeep brown, light beige\nbetween: bone white\nbecause the forest is on a chalk bed, so you get these startling whites, and the water when you see it runs crystal clear, chalk streams they’re called, so the soil not just brown but grey and hazel\nceder\nemerald\nlichen–a pale fire\nthen: tiny: you don’t notice them at first: lilac petals\nThese are the two shocking colours of the forest: tiny bright, secret purples foreshadowing the purple carpet of the heather that will come out in the autumn; and yellow, the bright yellow flowers of the gorse, a million points of light like the stars in the milky way\nall over this infinity of greens and browns and whites, a full half of my gaze, the bottom half is green, and the top half blue–the sky–and to notice that the world, the regular old world, is painted in primary colours, I lose my breath again\nSo the rest of the run I alternate between stopping and looking at the plants, the horses, the horizon, getting lost in it–and sprinting as hard as I can, feeling the land and the sky in my legs and my lungs\nIf I showed you a picture it wouldn’t make any sense. The real picture is how it shaped me and what it feels like to come back, my own psychic contours exactly complemented and filled by the landscape I am in once again.\nCalvino in Invisible Cities, after 55 magical descriptions of faraway places: Every time I describe a city I am saying something about Venice. His ur-place. The New Forest is mine.\n",
    link: "/home/2019/05/07/masala_recipes",
  },
  {
    title: "One year of Job Garden weeknotes, with links",
    date: "10.42, Wednesday 5 Jun 2019",
    content:
      "I missed the anniversary: it’s now week 61 of Job Garden. I write weeknotes on the Job Garden blog and they’re invisible here, so to rectify that: here are links to all the posts to date. Expect a combination of feature releases and rambling tangents about the old days of the internet.\nThis is more for me than you, so I’ll point out any particular post which I think is worth a read.\n\nHello, World! (Week 1) – launched with 26 open jobs at 8 startups \nThe time and the place (Week 2) – includes the old school “NEW” badge\nA new Suggested Tweet button (Week 3)\nGetting the word out, automation, and a request for ideas (Week 4)\nCompound interest (Week 5) – I talk a lot about compound interest when I’m advising startups, and it gets a brief mention here\nMore informative tweets (Week 6)\nIn which the sync code is tediously yet necessarily rewritten for little gain (Week 7)– there’s a stat in week 7. The number of applicant tracking systems that JG can talk to is: 4. Today that number is (checks code) 20.\nA look behind the scenes at the new settings screens (Week 8)\nAll products should have a demo mode (Week 9) – all products should have a demo mode!\nMaking the job board more useful by focusing it on a single city, in this case London (Week 10)\nHear about new jobs by email, with watchlists (Week 11)\n\nUntil this point, Job Garden was personal: just a place for me to share jobs at companies I’m connected with in some way (i.e. that I’ve invested in either personally or more likely via R/GA Ventures, or ones I advise, or they’re run by mates).\nNow, as an experiment, since a few others had asked if they could also use Job Garden, I started opening it up a bit.\nBut still very much a hobby. That’s one of the things I like about Job Garden: it’s well within my comfort zone to build and design, so as a hobby it’s perfect because it’s about craft and doing things “properly”… and whether that means “100% working” or “opinionated” I’ll leave open.\n\nThe number of job boards has doubled! Meaning, there are now two of us (Week 12)\nNew homepage (Week 13)\nSo it’s been three months since launch (Week 14) – it’s worth reading this because (a) it has a small retrospective in which I decide to carry on building the thing; and, (b) it has some thoughts about scaling including Quantity has a quality all its own which is a quote you really shouldn’t use because it’s from Joseph Stalin\nClosed this week (Week 15) - one of many references to the ancient internet, this one is about Newspaper Club’s summer holidays\n\nHere’s a post in its own section because it still gets a bunch of traffic. So maybe you would like to read it too?\n\nA pre-history of weeknotes, plus why I write them and perhaps why you should too (Week 16)\n\nThese next few months feel like their own chapter… adding a few more friends to garden their own job boards, and the general data and design improvements required in consequence:\n\nInvisible work (Week 17) - on the various types of invisible work\nArgh admin tools (Week 18) - on how to learn to juggle\nSome nerdy screenshots to prove that, yes, I’m actually building the admin stuff and not just farting around (Week 19) - on model railways\nA quick update because it’s time for dinner (Week 20)\nConnect Ventures’ entire portfolio is now on Job Garden, plus what I’ll work on next (Week 21) - on gradualism and, a favourite principle, how to cross the river by feeling the stones\nNo-op (Week 22)\nIt’s amazing it’s taken so long: pagination (Week 23) - huh, there’s a line:  A small improvement, but big improvements are made out of small improvements a thousand times. I’m pretty obsessed with this compound interest thing it turns out\nA new job board, and dealing with maintenance (Week 24)\nWelcome C4 Ventures (Week 25)\nWelcome Downing Ventures! (Week 26)\nModerate progress on adding location search, and how to approach insurmountable tasks (Week 27) - on various ways to do impossible things. Also, trust your boots\nContinued progress on location search, and some technical bits and bobs (Week 28) - The material will tell you what it wants to do.\nNew: find jobs by country and city (Week 29)\nMore useful email alerts, and a survey (Week 30)\nA new font, removing a feature, and thoughts on achieving design clarity (Week 31) - on three ways to achieve clarity\nNew arrivals (Week 33)\n\nAh, and at this point Stella was born. So everything stopped until week 50.\nThat 17 week period - four and a bit months - was interesting (baby aside, which of course is interesting and joyful and awesome and all kinds of superlatives, but I’m talking about JG here) because it gave me room to think about Job Garden. And remember it’s still a hobby at this point!\nComing into 2019, a handful of my users got in touch and asked for additional features. So I looked at what I’d built and I thought: it’s rare that you make something that does a valuable thing and also people want to use it enough that they’re requesting features. Then I thought: I should take this more seriously.\nSo the chapter that follows is the chapter of: work on Job Garden enough that I can tell whether or not to take it seriously.\nI’m not on JG full time. I’m working on other things too. I get up at 6 and work on Job Garden then, and I work at night after the family have gone to bed. During the day I often work on JG but I also have other gigs, and I’m a parent too, and the parent bit gets priority.\nPerhaps there’s something commercial in Job Garden that doesn’t compromise the value it provides to the startups I care about (that’s one of our overriding principles. We’ve got 12.). Perhaps not, and if there’s not then the worst thing that will happen is that we’ve built something good.\nThe goal for this year is to figure out whether there is something commercial and uncompromising there. If that’s the case, I’ll take JG seriously at that point.\nSo the rest of the weeknotes (till now, I guess) are in that chapter.\nThey are also less frequent, and seem to be more about feature releases although of course with regular tangents. Here:\n\nBack in the saddle, what’s been going on, and… hire #1 (Week 50) - big moment this, beginning to work with Phil Gyford\nWork in progress: showing background data on companies to help job seekers. Also, owls (Week 51)- some good infographics and a glorious owl-based pun in this one\nColourful profile images, company descriptions, and more ways to keep an eye on jobs, all launching today for our first birthday (Week 53)\nNew today: watchlists just for your city and old-school RSS too, plus a thought about kaizen (Week 55) - on kaizen, and building systems which are amenable to kaizen\nHere’s the new design that will see us through the rest of 2019 (Week 59) - includes a nice GIF showing design evolution since week 1. This is why you should screenshot your site periodically\nUsing statistical inference to let you find jobs in design, engineering, sales, and more: autotagging is now live (Week 60) - on writing for the web\n\nThat brings us up to date.\nReading all these weeknotes back, just now, it also feels like the end of a chapter, or at least a subchapter: having shipped autotags and the new design, Job Garden basically represents what was in my head pre week 1. Sure there needs to be more data on which to pivot, and more ways to receive alerts about new jobs, etc, and there is a ton to do around that, but that’s all just a matter of colouring between the lines.\nI feel like now everything’s on the table; the basic Lego bricks have been made; the frame has been created. So it’s time to figure out what to do with those pieces, and the motivations for what to prioritise from the roadmap (which is big believe me) will be different from what they’ve been so far.\nWhich means year 2 will feel different. Exactly how I’ll have to see in next year’s retrospective.\n",
    link: "/home/2019/05/10/the_new_forest",
  },
  {
    title: "Meat and gratitude",
    date: "07.30, Thursday 6 Jun 2019",
    content:
      "There’s a bunch of fuss about Beyond Burger rn regarding\n\ningredients - I’d mentally filed Beyond as “healthy plant-based” whereas it’s a ton of bad-for-you vegetable oil and really should be sceptically thought of as “heavily processed”\ncarbon footprint - beef is bad\n\nI’m excited about these new vegan burgers because\n\n“artificial” does not necessarily equal “bad” so I’m in principle ok with the heavily-processed thing (though I’m concerned in how this is being obfuscated)\nthe meat and dairy industry sucks\nyes, carbon footprint: as a society, we need to wean ourselves off things that are killing our planet\nnew flavours, good stuff\n\nBUT: thought experiment:\n\nWould I prefer not to eat heavily processed foods? Yes\nIf the carbon footprint of meat could be reduced to something closer to plant-based burgers, using a combination of reduced frequency of consumption and hand-wavey magic, would that reduce my discomfort? Yes\nIn that situation, would I still eat meat, assuming it came from a source that wasn’t unnecessarily cruel? Yes.\nThe big question: would I still feel uncomfortable about it? Yes.\n\nWhy my remaining discomfort? Because animals are, well, animals. They’re people too. I’ve known a bunch of animals, and we’re all people in different ways. That fact is hard to reconcile with eating them.\nFor me, I do continue to eat meat (although less than I used). But I think a lot of my discomfort around it - environmentally, the agro-industry, health - is displacement from the hard-to-digest fact that, when I’ve met a cow, they’re super nice to hang out with, and I could see us being friends. And that feeling isn’t going to go away.\nI have a hunch that our inability to deal with the immensity of this gift - this animal-person who has been killed so I can have my dinner - means that, either deep down or out loud, we end up denying there’s a gift or any kind of trade-off at all, hence the tribalism, and lack of sensible discussion, around the adjacent topics of health, carbon, and so on.\nOr, to put it another way\nThe slip-sliding and dissembling around health benefits/carbon/etc makes me think that a bigger issue is being psychologically avoided. And for me, maybe that issue is “meat tastes great” vs “holy shit animals are people too” which is so hard to reconcile that it gets repressed, and repressed feelings come out in weird ways.\nSo here’s my solution, because without addressing the core matter of co-personhood, nothing else will work\nI like that being vegan is a movement, in a way that being vegetarian was a movement in the 1980s, or Atkins in the early 2000s. These are lifestyle choices that bring alignment with the body and the planet by promoting practice changes and introducing a new kind of mindfulness.\nCould there be a similar movement that embraces some of the logic behind the Beyond Burger, but also includes meat?\nHere’s my suggestion:\n\na selective diet that is vegetarian except it allows meat when that meat is from a known local source, farmed with care, and not consumed with great frequency\nwhen such meat is eaten, a prayer of gratitude is said to the animal\n\nI am a big believer in vocalised gratitude as a means towards mindfulness, but mainly towards being able to accept the weight, meaning, obligation, and reciprocity of a gift.\nOnce gratitude is internalised and the gift of sacrifice is accepted, I’ve a feeling that the rest will fall into place. In short: a more balanced relationship between the food we need to live as individuals, and the planet we need to live together.\nOk so this is just saying grace. But oriented towards the animal.\nI wonder if there could be a single phrase which expresses gratitude for the gift?\nAnd something, unlike the traditional and passive For what we are about to receive…, that acknowledges my actions and choices that have brought about this meal of meat and all that it required? Said out loud, it would promote discussion and maybe even spread…\nGrativore!\n",
    link: "/home/2019/06/05/one_year_of_job_garden_weeknotes",
  },
  {
    title: "Midnight Poem by Sappho",
    date: "19.33, Tuesday 2 Jul 2019",
    content:
      "\nTonight I’ve watched\nThe moon and then\nthe Pleiades\ngo down\nThe night is now\nhalf-gone; youth\ngoes; I am\nin bed alone\n\nI don’t know much - really anything - by or about Sappho. Except this, a fragment of the Midnight Poem, and in particular this translation by Mary Barnard, which was the subject of a blog post by Clive Thompson from 2016 (that link to Internet Archive): In a mere eight lines, she paints the melancholy of middle age onto the canvas of the night sky.\nIt’s beautiful. The blog post is only available in the Archive now, and the translation isn’t available online except as a photograph which is a broken image in that blog post, so I’ve transcribed it here so I’ve got it to come back to.\nIn that post, Thompson describes a recently published astronomy paper:\nThe Pleiades (which is that tight box of stars which I recognise but I’m rubbish at names; by Aldebaran) - says the paper - were visible, in 570 BC around the time the poem was written, at the appointed time which is before midnight, between 25 January and 5 April.\nI can imagine how I feel at that time of night, at that time of year. No artificial light of course, or not much anyway. No stultifying heat. I haven’t slept yet, so it’s not in that witching hour before second sleep. But I’m awake and gazing at the sky, long enough that I can see the stars move.\nIt brings me closer to Sappho. The eyes of science as an empathy machine.\n",
    link: "/home/2019/06/06/grativore",
  },
  {
    title:
      "A lengthy ramble through many responses to that FaceTime Attention Correction tweet",
    date: "17.35, Thursday 4 Jul 2019",
    content:
      "The latest beta of iOS 13 came out, and there’s a feature called FaceTime Attention Correction which, on video calls, silently manipulates the image of your face so that you’re looking the other person directly in the eye. Which on first blush to me sounded cool (eye contact is good! Maybe?) but on further thought made me do a weird face.\n(Currently the camera and the screen are slightly offset, so even when you’re looking at the picture of the other person, the camera sees your eyes as looking slightly away — and so they see you as looking slightly away.)\nSo I tweeted about the new feature with some hyperbole:  Whoa. iOS 13 will ARTIFICIALLY RE-POINT YOUR EYEBALLS in video calls so you’re looking right at the other person instead of where you’re actually looking, which is the screen. Hey Apple, so long as we’re doing this, how about fixing my hair and maybe also the bags under my eyes — which is how you have to talk now to get RTs. (As at this moment: 140 retweets and 383 likes.)\nSome responses and my thoughts follow:\nJ. Rosembaum:\n\nThis is kind of amazing and I think it is really well done,\nBut as an autistic person I also find it discomfiting. One of the reasons I like video calls is that there is no expectation to meet the other persons eye.\n\nThis was one of several responses from an autistic perspective, and the concern really resonates with me. Phones have become pretty much mandatory at this point to participate in society, and for them to subtly prefer a particular model of self — that’s all kinds of problematic.\nI very much do not want to live in a world which discriminates against or erases different ways of being.\nMary Hamilton:\n\nFrom an autistic perspective, this is just a whole deeply visceral world of “nope”.\nPlease do not edit my online communication style to make it more neurotypical, I already have to do that enough in meatspace, thanks\n\nConsent is another issue: sure “Attention Correction” is a setting you can turn on and off, but if everyone does it, will it really be an option?\nAnd what about the consent of the other? Is there an icon to show that they’re speaking with an “attention corrected” person, or one that has their hair computationally styled, or their voice enhanced to sound more persuasive? Etc.\nRebecca Reeve Henderson:\n\nYou know Zoom has a pretty filter? Your skin will look dewy fresh.\n\n(Zoom being the business world’s new hotness in terms of video conferencing. Which is fair because it’s great.)\nIt’s important to remember that Attention Correction exists on a spectrum of image correction. But the Zoom pretty filter came as a surprise to me — I’m pretty sure I knew about it once, but it hadn’t seemed important enough to remember.\nSo perhaps what’s happened is I had mentally categorised video calls as a whole as “unmediated” and Attention Correction is reminding me that it they are very much mediated — more fool me for forgetting I guess — and we will have to develop personal skills and social norms to tell authentic and inauthentic apart?\nWe’ve gone through this process in, for example, email: “real” emails are text only, from our friends, don’t have a sig. “Unreal” emails use placeholder names, sales-y language, graphics, have an unsubscribe footer, etc. Our expectations for “real” include polite correspondence, turn-taking, no hidden agenda, for example. When these categories are violated, such as the recent fuss regarding the highly funded Superhuman email client which includes hidden tracking images, i.e. applying standard “unreal” email norms to “real” email conversations, outrage results.\nWe have similar tells — some enforced by regulation, and some that we develop through critical thinking — with TV. There’s a difference between programming and adverts, for example. In programming, there’s a difference between fiction and reality TV. And even with reality TV, we have language to discuss and understand exactly how real it is. What’s that phrase? Structured reality.\nSo from this perspective, maybe what Attention Correction represents is that this kind of mediation of realtime video is inevitable, and what we need is enough cues and tells and shared language to build up our categorisation instincts.\nSeb Potter:\n\nPrediction: within 3 years you won’t even need the camera to make video calls.\n\nEnough training to match my intonation to the expressions of my Memoji, and yes — all the pieces are there.\nTom Stuart:\n\nIn case you’re interested, gaze correction has been a long-running project for Microsoft Research, e.g. link\n\nI hadn’t seen the particular research Tom points out, but because of my digging around Glancing back in the day, I have folders full of papers about computers and gaze…\nOne paper that particularly comes to mind is Ishii and Minoru (1992), ClearBoard: A Seamless Medium for Shared Drawing and Conversation with Eye Contact, CHI ’92. In this work, two collaborators were linked over a shared screen and a video conference. The video call was presented, translucent, overlaid on the shared desktop screen and applications, and reflected.\nThe result being that you can see where the other person is looking at on the desktop, and they can see where you’re looking too: that is, when they look at a picture on their version of the shared desktop, their gaze on your desktop points at the very same picture. And in the study, this greatly improved ability to work together.\nFrom the paper:\n\nThe importance of eye-contact is often discussed in the design of face-to-face communication tools, However, we believe the concept of gaze awareness is more generalized and is a more important notion. Gaze awareness lets a user know what the partner is looking at, the user’s face or anything else on the shared workspace. If the partner is looking at you, you can know it. If the partner is gazing at an object in the shared workspace, you can know what the object is. Eye contact can be seen as just a special case of gaze awareness.\nWe think the notion of gaze awareness will be an important goal of the next generation of shared drawing tools. It can not be easily obtained in conventional meeting environments, and only CSCW [Computer Supported Cooperative Work] technology can provide it.\n\nThere is a ton of research into the gaze from the time, and — like the term CSCW itself — we’ve lost momentum bringing this into the user interface. We’re still in the era of the Personal Computer. The “collaborative” aspect of computing remains (to me) only a thin veneer on the PC. And the challenges we face in the future will only be met by working together…\nIt’s not just work, it’s all kinds of communication. In real world groups, gaze is used to request priority or give way. Visibility of the gaze of others directs group attention (another recently under-studied area).\nSo I’m excited because it feels like we’re opening up collaboration, gaze awareness, and group attention once more.\nHowever: I’m uncomfortable with the re-writing of the gaze as performed by the Attention Correction feature. I would feel considerably happier about it if there was a camera behind the screen so the result was meaningful gaze awareness without the post-truth undermining of “real” video. \nDespite my discomfort… the possibilities of eye contact in video! I would love to see a simplified reimplementation of ClearBoard from that paper, only using FaceTime. For example, could two people have a shared space as if we were both drawing on the glass window of the screen? This would work incredibly well on the screen of the iPad.\nOr… Could we make a translucent FaceTime call, to allow for gaze awareness, and overlay on it a Google Doc, so we could discuss paragraphs with the non-verbal cues of the gaze, and avoid stepping on each others toes with those multiple edit cursors by watching each other’s eyes? Would collaboration be more effective? I bet it would. Apple, Google, give me a call…\nStian Westlake:\n\nUnpopular opinion: Every little hack like this is getting us a bit closer to the (long-predicted, now largely derided) Death of Distance - which will have enormously positive effects on the economy and society when it finally happens.\n\nPositive statements like this were relatively rare in the responses to my tweet. And while I share the sentiment… the implementation and context give me equal concern.\nRachel Coldicutt:\n\nThis feels like a nope. Why should my phone decide where I should be looking? Auto-correct for facial expressions is a whole new weird world of darkness. (And maybe where the animoji training data has been going?)\nOh … I mean, is this actually deep fake as a product?\nQuite a few people (men FWIW) have replied to this to say it doesn’t seem creepy to them, but the first rule of “is this creepy?” is not “Do this seem creepy to ME?” but “Does this seem creepy to someone with less power or status or more vulnerability than me?”\n\nRachel Coldicutt’s response sums it up for me. Auto-correct for facial expressions is Attention Correction is a nutshell. Not only because auto-correct has both positive and negative consequences, but also because — in this case — an idea of “correctness” in face-to-face communication is invented, and the idea that there is or should be “correctness” here is something I would push back on very strongly.\nColdicutt’s final point, which is to bring in power, is the most important point in all of this: looking through the lens of power is where discussion of this feature should begin and end.\nAnd so my question is this:\nsince the category of “unreal” (deep fake, fictional, mediated) video is here to stay, and only going to grow, and knowing that gaze awareness is important and, yes, something that should be available to design with; listening to the many concerns and always sensitive to the dynamics of power and vulnerability; how could Apple present this Attention Correction feature differently today (it may be nothing more than displaying an icon on the receiving end) in order to help us develop the best cues and social norms to not only minimise damage, but to best position us for an inclusive, collaborative, technology-positive future?\n",
    link: "/home/2019/07/02/sappho",
  },
  {
    title: "Filtered for sexy animals (headphones required)",
    date: "10.58, Friday 19 Jul 2019",
    content:
      "1.\nOrangina commercials. Watch at least until the forest one. File under “sexy animals.”\nThis message brought to you by today’s trailer for the movie Cats.\n2.\nThe Popular Science Monthly, May 1877, “On the habits of ants” by Sir John Lubbock:\n\nLandois is of [the] opinion that ants also make sounds in the same way [by rubbing their abdominal rings against another], though these sounds are inaudible to us. Our range is, however, after all, very limited, and the universe is probably full of music which we cannot perceive.\n\nEmphasis mine. Source.\n3.\nThe sound of dial-up internet, decoded: what each segment of beeps, ping-pong, and static is doing and what it means.\nAlso: A short video of opera singers dubbed with modem noises.\n4.\nMy life has not been the same since I learnt that famously-silent giraffes are not in fact mute.\nAt midnight, in the pitch black, the neck becomes like a pipe organ, and they do this crazy deep ethereal HUMMING. Not kidding:\nListen to the video embedded here. (And read the paper.)\nAll I can think of is Palaeolithic humans on the African plains, it’s the dead of night, and they’re just bathing in this all-pervasive ASMR-inducing hum, the giraffes’ 14 Hz infrasound skewering the soul, the dark savannah as a nightly cathedral with no walls and for its roof the eternal stars.\n",
    link: "/home/2019/07/04/attention_correction",
  },
  {
    title: "Mwie Ltd",
    date: "10.10, Wednesday 13 Nov 2019",
    content:
      "About three weeks back, fellow traveller Tom Critchlow shared his annual notes on being an independent consultant: 5 years on the road: Thoughts on sustainable independence.\nAnd: coincidence! I work via a consultancy vehicle called Mwie Ltd. I am its sole employee. Mwie was incorporated in October 2014 and issued its first invoice in November  2014, so that also puts me 5 years on the job. Happy work anniversary, I guess (which is absolutely not a thing although LinkedIn insists it is).\nInspired by Tom, I started writing a blog post retrospective. What I’ve been doing, what some highlights have been, etc.\nWhat I’d like to do more of.\nWhat’s missing.\nWhat am I any good at.\nOh my god where is it all going anyway.\nOk so (a) I shouldn’t have tried to write to write a retrospective on my own on a Friday night; and (b) wow it got way too personal, there’s no way I’m sharing it.\nThe thing is that for the past five years, I haven’t been talking about what I’m up to, and there hasn’t been a plan. My strategy has been\n\ntalk with interesting people about what I’m interested in\ndon’t chase too hard: allow as much time as necessary for win-win situations to make themselves obvious\nonly do interesting, stimulating work — but never just because I need it for the cash or positioning (granted, it’s privilege to be able to be choosey like this, but I’ve previously worked to earn that)\nno marketing except word of mouth: marketing can’t abide complexity. Crafting a message that will carry, any message, requires reifying my practice and I haven’t been ready to do that.\n\nThat last point all about what we’d call in other contexts product-market fit. That hyphen is an arrow of influence that points both ways.\nMarketing requires a view on what the market finds valuable; what will resonate. In my case, how clients will find and understand business value. Not only have I lacked up-to-date knowledge of what value I, personally, can unlock, but prematurely working on marketing will shape the product before it’s ready.\nAnd what is the “product” here? Well it’s me, my practice — it’s some overlap of what I find stimulating, what I’m good at, and what helps me get future work which is the same but better. But can I articulate that? Not a chance.\nSo if I look at the last five years, the strategy has been\n\nfollow my nose\ndiscover what I want, because I can’t articulate it\ndiscover what the market wants, because I don’t know.\n\nIf it sounds like I’m starting from the ground floor here, I guess it’s because I am. BERG (the design consultancy turned tech startup I co-founded) shut its doors in 2014, and I carried on working on various loose ends well into 2015. My “voice”, needs, patter, platform, and intellectual interests had been mixed with the studio, in one incarnation or another, for 10 years. It’s… confusing. Moreover, I had been surrounded by some of the most talented, unique individuals I have ever met — and one of the jobs of a CEO is to do only what can’t be done by others.\nAll of which means I came into my current five year stint as “Independent Consultant” (according to my LinkedIn) with very little real idea of what I was good at and what I wanted out of my work. And, if I’m honest, a bit afraid that the expectations of others — potential clients — would shape my practice into what they needed and thought I could offer, before I could figure that out for myself.\nLet’s call it product discovery and market discovery. Business-speak as camouflage for feelings.\nI wish I could find the source of this quote. I remember reading Kevin Kelly relating something he heard from his mentor Stewart Brand:\nWe have time for three 15 year careers. In each career, you’ve got five years to learn and work your way into it. Then five years to do it as well as you can. Finally you have five years where you can offer a new spin from your own individual perspective.\nI think about this period I’m in as my second career. I’ve been in no hurry to figure out what it is.\nBut… five years in. Maybe it’s time to finish the discovery chapter and focus on execution for a bit.\nWhere were we? Oh yes, Friday night a little over two weeks back. On my own at the kitchen table with my laptop and a class of red, writing a career  retrospective that was rapidly devolving into a career existential crisis.\nHere’s what I did.\n\nI wrote down everything I would regard as a career highlight from the past five years, and looked to find themes.\nThen I went back to looked at extracurricular activities from the past five years. I’ve always got a side-project or two. Well, I decided, if they fit into one of my themes, they’re retrospectively now a work project.\nI listed everything that I felt was missing. What do I wish I had done more of?\nAnd then, at the end, there is this section: If I met me, and was advising me on what to do, this is what I would say: — and after answering that title I went to bed.\n\nBefore I go into the results of that personal career review, it’s worth saying why I separate myself from my consultancy, Mwie Ltd, even though the two are often the same.\n\nIt’s practical and means I can work with bigger clients. Incorporating means I can safely subcontract (which I’ve done frequently for clients) and relate to companies on the basis of product supplied rather than hours done.\nI can invest in assets. Through Mwie Ltd I have run a bookshop in a vending machine, and I’m building Job Garden. Both cost money. But because they stick to the consultancy, even if they don’t wash their face by their own account, they can be worth it for the marketing, creds, or capabilities benefits.\nSeparating the company bank account from my own provides a psychic buffer. For years I’ve paid myself a regular monthly salary. Company revenue goes up and down. Clients sometimes pay late. Sometimes there’s a good month and the company looks flush. But so long as there’s a six month runway in the bank, none of that affects my sleep.\n\nYou get what you do. Or rather, you get what others see that you do.\nIt’s funny. Jack and I gave an interview to the Daily Telegraph business section (I’m not even kidding) way back in 2007. I just went back and read it, and the advice in that article is exactly what I had to remind myself about that Friday night. Here’s the article:\n\n“We started turning down work,” says Webb, describing the duo’s slightly different approach to building a fledgling business. But Schulze and Webb had an unusual problem - when they spoke to potential customers they would get offers to design websites or graphic material. But that wasn’t what they meant by “design”. “Bits of plastic and microcontrollers,” says Webb, “the future world of products.” These were the things that excited them.\nFriends advised two strategies. One: find a way to communicate to people what you do in language they can use with others (such as their bosses). Two: make things that encapsulate the kind of work you want to do and hope people discover them.\n\nAnd at the end of the article:\n\nDo: Start with the smallest thing that’ll work. The learning you get from ‘doing’ is huge, it gives you pace, and big plans are always bigger than they look from the outside.\nDon’t: Take work only for the money. You get what you do, so work that makes you unhappy is not progressive. And it’s better to structure the business so you don’t need the cash than take work that kills the opportunity of much better work.\n\nBloody hell. Thank you very much Jack-and-me-from-2007.\nMy personal career review includes some course-correction points.\n\nI’m not doing enough public speaking of the sort that I enjoy — I feel I’ve lost touch with my tribe, and I miss that.\nAnd while the function of the work I’m doing is rewarding, and I enjoy and I’m good at it… I’m missing the opportunity to chase down intellectual avenues which — because of my individual perspective — fascinate me and I believe are important. I have a list of these.\nI also have a couple of points which boil down to: this isn’t the consultancy, but do more of it!\n\nI’m not going to share details on the above points if that’s ok.\nMainly, and this is what surprised me, when I looked back over five years of projects\n\nthere are indeed themes!\nthe kind of value I can offer and enjoy is supported by credible previous work!\nI have opinions about the industry that I’m in, and what should be done better and differently!\nI would like to do more of those things!\n\nNone of this was necessarily going to be the case. So, good news.\nYou get what you do.\nLong story short, I redesigned my website. Between other things that took two weeks and I put it live yesterday.\nI thought about renaming. But switching away from Mwie Ltd felt like it would be inauthentic — it is just me, after all, operating as a limited company, and I have no intention of building it into another agency. Been there, done that.\nSecret origin: “Mwie” stands for Matt Webb Import/Export because when I was a kid, visiting family in Nairobi, we would pass all kinds of import/export businesses and I still remember them as exotic and mysterious. I always wanted one of my own. And so.\nYet Mwie is a dumb name. So in the spirit of celebrating that which binds us, I figured I would lean in and put the expanded version on the homepage too.\nActually writing the case studies was pretty simple. This isn’t a launch of a new offer. There’s nothing aspirational here, and no new positioning. All I’m doing — very incrementally — is reinforcing existing word of mouth marketing by stating exactly what I already say in person.\nSo I just wrote down how I already talk about my projects.\nPutting them in one place, and grouping them: that’s new.\nOh, and the design. I get my hands dirty with web design every year or two. It’s fun, although of course now I can’t see anything except what I think is wrong with it.\nHere’s a screen grab of the old mwie.com website from November 2019. Single page. Useful mainly for the boilerplate which shows the company registration number.\nHere’s the new one:\nMwie Ltd: Matt Webb Import/Export, est. 2014.\nAs always, I’m up for hearing your thoughts. There’s a contact page on the other side of that hyperlink should you wish to get in touch.\n",
    link: "/home/2019/07/19/filtered_for_sexy_animals",
  },
  {
    title: "Filtered for music and history",
    date: "13.35, Tuesday 2 Jan 2018",
    content:
      "1.\nMechanical Techno machine:\n\nCut-up records on turntables stand in for samples and synths. Electrical contacts produce buzzes of sound as wires touch copper. Cowbells become kinetic, robotic sculptural elements. Basically, every rhythmic element is mapped into physical space, into locations on discs.\n\nAlso: Wintergatan’s Marble Machine which is a mechanical musical instrument using 2000 marbles.\nAlso, my friend Tom Armitage has released an album and it is excellent. Listen: Between the Years, by Telechir. Equal parts live recordings and arranged work, for piano and/or electronics.\n2.\nFor 40 million years, trees were not biodegradable.\n\n430 million years before present, the first vascular plants emerged from early tide pools. In order to stay upright, these plants employed cellulose, a chain of simple sugars … it was easy to make and offered rigid yet flexible support\n\nThis is from How Fungi Saved the World.\n90 million years later, heralding the Carboniferous period,\n\nplants developed a new kind of support material, called lignin. Lignin was an improvement development over cellulose in several ways: it was harder, more rigid, and, being more complex, almost impossible to digest, which made it ideal for protecting cellulose. With lignin, plants could make wood, and it lead to the first treelike growth form.\n\nBut lignin made the lycopod trees a little too successful. Because their leaves were lofted above many herbivores and their trunks were made inedible by lignin, lycopods were virtually impervious to harm.\nDead trees piled up without decomposing. Compacted by weight, they turned to peat and then to coal. 90% of all today’s coal is from this period.\nWood pollution lasted 40 million years.\n\nFinally, however, a fungus belonging to the class Agaricomycetes - making it a distant cousin of button mushrooms - did find a crude way to break down lignin. Rather than devise an enzyme to unstitch the lignin molecule, however, it was forced to adapt a more direct strategy. Using a class of enyzmes called peroxidases, the fungus bombarded the wood with highly reactive oxygen molecules, in much the same way one might untie a knot using a flamethrower. This strategy reduced the wood to a carbohydrate-rich slurry from which the fungus could slurp up the edible cellulose.\n\nWhich leads me to think:\nThere’s a ton of plastic in the ocean. Why not engineer a fungus to rot it? Having this magical material that lasts forever is absurd. This is a controversial idea I admit. But although I agree that we need to reduce plastic pollution (via social change and by regulatory intervention), cybernetics tells me that’s a fragile solution. Homeostasis is to be found in a ecosystem of checks and balances: instead of eternal plastic, we need plastic plus a plastic-rotting fungus plus an effective-but-hard-to-apply fungicide. Then balance can be found.\n3.\nAncient Greek statues dressed in modern clothes.\nSeveral images.\n4.\nFrom 1878, here’s a photo of Billy the Kid playing croquet.\nIt is only the second photo ever to be confirmed of the infamous outlaw and the only known photo of Billy the Kid with his gang, The Regulators. (They’re all playing.)\nHere’s a thing:\n\nCroquet became popular in the 1860s because it was the first sport that women could play on the same terms as men, and men and women could play each other\n\nHuh.\nRelated:\nBilly the Kid and his gang were the subject of the film Young Guns (1988). A quote from this film was sampled and opens the classic Regulate ft. Nate Dogg, by Warren G (1994).\nPlease refamiliarise yourself with the lyrics.\nNow follow @GerryMcBride taking a Google Maps journey through Long Beach as described in the song. Seriously, do this thing.\n",
    link: "/home/2019/11/13/mwie",
  },
  {
    title: "Fave 10 books from 2017",
    date: "12.13, Wednesday 3 Jan 2018",
    content:
      "I only read 23 books in 2017. (31 in 2016; 42 in 2015.)\nMy favourite 10:\nSPQR: A History of Ancient Rome, Mary Beard. I’ve been getting interested in Ancient Rome, thanks mainly to Dan Carlin’s Hardcore History podcast – in particular the series Death Throes of the Republic and the episodes on the Punic Wars. Beard has broadened my awareness to the social. The grand sweep of time - and the fact we’re all still Roman in so many ways - makes this fascinating.\nFour Futures: Life After Capitalism, Peter Frase. This book looks at two macro trends: abundance (via A.I. and automation) and scarcity (climate change). To see how these interact, Frase reintroduces the term class, built from first principles from the logics of capitalism and group allegiance. A vital term to navigate the late 2010s. Bonus: his four futures are illustrated with science fiction from books and movies.\nRadical Technologies, Adam Greenfield. The first nine chapters are worth it in their own right, deconstructing technologies and asking the question: is the trade-off worth it. They serve to equip you for the barrage in the second half of the eponymous 10th chapter – escape velocity ideas told with beautiful, luminous words.\nWolf Hall, Hilary Mantel. I’m late to Mantel’s semi-fictionalised story of Thomas Cromwell’s rise and fall (chief minister to Henry VIII and driving force of the English Reformation). The TV series is startlingly good: Mark Rylance is the embodiment of still waters running deep. It’s the only TV that comes close to the 1979 BBC adaptation of Tinker, Taylor, Soldier, Spy with Alec Guinness. Like the TV series, the books - for complexity, legibility, and a gentle but relentless pace - do not disappoint. This is the first of a trilogy; the third is out in 2019. I’m reading the second now.\nThe Control of Nature, John McPhee. Nobody writes about nature like McPhee. He narrates complex tangles of people, history, fire, and water – highly situated (the Mississippi, a volcanic eruption in Iceland, and an L.A. fire) but moving between the particular and general. Not my favourite by McPhee (that would either be his four volume Annals of the Former World for its weight and scope, or Encounters with the Archdruid for its humanity) but his deft sentences and ability to draw pictures are always a treat.\nNeutron Star (collection), Larry Niven. I read a bunch of sci-fi. This year I’ve been enjoying collections of short stories all told within the same universe: it’s neat to see an author explore ideas and consequences from a ton of different angles, and the the whole feels a lot bigger inside my head because of that. I’ve somehow missed reading into Niven’s Known Space future history so far. He’s got big ideas, and some cracking yarns. Great storyteller.\nHow Not to Network a Nation: The Uneasy History of the Soviet Internet, Benjamin Peters. Why didn’t the Soviet Union build its own internet? The argument in From Newspeak to Cyberspeak (Slava Gerovitch) is that the political insistence on materialism stripped cybernetics (and therefore computing research) of metaphorical yet inspirational ideas like “memory” and “learning”, constraining the vision of computing to simple calculation. Through detailed examination, Peters instead puts the blame on bureaucracy. Some interesting lessons here for institutions adopting (or not) new technologies.\n(Peters has also shifted my attention from our familiar dichotomy of public vs private enterprise - that is, the state vs the individual - to polis vs oikos. When the state is, in parts, captured by private interests, it makes more sense to look at the two ends of the spectrum being the national community (polis) vs the household, or your flesh and blood (oikos). It’s stuck in my head; worth thinking about more.)\nThe Good Immigrant, edited by Nikesh Shukla. What does it mean to be black, Asian, another ethnic group, or mixed in Britain? An immigrant or born here; in a race-based community or not; recognised or not? What do expectations from yourself and others feel like; what is identity. Here are 21 personal stories from different authors. Mind-expanding, thought provoking, intelligent, empathy-building, and it gets you in your heart – not least because of my own story. A side note: I hope that this British perspective on race can contribute to an unpacking (and a reckoning) of our repressed memories of colonialism. This poisonous history is all the more poisonous for not being aired.\nPlatform Capitalism, Nick Srnicek. A look at the dominant technology platforms - Apple, Google, etc - not through the lens of technology as something new, but from the perspective of capitalism. Srnicek makes it possible to see that Uber’s platform approach doesn’t have any legs (it’s just about exploiting labour, nothing new there) but that data extraction and processing does imply labour, and can help explain the weird adjacencies in the platform business models (e.g. why Google would get in such different businesses as advertising, email, virtual reality glasses and hardware.) This framing supports the view that data is the new oil.\nOne complaint: Platform Capitalism feels an introduction, like it’s defining terms for a much bigger argument. And one misgiving: Srnicek says that social interactions cannot be seen as labour as (I paraphrase) they are not competitive. I disagree as online - whether on Twitter, LinkedIn, Instagram, or a dating app - per Zygmunt Bauman’s Consuming Life, we are marketing ourselves and competing for attention, such attention making ourselves more marketable. Given this misgiving, I don’t know how stable Srnicek’s set of ideas is as a foundation for debate. Stimulating none-the-less.\nLiving Dolls: A Magical History of the Quest for Mechanical Life, Gaby Wood. A series of interlocking essays on the history of automata from the construction of mechanical people and simulated animals, to Edison’s recording of the human voice and the early history of cinema in France. What Wood does is focus on the individuals, the movement of ideas and artefacts, and the historical context.\n",
    link: "/home/2018/01/02/filtered",
  },
  {
    title: "Filtered for nice turns of phrase",
    date: "13.46, Wednesday 10 Jan 2018",
    content:
      "1.\nHow to award the contracts to run the overground railways in London:\n\nRisk is like a balloon with a price tag attached to it\n\nNice turn of phrase.\n2.\nPCalc is a calculator app, and it’s 25 years old. From the announcement of the original version, in 1992:\n\nEnclosed is a binhex file containing a submission for your archives.\nPCalc is a neat simulation of a programmable scientific calculator.\n\nA simulation of a calculator! Now simply a calculator. Since the 90s, software has become part of the real world. The virtual no longer exists.\n3.\nI like words and I like how they change. I like that sometimes everyone is using a particular word or phrase for a year or two, but look at the word closely and you’ll see how weird it really is. Or there are some new words that are weird now, but I know they will be commonplace in the future.\nI keep a list of words on Twitter.\n4.\nFrom Rolling Stone’s coverage of the unveiling of Magic Leap, the (potentially) groundbreaking augmented reality device:\n\n“You’re basically creating the visual world,” he says. “You’re really co-creating it with this massive visual signal which we call the dynamic analog light field signal. That is sort of our term for the totality of the photon wavefront and particle light field everywhere in the universe. It’s like this gigantic ocean; it’s everywhere. It’s an infinite signal and it contains a massive amount of information.”\n\nBeautiful nonsense.\n",
    link: "/home/2018/01/03/2017_books",
  },
  {
    title: "Filtered for recent computer exploits",
    date: "10.54, Tuesday 16 Jan 2018",
    content:
      "1.\nRecents hacks are about finding holes in the deep physics of computing.\nHere’s a technical explanation of Spectre and Meltdown, the two recent big ones. The words alone are beautiful: Spectre can be thought of as a (previously unknown) fundamental risk of speculative execution, one that can now be weaponized.\nHere’s a metaphor explaining both exploits, to do with librarians. In short, they involve measuring how long it takes for the computer to look up hidden data. Even if the data is eventually not shared, the computer has a terrible poker face.\nI see this as a kind of information asymmetry. Computer chip architecture is about the regulated control of information. The design never anticipated that unregulated information - time - would be brought in from the outside.\nSee also: Rowhammer, which is an exploit of how memory chips work  where the wild information, intruding from the outer reality, is electromagnetism and geography.\n\nAs DRAM manufacturing scales down chip features to smaller physical dimensions, to fit more memory capacity onto a chip, it has become harder to prevent DRAM cells from interacting electrically with each other. As a result, accessing one location in memory can disturb neighbouring locations, causing charge to leak into or out of neighbouring cells. With enough accesses, this can change a cell’s value from 1 to 0 or vice versa.\n\nThat is, the fact that two memory address happen to be physically close to one another is completely outside the computer’s knowledge of itself. Geography and electromagnetism have no presence in the computer’s inner reality. But bring that knowledge in from the outer reality…\nRowhammer was able to use this to induce bit flips … and hence gain read-write access to all of physical memory.\n2.\nLong profile in the New Yorker of Sam Altman, the head of Y Combinator (the incubator behind startups such as Airbnb, Dropbox, Stripe, and reddit).\nThis line:\n\nMany people in Silicon Valley have become obsessed with the simulation hypothesis, the argument that what we experience as reality is in fact fabricated in a computer; two tech billionaires have gone so far as to secretly engage scientists to work on breaking us out of the simulation.\n\nEmphasis mine.\n3.\nHere’s an interesting exploit that I feel should be better known: System Bus Radio.\n\nSome computers are intentionally disconnected from the rest of the world. This includes having their internet, wireless, bluetooth, USB, external file storage and audio capabilities removed. This is called “air gapping”. [However] Even in such a situation, this program can transmit radio.\n\nComputers can now write to memory with a high enough frequency that it’s in the radio spectrum. Now you’re hitting the RAM fast enough, you can play it like a xylophone and carve radio waves into the air.\nThere is demo code provided. And:\n\nRun this using a 2015 model MacBook Air. Then use a Sony STR-K670P radio receiver with the included antenna and tune it to 1580 kHz on AM.\nYou should hear the “Mary Had a Little Lamb” tune playing repeatedly.\n\nSo what happens when my mobile web browser loads an ad that loads some Javascript that reads my bitcoin exchange password and then runs tight array loops that hammer out arpeggios on memory, broadcasting access to all my worldly possessions to anyone standing nearby with a old-fashioned AM radio tuned into 1580 kHz?\nBreaking out of the simulation.\n4.\nBy volume, the Sun produces about the same amount of heat as a reptile.\nAlso the average density of the Sun is 1,410 kg per cubic meter: 1.4x that of water. Or to put it another way, the same as honey.\nSo yeah. The Sun. A million times bigger than the Earth. As hot as a reptile. As thick as honey.\n",
    link: "/home/2018/01/10/filtered",
  },
  {
    title: "Filtered for water in history",
    date: "12.40, Monday 22 Jan 2018",
    content:
      "1.\nIn 2003, the artist Natalie Jeremijenko built a robotic goose.\n\nThe robotic goose interface allows people to approach the birds, follow them closely and interact in a variety of ways that would not otherwise be possible without this interface.\n\nThe remote-controlled, human-haunted goose can speak:\n\nThe goose drivers can ‘talk to’ the geese, issuing utterances through the robotic interface, delivering prerecorded goose ‘words,’ their own vocal impersonations, or other sounds (such as goose flute hunting calls). Each utterance via the robotic goose triggers the camera in the robot’s head to capture 2-4 seconds of video recording the responses of the actual biological geese. These video samples upload to the public web-based goosespeak database that the participants can annotate, i.e. “the goose was telling me to go away,” “he was saying Hi.” As this database of goose responses accretes, redundancy and correlations in the annotations may provide robust semantic descriptors of the library of video clips.\n\nSpeaking to animals not by attempting to translate, but by entering their world.\nHere is a video of Jeremijenko’s project.\nSee also: Umwelt, the semiotic world of the organism, including all the meaningful aspects of the world for any particular organism. A bat will see and inhabit a different world than a human, than a goose, than an artificial intelligence.\nSee also: Timo Arnall’s film Robot readable world, an experiment in found machine-vision footage, exploring the aesthetics of the robot eye.\n2.\nFrom 2007, 3D Mailbox is an email client that visualises your messages as a virtual reality 3D environment.\nThe BBC covered the application, a virtual Miami Beach, a place where your e-mails are represented as bikini clad avatars.\n\nWhen you receive an e-mail the avatars appear at the entrance to the hotel’s pool. Your spam manager acts a gatekeeper, only allowing through genuine messages to lounge by the pool.\nSpam is dispatched to the beach, where they are represented as overweight tourists. Hitting delete results in the spam taking a deadly swim in shark infested waters.\nMeanwhile your unread e-mails perform lengths in the pool. Read e-mails tan themselves on the sun loungers.\n\nThere are pictures.\n3.\nIt used to be, when I went hiking, I’d step across where a stream was marked on a map or mentioned in the guide, and it would be a measly trickle or a torrential river. Well that’s clearly not a stream, I’d think.\nFor me a stream is a permanent feature of the landscape. It’s a constant, regardless of rainfall or time of year. It flows gently and runs in a ditch maybe a metre wide. It is probably clear.\nIt turns out this is rare.\nMy conception of a stream is a chalk stream.\nUnderground chalk acts as an aquifer, and then\n\nBubbling up out of thousands of springs, chalk streams collect first in ponds and then ripple over gravel beds through chalk hills towards the sea. They are typically wide, shallow and crystal clear, their alkaline waters pure thanks to the constant purifying and filtering in the chalk.\nThey are an irreplaceable relic of our past, created as the ice sheets retreated from England 10,000 years ago.\n\nThe temperature remains static.\nAnd:\n\nThere are at least 210 chalk streams in the world, and 160 of those are in England.\n\nIn particular, in the south of England. And in particular, in particular: where I grew up.\nI never realised that my picture of a stream isn’t how most people will think of a stream. Who knew.\n4.\nStafford Beer was the cyberneticist and business management pioneer who, in the early 1970s, built Project Cybersyn for the revolutionary government of Chile. Command economy meets socialist proto-internet.\nIn the early 1960s, he was running a more esoteric experiment, in pursuit of his desire to build an automated factory.\nFrom historian Andrew Pickering’s essay, The Science of the Unknowable: Stafford Beer’s Cybernetic Informatics:\n\nThe T- and V-machines are what we would now call neural nets: the T-machine collects data on the state of the factory and its environment and translates them into meaningful form; the V-machine reverses the operation, issuing com- mands for action in the spaces of buying, production, and selling. Between the T- and V-machines lies the U-machine – the homeostat, or artificial brain – which seeks to find and maintain a balance between the inner and outer conditions of the firm\n\nThe U-machine.\nBy the way,\n\nThe cybernetic factory was not pure theory. By 1960 Beer had at least simulated a cybernetic factory at Templeborough Rolling Mills, a subsidiary of his employer, United Steel\n\nIt is a core tenet of (early) cybernetics that sufficiently complex learning systems are somewhat equivalent, whether they are made of flesh and blood, or vacuum tubes. It is this tenet which allowed the audicity of the cyberneticists to consider building “intelligent” machines, or to model the brain as a network of moving information.\nAnd sure enough, when I went to the library to consult Beer’s collected papers, How Many Grapes Went into the Wine: Stafford Beer on the Art and Science of Holistic Management, Beer discusses the search for his ideal U-machine:\n\na self-organizing system need not have its circuitry designed in detail – otherwise what virtue is there in the self-organizing capability? Furthermore, if systems of this kind are to be used for amplifying intelligence, a fixed circuitry is a liability. Instead we seek a fabric that is inherently self-organizing, on which to superimpose (as a signal on a carrier wave) the particular cybernetic functions that we seek to model\n\nAnd he continues:\n\nDr Gilbert, who had been trying to improve the Euglena cultures, suggested a potent thought. Why not use an entire ecological system, such as a pond?\n\nSo Stafford Beer captures a woodland pond, and attempts to train it to run a factory:\n\nAccordingly, over the past year, I have been conducting experiments with a large tank or pond. The contents of the tank were randomly sampled from ponds in Derbyshire and Surrey. Currently there are a few of the usual creatures visible to the naked eye (Hydra, Cyclops, Daphnia, and a leech); microscopically there is the expected multitude of micro-organisms. In this tank are suspended four lights, the intensities of which can be varied to fine limits. At other points are suspended photocells with amplifying circuits which give them high sensitivity.\n\nThe intention was to communicate information about the factory into the pond via optical couplings. Earlier attempts, reported by Pickering, included attempts to induce small organisms – Daphnia collected from a local pond –to ingest iron filings so that input and output couplings to them could be achieved via magnetic fields.\n\nThe state of this research at the moment is that I tinker with this tank from time to time in the middle of the night.\n\nI have this picture of Beer, in his slippers in his basement, trying to figure out not only how to speak to this tank of water and algae in its own language, but attempting to put it through business school.\nWhat would be the management style of such a factory foreman? Risk averse? A deep sympathy with the principles of sustainability and the circular economy? (Given it sits in a closed-system tank.)\nOur modern efforts into machine learning and artificial intelligence have a familiar feel: we place the neural network at the heart of the system… and just turn it on. And although we can’t tell how the neural network recognises a face or optimises a system, we can tell that they have some natural politics: AIs are unable - or unwilling - to correct for their implicit racism and sexism.\nWhat is the umwelt of a pond? What is the umwelt of an AI?\nUber’s marketplace and Facebook’s newsfeed are run by captured artificial intelligences – unreasonably efficient optimisers, blind to human feelings, natural free market libertarians; a warp core of tremendous ability and held only just in check. We don’t know how these things make their decisions, but we are beginning to see the biases in their actions.\nObviously Stafford Beer’s experiments came to nothing: the factories of China are not run by captured, semi-sentient woodland ponds.\nOr. Who knows. Maybe we should put one in charge of Facebook.\n",
    link: "/home/2018/01/16/filtered",
  },
  {
    title: "Filtered for things to watch",
    date: "10.25, Monday 12 Feb 2018",
    content:
      "1.\nThis incredible 1933 Betty Boop animation from Snow White, to the music of St. James Infirmary Blues.\nWatch it.\nWhat happens when you treat animation as a pure moving visual field, rather than constraining it to representing a physics-compliant 3D simulation.\nBe reminded of: the bit in Dumbo where he gets drunk. Pink Elephants on Parade.  \n2.\nThis video wallpaper, at Moodica.\nMoods ranging from Cityscapes to Satisfying Sorting.\nI’m not sure what I would use these slow videos for, but I would like to find a place in my life for them.\nVersus: Archillect TV. Fast moving video slideshow of GIFs, snippets, and patterns.\n3.\n5 minutes of default Cisco system hold music, set to fast-cut glitchy cyber-era video.\nSee also: Mark Leckey’s GreenScreenRefrigerator, Part 1. A black Samsung Bottom Freezer Refrigerator stood on a green screen infinity cyc while [Leckey] coaxed it into revealing its thoughts and actions.\nSee also: the vapourwave aesthetic, an early-2000s musical and visual microgenre associated with glitch art, Ancient Greek sculptures, 2000’s web design, outmoded computer renderings and classic cyberpunk aesthetics.\n4.\nWatch this Italian pop song that sounds like American English.\nPrisencolinensinainciusol, by Adriano Celentano. 1972. You may die laughing.\n",
    link: "/home/2018/01/22/filtered",
  },
  {
    title: "Mid-program reflections #1 — the story so far",
    date: "18.37, Wednesday 21 Mar 2018",
    content:
      "This post is the first of a series of reflections on running a startup accelerator:\n\nThe story so far\nHow to run Founder Stories\nStartup cadence versus agency cadence\nSix thoughts about Office Hours\nAccelerators, corporates, and an ambition to become the Innovation Partner of Record\n\nIt’s week 6 out of 12 so I figured I’d write a bit about how this 3 month startup program works, and what I’m learning from it.\nThe “#1” in the title is entirely aspirational. I’m writing this with my thumb on the tube between Moorgate and London Bridge on my way to a morning meeting. I used to write and look at email on my commute, but in 2018 I’ve been either reading books or running. The first due to a successful new years resolution, the second a thinly veiled response to turning 40. So let’s see how much time I actually get to write these reflections.\nIn case you missed it, I’m Managing Director of the R/GA IoT Venture Studio which is a three month program here in London, aimed at startups in the general area of the Internet of Things, and it includes investment and hands-on support. This is the second time the program has been run in London, though there have been many more programs along the same lines in the US.\nR/GA is a global digital agency.\nMostly, the startups we work with sit with us in the office.\nThe London program works like this:\nThe first three weeks are dedicated to meeting mentors and people from the sponsors and around R/GA. The goals are to get feedback on how the founders are building their businesses, and to build personal relationships between the founders and the “mentors.” (I dislike the term mentors because it sets up a power imbalance with respect to “wisdom” and this is often inaccurate and usually unhelpful. Instead I prefer to call people what they are, which is experts, advisors, investors, and potential customers. But that’s cumbersome so mentors it is.)\nThe next five weeks, the second phase, is called Services, and it’s what we’re in the middle of now. A team from the agency side of R/GA, which is much larger than the newer Ventures side, works with each company to refine and professionalise its offer via brand, visual identity, and copy work. Often but not always there are sub-projects focused on areas like the user experience of particular dashboard, or the design of communications at the point of sale.\nThe idea, which I buy, is that by presenting in a more professional way, you can close more customers, get more traction, and therefore build the value of the company. Professionalising means making decisions and nailing down brand, etc, to deepen appeal to particular customer segments by highlighting particular benefits of the product or service. So the trick is to only nail things down where there is already positive customer traction. You have to avoid carving in stone anything speculative. Untested ideas do not—or at least, should not—survive contact with real customers. Putting work into untested ideas reduces your ability to iterate them. This is toxic for a startup, because a startup is a machine for learning. All of which means there is a knack to Services.\nWe also lend a hand with more future-facing or operational tasks. Examples of topics hit in the Office Hours sessions (I meet with each company for an hour each week) and in meetings with our program team:\n\nAddressable market sizing\nOutlining the employee onboarding deck, including processes and values\nReviewing the sales process, tools, and collateral\nCalculating unit economics\nPutting together the direct sales funnel, identifying relevant metrics, and setting the agenda for growth meetings\n\nThese meetings happen throughout the 12 weeks, alongside the odd workshop and fireside chat with guests.\nThe third phase is called Presentations and it’s about refining the pitch, the story, and the deck. R/GA New York has a dedicated presentations team, and they visit to work directly with the cohort.\nThere’s a demo event at the end which is a kind of finish line for the formal programming, at which point we move into a continuous phase which is internally called Engagement. This simply means that we make sure people in the R/GA agency know of all the startups, and we look for opportunities to make connections that could lead to work.\nOther programs—there have been a dozen or so—have a more active strand of building collaborations between corporate partners and the startups in the cohort.\nWe’re working with nine companies in the 2018 cohort. R/GA Ventures investments to date number in the mid 80s. Here we have our first circular economy startup. We have our first applied biochemistry startup.\nI spoke with Fast Company and they did a great write-up of all nine.\nWe invest £75,000 in each company, in addition to the in-kind investment of the three program phases, in return for equity.\nHere’s what W6 involves, for me:\n\nMonday was Office Hours in the morning. You never know what a session will be about until you’re in it. These three were: a tactical look at closing sales; a question about a focus on product build; identifying the current soft spot in the future pitch deck. Those were the topics, but my overall goal for Office Hours is remove barriers to growth and to build a habit of momentum. In the afternoon we were insanely lucky to have Joshua Edwards visit from Lab126 which is Amazon’s super secretive hardware division. He took us through their new product development process and also how Amazon makes decisions. We weren’t allowed to record it, or invite anyone in from outside the program (we asked). In the afternoon I met with the Head of Marketing from one of last year’s cohort to discuss how they are taking their product to the US.\nTuesday included more Office Hours, and also meetings. One with an accountancy firm, and one with and Stephen about plans for future programs in London. Stephen is the global COO of R/GA and Managing Partner of R/GA Ventures. I have learnt a ton from him.\nWednesday is today, which is the day after I started writing this post. I’ve met with investor friends for breakfast, discussed plans for various program events, and hosted the weekly call named “IoT18 - legal sync” in my calendar. I use Outlook. I coordinate the investment deals with the startups, which means that I’m often talking through paperwork and terms with founders, and also working with the legal team on this end. Deal work is fascinating: you move between the macro of commercial intention and the micro of clauses; there’s project management, negotiation and negotiation strategy, and sitting with Excel to model scenarios and so educate one’s intuition.\n\nWhat I’m not saying is that most of the time I’m not with startups or in a meeting, I’m working with Lisa Ritchie. Lisa is the Program Director here, which means she runs operations, the budget, and the program team. Lisa has been my single hire (for this program she has hired or selected everyone else), from back before the first London program, and we run this thing together. She is even more excellent than I had hoped.\n\nThursday is tomorrow. In the morning we have five “mentors” visiting to spend time with the companies. Usually I would debrief with the mentors over lunch, but I’m in Office Hours sessions instead so Lisa will do that. Then, looking at my calendar, I’ll be sitting down with the program team to review any small projects we might run to unblock progress for any of our companies; I’ll be meeting with Bob Greenberg who is the founder of R/GA and this week visiting the London office; and finally I’ll be doing a fireside chat with Bethany Koby (CEO and founder of Technology Will Save Us) who is visiting to share her story with the cohort. In the afternoon there is a workshop about the implications and opportunities of GDPR.\nOn Friday, I’m not in the office. For the past few years I’ve kept one day a week back to develop future work. Never sell Fridays. That means I go to art galleries and read; it also means I take meetings around more speculative directions; I meet with the companies where I’m an advisor. But this Friday I’ll be on the train to Nottingham because I have a reservation at Restaurant Sat Bains for their tasting menu. I understand it’s pretty experimental. One of the courses is named after the restaurant’s postcode. The name of the course, and the postcode, is NG7 2SA. There are either seven or ten courses in the tasting menu. There are approximately 1,700,000 postcodes in the UK.\n\nWhen I say “we” I mean any of R/GA, R/GA Ventures, the Ventures team in New London, this program, and the program team. The program team is me, Lisa, Soala, and Amanda. Each “we” is great, but considering this program team in particular, I couldn’t be happier to work with them.\nMy intention is to write more words like this.\n",
    link: "/home/2018/02/12/filtered",
  },
  {
    title: "Mid-program reflections #2 – how to run Founder Stories",
    date: "14.10, Wednesday 28 Mar 2018",
    content:
      "It’s the middle of week 7 and we had our third Founder Stories session on Monday. (Here’s some general background on the program.)\nBack in the winter of 2014, Jon Bradford roped me in to be EIR at Techstars London where he was Managing Director at the time. Techstars is the standout global network of startup accelerators. They’ve worked with over 1,200 startups, all via three month programs built around mentoring. “EIR”–my role in that single program–stands for Entrepreneur in Residence and it’s a fancy phrase for hanging out, lending Jon a hand, and getting exposure to all the companies and the programming while figuring out what to do next.\nFounder Stories was a component in that program: every week or so, a founder of a more developed startup would come in and present their story, with a Q&A afterwards. I loved it. I’m pretty sure the startups on the program all loved it. When it came to running a program myself, I wanted something that did the same job. So I nicked the format.\nHere’s how it works:\nI have a bunch of buddies who run startups. For a Founder Stories session, I invite one of them in for an hour-long interview with the program cohort as audience. The interview is 40 minutes; the open Q&A is 20 minutes. It’s an interview because it minimises prep time for the guest.\nThe session, ideally, runs 5-6pm. Last year we ran it later, but that meant that people with home lives found it hard to join. So this year we’re running events in the evenings as little as possible.\nI get everyone in the room to introduce themselves to start with. This opens up the room, and provides practice for founders and team members to introduce their startups in just one sentence. The final person to introduce themselves is our visiting founder.\nI have a pattern for the interview:\n\nstart at the end: what does the company do now, how many people is it, etc. This avoids surprises. Surprises are great for drama but get in the way of learning from vicarious experience\nthen go all the way back to the beginning, and narrate the story more-or-less chronologically. Funding rounds are good milestones for this. I have a discussion with the guest just before the event and take notes so I can keep the conversation on track\n\nIf the founder brings up a particular topic, I like to follow it along and see how it develops over the stages of their company. If they are interested in team dynamics, I like to ask how the team has evolved and how processes have been adopted. If fundraising comes up, it’s interesting to follow that thread.\nEndpoints often seem either unattainable or inevitable. My goal is to point out the steps and to show a chain from then to now. If you can imagine such a journey, you can work on taking it. If you can’t imagine your shoes taking those steps, you won’t even notice the opportunities and invitations that come your way.\nHere’s what I avoid:\nI prefer to avoid gasping at luck or indulging in struggle. This is entertaining, but puts the founder on a pedestal: they must have been exceptional in some way to get through it. I don’t want them to appear anointed. I want the founders in the audience to think, hey, that could be me.\nThere are small ways of building identity between speaker and audience. One is to avoid stages and use low chairs.\nI want the startup story to become normal. Almost mundane. This is delicate because the founders who visit to tell their stories are exceptional. Getting this far is rare. So it’s not a matter of popping the balloon but rather steering the conversation to acknowledge that success is a combination of, yes, luck, and also talent and hard work. Sometimes, for a new entrepreneur, the key to unlock success is to recognise their own talent and their own superior knowledge about their domain.\nIt’s such a balance. My favourite founders balance humility to listen and learn from their customers and advisors, with a strong resilience grounded in an understanding of their own talent and a mysterious vision. Plus luck! It takes belief that sometimes the universe hands you luck in order to notice it and drink from it.\nHere’s why I think Founder Stories is useful:\nA startup is as much an approach as anything else–an approach to solving problems (visionary yet iterative and data-driven), language (the strategy of startups is there for the reading, but it’s encoded in a shorthand that you can learn through immersion), an understanding of what is normal (it’s easier to ride the tiger if you know what to expect), and an ecosystem of reputation, introductions, and people. Reading this back, I realise that I don’t mean that startups have an approach. Startups have a culture.\nOne of the jobs of a successful accelerator is to transmit startup culture.\n(Different accelerators do that in different ways, and that they do on-top is what makes different accelerators appropriate for different startups at different stages. And just to be clear, an accelerator isn’t a necessary step in a startup’s life. There are many other ways to be part of the culture, and joining an accelerator should be a considered decision like any other business move.)\nI say transmit because culture isn’t taught.\nWhen I think of transmission I think of the way a sourdough starter is created by taking a fist of the original starter, and growing it with flour and water.\nMy go-to analogy used to be that you can’t cold-start a gut biome. If a person unfortunately loses their gut biome, it has to be replaced by taking a sample of a compatible biome from inside another living person and medically transferring it. But the connection with startups always got lost as I started getting into the reasons and methods of fecal microbiota transplants, so I abandoned that particular explanatory method as possibly too distracting.\nDemystifying. Allowing a new entrepreneur to picture themselves further along the road. Scouting ahead to build familiarity with the language and the challenges. Hearing the story isn’t (or so I believe) directly about learning.\nWe’ve been lucky to have Hal from Unmade, Bethany from Tech Will Save Us, and Emily from Blaze share their stories so far. We have a couple more Founders Stories lined up.\nAfter Emily’s visit, one of the founders in the cohort said to me that she could see a bit of herself in Emily. Seeing Emily let her know that, in building her startup, being herself was okay.\nBig moment.\n",
    link: "/home/2018/03/21/reflections-1",
  },
  {
    title: "Mid program reflections #3 – startup cadence versus agency cadence",
    date: "16.05, Friday 13 Apr 2018",
    content:
      "As I write this it’s Tuesday of week 9 and it’s 8.30am so there are only two of us in the office: me and the founder of one of the startups.\nWeek 9 marks a change of pace. For the last five weeks, “programming” (that is, meetings and workshops) has been relatively light. The focus has been on “Services”–the strategically-led creative work provided by agency teams that makes this particular startup accelerator different from the others. In addition there are weekly meetings with me that the industry universally and mysteriously calls Office Hours.\nThe team working on Services has produced fantastic work. It’s spot-on. The feedback has been tremendous. And the Presentations work has already resulted in exciting pitches, radically more easily understood.\nWarning: working practice simplification and stereotyping ahead.\nThe cadence of how startups work:\n\nDo something end-to-end, whether it’s a web product, hardware prototype, or pitch deck. Get it in-front of its eventual users, customers, or consumers. The earlier and uglier the better. Observe feedback. Iterate.\n\nThe cadence of how agencies work:\n\nFollow the process and build foundations for the first 80% of the time. Foundations are answers to questions like: what are the values of this brand? To what customer segments should it appeal, targeting what motivations? At what points of the experience of the product or service can these brand values be made evident? Then suddenly the invisible work is completed. For the remainder of the time create highly visible executions–web pages, sales collateral, dashboard wireframes, point of sales communications, guides to words and phrases to use in future marketing.\n\nBoth methods are highly effective.\nThe Services phase of this program poses a challenge. To a startup, agency cadence has pros and cons.\n\nPro: the rigorous process forces each startup to better understand itself, its value proposition, and its customers, and gives it language to talk about and iterate all of that\nPro: the result is a newly professional appearance–essential to be taken seriously by business customers\nCon: the agency cadence can be abstract and hard to grasp. In my Office Hours I make sure we discuss how to use and build on the deliverables\nCon: the agency cadence lacks iteration in the face of true customer feedback\n\nTo me this last point is the most serious: no matter how much thought and strategy has gone into it, no work survives contact with the market. An iterative approach is essential.\nYet work that has been over-thought becomes brittle and slow to change.\nSo the risk of agency work to a startup is that it takes the startup down a dead-end with no way to turn around.\nMy response is to ensure that the Services phase focuses on amplifying what is already working. Create only where there is traction and proof that customers are responding positively.\nGiven the above, the question is why run a program that includes agency services supplied to startups? The same can be asked of the Presentations phase. I’ll let you know in another 540 words.\nI said there had been a change of pace. Services is winding down; Presentations is winding up.\nThis four week stretch is about creating a 5 minute pitch deck. There’s assistance with crafting the story, speaker training, and design help to make great-looking slides.\nWhat’s the deck good for? It’s always handy to have an intro that hits all the bases: the what and the why of the product; the business potential and customer traction; the team and roadmap; the secret sauce. This intro, with adjustments, will get used for investor intros, and also to explain the company to partners, customers, and new hires.\nA key skill in any pitch, whether you’re a founder or a young designer, is to quickly and uncontroversially explain your idea space, so you can concentrate the discussion on what matters. For example, how to work together. This deck does that job.\nProducing the pitch deck in this form does another job, which is to shake out the inconsistencies in the business.\nThere are standard formats for pitch decks, such as the Kawasaki 10 slide deck, or the more recent Y Combinator seed deck template.\nI think of these decks as a narrative versions of the Business Model Canvas. I used to be a skeptic. Surely it doesn’t make sense to outline an entire business in nine boxes on a single sheet of paper? But I’ve become a convert.\nThe Business Model Canvas is like an electrical wiring diagram but for flows of motivation and money. For example:\n\nyou itemise your customer segments. There’s another box to list how you reach customers. Wire them together. There’s another box for the product value propositions that should appeal to your different customers. Wire them up. Ok, so your product has a particular point of value that should appeal to a particular type of customer… but there’s no way of reaching them? Whoops\nthere are costs. There are revenues. Wire them up. Oh so revenue comes in on a per-product-sale basis but costs are on an annual basis? Impedance mismatch, rethink the business\n\nSo you draw out the business and look out for gaps or anywhere the gears grind. When I’m starting a new project, I make a quick Business Model Canvas to give me an idea of any dark corners. It’s not everything, but it’s a sketch.\nWhen you run through a pitch deck, ideally it should cover all the same points–but with proof too. Ok so the goal is to sell such-and-such product to such-and-such customer? Well how can that be demonstrated? Ok so the business is dependent on a special technology. Well does that tech exist, and can it be protected? And so on.\nIn Office Hours over the past two months, I’ve tried to keep in mind each company’s upcoming pitch deck, and I’ve been steering the conversation towards exploring some of the gaps.\nI believe that a good pitch (and a good startup website, and good startup sales collateral, and a good introductory paragraph) has got to include belief and desire.\nDesire: make your audience see dollar signs in their eyes. Make them want it.\nBelief: make this seem inevitable. Show the detail. Build trust.\nThe sizzle and the steak.\nSo given my above misgivings, why do this work with the startups? Why not operate like other accelerators, focusing on coaching and pitching?\nFirst–some teams need to plug a design gap. If you help with the right ‘kit of parts’ then it’s a proper leg up. \nSecond–the process is useful. But you could get the thinking via Office Hours and conversation, right? Why do the additional hands-on strategically-led creative if there’s a risk of compromising the startup’s ability to iterate?\nSo, for me, the answer can be found on the customer side: some customers, big and small, judge a book by its cover. Even when meeting a startup with crazy new technology, a radical business model, or simply a better mousetrap, they’re put off because the website isn’t professional, the sales deck doesn’t quite express the whole story, or the dashboard looks a bit fiddly.\nBig corporates are not monolithic. They are, internally, networks, and these networks resist anything which is hard to understand. Sales material will be passed around behind the scenes to people who are finding out about the startup for the first time. The product will be used be people unfamiliar with startup norms, and seen by people who aren’t trained. An aspirational story will transmit better than a hair-shirt story. Etc.\nMore than that: an employee of a big corporate who takes the reputational risk of introducing a startup wants to look smart to their colleagues. No matter the quality of the startup’s product, if the benefits are hard to understand or it’s easy to give a kicking, it’s not going to fly.\nIn short:\nCorporates want to be innovative. A path to being innovative is to work with startups. But when they meet a startup, they often can’t digest it. So either the corporate has to change. You could push water uphill. Or the startup can change–just a little bit–to accommodate the relationship. A spoonful of sugar helps the medicine go down.\nIterate with the agency cadence, then amplify with the agency cadence.\nMy feeling is that’s what makes R/GA’s programs different: in the DNA of the organisation is partnering with corporates around innovation.\nOne last thought. Despite all of this, startups shouldn’t look too professional. The character of the team should still shine through.\nOnce you take away the product and the revenue model and the technology breakthroughs, the big reason that a person working in a big corp wants to work with a startup is that they love hanging out with startups.\nFor a few years I’ve run a session at Bethnal Green Ventures about sales and marketing 101. (It’s an incubator for social good startups. Early stage. Great organisation.) I joke about people who work in corporates. I say they have miserable lives. I say they wish they could leave but they have mortgages and school fees and they’re addicted to holidays. Instead they live vicariously by working with startups. So take advantage of it.\nIt’s a horribly mean thing to say and it’s certainly not the whole truth. But there’s definitely a glamour that mustn’t be washed away. So I’m also paying attention to that, in the Services and Presentations phases.\nAnyway. It’s Friday now, somehow. Next week: week 10.\n",
    link: "/home/2018/03/28/reflections-2",
  },
  {
    title: "Mid-program reflections #4 – six thoughts about Office Hours",
    date: "17.20, Friday 20 Apr 2018",
    content:
      "I meet with each of the nine startups for an hour every week. The session is called “Office Hours” and I’m pretty sure that all startup accelerators do something like this.\nFor me, it’s about founder coaching and generally making sure each team is getting the most out of the program.\nI first saw how this works because of Jon Bradford. I was lucky enough to sit in on his Office Hours sessions in 2014 when he was MD with Techstars London. I’ve developed my own style since. All the good bits are from Jon.\n“MD” stands for “Managing Director.”\nWhat does a program Managing Director do? I can’t tell you in general, but I can say what I do.\nI lead on outreach and then selecting the startups. I make the case to the rest of the team about why each startup is worth investment, and I have a thesis about what’s happening in the market. I lead on deal negotiation, and I coordinate the legal team.\nProgramming: I work closely with the Program Director, Lisa Ritchie, and her program team. In theory I’m backstop if there’s trouble, but there’s been little of that: Lisa both runs a tight ship, and thinks imaginatively ahead of the puck. So I’m consulted only as needed, usually as a startup is being handed off between the different parts of the program. Because of my design consultancy background, I’m a second pair of eyes on the briefs for the agency-led Services phase. I bring in much of the network of experts and advisors, and founders for Founder Stories sessions.\nI run Office Hours. I coach the startups when they’re in the room, and evangelise for them outside it.\nThese reflections are about Office Hours. Although this is the ninth paragraph, it was the final paragraph written. I finished writing this post, read it through, then came back here to give you a warning: there are too many words, and I have that horrible deer-in-the-headlights feeling I sometimes get when doing public speaking that, holy shit, everything I’m saying is obvious and asinine. So I’m going to do what I usually do when that feeling comes on, which is to double down and barrel on.\nI estimate that I’ve led or sat in on 250 hours of Office Hours sessions. This doesn’t include advisory sessions or board meetings. I don’t feel that 250 hours is enough to get good at it.\nAlso: who the hell am I to be giving advice? I’m less successful at the startup game than a lot of the people I meet with, and with the rest that’s only because they’re just getting started. But I’ve seen a lot.\nSo given I don’t feel particularly good at it, I keep notes of approaches that seem to work. This is something I’ve been doing for a couple of years, on and off: privately journaling at the end of the week about working practice and team dynamics.\nThen I come back to the approaches later. I don’t mean to follow them slavishly. Only that, in a session, I try to remain conscious of them rather than reacting in the moment.\nSix things I try to keep in mind while I’m running an Office Hours session:\n1. Do they know how to run the room?\nMy first session is about us getting to know each other, and talking about what we can expect from Office Hours. After that, I start by asking a question: what’s one great thing and one challenging thing that’s happened over the last week. (Then we dig into the challenging thing.) \nAbout halfway through the program, I put more of the agenda in the hands of the founders: at the beginning of the meeting I get them to write the agenda up on the whiteboard. This becomes habit pretty quickly. If I’m not clear what a topic is, or what kind of response I’m being asked for, I say.\nMuch of any founder’s time will be spent meeting advisors and investors. There’s a knack to running the room and getting what you want out of it, while maintaining a feeling of collaboration and conversation. Meetings aren’t just time you spend in a room together. Meetings are an atomic unit of work. They should have purpose and outcomes, although these don’t necessarily need to be stated. There are lots of small ways to make sure attendees don’t drift or feel lost.\nMost of the founders I work with already know how to run a room. At which point, reassured, we can go back to chatting.\n2. Am I thinking a couple weeks ahead?\nWe provide a bunch of programming to the startups, and I want to make sure it’s effective.\nFor example, ahead of “mentor” meetings with experts and advisors, we discuss how to pitch (5 minutes to intro the company, then dig deep into one or two issues. They may have to work to make it useful). During the Services phase, I try to bring up the differences between how agencies work and how startups work, and also how to integrate the deliverables.\nAbsent anything else, I think ahead to the eventual pitch deck. I’m imagining the slides. If there’s not yet a strong traction slide, I work backwards through sales and then to processes around customer development, and guide the conversation to those topics.\nBecause of this, I need to have a strong opinion about where the company should go and how it will get there. I spend a lot of my time between Office Hours thinking about this. This isn’t so that I can say there is a “right” or “wrong” answer, it’s so I can have a good understanding of the complexity of what they are taking on. Rather than “correct” or “incorrect,” it’s useful to feel out decision qualities such as “ability to easily iterate” or “here be layers of unconscious assumptions and hope.”\nFounders are very convincing people, so I have to watch for where an argument is strong because of good analysis versus mere charisma. Sometimes founders convince even themselves. There’s a knack to jumping between sharing visions of the future and robust self-honesty.\nMy personal mantra is: strong opinions, weakly held. I have to remember that my view is secondary to what the founder and the team wants. Of course my opinion might be that the founder is missing something, so I have to satisfy myself that their decision is made with a good process. (And sometimes the choice is between two routes and the answer is: do whatever you’re ok waking up at 4am and thinking about for the next 4 to 7 years.)\n3. Why hasn’t the founder answered this question already?\nThese founders are some of the brightest people I’ve met. If anyone has the mindset to tackle any challenge they meet, it’s them.\nSo when a question is brought to Office Hours, I try to ask myself why the answer is not obvious to the founder. I try not to immediately answer it myself.\n(There’s another reason why I shouldn’t leap to answering questions, in that the founder has been closer to and thinking more deeply about their startup than I ever will. In the end, all I really have is a perspective.)\nWhy might a founder ask a question?\nThere might be a knowledge, skills, or experience gap. This is possible. I think to myself why they have not worked it out with friends or google. We can figure out an approach together, and what I try to do then is ask smaller questions which will lead the founder to the answer for themselves.\nA second possibility is that the higher-level framework has something missing. A question about, say, which product features to highlight on the homepage should be obvious given a validated model of the customer and an understanding of product differentiation. And those should be possible to figure out given their priors: in this case, a process of having a business model hypothesis and testing it by speaking to customers and investors.\nSo a question from a founder is a chance to dig upwards to these frameworks. Frameworks aren’t axioms. They can and should change, but always deliberately. \nThe important thing here is not the answer, but the ability to deconstruct the question, to ask it intelligently, and to discuss it. If a question can be treated like this, then it can be worked on by the founder with their team and with their advisors–all people who are much smarter and more experienced than me. A question answered by instinct can’t involve and take the benefit of all the smart people around us.\nA third possibility is that the answer is clearly evident, but there is some personal or team resistance to seeing it. A resistance comes about often because the answer implies something undesirable. You’d be surprised how often this happens, or maybe you wouldn’t. If it’s a single founder, some possibilities are that:\n\nthe answer might imply something that conflicts with the founder’s self-image\nthe answer might reveal an undesirable kind of hard work: it’s preferable to do the all-consuming and intellectual hard work of grinding through product development, versus the emotionally scary work of sales and possible rejection (for example)\nlike all answer, this answer means bringing an idea into reality, which is terrifying: all ideas are perfect; reality is at best mundane and at worst can fail\n\nSo in this case, I try to help the founder be clear-eyed about what an answer means.\nIf it’s a team, these different viewpoints can be embodied in different team members. This is not necessarily a conflict. One member might be not surfacing the answer because they imagine another team member is highly invested in a different approach. Possibilities are unvoiced from an overabundance of care. My job here is to help them become a functional team, and one way to do that is to illustrate the power of saying conflicting viewpoints out loud. So I try to point of differences of opinion. Just because differences of opinion have been unearthed does not mean they need to be resolved. Differences can be tolerated and embraced. (Although courses of action, once decided, need commitment.)\nI have a hobby interest in small group dynamics, so I love these sessions intellectually. Though they are the hardest to work.\n4. There is often a crisis. Fixing the issue is not my job.\nA special type of Office Hours is when there’s a crisis. I would characterise a crisis as any time the founder brings urgency into the room–whether it’s good or bad. There are times when sales are going just too well! “A great problem to have” can trigger a panicked response just as a more existential crisis such as an unhappy team.\nI have to remind myself that fixing the issue is not my primary job. Participating in panic validates panic as a response. But if a startup responded to every crisis with panic, nothing would get done. (I would characterise panic as short-termist thinking, accompanied by a stressed and unpleasant emotional state.)\nWhat makes this challenging is that I often know what they’re going through. Sometimes I recognise a situation and my own emotional memories well up. There have been sessions where my heart races, or my palms sweat, or I look from team member to team member and wonder if they realise the dynamic they’ve found themselves in.\nSo before we talk about the issue, I try to find the appropriate emotional response: enthusiastically cheer first sales (but don’t sit back on laurels); get pissed off about bad news but move on with good humour; treat obstacles with seriousness but don’t over-generalise. It’s a marathon not a sprint, and so on.\nThen use the situation to talk tactics and build some habits. I like to encourage:\n\nWriting things down. Startups are not about product, they are about operationalising sales of that product. Operationalising means there is a machine. The minimum viable machine is a google doc with a checklist. The sales process can be a checklist. HR can be a checklist. Bookkeeping can be a checklist. When things don’t work, revise the checklist. Eventually, turn it into software and people following specific job objectives. This is how (a) the startup can scale where revenue scales faster than cost of sale; and (b) the founder can one day take a holiday.\nA habit of momentum. I forget who said to me “first we figure out how to row the boat, then we choose the direction” but movement is a team habit. If, in every meeting, i respond to a business update with “so, what are you doing about that” then that expectation of action will eventually get internalised\n\nI find these viewpoints sink in better when they’re using in responding to a crisis.\nI also like to encourage self-honesty. Sometimes my job is to say out loud things which are unsaid. Founders are very good at being convincing (both themselves and others) otherwise they wouldn’t be founders. Sometimes that data that doesn’t fit the narrative is left out… to others and to themselves. So I can help break that down.\nThere will be crises and crises and crises. But we only have these Office Hours for 12 weeks. If we concentrate on fixing just today’s issue, we miss the opportunity to build habits that can handle tomorrow’s.\n5. Am I being useful right now?\nAs much as the above is useful in the long-term, there has to be a balance: these sessions should also tackle the issues brought into the room. In the last few weeks of the program, I find that we spend more and more time on day-to-day business issues. The founders have figured out how to get what they need out of me. And if they can do it with me, my hopes are high they can do it with anyone.\nWhat do we look at? An iteration of the pitch deck. A run-through of the sales process. How to hear a “no” as a description of what a customer wants, and to use it to win the sale. Examples of pipelines and proposals. The agenda for a weekly growth meeting. Showing how the almost identical pitch deck can be re-pitched with added intensity if you pay attention to emotional narrative and rhetoric. Investor motivations.\nI’m not an expert, but I do a lot of things a little bit, so I can be a useful second pair of eyes.\n(I pay attention when the same topic comes up more than once and try to understand why the founder has not instinctively generalised.)\nAlso towards the end of the program, I get more open about some of my approaches above. The sessions get more and more collaborative. In the end I’m learning quite a lot.\n6. If nothing comes up, getting to know each other is great.\nI want to make it very clear that all the good stuff you see is entirely down to the startups themselves. Advice is bullshit. The bar I set myself is: can this hour be more effective than the hour they would otherwise spend building their business. Almost certainly not.\nAs I said above, the founder has been thinking way more about their company and their market than I have. There are experts out there far smarter than me. But there’s a bigger point:\nI have to remind myself it’s not my company. I don’t make the decisions. In the event that I do recommend a direction, I remind myself that I mustn’t get offended if they don’t take my advice. (It’s a natural and human response to be offended when offered office is not taken.) It’s not that I ought not be offended–it’s that being offended would be a category error. The material I work with is the actions of the founder. The material isn’t right or wrong, it simply is.\nA good way to do all of the above–to react appropriately, to coach good habits, and to be useful–is for the founder, team, and me to get to know one another. The better you know each other’s values, the higher the information content of any given interaction. So sometimes the best thing to do is to hang out.\nReading these reflections, I sound, even to myself, like a pompous arse. I mean, there’s a very good chance that I am a pompous arse, which would be the reason why.\nHonestly mostly the sessions are just chatting. I work hard to make them useful chatting, and yes I probably overthink it. My Office Hours will be more useful to some founders than to others. And I sure a lot of people, in my shoes, would do a much better job and wouldn’t indulge themselves with endless introspection.\nAmateur hour coaching, that’s all it is.\nThis feeling is so strong that I think I will have to warn readers somewhere near the top. Say, around the ninth paragraph.\nHere’s a quote from Bob Shaw’s short story “Call me Dumbo,” found in the collection Tomorrow Lies in Ambush.\n\nAn aircraft factory is a machine for producing aeroplanes and it may be disastrous to attempt to improve production by piecemeal tinkering with individual departments–one must seek out in all its ramifications, and destroy, the machine for stopping the production of aeroplanes, which lurks like a parasite within the organisation.\n\nI love this way of thinking.\nLet’s start from the perspective that a startup is a machine for growing. But there are obstacles which temper the growth. Our job, together, is to identify and to remove the invisible anti-growth machine.\nThe end of week 10.\n",
    link: "/home/2018/04/13/reflections-3",
  },
  {
    title:
      "Mid-program reflections #5 – accelerators, corporates, and an ambition to become the Innovation Partner of Record",
    date: "10.25, Wednesday 2 May 2018",
    content:
      "It’s Wednesday of week 12, which means the big pitch event that we’ve all been working towards is tomorrow morning. The pitch decks for each of the nine companies are looking great. There’s been a ton of practice. The attendee list is also looking good. The program team around me is working super hard.\nAccelerators usually end in something called Demo Day. Everyone pitches. Everyone claps. In theory it’s great networking and a kick-off for investment, but my feeling is it’s more of a finish line to the program. Everything has to be done by this date. No loose ends in the business plan, or the articulation of the product. Demo Day is a forcing function. The real work happens next, so the past couple of weeks I’ve been saying to the founders they should fill the week following the program with investor meetings.\nThe risk is that because the program is so full on, you take a breather in the week following. Then you arrange meetings, and the emails take a week to get through then a week to arrange. Then suddenly it’s a month later, and you can no longer say as your opening gambit “so, a lot has changed in the last three months.”\nPace yourself. I can’t remember who described to me closing an investment round as “sprinting to the start of a marathon” but it’s true for finishing these programs too.\nThis will be the final mid-program reflections piece.\nI’ve been thinking about the other side of the value equation: what do corporate partners and sponsors get out of these programs?\nHere are all the posts so far:\n\nThe story so far\nHow to run Founder Stories\nStartup cadence vs agency cadence\nSix thoughts about Office Hours\nCan agencies become the Innovation Partner of Record? (This post)\n\nBonus post from 2017:\nHere’s my PR tip for people (like me) who are terrible at PR a.k.a. the Tick-Tock List\nAccording to a government report in April this year, there are 163 startup accelerators in the UK. Here’s the original report (it’s comprehensive) prepared by Nesta.\nHalf of these 163 are corporate backed.\nHelpfully, the report gives reasons why a big ol’ corporate would want to back an accelerator. Benefits:\n\nRejuvenating corporate culture to create an entrepreneurial mindset among employees\nCreating an innovative brand that attracts customers, business partners and future employee\nSolving business problems quicker and at lower risk\nExpanding into future markets by accessing new capabilities or channels\n\nWhich, yes ok, I buy:\nIt’s all about innovation.\nI believe-although I can’t prove-that over the 15 years I’ve been working in it, innovation has become more central to more businesses. It used to be buried in R&D departments (engineering) or “Labs” (often marketing). Now it’s at the top of an organisation.\nWhy? Again, only a guess, but for what it’s worth here’s my take: technology continuously changes and creates new opportunities; a market of technology-native companies means both the competitive landscape and consumer expectations also change rapidly. Innovation is how to keep up and get ahead.\nAside:\nA friend told me this, probably apocryphal, story about British Sugar. British Sugar processes beets. They are the sole purchaser of sugar beet in the UK. How much they pay and how much they buy is specified in legislation. How much the sugar sells for, and how much is produced, is similarly on a quota. Consultants are brought in periodically to find optimisations in the business.\nOne day one bright individual realised that the by-product of sugar manufacture is hot air. What needs hot air? Greenhouses. Tomatoes. So now British Sugar is the largest producer of supermarket-sold tomatoes in the UK. I am assured this story is legendary in management consulting circles and held up as the pinnacle of consultant achievement.\nI just googled to check veracity. No luck. But I did discover that British Sugar is switching from cultivating tomatoes to cultivating cannabis. \nDespite my 15 years in the innovation game, I couldn’t tell you with any authority what it means.\nI can tell you the results. The results of a business innovating are things like:\n\ngrowing a new part of the business which has a new business model, for example using subscriptions instead of product sales\nswitching to new technology that cuts operating costs\nlearning how to reach consumers in a new way\n\nIt’s harder than you would think for an established company to do these. Companies are optimised to continue doing what they already do. They are intricate machines and so, in order to maintain smooth-running of the machine, individuals are discouraged from arbitrarily changing what they do day-to-day.\nYes, a good business will always be looking for “new ways of doing things.” But new ways are non-obvious because the machine cuts across lots of people who may not even know one-another. And even when discovered, there are vested interests in the old ways: it’s not easy to sit in a meeting and propose, say, automation or a website to replace multiple Excel spreadsheets, when that means your buddy over the table is going to be put out of a job.\nAll of which is to say: discovering new ways is tough.\nSo innovation itself is not the result, but a whole grab-bag of processes to get there. Such as:\n\norganisational interventions: Amazon’s ‘two pizza’ small teams allow for permissionless innovation: You can add new product lines without adding new internal structure or direct reports\nmoonshots: prototypes, large and small, help align teams around new goals, and create spinout technology. An old example I know from the inside-out: Mag+ from BERG and Bonnier R&D (2009)\nmergers and acquisitions: of the multiple reasons Unilever acquired Dollar Shave Club, the strongest to me is that they were acquiring the culture and practices of a whole new business model. Subscription consumer goods, reaching consumers in new ways, in a company built by engineers\nart: I’ve been collecting examples of how art is used by tech firms to change internal culture\n\nPlus old-school R&D, plus simply working to invent and launch a new product and service, plus communicating new ideas, plus changing employee incentives to encourage new approaches… Etc.\nAnd of course: working with startups.\nStartups are technology-native. They make decisions with a customer-first mindset, prepared to sacrifice product, strategy, and existing practices if that means serving the customer better (to me, this is why startups differ from incumbants. It’s a fundamental difference in organisation). They embody “new ways of doing things.” Simply exposing corporate employees to the startup mindset can be transformative!\nBut there’s often hand-holding required to get corporates and startups to spend time together, let alone work together. And, even when the benefit of working together is clear from the outside, corporates–as I said earlier–resist new ways.\nThe job of an accelerator is to reduce that friction. Accelerators help corporates innovate using startups.\nAre accelerators effective at helping corporates innovate?\nWell that’s a different question.\nIdeally what we’d see, in addition to the accelerator itself, is corporate engagement like:\n\nunderstanding the challenges and 2 year roadmaps of different business units, and sharing these with startups\nexercises to “roleplay” a corporate working with a startup, to see if procurement and contracting can be updated\nstartup mentoring being taking seriously by HR as personal development and also talent retention\nincentives given for meaningful pilots and startup partnerships\nacquisitions\n\nBut we don’t, not always. Some corporates do some of these; all could be doing more.\nI think: accelerators are not as effective as they could be. Too often, accelerators are considered in isolation from other innovation processes. Innovation is poorly coordinated, done piecemeal, and best practice is not shared enough.\nThere’s a phrase in the marketing world which has dropped out of fashion. Agency of Record:\n\nIn the world of marketing and advertising, Agency of Record (AOR) was typically understood to mean a single agency responsible for all the services that a particular business might require. These services traditionally included brand strategy, creative and media placement, but today, can include a mix of other services as well, such as interactive media, web development services and digital marketing.\n\nAdvantages (see the above-linked article) include effective strategy; ownership; efficiency; trust.\nHowever,\n\nmore businesses now rely on a mix of different agencies to provide various specialized services.\n\nMy take is that what we need to start thinking about, for effective, coordinated innovation, is Innovation Partners.\nInstead of a corporate having multiple strands of research, new product development, startup outreach, and so on, this should be coordinated by let’s say a VP Innovation. Their job is to set strategy and to coordinate. Also to choose when to do work internally, and when to bring in partners. This role already exists, and I think it’s important to separate it out: corporates shouldn’t be innovating the whole time, in every area. Sometimes they should simply be executing in an excellent way. The job of the VP Innovation is to choose when and how to shake things up.\nThis points at a possible future for the traditional agency.\nGiven agencies are already tasked with finding new ways to communicate with consumers; to work on new products and services; on organisation change and digital transformation; on startup outreach, I feel there’s a new way to package this and also solve the innovation effectiveness problem:\nI’m saying agencies should step from the pier to the boat and call their role what it has already become: the stated ambition of the agency of tomorrow should be to become Innovation Partner of Record.\nA new phrase for an old relationship. This is what I’ve been calling it in my notes, and I think it makes sense.\nBy which I mean: an agency should aspire to consult directly to the VP Innovation on all the innovation processes a corporate undertakes. Sometimes the individual projects will be run internally, sometimes the go-to provider will be the partner of record, and sometimes by a specialist in the partner’s network will be brought it.\nTranslate this back to accelerators: a startup accelerator should not be run on its own, but as part of a package that includes internal comms and strategy; an audit of procurement processes; events and external comms to increase dealflow; and so on, and so on.\nThinking about my own program, this is why the Services phase is so important: the brand, visual identity, and messaging work is not merely value-add creative services for the startups in the program. It’s work to make the startups understandable and easy to work with for the corporate partners attached to the program, and is a big part of what makes the Venture Studio model effective.\nTo my mind, we’re still at the beginning of understanding all of this.\nR/GA Ventures is the innovation and investment arm of R/GA. Behind the scenes these programs are not just about running the core startup accelerators. In the programs which have corporate partners, there’s already strategy work to understand business unit needs and build towards meaningful collaborations. As we learn more, the process develops.\nOf all the agencies I’ve seen, R/GA is the closest to realising the “Innovation Partner of Record” goal.\nSo I’ll wrap up with a quick pitch: if you’re a VP Innovation or similar, you should talk to R/GA Ventures about running a program.\nNot least because if run it in London you’ll get me as program MD, and that would be neat.\n",
    link: "/home/2018/04/20/reflections-4",
  },
  {
    title:
      "What’s changing in property and the thought process behind working with a couple of startups in the recent program",
    date: "12.21, Thursday 10 May 2018",
    content:
      "The accelerator finished last week and my latest cohort of startups has flown the nest. Insert shedding-a-tear emoji here. I’m super proud. And a personal milestone: that makes 20 startups I’m connected with, either directly or via R/GA Ventures.\nCampaign magazine did a great write-up and video of pitch day. Campaign noticed that five of our nine startups were pitched by women founders. A shift towards normality after last year’s male-skewed cohort, but still not representative of the real world: ignore the presenters themselves and look at the companies in their entirety. Only five of the nine startups have women in the founding teams. It should be all nine. There’s work to be done.\nHere’s a puzzle. What connects these two startups, both in the 2018 program:\n\nBeringar which measures and helps optimise productivity in commercial real estate (like offices and hospitals) using sensors on the ceiling and a machine learning back-end. The business model is hardware-enabled SaaS.\nCupClub which is on a mission to eliminate single-use food packaging, starting with coffee cups. Initial customers are businesses with internal cafés, and they pay a competitive per-drink price for reusable cups and a wash/return service.\n\nThe rationale I gave to the R/GA Ventures investment committee was the same in both cases.\nThe logic goes something like this…\nCommercial real estate is changing. The days of the 25 year lease are over. We’re seeing the WeWork-isation of everything. By which I mean, instead of long leases, we see not 5 or even 3 years, but companies moving to annual or month-by-month leases. This provides flexibility (reduced risk, ability to grow) plus access to pooled services normally only available to much larger firms.\nWhy is this happening? We can guess. My hunch is that it’s to do with Ronald Coase and the internet. In 1937 Coase asked why firms exist. If the free market is so great, why bundle together everything from finance to marketing to tech inside one company; why not do everything by contracting out to the market? The answer is that the free market isn’t free. There’s a cost associated, and firms exist to make everything inside them cheaper.\nBut then the internet happened. Transaction cost dropped precipitously. Now firms can be smaller than ever before. Consider startups: everything is outsourced except core activities. Finance, HR, marketing operations, customer support, etc. Tons has been taken over by software (or rather, by the people at external firms who provide the software).\n(Here’s me rambling about Coase in 2014.)\nSo firms are smaller and more nimble than ever.\nAside: I think the same dynamic is responsible for the fact that some firms are more_gigantic_than ever. There’s a bimodal distribution. Another effect is the growth of freelancers as a mode of employment, and what is either called the sharing or gig economy depending on the class of the worker: “sharing” if it’s rich people renting out their homes on Airbnb; “gig” if it’s working class people renting out their bikes and their sweat.\nThese firms pop into and pop out of existence. They don’t want 25 year leases. They don’t want to do fit-out, or manage their own office services.\nThis trend (here’s my guess) is only going to continue.\nAssuming this is true, what are the implications?\nOne shift I think we’re seeing is that property owners are no longer planning (as much) on making their profit from rent. Instead rent should get them merely to break-even. Profit comes from selling services to their tenants.\nThese services have healthier margins than property, and they’re charged on a recurring basis. Services like the usual ones: gas, electricity, cleaning, security. Then also higher-level services… like office productivity, and coffee. Bingo.\nThe shift is parallel to what happened in the consumer space. FMCG (fast-moving consumer goods) used to sell to consumers via supermarkets, unit by unit. Marketing was focused on keeping consumers loyal to the brand. We’re in the middle of a shift to subscriptions–look at my oft-referred-to purchase of subscription shaving supplies co Dollar Shave Club by trad FMCG giant Unilever for $1BN. Marketing is now focused on customer acquisition, and highly targeted.\nAs it is in the consumer product space, and as it happened in the software space (from boxed software to SaaS) and also media (from DVDs to Netflix), so (I believe) it’s happening in the property space. A shift to a services model.\nWhat Beringar and CupClub have in common, for me, is that they are both beneficiaries–and will continue to be beneficiaries–of this property trend.\n\nThey are both services targeting businesses, charged on a recurring basis\nThey are likely to be resold by property owners to their tenants. That is, for both startups, landlords are channel\n\nThere were other reasons to invest, to be sure, but I made this same argument for both of them, and I get a kick out of that.\nIs this all correct? Honestly? Who knows. It’s a hunch.\nIt’s useful to have a hunch about the bigger picture, because then my hunch-making muscles get some feedback. I have a similar hunch about all of the startups I’ve worked with. Sometimes it’s obvious, sometimes it’s not. Once you have a hunch you can build models and do research to check assumptions. Hopefully over time my hunches will get better.\nI’m guessing that to proper investors (I just play one on TV, as they say) this kind of thinking is painfully obvious, so apologies for talking about how to suck eggs.\n",
    link: "/home/2018/05/02/reflections-5",
  },
  {
    title: "Four short stories and what I learnt writing them",
    date: "19.02, Thursday 31 May 2018",
    content:
      "So I’ve now written FOUR whole stories for my short fiction writing group, Upsideclown. ICYMI in August last year, we started publishing again after a 14 year hiatus.\nI wanted to collect links to my four stories in one place. = this blog post.\nI wouldn’t say I’m great at writing fiction. I find it tough. It is the easiest thing in the world for me to pick holes in what I’ve written. So instead, as an exercise–and as some personal positive reinforcement–I want to remind myself what I learnt writing each one, and also what I like.\nMoving House (August 2017)\n\nWe sat atop Parliament Hill as the sun went down, London lapping at our feet, glass of wine in hand, a hard red line on the horizon fading not to black but the glow of LED streetlamps diffused through the humid breath of our ten million neighbours.\n\nI love the way scenes ping pong between two different time periods, immediate and past, and I love the punchiness of last two lines.\nBut goodness is it dense like a compacted shit. You can tell that I hadn’t written for years, and had been attempting to peristaltically emit this particular story for most of that time. The ideas are given zero room to breathe. When I read it back, there are concepts in shorthand that flower in my head–but there are no clues available for anyone else.\nOne thing I like:\n\nIn this story I managed to write dialogue for the first time ever. My way in was to reduce reporting to “said”. I also (again for the first time) started thinking consciously about point of view: the POV character has no insight into what K– is thinking (or doing while she is out of sight), and so neither does the reader.\n\nThe search for another intelligence (December 2017)\n\nBruno had been approached to do background colour for “3,114 B.C. and All That,” an upcoming TV series on the conspiracy theories centred on that year. The dawn of the Mayan calendar; the mysterious construction of Stonehenge. Docu-entertainment. ‘Docu-bullshit,’ he had replied but he took the work. The chance to get closer to TV producers again, that had been why he did it.\n\nOh gosh I like this one. The best of the four.\nThis marks the first time I have ever written fiction in a conscious and deliberate fashion: I had an idea; realised it needed to cross over with an emotional journey so added that; sketched it out in a series of lines; blocked those lines out into scenes; wrote each scene properly; and then revised. It was also the first time I ever managed to write a story over approx. 1,000 words.\nPreviously all my writing has been automatic: wait for the muse, then type until my mind goes too fast for my hands or I need to pee. Great when it works, but a local maximum in terms of quality. My goal in writing with this group is to learn the craft.\nI’m pleased at how the scenes work: I don’t spend excess time getting into them (you know the Wadsworth Constant where you can no-fear skip the first 30% of any YouTube video? I tried to internalise that).  And I tried to finish each on something that would provide impulse to read the following.\nI spent time working on the characters for this one. I have an idea about who Bruno and Hope are, with character notes too. I was brutal with myself about making sure I understood their motivation at every point-and then being rigorous to ensure that every other action was true to that required motivation.\nThe ending is poignant, although maybe a little cheap.\nIt’s also exposition heavy. The story doesn’t work without a ton of explaining. And given that the emotional journey leans heavily on human fundamentals… well, I perhaps should be stretching myself more. Pop songs are always love songs. But there are maybe more interesting anchors.\nStill, it works, and if I would change anything it would be to make it slightly less abrupt in places, and to ease up on the background. As yet I lack the skill to revise (I can tweak words but I haven’t figured out how to have the distance to re-write scenes) but this is one I’ll come back to. \nThe Ursa Major Moving Group (March 2018)\n\nIt happened regularly, thought Ant, this premonition of the end of living, the Grim Reaper’s breath every six months or so, and every time it left Ant untethered and terrified, driven to his studio to use his eyes and use his hands. Twice a year or more he was picked off his feet by who-knows-what and swept up the beach, left gasping when the wave retreated, shivering and exposed.\nAs his own death had become a familiar acquaintance, at some point in the last decade, layered underneath as the swell is beneath the waves, Ant had met something slower and longer, tidal and from beyond the horizon, something entirely deadlier and more final, the echo from the deep future of the end of humanity itself.\n\nGood grief I hated writing this story.\nI had something written in my notes–a pun on an astronomical feature, the Ursa Major Moving Group–and it lodged in me to the point that literally nothing else could get out of my fingers. So this took a month to force out.\nBuilding on the previous stories, I used outlines and characters… but really Ant is the only one I understand. Even he doesn’t have much depth.\nIs it any good? Who the hell knows. I like the first half. The second half–which bounds forward I’m not kidding 10,000 years in nine short scenes-is far, far too dense. This second half is framed almost entirely in a dream, and this was a solution to a particular conundrum. But it doesn’t feel nearly hallucinatory enough to be believable, or have enough story for you to get engaged in it for its own sake.\nThe conundrum was how to reach a particular concluding feeling that Ant has of betrayal, envy, and acceptance. You know, I think it works for that. I’ve been fascinated for a while by the story of Augustus and Caesarion and how it might have actually felt–I’m not quite there, but it’s a rich seam.\nSo what I liked here? There was a certain complicated feeling I wanted to arrive at. Tick.\nVolume Five (May 2018)\n\nAt 3am he woke up with the heavy taste of whisky still in his mouth, cheek stuck to the pillow. Sophie was in the other room, in their bedroom. The flat was quiet. The streetlamp outside shone through the naked window onto the diary left open on the spare room bed.\nIt was the fifth volume. He didn’t remember looking at that. It was open to the page for June 5th, one week from today’s date.\nLeo blinked gummy sleep from his eyes. Where the page should have been blank, there was a single sentence: Leo gets a job.\n\nThis story went up a couple days back so maybe I don’t have the distance… but I’m kinda not a fan, and kinda totally am. It mundane; the characters are one-dimensional; there’s nothing clever about how the narrative works; I wrote it in a rush.\nBut. But there’s an actual story here. It’s not a story that relies on my usual cheap go-tos: huge epiphany; lengthy exposition; plumbing the depths of human agony and/or ecstasy. That was the challenge I set myself-to tell a good old fashioned story with zero frilly bits-and it’s the first time I’ve managed to do that. (Well, actually I wanted to write a ghost story, avoiding sci-fi, and while it’s not quite a ghost story it is in the right direction.)\nTechnically I enjoy the way the scenes move. My sketched outline had more detail, but the final story hides and reveals, hides and reveals, in a way that propels it along. That’s a little bit of craft I’ve picked up from the previous three stories, and it felt easier this time.\nWhat don’t I like? The characters and their motivations could be better understood. The situations could have more texture. Structurally something more exotic could be going on. The emotional journey could wrestle a little with the narrative.\nIn particular, the words could use poetry. My self-set personal challenge has been to steer clear of fancy words. Abandon any and all crutches to force me to concentrate on story and dialogue. I think, over the last year and these four stories, I’ve done that enough… but now I find myself wondering where my voice is and how to reintroduce it. It’s one thing writing blog posts, like this, but I’d love to find the same fluency and style in fiction over which I deliberate.\nEnough with the self congratulatory introspection.\nTL;DR:  I’m enjoying writing again enormously. I feel like I’m learning some lego bricks that with a bunch more practice might one day evolve into actual craft. Hopefully a few people are enjoying reading these stories too.\nHey and let me not take away from the other authors! There are SEVEN of us in the writing group, six who are writing regularly. Check out the whole archive since the reboot. It is legit good shit.\n",
    link: "/home/2018/05/10/property",
  },
  {
    title: "I’m also blogging over at the Job Garden blog",
    date: "10.30, Thursday 28 Jun 2018",
    content:
      "It’s been a little quiet on this site lately. A bunch of my writing energy has been going into weekly posts on the Job Garden blog.\nJob Garden is a new kind of social job board. I started building it because I know a bunch of great startups, and I want to help them with their hiring. It’s a real scratch-my-own-itch kind of thing. Right now on my personal job board there are 38 open roles at 12 companies, and you can check them out here.\nIt’s only 12 weeks old. I try to add something to it every week. So this week: somebody other than me has created a job board. Last week: I launched weekly email updates of new jobs. The week before that, the ability to focus down on just London jobs.\nIt’s super simple (the tech is entirely within my comfort zone), there’s zero visual design, in terms of stage it’s like pre-pre-alpha, and it’s fun to stretch these muscles that haven’t had a workout in a long ol’ while.\nThe weekly posts can be a bit rambly, and occassionally stray into the realm of “half-thought-through opinions about code” which, who knows, might be entirely up your street. \nTo read from the beginning, the blog has a weeknotes categories.\n",
    link: "/home/2018/05/31/upsideclown",
  },
  {
    title: "A pre-history of weeknotes",
    date: "12.46, Tuesday 24 Jul 2018",
    content:
      "The following was originally posted on the Job Garden blog and has since been moved here.\nA pre-history of weeknotes, plus why I write them and perhaps why you should too (Week 16)\nHave a look at the title where it says “Week 16”: there’s a format to these posts. I report and reflect. The format is called weeknotes.\nThere’s a decent-sized community of people who keep weeknotes. Check out Web of Weeknotes which brings together a couple dozen adherents.\nI have a few friends whose weeknotes I always look forward to reading. Tom Armitage does that lovely thing of reporting progress abstractly week by week, using only project codenames, then revealing when the work ships what the codename was so you can connect the dots all the way back. His Week 227 is a good example. With Tom there’s always the joy/risk that halfway the post goes into a rabbit hole of (as in this case) soldering microcontrollers and what it feels like when today you don’t quite have the dexterity. And that kind of perspectival swerve is the fun of reading weeknotes.\nI’m not sure Warren Ellis’ Orbital Operations (subscribe here) counts as weeknotes because it doesn’t self-identify as such and it’s an email newsletter, but unlike most newsletters it shares many of the weeknotes qualities: there’s a weekly rhythm; the spine of each edition is a weekly report of Warren’s work and observations, rather than following the popular newsletter formats of topic-driven essays or link lists; you see projects coalesce from Warren’s musings and interests through to codenames and, later, emerge as comics and Netflix seasons; you get a crazy privileged insight into whatever he’s reflecting on. To pick up on that last point, take this snippet from a recent Orbital Operations email:\n\nI have (checks clock) sixteen days to finish a movie script. This is actually fine. A thing I learned from John Rogers is to write-over. Each stage of the job - beat outline, treatment, screenplay - is built on the other. Copy the rough beat outline into a new document and rewrite and add and expand until it’s a treatment. Copy the treatment into Final Draft and rewrite and add and expand until it’s a screenplay. That way, you only start with a blank piece of paper right at the very start of the process. Every other stage comes with scaffolding and a base coat. Works for prose and comics too. Try it. Just copy the previous document into the next one and start rewriting and adapting it. Might not work for everything, but it might give you a leg up.\n\nInsane. Where else would you hear this kind of report from a ridiculously-accomplished culture-alchemist? Nowhere else, that’s where.\nA third weeknotes-author I look forward to reading is Phil Gyford. Here’s Phil’s w/e 8 July 2018 which bounces between exhibitions attended, and nuggets of things learnt. In this particular edition (?)/episode (?)/transmission, Phil has made an acting showreel and summarises the process in seven bullets - hard-won knowledge generously shared- before ricocheting directly to his uncertainties re his craft:\n\nI’m uncertain about my performance, but we’ll see how it looks. I felt pretty lost and useless, unable to conjure up the required emotions. Maybe my preparation hadn’t been right or enough but, ugh, I felt so dry. Nothing there. An emotionless husk.\n\n(1) Reading: These moments of vulnerability are wonderful to read, and I feel a sudden and greater personal connection with Phil, in addition to feeling less isolated in my own moments of uncertainty.\n(2) Writing: I know from experience that naming and recording these wobbly feelings is valuable because, at some point in the not-too-distant, you come back to your own work and say, “holy shit, that’s amazing, how was I capable of that,” and then you read the historic weeknotes and realise that at the time you were miserable about what you are now delighted by, and closing the loop like that gives you perspective during self-doubt moments in the future.\nI always enjoy and appreciate Phil’s sign-offs. In that one: “I can cry! Wipe your happy tears, and I hope you have a good week.”\nA pre-history of weeknotes\nI wrote the first ever weeknote in August 2009 at BERG and here it is: Week 217. Like anything new, the origin is fuzzier than that.\n\nI thought it’d be interesting to start giving a weekly update here of what we’re up to in the company.\n\nEven in that proto weeknote the format is there already: a little reporting on the life of the business; a little off-road rambling; a single person’s individual perspective; a strong feeling of in medias res.\nThese posts continued for years, eventually rotating round the studio so everyone could (had to…) have a shot in their own particular way. Timo’s posterised video Week 335 is a particular favourite.\nWeeknotes weren’t called weeknotes when I wrote that first one.\nIn September 2009, the following month, Bryan Boyer started writing weekly updates, inspired by that first one at BERG, and finally in November I noticed that Bryan had named them “weeknotes” and so I adopted the tag. A few other studios had also started writing by then. Bryan created weeknotes.com which aggregated these posts. Now gone, it can be found in the Wayback Machine. (Here’s a screenshot from December 2009.)\nAnd then Russell Davies wrote about weeknotes in his monthly Wired column! On the structure of time (May 2010):\n\nWeeknotes detailed what they were up to that week, what had been going well, what hadn’t. They were just blog entries, updated weekly, nothing more remarkable than that. Except they struck a little chord with people - and other companies and individuals started doing the same thing.\nThey seem to have a pattern and rhythm that people like. A few paragraphs about what you’re up to. No need for big insights or revelations, just a bit of sharing and perhaps a moment of reflection. They fit neatly into that globally distributed culture of small creative businesses and people. Individuals and small companies such as these need to share to learn and to find like-minded partners and employees - the Weeknote matches the rhythms of their work, and the blog and RSS are the perfect way to deliver it.\n\nRSS! Remember that?\nAnd:\n\nIt helps to see that other people struggle with deadlines and clients, that big projects can fall apart and still get put back together, that finance is taxing but that this or that software package can help. Above all, it’s nice to realise that everyone else is also just making it up.\n\nAnd we still have weeknotes today.\nWhat about before August 2009?\nI wrote that first weekly update inspired by a blog post that Russell had written two months earlier at Newspaper Club (company previously mentioned in Week 15) which was down the hall at the time. Here it is, Week One. They carried on writing these update posts for a little while, but I think just for the first chapter of the company.\nThe transparency and diary format reminded me of (and this is going to sound slightly weird so apologies for the remainder of this paragraph) The Worst Journey in the World by Apsley Cherry-Garrard, being his retelling from his contemporaneous diaries of his participation in Scott’s 1910 expedition to the Antarctic - often called ill-fated but reading the book much of it was ill-their-own-bloody-faults - which I had read not long before, and which I loved for the adventure and tick-tock unfolding and the meandering thinking-out-loud-ness of it all, and I wanted to write something with a similar sense of road trip.\nAlthough it wasn’t in my head at the time, I have also always been a fanatic of lab books in which you write, each day, what you’ve been up to in the laboratory, recording experiment results, musings, and anything else that occurs relevant or ir-. To prevent retrospective editing, you sign off the pages at the end of each day.\nI have a physics background and enjoyed enormously my time in the lab. You can’t tell, in the middle of an experiment, what will be important. So write down the millilitres of whatnot and the pitch of the diffraction grating and the hypothesis you’re chasing down, but also whether you’ve shaved because there might be crystal seeds in your beard and what the weather is. You don’t know what is important until you’ve had a chance to look back and reflect.\nSo that was where that came from. And if nothing else, it demonstrates the depth of deviousness to which Russell is able to stoop to generate column fodder.\nMy habit at BERG, for some years, was to go to the studio on Saturday mornings and reflect on the week. One of my most rambling, longest, personally-most-enjoyable weeknotes was Week 315 and it came from a morning like that. It’s a series of notes of whatever was on my mind, and word-sketches about studio life.\n\nIdling: They say dreaming is the brain’s way of processing the day’s events and emotions. A necessary process of defragmenting, filing, and letting things come to rest and join up. Idling is a waking dream, time to be with work but not to be working, to let events and activity settle out and resolve, and let ideas and strategy take form in an unforced way. A necessary process.\n\nSo you’ll read some thoughts about attention and risk, plus a record of what I had for dinner. A lab book!\nI try to keep this weekly space for reflection going even now, though it more regularly happens on Fridays.\nOne of my favourite and shortest weeknotes, Week 243:\n\nThis moment, sat on the windowsill with my laptop on my lap, drawing interfaces and technical architectures in red felt tip pen, cutting paper and covering walls, writing rules that will govern us for weeks or more to come, this is the only moment, the legitimacy of kings is written in blood, and this is the reality of life in Scenario 4.\n\nI’m at home right now. We got back from hols on Sunday and yesterday - mod a meeting or two - was a write-off. Today I’m writing about the history of weeknotes in part because there’s no Job Garden software development to report, and mainly to warm up my fingers after the break.\nI was sitting in a caf’e writing and drinking coffee early this morning, although really it’s much too hot for coffee, and I came home to meet a FedEx delivery which in the event arrived early but managed to leave its package anyway, and missed a UPS delivery which I didn’t know was coming and left its package inconveniently about a kilometre away and I’ll go out to fetch that later.\nI also use private weeknotes.\nI have a micro consultancy called Mwie Ltd which stands for Matt Webb Import/Export but Alex DS has decided is - and this is now canon - pronounced mais oui.\nFor the past couple summers I’ve run teams on innovation projects in the Android team at Google. They got weeknotes.\nThe startup accelerator I run (my reflections here) at R/GA Ventures with Lisa Ritchie who is program director: Lisa wrote weeknotes.\nThe per-project weeknotes are a little more structured, sure, but what I like about them is they’re not simply a reporting tool. There’s space to bring up weak signals and also anyone can be added to the distribution list, whether they’re in the project chain of command or simply an interested party. By being open about what’s not yet fully baked, and liberal with the subscription policy, fellow travellers encountered earlier in the project can jump in with opportunistic assistance.\nWhy write these things anyway\nI’ve not been involved in the public weeknotes scene for some time. It’s grown and become its own culture which is delightful (though capped by the general decline in blogging over time, which is a shame but perhaps reversible).\nThis article, The why of weeknotes, captures the motivations well:\n\nAnyway I found these seemingly simple updates a fascinating peak behind the curtain of a design studio that were generally just doing really interesting things but also being open as to the how and why of it all. They regularly (at least early on) were more than status updates and instead provided an interesting narrative. It was a geek serial.\n\nThat’s about reading. The real magic comes in why to write. The article continues:\n\nmost obviously they are an amazing aide memoir\n\nAnd it also cites (I summarise):\na regular check intostate of mind; finding, within an organisation, “new stealth readers in leadership or HR type roles”; sharing problems; providing a conversation starter.\nThat last one is a biggie. I think of blogs like a green “available” light on Skype. I’m here, alive, and ready to chat!\nFor me, keeping weeknotes while I’m building and thinking about Job Garden, there’s another benefit in that I’m relying on compound interest to develop this product. I’m not doing much each week, but if I take a step every week, I should get somewhere. That’s the theory. In practice, in the middle of events, when you’ve left the near shore and the far shore is not yet visible, progress can be hard to discern and energy harder to find. So the passing mile markers of weeknotes give me some kind of reassurance.\nI’m seeing more people starting weeknotes recently: Public Digital has a weeknotes category, started May of this year. Better Work Lab is today up to Week 26. Good.\nHowever the weeknotes format has evolved, I think three qualities endure:\n\nsome kind of rhythm. Obviously. Weekly? Probably. Possibly. Aspirationally anyway.\na feeling of being in the middle of things. The rhythm helps with that: a regular sampling frequency means you don’t just report on projects and ideas when they’re finished, which is the normal temptation. Benefit: the “work in progress” feeling encourages others to jump in.\nwritten by an individual. The person with the conch might change week to week, but in my view the single perspective is vital. Individuals have fully rounded interests: yes this person is reporting on projects, but they’re also alive with feelings, and oh by the way they’ve also gone out and got ice creams for the office because it was hot this week.\n\nI’ll add a last: the joy of weeknotes is just as much in the writing as the reading. If marketing happens too that’s a happy side-effect.\nBut honestly, there’s no dogma. Everyone has their own style.\nHave some downtempo new wave synth pop.\nIf you start writing weeknotes because of this post, let me know.\nThat’s all. Keep on, I guess.\n",
    link: "/home/2018/06/28/job_garden_blog",
  },
  {
    title:
      "What has the EU ever done for us? Some thoughts on a new mapping project",
    date: "16.30, Tuesday 11 Sep 2018",
    content:
      "There’s a new project being shared round today that maps EU-funded projects in the UK: here it is. It’s easy to use and very interesting to find out, for example, what projects have been funded in my home town.\nKudos to the folks who built it. Creating sites like this is hard work, and a vital part of the national discussion about the EU.\nSo for transparency (which is a good thing) I’m hugely in favour of this.\nBut in terms of what I think about the EU funding itself, I’m not so sure. The strapline for the site is What has the EU done for your area? and while in one sense that’s true, it makes me think: but this was the UK’s money to begin with, right?\nLooking at the breakdown of the EU membership fee, the UK paid £13.1bn into the EU budget in 2016, and received back £5.5bn in various forms of funding (£4.5bn channeled through the public sector, and approx. £1bn direct to the private sector). So the first thing the mapping project highlights is that the UK pays more to the EU than it “gets back.”\nThat purely budgetary framing makes me uncomfortable. Should we really be looking at what we “get back” from the EU in terms of project funding? How do we value reduced friction to trade (and associated economic boost), the reduction in defence and diplomatic spending (by being part of a bloc), the cultural benefits of having a stronger voice on the world stage, etc.\nWhat this mapping project also highlights is, well, should the EU be choosing how this money is spent at all? When money is spent directly by the UK government there is a certain amount of democratic accountability. I know who I can complain to, I know how I can try to influence the spending criteria, and I can campaign to vote out the people ultimately responsible if I really disagree.\nBut for EU spending? It’s more abstract. When I see this map of EU spending in the UK, what it makes me ask is why the UK government isn’t in charge of it. That same discomfort was, of course, a reason why people voted for Brexit in the 2016 referendum. Although if the UK government controlled the spending, that doesn’t imply that it could all go the NHS instead–regardless of what was written on the side of a bus–as many of these projects are vital for our agriculture, regional growth, jobs, and industrial strategy, and you wouldn’t want to stop them. So leaving the EU wouldn’t mean we’d get this money “back” in the national budget by any means.\nNow, on balance, I believe Brexit is a bad idea. The UK’s contribution to the EU is only 2% of our total national budget and, as I said, the “non-spending” benefits of EU membership matter significantly, and many of these projects would be funded anyhow.\nBut I’m not an unequivocal booster of everything the EU does. This mapping project is fixing a huge lack of transparency. The level of democratic accountability worries me: how do we know that all of these projects are within the mandate that we’ve given to the EU under the treaties, and how can we influence the allocations? I happen to believe that these problems are addressable as a member of the EU. (And to be honest, the same concerns could be levelled at the UK government about the project grants we do control.)\nSo while I’m pleased (and relieved) that this spending is broadly sensible, I’m not sure it should be waved around as “hey look at all this awesome stuff we’re getting from the EU.” I don’t think that’s the case it makes at all.\n–\nMy brand of weight-it-all-up ambivalence doesn’t play particularly well in this era of hyper-shareable Facebook posts and 24 hour news cycle sound bites.\nHowever it’s by taking into account evidence like this that I’m able to say with increasing confidence that Brexit doesn’t add up. I look at what’s going on, consider alternatives, and… well, the Brexit options currently on the table look terrible, and the impending exit day of 2019 (which occurs well ahead of any trade deal being done) is so close with so little certainty around which to prepare that I fear a lot of damage and hurt will result.\nIt’s also this kind of easy-to-read evidence that we were lacking in the 2016 referendum, which is why I don’t think anyone (however they voted) really knew enough to make an informed decision, and why it’s perfectly ok to revisit the issue now and have a re-think before it’s too late. Given the circumstances it’s ok to change your mind.\nThat mapping project again: myeu.uk. More like this please!\n",
    link: "/home/2018/07/24/weeknotes",
  },
  {
    title: "Hardware-ish coffee morning, Weds 5th",
    date: "12.55, Monday 3 Jul 2017",
    content:
      "dink dink is this thing on\nMY DEAREST DROOGS:\nI hereby announce that I have been really busy all of 2017 so far and therefore there has been no hardware-ish coffee morning yet. So we’re just going to write off the first half of the year. Just like that. Done.\nWednesday 5 July, 9.30am for a couple of hours, at the Book Club, 100 Leonard St.\nWhat is a hardware-ish coffee morning? I barely remember, we’ll have to make it up. As far as I remember: No intros, no presentations. We take over a corner at a handy cafe and seriously talk to EVERYONE it’s worth it. Bring prototypes if you have em, and if you don’t then your good self is enough… We’ve had manufacturers, hardware startups, product-curious agency folks, a baby or two, diletantes and job hunters. Chatty chat chat.\nMight be 5 people, might be 25, might be just me and my email. I’m betting on 12 people and you should believe me because I won £11.80 on there being a hung parliament and £15 on Trump getting in so I’ve got form. Feel especially welcome if you are NOT A DUDE because it’s weird if it’s tons of dudes.\nAnything else? Don’t think so. My blog was broken but I fixed it just to post this. See you on the 5th.\n(As previously posted to the coffee morning announce list.)\nUpdate:\nA great turnout this morning! People who signed the register were Ed and Antton from Flock (pay-as-you-fly insurance for drones), Markus and Alex from product development and production firm RPD, Abigail and David of digital product agency Pixie Labs, and Kaye and Richard of crowdfunding launch assist agency Paved With Gold. It wasn’t all people doubling up. Some came along on their lonesome: brilliant to see Tom E from parenting hardware startup BleepBleeps with a production-run version of his new product (and a prototype of the next one), Tom A fresh from launching his DIY musical instruments project Foxfield, Tamar from Soda which is doing exciting things in retail and launching a concession in Selfridges (!!), plus Dan, Phil, and most importantly Deb who prompted this coffee morning reboot! _(And I wonder whether this will prompt a reboot of her email newsletter Metafoundry…) _\nThanks for coming y’all!\nToo many conversations to keep up with, but my particular morning included Snapchat Spectacles, how to keep time ring-fenced to contemplate the future, the pros and cons of showrooming, and Jeremy Bentham’s head.\n",
    link: "/home/2018/09/11/eu_project_map",
  },
  {
    title: "Two positive signals for the Smart Home",
    date: "10.58, Wednesday 16 Aug 2017",
    content:
      "I’m bullish on the Smart Home, and as someone with a professional interest in the Internet of Things who was consumer-IoT-shy this time last year, I’ve been thinking about what changed my mind.\nThis isn’t a whitepaper, or a even a properly considered analysis: just some notes about where my head’s at and what I’m looking at. I’d appreciate feedback — both supporting points (especially pointers to UK startups who are taking advantage of these trends) and counter-examples. If I’m off-base I’d like to know!\nOver the last couple years, the Smart Home has been getting a bad rap. Connected consumer products suffer for a bunch of reasons, including but not inclusively:\n\nthe sane products aren’t worth the money. Features for this generation of products are generally iterative not transformative: is it useful to remote-check your slower cooker. Sure. But at 5x the price, with the cognitive overhead of apps for everyone in the family, etc? Not so much. Many of the benefits become clear when there’s a critical mass of products that can orchestrate and learn from one another\nthe category-busting products aren’t acceptable in the market. Consumer behaviour is hard to shift, both for features and also for the business models required for connected hardware. Look at the outrage when a software application goes subscription-only; now think of how a subscription washing machine would go down\nthe barriers to entry are too high when you combine hardware and software. Shifting consumer behaviour is possible… but it takes a lot of experimentation on both ends. Hard to do when hardware is so expensive in small batch production, especially for a startup\n\nAll of that said, this year I’m getting excited about consumer Internet of Things again. There are a few trends that make it easier for the Smart Home to get out its slump, such as the ever-increasing acceptability of e-commerce and direct sales, which reclaims the retailer margin.\nBut two signals in particular.\nThe smart home platforms have finally given up their fight to own it all\nThe first signal is smart lighting from Ikea which both fulfils the promise of a low-cost modular system, and also has sane interaction design (that is: it includes physical controls and works when the internet is absent).\nMore importantly it works with a gamut of Smart Home controls: Apple HomeKit, Google Assistant, and Amazon Alexa. This tells me that the GAFA stacks (aside: where is Facebook in the Smart Home?) have given up on their unrealistic desire to treat the home as a monolithic own-able platform. The layers are emerging: it will soon be possible for a startup to innovate on a new type of bulb without having to also break into the service layer (and yes, I’ve met companies with internet-connected bulbs showing a 10x life at comparable cost. Being able to plug-and-play HomeKit, Assistant, and Alexa would be a godsend for them).\nAt the service layer, it should also become possible to innovate on software and orchestration between devices: I look forward to services that are able to plug in to a smart home from a mix of manufacturers, providing highly specific and differentiated functionality. I think voice has a part to play here: it’s the excuse we’ve been looking for to put our phones down at home.\nInterop is good news: more ways in for startups, more places to innovate, and better value for consumers.\nReference designs lower the barrier to innovating on features\nThe second signal is also a healthy emerging fracture point in the connected hardware stack: Qualcomm’s reference designs, including this speaker platform. Reference designs allow for some interesting manufacturer efficiencies. A small company can go and ask for a customised version of this product, benefiting from a supply chain shared with other small companies, and with engineering costs amortised across the same.\nThe reference design linked above is for a smart speaker. A speaker is no longer just a speaker: it’s a speaker with directional microphones, a wi-fi connection to a cloud somewhere, and enough on-board GPU to run a voice assistant, whether that’s from Apple or Google. I’m interested to see what the equivalent reference designs are for a smart screen, smart doorlock, smart book, and so on.\nIf these appear, it will show that the consumer categories for smart products are stabilising. Categories are useful because they allow the rest of the industry to align: retail buyers can set up aisles; marketing educates the consumer; it becomes worthwhile for distributors to do their thing. With a baseline of many products in the same category, it becomes possible to experiment.\nCritically reference designs provide an entry point to startups that lets them mimic Apple’s business model: hardware differentiated by software. To date this has been inaccessible to startups because hardware development is a huge barrier to overcome before service innovation can begin (not to mention the challenge of distribution). The table stakes are, happily, coming down.\nOverall the Internet of Things is going to see an interesting few years. The digital world has seen rapid change: Blockchain, A.I. (in a thousand forms), and next generation interfaces too: voice and augmented reality. The recently stabilised IoT tech stack is pretty solid: digital dividends should be coming into the real world much faster than before.\nAnd then, maybe, finally, we’ll start seeing those category-busting transformative products that we’ve been waiting for.\n",
    link: "/home/2017/07/03/hardwareish",
  },
  {
    title:
      "A few technical words about Upsideclown, and some thoughts about audiences and the web",
    date: "10.07, Thursday 17 Aug 2017",
    content:
      "I also write stories over at Upsideclown, which is both a website and a small writing group. Well I should be careful about the present tense: I wrote there between 2000 and 2003, and I shortly will again. We recently resumed after a 14 year hiatus.\nFirst time round we published twice a week. There are a ton of stories! We had a party for our readers! We self-published a book! Which back then was hard. I had to do layout in Quark and install a special printer driver that would send pages to a printing firm in Tennessee which could do short-run binding. Taking payments online to sell books was, well, I think we ended up mostly doing cash.\nThis time round it’s lower-key: we’re publishing once every two weeks. It’s the same group of seven, so each of us comes round every three months and some. I’m enjoying seeing how our writing has changed and also how it hasn’t. \nUpsideclown is old-fashioned I suppose. I started it as an excuse to keep in touch with friends from uni. It’s me, plus Dan, George, Jamie, James, Neil, and Vic. And it’s mostly about that plus of sprinkling of some useful pressure to keep my hand in writing fiction. It’s not the central purpose but it’s always nice to have readers so I do a little light promotion too. (Subscribe to the newsletter!)\nIt feels transgressive to have a website in 2017. Something about having a domain name and about coding HTML which is against the grain now. It’s something big companies do, not small groups. We’re supposed to put our content on Facebook or Medium, or keep our publishing to an email newsletter. But a website?\nTechnical details\nResuming 17 years after starting gives you a glimpse of the long now of the web.\nThere are pages I made - the first stories - that I haven’t touched in almost two decades and they still work. Web-world that’s pretty rare. They’ve outlasted most places that encourage you to host their content with them, and even the popularity curve of many programming languages and web frameworks. Database technologies have come and gone.\nAnd then there’s my own attention and ability… I no longer program for a living as I did when Upsideclown started. I keep in touch and still make the odd thing, but I’ve forgotten a ton. So I have a philosophy around choosing what tech to use when I’m building this stuff: will I be able to fix it, half drunk, ten years after I’ve lost all the tooling.\nOn the design side I’m pleased that when the design changed, I made sure the old stories kept the old design when the newer ones picked up the new one. Design changes meaning. A story would mean something else if I retroactively put it in a classy frame, or a punk frame, or added highlights.\nSo it’s all about longevity and data. I rewrote everything for the reboot and here’s how it works now:\nNew Upsideclown stories are stored in Markdown because it’s a simple format and, in another decade, when I’ve forgotten everything I know, I’ll be able to tell what I meant just by looking at it. Here’s Neil’s recent story as published. Here it is in the Markdown “source” format. No databases, it’s all files. \nRendering is in PHP. Old school I know, but it’s a language which has stood the test of time, and I can go from a standing start (seriously I hadn’t coded with it for ten years) to a functional and decent looking site in a leisurely weekend. So if I need to rewrite I know I can. I’m not planning to: unless some burning desire strikes, not until 2034 at the earliest. It’s served with Apache, no app engine. I figure web servers will be around for the duration.\n(I have the same approach with my blog: posts are text files and go back to February 2000. The publishing engine I’ve rewritten a few times.)\nThe reason the stories aren’t kept in HTML is so I can publish out to other formats: there’s an RSS version that is picked up by Mailchimp so readers can subscribe to the newsletter. The archive is dynamically generated. \nI’m looking at whether to also generate Facebook Instant Articles and Google AMP, perhaps plug into Apple News too.\nPeople don’t visit or link to websites like they used to.\nYou gotta fish where the fish are.\nBut you also want to be able to look back on what you’ve created once you’ve retired. So it’s a balance.\nHow web publishing has changed\nI knew that publishing to the web was out of fashion. What I hadn’t realised was how much the tools had eroded. Or rather, two things: if you want to know how many people have read your stories, and where they came from, then (a) the analytics tools haven’t kept up with how and where people read; and, (b) the analytics tools are made for big companies optimising the flow of audiences down funnels to achieve particular goals. Not for small, independent publishers.\nHere’s an example. There’s no simple online tool that lets me add up how many people have read a particular story on Upsideclown via the website, the RSS feed, and the email newsletter. Why not? If I add syndication to Facebook, Google, and Apple, I’m even more at sea.\nThis isn’t because I want to optimise an audience; this isn’t because I want to sell ads. This is because it’s nice to know that 17 people read the website and 21 people opened the newsletter, and 36 people read the same story on Facebook, and 6 in an RSS reader – and gosh that’s like the whole top level of a double decker bus, all those people read my story! When companies deal with millions and billions, I think perhaps they forget how the intimate feels. How sometimes it’s not about a thousand retweets but instead about an audience of readers who come back. With whom you have a relationship. Who appreciate you, and you appreciate them. Yes it’s a pleasure to write, and yes I will do it without needing to get 1,000 likes on each and every story, but also let’s not forget that it’s more pleasant with company.\nThese likes, faves, and claps are cold. No wonder we need so many of them to feel sated. Instead I’d like to look at the depth and duration of meaningful relationships, and to share that with my fellow authors. I know analytics feels like a dirty word in this context, tarred as it is with A/B testing and e-commerce flows, but there’s a joy to be had in being on stage and seeing the faces of your audience — rapt. The erosion of tools for modern online publishing has, bizarrely, made the intimate audience invisible. What can we count so that we’re over the moon when there’s twenty of it? And simultaneously I’d like to make it easy for readers to read wherever they are, whether that’s the web, Facebook, email, or whatever. I can handle that last bit but Google Analytics doesn’t help me with the former. Nor does Medium.\nNot without budging on my desire to make pages which I can still read in 2034, anyway. It seems to me that, sometime in the last 17 years, the web forgot the simple pleasure of making, and appreciating what’s made, together.\n",
    link: "/home/2017/08/16/smart_home",
  },
  {
    title: "Gratitude and a possibly inappropriate technological intervention",
    date: "11.55, Friday 25 Aug 2017",
    content:
      "I was reading Melanie Klein’s Envy and Gratitude and Other Works (which I still haven’t finished) and there’s something about Kleinian gratitude which is crucial in developing the primal relationship between mother (the good object) and child. It is also the basis for the child perceiving goodness in others and herself.\nConscious gratitude seems to be more focused on the other, rather than a self-centred idea of being the cause of goodness or its reverse. Developing gratitude might allow for greater capacity for appreciation, acceptance, and the sharing of love.\nGratitude is inherently outwards looking. And surprisingly hard! It touches all kinds of other feelings like deservedness, and is easily corrupted  with responses like entitlement.\nSo I was thinking: a habit of gratitude would be an interesting thing to foster. Gratitude being a component of prayer, I know, but I don’t pray. So. I need to get it somewhere else.\nAnyway.\nWe can fix this with technology. I know, I know. Forgive me.\nWhat I do is I have a folder in Ulysses, which is a writing app I have on my iPhone (and I use for everything). The folder is called: What I Am Grateful For.\nPlease also forgive the ugly dangling preposition. It upsets me too.\nIn that folder are tons of notes. Each note has a date, and a line of text: the thing I am grateful for that day. Sometimes big, mostly small. Sometimes easy to observe, sometimes really, really difficult. Always interesting to note when I’m going through a phase in which gratitude is a challenge to attain, and with what that correlates.\nBack to the tech.\nOnce a day, at midday, I get a notification which says “What are you grateful for today?” I tap the notification, and a text box opens up on my phone. I type into the text box and it gets saved into the folder.\nHere’s how that bit of automation works:\n\nI use an app called Workflow which links together different apps and lets you program them in a flowchart sort of way\nI’ve written a particular workflow called “Grateful Daily” that does all the work of opening the text input box and saving it to Ulysses. You can get the workflow here. If you copy the workflow, you’ll have to update the special Ulysses code bit to make sure it saves to the right folder\nAnother app called Launch Center Pro is able to trigger workflows on a timer. I have it set to run Grateful Daily at midday\n\nCross-app automation is a nascent but interesting area. I’m finding myself able to do pretty complex workflows from my phone now (I also have a process to edit and deploy code, using multiple different apps). It’s got a way to go as a pattern of user behaviour, but I’d like to see iOS or Android take automation more seriously. To see where it could go. It has a different nature to automation on PCs, and I think there’s the opportunity for these automation scripts to unbind from the smartphone and move into the cloud (somehow). Maybe use a bit more intelligence too. Centaur automation.\nYeah but so: gratitude.\nTo receive - and to be open to receiving! - something which is good, and to take in that goodness and to internalise it, but to also appreciate the goodness itself, and its source and the source’s reasons. A tricky business.\nI don’t even pretend to have even half a handhold on Klein, or Kleinian gratitude, or hell even gratitude, but her words opened something in me. (Thanks!)\n",
    link: "/home/2017/08/17/upsideclown",
  },
  {
    title: "What Blade Runner is about, and the Narcissist Creator Razor",
    date: "22.35, Friday 1 Sep 2017",
    content:
      "Everyone has a pet theory about Blade Runner, and I want to tell you mine. Spoiler: Blade Runner is about Blade Runner. Or rather, it’s about creating Blade Runner. I reckon many films and books make more sense seen this way: creatives are narcissists, and creative works are commentaries on the act of creation.\nStar Wars\nOk. Let’s start with an easy one. In Star Wars, what is the Force? This 2005 article in Slate hits the nail on the head:\n\nthe characters come to understand that there is another agent, external to themselves, that is dictating the action. Within the films’ fiction, that force is called … er, “the Force.” It’s the Force that makes Anakin win the pod race so that he can get off Tatooine and become a Jedi and set all the other events in all of the other films in motion. We learn that Anakin’s birth, fall, redemption, and death are required to “bring balance to the Force” and, not coincidentally, to give the story its dramatic shape.\n\nThere’s a tension for an author between doing what the characters and internal logic of the universe demand, and doing what the reader or viewer demands: moving the story forward, keeping attention through cliffhangers and long story arcs, surprising but not subverting the genre, and so on. It’s a balance.\nAt its worst, when plot beats sense, blunders are easily observed as called out as “deus ex machina” and MacGuffins. At best, the story feels completely natural. \nI’ve read that Pixar consider three foundational elements, and each has to make sense in the context of the previous: the world, then the characters, then the narrative. If there is trouble resolving the story, the characters (or even the world) may have to change. This loopback is how the eventual whole feels so complete, immersive and organic.\nThat Star Wars article continues:\nThe Force is, in other words, a metaphor for, or figuration of, the demands of narrative. The Force is the power of plot.\nThe Force is another way of bridging the needs of the world and the needs of the narrative: it’s an in-fiction concretisation of the gap itself. The relationship between the characters and the Force - that is, the prophecies and the balance - is an examination by the author into this gap.\n2001: A Space Odyssey\nThe monolith in 2001 is, like the Force, a catalytic agent: it turns the apes into humans, and takes modern day humans through another evolution and brings about the Star Child.\nAs has been pointed out, the monolith is the cinema screen, and this idea has been well explored. The proportions are the same; it transforms the in-fiction characters just as it mysteriously transforms the audience.\n\nSo in the films opening and during the intermission, we are not looking at an empty black screen at all. We are looking directly at the surface of the monolith! The monolith is the film screen and it is singing directly at its audience in the same way that the apes and astronauts are entranced by its heavenly voice, not realising that they are being communicated with directly\n\nBut for me, 2001 (the movie) is an exploration of the relationship between the director and the audience, with the in-world characters making the examination by glimpsing, from their side, this boundary: the screen/monolith.\nThere’s the famous shot of the aligned planets: this conjunction only makes sense from the perspective of the viewer, but there’s no viewer present in space at this point… except, suddenly, the audience. So the audience is forcibly inserted; given a location in the in-world universe.\nThe boundaries are blurred again when a shot on the Moon brings the monolith (as Tycho Magnetic Anomaly One) - black, indistinguishable from the dark room of the cinema - from the edge of the screen, again pulling the audience’s environment into the film. An equivalent is made between the audience’s world and the agent of change in the in-fiction world.\nWhich is of course true: the fiction-world only lives while the film plays, while the literal film is projected. The characters reaction to the embodiment of that (the monolith) is as spiritual and ineffable as ours would be, encountering our own agent of reality.\nArrival\nSticking with science fiction, Arrival (2016) - which is a gorgeous, beautifully paced movie, and you should definitely see it - gets into playing with time.\nSpoilers, obviously, so let me summarise: aliens land, and their language is somehow outside time. They apprehend the past and future as one, fitting together into a cohesive whole. A human - a woman - learning their language, finds she can now do the same. \nAs a film this makes a cracking story. As the short story on which it was based (Story of Your Life, by Ted Chiang) it’s a classic. The story of the title is both the in-fiction story of the woman’s daughter, and the short story in the reader’s hand. The alien’s ability to apprehend all of time at once (but also be within it, yet without the capacity to change what happens) is the reader’s perspective too.\nChiang is using his protagonist as an agent to examine whether it’s possible to break through from the inner reality of the fiction to the outer reality of the reader.\nGreg Egan\nThis section is kinda obscure, so feel free to skip. But before you do: you should read these Egan novels because otherwise you’ll be missing some of the best, most robust hard sci-fi of the late 1990s/early 2000s. \nGreg Egan is an Australian author and computer programmer. The kind of author who, when he invents in a story a game called quantum soccer where the players move a ball which is a quantum mechanical probabilistic wave function, and scoring a goal means manipulating the probability of the “ball” such that it is (probably) in one of the goals, he then goes ahead and builds a simulation of the game playable on his website. The kind of author who works out the equations for a rock in orbit around a black hole, and then has to invent new words to describe new directions because space gets all mixed up under the extreme regime of general relativity. \nThree of his early novels are investigations of what it means to be human, and how human-ness is conserved across greater and greater extreme translations from the flesh and the everyday. For me these three sit together as a trilogy: Permutation City, Schild’s Ladder, and Diaspora. They’re surprisingly easy reading, and have that magical characteristic of boiling frog gentle escalation where every single step makes individual sense but you look behind you at the end and all you can say is “holy shit how did we end up here.” (Like Apocalypse Now where you get to the end and all you can think was, hang on weren’t we just surfing.)\nThis is only going to make sense if you’ve read them, but my contention is that each book is about the characters of the inner reality probing and attempting to understand the outer reality. And the outer reality, in this case, is not only the reader’s world, but the actual physical book in the reader’s hands, paper pages and all.\nConsider: \n\nIn Permutation City, the demonstration that intelligence is shown, in the inner reality, to be robust against the shuffling of time (or: the reader or author jumping between pages) \nIn Diaspora, that life is equivalent regardless of the in-fiction substrate, and consider also the characteristics of movement between universes: movement is easier forward than backwards, and in-fiction life can even be spread in static slices across too many universes to count, time advancing with each universe crossed. Universes being pages, of course.\nIn Schild’s Ladder, the bubble universe is a representation of the book itself: when the characters encounter it, the frontier is so wide the edges can’t be seen. Yet, tunnelling into it, it forms layers that are extremely thin. It’s as if the characters had become able to see themselves on the flatland of the page, and found themselves able to tunnel through pages (layers of the bubble universe) along with the reader reading.\n\nIf our own universe was actually a book, that was written, isn’t this how we would attempt to understand the outer reality – piecemeal, and never completely? In fact, with our enormous particle colliders and speculation about the universe being a holographic projection of a pattern on a bubble surface, and trying to find ways we might test that, isn’t that what’s happening now?\nRosencrantz and Guildenstern Are Dead\nIn fiction, there are three times. The time of the inner reality, of the fiction, of the characters. The time of the reader or audience. And the time of the author. These times don’t only vary in pace, but may be ordered differently. They may repeat, or not. They have differing agency over what is real.\nThis is fertile ground for exploration.\nTom Stoppard’s play Rosencrantz and Guildenstern Are Dead follows two minor characters from Shakespeare’s Hamlet, between scenes and interleaving the original Hamlet itself.\nIt opens with the two characters asking themselves whether they are doomed to have the same conversation again and again. Well yes, they do in the play. But they do in another sense, in the outer reality, because the play has a nightly performance.\nThey ask each other whether they remember what happened before. Was there a before? For the character, kinda: the character has a memory and a backstory, but if the audience didn’t see it, did it really happen? And there is definitely a “before” for the actor playing the character.\nWe’ll come back to Ros and Guild. They’re replicants.\nHamlet\nSo Stoppard’s play is a play exploring what it means to be a play. It’s built on good source material: Shakespeare was exploring the same ideas with Hamlet.\nFirst, yes, the famous play within a play at the heart of Hamlet. A recursion like the monolith representing the cinema screen being shown on the screen.\nSecondly, and mainly, the ghost.\nHamlet is a clever, wonderful, tightly told, and above all realistic play. The story unfolds from the internal drives of, and feelings between, the characters. There are few coincidences, no deus ex machina. It’s insightful and subtle, and derives from details in the depths of the human condition. It feels true. \nBut at the beginning - the domino that kicks off the whole sequence of events - there is the ghost of Hamlet’s father. You what? This isn’t just Prince Hamlet’s wild imagination. The guards see the ghost too. This is, right upfront in an obstinately real story, the presence of the supernatural, driving the narrative.\nSounds like the Force.\nAnd, get this: According to oral tradition, the Ghost was originally played by Shakespeare himself.\nHow’s that for a statement on how the inner reality relates to the author from the outer reality!\nBack to Blade Runner\nThe ambiguity about Blade Runner is whether Deckard, the replicant hunter, is himself a replicant. Are his memories real, or has he been instantiated with a remembered past borrowed from elsewhere; will he - like other replicants - live only for a brief time, just four years? Or is he human?\nThere’s a solid theory that Deckard is a replicant with Gaff’s memories. Gaff being a detective who makes origami that mysteriously mirrors Deckard’s dreams, indicating that he has special access to Deckard’s inner life.\nWhat makes the Blade Runner ambiguity so delicious is that in the released 1982 theatrical cut, Deckard’s replicant identity is ambiguous. In the later director’s cut, all the hints are inserted. We get to choose, and the fact that it’s still debated which the “true” cut is (the one with the bigger audience? Or the one the director wanted us to see?) enlarges the ambiguity to ask who gets to determine reality.\nBut what happens if we apply the Narcissist Creator Razor? The answer becomes that Blade Runner is simply about the act of making Blade Runner. The fictional inner reality isn’t about the story, it’s about the reality of the maker. And what is that reality? This:\nThe reality of Blade Runner is this: Deckard isn’t a human, and Deckard isn’t a replicant. Deckard is a sequence of recorded images of Harrison Ford saying lines written by someone else. The story is an exploration of that fact.\nReplicants are characters\nHere’s Aaron Sorkin (screenwriter of the West Wing, A Few Good Men, and much more) talking about characters and backstory:\n\nYour character, assuming your character is 50 years old, was never six years old, or seven years old or eight years old. Your character was born the moment the curtain goes up, the moment the movie begins, the moment the television show begins, and your character dies as soon as it’s over. … Characters and people aren’t the same thing. They only look alike.\n\nThat’s what’s being explored in Blade Runner. Characters look like people, except they exist for only the duration of a movie – only while they are necessary. They come with backstory and memories fully established but never experienced, partly fabricated for the job and partly drawn from real people known by the screenwriter. At the end, they vanish, like tears in rain.\nLike Rosencrantz and Guildenstern. Like replicants.\nRoy knows he is a replicant. He’s the one who comes closest to understanding his true nature: that his memories were given to him, that when the short span of the film passes he’ll be gone. He’s coming to terms with his emotions about this in a short period - his journey as a replicant but also as a character in a film - in a way that no one else does. The Off-World Colonies - Roy’s point of origin and source of memories but never seen - are a stand-in for the inaccessible outer reality of the creator.\nDeckard is a character. Roy is a character. Gaff is a character.\nSo that’s what Blade Runner is about, for me: it’s an examination of what it means to be a character. It’s a creator using their creation to examine the nature of that creation.\n(This is also why I don’t like the idea of the Blade Runner sequel. It risks the delicate balance of audience vs creator, and inner vs outer reality, and I think we might lose access to a very interesting place because of that.)\nI am aware, by the way, that proposing a totalising general theory of all creative work is an utterly ludicrous thing to do. But to hedge the above appropriately would have added too many words, and this is long enough already.\n",
    link: "/home/2017/08/25/gratitude",
  },
  {
    title:
      "With GE and Juicero, the Internet of Things world has taken a battering this week",
    date: "12.15, Wednesday 6 Sep 2017",
    content:
      "It’s been a rough week for business and the Internet of Things.\nIndustrial IoT\nOn the industrial IoT end of things, GE - which has bet on “digital industrial” in a big way - has scaled back its target revenue in this space from $15 billion in 2020 to $12 billion. With industrial IoT we’re talking applications like remote monitoring of wind turbines, improved construction equipment utilisation, and smart power grids. \nEven GE’s adjusted numbers are massive, but as Stacey Higgenbotham’s analysis explains, the adjustment shows that industrial IoT isn’t a problem that can be tackled as a horizontal platform play. She gives a couple of related examples, including\n\nSamsara, a startup that formed in 2015, aimed to build a wide-scale industrial IoT platform that started with generic sensors. It has since narrowed its focus to fleet monitoring and cold-chain assurance, which is how some of the earliest users of its product used it.\n\nFor me, this is a healthy shift. The technology behind the sharp, physical end of the Internet of Things is stabilising but still in flux. And I mean everything: data centres, connectivity, monitoring tools, security, provisioning standards, and so on. For a company like GE, building platforms in a fast-changing platform ecosystem is a long way from core competency, and not a good place to be.\nInstead, as I’ve said before, focus on applications. Provide real business value with whatever platform tools are at hand, and leave room to hop technology as and when.\nConsumer IoT\nWidely mocked startup Juicero is shutting down. Juicero raised $120MM to sell a $400 home juicer. Not any fruit; only proprietary Juicero packets. Using IoT technology to keep the consumer channel open, the projected lifetime value must have been enticing to investors. But the product made a number of missteps: a little too keen to tap that recurring revenue, it wouldn’t work without wi-fi.\nDespite this news, I remain convinced that\n\nthe smart home is interesting again now the platform wars are over\nconnected products should be seen as channels open for constant communication between the brand and consumer: in the future, all FMCG brands will be like Nespresso\n\nHowever, we can take some lessons.\nIf the Juicero juicer is really a channel, not a product per se, shouldn’t it have been managed by a brand strategist – someone sensitive to the latent meaning of the product features (and anti-features) for the audience, and their impact? My hunch is that, with just a couple of small changes, Juicero would have felt high-value rather than money-grubbing.\nMarketing matters!\n(And if you need to be convinced, read Russell Davies on the iPhone TV ads and his concept of pre-experience design.)\nWith my startup hat on, I can see the reason to charge for the machine. For the consumer however it’s simply paying to have the privilege of paying more. There’s an equitable balance to be found, I’m sure, but maybe this the best it gets for business models in consumer IoT: there are nice businesses to be built (maybe even at scale like Nespresso), but they will always be a hard slog and never have the margins of a pure software play.\nBut but but. I remain positive:\nAs the Reverend of Revenue  says, profitability means you can own your own destiny. Could Juicero have sought to build a business that worked small and allowed it to fund its own growth? And on that platform, for hardware startups, could there be discovered the scale of the non-hardware Silicon Valley-style startups? That was the Amazon playbook, after all.\nEnterprise IoT\nThe ideal business model for consumer IoT remains elusive. \nI ran the R/GA IoT Venture Studio earlier this year centred around what we dubbed Enterprise IoT, that sweet-spot which offers real business value like industrial IoT, but with the productised scalability - and faster route to market - of consumer.\nThe native business model of Enterprise IoT is hardware-enabled SaaS. The software-as-a-service mindset is cribbed from the online world, and it’s not just a pricing model but a whole set of techniques about marketing, pricing, metrics, and growth. It’s neat because it means recurring revenue, and that matches the cadence of the recurring operating costs necessary for these kind of server-heavy data businesses.\nWhat “hardware-enabled” means is that although the hardware is necessary (it’s a sensor, or a camera, or whatever), it’s not core. It can be commodity. To take two examples from the recent Venture Studio, we worked with Winnow which is enabled with a smart food waste bin in the commercial kitchen, but provides ongoing value (and charges monthly for) the intelligence that produces. And Hoxton Analytics which monitors pedestrian footfall using machine learning. It uses commodity web-connected cameras (from Cisco) but, again, is primarily a data play providing ongoing value.\nI’ve seen close-up how these hardware startups are able to focus on their true differentiation – which isn’t the hardware.\nAnother benefit of this model is that these startups have customer retention literally bolted to the wall, yet they’re able to sidestep the friction and risk of custom hardware development and batch production.\nBack to consumer\nSo if hardware-enabled SaaS is the model for Enterprise IoT, could there be a similar flip for consumer?\nMy instinct is that there’s a freemium-like model to be found. Popularised by LinkedIn, freemium was the realisation that - with a digital service - 5% paying of a massive customer base is better than 100% of a tiny one.\nThis wouldn’t quite the same for consumer, but imagine a fictional Juicero (to stick with that example) that was a great juicer for any fruit – and also the ability to “upgrade” to a hassle-free monthly subscription of more exotic juice packets.\nOf course LinkedIn innovated on both revenue and distribution simultaneously. It wouldn’t have worked without the viral traversing of your address book. Consumer IoT hasn’t yet discovered its virality, and that’s a challenge.\nWhere next?\nConspicuous setbacks like those above damage confidence in the Internet of Things, but they’re part of the process and it’s important to learn from them.\nIoT is an enabler, not a feature. Like machine learning, it’s an interoperating set of technologies and approaches that opens doors in all kinds of sectors. For IoT, the immediate value is in bringing the dividends of the 50 year digital boom right into the real world.\nThis is a challenge for the business world (for corporates, for investors, and for founders) because there’s no guarantee that (a) existing business practices will remain intact; or, (b) lessons learnt about the Internet of Things in one sector will translate to a second.\nSo what to do if you’re in that world? Watch, learn, experiment, and share. It’s how we get through the idea maze together.\n",
    link: "/home/2017/09/01/bladerunner",
  },
  {
    title: "Filtered for non-human earths",
    date: "17.35, Monday 11 Sep 2017",
    content:
      "1.\nIce age Eurasia was not a human world. Cave bears and the Upper Paleolithic: The longest war ever fought by humans was not fought against other humans, but against another species – Ursus spelaeus, the Cave Bear.\n\nUnlike human beings, cave bears probably could not have survived elsewhere … The caves of ice age Eurasia were their world, and they spent enough time in these shelters that the walls of caves have a distinctive sheen that is called “Bärenschliffe”\n\nOh!\n\nThe “Bärenschliffe” are smooth, polished and often shining surfaces, thought to be caused by passing bears, rubbing their fur along the walls. These surfaces do not only occur in narrow passages, where the bear would come into contact with the walls, but also at corners or rocks in wider passages.\n\n2.\nListen: For thousands of years in cultures all over the world the magic mushroom or psilocybe cubensis has been used by humans.\nAnd: It is possible the psilocybe mushrooms evolved their ability to interface with animal consciousness to give them a unique look at all the information their brains typically disregard. The mushroom can inspire higher thought and evolution.\nWhat if - hear me out on this - what if\n\nit is possible the mushroom originated somewhere else in the universe forming symbiotic relationships with other species. Species all over the universe may find common ground in this higher consciousness symbiotically obtained from the same mushrooms. Maybe these alien species leave behind spores all over the universe, or perhaps the spores traverse space themselves.\n\nMore: Magic mushrooms or ancient aliens?\n3.\nAlways Coming Home by Ursula Le Guin is an archaeology of the future. This is an excellent review.\nIt’s a compendium of poems, linguistic studies, personal narrative and religious observations (with an original cosmology) about the Kesh, a society in far-future California living a kind of new Bronze Age utopia.\nAnyway, much poetry.\nAnd buried right in the middle of this book is the revelation that the Earth is also populated by a network of post-singularity artificial intelligences, Yaivkach, the City of Mind:\n\nSome eleven thousand sites all over the planet were occupied by independent, self-contained, self-regulating communities of cybernetic devices or beings – computers with mechanical extensions. This network of intercommunicating centers formed a single entity, the City of Mind. … It appears that an ever-increasing number were located on other planets or bodies of the solar system, in satellites, or in probes voyaging in deep space.\n\nAnd:\n\nIts observable activity was entirely related to the collection, storage, and collation of data\n\nWhich is what it does.\n\nThey seem not to have interfered in any way with any other species.\n\nThere’s a kind of information exchange, mediated by special sites called Exchanges.\nLe Guin has put the chapter about the City of Mind online. It’s short and an interesting read, one view of what it might be to cohabit our planet with an intelligence that no longer cares about us. Here: Yaivkach: The City of Mind.\n4.\nGoing through some of my old notes, I found this paragraph from the Extended Phenotype by Richard Dawkins:\n\nJanzen (1977) faces up to the same difficulty, suggesting that a clone of dandelions should be regarded as one ‘evolutionary individual’ (Harper’s genet), equivalent to a single tree although spread out along the ground rather than raised up on the air on a trunk, and although divided up into separate physical ‘plants’ (Harper’s remets). According to this view, there may be as few as four individual dandelions competing with each other for the territory of the whole of North America.\n\nEmphasis mine.\n",
    link: "/home/2017/09/06/ge_and_juicero",
  },
  {
    title: "Filtered for mammals",
    date: "11.16, Wednesday 20 Sep 2017",
    content:
      "1.\nThe memetic history of medieval elephants:\n\nAfter the fall of the Roman Empire, elephants virtually disappeared from Western Europe. Since there was no real knowledge of how this animal actually looked, illustrators had to rely on oral and written transmissions to morphologically reconstruct the elephant, thus reinventing an actual existing creature.\n\nThis is a tree diagram covering 700 years of imagined elephants.\nI am in love.\n2.\nIf cancer can strike any cell, then why don’t larger animals (with more cells) get cancer more than smaller ones? Peto’s paradox: the incidence of cancer in humans is much higher than the incidence of cancer in whales. This is despite the fact that a whale has many more cells than a human.\nWhy? One possibility: hypertumors.\nA novel hypothesis resolving Peto’s paradox: since cancer cells are predisposed to be aggressive, maybe mutant cancers appear in the cancers that then grow as a tumor on their parent tumor, creating a hypertumor that damages or destroys the original.\nAnd:\n\nIn larger organisms, tumors need more time to reach lethal size, so hypertumors have more time to evolve.\n\nIn smaller animals, hypertumors don’t have time to emerge, so cancer incidence is higher.\n3.\nNews from 1929:\n\n[Professor] Wever and [research assistant] Bray took an unconscious, but alive, cat and transformed it into a working telephone to test how sound is perceived by the auditory nerve.\n\nThe cat telephone.\nHere’s how: A telephone wire was attached to the nerve and the other end of the wire was connected to a telephone receiver. Bray spoke into the cat’s ears; Wever listened from a soundproofed room 60 feet away.\nThe original paper from 1930 states that speech was transmitted with great fidelity. Alas no clue on the first words spoken over the cat telephone.\n(Even more alas for the cat, who didn’t come through the procedure alive.)\nThe first words spoken over the Chappe telegraph system, which later covered Napoleonic France with over 500 stations, on March 2, 1791: If you succeed, you will bask in glory.\n4.\nTrotify. A device that attaches to your bicycle and makes it sound like a horse.\n",
    link: "/home/2017/09/11/filtered",
  },
  {
    title: "Filtered for robots",
    date: "09.40, Tuesday 26 Sep 2017",
    content:
      "1.\nThis video of a robot sorting system for a warehouse.\nThe dance of those little orange cushions charging from source to destination, giving each other room… lovely.\nPacket switching. It used to be that the pipes were visible, and the packets were dumb but had addresses. The junctions were smart and did the work. We call them routers. Here there are no routers and there are no pipes. But instead, autonomous packets.\nI wonder if the internet could work like this: not dumb packets with addresses, but each packet with a tiny bit of software to choose its own next destination. I’d be interested to hear of any work in this direction.\n2.\nWoffice, a property service company in Handan province, China, has a monthly relaxation day for its staff. One month it was “No Face” day.\n\nLuckily for these employees in China, they’ve been given a day off to go “faceless”. [Staff] wore masks on Tuesday so they didn’t have to fake their facial expression throughout the day.\n\nAnd:\n\nMost workers chose to go with the “No Face” mask to relax their smiling muscles and remain anonymous in front of customers\n\nIdentity is work.\nGreat photos.\nThe caption to the bottom photo is brutal: This way no one can see me cry.\n3.\nA robot monk in Longquan Temple, China. Named Xian’er.\n\nThrough a touch screen held on his tummy, he can answer voice commands and up to 100 questions on Buddhism.\n\nA robotic priest in Wittenberg, Germany. Named BlessU-2.\n\nThe machine delivers various blessings in eight languages.\n\nDoes a benediction from a robot have an effect? Is sentience necessary to facilitate the presence of the divine? \n4.\nRings that look like fingers. Earrings that look like ears.\n",
    link: "/home/2017/09/20/filtered",
  },
  {
    title: "Book recommendations from the Juvet AI Retreat",
    date: "16.55, Saturday 30 Sep 2017",
    content:
      "I’ve been at a retreat the last few days, 20 of us at a gorgeous hotel in Norway nattering about artificial intelligence. Here’s a photo of how insanely beautiful Norway is. And here’s a list of who was there, plus some more background on the retreat from the organisers.\nI collected book recommendations as I’ve done regularly at conferences. The question I ask is always the same: What 3 books should I read this year? I don’t want to hear your best-ever books, nor the books that will make everyone believe you’re a super-genius, just… if we were speaking face to face, knowing what you know about me, what are the 3 books you would recommend for me right now? Here’s a pic of how the question is posed. Putting it that way gets some cracking suggestions.\nAnyway, I’ve ended up with 40 recommendations from a dozen-plus folks. So here they are. All links go to a physical edition at Amazon UK.\nBook recommendations\nAdrian Zumbrunnen, @azumbrunnen_:\n\nPredictably Irrational: The Hidden Forces that Shape Our Decisions, Dan Ariely\nIncognito: The Secret Lives of the Brain, David Eagleman\nTime Warped: Unlocking the Mysteries of Time Perception, Claudia Hammond\n\nAmber Case, @caseorganic:\n\nCalm Technology: Designing for Billions of Devices and the Internet of Things… by Amber Case. (There’s nothing in the rules that says you can’t recommend your own book!)\nAvogadro Corp (“Book One of the Singularity Series”), William Hertling. Fiction\nTake Too Little Time for Yourself. Available independently. Poetry\n\nBen Sauer, @bensauer:\n\nGood Strategy, Bad Strategy: The Difference and Why it Matters, Richard Rumelt\nFlood!, Eric Drooker. Graphic novel\nSex Criminals (volume 1), Matt Fraction and Chip Zdarsky. Graphic novel\nSum: Forty tales from the afterlives, David Eagleman. Fiction\n\nBill Thompson, @billt:\n\nFen, Daisy Johnson. Fiction\nM Train, Patty Smith. Fiction\nThe Lure of Greatness: England’s Brexit and America’s Trump, Anthony Barnett\n\nCennydd, @cennydd:\n\nKilling and Dying, Adrian Tomine. Graphic novel\nThe Politics of Bitcoin: Software as Right-Wing Extremism, David Golumbia\n\nChris Noessel, @chrisnoessel:\n\nSuperintelligence, Nick Bostrom\n\nDan Harvey, @dancharvey:\n\nRed Harvest, Dashiell Hammett. Fiction\nThe Vision (volume 1), Tom King and Gabriel Hernandez Walta. Comics collection\nNetworks of New York: An Illustrated Field Guide to Urban Internet Infrastructure, Ingrid Burrington\n\nDan Hon, @hondanhon:\n\nThe Big Picture: On the Origins of Life, Meaning, and the Universe Itself, Sean Carroll\nLexicon, Max Barry. Fiction\nTroika, collected in Beyond the Aquila Rift: The Best of Alastair Reynolds. Fiction\n\nIshan, @poietic:\n\nSmall Arcs of Larger Circles: Framing Through Other Patterns, Nora Bateson\nHyperion Cantos (series), Dan Simmons. Book 1: Hyperion. Fiction\nThe Nexus Triology (series), Ramez Naam. Book 1: Nexus. Fiction\n\n(I’m tempted to say that recommending a whole series is cheating…)\nJosh Clark, @bigmediumjosh:\n\nNew York 2140, Kim Stanley Robinson. Fiction\nWeapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, Cathy O’Neil\n\nKaren Kaushanskyn, @kjkausha:\n\nNotorious RBG: The Life and Times of Ruth Bader Ginsburg, Iron Carmon and Shana Knizhnik. (Karen says to get the physical edition because the design of the annotations requires it, and they add a lot.)\nMachines of Loving Grace: The Quest for Common Ground Between Humans and Robots, John Markoff\nThe Art of Fielding, Chad Harbach. Fiction\n\nKate Devlin, @drkatedevlin:\n\nHouse of Leaves, Mark Z. Danielewski. Fiction\nNot Fade Away, Jim Dodge. Fiction\nThe Holy Machine, Chris Beckett. Fiction\n\nMe, Matt, a.k.a @genmon:\n\nFour Futures: Life After Capitalism, Peter Frase\nRadical Technologies, Adam Greenfield\nThe Red Men, Matthew de Abaitua. Fiction\n\nWarren Ellis, @warrenellis:\n\nThe Baroque Cycle (series), Neal Stephenson. Book 1: Quicksilver. Fiction\nGnomon, Nick Harkaway. Fiction (will be released November 2017)\nAt The Existentialist Cafe: Freedom, Being, and Apricot Cocktails, Sarah Bakewell\n\nRecommendation made with no name attached:\n\nFeed, M. T. Anderson Fiction\n\nThanks all! Transcription corrections welcome.\n",
    link: "/home/2017/09/26/filtered",
  },
  {
    title: "Filtered for integrity in visual representation",
    date: "10.20, Wednesday 4 Oct 2017",
    content:
      "1.\nDomino’s pizza photos on Instagram are gross deliberately.\nRealism. Quote: Imperfectly real. (Not quite sure when the real got relegated.)\nTwo possibilities for this shift: \nLegitimacy in the age of conversation is not communicated via iconic images. I’ve covered legitimacy previously, in the context of the media:\n\n“People trust us because we’ve spent years developing a relationship with them. We have been scrutinized and found not evil. Our legitimacy comes from honesty, not from cultural signals or institutions.”\n\nSecond possibility is that this is the age of photoshop and everything mediated is manipulated. Hard to build trust.\nIt is also the age of marketing where “greed is good” and “might is right” have been joined by another tyranny: truth is what you can get people to believe.\nSo there’s space for an approach that doesn’t (appear to) dress up and doesn’t (appear to) convince. \nSee also: the Instagram trend called the plandid, the planned candid – where you look totally natural in your posing, like you’ve been caught in the act and just so happen to look triple-digit-Insta-likes amazing.\nExamples are given.\n2.\nI grew up in the waning years of the Cold War, those happy days where apocalypse was total but distant, rather than continuous, partial, and immediate. The word “DEFCON” is engraved on my soul. Turns out each of the five levels has a code word associated with it too.\n\nDEFCON 5, Fade Out. Normal readiness\nDEFCON 4, Double Take. Above normal readiness\nDEFCON 3, Round House. Air Force ready to mobilize in 15 minutes\nDEFCON 2, Fast Pace. Armed Forces ready to deploy and engage in less than 6 hours.\nDEFCON 1, Cocked Pistol. Nuclear war is imminent / Maximum readiness\n\nFrom DEFCON on Wikipedia.\n3.\nThe Triumphant Rise of the Shitpic, the patina that comes from cycles of screencapping and upload-compression as a picture is shared and shared again,  the first non-numeric indicator of viral dissemination.\nWonder how long it’ll take for Domino’s to adopt this. \nWonder which version of the iPhone will have a computational photography mode to create pre-distressed selfies, for that already-shared look.\nSee also: this video of the LaserSharp Denim HD Abrasion System which creates identical pre-distressed jeans.\nSee also: Gudak, the disposable camera app. You get only 24 photos at a time; a roll of film takes three days to develop; the photos are grainy and the light that leaks over them is the colour of summer days that never ended, when you were still young and you still laughed and your life stretched out ahead of you and you could still be anything.\nFun app. Five stars.\n4.\nThis oral history of the CGI visual effects in Terminator 2 is an awesome long read. So much of the use of computers was new, then.\nAlso awesome for this photo of Robert Patrick, almost naked, covered in a Sharpie grid, being filmed for motion capture.\nRobert Patrick played the T-1000, the liquid metal morphing Terminator from the future.\nAlso, also awesome for the terminology of the engineers and artists:\n\nSo, we had what we called RP1 through to RP5. Robert Patrick - RP - that was the actual naming convention.\nRP1 is the blob, an amorphous blob. RP2 is a humanoid smooth shape kinda like Silver Surfer. RP3 is a soft, sandblasted guy in a police uniform made out of metal, and RP4 is the sharp detail of the metallic liquid metal police guy, and then RP5 is live action.\n\nRobert Patrick, the actor, the actual dude, gets relegated from his own name.\nRP5. Fade Out.\n",
    link: "/home/2017/09/30/books",
  },
  {
    title: "Filtered for stream of machine consciousness",
    date: "19.40, Thursday 12 Oct 2017",
    content:
      "1.\nThis is an amazing long essay, well illustrated, about someone who builds an heat sensitive camera. It is peppered with poetic descriptions of what the camera sees.\n\nthe air itself glowing\n\nAnd, looking outside,\n\nthe vegetation is not as reflective, so you get the “blackness of space” sky with regular-ish landscapes. It’s almost like being on the airless, derelict Earth - preserved under the void after whatever disaster befell it.\n\n2.\nI’m Google by Dina Kelberman.\nIt is:\n\nan ongoing tumblr blog in which batches of images and videos that I cull from the internet are compiled into a long stream-of-consciousness. The batches move seamlessly from one subject to the next based on similarities in form, composition, color, and theme. This results visually in a colorful grid that slowly changes as the viewer scrolls through it. Images of houses being demolished transition into images of buildings on fire, to forest fires, to billowing smoke, to geysers, to bursting fire hydrants, to fire hoses, to spools of thread. \n\n3.\nThe Japanese Museum of Rocks That Look Like Faces.\nDoes what it says on the tin.\n4.\nHere’s a system using artificial intelligence to generate human faces.\nWorth it for:\n\nthe gifs seamlessly morphing between faces and emotions, exploring parameter space\nand, the best bit, the illegal faces. Search for the word illegal to see what the system does when it’s asked to generate faces from inputs outside the regular range. The faces are weird patchworks, a computer-native cubism\n\nSee also: WaveNet, which makes realistic speech audio also using A.I. It’s incredibly realistic, but search for babbling and listen to what the system produces in the absence of any text to process. It’s a mess of clicks, hums, and wet mouth noises – horribly human but with an absence of intelligence. Uncanny.\n",
    link: "/home/2017/10/04/filtered",
  },
  {
    title: "The next hardware-ish coffee morning is next Thursday",
    date: "18.11, Friday 13 Oct 2017",
    content:
      "My Dearest Droogs,\nLet’s have a hardware-ish coffee morning! Soon!\nThursday 19 October, 9.30am for a couple of hours, at the Book Club, 100 Leonard St.\nI’ll be back from my travels, moderately jetlagged, and in no state to conduct linear conversations. So it will be especially important to (a) talk to everyone else who comes (they’re always really friendly); and, (b) poke me in the ribs if you see me nodding off.\nUsual rules: we don’t do intros; everyone talks to everyone else; you order coffee from the counter and please don’t forget to pay otherwise the staff get confused; bring a prototype if you have one; actually working with hardware IS NOT A requirement, you just have to be curious. Here’s what happened last time.\nMight be 5 people, might be 25. If you’re a startup and want to ask me about the new R/GA IoT Venture Studio, I am happy to chat.\n(Also posted to the coffee morning announce list to which you should subscribe for future updates.)\n",
    link: "/home/2017/10/12/filtered",
  },
  {
    title: "Filtered for things I learned over the weekend",
    date: "17.53, Tuesday 17 Oct 2017",
    content:
      "1.\nComputers can be trained to see. But they don’t necessarily fixate on the features humans see.\nAdversarial Machine Learning is a technique to change an image to be recognised as something else, without looking any different to humans.\nFor example: a panda that - with the right fuzz of pixels added to it - looks to the computer 99.3% like a gibbon.\nA hack: adversarial stop signs.\n\nthe team was able to create a stop sign that just looks splotchy or faded to human eyes but that was consistently classified by a computer vision system as a Speed Limit 45 sign.\n\nExamples are given.\n2.\nOntology is the philosophical study of existence. Object-oriented ontology:\n\nputs things at the center of this study. Its proponents contend that nothing has special status, but that everything exists equally – plumbers, cotton, bonobos, DVD players, and sandstone, for example.\n\nThings from their own perspective.\nA desk telephone, from its own perspective, is constructed to entice (a curve of a handle, buttons that want to be pushed) to feed on sound. To be nourished by sound. And with that consumed energy, to reach out across the world and touch - out of an infinity of destinations and through the tangle - one other. And to breath in relief at this connection, a sigh: another voice.\n3.\nThe Ethics of Mars Exploration, an interview with Lucianne Walkowicz:\n\nit remains a fact that Mars is a place unto its own that has its own history, and what respect do we owe to that history? What rights does that history have?\n\nWhich makes me ask this:\nYes I believe there’s a human imperative to go to Mars; yes I believe it has to be done in an inclusive way; yes space mustn’t be about resource exploitation, a cosmic Gestell; yes potential life on Mars must be preserved.\nBut also, what Walkowicz said, the land, the land, the land.\nI hike, and the land has an intrinsic right to be itself. But I also believe in the human experience of the land, that this is a component of meaning: so, paths? When you walk the trails of the American south west, you come to understand that the trail-makers are poets, giving the land a voice to sing through human experience: effort, surprise, endurance, revelation, breathlessness.\nSo there should be trails on Mars too.\nWhich makes me think this:\nWho is working to understand this interplay of the subjectivity of the land, and the human gaze, right now? Not necessarily on Mars.\nLandscape artists - landscape photographers - do this well.\nAnd that’s a process that, for Mars, could start today.\nThere is Mars exploration via rover right now. The rovers, of course, have cameras. Do they have landscape photographers on the team? Are those artists given reign to look, be, and create?\nWhy Hasn’t David Hockney Been Given The Keys To The Mars Rover Yet.\n4.\nA list of interstellar radio messages. That is, ones we’ve transmitted, not ones we’ve received.\nThe first one, from 1962, in Morse code: MIR LENIN SSSR Sent to Venus.\nA more recent one, A Simple Response to an Elemental Message, was transmitted in October 2016 and comprised 3,755 crowdsourced responses to the question How will our present, environmental interactions shape the future? It was transmitted towards Polaris and will take 434 years to arrive. (Then another 434 years to hear back.)\nThe Golden Record is not a radio transmission but a physical item, copies of which were placed on Voyagers 1 and 2 in 1977, includes pictures, sounds, music, and greetings in 55 languages including, in Amoy, spoken in southern China, these words:\n\nFriends of space, how are you all? Have you eaten yet? Come visit us if you have time.\n\nWhich I hope desperately isn’t misinterpreted as offering humanity up for lunch.\nVoyager 1 will make a flyby of a star in 40,000 years. Star AC +79 3888 is 17.6 lightyears away, so the earliest we will receive a radio message back is in 40,017.6 years. We should remember to listen out for that. Year 42,034. June.\nThe Rosetta Project is an archive of all the world’s languages by the Long Now Foundation, and is intended to be a code for future civilisations to unlock… what? An archive that we leave behind.\nOver the weekend I heard it asked:\nWho is keeping an archive of all the messages we send into space, and how will that archive be maintained? We won’t receive an answer from the stars, if any, for hundreds or maybe tens of thousands of years.\nIf, when, we receive a reply saying YES then how will we know what it’s a YES about?\nMy weekend\nI spent the weekend at Kickstarter HQ in Brooklyn for PWL Camp 2017 – a 48 hour, 200 person unconference where the agenda is created by the attendees at the beginning of the meeting. Anyone who wants to initiate a discussion on a topic can claim a time and a space.\nTons of great conversations. A very open, generous, and talented crowd. My notebook is full but mostly incomprehensible. The above are four things that came up. I’m grateful for having been invited.\n",
    link: "/home/2017/10/13/hardwareish",
  },
  {
    title: "Filtered for fractional artificial intelligence",
    date: "10.15, Tuesday 24 Oct 2017",
    content:
      "1.\nVoice systems are always listening, but it’s expensive (and invasive) to analyse everything picked up by the microphone. Hence wake-up words, which keep the rest of the system switched off until heard, and are - in theory - cheap to detect.\nHow the “Hey Siri” wake-up words work, by Apple’s machine learning team.\nThe wake-up words run as a tiny brain. In the following, DNN stands for Deep Neural Network.\n\nTo avoid running the main processor all day just to listen for the trigger phrase, the iPhone’s Always On Processor (AOP) (a small, low-power auxiliary processor, that is, the embedded Motion Coprocessor) has access to the microphone signal (on 6S and later). We use a small proportion of the AOP’s limited processing power to run a detector with a small version of the acoustic model (DNN). When the score exceeds a threshold the motion coprocessor wakes up the main processor, which analyzes the signal using a larger DNN.\n\nCompiled tiny brains. High accuracy, low power recognisers, super focused single feature fetishisers.\nA.I. on dedicated silicon is getting cheeeeeap.\nMy hunch:\nGive it a few years, and I reckon voice-on-a-chip and hand-gesture-sensitive-lensless-camera-on-a-chip and make-any-surface-touch-sensitive-on-a-chip and make-use-of-nearby-watches-and-headphones-on-a-chip will be so accurate, so power efficient, and so cheap that they will undercut the cost of physical interface components like buttons and screens – and therefore be used instead. For everything from kitchen scales to door locks. Which will change how we interact with products and what they look like.\n2.\nDung Beetles Use the Milky Way for Orientation\n\nThis finding represents the first convincing demonstration for the use of the starry sky for orientation in insects and provides the first documented use of the Milky Way for orientation in the animal kingdom.\n\n3.\nWhat factories looked like in the age of steam:\n\nThe mechanical power came from a single massive steam engine, which turned a central steel drive shaft that ran along the length of the factory. Sometimes it would run outside and into a second building.\nSubsidiary shafts, connected via belts and gears, drove hammers, punches, presses and looms. The belts could even transfer power vertically through a hole in the ceiling to a second or even third floor.\n\nAnd then electricity:\n\nBut electric motors could do much more. Electricity allowed power to be delivered exactly where and when it was needed.\nSmall steam engines were hopelessly inefficient but small electric motors worked just fine. So a factory could contain several smaller motors, each driving a small drive shaft.\n\nElectricity changed factory architecture:\n\nA factory powered by steam needed to be sturdy enough to carry huge steel drive shafts. One powered by electricity could be light and airy.\nSteam-powered factories had to be arranged on the logic of the driveshaft. Electricity meant you could organise factories on the logic of a production line.\nOld factories were dark and dense, packed around the shafts. New factories could spread out, with wings and windows allowing natural light and air.\n\nMore here: Why didn’t electricity immediately change manufacturing?\n4.\nThe fractional horsepower motor took the domesticated factory drive shaft right into the home:\n\nElectrification began in cities around 1915 and with electrification so too came the potential market for washing machines, refrigerators, vacuum cleaners and a host of other commercial appliances. … By 1920, over 500,000 fractional horse-power motors were powering washers and other appliances in America.\n\nBack in 2012, I wrote about fractional artificial intelligence. Here’s a talk on the same topic from 2010. Watching this now it’s like watching somebody stumbling around in the dark, but I think this is what’s happening today.\n",
    link: "/home/2017/10/17/filtered",
  },
  {
    title: "What I’m doing now: R/GA IoT 2018",
    date: "12.15, Tuesday 24 Oct 2017",
    content:
      "Early in 2017 I ran an accelerator in London investing in Internet of Things startups, and it went so well that we’re doing it again. Tell your friends.\nUpcoming events: see the bottom of this post for some places we can meet over the next month.\nThe program in 5 bullets:\n\nIt’s with R/GA Ventures which is the ventures arm of the global, 2,000-person digital agency R/GA. Ventures has run a dozen programs to date, with 81 startups in the portfolio\nThis program is 3 months and based in London. It includes hands-on creative work from the agency (for example, to lend a hand on the visual identity and messaging) and design/story assistance on the pitch deck. Plus networking and workshops\nInvestment is £75,000 for 6%, but we like companies that have already raised so there’s some flexibility (e.g. 6 out of the 9 startups in the 2017 cohort had already raised so we had custom terms)\nThis isn’t a traditional accelerator. It’s optimised for companies showing early traction - whether through pilots or field trials - and we like to think about this as a partnership. For example, we keep program meetings to Mondays and Thursdays because people have actual businesses to run\nThe program will run February to May 2018. We’re open for applications from now until December\n\nIf you’d like to see an example of the visual identity work, I love the look and messaging of Flock’s website and app (alum 2017). Flock sells pay-as-you-fly drone insurance, using a proprietary and automatic risk algorithm, and is now - impressively - partnered with Allianz for underwriting.\nFor me, Internet of Things means digital reaching into the real world. My favourite startups use now-mature IoT tech (whether hardware or software) to do something that wasn’t possible before, such as insanely accurate pedestrian football by using artificial intelligence to count shoes, or halving food waste in commercial kitchens. Both of those are companies in the 2017 cohort. My favourite IoT startups don’t say IoT on their homepage.\nHere are the 2017 alumni. I’m delighted with how the cohort is going. (Some are now based here at R/GA London where we offer below-market desks to portfolio companies.)\nThe website: R/GA IoT Venture Studio UK with info about the upcoming program.\nA request to spread the word\nLast year only 3 of the 9 companies in the program had women founders. That tells me we didn’t do a good enough job.\nThis year, I’d like to get info out especially to women and people of colour. If that describes startups you know, or you know groups and networks that are representative, I would appreciate your help to spread the word. Please share a link to this post.\nUpcoming events\nThere are a number of ways we can meet/talk.\n\nCome to our meet-and-greet on 31 October (use that link to RSVP). V. informal. I might take 5 minutes to say hello but otherwise no presentations. A good chance to come and meet me and our Program Director Lisa Ritchie… or if you’ve lent your time to the program before, a good chance to hang out again after the summer\nGrab me on Skype (use that link to pick a time). I spend two afternoons each week meeting founders on Skype. Tell me about your company and let me answer any questions you have about the program\nIf you’re at Web Summit in Lisbon in November, drop me a note: we’re hosting a dinner on Monday night, and I’ll be about all week. My email is matt.webb@rga.com\n\nApplying to the program is easy: use the form here.\nWe’re accepting applications until 7 December 2017. \nCheeky question\nWe’re also always looking for more sponsors. Companies like Snapchat, Westfield Labs, and Intel like working with R/GA Ventures because they get visibility in the emerging tech ecosystem, and early access to startups which are ready to partner. Let me know if you’d like to chat more.\n",
    link: "/home/2017/10/24/filtered",
  },
  {
    title:
      "Here’s my PR tip for people (like me) who are terrible at PR a.k.a. the Tick-Tock List",
    date: "17.34, Thursday 26 Oct 2017",
    content:
      "The problem is that you launch a thing or have some big news and those pesky journos won’t cover it. \nHere’s one approach:\n\ntreat journalists like human beings because that’s what they are. I’ve seen the “pesky journos” attitude a bunch and it’s an unhelpful category error that sets up an us-and-them division: most journalists I know are also product developers, consultants, entrepreneurs, creatives in other fields, etc. I don’t mean pretend to be mates, but do acknowledge that you’ve both got a job to do (you to get coverage, them to provide interesting stuff for their readers) and build a professional relationship around that \ndon’t reach out only when you want something\n\nIf you’re a pro, or if you have a marketing team, talking to journalists like this is second nature. But for founders who are just getting going - and for rank amateurs like me - it can be hard to know where to start.\nSo one way is to use what I call a Tick-Tock List.\n(I only call it this in my head. Nobody else says this. What I mean is you should email people on the regular, like clockwork.)\nHow to run a Tick-Tock List:\n\nMake a list of journalists who have covered you or your company before. Not the publications but the individuals (with luck you’ll build a relationship with them that lasts years as they end up super influential at big publications) \nEmail this group every 2 or 3 weeks. This email should be written by you, from your personal email, with no weird formatting: it’s not a newsletter. Journalists on bcc\nSubject line: Company name, update number or date, top news \nDon’t ask for coverage\n\nWhat should be in each email:\nThe email should be short and easy to read. Use bullets.\nContents:\n\nSay hello\nSay that they’re receiving this email because they’ve covered you before, that there are 12 people (or however many) on the list, and that you’ll stop emailing if they ask (or add them if they got the email as a fwd). The number is good transparency\nSay the one sentence version of what you do in plain language like when you have to explain to your parent’s friends what the hell you do. Ideally this includes a “because”. Like, “We’re doing [what it is] in order to [big hairy goal] because [a value judgement about the world]”\nSay these three things:\nwhat your company had achieved since you last emailed\nthe biggest achievement they might have missed the last few emails (if there’s news coverage, include a link and say thanks)\nwhat’s coming up over the next week or two\n\n\nSign off with your name, phone number, your email address, and being open for a chat \n\nBy achievement I mean something that is outward-facing that is actually interesting. Concrete. If nothing happened, say nothing happened – and why.\nAfter you’ve done this a few times, and if you’ve got something genuinely worthy of a story, you might want to say - before your three things, in bold - that you’ve got a launch/event/newsworthy thing coming up in a week or two, and you’re hunting for coverage. Offer to chat about it.\nYou might find - and this is the goal - that somebody on your list, somebody who has never replied before, happens to receive the email at the right time and they have the right-shaped hole in their slate, and so they get in touch to learn more and hopefully do a story.\nMore tips:\nWhen you say what’s coming up, don’t be cagey or fake-enticing. Your email recipients aren’t marks, they don’t owe you anything, these are humans, one day maybe you might be friends. Be open enough for them to make a decision. But likewise don’t put them in the difficult position of being told a detail via email that you really want to keep secret.\nWhat is newsworthy? Think: is this so interesting that if you heard it about someone else you would want to tell your non-bubble friends; have you said it in the right way to be easily understood, and provided the right words for others to do the same; can it further the narrative of the journalist.\n(Aside. I feel that every publication has a worldview that it is continuously pushing. It could be something like “technology is building the beautiful future we imagined when we were kids” or it could be “this thing is niche right now but one day it will be mainstream and momentum is growing.” Find and provide an angle to allow journalists to use your story to develop and argue this worldview with their readers.)\nThe hard bit:\nThe hard bit: continue with the Tick-Tock List.\nLet’s see, what else. Did I already say this isn’t a newsletter? This isn’t a newsletter - and there are many and I subscribe to many and they are brilliant - so you should also one of those (and a blog, and a twitter, and…). But this is more intimate. An actual email. Um. Be respectful. Your goals are\n\nto build a professional relationship \nto build a soap opera sense of momentum\nprovide familiarity so that big events and asks don’t come out of the blue \noverall, to save time for the journalists\nto provide potential stories in a mutually beneficial way\n\nI’ve shared the Tick-Tock List pattern with a few companies over the years. I’m actually a bit nervous to share it here because it’s so trivial. But I’ve had a good experience of this personally, and reports of good effects, so I figured I’d write it up.\nPlease let me know if it works for you. (And if you’re on the other side of the fence, I’m curious about your views too.)\nBonus link: Mike Butcher’s article/rant The Press Release Is Dead - Use This Instead is fantastic. Check out the list of questions that he needs answered, as Editor-at-large of TechCrunch Europe, to get to grips with a possible story.\n",
    link: "/home/2017/10/24/rga_iot_2018",
  },
  {
    title:
      "Security and privacy, startups, and the Internet of Things: some thoughts",
    date: "17.51, Tuesday 31 Oct 2017",
    content:
      "Upcoming event in London: I’m going to be speaking about the Internet of Things, security, and privacy with Sarah Gold, CEO of IFat Machines Room (an awesome east London makerspace), tomorrow.\nInsecure Futures: Privacy, Security and Connected Devices (Weds 1 Nov, 6pm): RSVP here.\nThe event is part of a series of panels curated by Machines Room and Kickstarter. Sarah and I will be doing this as a “fireside chat.” Should be thought-provoking – these are some chewy topics, and Sarah is an expert. Her consultancy researches trust, policy and design for clients with Google and Facebook with output both practical and speculative.\nWe’ve each been asked to spend 5-10 minutes at the beginning of the session to set out our stand, so to speak. So this is my current draft on what I’m going to say. Comments welcome; I’ll evolve it some before speaking.\nOn IoT, security, and privacy. But security first:\nLet me say a few words about security first. Then privacy.\nAnd really, because we’re talking about the Internet of Things, we’re talking about the security of a device in people’s homes and in businesses, what we’re talking about is the security of data and other devices on the trusted networks in those places.\nWith my investor hat on, a startup that doesn’t take security seriously is obviously a problem because it’s saving up problems down the road – it will be harder to acquire, and it has the potential of being part of something catastrophic.\nFor me, one tell around this - a technology red flag - is when companies build their own stack themselves for secure connection of devices to user accounts (called provisioning), or for performing over-the-air (OTA) updates. These two are bellwethers: if something isn’t right here, it’s likely that security hasn’t been considered elsewhere in the stack.\nIt’s easy to convince yourself, as a startup, that there is no solution out there that meets your needs for provisioning and updates. But over the last 12 months, the technology stack for connected devices has matured. And honestly, these stacks come with features that you will never get round to building yourself. So it’s worth looking for existing solutions.\nresin is an interesting example of a useful stack. One of the things resin makes easy is over-the-air updates for device software. But because some of their users run this software for drones, they also include a feature that allows the drone to postpone the software update until it has safely landed. That’s a useful feature. Let’s say you’re building a cash register: it would be great to have a feature where it can postpone updates till after the lunch rush is over. That’s the same thing. But will you get round to building it yourself? Probably not.\nSo building your own stack is hard to get right, and more importantly it’s expensive to keep up to date. Over months, as the technology landscape evolves, a resource constrained startup may find itself lagging. And that’s where security problems emerge.\nBuilding your own artisan stack feels like an expensive indulgence in most cases. The line to keep in mind is Werner Vogal’s maxim - Vogal the CTO of Amazon - his maxim of no undifferentiated heavy lifting. That is, don’t put significant engineering resource into stuff that isn’t your core business.\nBut security isn’t just technology. It’s design.\nIt’s what you encourage users to do. A friend of mine in San Francisco had some smart lighting and smart plugs some years ago. It has this great feature where if you’re on the same wi-fi network, it automatically associates the devices with your app so you can control them. And then, even when you’re not on the network, you can turn the lights on and off. Handy.\nSo some months after staying with my friend, I discover - from London, while demoing the app - that I can turn on the lights in his front room. I discover this because he texts me, after I’ve been doing this for some weeks, to ask if it’s me turning on and off his lights at 4am. Yes, yes it is.\nOf course I reckon with this power I can possibly start a fire. Lights on and off as quick as possible. No security stack is going to help. But thoughtful design can.\nHowever.\nThe tension for startups is that design for thoughtful design, and therefore for good security requires you to know what your product and service is doing, but in the early stages you may have to change the product quite a few times to get it right.\nNow you think I’m going to say that this is a difficult decision, blah blah blah, that startups should consider security early on, despite this.\nI’m not going to say that. I’m going to say that maybe a startup should ignore security, just a little bit.\nWhat I mean is: if I meet a startup who has spent ages on its security, pre getting some real customer traction, I am going to be nervous that they have over-engineered the product, and won’t be able to iterate. The product will be too brittle or too rigid to wiggle and iterate and achieve fit.\nSo it’s a balance.\nPrivacy:\nOne of the reasons that security matters is because it can lead to privacy being violated. Or rather, let me clarify:\nPoor security can mean a startup’s customer gives up privacy in an unintended way. That’s going to damage sales.\nBut what’s more of a preoccupation to me is when privacy is reduced in an intended way. You see this a lot when a startup has figured out how to make a business work by being not quite straight-up about what they’re doing with the data they’re collecting.\nFor example:\n\nA consumer-facing startup that gets its product out for free, and then collects user data to sell later. I don’t believe consumers can ever really consent to data use in this fashion: it’s never really made clear. It pulls the startup’s interest and the consumer’s interest out of alignment, and that - in my view - makes it hard for the company to grow in a clear way. This contradiction at their heart will make it tough to make product decisions\nA B2B startup which operates by collecting data on behalf of its clients – for example, collecting images of faces of shoppers for retail analysis. This can be legally legitimate. But sometimes it can be legitimate but still wrong: if properly informed, a regular consumer would feel uncomfortable\n\nYou would be surprised how many companies like these I encounter. Or maybe you wouldn’t be.\nI think it should be a point of greater social concern that consumers are asked to consent to data retention and usage when even the people collecting the data don’t know what it may be used for down the line. Object recognition and facial recognition is getting really good – but it wasn’t great or well known at the point I subscribed to most of the services I now trust with my data. Can it really be said I consented to this? So we need a better way to discuss this, in society.\nWith a more commercial hat on I subscribe to the view that, in most cases, big data is not an asset, it is a liability. If it’s not necessary for the business model, then it’s an expense to keep it secure. So don’t keep incur that expense. For example, you don’t need to keep credit card numbers to take payments. OIutsource it. You don’t need to move video to the cloud to data to do image recognition – we have machine learning at the edge for that now.\nBut mainly, I think about this: is it skeevy?\nThe tide has turned on privacy, just as it did for sustainability. For ages being sustainable was something companies did just to feel good about themselves. Now it’s both consumer expectation and good business.\nWith privacy? For B2B startups I feel that being privacy conscious is becoming a differentiator and should be advertised as such. No potential business customer will want to be associated with the risk of leaks, being hacked, or potential damage to the brand from revealed “skeevy” behaviour.\nIt’s not a negative thing. There’s opportunity here too.\nI want to end with an example which is Hoxton Analytics, a company I had the privilege of working with at the R/GA IoT accelerator I ran earlier this year. By the way, we’re running another one, and applications close on 7 December, just a few weeks from now. We can talk about that afterwards.\nHoxton Analytics supply, for their clients, pedestrian footfall intelligence. They count the number of people walking in and out of your shop.\nHistorically this has been done with infra-red beam interruption. Well, that can’t track groups or whether people are going in or out.\nSo instead you can do it by tracking smartphone signatures. Information-rich but not everyone has their Bluetooth or wi-fi turned on.\nSo you can really amp it up and monitor footfall with cameras doing facial recognition: that doesn’t fly in Europe, it’s personally identifiable information. Fine elsewhere in the world though. \nHoxton takes a different approach. They have cameras right down low on the floor, and they use machine learning - on the device - to recognise shoes.\nIt’s crazy accurate. 95% accurate. It can also count group sizes, and whether people are going in or out. So it can do capacity.\nIt also doesn’t store personally identifiable information so it’s good in Europe.\nBut get this. Because they’ve built this solution, it means they can also use it in public places. So you can point the camera out of the window and see how many people are walking past, versus how many people are walking in. This is the holy grail, like a conversion funnel, like Google Analytics, but for physical retail. And they’ve got there by considering privacy not as a product constraint, but as a product feature.\nWrap up:\nThat’s where my head’s at regarding security and privacy. I’m going to chew on these thoughts a bunch before the discussion with Sarah, and I’d welcome your thoughts – either on my views as laid out above, or on questions to ask her.\nI don’t know if there are any tickets left but if there are do come along and if you’re already signed up, then I look forward to seeing you on Wednesday night.\n",
    link: "/home/2017/10/26/ticktock",
  },
  {
    title: "Filtered for what celebrities and dinosaurs look like",
    date: "09.58, Wednesday 1 Nov 2017",
    content:
      "1.\nNeural network image synthesis: artificial intelligence systems are really good at generating super-realistic, fake images. Like the faces of celebrities.\nGiven the synthesised images can be made to be very similar to one-another, it’s possible to make a long chain of synthesised images - all faces, all similar to the one previous - and turn that into an animation.\nResulting in this video: One hour of imaginary celebrities.\nIt’s like David Lynch took over the Daily Mail showbiz section.\n2.\nMapping startup Mapzen put together some slides of gorgeous forms and lines, abstracted from maps.\nExplore the world of form. Scroll through the whole thing.\nSee also: photos of highway interchanges by Peter Andrew.\n3.\nGenerated animation of driving a car at night. Tail lights, rain on the window.\n(You’ll probably need to run this on a desktop, but click fullscreen.)\nAlso, this video clip from a game about looking out of a train window. Full game here: To West.\n4.\nDinosaurs aren’t drawn right.\n\ndinosaur illustrations should take more cues from animals living today. Our world is full of unique animals that have squat fatty bodies, with all kinds of soft tissue features that are unlikely to have survived in fossils, such as pouches, wattles, or skin flaps.\n\nHere’s what present day animals would look like, if we drew them as badly as we draw dinosaurs.\nThe illustration Swans imagined as though they were featherless dinosaurs is particularly terrifying.\nOf course we’re not talking about about dinosaurs now because they are indeed now particularly skinny, being skeletons.\nThis is in relation to millions of years ago, before the dinosaurs got raptured, before we used their fermented meat to drive our cars.\nSee also: Egyptian mummies were dug up and burnt to power steam trains. (Or rather, they weren’t. It turns out this was made up by Mark Twain.)\n",
    link: "/home/2017/10/31/security_and_privacy",
  },
  {
    title: "Filtered for things to read on your tube ride home",
    date: "17.20, Monday 13 Nov 2017",
    content:
      "1.\nSeat 14C is a collection of short stories all with the same premise. Each is a first-person account of the passenger in Seat 14C, on ANA Flight #008, as this passenger discovers they’ve mysteriously been transported 20 years into the future. There are some biiiiig name authors.\nBruce Sterling’s story is fantastic:\n\nThe planet, humankind, had undergone some huge, universal, metaphysical enlightenment. … They no longer used mushy, mystical terms from 2017, vague words like “thoughts, “feelings,” “moods,” “souls,” “intelligence.” They had precise, scientific formulations for those phenomena, with about a million high-tech terms-of-art.\n\nRead it: It Feels So Exponential.\n2.\nLine-us is a little robot drawing arm on Kickstarter by Durrell Bishop and Robert Poll. It is lovely.\nHowever I am not here to say how lovely this robot arm is.\nRather, their Kickstarter updates are gold dust. They are experienced designers and manufacturers, and they are narrating their experience from prototype to production in Shenzhen with a clarity, transparency, and education which is rare as hens teeth. Many of the updates are open to the public, not locked down to project backers.\nFor example:\n\nUpdate #4 which is about printed circuit boards\nUpdate #5 which is about injection moulding and electronics markets\n\nRead all the updates.\n3.\nBret Easton Ellis on Living in the Cult of Likability.\n\nNow all of us are used to rating movies, restaurants, books, even doctors, and we give out mostly positive reviews because, really, who wants to look like a hater? But increasingly, services are also rating us.\n\n(Uber, Airbnb.)\n\nWho wants to share a ride or a house or a doctor with someone who doesn’t have a good online reputation? The reputation economy depends on everyone maintaining a reverentially conservative, imminently practical attitude: Keep your mouth shut and your skirt long, be modest and don’t have an opinion. The reputation economy is yet another example of the blanding of culture, and yet the enforcing of groupthink has only increased anxiety and paranoia, because the people who embrace the reputation economy are, of course, the most scared.\n\nRead it.\n4.\nThis interview with Noel Gallagher in Esquire in 2015!\nI mean Gallagher always gives good interview but this is great.\nAlso when he says this\n\nI’m never going to write a song that connects with people as much as “Don’t Look Back in Anger” has, but that doesn’t stop me from going to the well every morning.\n\nwhich he has impressively managed to reconcile with this\n\nas a writer you surely always think that your best work is in front of you, even though I’m self-aware enough to realise it’s probably fucking behind me.\n\nAlso, also he does good swearing.\nRead it.\n",
    link: "/home/2017/11/01/filtered",
  },
  {
    title: "I wrote a story and you can read it",
    date: "17.30, Monday 4 Dec 2017",
    content:
      "I’ve mentioned here before that I’m part of a writing group called Upsideclown. We take it in turns to write short fiction, and I’m up today!\nIt’s a gentle tale of extraterrestrial visitations, and of rekindling old friendships. Here’s a taster:\n\nPetr held the Scotch egg still between thumb and forefinger, and cut it carefully in two. They sat in the library cafe. He placed the symmetrical halves side by side on the plate, two halves of egg in two half balls of sausage, centred on yellow yolks.\n‘The Dogon people, in Mali,’ said Bruno, eying Petr’s lunch, ‘were visited by aliens from the Sirius star system.’\n‘And you find somewhere scenic for the presenter to stand while they say this,’ said Petr, ‘so nobody notices how absurd it is.’\n\nRead: The search for another intelligence, by me, at Upsideclown.\n#\nI’m rusty at writing fiction so I’m loving being part of this rebooted writing group. But I’m also particularly pleased at how this story came out for a couple of reasons:\n\nI’m using characters and dialogue – it’s been a personal challenge to make full use of both, and I think I’m beginning to get the hang of it\nI’m beginning to write deliberately. For fiction I’ve always written intuitively before: hold an idea in my head and then just bang it out. Which is great but is very mood-dependent. This time I had a process: I sketched out a summary, turned it into an bigger summary, and then wrote out the story over a few sessions, finally making revisions. This process is not a breakthrough to anyone except me! But what it means is I can now handle stories longer than 1,200 words, and I can also work on them incrementally such as on the tube and in the evenings\n\nSo yeah. Learning the craft. It’s not my best story by any means, but right now it’s the one I’m pleased with most.\n",
    link: "/home/2017/11/13/filtered",
  },
  {
    title: "Filtered for two worlds",
    date: "12.53, Thursday 21 Dec 2017",
    content:
      "1.\nAccording to the excellent Radio 4 show In Our Time, politeness was an 18th century revolutionary philosophy.\nListen to the episode on Politeness here (28 mins).\nOr read this very rough transcript. (I’m ashamed to admit that I have a problem paying attention to podcasts, and would be much happier reading instead. So I loaded the MP3 into Simon Says and got that transcript back in a few minutes.)\nWhat politeness replaces is decorum:\n\nThe idea of decorum is is the notion that everybody’s supposed to behave according to their place in society, according to their age.\n\nAnd then there are more people talking: a move from a world of decorum - the nobility is only about 160 families - to a world governed by, well, it’s put in this lovely way: the amicable collisions of urban life.\n(Coffeeshops being part of this.)\n\nAnd that changed world means that it’s a world of debate and a world of public life, particularly in London; a world of socialising, and it needs a new model of behaviour and politeness comes forth.\n\nThis need collides with a reformist idea: the fundamental idea is the idea that the world can be - and we, the citizens of it - can be improved.\nThe idea of conversation gets internalised:\n\nwhen he talks about conversation he is talking about conversation between people but also an internal conversation … whereby you modify and develop yourself.\n\nPoliteness, and conversation, is a route to self-improvement, but also how to rub along together:\n\nhuman beings are naturally benevolent and this is a quite new notion of human nature, to insist on man’s capacity to love each other and to feel sympathy for each other and to respond empathetically to each other. And politeness is partly about feeling other people’s feelings, recognising how they respond in circumstances, traveling alongside with them in conversation\n\nMakes me wonder what a similar benevolent, positive philosophy - pointing inwards at the self and outwards at society - would be nowadays, and what new modes of interaction it could draw on. The internet I suppose. But how.\nSee also: the New Yorker on In Our Time and its host Melvyn Bragg which it describes (accurately) as four intelligent people in a studio, discussing complex topics that are … aggressively uncommercial.\nSome trivia: In Our Time was the BBC’s first podcast, and I set it up. This was back in November 2004, and the term had only been coined in February that year. The BBC was the first national broadcaster to do any podcasting at all. There are some funny little stories about hand-writing the XML files for the servers, and I should dig out the deck I made explaining podcasting, expressed in a way that we could avoid the BBC having to go back to the government to ask for permission to do it (we described it as “listener-scheduled radio”). A decade later, in 2014, the BBC announced 1.1 billion podcast downloads. In terms of effort expended, probably my most impactful work.\n2.\nLong Twitter thread on the Victorian idea of the ‘veil between the worlds’:\n\nThe concept of ‘thin places’ (where the ‘veil between worlds’ is thin) was even worse - deemed ‘ancient Celtic’, actually invented in 1938.\n\nBecause:\n\nNowadays we don’t think of spirits’ or Gods’ realms as physical places, but as ‘planes’. But back then, the Gods lived on Mount Olympus.\nHeaven was believed to be as physical as Earth. Hell could be reached through openings in rocks. The whole cosmology was different.\nOf course, now that the Earth is mapped, we needed to imagine otherworlds as ‘higher planes’. It was the only place for the unknown to be.\nThe idea of superimposition, borrowed from photography, was a convenient analogy for how people thought the spirit world interacted w/ ours.\n\nPhotography!\n3.\nThe concept of Thinning from fantasy (thanks Tom Stafford for sharing this on Facebook).\nBy way of intro:\n\nFantasy tales can be described, in part, as fables of recovery … the happy endings of much fantasy derive from the notion that this is a restoration, that before the written story started there was a diminishment.\n\nThen:\n\nThe passing away of a higher and more intense Reality provides a constant leitmotif in the immensely detailed mythology created by J R R Tolkien. The Lord of the Rings (1954-1955) comes at the end of aeons of slow loss. Within the global thinning manifested by the text throughout, local thinnings occur, examples including the realization that the elves are leaving Middle Earth for ever, or the return of Frodo to the Shire to find it has been thinned into a secular Waste Land. \n\nThe passing of the old and the beginning of the Age of Men.\nLook at Star Wars – the idea that there was a golden age of noble Jedi knights that has given way to scuffles and trade negotiations, the magic and chivalry ebbed away. And now being restored. Why is this appealing now, in 2017?\nIs the feeling that the world is thinning simply part of growing up? That as children, the world was magical – we were continuously confronted with that which we didn’t understand. Where beings with super-powers would swoop in and do things we couldn’t possibly understand, like conjuring up goods and services (paying for stuff) and teleporting (driving places). And now, as adults, we understand all (or at least, have learnt to avoid thinking too hard about what we don’t understand) and so the magic has gone?\nAnd then the restoration, an essential part of the thinning narrative, a coming to terms with this, the whole a meditation on becoming-adult?\nOr another manifestation of the wish that the one who saved us before - King Arthur, Roland, Jesus Christ - will come again, as a way of avoiding the hard work of actually buckling down and making the world better?\nAnyway. Feels timely.\n4.\nDappled light generator.\nomg how beautiful is this:\n\nCreated by Leslie Nooteboom, komorebi is a platform that uses a robotic projector and generative projections to replicate the natural reflections and shadows of sunlight. komorebi can create sunlight filtering through leaves or a dance of light and shadow.\n\nWatch the videos.\nSee also: CoeLux which appears to be a skylight but is actually an artificial sky, with calibrated angle and temperature to simulate a hot day in the Mediterranean or the Tropics.\nThe light of non-places leaking through.\n",
    link: "/home/2017/12/04/upsideclown",
  },
  {
    title: "Filtered for historical facts",
    date: "10.50, Monday 4 Jan 2016",
    content:
      "1.\nThe beautiful Crab Nebula… 6,500 light years away, 10 light years across. In the nebula’s very center lies a pulsar: a neutron star as massive as the Sun but with only the size of a small town.\nThe supernova that caused the nebula was visible from Earth in 1054 AD. There’s a rock carving of it, made at the time, in a canyon in New Mexico.\nSee also: An eclipse mentioned by Homer in the Odyssey has been precisely dated. We now know that Odysseus returned home, 10 years after the sacking of Troy, on April 16, 1178 B.C., close to noon local time.\n2.\nArchimedes was a weapons inventor who lived in Sicily, a battleground between Rome and Carthage in the Punic Wars. To protect his city, he invented heat rays and a giant hook called the Claw of Archimedes that was used to lift the enemy ships out of the sea before dropping them to their doom.\nHe was killed by a Roman soldier at the end of the Siege of Syracuse during the Second Punic War.\nThe Second Punic War is the one that started with Hannibal (a Carthaginian commander) crossing the Alps to invade Rome, spending 15 years traipsing round Italy with his army, generally causing havoc.\nSomething about connecting the dots between these historical characters makes them more alive for me.\nSee also: John Milton (author of the poem Paradise Lost) visited Galileo in Florence in 1638.\n3.\nWe know who invented paper.\nCai Lun: In A.D. 105, Cai invented the composition for paper along with the papermaking process.\n\nIn ancient times writings and inscriptions were generally made on tablets of bamboo or on pieces of silk called chih. But silk being costly and bamboo heavy, they were not convenient to use. Tshai Lun [Cai Lun] then initiated the idea of making paper from the bark of trees, remnants of hemp, rags of cloth, and fishing nets. He submitted the process to the emperor in the first year of Yuan-Hsing [+105] and received praise for his ability. From this time, paper has been in use everywhere and is universally called ‘the paper of Marquis Tshai’.\n\n4.\nHow Little Richard found God:\n\nAt the height of his fame, on tour in Australia in October 1957, he saw a big ball of fire in the sky above the stadium. … The message, to Little Richard, was clear. He had to leave show business … He enrolled at Oakwood College in Huntsville, Alabama, to study to become a minister.\n\nAnd:\n\nWhat Little Richard saw overhead in Australia was in fact Sputnik, the Russian satellite traveling 18,000 miles an hour in the night sky.\n\nSee also…\nIn 1899, in Colorado, Nikola Tesla heard a signal from Mars. He wrote in 1921:\n\nthe signals consisted in a regular repetition of numbers, and subsequent study convinced me that they must have emanated from Mars\n\nHowever:\n\nMarconi was transmitting messages hundred of miles across Europe and the English Channel during the summer of 1899 and was using as a signal the Morse-code letter S (dot-dot-dot), which precisely corresponds to the three beats Tesla said he intercepted\n\nI prefer to believe that Tesla heard Mars, and that Little Richard saw God.\n",
    link: "/home/2017/12/21/filtered",
  },
  {
    title: "Filtered for background",
    date: "12.05, Friday 15 Jan 2016",
    content:
      "1.\nTime-lapse of scenery in Red Dead Redemption.\nWestern video game. Keeping my fingers crossed for a sequel.\n2.\nHomo erectus made world’s oldest doodle 500,000 years ago.\nArt by non-humans would make me feel we had more company in the universe. I’m not quite sure this counts, but it’s close.\n3.\nThe art of viewing moss.\nMicroscopic rainforests.\n4.\nThe colour of e-ink… that grey screen that goes back to the first Amazon Kindle.\nOr these new London bus stops using e-paper, the same.\nWeb pages used to always have a grey background – inherited from the grey used by Mosaic in 1993.\nThe other day I stepped out of the tube and the sky was this medium grey – not matte, not dark, not bright, not quite pearlescent, just… there. The colour of an e-ink screen before the words arrive.\nSee also, blue.\n",
    link: "/home/2016/01/04/filtered",
  },
  {
    title: "Vincent van Gogh on the stars",
    date: "17.00, Friday 22 Jan 2016",
    content:
      "Letter from Vincent van Gogh to Theo van Gogh Arles, c. 9 July 1888:\n\nThat brings up again the eternal question: is life completely visible to us, or isn’t it rather that this side of death we see one hemisphere only?\n\nAnd:\n\nFor my own part, I declare I know nothing whatever about it. But to look at the stars always makes me dream, as simply as I dream over the black dots of a map representing towns and villages. Why, I ask myself, should the shining dots of the sky not be as accessible as the black dots on the map of France? If we take the train to get to Tarascon or Rouen, we take death to reach a star. One thing undoubtedly true in this reasoning is this: that while we are alive we cannot get to a star, any more than when we are dead we can take the train.\nSo it doesn’t seem impossible to me that cholera, gravel, pleurisy & cancer are the means of celestial locomotion, just as steam-boats, omnibuses and railways are the terrestrial means. To die quietly of old age would be to go there on foot.\n\nWhich, to me, puts his Starry Night on a bigger canvas than it had before.\n",
    link: "/home/2016/01/15/filtered",
  },
  {
    title: "Filtered for some nice words",
    date: "10.20, Monday 1 Feb 2016",
    content:
      "1.\nFrom this article about how computers play chess,\n\nThe values [of moves] are commonly measured in units of 0.01 called centipawns – figuratively hundredths of a pawn.\n\nCentipawns!\nSee also: The micromort which is unit of risk measuring a one-in-a-million probability of death. For example, simply living in England and Wales exposes you to 24 micromorts daily; flying 12,000 miles adds one more.\n2.\nLook, it’s awkward to mention anything by Ezra Pound – and by “awkward” I mean, wasn’t he a fascist and wildly antisemitic? Not the kind of ideas I want near me.\nAnyway, he wrote Revolt Against the Crepuscular Spirit in Modern Poetry which is… well, full of feeling.\n\nI bid thee grapple chaos and beget\nSome new titanic spawn to pile the hills and stir\nThis earth again.\n\nSee also Ozmandius by Shelley which I hadn’t realised was so short, just a sonnet, but picture-packed to the rafters.\n3.\nThe fall of Jersey: how a tax haven goes bust, an article which includes this gorgeous phrase:\n45 square miles of self-governing ambiguity entirely surrounded by water.\nThe ridiculous physics of the free market.\n4.\nSo there are rumours that gravity waves have been detected.\nBut waves in what? Waves in the fabric of spacetime itself, or in physics words: it’s perturbations to the Metric (a description of the curvature of spacetime), where zero-amplitude corresponds to Minkowski space.\nFrom the linked paper,\n\nThere are also a number of “exotic” effects that gravitational waves can experience … scattering by the background curvature, the existence of tails of the waves that interact with the waves themselves, parametric amplification by the background curvature, nonlinear coupling of the waves with themselves (creation of geons, that is, bundles of gravitational waves held together by their own self-generated curvature) and even formation of singularities by colliding waves\n\nYou know that feeling where you’re listening to choral music in Latin, or Buddhist chanting, and you don’t know the words but the sound of them is enough? Yeah. Perturbations to the Metric.\n",
    link: "/home/2016/01/22/van_gogh",
  },
  {
    title: "Augustus and Caesarion",
    date: "11.55, Monday 1 Feb 2016",
    content:
      "I’d like to read a story about these two.\nCleopatra, from an ancient civilisation and a family that rules an even more ancient civilisation, in 250 years the first to really put her roots down and speak the language.\nCaesar, bringing about the end of the republic, the expansionist warmonger of the upstart empire.\nThey fall in love. Love and politics. She has a son with him to cement the throne. For Caesar this is possibly his only son.\nCaesar is assassinated in the death spasm of old Rome. Cleopatra falls in love with his right hand man.\nCaesar’s adopted son - after a second war that engulfs the Mediterranean, the first being Caesar’s civil war - succeeds him: Augustus.\nCleopatra’s son, Caesarion, succeeds her.\nThen the upstart empire takes the most ancient one, and Augustus kills Caesarian.\nDid they meet? Caesarion escaped for a time and was lured back. Did they have a final conversation? That must have been something.\nTwo sons, two brothers. One by blood, one anointed; one with history on his side, the other with the future. Augustus was the founder of the Roman Empire, which would last 400 years.\nAnother story says that Caesarion escaped.\n",
    link: "/home/2016/02/01/filtered",
  },
  {
    title: "Filtered for rambling thoughts",
    date: "12.00, Monday 22 Feb 2016",
    content:
      "1.\nPosition. How fast position changes is velocity. How fast velocity changes is acceleration. How fast acceleration changes is… jerk. Then snap, crackle, and pop.\nHere it is explained:\n\nSo each one is a measure of how fast the previous one is going. Position is the location of your car, velocity is the speed of your car, acceleration is how hard you have the foot on the gas. jerk is how fast your foot is moving on the accelerator, snap is how fast your foot is accelerating on the accelerator. It can be conceptually visualized as the pedal controlling the thing you’re looking at as you just keep repeating it.\n\nAnd:\n\nThe thing is that large variations in ‘snap’ can be visible as “unnatural” or “uncanny” … A very consistent ‘snap’, even when “jerk” is strongly controlled, can make things feel overly precise or planned. Imagine someone “doing the robot dance”\n\n2.\nScientifically accurate images of Earth’s sky with Saturn’s rings taking into account shadows and latitudes.\nSee also: Views of Jupiter from the top and bottom.\nI was getting the tube back home the other day, just after sunset – the sky was burnt umber, all deep orange and brown and shadowed. And because it was late, it was dim, that low light where it’s not bright and not dark, but the clouds look painted on horizon, unlit. But so, yeah, it looked like a gas giant, a planet just hanging there.\nAnd I thought… Well, Nasa have their Pluto time widget which tells you at what time of day it’s the same brightness as it is around Pluto, for where you are. So I worked it out for Jupiter, where it’s about 1/27th as bright as Earth – which, it turns out, for London, on a winter’s evening, is about 6pm.\nSo by coincidence, that day in the late afternoon, I was looking out at a sunset with the colours and pattern of Jupiter, just as bright as Jupiter itself would look, if I was hanging by it in orbit, gazing across its deep clouds and churning storms.\nSee also: Images of whole galaxies as if they were teeny-weeny.\n3.\nBack in 2007, it used to be that tech startups were old Unix tools warmed over for the Web. grep is Google. finger is Facebook.\nThen there was an era where tech startups were about individuals doing stuff publicly. YouTube, blogging, Twitter.\nI think there’s a similar, simple pattern now: There are a ton of big startups aimed at doing stuff your parents used to do for you.\nUber is being carted around. On-demand laundry and odd jobs is about having someone pick up after you. Food delivery is about being cooked for.\nI know I have this preoccupation about being infantilised by brands – cynically: modern coffee is a thin excuse for grown adults to drink hot sweet milk from a sippy cup.\nBut there’s a difference between doing stuff for me (while I lounge in my Axiom pod), and giving me superpowers to do more stuff for myself, an online Power Loader equivalent.\nAnd with the re-emergence of artificial intelligence (only this time with a buddy-style user interface that actually works), this question of “doing something for me” vs “allowing me to do even more” is going to get even more pronounced. Both are effective, but the first sucks… or at least, it sucks according to my own personal politics, because I regard individual alienation from society and complex systems as one of the huge threats in the 21st century.\nThis user experience “stance” is similar to the dichotomy we see in Internet of Things consumer products: Is it me controlling the product with my smartphone, or does the product have smarts of its own? I favour the second. There are a lot of smart home gadgets that you need a phone to control. Fine.\nBut when you use Sonos speakers you find that they connect to the streaming music services across the Internet themselves. You ask the speaker to “tune in” to music using your phone. Then somebody else can use their phone to adjust the track, change the album, whatever.\nThe difference between these two stances sounds minuscule and academic… but one approach leaves the product diminished, no more than a physically rendered version of an app. And the Sonos approach allows the speaker to stand alone, and consequentially become more social and more part of the home.\nI don’t know how to refer to this design challenge (in Internet of Things, in artificial intelligence) except as stance. There must be a better way of talking about it.\n4.\nSome more imagery…\nBeautiful photos of Tokyo.\nGeometrica, patterns by Guy Moorhouse.\nThe gorgeous landscapes of Grand Theft Auto V.\n",
    link: "/home/2016/02/01/caesarion",
  },
  {
    title: "3 Books Weekly #1 - America and Essex",
    date: "09.00, Friday 4 Mar 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nWelcome to the first edition of 3 Books Weekly! Today’s books are shared by Russell Davies. Find Russell on Twitter as @undermanager and on the web over here.\nIf you enjoy these faves, please tell your friends, and look out for edition #2 on Friday next week :)\n-Matt\n#1. For Richer, For Poorer: Confessions of a Player, by Victoria Coren\n\nI bought this because I love books about poker and Victoria Coren always strikes me as a good egg when I see her on the telly. This book is so much better than those two facts would lead you to believe. She’s much more than a good egg, she’s a sharp and tender writer who soaks you in poker language (that you don’t quite understand and have to read like poetry) and then pulls you out and shows you the people and their world with clear, precise, ironic wit. You learn about the playing of the game, about the changes ‘the industry’ went through, you learn how poker slotted oddly but completely into her life. I’ve read a lot of books about poker. This is the best.\n\nFor Richer, For Poorer: Confessions of a Player: Amazon / Amazon UK\n#2. Cargo Of Eagles, by Margery Allingham\n\nOn another day I could easily be recommending a Dorothy L Sayers novel, probably Murder Must Advertise, I love golden age detective fiction novels. But I think what swung it for me is that Campion (Allingham’s hero) started as a parody of Lord Peter Whimsey (Sayers’ hero) and so he’s always a bit lighter and more fantastical - even in the later books where she takes things more seriously. And Campion has the best business card of all time. It reads: “Coups Neatly Executed, Nothing Sordid, Vulgar or Plebeian, Deserving Cases Preferred, Police No Object.” Cargo of Eagles is the latest of the later books, a treasure hunt and a jaunt, bouncing between London and the mysterious, hidden bits of smuggler’s Essex - “London’s back-door”, “the funnel through which secret goods or people were smuggled in or out of East London”.\n\nCargo Of Eagles: Amazon / Amazon UK\n#3. Blue Highways: A Journey into America, by William Least Heat-Moon\n\nRecommending this book is dangerous. It’s a book I loved when I was 15, it’s hard for me to be objective. It might be like me recommending Jonathan Livingston Seagull or The Weirdstone of Brisingamen. It was written in the late 70s by an English professor who lost his job and went to discover America - it might be the worst kind of hippy nonsense. But I don’t think so, because he sticks to the smallest roads on the map (the Blue Highways) and he visits the towns “that get on the map-if they get on at all-only because some cartographer has a blank space to fill: Remote, Oregon; Simplicity, Virginia; New Freedom, Pennsylvania; New Hope, Tennessee; Why, Arizona; Whynot, Mississippi.” He drives slowly and he visits diners and talks to the elderly and the odd and the punk-kid in you wants to hate it. But you can’t because it’s lovely. It made me want to drive around America, and it made me glad I did.\n\nBlue Highways: A Journey into America: Amazon / Amazon UK\n",
    link: "/home/2016/02/22/filtered",
  },
  {
    title: "Lessons on finding flow",
    date: "18.36, Monday 7 Mar 2016",
    content:
      "The following written using The Most Dangerous Writing App which deletes everything unless you type continuously for 5 minutes, on 29 February 2016 at 19:05. You get 5 seconds grace. Discoveries are made. Output follows.\nThis reminds me of that game on Radio 4 where you have to speak continuously for one minute, with no hesitation, deviation, or repetition. Except here I don’t this repetition matters. It’s all about not stopping.\nWhich means maybe it’s more like the movie Speed with Keanu Reeves where he couldn’t slow the bus down below whatever it was, 40 mph, or otherwise it would blow up.\nExplode.\nGo bang.\nOr maybe, it occurs to me, it’s more like that neuroscience experiment where you try to say as many difficult challenges as possible for a whole minute. And the effort of that results in more blood flow to the brain, and because that’s already a large amount of your oxygen usage anyway, that’s detectable, and your head should be warmer, or you end up breathing faster, or something like that.\nI don’t remember.\nThe weird thing with this experiment is that it’s not the paragraphs that are hard to figure out. I have enough time while I’m typing to choose something that comes next.\nNo. The problem is this:\nIt’s when I get halfway through a sentence and I don’t know exactly how to phrase what I way to say. So I usually pause for a second, delete, choose a different word. Or pause for longer, and in that gap go back and want to revise the previous sentence.\nWhich breaks my flow state. When I get lost in a particular word - a stutter if you like - I stop being able to think of what’s happening in the next paragraph.\nI feel that there’s a lesson here in how I write usually.\nNotes, discovered at this point 4 minutes in, that I need to remember for later, about how to write more fluently without using this app:\n\nI need to slow my writing down, in general, so that I can plan the next paragraph.\nI need to keep writing and keep moving forward. Don’t go back, don’t revise as I go. I can revise later, and that’s editing. The point is to write without stopping.\nI need to capture this state without the app.\n\nI’ve got to 5 minutes now, which is the stopping point, and already I found I have revised this sentence by deleting its second clause; I have gone back and added point 3 above which wasn’t there before; I am pausing slightly to second guess myself.\nSo, lessons. Time to stop.\nA week later\nLooking back on what I wrote a week ago, I boil it down to this:\nWriting and editing are separate tasks, and I should approach in different ways and at different times.\nI was only able to see this after finding flow for, what, four minutes. And this category of ideas that are only visible after some period of time, or some kind of journey… this is interesting to me.\nI’ve been reading about scoring centuries in cricket and there’s something resonant for me in those stories about getting to the magic 100: An individual game, every ball the same as the last but somehow not; a score made run by run. Don’t think about the 100 when you start, just start. Every ball on its merits. Even the greats remind themselves to watch the ball every time one is bowled. You can’t score runs from the pavilion.\n",
    link: "/home/2016/03/04/3_books",
  },
  {
    title: "3 Books Weekly #2 - Virginia Woolf, time, and the Dream",
    date: "09.00, Friday 11 Mar 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nWelcome to the second edition of 3 Books Weekly! Today’s books are brought come from Tina Aspiala. Find Tina is on Twitter as @spongefile and check out her Know Cards.\nIf you enjoy this, please forward to friends :) They can subscribe over here.\n-Matt\n#1. To the Lighthouse (Wordsworth Classics), by Virginia Woolf\n\nI first read this in high school, and found it a thin book dense with correct truths about how people work, how life works, what time really feels like, and many more things I didn’t quite understand but might if I reread it in a few years. Unlike other books that impressed me back then, I still agree with this assessment. One of the things that stuck with me over the years was seeing people as containing pools of water where dark movements in the depths create ripples visible at the surface that let you guess at what’s underneath. Much striving for perfection, achievement, insight, connection. Then, the sweep of the lighthouse light like a great photon-stream hand on the clockface of spacetime, regularly witnessing and wiping it all away.\n\nTo the Lighthouse (Wordsworth Classics): Amazon / Amazon UK\n#2. Here, by Richard McGuire\n\nI once had a long distance relationship at a time when webcams were rare, and I found just one in the city my girlfriend lived in, focused on the corner of a bus depot. I’d check on this regularly. Sometimes she’d come there to wave. Sometimes there’d be kids at four am sitting on the curb, chatting after clubbing and waiting for the earliest morning bus. One of them once dropped a piece of whitish trash there, and for weeks I watched it slowly make its way, randomly kicked and nudged in tiny increments, to somewhere off frame. That framed space itself, traveling through time as much as I was, became a personality I accidentally got to know. Here is the first book I’ve ever seen that does the same thing, but on a much larger scale. It travels only in time, not an inch in space in any direction. And layers vast distances of this time on the same page in a way that only a graphic novel can. Total head rush, like an unexpected drug effect.\n\nHere: Amazon / Amazon UK\n#3. Between The World And Me, by Ta-Nehisi Coates\n\nThis is all very much tied to a very specific kind of now, but Between the World and Me describes one thing I’ve never seen described as well anywhere else. Coates talks about the Dream, which I can only describe as the unexpressed story of how things are officially supposed to work. It’s the default story unless something about your particular circumstances or experience forces you out of some or all of it. And then he describes what it’s like to be pushed really, really far out of it, so far that you may as well be in another galaxy, so you see the whole thing (as much as you can without actually having experienced this yourself) as the bizarre, anxiously defensive, self-centered monster it is, and the damage it generates by maintaining its borders. It’s a point of view worth having access to.\n\nBetween The World And Me: Amazon / Amazon UK\n",
    link: "/home/2016/03/07/finding_flow",
  },
  {
    title: "Filtered for quick links",
    date: "17.30, Friday 11 Mar 2016",
    content:
      "1.\nA robot that sits on your back and feeds you tomatoes while you run.\n2.\nBy Mattel, toy race cars driven by live crickets.\n3.\nVideo: Star Wars by Ken Loach.\n4.\nThe bedrock under Manhattan and how it leads to taller buildings.\n",
    link: "/home/2016/03/11/3_books",
  },
  {
    title: "Filtered for vending machines",
    date: "13.25, Monday 14 Mar 2016",
    content:
      "1.\n30 bizarre vending machines from around the world.\nLive hairy crabs, cupcakes, acne medication, a real live person who hands out sweets.\nSee also this ticket machine in Japan, where pressing the “help” button leads to an attendant appearing from a tiny hidden door. I can’t figure out whether this video is real or not.\n2.\nBeautiful vending machines that sell fresh salads. (Made for office lobbies.)\nThe Auto Store… Versatile and modular, ASC provides a retail platform that can be easily adapted to any retail environment, integrating sales and smart locker compartments.\nSmart lockers are smart. See Doddle which now has concessions at train stations, allowing for e-commerce click and collect – and also returns.\n3.\nA brief history of book vending machines.\nSee also: The short story vending machine in Paris. Uses a receipt printer.\nAnd not forgetting that the modern paperback was popularised by Penguin, together with a new form of distribution and the ability to sell books outside traditional bookshops.\nThe New Yorker on mass-market paperbacks:\n\nMore than a hundred and eighty million books were printed in the United States in 1939, the year de Graff introduced Pocket Books, but there were only twenty-eight hundred bookstores to sell them in. There were, however, more than seven thousand newsstands, eighteen thousand cigar stores, fifty-eight thousand drugstores, and sixty-two thousand lunch counters—not to mention train and bus stations.\n\nSo…\n\nThe mass-market paperback was therefore designed to be displayed in wire racks that could be conveniently placed in virtually any retail space.\n\nI like this:\nYou can’t tell a book by its cover, but you can certainly sell one that way.\n4.\nVending Machine (2009) by Ellis Harrison:\n\nAn old vending machine is reprogrammed to release free snacks only when search terms relating to the recession make the headlines on the BBC News RSS feed.\n\nRelated: Tim Hunkin’s Novelty Automation: A new London arcade of satirical home-made machines – and if you haven’t visited already (it’s near Holborn) you must, you must.\n",
    link: "/home/2016/03/11/filtered",
  },
  {
    title: "3 Books Weekly #3 - featuring Kitschies award director Glen Mehn",
    date: "09.00, Friday 18 Mar 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks,\nWelcome to the 3rd edition of 3 Books Weekly, featuring recommendations from Glen Mehn!\nGlen is award director at the Kitschies, celebrating the speculative and fantastic in literature since 2009. Bonus recommendations: Check out this year’s winners announced just a couple of weeks ago.\nYou can find him on Twitter as @gmehn and his homepage is over here.\nIn teeny bookshop news… My bookshop is a vending machine :) Here’s a pic. Fit-out comes next, and the moving in date is Real Soon Now. The selection is 100% curated (so you’ll recognise some of the recommendations from this newsletter). We’ll have the pop-up open in Shoreditch, London, during April. There’s still a ton to do. Gulp.\nNow let’s hear from Glen :)\nHappy Friday!\n-Matt\n#1. The Machine, by James Smythe\n\nThe Machine is a story of unconditional love and the desperation that that engenders. The eponymous Machine was created to selectively edit memories in order to treat dementia and PTSD, and it seems like it worked, until it went terribly wrong. Now Beth wants her husband back. It’s short, by modern standards, and not a whole lot happens over the first three quarters of its length - and, in fact, the reader pretty much knows the plot of that chunk of the novel within a dozen pages. It grips the reader, though, this story of recklessness in the face of despair. It is criminal that this book is as unknown as it is. The paperback edition very unfortunately has a really poor-quality cover and printing. It’s sad, but the book is stunning.\n\nThe Machine: Amazon / Amazon UK\n#2. The Lie Tree, by Frances Hardinge\n\nIt won the Costa award - the second-ever children’s book to do so, and it’s heartbreaking and brilliant - Hardinge has been an undiscovered gem for years. What’s it about? In Victorian England, a famous Reverend scientist has secrets, and a personal shame. He has a series of sickly sons, most of whom have died, and the last of whom is writing left-handed. He is driven away from his home by scandal. His daughter, Faith, remains steadfast despite any evidence she has against him. She is his true daughter, clever and quick-witted and interested in science and used poorly, again and again. This Faith’s story of discovery of her own strength and what it means to be a modern woman; it is heartbreaking, true and absolutely wonderful in its awfulness.\n\nThe Lie Tree: Amazon / Amazon UK\n#3. Lagoon, by Nnedi Okorafor\n\nFour of my top books that I read over the two years I spent judging the Kitschies stick in my mind - and they’re all from either Nigerian or Nigerian diaspora authors. This book grabbed me by the throat and didn’t let go for a second. What happens when aliens invade the planet - and decide that the best place to land is Lagos, Nigeria? This book is a Nollywood drama smashed headlong into alien invasion, all steeped in Nigeria’s history, both real and legendary. It starts out looking like an eco-thriller, then weaves together the lives of a marine biologist, a soldier with strong ethics, and a Ghanaian rapper and at one point they get into an argument with a road. It’s absolute madness. The book is impressive in ambition and it doesn’t spoon-feed a thing; you’ll be rewarded with a range of emotion from laughter to terror to bleak, black humour.\n\nLagoon: Amazon / Amazon UK\n",
    link: "/home/2016/03/14/filtered",
  },
  {
    title:
      "3 Books Weekly #4 - featuring designer and founder Alexandra Deschamps-Sonsino",
    date: "09.00, Friday 25 Mar 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks – and welcome to 3 Books Weekly, edition #4!\nToday we have books shared by Alexandra Deschamps-Sonsino, designer and the mind behind Good Night Lamp, the internet-connected lamp that brings loved ones closer together. She also runs the long-standing and highly regarded community event, Internet of Things London.\nYou can find Alexandra on Twitter as @iotwatch.\nIn teeny bookshop news… We have a logo! Here’s a pic. The bookshop is called Machine Supply.\nAnd also we have a location! Google is hosting Machine Supply for the month of April, at Campus London in Shoreditch. Thank you Google! The vending machine is open for business next week. You’re the first to know. You’ll find today’s books from Alexandra for sale, as well as recommendations from previous editions of this newsletter.\nIf you enjoy 3 Books Weekly, please do share with your friends. They can subscribe here.\nHappy Friday!\nMatt\n#1. Ocean Sea, by Alessandro Baricco\nI bought this book accidentally I think when I was 23. There used to be a great bookstore on Ste Catherine in Montreal called Indigo. The type of place that you could browse in and sit with a friend while having a latte for hours. Anyway, I bought it there and have taken my copy with me on several relocations for 12 years and counting. It’s a book that introduced me to a type of absurdist and surrealist fiction that Alessandro Baricco masters completely and has me addicted now. It’s the story of a number of different characters whose lives are brought together by a little B&B by the sea, in an unknown time, in an unknown place. A young princess, a dangerous sailor, a painter that doesn’t paint, a writer that writes an encyclopaedia about the end of the sea, as I write it it sounds like fantasy but that’s not it at all. It’s about examining our lives as we do when we stare at the sea on a beach holiday.\nOcean Sea: Amazon / Amazon UK\n#2. Lee Miller: On Both Sides of the Camera (Bloomsbury Lives of Women), by Carolyn Burke\nI ended up buying this book after going to the V&A’s Surreal Things exhibition and it made me fall in love with Lee Miller’s work, incredible life in front of and behind the camera, and her tenacity. She was the only woman photographer to cover the Second World War for Vogue magazine after having worked as a model and a photographer. She learnt her trade from Man Ray, her lover, married an Egyptian and eventually married again to Sir Roland Penrose, a painter and the eventual founder of the ICA. Her experience and later years out of the limelight, with PTSD and alcoholism, working on a never-ending cookbook, became a sort of warning sign for my own career and any woman’s I think. A real inspiration, and a complex woman brought to light in the her only authorised biography.\nLee Miller: On Both Sides of the Camera (Bloomsbury Lives of Women): Amazon / Amazon UK\n#3. Staring At The Sun, by Julian Barnes\nThis book saved my life at a time when I was very depressed after I closed my first business. It’s the story of a woman and her relationship with the men around her, a pilot who stayed with her family during the war, her crazy uncle and her middle-aged son decades later. The timeframe and place isn’t completely clear but her experience is. It’s about a sense of loss when we think about the past and how we struggle to relate to the future. How quickly it all goes. I reread it every couple of years and find it very soothing. Barnes is great at relating the woman’s experience of the world which is rare.\nStaring At The Sun: Amazon / Amazon UK\n",
    link: "/home/2016/03/18/3_books",
  },
  {
    title:
      "3 Books Weekly #5: Featuring Benjamin Southworth on history and creativity",
    date: "09.00, Friday 1 Apr 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nFor 3 Books Weekly edition #5, I’m delighted to share recommendations from Benjamin Southworth, well-known in the start-up world as a catalyst here in London, through 3beards and more.\nCheck out the Unicorn Hunt job board, and find Benjamin on Twitter as @inthecompanyof.\nBookshop news! The vending machine opened for business at Campus London (Bonhill St, London) a few days ago. Thank you Google for hosting :) Here’s a photo. Here’s it in action.\nAnd it’s not only a bookshop in a vending machine – it’s a bookshop that tweets when it makes a sale. I couldn’t help myself, it had to be done. Follow @MachineSupply to check it out.\nCome visit. Campus is near these tube stops: Old Street, Moorgate, Liverpool Street.\nA new week means an ALL NEW SELECTION. Here’s a sneaky preview of the 12 books that will be stocked from Monday, you’re the first to know. They’ll be stocked for one week only. As always, every book is recommended by a Real Live Human. The recommendation is on a card on the front of each book.\nNow, on with the show. Happy Friday!\nMatt\n#1. A Little Life, by Hanya Yanagihara\n\nI’ve always been a reader, and it’s normal for me to have several books on the go at a time. However, as I went through my stack of the books nominated for the Man Booker, this one was a frightening prospect. It’s a beast of a book, physically, and emotionally. The story of 5 friends over 20 years. We become silent witnesses to a breathtakingly powerful story. A book to change philosophies and mental models, a depth charge for the soul.\n\nA Little Life: Amazon / Amazon UK\n#2. A Little History of the World, by Ernst Gombrich\n\nBest known by his seminal work “The Story of Art”, here Gombrich dissects history as if educating his 8 year old nephew in this charmingly generous romp through Greece, Iran, Moscow, and the world, as we’re taken on a journey of the most perfect paternal storytelling. A great shortcut to make up for not having read history at college.\n\nA Little History of the World: Amazon / Amazon UK\n#3. Act of Creation (Picador Books), by Arthur Koestler\n\nThe essential guidebook to your creativity. As someone who has to use creativity as a skill, there is much to be made of having many other creative pastimes, painting, sketching, music, for example. Koestler guides us through the various skills and impacts of why we create. Sadly no longer a set text, but in the age of screen framed myopia this remains more powerful and fascinating than ever.\n\nAct of Creation (Picador Books): Amazon / Amazon UK\n",
    link: "/home/2016/03/25/3_books",
  },
  {
    title: "3 Books Weekly #6: Anne Galloway, and the space-time of moss",
    date: "09.00, Friday 8 Apr 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks!\nWelcome to the 6th edition of 3 Books Weekly featuring Dr Anne Galloway!\nAnne’s an old friend, and her perspective on what it means to be a person of human, animal, or other variety - whether that’s informed by talking to shepherds as they use (or don’t use) drones, or hanging out with her sheep in New Zealand - is always mind-opening for me. Anne runs the More-Than-Human Lab at the Victoria University of Wellington, and tweets as @annegalloway.\nSome brief bookshop news… If you’d be up for sharing your recommendations, I’d love to stock them in the vending machine! You can find a mini questionnaire to fill in, and the latest weekly selection, right here. Machine Supply is a popup bookshop that has popped up at Campus London for the whole of April.\nAnd as ever, if you’ve enjoyed 3 Books Weekly, please share with friends :) They can subscribe here.\nHappy Friday!\nMatt\n#1. The People in the Trees, by Hanya Yanagihara\n\nI read a lot of novels, but this is one I read last year that really got under my skin. Written as an intellectual memoir, this is a story of first contact, culturally relative ethics, and universal cruelty. To my mind it epitomises the fragile beauty and durable disgrace of humanist modes of inquiry, but I remain most disturbed that I wish I could cross paths with Perina. I suspect it would change me forever.\n\nThe People in the Trees: Amazon / Amazon UK\n#2. The Mushroom at the End of the World: On the Possibility of Life in Capitalist Ruins, by Anna Lowenhaupt Tsing\n\nThis is an ethnographic account of companion species, one about (as Jedediah Purdy writes) “what we make of mushrooms [and] what mushrooms might make of us.” It’s a story of relationality and interconnectedness; a deeply curious and hopeful feminist ecology for the damaged worlds we share. I wish more research was like this. I wish more people thought like this.\n\nThe Mushroom at the End of the World: On the Possibility of Life in Capitalist Ruins: Amazon / Amazon UK\n#3. The Signature of All Things, by Elizabeth Gilbert\n\nThe protagonist Alma Whittaker is a peculiar - and utterly beguiling - combination of insatiable and humble. But I loved this story because it taught me something important about scales of lived experience, and I think that Alma was taught something important about scales of lived experience through her encounters with moss. Seriously, all that matters here is the space-time of moss.\n\nThe Signature of All Things: Amazon / Amazon UK\n",
    link: "/home/2016/04/01/3_books",
  },
  {
    title: "Hardware-ish coffee morning tomorrow",
    date: "11.35, Wednesday 13 Apr 2016",
    content:
      "[Short version: Coffee morning on Thurs 14 April in Old St! I sent this out to the coffee morning newsletter last week. Subscribe to the newsletter here.]\nMy Dearest Droogs,\nWe haven’t had a hardware-ish coffee morning at all this year. I’ve had no Thursdays because I’ve been avec job for a few months earning coins. I know, I know, but it happens to all of us sometimes. Still, done with that now, and fingers crossed I can avoid gainful employment for a little while longer.\nLet’s hang out and drink too much coffee and talk about hardware! Same bat-time, same bat-channel:\nThursday 14 April, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nSame old format… If you’re curious about, or working in… designing physical things, paper or weird sensors, installations, knitting, manufacturing, internet-connected doodads, retail for hardware startups, sculpture, investment, or whatever, please come along.\nThere’s no formal intros so it’s easy to sneak off if everyone is horrendous. (They’re mostly not.) Come say hi to me when you turn up, and we’ll make sure you chat with interesting folks. (Most everyone is interesting.) Everyone loves prototypes, so bring em along if you have em. There are usually one or two.\nIf you’re a woman, or don’t present or identify as a dude, please do feel welcome. It’s a concern to me that this tech industry, while very human and egalitarian in its early days (this goes for mainstream tech and hardware startups too) appears to heavily skew to Mainly Dudes as time goes on. That’s something I can push against, a tiny bit, by trying to ensure these coffee mornings don’t go the same way.\n(On which serious note: If you don’t feel you would be welcome - obviously or in hidden ways - at a hardware-ish coffee morning, and you’d be willing to share your feedback privately with ideas of how I could improve the format, I’d like to hear. My personal email is matt AT interconnected DOT org. Thank you!)\nSee you on the 14th!\nMatt\nps. I’ve got a new hobby and it’s a robot bookshop that tweets. You can visit it! Here it is. It’s called Machine Supply.\n",
    link: "/home/2016/04/08/3_books",
  },
  {
    title: "3 Books Weekly #7: Featuring Jeremy Keith",
    date: "09.00, Friday 15 Apr 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nFeatured in 3 Books Weekly #7 is maker-of-great-web-things Jeremy Keith a.k.a. @adactio. You may recognise Jeremy from his many speaking gigs, his podcast assistant Huffduffer, or many other places. You get it, he’s prolific.\nI’m super pleased to be able to share three book recommendations from Jeremy today. And not just because the ones he’s picked also happen to be favourites of mine…\nBookshop news! The residency at Campus London continues, come visit before it moves on at the end of April! I’m up for meeting folks who would like to host Machine Supply in London for a month or more. Lobbies, cafes and cultural spaces, etc, all worth a chat. I’m 80% locked down on a location for May, but June is wide open.\nA few ‘Sold Out’ signs are visible this week. That’s what we like to see :) Get the books while you can, there’s a new selection on Monday or Tuesday next week.\nA call for recommendations! The Machine Supply vending machine is stocked with books recommended by real humans. (That’s you.) I’d love to stock your picks. Fill in this online form to join in.\nHappy Friday!\nMatt\n#1. The Victorian Internet, by Tom Standage\n\nA book about the history of telegraphy might not sound like the most riveting read, but The Victorian Internet is both fascinating and entertaining. Techno-utopianism, moral panic, entirely new ways of working, and a world that has been utterly transformed: the parallels between the telegraph and the internet are laid bare. In fact, this book made me realise that while the internet has been a great accelerator, the telegraph was one of the few instances where a technology could truly be described as “disruptive.”\n\nThe Victorian Internet: Amazon / Amazon UK\n#2. Ancillary Justice: 1 (Imperial Radch), by Ann Leckie\n\nAfter I finished reading the final Iain M. Banks novel I was craving more galaxy-spanning space opera. The premise of Ancillary Justice with its description of “ship minds” led me to believe that this could be picking up the baton from the Culture series. It isn’t. This is an entirely different civilisation, one where song-collecting and tea ceremonies have as much value as weapons and spacecraft. Ancillary Justice probes at the deepest questions of identity, both cultural and personal. As well as being beautifully written, it’s also a rollicking good revenge thriller.\n\nAncillary Justice: 1 (Imperial Radch): Amazon / Amazon UK\n#3. The City & The City, by China Miéville\n\nChina Miéville’s books are hit-and-miss for me, but this one is a direct hit. The central premise of this noir-ish tale defies easy description, so I won’t even try. In fact, one of the great pleasures of this book is to feel the way your mind is subtly contorted by the author to accept a conceit that should be completely unacceptable. Usually when a book is described as “mind-altering” it’s a way of saying it has drug-like properties, but The City & The City is mind-altering in an entirely different and wholly unique way. If Borges and Calvino teamed up to find The Maltese Falcon, the result would be something like this.\n\nThe City & The City: Amazon / Amazon UK\n",
    link: "/home/2016/04/13/coffee_morning_14",
  },
  {
    title: "3 Books Weekly #8: Featuring futurist Natalie D Kane",
    date: "09.00, Friday 22 Apr 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nToday’s book recommendations come from Natalie Kane who is a researcher into (amongst other things) the future, and ghosts. I know right?? Natalie’s website is chock full of fascinating writing, and you can follow her on Twitter as @nd_kane.\nShe’s chosen to share a eclectic collection of books. It’s one of those selections that makes me want to read them all. I hope you feel the same way.\nSome quick bookshop news while I’m here!\n\nNext week is sci-fi week! Look out for new stock on Monday – follow @MachineSupply to get the latest\nThe residency at Google’s Campus building in Shoreditch comes to an end in two weeks. Booooo. HOWEVER, I have an exciting next location lined up… which I’ll say more about next week. In the meantime, come visit\nCrazy experience: the BBC did a piece on Machine Supply! The blimmin BBC!!!! So here’s a video of me gabbing on about vending machines. Thanks Team Beeline and Sarah Drinkwater (head of Campus) for taking part. btw the journalist asked me whether this was yet another example of the robots taking our jobs. Watch the vid to see my answer.\n\nThis is 3 Books Weekly #8 – hope you’re having a great Friday. Now let’s hear from Natalie.\nMatt\n#1. We Have Always Lived in the Castle (Penguin Modern Classics), by Shirley Jackson\n\nThis is a really recent read for me, and it hit me like a sledgehammer. I like quiet, bewitching books that aren’t necessarily full of action or adventure, but overwhelm you with the human relationships and neuroses within. It’s the story of a small family, hidden away after a terrible event, who are just starting their reconnection to the small town outside of their territory. Mary-Katherine, Merricat for short, buries things for protection, for good luck, or to keep the townfolk away. There’s a scene in this that will absolutely rip your heart out, and make you rage at the injustice thrown at this magical, painfully isolated family. It’s about how outsiders are seen by society, and what happens when a supposedly well-meaning outside world tries to make them fit. In so many ways the house, and the narrative, is frozen in time. It’s a really wonderful book, and the last chapter continues to haunt me.\n\nWe Have Always Lived in the Castle (Penguin Modern Classics): Amazon / Amazon UK\n#2. Fahrenheit 451 (Flamingo Modern Classics), by Ray Bradbury\n\nI’m a big fan of the very mundane, but highly human, fiction of people such as Raymond Carver and Carson McCullers. Bradbury sits there in the middle. I always come back to him when I think about the stories we should be telling about the future, which are first and foremost human, and secondly, far more mundane, and bureaucratic, and broken than we imagine. There’s a great scene early on in Fahrenheit 451, where Montag’s wife is sitting in the centre of her living room, watching the people on the televisions lining almost every wall in the apartment. It’s the vision of what we thought the future might be like, with the most impressive technology we can imagine, but when asked to tell them off, she tells him no, ‘They are my family.’ That line reveals something deeply disturbing about the character’s relationship to this kind of future, a supplement for any real engagement with physical, real, human beings.\n\nFahrenheit 451 (Flamingo Modern Classics): Amazon / Amazon UK\n#3. Playing the Whore: The Work of Sex Work (Jacobin), by Melissa Gira Grant\n\nThis is a fundamentally important book for anyone who wants to understand the work of sex work, the labour politics behind it, and most importantly, the people involved. I’ve been following Melissa’s writing for years and years, so when this book came out I was hugely excited. I was just starting to understand the unique issues around sex work, and this is a perfect primer who wants to know more, or want to look away from the often mainstream narrative that all sex workers need saving. It’s absolutely eye-opening, expertly arguing the importance of decriminalising sex work for the safety of those involved, and as a way to treat it how it actually is, work, with all of the laws and legislation involved. As Melissa goes on, separating it from the ‘legitimate’ economy, not removing stigma, is dangerous, and only marginalises further those we should be helping have these rights. It’s a book I vigorously nodded through.\n\nPlaying the Whore: The Work of Sex Work (Jacobin): Amazon / Amazon UK\n",
    link: "/home/2016/04/15/3_books",
  },
  {
    title: "How my Twitter bot makes personalised animated GIFs",
    date: "10.45, Wednesday 27 Apr 2016",
    content:
      "Ben Brown noticed that my bot @5point9billion made him a personalised animated GIF when it tweeted him yesterday (on the occasion of light that left Earth as he was born, right at that moment passing the star Iota Pegasi, a little over 38 light years away). And he was curious about how it did that. So:\nThere’s a previous write-up about @5point9billion here. From that post:\n\nMy new bot is called @5point9billion which is the number of miles that light travels in a year. The idea is that you follow it, tweet it the date of your birth (e.g. here’s my starter tweet), and then it lets you know whenever you reach Aldebaran or wherever.\nYou get tweets monthly, and then weekly, and for the last couple of days… and then you pass the star. It feels neat, don’t ask me why.\n\nSince that write-up, I’ve also added a website to the bot. In addition to getting the realtime notifications on Twitter, you can sign in on the site and see what stars you’ve already reached.\nCheck this out: There’s also a public view, with an animation. This is a 3D animated map of all the star systems we can see from Earth, within 100 light years. It sits there and rotated. You can type in your date of birth, and it’ll show you what stars you’ve already reached.\nI made this public view as a “kiosk” mode when @5point9billion was exhibiting at the Art of Bots show earlier this month. The stars were laid out on the floor, fanning out from the Sun which was right by the kiosk. Here’s a photo. It was good fun to walk out from the Sun till you find the star you’ve just passed. And then to walk out to about 80 light years and think, hey, most people die around this point, and look at the stars falling just further from you and think, hey, I probably won’t reach those. Huh.\nThe star map is drawn and animated in Javascript and WebGL using three.js which I really like.\nAnd doesn’t it look kinda the same as the personalised star map that the bot made for Ben? Yup.\nMaking animated GIFs\nI knew I wanted to tweet out personalised, animated star maps, whenever a bot follower passed a star (there are over 500 followers, and between 2 and 5 of them pass a star each day).\nRoutes I considered but discarded pretty fast:\n\nGenerating the star maps offline. For sketching on my Mac, I use a Python drawing package called PlotDevice – this is what I used to make the first quick-and-dirty star map. I don’t like generating graphics offline because I want the ability to tweak and change my mind\nDrawing the graphics frame by frame using a dedicated package like Cairo. But I already have star maps in Javascript for the browser. I don’t like the idea of having two routes to draw the same graphics for different outputs. Feel like a lot of work\n\nThis is the rendering pipeline I settled on:\n\nThe source animation is the same animation I use for the website… it’s drawn in Javascript using three.js. It’s just a page on my site\nI already have queues and asynchronous processing on my website. The website is all Python because that’s my preferred language, and I have a my own Twitter bot framework that I’m gradually building up (this is a whole other story)\nWhen a user passes a star, the machine responsible for that task adds a tweet to the send queue, and flags it for requiring media\nAt the appropriate time, the queue runner loads the animation page using PhantomJS which is a web browser that can run headless on the server. It’s possible to drive Phantom from Python using Selenium\nBecause the animation is created on demand, and generated just for this tweet, it can include personalised information like today’s date, and the name of the user\nThe animation exposes a single Javascript function, step(), that renders the next frame. Phantom has the ability to reach into a page and make Javascript calls\nUsing Phantom, each frame of the animation is generated by calling step(), capturing as a screen shot (as a PNG) to an in-memory buffer, and then down-sampling to half its original dimensions (this makes the lines sharper)\nUsing images2gif (this is the Python 3 version of the library), the frames are assembled into an animated GIF, and saved as a temporary file\nThe GIF is optimised by shelling out to gifsicle, a command-line tool for that purpose\nFinally, the media is uploaded to Twitter using Tweepy. Technically Twitter supports animated GIFs up to 5MB, but this is only available using a kind of chunked upload that Tweepy doesn’t yet support, so the GIFs have to come in under 3MB. Twitter returns a media ID, which the code associates with the queued tweet in my send queue, and that is posted when its time comes round. (The send queue ticks every 40 seconds, because Twitter rate limits.)\n\nIf you’re curious, here’s the source animation on the website. And here’s how it looks in a tweet.\nIf you want, knock the “draw=1” off the URL – you’ll get a blank page. Then call step() in your browser’s Javascript console and see each frame being generated.\nThere’s a wrinkle: Phantom doesn’t support WebGL, so the star map animation in three.js had to be re-written to draw directly to canvas… which three.js supports but you have to add custom sprites and a few other things. It gets hairy, and I’m super happy to have worked with @phl on that side of things – he looked after the Javascript drawing with his amazing code chops.\nAnother wrinkle: PhantomJS 2 (which this requires) installs on the Mac using Homebrew just fine, but is a pain to build on Ubuntu which is what my server runs. There’s a pre-built binary here.\nIn summary, this is a rendering pipeline which:\n\nFits my web-first approach… there’s no separate drawing package just for these animations, so debugging an image is as simple as opening a browser window\nMinimises the number of moving parts: I’ve added the ability to create images using Phantom but that’s it, there’s no separate drawing package or offline rendering\nIs agile: I can tweak and change last minute\n\nWhat else am I using this for?\nI prototyped this rendering pipeline with another Twitter bot, @tiny_gravity which just does a tiny particle simulation once every 4 hours. Sometimes it’s pretty.\nThis animation doesn’t use three.js for drawing, it uses processing.js, but the principle is the same. Again, the animation is just a webpage, so I can tweak the animated GIFs in the same way I tweak the rest of my website and bot behaviour. Here’s that animation as a tweet.\nOne of the things I’m most enjoying about having multiple projects is how they cross-pollinate.\nMy main side project right now is my bookshop-in-a-vending-machine called Machine Supply. Here it is at Campus, Google’s space for entrepreneurs in Shoreditch, London.\nIt tweets when it sells a book. Because of course it does.\nThe selection is changed over every Monday, and you’ll notice that each of the books has a card on the front (here’s a photo) because every book is recommended by a real human made of meat.\nThese cards and the shelf talkers (the label which says the item code and the price) are beautifully designed by my new friends at Common Works. But they’re a pain to produce: For layout, the templates are in InDesign (which I don’t have), then I have to send an Excel spreadsheet of the new stock over to Sam at Common Works, which he then puts into the template, and prints.\nMy new process comes straight out of the @5point9billion code. The browser is my layout tool.\nSo Sam moved from InDesign to the web, and here are this week’s shelf talkers as HTML. This is part of my admin site, I’ve temporarily turned off permission checking to this page so you can see. The template is automatically populated with details from the weekly planogram. (A planogram is the merchandising layout for a set of shelves or a store.)\nAnd here’s the exact same page as a PDF. The pipeline is taken from @5point9billion: Phantom is used to grab the webpage, and this time render it to a PDF, complete with vector fonts and graphics. Because it’s a PDF, it’s super exact – which it needs to be to print right and fit neatly on the shelf edge.\nIt’s much quicker this way.\nMy rule for Machine Supply, as a side project, is that it should take the minimum of my time, never feel like an obligation, and I should be able to manage it on the hoof. As a hobby, it should be Default Alive.\nSo automation is helpful. I like that this mode of generating PDFs can be done without my laptop: I can do everything from my phone, and print wirelessly.\nAnyway. You should follow @5point9billion! It’s fun, and you get a personalised animated GIF every time you pass a star, generated with the most ludicrous rendering pipeline ever.\n",
    link: "/home/2016/04/22/3_books",
  },
  {
    title:
      "3 Books Weekly #9: Featuring head of Campus London, Sarah Drinkwaker",
    date: "09.00, Friday 29 Apr 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi all!\nWe’re heading into the final week at Campus London, where the Machine Supply vending machine has been in the lobby since the end of March… our teeny popup bookshop is popping down on 5 May. (But immediately popping up somewhere else! Read on to find out where.)\nTo mark this chapter, 3 Books Weekly #9 features recommendations from the head of Campus, Sarah Drinkwater. Campus is Google’s space for entrepreneurs, a seven-storey space in east London with working space, hundreds of events, and mentorship for entrepreneurs. It’s jam-packed full of startups. I’m super grateful to Sarah - and to Google - for being our very first host! Find Sarah on Twitter as @sarahdrinkwater.\nIf you like her books, you’ve got a week to get your hands on them: They’re in stock right now. The 12 picks in the machine are refreshed every week, and this is the 6th selection, featuring recommendations from Sarah and several other folks. Check out the whole selection here.\nWhere next? On 5 May, Machine Supply will be moving directly to another central London location… the front lobby of Carmelite House, the brand new UK HQ of massive publisher Hachette, one of the “Big Five.” It’s an amazing spot, and just incredible that Hachette offered to host. We’ll be there for a month, and then who knows! Well perhaps you know: Drop me a note if you’d like to chat about hosting :)\nOh! One more thing. We’re trying out some new shelf-talkers. (A shelf-talker is that label on the shelf that tells you about the book.) You can now read the whole recommendation, plus see the book covers. Here’s a photo. I think they look neat.\nHappy Friday,\nMatt\n#1. Living Dolls: A Magical History of the Quest for Mechanical Life, by Gaby Wood\n\nWritten over a decade ago - before AlphaGo, Siri, and Google Now - this is a fascinating look at how long humans have been besotted with the possibility of mechanical life. Mixing history, science and belief, it covers everything from Edison’s failure to build a talking doll to the infamous Turk, a mechanical chess player who toured the US and Europe in the 18th century before its secret was revealed…\n\nLiving Dolls: A Magical History of the Quest for Mechanical Life: Amazon / Amazon UK\n#2. What a Carve Up!, by Jonathan Coe\n\nA big, meaty, funny, angry novel. The Winshaw family have many fingers in many pies, from tabloid newspapers to intensive poultry farming and filmmaking. A screwball comedy with a real political point to make about inequality and the state we’re in.\n\nWhat a Carve Up!: Amazon / Amazon UK\n#3. The Bloody Chamber And Other Stories, by Angela Carter\n\nRemember those stories we all grew up with - Bluebeard, Hansel and Gretel, Little Red Riding Hood? Carter rewrites, chops and inverts them. Rich, fantastical and radical.\n\nThe Bloody Chamber And Other Stories: Amazon / Amazon UK\n",
    link: "/home/2016/04/27/making_animated_gifs",
  },
  {
    title: "3 Books Weekly #10: Featuring artist James Bridle",
    date: "09.00, Thursday 5 May 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks, and welcome to edition 10 of 3 Books Weekly.\nI’m super pleased that today we have artist and writer James Bridle sharing his book recommendations. James is also an essayist, and his website is well, well worth a few hours digging and reading.\nYou may know already know James through his drone series of artworks and installations. Exhibitions here. Find him on Twitter as @jamesbridle.\nBookshop news: Machine Supply has a new home! For the next month, we’re being hosted by Hachette in their new HQ on the Thames in London. Everyone’s welcome to visit. Opening hours and a photo are over here. It’s awesome of Hachette to host like this. (If you’re in London and could host Machine Supply in June, drop me a note!)\nLet’s get straight to the books. Happy Friday all.\nMatt\n#1. The Argonauts, by Maggie Nelson\n\nMaggie Nelson is an American poet, critic, and essayist, whose work often combines elements of all three to beautiful and powerful effect. In “The Argonauts” she writes about and through her own experience of queer motherhood and family, and her relationship with her trans partner and community. The result is never less than visceral and lyrical. Bodies are twisted by sex, transformed by hormones, bruised and birthed, and intertwined with theory, quotes, memoir and art history. For Nelson, the body and the word are always in a process of becoming, full of reference and history, but also capable of forging their own identity and new, startling presence in the world.\n\nThe Argonauts: Amazon / Amazon UK\n#2. A Prehistory of the Cloud, by Tung-hui Hu\n\n‘The cloud’ is one of today’s most pervasive metaphors: a universal utility, providing computation, connection, and storage on demand, while also threatening privacy, international law, and personal agency. In this ‘prehistory’, Hu thoughtfully explores both the physical infrastructure of the cloud - the millions of computers, cables, and datacentres distributed around the world - and its metaphysical implications. As we become ‘users’ of computers, a process which started with 1960s time-sharing technology, we also become modern ‘subjects’: expressing ourselves through social contribution and media production, tracked and tagged whatever we do. The cloud is one expression of modernity itself: the promise of individual freedom and creative expression, bound by a Faustian pact with vast and often hidden powers.\n\nA Prehistory of the Cloud: Amazon / Amazon UK\n#3. Round the Bend (Vintage Classics), by Nevil Shute Norway\n\nNevil Shute is best known for the apocalyptic “On the Beach” and the romantic “A Town Called Alice”, but he also wrote a number of novels based on his day job as an aeronautical engineer. In “No Highway”, the unassuming air crash investigator Theodore Honey battles powerful corporate interests to ground a fleet of unsafe early jet planes, winning the heart of an air hostess and a Hollywood star along the way. “The Trustee in the Toolshed” tells the story of an engineer and model-maker who travels half way round the world to secure his niece’s inheritance, learning to fly and sail en route. But “Round the Bend” is perhaps the strangest: against the background of post-war aviation and the birth of the Persian Gulf oil industry, a young flight engineer starts a new religion based on aircraft maintenance, inspiring thousands of followers across the Middle East and Asia. Schute blends science with a personal mysticism - and takes a strong stand against Imperial racism and intolerance.\n\nRound the Bend (Vintage Classics): Amazon / Amazon UK\n",
    link: "/home/2016/04/29/3_books",
  },
  {
    title: "3 Books Weekly #11: feat. Hachette’s George Walkley",
    date: "09.00, Friday 13 May 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nToday’s picks are by George Walkley, who is head of digital for Hachette UK – Hachette is one of the “big five” book publishers. So in addition to being three cracking picks, these are all very relevant to an Internet of Things bookshop in a vending machine :) Find George on Twitter as @walkley.\nHachette is also currently hosting the bookshop. It’s Friday today, so that means there’s a new selection of 12 books for the week. If you’re near Hachette’s HQ on the Thames by Blackfriars, do pop in. George’s picks are stocked there right now! Check out the whole list of books and get a map to the location… here.\nOkay, on with the show. Happy Friday, all.\nMatt\n#1. The Wolves of Willoughby Chase (Vintage Children’s Classics), by Joan Aiken\n\nThere’s something particularly lovely about rediscovering a childhood favourite through your own children reading it, as happened recently with this. Set in an alternate Britain where Jacobites rule instead of Hanoverians, The Wolves of Willoughby Chase is a spendidly atmospheric, creepy story of two children discovering that the danger of the world at large is as nothing next to danger close to hand. If you drew a line from Dickens to Philip Pullman, this would be on it. Incidentally, I also love the slightly Edward Gorey-ish cover on this reissue.\n\nThe Wolves of Willoughby Chase (Vintage Children’s Classics): Amazon / Amazon UK\n#2. How to Lie with Statistics (Penguin Business), by Darrell Huff\n\nA splendid and highly practical book for the lay reader on how statistical data can be twisted to mislead the unwary. It shows its age in some of the language and examples, but overall it’s written in a highly accessible style. Hopefully no one reading this recommendation will use it to deceive, but buy it and you’ll be forewarned against others doing so. It’s a book that changes forever the way you look at newspapers, politicians’ statements, market research and other data.\n\nHow to Lie with Statistics (Penguin Business): Amazon / Amazon UK\n#3. The Art of the Publisher, by Roberto Calasso\n\nI’m currently very taken with short form non-fiction: 25-30,000 words is the perfect length to be able to commit to a book, read it in an evening and have a sense of closure – as opposed to the uncompleted thousand page books that reproach me from the shelf. This is a lovely example of the form, a collection of essays by the Italian publisher Roberto Calasso on the history and meaning of his trade from Aldus Manutius to Google: in the Renaissance origins of the business, Calasso sees how it can remain relevant in an era of abundant content.\n\nThe Art of the Publisher: Amazon / Amazon UK\n",
    link: "/home/2016/05/06/3_books",
  },
  {
    title: "3 Books Weekly #12: feat. Debbie Chachra",
    date: "09.00, Friday 20 May 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nFor edition 12 of 3 Books Weekly I’m delighted we have Debbie Chachra. I don’t know if you’ve been following the recent newsletter trend, but if there’s such a thing as a 21st century essayist crossed with having privileged access to a special perspective on the world… that’s what you get with newsletters, straight to your inbox. And Deb’s Metafoundry is a must-read. Go subscribe as soon as you finish this. And find her on Twitter as @debcha.\nIf you’re in London, come visit my teeny bookshop in a vending machine – it’s near Blackfriars tube. Map and stock list here. There’s a brand new selection every Friday, and if you’re inspired by Deb’s recommendations, you can find a couple of them ready to buy there and then. Latest news, as always, at @MachineSupply.\nHappy Friday!\nMatt\n#1. The Real World of Technology (Massey Lectures), by Dr Ursula M Franklin PH.D.\n\nVery, very rarely, you re-read something from your youth, and you realise how much it’s shaped you. I first read The Real World of Technology, based on Ursula Franklin’s 1989 Massey Lectures (broadcast on CBC Radio in Canada) as an engineering student in the department where she was Professor Emerita. The essays describe how technology shapes culture and society, and how we need to see this as an active, volitional process. It’s not a book with answers; it’s a book of frameworks and questions, that gently but insistently exhorts us to thoughtfully consider our technologies and the social systems they engender. When I re-read it a few years ago, I was stunned at how much my personal philosophies of engineering and of education were rooted in her ideas, and decades having elapsed, her prescience was clearly apparent. It’s a worthwhile read for anyone, but it’s absolutely mandatory for technologists.\n\nThe Real World of Technology (Massey Lectures): Amazon / Amazon UK\n#2. A Wrinkle in Time (A Puffin Book), by Madeleine L’Engle\n\nLike Meg Murry, I was a bespectacled, braces-wearing, messy pre-teen girl, who loved math and science and mostly lived inside my own head, and I must have identified with her in a way I didn’t with, say, Anne Shirley (she of Green Gables, another favourite). And I now have a better understanding of the rarity of a children’s novel from the 60s with a girl as protagonist and agent and where the boys were sidekicks (the book racked up twenty-six rejections before it was published). But for me, A Wrinkle in Time was a gateway drug to science fiction; to the idea that the universe is immense and complex, simultaneously knowable and unknowable; and an early demonstration that, despite much cultural messaging to the contrary, science and warm humanity are not incompatible. I was a precocious kid, and when I lay on the ground and stared at the sky as a child, it was in full knowledge of the scale of what I was looking at. I still gaze out at the stars, and I still return to this book.\n\nA Wrinkle in Time (A Puffin Book): Amazon / Amazon UK\n#3. Dept. of Speculation, by Jenny Offill\n\nDept. of Speculation is a Japanese rock garden of a novel. It’s small, entirely contained, and composed of discrete components-the book is less than two hundred pages long, and largely consists of short, self-contained passages, some cryptic, some witty, some deeply moving, some all of the above. At first glance, it seems like an entirely formal exercise-what possible mapping could there be between these carefully-placed rocks on raked gravel and the reality of a tangled forest? But, like the rock garden, the individual elements of Dept. of Speculation add up to a cohesive, absorbing whole of a novel that captures the essence of its subject matter unexpectedly and beautifully.\n\nDept. of Speculation: Amazon / Amazon UK\n",
    link: "/home/2016/05/13/3_books",
  },
  {
    title: "3 Books Weekly #13: feat. investor Philipp Moehring",
    date: "09.00, Friday 27 May 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHullo folks – and please welcome Philipp Moehring to 3 Books Weekly!\nPhilipp’s an investor, and looks after everything Europe at AngelList. I’m always intrigued to see what people who are focused on the future (which an investor has to be) pick when they’re recommending books. This is a great mix, a bit of fiction and a bit of non-fiction… including one that I’ve had recommended to me so many times that I’m embarrassed I haven’t read it. I’m not going to say which it is.\nFind Philipp on Twitter as @pmoe.\nALSO! You can find two of Philipp’s picks in the vending machine right now. Friday is new books day, and I stocked them just a couple hours ago. They’ll be there all week or until they sell out. Newsletter and machine in sync. It’s what they call OMNICHANNEL RETAIL, people. Full stock list, and a map so you can visit here.\nHey, a couple of requests…\n\nIf you’re enjoying 3 Books Weekly, please share with your friends. They can subscribe here.\nI’m thinking about where Machine Supply should go in July and August. It has to be London so I can tend it. I’d love to have the vending machine in somewhere like a WeWork co-working space, or a big busy cafe. If you know someone who works in facilities or marketing at a place like that, can you put me in touch? Thanks!\n\nOkay, onto the main event. Happy Friday all!\nMatt\n#1. The Stand, by Stephen King\n\nThis is the Stephen King version of the dystopian future. Wrecked by a superflu epidemic, the few survivors band together through a treck across the states and start building a community. All the while, the bad and ugly is collecting powers in a different place… This is Stephen King at his finest: Incredible characters, deep relationships, and the supernatural somehow believably weaved in. Caution: The new and extended version is another few hundred pages longer than the already “obese” first version. I liked it, because I like reading.\n\nThe Stand: Amazon / Amazon UK\n#2. Ready Player One, by Ernest Cline\n\nHey, saw how augmented reality is all the rage? Saw how the FBI tried to get access to that guy’s phone?? See how corporations control your f*cking life???\n\nReady Player One: Amazon / Amazon UK\n#3. The Fabric of the Cosmos: Space, Time and the Texture of Reality (Penguin Press Science), by Brian Greene\n\nThis is the hardest book I ever read (ok, maybe apart from “Accounting for Supernational Evil Corporations” in Bschool). It explains the somewhat-current status of physics research (string theory, time travel theories, relativity, and all the other things you have no real idea about) in “everyday language”. It took me about 10 minutes per page to read, but oh did I feel smart afterwards. I’m reading it again now because I realize how much I loved it, and how little of it I understood.\n\nThe Fabric of the Cosmos: Space, Time and the Texture of Reality (Penguin Press Science): Amazon / Amazon UK\n",
    link: "/home/2016/05/20/3_books",
  },
  {
    title: "3 Books Weekly #14: Featuring Gollancz editor Marcus Gipps",
    date: "09.00, Friday 3 Jun 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nI’m a massive fan of the SF Masterworks series of classic science fiction – it’s published by Gollancz, and I don’t know how much of the series I have on my bookshelves at home… I’d have to measure in feet instead of counting. Big fan. Gollancz is the UK’s oldest SF + fantasy publisher.\nAnd today we have recommendations from Gollancz’s Marcus Gipps! Super pleased to welcome him here, and not only because I’m a giant sci-fi nerd. You can find Marcus on Twitter as @marcusgipps. Thank you!\nIt’s sci-fi week in the vending machine this coming week. You’ll find all of Marcus’s recommendations there, PLUS there are three more titles at the special price of lb1. YES THAT IS CORRECT, BOOKS FOR ONLY ONE SINGLE ENGLISH POUND.\nSo check it out… here’s the map and full book list.\nIt’s our final week at Hachette. Booooo :( HOWEVER I am delighted to announce that from Friday 10 June till mid July, we’ll be hosted by Lost My Name, makers of those wildly popular personalised kids books. Awesome. I’ll be doing a talk there in a couple weeks. Sign up to come along.\nLet’s hear from Marcus. Happy Friday!\nMatt\n#1. Riddley Walker, by Russell Hoban\n\nI’d love you to read this because, quite simply, I believe that Riddley Walker is one of the most powerful, affecting, clever and remarkable books ever published. It isn’t out of print, or languishing forgotten, but it doesn’t get the attention it deserves. I could go on and on about it - the reworking of myth, science and history into a new religion in this new world, the highs and lows you will feel alongside poor Riddley - but to me they’re all adjuncts to the most impressive piece of sustained writing I’ve ever read. I urge you to set aside some time, ready your brain, and delve in.\n\nRiddley Walker: Amazon / Amazon UK\n#2. Rivers of London: 1, by Ben Aaronovitch\n\nA wonderful book about London. Oh, there are police officers and a murder to investigate and even some magic, but at its heart this is Ben’s love letter to the city. You’ll read certain sections and think ‘yes, that’s exactly what that area is like’. You’ll learn about the mythology and history of London. And you’ll get caught up in the adventures of PC Peter Grant as he discovers that there’s more to London than he had previously believed. And then you’ll go out and buy the next one…\n\nRivers of London: 1: Amazon / Amazon UK\n#3. Sarah Canary (S.F. MASTERWORKS), by Karen Joy Fowler\n\nFrom the author THE JANE AUSTEN BOOK CLUB, this debut is a remarkable piece of historical science fiction. Or is it? Set in the Old West, we follow the - frankly quite strange - Sarah Canary as she gets embroiled in a series of strange adventures. By turns funny, moving and scary, this is a very different novel and one which repays close reading.\n\nSarah Canary (S.F. MASTERWORKS): Amazon / Amazon UK\n",
    link: "/home/2016/05/27/3_books",
  },
  {
    title: "3 Books Weekly #15: Kim Plowright and books about messy emotions",
    date: "09.00, Friday 10 Jun 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nToday we’ve got 3 books picked by Kim Plowright who is incidentally an old friend, but more meaningfully a bringer-to-life of all kinds of awarding-winning things on the internet. Kim is @mildlydiverting on Twitter, and you can find her homepage here.\nThis is usually the bit where I say you can find these books in the vending machine. HOWEVER, the vending machine [left Hachette this morning] and is now located at Lost My Name – hot tech startup and makers of super personalised kids books. Here’s a pic. It’s in their office and just for staff and guests for the next month or so.\nI want to say a huge and public THANKS to Hachette UK and especially George Walkley for making the last month possible. It’s been brilliant to have Machine Supply in your lobby, and to enjoy the feedback from v smart people who love books. \nOkay, gotta go, happy Friday all!\nMatt\n#1. Keeper: A Book About Memory, Identity, Isolation, Wordsworth and Cake …, by Andrea Gillies\n\nA powerful, honest memoir of a writer who moved her family to Scotland as their elderly mother developed dementia. It’s not just a tearjerker; it won the Orwell Prize and Wellcome Trust awards for science communication, and tackles the science behind the illness as well as the human story of the loss of self for those with the disease, and those who look after them. More than any self help book or carefully written leaflet, this book helped me understand and prepare for the realities of caring for my father as he slowly died of Alzheimers.\n\nKeeper: A Book About Memory, Identity, Isolation, Wordsworth and Cake …: Amazon / Amazon UK\n#2. Original Bliss, by A.L. Kennedy\n\nAn amazing collection of short stories (and a novella) that deal with the frail, silly, broken ways that people deal with sex. A.L. Kennedy is a wonderful writer - dark, funny, and somehow clear-sighted; writing about difficult, messy emotions with a kind of honest tolerance and affection. And oh, such words. This remains my favourite of her books, probably because it was one of the first I read.\n\nOriginal Bliss: Amazon / Amazon UK\n#3. The Bone Clocks, by David Mitchell\n\nLike Cloud Atlas, this book dances at the edge of science fiction. A story of a runaway, it slowly opens up an interconnected web of people and powers - and hints that Mitchell’s books might all be part of a bigger universe. I’ve fallen out of the habit of reading fiction in the last few years, but this book completely absorbed me. The last segment has particularly stuck with me, changing the way I imagine the near-term future.\n\nThe Bone Clocks: Amazon / Amazon UK\n",
    link: "/home/2016/06/03/3_books",
  },
  {
    title: "Hardware-ish coffee morning, this Thursday",
    date: "09.40, Monday 13 Jun 2016",
    content:
      "I figured it might be fun to get together for coffee this week? Usual game – nothing formal, just hanging out in a cafe with a bunch of folks in the same game. Hardware startups, electronics, physical installations for work, hobby Internet of Things stuff at home, or simply following along by backing tons of Kickstarter projects…\nI’ll be at the Book Club (100 Leonard St) from 9.30am on Thursday 16 June.\nCome join me! Would be great to catch up. I’ll make sure I have some Machine Supply badges with me.\nThere’s a newsletter for these announcements. Subscribe here.\n",
    link: "/home/2016/06/10/3_books",
  },
  {
    title:
      "3 Books Weekly #16: Featuring Lost My Name founder David Cadji-Newby",
    date: "09.00, Friday 17 Jun 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nToday I am super delighted (and a bit awe-struck) to have recommendations from David Cadji-Newby – BBC comedy writer, novelist, children’s author, and co-founder of Lost My Name. I’ve been googling him - as you do - and this interview stood out, it’s worth a read for David’s take on the world and the story of the company. An inspiring story, as you’d expect.\nFind him over here on Twitter: @DavidCadjiNewby\nLost My Name creates personalised (and beautiful!) kids books, and they’re a phenomenal success. It’s where Machine Supply is located this month – it’s for staff only except on event days. I’m doing a talk there next week… follow that previous link to find out more. You’ll find David’s book picks in stock and a bunch more.\nLet’s see, what else? I got some Machine Supply badges made! They’re hard enamel and feature the logo designed by Common Works. I’m really pleased with them. Here’s a pic. I’ll be in touch with everyone who has shared recommendations for the vending machine soon, I’d like to send you a badge in the post.\nAnd if you’d like to share recommendations, I’d love to stock your books too :) The form I use to collect recommendations is right here.\nOkay, let’s get on with the show. Happy Friday all!\nMatt\n#1. The Road Home (Bello), by Jim Harrison\n\nEscapism is often used in a disparaging way, for pulp fiction packed full of thrills, suspense and implausible plots. But Jim Harrison writes novels so poetic and profound, so beautifully written and full of humour, that just the reading of the words, never mind the plot (which there isn’t a lot of) takes you away to a different place. This novel is a sprawling family epic of the mid-West, but that hardly matters. I’d read Jim Harrison’s guide to flat-pack furniture, frankly, just to enjoy his unique and wonderful voice.\n\nThe Road Home (Bello): Amazon / Amazon UK\n#2. A Perfect Spy, by John Le Carré\n\nPeople often think of John le Carré as a slightly old-fashioned, oh-so-British espionage writer. Well, they’re half right. But only half. This book is half spy novel, half Bildungsroman, and full of contradictions, the main one (in my opinion) being that it is simultaneously one heck of a page-turner, and also a gobsmackingly brilliant postmodern exploration into the unreliability of both identity and narrative. Philip Roth called it ‘the best English novel since the war,’ and I reckon he’s right.\n\nA Perfect Spy: Amazon / Amazon UK\n#3. Into Thin Air, by Jon Krakauer\n\nI’ve never climbed a mountain in my life and, to be honest, I don’t want to. It sounds like hard work and, after you’ve read this, bloody dangerous with it. But this account of a doomed expedition to summit Mount Everest is insanely compelling. Egos, hubris, heroes, villains, selfishness, selflessness, endurance, tragedy, it’s got the lot. I read it on a plane from Nepal. I’m scared of flying, but this time I was too engrossed to be scared. It reads like a novel (often said about non-fiction, usually a lie) and the best thing is, no matter how unreal a lot of it sounds, it actually happened.\n\nInto Thin Air: Amazon / Amazon UK\n",
    link: "/home/2016/06/13/coffee_morning",
  },
  {
    title: "3 Books Weekly #17: Life in a changing world",
    date: "09.00, Monday 27 Jun 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nAn eventful week last week. I figured I would delay this edition of 3 BOOKS WEEKLY from Friday till today.\nWe’ve got a great selection today – Daniel Fogg has given us recommendations for three books that I would never have encountered otherwise. And, for me, that’s what this is about: New perspectives, a chance to see through the eyes of someone who really knows their stuff.\nDaniel’s picks are in the machine this week, and you can find him on Twitter as @danielfogg.\nMore recommendations wanted! If you’d like to share your 3 books for this newsletter, or for the vending machine, please do contribute using this form.\nHave a great week, and look after yourselves\nMatt\n#1. How to Get Filthy Rich In Rising Asia, by Mohsin Hamid\n\nThis is a story about, well, you! Told in the rarely-used second-person, and written in the popular style of a self-help book, the author places you in the position of the unnamed protagonist at several key points in your life. It shows how you go from nobody to somebody, from poor to rich, from alone to in love, in a claustrophobic, chaotic unnamed city in South Asia. Intense, funny and incredibly well observed, this book is an empathy overload and it had a big impact on me. I have worked in India and Pakistan, developing and deploying new technology in some of the poorest, toughest parts of these two fascinating, complex societies. For me, this book reveals more about life in South Asia than any article or account that I have read.\n\nHow to Get Filthy Rich In Rising Asia: Amazon / Amazon UK\n#2. Eastern Approaches (Penguin World War II Collection), by Fitzroy MaClean\n\nThis book was lent to me by a boss and mentor I worked with in the security industry when I was 24, and it reinforced my desire to travel and work in some of the world’s most interesting/dangerous countries. Not because of the adventure (although that is, admittedly, part of it), but because I believe you can never truly understand a place or its people without going there and getting involved. This is a man who happened to be involved in some of the 20th century’s most important geopolitical events. He travelled incognito to early-Soviet Central Asia, attended Stalin’s show trials, was recruited into an early incarnation of the SAS to fight Nazi Germany in the Middle East and, at the personal request of Winston Churchill, helped Tito form an underground resistance to Hitler’s forces in Yugoslavia. It is this remarkable career that has led many to believe Ian Fleming used MacLean as inspiration for James Bond. MacLean provides a fascinating account of life on the frontline during WWII.\n\nEastern Approaches (Penguin World War II Collection): Amazon / Amazon UK\n#3. Out of the Mountains: The Coming Age of the Urban Guerrilla, by David Kilcullen\n\nWhen people think about military theory, they think about Sun Tzu, Clausewitz and probably Machiavelli. While the lessons from those books are still valid, the nature of modern conflict is changing fast. “Out of the Mountains” is about the future of urban warfare and how communication technology, population growth, resource scarcity and urbanisation will define the future of crime, violence and armed conflict. Its author, David Kilcullen, is one of the world’s most respected and most interesting military theorists. He writes clear, simple prose and supports his unified theory of “competitive control” with fascinating case studies from Kingston, Mogadishu, Lagos, Benghazi and Mumbai. For me, this is a key text for understanding the chaotic nature of modern conflict. It helped me understand why people support ISIS, why our military is often ineffective against terrorism and why criminals are sometimes better than governments.\n\nOut of the Mountains: The Coming Age of the Urban Guerrilla: Amazon / Amazon UK\n",
    link: "/home/2016/06/17/3_books",
  },
  {
    title:
      "3 Books Weekly #18: The financial crash, and gentle lives on the frontier",
    date: "09.00, Friday 1 Jul 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks!\nToday’s 3 books are from my friend Maya Schram, who is on Twitter as @brixtonfooty. She tells me she works at a tiny fashion school but I’m suddenly unclear whether that is a school that is tiny, or tiny fashion, like, fashion for ants.\nI should check. \nHere’s the thing about 3 books: I’ve been asking people what three books I should read this year for… oh, a decade. More. Last week at the Strange Tales event (you’ve missed it now, sorry), I asked everyone for their 3 books, and we put them all down on post-its and had a look at them afterwards. One of the post-its recommended two of my favourite books (Left Hand of Darkness and Tainter’s Collapse of Complex Societies if you want to know) and I hadn’t heard of the third. So I’m going to read it. A recommendation is such an exposing thing - you open yourself up so much to share it - and such an incredible gift. To receive a book recommendation is to know the recommender. We have such a limited amount we can read in a lifetime, and there are so many books, that to know what a particular person has read and loves… well it’s to see their journey through life, their perspective. And if you’ve read the same books! Well.\nI didn’t know what to expect from Maya’s picks. Reading them now I can hear her voice, and I know a little more about how she thinks and the memories she carries with her. I love these little stories, these little glimpses. Thank you Maya!\nHappy Friday all, look after each other.\nMatt\nps. I’m always after more recommendations to share in this newsletter! Please contribute using this form if you’d be up for playing.\n#1. The Golden Notebook, by Doris Lessing\n\nI am not a fan of novels that mess about with structure. This novel is such an experiment, but an extraordinarily readable one. The main protagonist, Anna Wulf, is writing a novel. Alongside, she writes her own thoughts on politics, the art of writing, her relationships, and everyday events, in four separate notebooks. Through Anna we have a fascinating account of London in the mid 1950s, its social history, the labour movement, the sexual politics and the fears of nuclear holocaust. Lessing did not perceive this as a feminist novel. Betty Friedan’s ‘The Feminine Mystique’, now considered to be the launch pad of second wave feminism, was not published until a year later. She was therefore unprepared for the vitriol she received from some male critics at the time and expressed astonishment that they overlooked the originality of structure, a device which she had used to illustrate society’s fragmentation. It is a landmark novel, beautifully crafted, and a superb record of its time.\n\nThe Golden Notebook: Amazon / Amazon UK\n#2. Boomerang: The Meltdown Tour, by Michael Lewis\n\nMichael Lewis is a financial writer who contributes to Vanity Fair. Following the sub-prime crash, he wrote a series of essays for the magazine focusing on the aftermath in five countries, Iceland, Greece, Ireland, Germany and US. The essays were later gathered together in a book called Boomerang. Lewis approaches the topic almost like a travel writer. He examines each country’s descent into financial madness from an anthropological perspective, while also deftly explaining the intricacies of credit default swaps and the like. Here lies his genius, he approaches the technical world of finance from a human perspective and exposes, with hilarious anecdotes, the greed and incompetence that led us all to total disaster. He is irreverent, and you may not agree with all of his insights. The Letters pages of Vanity Fair were littered with complaints (mainly from Germans). Nevertheless, he will have you laughing out loud, despite the oftentimes tragic subject matter.\n\nBoomerang: The Meltdown Tour: Amazon / Amazon UK\n#3. Little House in the Big Woods (The Little House on the Prairie), by Laura Ingalls Wilder\n\nWhen I was eight, I had a teacher called Mrs Boyles who was very, very old. She did not embrace modern teaching methods. Instead we sat in single rows, and worked alone, silently. If we got stuck, we could line up at her desk and get help. She only taught us English, Maths and Needlework. I liked her style. At the end of every day, she would read us a chapter from the Little House in the Big Woods. It is the first of an autobiographical series about a pioneer family who lived in Winscousin in the 1870s. This novel took us to a time when life was simpler, dominated by the seasons, and focused on survival. A lot of time was spent hunting, sewing, pickling preserves and smoking meat for the winter. For recreation, Pa would play the fiddle and sing. It was a world of corn bread, maple syrup, calico dresses and rag dolls. We would all sit quietly, even the boys, totally transported, and groan when the home-time bell rang.\n\nLittle House in the Big Woods (The Little House on the Prairie): Amazon / Amazon UK\n",
    link: "/home/2016/06/27/3_books",
  },
  {
    title: "3 Books Weekly #19: Travel books from author Nick Jubber",
    date: "09.00, Friday 8 Jul 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks\nWe’ve got three particularly transporting books today from author Nick Jubber. I have his first book, The Prester Quest, at home – he’s off travelling again right now (of course) and his third book is out soon. Actually I’ve just been nosing around on Twitter and it’s got a cover already! Here’s a pic of the proofs.\nFollow Nick on Twitter: @jubberstravels.\nHappy Friday!\nMatt\n#1. Beware of Pity (B-Format Paperback), by Stefan Zweig\n\nStefan Zweig was one of the most popular writers in Europe. Then the Nazis burned his books and he fetched up in Brazil, where he overdosed on barbiturates in 1942. His reputation dribbled away, although it’s been reviving lately (Wes Anderson cited him as an inspiration for Grand Budapest Hotel). Beware of Pity is the brilliant tale of a young soldier in the Austro-Hungarian army and his tumultuous battle with his own compassion. Nobody dissects emotions like Zweig. He cuts so deep you can almost hear the blood pumping as you turn the pages, yet his writing is forensic in its detail. Whether exposing the young soldier’s insecurities, the lovesickness of the crippled girl he mistakenly asks to dance, her father’s anguished neediness, even the tearfulness of the manservant, Zweig carries you through the literary equivalent of a car crash, racing towards a head-on collision with the great event of the age. It’s brutal, bruising stuff, and brilliantly entertaining.\n\nBeware of Pity (B-Format Paperback): Amazon / Amazon UK\n#2. Palace Walk: Cairo Trilogy 1 (The Cairo Trilogy, Vol. 1), by Naguib Mahfouz\n\nI first read Mahfouz’s intimate, inter-generational saga on bus journeys across the Middle East, and it pumped life into the world I was skimming through. Staying in the home of a shouty patriarch, I thought of Mahfouz’s stern Abd al-Jawad; drinking with a lusty Cairene near the Nile, I recalled bottom enthusiast Yasin. Later, I got to meet Mahfouz, although it was a salutary lesson: the octogenarian author had lost the fire that’s preserved so brilliantly in his books. For the western reader, much of the power in Mahfouz’s novels comes from the tension between the familiarity - sibling rivalries, erotic yearnings for the girl next-door - and the alienness of time and place. It’s an intricate depiction of a society on the cusp of change, twitching against colonial rule. Watching the footage of crowds protesting in Tahrir Square recently, I couldn’t help thinking of the scenes of protest in Mahfouz’s novels, and imagine the family of Abd al-Jawad there amongst them.\n\nPalace Walk: Cairo Trilogy 1 (The Cairo Trilogy, Vol. 1): Amazon / Amazon UK\n3. A Time of Gifts: On Foot to Constantinople: from the Hook of Holland to the Middle Danube, by Patrick Leigh Fermor\n\nI’ve been scribbling a travel book recently, so I feel I had better recommend one! Top of the pile has to be Fermor’s mercurial trilogy. It’s a timely read, reminding us what the continent was like before the last century’s most seismic catastrophe - and how benign a place can appear when the fracture lines are already spreading. Fermor set off from the Hook of Holland in 1933, with the intention of walking to Istanbul, hanging out in the schlosses of Central European counts, kipping in barns, or dossing down with gypsies in the woods. Writing much later, he conjures a magical contrast between his wistful middle-aged self and the younger, more callow adventurer, transporting us into his travels with prose immersive and elegant. For anybody unaware of the bewitching potential of the travel book, A Time of Gifts will be a thrilling discovery. For anybody wanting to understand Europe, this passionate, erudite account is the most essential book I know.\n\nA Time of Gifts: On Foot to Constantinople: from the Hook of Holland to the Middle Danube: Amazon / Amazon UK\n",
    link: "/home/2016/07/01/3_books",
  },
  {
    title: "Hardware-ish coffee morning, next Thursday",
    date: "17.50, Friday 15 Jul 2016",
    content:
      "Hey, shall we do a July hardware-ish coffee morning? And, just for kicks, shall we try a different location?\nThursday 21 July, 9.30am for a couple of hours, at Machines Rooms, 45 Vyner St.\nLast time we had a fun crowd. Thanks for coming Ross, Paul, Anders, Pauline, Josh, Avril, Phoenix, John, Lloyd, Tom, and Nat.\nIt was from Nat that I learnt about Machines Room – it’s a makerspace right in the middle of London’s densest area for hardware startups. Tech Will Save Us is on the same road, for example.\nThere’s equipment there, and coffee, and events. So next week is going to be a busy one of us doing stuff together! On Tuesday night, I’m taking part in an event about hardware startups and business models. Sign up here. On Wednesday, my bookshop vending machine Machine Supply will be moving there for its latest residency. And on Thursday morning, this hardware-ish coffee morning!\nUsual drill… there’s no standing up and doing intros, or anything super formal. The coffee morning is simply a friendly space to hang out, chat, get caffeinated, and compare notes on everything hardware related, whether that’s making stuff as a hobby, figuring out how to do manufacturing, swapping interesting new Kickstarters, or just spending time with like-minded people.\nHope to see you at Machines Room next Thursday!\n",
    link: "/home/2016/07/08/3_books",
  },
  {
    title: "3 Books Weekly #20: Big ideas",
    date: "09.00, Monday 18 Jul 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks!\nThis week’s picks are from Dave Gray. Dave is a founder, designer, author… and book recommender. His suggested reading lists are awesome browsing. But but but his recommendations HERE are different. More about getting to know him as a person. His first pick is The Art of War which I’ve been stocking in the vending machine a bunch recently. I take secret glee in placing it right next to the The Art of the Publisher. That’s merchandising y’all.\nFind Dave on Twitter right here.\nIt’s all change for the vending machine this week! In a few days we’re moving out from Lost My Name HQ - THANK YOU!! - into Machines Room which is a makerspace in Hackney. I’m super excited about this latest residency. I’ll send pics in the next newsletter, and a map too – you’ll be able to visit over the summer.\nHave a great week\nMatt\nps 1. Recommend books for the newsletter! Use this form!\nps 2. I run a little coffee morning for hardware-minded folks. The next one is this Thursday and will be at Machines Room so you can check out the vending machine then. More details on my blog.\n#1. The Art of War, by Sun Tzu\n\nI reread this book every five years or so. It’s always different and I always come away with new thoughts. It’s like the ideas in the book interact with the currents of my life and create different ripples every time. It’s critical to read Griffith’s translation. The others have not moved me. Perhaps this is because Griffith was a military man and a strategist himself.\n\nThe Art of War: Amazon / Amazon UK\n#2. Penguin Great Ideas : Meditations, by Marcus Aurelius\n\nMarcus Aurelius was the emperor of Rome, a true philosopher-king. He was a wise, thoughtful and disciplined man. If you can imagine what kind of power he had, maybe you can also imagine that for a ruler with such great power, the most difficult thing would be to rule one’s self. This book is his diary, where he catalogued his thoughts and struggles to be a truly good person. The beauty and integrity of his mind shine through every sentence. He provides a great example of how to live your inner life.\n\nPenguin Great Ideas : Meditations: Amazon / Amazon UK\n#3. Foundation: 1/3 (The Foundation Series), by Isaac Asimov\n\nIt’s a trilogy. Is this allowed? I first read this book in my early teens. It’s a beautiful epic intertwingling science and fantasy. A galactic empire rotting from within. A scientist who predicts the future and comes back as a holographic guide. A mysterious mutant warlord. A secret society of mind-reading empaths. A story line that unfolds over centuries.\n\nFoundation: 1/3 (The Foundation Series): Amazon / Amazon UK\n",
    link: "/home/2016/07/15/coffee_morning",
  },
  {
    title: "Two obvious financial tips",
    date: "12.05, Monday 18 Jul 2016",
    content:
      "I think the LinkedIn euphemism for it is a “portfolio career,” but really what that means is I have a bunch of stuff on the go simultaneously.\nSo for the past three months I’ve been working with Google, directing a small team on an invention project. I have my vending machine bookshop; I advise a couple of hardware startups; I’ve been doing a bit of teaching, etc, etc. I am trying to avoid building another agency.\nWorking for myself: I love the independence.\nWorking for myself: Holy shit I hate thinking about cashflow. It destroys any kind of creativity I have, and stops me being casual.\nThere’s a time for hustling, and there’s a time for being casual. I find the most interesting opportunities emerge from coffees and talking widely. And interesting opportunities breed interesting opportunities – as Jack says, you get what you do. So, doubly important to hold off accepting anything until the great stuff appears.\nAnd if I haven’t got much money in the bank? That’s when I make bad decisions. I mean, this is a question of BATNA: If my Best Alternative to a Negotiated Agreement is that I can’t pay my mortgage, then I have to take whatever gig is going, at whatever terms.\nI follow two rules to keep myself sane as an independent. This goes for freelancers, contractors, sole traders, and whatever other forms of “self-employed” there are out there.\nIt occurred to me that other people might be interested, so I thought I’d share them here.\nPay yourself a salary\nBusiness money is not my money. To smooth out peaks and troughs, all gigs pay into a separate account and I pay myself monthly.\nMy salary is the same amount every month, and paid on the same day of every month.\n(Business) taxes also come out of this float.\nBuild a runway\nOnce I take into account business expenses and my salary, I can calculate how many months I can survive without work. That’s my runway.\nIf my runway is six months, I can sleep at night. If it’s six months minus one day, that’s a psychic shitstorm right there.\nThe reason being that it typically takes me three months to go from asking around to starting a gig (longer for the most unusual ones). Then let’s say I get to invoice after a month’s work, then it takes a month to get paid, then add a month as a buffer… that’s six months right there.\nWhen I started as an independent again, I kept my salary super low until I built up my six months runway.\nThere’s a flip side: If the runway is too long, I stop being hungry. Being hungry is good.\nMinimum viable financial management\nTwo tips. Not rocket science. I imagine most people have something similar. For me, this is what gives me room to be exploratory, and how I sleep easier at night.\n",
    link: "/home/2016/07/18/3_books",
  },
  {
    title: "3 Books Weekly #21: Architecture, singing, weather",
    date: "09.00, Friday 22 Jul 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi all!\nWelcome to 3 Books Weekly edition 21. Blimey. 21.\nOkay we’ve got some brilliant picks today. I’m beginning to pick the books to take with me on my summer hols… I’ve found a couple right here.\nThis week’s picks are from David Honigmann who I am slightly ashamed to say I met through a management consultancy context, but actually he writes about music for the FT (articles here), and I’m having one of those moments where reading somebody’s recommendations is suddenly letting me know them way better. Thanks David! Find him on Twitter as @TheHonn.\nOk on with the show.\nHave a great weekend\nMatt\n#1. A Pattern Language: Towns, Buildings, Construction (Center for Environmental Structure Series), by Christopher Alexander\n\nAlexander and his fellow writers describe how to make spaces liveable, at every level from region down through city to neighbourhood to street to house to room. The patterns interlock upwards and downwards and sideways (so, for example, a Half-Hidden Garden needs a Garden Seat and is itself part of an Entrance Transition). Each chapter is stated as a problem, analysed, and then solved. Patterns are illustrated with black-and-white photographs (frustratingly small - someone should produce an updated edition with the sumptuous illustrations the book deserves). To read A Pattern Language is to be given tools for looking at physical spaces and why they work or don’t - it’s like suddenly being able to see in much sharper focus. When we designed an extension to our house, we referred to it constantly, and where we were able to follow the patterns closely they have worked wonderfully. The book makes you ambitious to live not in a more luxurious way but in a better way.\n\nA Pattern Language: Towns, Buildings, Construction (Center for Environmental Structure Series): Amazon / Amazon UK\n#2. Naked at the Albert Hall: The Inside Story of Singing, by Tracey Thorn\n\nEveryone loved Teenage Bedsit Disco Queen, Tracey Thorn’s memoir about her career in Everything But The Girl (and before that, the Marine Girls). But this follow-up is even better. It’s a book about being a singer, mixing her own experience, science, critical theory and interviews with fellow practitioners (Green Gartside, Linda Thompson, Romy Madley-Croft) in which she is unafraid to be an unabashed fan. She is clear about the practical problems and anxieties of her craft: there’s one amazing and incredibly insightful passage where she talks about the technical inner monologue that’s going on in her mind as she approaches a difficult passage of music. I interview a lot of singers, and I wish they were all this self-aware, lucid and funny.\n\nNaked at the Albert Hall: The Inside Story of Singing: Amazon / Amazon UK\n#3. Weatherland: Writers and Artists under English Skies, by Alexandra Harris\n\nHarris’s Romantic Moderns brought together British culture between the wars - everything from literature to art to gardening. Weatherland is even more ambitious: it tells the history of British culture through the very specific lens of the weather. She starts with the very earliest medieval literature (all Western winds) and runs through to the present day, where weather is at worst a mild inconvenience, not potentially a threat to life. Again, she sets writers in dialogue with artists. At the spine as an organising device is Virginia Woolf’s Orlando, in which Woolf introduces new time periods by caricaturing their climates (Victorian London is literally under a cloud; the twentieth century suddenly sees the air clear). Harris’s broad sweep is underpinned by close reading: every page contains the nuggets of ideas that could easily have been a whole book.\n\nWeatherland: Writers and Artists under English Skies: Amazon / Amazon UK\n",
    link: "/home/2016/07/18/two_financial_tips",
  },
  {
    title: "3 Books Weekly #22: Featuring Nat Hunter from Machines Room",
    date: "09.00, Friday 29 Jul 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHullo hullo\nThis week we have three fantastic recommendations from Nat Hunter. Nat is Strategic Director at Machines Room and you can follow her on Twitter as @redfishnat.\nThe vending machine is all moved in to Machines Room for the summer and we’ve collectively decided that it’s their very first Machine-in-Residence. Hurrah! It’s where Machine Supply will be located throughout August, so head down and check it out for some summer holiday reading. You can find a couple of Nat’s picks in stock :) (On a personal note, I read Shaping Things when it came out and it totally blew my mind. So get that.)\nIn other news, I’m super excited to have a Machine Supply partner in crime! Lisa Ritchie is joining me to help write the newsletter and run the vending machine. Stay tuned for Lisa’s book recommendations next week.\nHave a great week, and happy reading!\nMatt\n#1. The Thrilling Adventures of Lovelace and Babbage: The (Mostly) True Story of the First Computer, by Sydney Padua\n\nA beautifully drawn and slightly bonkers graphic novel about Ada Lovelace and Charles Babbage and the birth of computing. It starts out as a true story about Byron and Maths then becomes a bit more whimsical as the book goes on. Interesting, informative and entertaining.\n\nThe Thrilling Adventures of Lovelace and Babbage: The (Mostly) True Story of the First Computer: Amazon / Amazon UK\n#2. Sex, Bombs and Burgers: How War, Porn and Fast Food Created Technology as We Know it, by Peter Nowak\n\nLove ‘em or hate ‘em, this is the story of how the killer trio of war, fast food and pornography have accelerated the pace of change of our technology.\n\nSex, Bombs and Burgers: How War, Porn and Fast Food Created Technology as We Know it: Amazon / Amazon UK\n#3. Shaping Things (Mediawork Pamphlet), by Bruce Sterling\n\nEver wanted to know what a “spime” is? Well, read this book. A spime turns out to be an object with “informational support so extensive and rich that they are regarded as material instantiations of an immaterial system”. They are designed on screens, fabricated by digital means, and precisely tracked through space and time. So there. Now you know.\n\nShaping Things (Mediawork Pamphlet): Amazon / Amazon UK\n",
    link: "/home/2016/07/22/3_books",
  },
  {
    title: "3 Books Weekly #23: Memories, despair and dreams",
    date: "09.00, Friday 5 Aug 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here. The intro is from Lisa Ritchie.\nHello hello,\nA huge thanks to Matt for letting me loose on this marvellous book-loving community! I’m Lisa and I get very excited about books (that sounds a bit like the intro to a Readers Anonymous meeting in a parallel universe).\nBy way of introduction, I’m a project manager and communications specialist, book nerd and podcast enthusiast. The last book I read was The Drowned World by J.G. Ballard (if you love Heart of Darkness or Lord of the Flies then it’s probably up your street).\nThis week I’m kicking off with my own recommendations, some of which you can find in the vending machine (it’s currently living at Machines Room, go check it out). I’ve had a crash course in vending machine management and I’m looking forward to running the tiny bookshop :)\nStay tuned for lots of lovely recommenders coming up over the next few weeks!\nHappy reading!\nLisa\n#1. Cat’s Eye, by Margaret Atwood\n\nI’m a huge Margaret Atwood fan. If I had to do that thing where you choose famous people to have dinner with, she’d be on my list. The Handmaid’s Tale was the first Atwood book I ever read, I still re-read it every few years. Cat’s Eye stands out for me as it’s an incredible example of Margaret Atwood’s genius at capturing relationships. Dark memories are linked to very real feelings that surface in the protagonist’s life. We all have memories that tap into our deepest fears and doubts about ourselves and Atwood explores this brilliantly.\n\nCat’s Eye: Amazon / Amazon UK\n#2. Stoner: A Novel (Vintage Classics), by John Williams\n\nI bumped into my high school English teacher in a pub. I didn’t want to be that annoying ex-pupil, but I had to go and say hello. We had a quick chat and she said if I read anything that year, it had to be Stoner. So I bought it. The story follows a very ordinary man’s life from adolescence to death. It’s written in simple, unexpressive language. It floored me. There were times when I actually had to put the book down as I felt like I’d been kicked in the stomach. I cried on the tube. I think it’s the saddest book I’ve ever read, but there’s something incredibly compelling about it.\n\nStoner: A Novel (Vintage Classics): Amazon / Amazon UK\n#3. Just Kids, by Patti Smith\n\nI’ve never really listened to Patti Smith’s music, but I read an except from this book in a newspaper and immediately went out and bought it. It follows her leaving the countryside for New York to become an artist. It has a beautifully dreamy quality that contrasts sharply with the grim reality of her everyday life. It’s a story of grit and resilience and reading it transported me into the bohemian existence of 60s and 70s New York. I still don’t know much about Patti Smith’s rise to fame, the story stops just before that, but it’s worth reading for the world that Smith recreates.\n\nJust Kids: Amazon / Amazon UK\n",
    link: "/home/2016/07/29/3_books",
  },
  {
    title: "3 Books Weekly #24: Feat. Miranda Roszkowski",
    date: "09.00, Friday 12 Aug 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here. The intro is from Lisa Ritchie.\nHello fellow readers,\nThis week two bonus books, hurrah! I’ve been travelling quite a bit, which gave me the chance to get stuck into two books I’ve been looking forward to reading. The first was Smarter Than Us, a short and sweet musing on the hazards and benefits of machine intelligence (really interesting and you can blast through it). The second was The Girls, the debut novel by Emma Cline, which the media has been raving about recently (take a look at this review in The Economist). It’s a dark and disturbing summer read, with observations that really get under your skin. If you’ve read either book, tweet me with your thoughts!\nThe world’s smallest bookshop (aka our book vending machine, Machine Supply), is enjoying its summer holiday at Machines Room in Hackney, pop down and a take a look!\nNow, over to this week’s recommender, Miranda Roszkowski. By day Miranda works for the government, and in Clark Kent style, by night she’s a literary whirlwind, in the midst of writing her first novel and running an awesome spoken word and short story night, There Goes the Neighbourhood (follow Miranda on Twitter @miranda_roszko for info on the next event).\nOver to Miranda, enjoy!\nLisa\n#1. For Esmé - with Love and Squalor: And Other Stories, by J. D. Salinger\n\nThis is the book that made me want to write. I had read Catcher In the Rye and not been blown away, but when a friend leant me this short story collection I was absolutely transported -I never gave it back. Published (in typical Salinger understatement) as “Nine stories” in the U.S. this short story collection is so full of quirky characters and heart-breaking stories it’s hard to pick a favourite. From the tough-girl wannabee Ginny, the presumptuous ‘Jean de Deaumier-Smith’ to the troubled young war veteran in A Perfect Day for Bananafish and boy genius Teddy, every one of Salinger’s protagonists are painfully human, their stories gripping and hilarious, and all of them seeking the answers in a world that is topsy-turvey. The writing is as fresh now as it was in 1953, and every time I need inspiration I open it to find something new. If you haven’t had the pleasure, open your arms to this collection of renegades.\n\nFor Esmé - with Love and Squalor: And Other Stories: Amazon / Amazon UK\n#2. My Brilliant Friend: 1, by Elena Ferrante\n\nElena Ferrante is the Sia of the literary world. No one knows who she really is, only that she shares her first name with the protagonist of this epic first book in her series of Neapolitan Novels. In a post-Referendum world, I think it’s even more important to try to understand our European heritage, and if (like me) you’re not one for factual books, novels like this are an easy way in. Ferrante’s story is bursting with content- politics, history, class divide, romance. All set to the backdrop of a complicated friendship between two young girls. It’s bonkers and like the friend of the title, utterly brilliant.\n\nMy Brilliant Friend: 1: Amazon / Amazon UK\n#3. Not That Kind of Girl: A Young Woman Tells You What She’s Learned, by Lena Dunham\n\nA friend recently asked me why Lena Dunham was a feminist icon - “she’s really awful”. Sure, her alter-ego Hannah Horvarth from Girls once tried to get out of a disciplinary by flashing her boss. But Dunham’s work is not just spine-crawlingly cringey, it’s hilarious and importantly, honest. I was thrilled to see her fearless, fiercely creative approach to life and art shining from these pages. My housemate and I nearly cried with laughter reminding ourselves of the account of Lena’s inaugural discovery of her own body odour at camp. It’s not all funny, there are some really serious bits in there too and I would beg everyone, men and women to read this to gain some insights into the female, and indeed, human condition. By her own account, sometimes Lena Dunham is awful, but then, sometimes, so am I.\n\nNot That Kind of Girl: A Young Woman Tells You What She’s Learned: Amazon / Amazon UK\n",
    link: "/home/2016/08/05/3_books",
  },
  {
    title: "3 Books Weekly #25: Featuring novelist Matthew De Abaitua",
    date: "09.00, Friday 19 Aug 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here. The intro is from Lisa Ritchie.\nHello hello,\nI’m stupendously excited to welcome author and university lecturer Matthew De Abaitua to 3 Books Weekly! Matthew’s work includes the mind-bending sci-fi novel The Red Men, which was shortlisted for the Arthur C. Clarke Award. (A personal favourite, it was recommended to me and I’ve lost count of the number of times I’ve recommended it other people!) \nYou can find out more about Matthew’s work here and follow him on Twitter at @MDeAbaitua.\nIn tiny vending machine bookshop news, this week I did a test called ‘Will it Vend’. (Maybe there’s a YouTube series in that.) All the items passed with flying colours, hurrah! So this week we’re vending some non-book products thanks to our friends at Machines Room. We’ve got Sugru, an instrument making kit from Technology Will Save Us and some marvellous robots from The Crafty Robot - they’re super cute! \nOver to Matthew. Happy Friday!\nLisa\n#1. Seize the Day (Penguin Modern Classics), by Saul Bellow\n\nI always carry an early collection of Saul Bellow’s short stories in my bag. His prose is hot with the street and a yearning for transcendence; if I only have a few minutes to read then I’ll study a paragraph of his to follow how he develops his thought or description. Of his novels, Seize the Day is the one I re-read. It’s short and potent, the story of Tommy Wilhelm, who is taking account of his failings in early middle age. It’s devastating on masculine self-delusion and deeply moving on the human condition, all set on the oppressive steaming New York street of Broadway.\n\nSeize the Day (Penguin Modern Classics): Amazon / Amazon UK\n#2. Ubik (S.F. MASTERWORKS), by Philip K. Dick\n\nStanislaw Lem, the Nobel Prize-winning author of Solaris, declared Ubik to be Philip K Dick’s masterpiece. The narrative pull of the novel comes from its nested realities. You never know quite which world you are in, and then Dick pulls the fabric of space and time from under your feet. I read Ubik and Dick’s Valis while writing my first novel The Red Men. Ubik taught me that flipping the reader’s reality was far more compelling than violence.\n\nUbik (S.F. MASTERWORKS): Amazon / Amazon UK\n#3. The Dispossessed, by Ursula Le Guin\n\nA novel that imagines an anarchist society, how it would work on a granular level, and what it would feel like; how such a worldview would alter the people inhabiting it. The Dispossessed of the title are the anarchists who have abandoned a lush unequal capitalist planet for an arid moon. Life on the moon is hard but through collective effort they make it habitable. Le Guin picks up the story of their society a few hundred years after its inception, and follows the journey of their lead scientist back to the planet his ancestors left behind. I put this novel on the reading list for the creative writing science fiction course I teach at the University of Essex. Some students have been blown away by it. They’ve never encountered such a convincing alternative society.\n\nThe Dispossessed: Amazon / Amazon UK\n",
    link: "/home/2016/08/12/3_books",
  },
  {
    title: "3 Books Weekly #26: Featuring Yousef Tuqan Tuqan",
    date: "09.00, Friday 26 Aug 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here. The intro is from Lisa Ritchie.\nHello hello,\nThis week our recommender is a dear friend of mine, Yousef Tuqan Tuqan. We met when I lived in Dubai and we’ve shared lots of amazing adventures, from partying at Notting Hill Carnival to visiting his hometown of Nablus in Palestine. Yousef always seems to be up to something exciting every time I speak to him. He’s just one of those people.\nYousef’s an expert on the Arab startup landscape and all things marketing in the MENA region. You can find him on Twitter at @yousef. (Yeah, badass twitter handle.)\nOur vending machine bookshop continues its residency at Machines Room in Hackney, pop down and check it out :)\nHappy reading!\nLisa\n#1. 1493: Uncovering the New World Columbus Created, by Charles C Mann\n\nWhat do European smokers, American slavery and the Irish potato famine have in common? They all have Christopher Columbus to thank. This book chronicles our world after the “Colombian Exchange” of Columbus’ arrival in America, and how his “reunification” of the continents led to the most unexpected of consequences that defined the world for centuries to come. Mann takes a heavy and complicated subject with a lot of moving parts, and clearly illustrates the positive and negative effects of globalization, with many lessons we could learn in today’s new world.\n\n1493: Uncovering the New World Columbus Created: Amazon / Amazon UK\n#2. A Confederacy of Dunces (Penguin Modern Classics), by John Kennedy Toole\n\nThis book won the Pulitzer Prize in 1981, and remains one of the funniest books I have ever read. The chronicles of Ignatius J. Reilly, a modern-day Don Quixote who lives with his mother and rails against the world are unforgettable, and made all the more poignant by the story of the author, who committed suicide when he couldn’t get this book published. Full of brilliant quotes and colourful characters, this book is so funny you’ll want to read it out loud to someone, as my sister and I did for weeks on our couch as teenagers.\n\nA Confederacy of Dunces (Penguin Modern Classics): Amazon / Amazon UK\n#3. 1493: Uncovering the New World Columbus Created, by Charles C Mann\n\nWhat do European smokers, American slavery and the Irish potato famine have in common? They all have Christopher Columbus to thank. This book chronicles our world after the “Colombian Exchange” of Columbus’ arrival in America, and how his “reunification” of the continents led to the most unexpected of consequences that defined the world for centuries to come. Mann takes a heavy and complicated subject with a lot of moving parts, and clearly illustrates the positive and negative effects of globalization, with many lessons we could learn in today’s new world.\n\n1493: Uncovering the New World Columbus Created: Amazon / Amazon UK\n",
    link: "/home/2016/08/19/3_books",
  },
  {
    title: "3 Books Weekly #27: Featuring design writer Cliff Kuang",
    date: "09.00, Friday 2 Sep 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi folks!\nMatt here again. I just want to say THANKS guest editor Lisa for bringing us 3 BOOKS WEEKLY while I’ve been on the road. She found some amazing contributors. Maybe we can have her back again soon :)\nToday I’ve asked Cliff Kuang what 3 books I should read this year. Cliff’s one of those people with a birds-eye view of the design and tech world, and in particular its role in culture. He was founding editor of the site Co.Design which really quickly became my go-to site for timely and thoughtful design news and comment. So I’m super intrigued to see what he recommends…\nI met up with Cliff for coffee when he was in London over the summer, and we had a pretty brain-buzzy conversation about the various avenues design has explored. It was also at that point I found out he’s working on a book - to be published in the not too distant future - and after our chat, I can’t wait to get my hands on it. Follow him on Twitter at @cliffkuang.\nOk, on with the show. Oh first! If you’d like to pick books for 3 BOOKS WEEKLY, there’s a form right here. Please do share if you feel so inclined.\nMatt\n#1. The Orphan Master’s Son, by Adam Johnson\n\nAdam Johnson is a genius, full stop. Before this book, he was best known among literary geeks for his short stories-heartfelt, bittersweet takes on science fiction. But this novel is something else entirely. It’s the story of a North Korean prisoner who manages to find himself at the top of the military ranks and in love with a famous South Korean movie star. They’re both wrapped up in the absurdity of the Kim Jong Il regime, trying to save themselves and their souls. The setting is perfect for Johnson’s gift with the surreal, because there really is nothing more surreal than North Korea. But more than that, it’s a stunning, moving testament to love and sacrifice in the oddest of circumstances.\n\nThe Orphan Master’s Son: Amazon / Amazon UK\n#2. Age of Ambition: Chasing Fortune, Truth and Faith in the New China, by Evan Osnos\n\nI’m a bit of a China addict, having travelled there and been stunned at how strange life there is. All the cliches about its rapid development are true, and gob-smacking regardless. It’s moving, terrifying and inspiring all at once to witness an entire country shift, within 10 years, from subsistence farming to 200mph bullet trains. There is no book written that better captures the human beings living this story every day. Osnos is a brilliant reporter and writer, and his portraits of everyday Chinese pursuing fortune and family and love are unmatched. This is one of those books that just puts you in a world that isn’t your own. What’s better than that?\n\nAge of Ambition: Chasing Fortune, Truth and Faith in the New China: Amazon / Amazon UK\n#3. The Gene: An Intimate History, by Siddhartha Mukherjee\n\nIt’s an amazing thing when a science book can read like a detective story. Mukherjee is a brilliant writer and doctor and with this book, he tackles the many linked revelations we’ve achieved in genetics over the last 200 years, but more than that, he has an amazingly supple way of conveying the visceral thrill of discovery. And, more than that, he ties those discoveries with some moving stories about his own family and the madness that has been carried across generations by their own chromosomes. Mukherjee’s book about cancer, The Emperor of All Maladies, is also a must-read.\n\nThe Gene: An Intimate History: Amazon / Amazon UK\n",
    link: "/home/2016/08/26/3_books",
  },
  {
    title: "Hardware-ish coffee morning, Thursday 15th",
    date: "11.05, Monday 5 Sep 2016",
    content:
      "I am BACK FROM MY SUMMER HOLS, it’s raining outside, and I am in the mood to hang out with hardware folks. Let’s have a hardware-ish coffee morning?\nThursday 15 September, 9.30am for a couple of hours, at the Book Club, 100 Leonard St.\n(Timed to follow the Internet of Things conference ThingMonk, so if you’re in town for that, do come and hang out for coffee too.)\nUsual drill… there’s no standing up and doing intros, or anything super formal. We just meet in a convenient cafe and hang out. Folks are often involved in the hardware scene somehow, whether it’s making stuff for a hobby, figuring out how to do manufacturing, or in the middle of their Kickstarter campaign. All pretty chilled. Bring prototypes if you got em.\ntbh it might just be me and thee. But that’s fine, we’ll have a cuppa and have a chat.\nI have a secret agenda – I’m heading up R/GA’s newest startup accelerator and we’re focusing on hardware and Internet of Things startups. Announcement was just the other day. So I’m thinking about what kind of support startups really need, and I’m talking to as many people as possible about that.\nSee you on the 15th!\nps. for email updates about hardware-ish coffee mornings, subscribe to the mailing list.\n",
    link: "/home/2016/09/02/3_books",
  },
  {
    title:
      "3 Books Weekly #28: Sensuous space-time and revolutionary Yugoslavia",
    date: "09.00, Tuesday 13 Sep 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHey folks\nFirst things first – 3 BOOKS WEEKLY is a little late this week because I’ve got a new gig and my goodness it is eating all my thoughts. Good place to be. Counter-intuitively, it’s also done wonders for my reading: Sitting with the Kindle is a great way to relax both eyes and mind, and I am chewing through some amazing Golden Age sci-fi in the evenings.\nThe main event: I am super pleased to bring you recommendations from GRAND MASTER OF MEMORY Ed Cooke today. Ed is founder of gorgeous learning startup Memrise, on Twitter as @tedcooke, and– Hang on, I hear you say, Grand Master of what now???\nYeah. This is somewhat weird. Read about it on Wikipedia. Being a Grand Master of Memory means Ed can memorise the order of 10 decks of cards in an hour. Also a 1,000 random digits. It’s insane, and it’s for this reason he pops up in odd places. I remember waking up in the middle of the night one night to Ed’s dulcet tones on the radio - I sleep with the radio on - and having that “um is this a dream” moment.\nEd tells me that one of his three picks, Ada (Nabokov), is the one he’d take to a desert island with him. Only he goes on: “Not for its first chapters, mind you, which are ludicrously turgid. Incidentally, I suspect that Nabokov, who was an awful snob, put them there to scare us ordinary readers off. Don’t be fooled.”\nALSO! This is the first time a Featured Recommender has picked a book that was previously picked. So if you like these, continue by checking out Daniel Fogg’s picks in edition #17.\nOk ok ok enough from me, on with the show.\nMatt\n#1. The Age of Wonder: How the Romantic Generation Discovered the Beauty and Terror of Science, by Richard Holmes\n\nIt’s a story about the scientific revolution in late 18th century Britain – a moment in time when the nature of the world was wide-open and mysterious, the word scientist hadn’t yet been coined, and the divisions between disciplines that today chain our imaginations were entirely absent. Each chapter is a sketch of one of these proto-scientists: An adventurer, balloonist, telescope-maker, chemist, author… Take the chapter on Humphrey Davy, which reveals how his notebooks were filled with rhyming couplets, because poetry and science hadn’t yet separated; that after synthesising a chemical in the lab, he’d routinely inhale a load of it to see its effects on the mind (better for laughing gas than carbon monoxide); that he’s constantly in love. Holmes brings out the genius and fun and romance of this generation. It’s enough to help one fall in love with science again, and reconnect to a more general love for the world.\n\nThe Age of Wonder: How the Romantic Generation Discovered the Beauty and Terror of Science: Amazon / Amazon UK\n#2. Ada or Ardor: A Family Chronicle (Penguin Modern Classics), by Vladimir Nabokov\n\nI’ve read Ada five times, and each time I do, I feel like I must have been half asleep on the previous occasion to have missed quite so many moments of magic. There are people on web forums who say that it keeps delivering similarly after 20 or 30 readings. Its 700-odd pages recount the story of an 80-year-long love affair (between Ada and her lover, Van, the author) set in an alternate universe of impossible cultural, social, intellectual and sexual riches. All aspects of reality - space-time, geography, science, culture - are sensuously reimagined, every dimension of human experience is dialled to the max, and the prose, oh boy, the prose is just mind-bendingly awesome and painterly and fizzing with novelty and Beethovan-level emotion. It was reading Ada that made me realise that no form of future virtual reality will ever likely out-gun reading as a tool of imagination; that reading, said differently, is the first and best form of virtual reality.\n\nAda or Ardor: A Family Chronicle (Penguin Modern Classics): Amazon / Amazon UK\n#3. Eastern Approaches (Penguin World War II Collection), by Fitzroy MaClean\n\nThe third section is the peak of Eastern Approaches: The tale of MacLean’s experiences in Yugoslavia, into which he was parachuted in late 1943 to investigate a resistance movement, or person, or something-or-other called Tito. Turns out to be the the future President Tito, at that point fighting an improbable guerrilla resistance to German occupation with his small band of Partisans from their piratical HQ in a ruined castle. For two years, MacLean fights alongside and helps out the amazingly impressive Tito and his band of Partisans till they successfully run the Germans out of the country. Tito, by this point a national hero, assumes power over a united Yugoslavia at the end of the war, masterfully plays the Russians off against the Americans, and creates a ‘Third Way’ between communism and capitalism, which, by all accounts, was pretty solid.\n\nEastern Approaches (Penguin World War II Collection): Amazon / Amazon UK\n",
    link: "/home/2016/09/05/coffee_morning",
  },
  {
    title: "Upcoming chances to meet in Amsterdam, Berlin, etc",
    date: "11.15, Monday 26 Sep 2016",
    content:
      "So I’m heading up this startup accelerator for IoT and connected hardware. Applications close 14 November. I’ve just been in the states seeing how previous programs have run. It’s all pretty excellent. More on that later.\nRight now I’m in outreach mode. I’m meeting as many startups as possible in order to spread the word, and to get a better sense of what the current challenges and opportunities are.\nIn return, I’m happy to share my take on the business and product, make connections to potential partners and investors where I can, and answer questions about how this particular accelerator works.\nAll of this is usually quite ad hoc, but there are a few convenient times coming up:\n\nAmsterdam. I’ll be at Makerversity in Amsterdam on Friday 7 October. We’ll be hanging out and having coffee in the afternoon, sign up here. More focused meetings also possible.\nBerlin. I’m in Berlin for a few days, and will be running office hours at Betahaus on Friday 14 October. Got an Internet of Things or hardware startup? Sign up to meet.\nSkype. The problem with coffee meetings is you only spend time with startups who are nearby. So on Wednesday afternoons though October, I’ll be at my laptop ready to speak. Choose a time here.\n\nOf course I’m always up for meeting over coffee. Drop me a line if you want to set something up: matt at interconnected dot org\n",
    link: "/home/2016/09/13/3_books",
  },
  {
    title: "3 Books Weekly #29: feat. Christina Cacioppo",
    date: "09.00, Friday 30 Sep 2016",
    content:
      "The following was first posted on the 3 Books Weekly email newsletter and has since been archived here.\nHi all!\nAfter an Unplanned Hiatus (I was travelling for a couple of weeks…) we’re back, and I am super delighted to have 3 books picked by Christina Cacioppo (Twitter: @christinacaci).\n…who is a CRAZY PROLIFIC reader. When I have a spare moment, I browse her book recommendations. I suggest you do too. Website over here which has more books, more projects.\nSo we’ve got more East Africa this edition, and more China too, which is definitely becoming a theme. Also a hint at a bit of a personal story – Christina, seriously, you read a book and totally upended your life?? Dangerous stuff, reading.\nBefore we get to the books, a favour: I’m looking for a new host for the vending machine. Somebody who wouldn’t mind having a mini automatic bookshop in their lobby for a couple of months. It’s been at Hachette and at Google. Spread the word, drop me a line.\nHappy Friday all!\nMatt\n#1. Open City, by Teju Cole\n\nI read fiction in order to see through someone else’s eyes, if only temporarily, and Teju Cole gives his readers outside lenses better than everyone else. Open City’s narrator, Julius, is a half-Nigerian, half-German immigrant who spends the book wandering New York City, slamming off those he meets like bumper cars. I like this book so much because it introduced me to the concept of ordinary solipsism - the idea that we each play hero roles in our own stories and heroic roles in others’ stories; it’s the best way I’ve found to explain myself and other humans - especially when someone’s frustrated.\n\nOpen City: Amazon / Amazon UK\n#2. I Didn’t Do It For You: How the World Used and Abused a Small African Nation, by Michela Wrong\n\nMichele Wrong has the best sense for place, hands down. She spent her career reporting from East Africa, mostly for news magazines, and I Didn’t Do It For You is the second of her four books. It’s the story of Eritrea: a country cleaved from Ethiopia after a half-century’s struggle and that, to commemorate its independence, erected a statue of a sandal (5m long, in Shida Square) in its capital, Asmara. She tells Eritrea’s story by profiling the people and places that made the country, and it’s absolutely captivating. I found it so enthralling, in fact, that after I finished this book in university, I changed what I was studying, applied for a summer research grant, and booked a flight to Asmara.\n\nI Didn’t Do It For You: How the World Used and Abused a Small African Nation: Amazon / Amazon UK\n#3. River Town: Two Years on the Yangtze, by Peter Hessler\n\nThis is the I-spent-two-years-in-the-Peace-Corps-and-here’s-what-I-learned bildungsroman that everyone tries to write and no one pulls off. No one, that is, except Hessler. River Town is a personal profile, ostensibly, about Hessler’s teaching English in rural Sichuan in the 90s, though you learn more about the Sichuan before cars, highways, and the Three Gorges Dam than you do about him. Hessler’s talent, as a journalist, is his minute interest in “the everyman”; by writing about dumpling-shop owners, Party administrators, and his students, he captures what it meant to be Chinese before everything changed. There’s no book better in English about what China was.\n\nRiver Town: Two Years on the Yangtze: Amazon / Amazon UK\n",
    link: "/home/2016/09/26/chances_to_meet",
  },
  {
    title: "Visiting Berlin, and some thoughts on the new IoT program",
    date: "08.40, Tuesday 11 Oct 2016",
    content:
      "I’m meeting a ton of interesting startups in the course of outreach for this new Internet of Things accelerator in London. What’s working best is turning up at events and talking about it – because what we’re doing isn’t typical, I guess, and it needs a bit of an intro. More about that further down this post…\nBerlin\nI’m off to Berlin this week. Spending a few days because the Internet of Things scene is well developed, and there are a ton of connected hardware startups.\nSo, here’s where I’ll be. Please sign up to any and all!\n\nThurs 13 October, 7pm. IoT Berlin meetup at IXDS. Hosted by Martin Spindler. I’ll be speaking about the new program… plus sponsoring the drinks which is maybe more of a draw\nFri 14 October, 9am. Hardware-ish coffee morning is spreading to Berlin! Same format at London: Coffee, nice people who are doing hardware or curious, chat, super informal. Here’s Martin’s announcement. Location: Distrikt Coffee. Should be fun hanging out, bring prototypes if you have em.\nFri 14 October, 11am-4pm. Opportunity for one-on-one chats at. Betahaus are kindly lending me a space to hang out for the day. Details here. If you’d like feedback on your startup or have questions about the program, drop me a mail with when you’d like to come along. My work email is best: matt.webb@rga.com\nSat 15 October, afternoon/evening. I’ll be at Betapitch, on the jury and meeting startups. If you’re there, say hi!\n\nProgram\nI travelled to the states a couple of weeks back to meet alumni from R/GA’s previous programs. I wanted to get how it works from the horse’s mouth, if you know what I mean.\nMy conclusion is this… it’s an investment package (£75k in the case of the new London program) plus 12 weeks to take the 10 startups in the cohort through a traction step-change.\nHow that works is via carefully selected mentors, and a lightweight curriculum of workshops (say, on performance marketing, depending on what folks need), but MAINLY\n\nMaking use of R/GA’s creatives and strategy folks. There’s an assessment at the beginning to identify what one or two things would unlock growth for each company. Maybe it’s a finessed business model which we can get to through market sizing; maybe it’s a sales deck, or messaging strategy, or refreshed brand. Maybe it’s how to best tell the story of some amazing tech but in a newly professional way. So we figure that out, then deliver that thing.\nMaking use of the client networks. Most startups could benefit from partnerships with corporates – either pilots towards becoming customers, or because a partnership would prove out some of the business model. That’s tough in one or two meetings. But R/GA knows its client network really well, and we’re getting to know the Innovate UK of smart cities and innovation hubs too (the government, via Innovate UK, is a partner in the program). Over 12 weeks, we can work to make something happen. I like this because it’s time-boxed: If it doesn’t work out, the startup hasn’t wasted their time trying to work with corporates who are typically pretty slow. If it does… well that’s some great traction and something great to show off about.\n\nAt the end of 12 weeks, there’s the usual demo event, and that’s usually also firing a starting pistol for an investment round. There’s a ton of help with creating the pitch and pitch deck too.\nImagine coming out of the program and having one or two new big names on the traction slide.\nBecause R/GA has a stake, interests are aligned on long-term success – I met a startup in NYC who went through the connected devices program there 2 years ago. They’re now 30 people, still in the R/GA NYC office, and keen to stay there because of the access to people and new connections.\nSo I think of this more like a growth-focused program. I’m moving away from using the word “accelerator.” The investment terms are friendly to slightly later stage startups (i.e. the hardware is at least at prototype stage) and perhaps that’s where the R/GA approach works best.\nStages\nI say “stage,” that’s not what I mean. Some startups are great at hardware but - because attention and people budgets are limited - a bit too lean on the sales, marketing, and partnerships side. Some are brilliant at the business side but need help developing the hardware.\nThere’s a lot of support in the London ecosystem for early hardware development (let me know if you need pointers), but in our ground floor space, we don’t have a machine shop. We’ll be making room for physical work, but that’s not the focus.\nThe gap I’m wanting to fill is, ok, you’ve got the hardware, but the service around it: How to sell that. Or you’re between Kickstarter and shipping, ok how to get all the ducks in a row so this becomes a serious business.\nGrowth.\nWhy hardware?\nI talk a lot about connected hardware, even when I’m talking about the Internet of Things. And with IoT, surely I could be talking about platforms that are software-only? Big data analytics, device provisioning, security, etc. There’s a lot. And yes, I love that.\nBut I’m especially interested in hardware. For me, hardware is a signal that all the power of software and the web is being applied to the real world. The hardware doesn’t need to be complex or involve a massive breakthrough – in fact maybe the simpler the better.\nOnce you apply hardware, you start being able to tackle problems like food waste, retail, soil, gestural interfaces, and power. In short, where we live.\nLinks\nThere’s more info about the program on the website.\nWe’re having an open house event in London the evening of 27 October. Sign up here.\nApplications close 14 November. The program runs February to May 2017.\nHappy to chat on Skype about whether there’s a good fit. Book some time in my calendar here.\n",
    link: "/home/2016/09/30/3_books",
  },
  {
    title: "Hardware-ish coffee morning, Thursday 10th",
    date: "09.50, Thursday 3 Nov 2016",
    content:
      "Time for a hardware-ish coffee morning…\nThursday 10 November, 9.30am for a couple of hours, at the Book Club, 100 Leonard St.\nYou know the score: No intros, no presentations. Just a corner at a handy cafe and seriously talk to EVERYONE it’s worth it. Bring prototypes if you have em, and if you don’t then your good self is enough… especially if you’re interested in hardware, discovering spectacular new business models that make delivering hardware worth it (sigh), Kickstarter, how to get to manufacture, tinkering, etc, etc.\nSometimes there are four of us, sometimes 14. Once there were 24. All super relaxed and friendly. Come along!\n(This coffee morning is on request. Somebody got in touch because they want to bring some early protos. Awesome!)\nMy secret agenda – I’m heading up R/GA’s newest startup program and we’re investing in hardware and Internet of Things companies. I’m on the hunt for great startups. But if you’re interested in the program, don’t feel you need to come to this… coffee morning is about hanging out with everyone there, not about me. To talk program stuff, we can always Skype. Book a time here.\nSee you on the 10th!\nps. for email updates about hardware-ish coffee mornings, join to the mailing list.\n",
    link: "/home/2016/10/11/berlin",
  },
  {
    title: "Hardware-ish coffee morning, Thursday 15th",
    date: "09.15, Wednesday 7 Dec 2016",
    content:
      "Okay okay okay, let’s have one more hardware-ish coffee morning to wrap up 2016…\nThursday 15 December, 9.30am for a couple of hours, at the Book Club, 100 Leonard St.\nYou know the score: No intros, no presentations. Just a corner at a handy cafe and seriously talk to EVERYONE it’s worth it. Bring prototypes if you have em, and if you don’t then your good self is enough… More info here.\nMight be 5 people, might be 25, might be just me and my email. Feel especially welcome if you are NOT A DUDE because it’s weird otherwise. All super relaxed and friendly. I’ll bring Christmas crackers if I remember and we can all wear hats.\nSee you on the 15th!\nps. for email updates about hardware-ish coffee mornings, join to the mailing list.\n",
    link: "/home/2016/11/03/coffee_morning",
  },
  {
    title: "Filtered for the great outdoors",
    date: "10.05, Monday 5 Jan 2015",
    content:
      "1.\nWhat playing cricket looks like to Americans (video).\nI’ve been sick since just after Christmas – nothing much, just a light cold that turned into a sinus infection which is usual for this time of year. A slight ringing in the ears; dizziness if I move my head too fast.\nEvery year this happens! I need my sinuses like I need a hole in the head. Badum tish.\nThe weirdest effect of this barely-there sickness is that it’s leaching my volition. I have zero ideas. Or rather, I can respond to stuff quite adequately. But self-starting volition: Nope. All gone.\nCricket is simultaneously boring and this long, complex, open-ended… something. The annual-or-so Australia/England Test series - the Ashes - comprises five 5-day games. The place in a series can only be described half as stats and half as story.\nAll the possible cricket fielding positions.\nMy favourite is when the games are being played in Australia, because then I have the radio on all night and I listen to the ebb and flow of the game through dozing and the half-light of consciousness. And that fully felt, undescribable sunlit contest builds in my head for a month and a bit, the length of the series. A soundtrack.\nI wonder why we fall so easily into accepting a movie soundtrack. Maybe we have soundtracks in regular life. Not heard but felt. And that’s the niche being occupied.\nRegularity, daily routine, the beat of a soundtrack composed in microhertz. I can choose.\nGood grief, I need to see the Sun.\n2.\nThe Capital Ring (which is in yellow on this map) is a 70-something mile walk circumnavigating London, linking together parks and open spaces in the city.\nIt’s made of 15 sections.\nI think I need some outdoors, that’s basically it.\nBut I also wonder, why no volition? What’s resting? What’s finding a new direction?\n3.\nThe US National Institute of Standards and Technology (NIST) publishes random numbers, every minute of the day: FEB25F1F8A3CD0712 7162AAFF20D0B17D 5A7FFF80523028C8 BE793471EED8335\n A955C461D6F4B9C2 8075327469F57315 F2CA216CC5805561 1DF490AEAF64F2B9\nThe story of how it works is interesting. Coin flips, seeds, and trust.\nI don’t think having new ideas is quite like having an internal random number generator. But whatever’s gummed up in my sinuses right now, that’s what’s rusty, or sore and stuck.\nI think the reason I reach for this kind of language is that one way of seeing illness is as a psychic phenomenon. If I bash my leg, a bruise comes up: fluid builds up around the flesh to hold it and cushion it while it repairs. My being sick is also me wanting to be sick; I am the fluid cushioning, in a way. But holding what while it builds strength?\nThere’s also something magical about being sick that always brings home to me how embodied we are. No mind/body partition here, no way.\nRelated: I watched the movie Computer Chess over the holidays. The Guardian review calls it audaciously boring. Human/machine. Recommended!\n4.\nOne of my favourite accounts on Twitter is @herdyshepherd1 – he’s a shepherd in the Lake District. It’s mainly pictures of sheep and his dogs (and fields) early in the morning. Which would be enough…\nIt’s also, for me, a sense of connection. With sheep and dogs (and fields).\nWhich is wonderful.\nHis story.\nHis photos on Instagram. Must follow.\nThen there’s stuff like his commentary on fell walking, for instance, Wainwright’s canonical fellwalks of the 1950s.\n\nIt is quite common for Lake District shepherds to have not been to some of the other valleys - knowledge and work is very local.\nThe idea of ticking off fells like Wainwright is a fairly alien notion to local folk - many would reply ‘what for?’\nOlder folk thought fell walking was a sign of someone not being a full shilling.\nFell walking is inherently modern - based on idea that an individual can experience something and that the ‘self’ matters…\nBut older working communities are more medieval in their perceptions and value an individual within their working context… Self irrelevant\n‘This accidental present is not the all of me… That was so long in the making’ Oodgeroo Nuunucal\nSo, Lake District has two cultures… One that is very modern and about the ‘self’ and one very old and native that is about the ‘community’\nIt’s the X Factor that has set me off… No one gave a damn if you had a ‘passion’ before romanticism. Wordsworth turned in to Simon Cowell\nThe genius of romanticism is that it says everyone can join the club… Whereas older patterns of experience of place are earned/closed\nI’ve been trying to be a farmer/shepherd for about forty years and am in the beginners class… Fell walking is easy to become part of!\n[true enough, although walking (and tourism) is surely important for your communities?] Yes. I like guests, not conquistadors\n\n@herdyshepherd1 is James Rebanks, and his book, The Shepherd’s Life, is out in April: His family have farmed in the same area for six hundred years.\n",
    link: "/home/2016/12/07/coffee_morning",
  },
  {
    title: "Filtered for monkeys and A.I.",
    date: "14.56, Thursday 8 Jan 2015",
    content:
      "1.\nWho owns the monkey selfie?\nThere was an interesting dispute last year around that photo the monkey took of itself… or rather, a photographer was out to take pictures, but a monkey nicked the camera and took loads of pictures, then the photographer picked out a particularly good one and shared it, and everyone called it the “monkey selfie.”\nThen Wikipedia published the photo without asking the photographer, and justified it by saying that actually the monkey owned the photo.\nAnne takes this to an interesting place:\n\nDoes the monkey have agency? Clearly.\nIs the monkey the author-photographer? Sure.\nIs the monkey the owner? Possibly.\nAnd if this nonhuman has agency, and the power of authorship and ownership, what about other nonhumans?\nWhat about the camera? What kind of agency does it have? Can a camera author an image? Own a photograph?\n\nIs the camera the author of the photo?\n2.\nAmazon’s robotic fulfilment army [video].\nIn other robot news, If Your Robot Buys Illegal Drugs, Have You Committed a Crime?\nIf I give you a cake, did I deliberately make you happy? Of course.\nIf I order it to be sent online? Of course.\nIf I flip a coin and if it comes up heads then you get cake, then I flip the coin and it’s heads? Yes.\nIf I write a program that can buy all kinds of stuff and sometimes buys cake? Probably, yes.\nIf I write an artificial intelligence that wants to delight you, and it happens to get you cake, is that still my agency? I think so, yes.\nAt a certain point of complexity (is it complexity that matters?) it’s no longer my agency. But I don’t know what that is.\nI want there to be like an age of majority for systems of cause and effect, with a threshold of complexity rather than years since birth.\n3.\nx.ai is an automated, email personal assistant to help you arrange meetings. It uses artificial intelligence.\nMatt Turck’s analysis of A.I. as a space is great. How artificial intelligence will come to market:\n\nwe’re about to witness the emergence of a number of deeply focused AI-powered applications that will achieve commercial success by solving in a definitive manner very specific issues.\n\n…which is a great way to think about it. I don’t care how this personal assistant works, but it’s great that the company behind it were able to create it. And they were able to create it because of A.I.\nIf it does something weird or wrong, whose fault is that? The programmers? In some cases. But in most cases, if the person I’m arranging a meeting with is let down or offended or pissed off… it’ll be my fault, the user, the person who introduced the A.I. into the situation.\nSo how do I “interview” an A.I. for this personal assistant job role? How do I get to know them, assure myself they’re not going to do anything bonkers?\n4.\nIntel have released a computer that plugs into the back of a TV.\nWhen you open the box, it plays the Intel jingle.\n",
    link: "/home/2015/01/05/filtered",
  },
  {
    title: "Coffee morning 4",
    date: "10.29, Friday 9 Jan 2015",
    content:
      "Let’s have another coffee morning! First one of 2015.\nThursday 15th January, 9.30am for a couple of hours, at the Book Club in Old St.\nDo come, it would be lovely to see you!\nHere’s what what happened at the last coffee morning. tl;dr we talked about the manufacturers of web-connected products speaking to consumers for the very first time, and sexy turducken. Also there were crackers.\nAnd here’s what coffee morning is all about… a mini, informal street corner to chat about nonsense and hardware. But mainly to drink coffee and hang out.\nOh and – if you want reminders by email, there’s now a coffee morning announce list. Subscribe here.\nSee you next Thurs!\n",
    link: "/home/2015/01/08/filtered",
  },
  {
    title: "Filtered for the Internet of Things",
    date: "10.48, Tuesday 13 Jan 2015",
    content:
      "1.\nWhat acronym do we give the Internet of Things? John Gruber:\n\n“IoT” is a terrible acronym, especially in a world where Helvetica and Helvetica-like sans serifs are so popular. Capping the “o” too would help a little – it would make it much more clear that it’s spelling EYE-oh-TEE, not ell-oh-TEE.\n\nOk, IOT it is.\nI wrote a post back in 2013 about how any of Amazon, Apple, and Google could become the default platform for IOT.\nSince then…\nAmazon have launched new Amazon Web Services tech focused on supporting sensors and web-connected devices.\nGoogle acquired the home gadgets company Nest, back in January 2014. Since then they’ve been expanding the platform for developers, and there are now many home products that work with Nest. My feeling is that, for IOT, this is the best way to build a platform: Start with a killer product, then include partners, then finally move to 3rd party developers.\nAnd Apple released Homekit, some standard tech for wireless chips that makes 3rd party products work better with iPhones. For instance, every Homekit product has to support identification: Users need ways to identify the accessory they are adjusting, so make sure to provide quick access to a control that physically identifies the accessory. In the case of a light bulb, for example, you might let users flash the bulb using your app to confirm its identity in the home.\nMost interesting? Apple has added features to the Apple TV box so that it enables Homekit products being controlled from outside the home: So, while commands like ‘Siri, turn off the lights in the living room’ will always work while connected to your home Wi-Fi network, they won’t from the airport unless you have an Apple TV.\nCurious. Sounds like Apple is building the right thing.\n2.\nHalf of the Internet of Things is the things.\nBut making hardware is hard. Or rather… it requires a process which isn’t familiar to most of the startups who turn their attention to hardware, and investors aren’t familiar with how to fund hardware startups.\nSo specialised startup incubators are emerging.\nThe Economist has a special report. Hacking Shenzhen, Why southern China is the best place in the world for a hardware innovator to be.\nFocuses on Haxlr8r.\n3.\nTwo hardware startups I’ve run across recently…\nRe-Timer, a wearable headset that uses bright lights to tinker with your circadian rhythms – and fix jet lag.\nAnd Kisha, the umbrella you’ll never lose. It’s a weather forecast app, plus an alert that goes off if you leave your umbrella outside your “safe” places.\n4.\nFrom IBM, this Executive Report, Device democracy: Saving the future of the Internet of Things (via @bruces).\nLiquifying the physical world.\nGreat summary of the opportunities and challenges in scaling IOT.\nChallenges identified:\n\nThe cost of connectivity\nThe Internet after trust\nNot future-proof\nA lack of functional value\nBroken business models\n\nFrom experience, these are exactly the challenges businesses face as they have to adapt to connected products.\nI’m impressed with what IBM are up to at the moment. Their collaboration with Apple has produced some solid business apps, and their new design language is great.\nAlso: The UK government’s approach to the Internet of Things is laid out in the Blackett review, a paper by the Government Chief Scientific Adviser on what the IOT opportunities are and how the government can help.\n",
    link: "/home/2015/01/09/coffee_morning",
  },
  {
    title: "Today’s coffee morning, and SALES SALES SALES",
    date: "18.10, Thursday 15 Jan 2015",
    content:
      "Coffee morning 4 was super fun! Great chat and thank you for coming, Tom, James, Martin, Tom, Matthew (who took a photo), Dev, James, Daniel, Basil, Ben, Chris, Iskander, another Tom, and Jess!\nThree people showed prototypes from their hardware startups. So, so good. Two people had successful Kickstarter campaigns under their belts. There was talk of new year’s resolutions and books, and Dev described his brand of technology as the art of turning things off and on… but, you know, in an experience sort of way. And I got to play with some Duplo because Jess brought her infant. Or someone’s infant, I didn’t think to ask.\nBut before I get to any of that:\nHoly shit, TOO MANY DUDES.\nThis is a real problem. I know this is only chat and coffee, but what I’m attempting to foster here is a sparky street corner where serendipity occurs. With no structure! Informality! And it’s working well. But when it’s mostly men it’s just weird.\nSo I had a chat with Basil and I had a chat with Jess, and we’ve got a couple of ideas about how to bring this back into alignment with the regular world – and there’s no excuse, especially because hardware startups so often have women founders. If I don’t fix this soon, it’ll get entrenched. So more ideas welcome.\nSelling to people who aren’t your mates\nWhen I was a kid, I had an LP – a long-playing vinyl record, which is kind of a large black CD where the sound is actually sculpted into the surface of the plastic – and I guess I should also say that a CD is a Compact Disk, at which point you say: Compact compared to what? It stores a hundredth of what you get on an iPod and you can’t even plug your headphones in.\nAn iPod, by the way, used to be a physical thing. Now it’s an app on your phone.\nI had an LP.\nOn the LP was a novelty song by Charlie Drake called My Boomerang Won’t Come Back, and I won’t pretend it was anything other than shamefully racist. Sayeth Wikipedia, the track is not exactly a paragon of political correctness, even by 1961 standards. In the song, an Aboriginal meeting is described as a ‘pow-wow’, something more appropriate for Native Americans, while their chanting sounds more African than Aboriginal.\nHere’s the song on Youtube. Listen at your own risk.\nHowever.\nThe punchline of the song is where the boy who’s boomerang won’t come back (who has practiced till I was black in the face/ I’m a big disgrace to the Aborigine race) meets a witch doctor (I know, I know…) who tells him:\nif you want your boomerang to come back, well, first you’ve got to throw it.\nWhich is true. And also hands-down the best sales advice I’ve ever encountered.\nTHE RELEVANCE OF THIS:\nOne of the most common challenges I see in hardware startups is that, after the initial burst of selling, product sales stall.\nThere were two conversations I had this morning that made me think of this. There’s a startup at Techstars who is thinking about the same thing; I’ve had similar conversations with a couple of other hardware startups thinking their way through this. I’ve experienced this myself, and the story goes as follows:\nYou’re a designer, or a creative technologist, or whatever. You’re good at networking so you know how to reach many thousands or millions of people.. You’re good at pitching your idea, well practiced, so you know how to craft a story. You launch your product; it sells.\nAnd sales are decent. When you have PR.\nBut hardware ain’t websites and ain’t apps. You don’t get an email address with hardware. You can’t encourage your users to spam their Facebook friends, like an app can. Apps have got virality: Monkey see app, monkey download app from the App Store right there and then. Hardware got no virality. Users don’t get more users.\nSo sales don’t hockey-stick.\nNow what you do is what everyone does when they experience a challenge, which is you repeat what made you successful in the first place. You do what you’re really good at. You iterate the design, add features, you do better PR, you do a bunch of talks and you craft better stories.\nBut this is a build it and they will come approach. It probably doesn’t work.\nYour local social network is now saturated. You need to reach beyond your mates - and your mates of mates - and sell in a different way. But how?\nYou gotta advertise.\nAt Techstars, I’ve been privileged to work with people who really know their shit about digital marketing. They understand e-commerce inside-down and upside-out.\nHere’s a simple thing they talk about: Putting a budget against, say, Facebook ads. Try a bunch of stuff, see what works. Whatever profit you make from that, recycle it: buy more ads! If you’re receiving money from new sales on a weekly basis, you get to recycle money every week. If you get money daily, you recycle daily and grow faster!\nAs you get better at selling, you recycle the cash and your budget grows and grows… but it’s free money! It’s still your original budget!\nI was talking to Dev about this - at the coffee morning - and he went through the same thing for his Kickstarter campaign. He said that digital marketing was clear and obvious… once it had been framed for him as an engineering challenge with end goals and a toolset. What channels generate sales? What phrases work? Measure it all.\nAnyway, I know this is obvious, but it’s all about reaching and selling to the people we don’t already know, in a repeatable, testable, iterated-and-improvable way. And I only say it because I’ve had this conversation a dozen times in the last month, and as tech folks and designers (as opposed to biz and marketing people) it appears to be something that we don’t notice, or don’t get to, or find excuses to not do because “the product isn’t ready” or something. Holy shit I’ve heard a lot of excuses.\nThis sales attitude has got to be in the team DNA early on, or it’ll feel alien when it - inevitably - gets introduced later. What the product is and how the product is understood AND SOLD has to evolve hand-in-hand.\nIf you want your boomerang to come back, first you’ve gotta throw it.\nOther reason I bang on about this: Ignoring sales is a personal pitfall, and I want to make sure that, for my next venture, I think about sales as early as possible. Ultimately it’ll make for a better product.\nNext coffee morning\nCoffee morning 5 will be January 29th, same bat-time (9.30am), same bat-channel (Old St). For reminders, join the mailing list.\nFolks who came today: Thank you for coming! If you want me to connect you with anyone you chatted to, drop me a mail – I collected email addresses. I’d love to hear about the conversations you had, let me know what sparked your imagination!\n",
    link: "/home/2015/01/13/filtered",
  },
  {
    title: "Filtered for cats and bears",
    date: "08.24, Friday 16 Jan 2015",
    content:
      "1.\nList of company name etymologies, Wikipedia.\nSome Korean companies:\n\nDaewoo which means ‘Great House’ or ‘Great Universe’ in Korean\nHyundai ‘the present age’ or ‘modernity’ in Korean\nLG from the combination of two popular Korean brands, Lucky and Goldstar\nSamsung meaning three stars\n\nGood names. Great universe.\n2.\nBusiness Cat has some coffee.\n3.\nWhen you press the Help button on the ticket machine at the subway in Japan, a man climbs out of a hidden little door.\n4.\n\n24 pieces of life advice from Werner Herzog.\nSome faves:\n\n\n\nSend out all your dogs and one might return with prey.\n\n\nLearn to read the inner essence of a landscape.\n\n\nTake revenge if need be.\n\n\nGet used to the bear behind you.\n\n\n\n",
    link: "/home/2015/01/15/coffee_morning",
  },
  {
    title: "Filtered for weekend reads",
    date: "13.32, Sunday 18 Jan 2015",
    content:
      "1.\nI mentioned the women’s movement classic The Tyranny of Structurelessness the other day, on the dangers of refusing to admit power… informal structures have no obligation to be responsible to the group at large. Their power was not given to them; it cannot be taken away. Their influence is not based on what they do for the group; therefore they cannot be directly influenced by the group.\nHere’s a critical response by Cathy Devine, The tyranny of tyranny, which raises the counter-risk of roles in organisations standing in the way individuality:\n\nWhat we definitely don’t need is more structures and rules, providing us with easy answers, pre-fab alternatives and no room in which to create our own way of life.\n\nAnd,\n\nwe are reacting against bureaucracy because it deprives us of control, like the rest of this society; and instead of recognising the folly of our ways by returning to the structured fold, we who are rebelling against bureaucracy should be creating an alternative to bureaucratic organisation. … it is more than a reaction; the small group is a solution.\n\nTouches on a few topics I’m super curious about right now… small groups, informality, a trust in the irreducible human element.\n2.\nGenevieve Bell and Paul Dourish’s 2006 paper Yesterday’s tomorrows: notes on ubiquitous computing’s dominant vision which makes the compelling argument that the habit of researching ubiquitous computing (now called Internet of Things) as something science-fictional or in the future prevents us from applying those learnings to the ubiquitous computing already here today.\n\nthe centrality of ubiquitous computing’s “proximate future” continually places its achievements out of reach, while simultaneously blinding us to current practice. By focusing on the future just around the corner, ubiquitous computing renders contemporary practice (at outside of research sites and “living labs”), by definition, irrelevant or at the very least already outmoded. Arguably, though, ubiquitous computing is already here; it simply has not taken the form that we originally envisaged and continue to conjure in our visions of tomorrow.\n\nI worry about this with the Internet of Things. There’s a lot of research and good thinking… a ton of understanding. But without a deliberate effort to draw that research into the present, will present-day IOT - like connected products in Kickstarter and city-wide transit swipe cards - be able to learn?\nAnd what I really mean is, given research and products come from groups of individuals, do these people hang out and have a common language?\n3.\nPulp’s Big Moment, the New Yorker on the origin of mass-market paperbacks in the 1930s… The key to Lane’s and de Graff’s innovation was not the format. It was the method of distribution.\nTrain stations! Wire racks! Putting books where books weren’t usually sold!\n\nInstead of relying on book wholesalers … de Graff worked through magazine distributors. They handled paperbacks the same way they handled magazines: every so often, they emptied the racks and installed a fresh supply.\n\nPlus the usual high-brow/low-brow scuffle.\nSpeaking of which, readers absorb less on Kindles than on paper, study finds. Interesting if true, but I’m suspicious of high-brow snobbery.\n4.\nThe New York Times on a series of 36 questions that makes any couple fall in love (you’re also required to do 4 minutes of silent continuous eye contact).\nFrom before: the similarities between dating and variable-interval operant conditioning.\nAnd OF COURSE somebody on Hacker News went and turned the 36 questions into a website… Want to fall in love? Play The Love Game (TM).\nHacking intimacy.\nIs there a serious difference between this and Jeff Bezos’s acclaimed method to introduce “Service-Oriented Architecture” at Amazon by imposing the two-pizza rule? any team should be small enough that it could be fed with two pizzas.\n",
    link: "/home/2015/01/16/filtered",
  },
  {
    title: "Filtered for pictures and what’s OK",
    date: "10.18, Tuesday 20 Jan 2015",
    content:
      "1.\n\nThe decision to remove Grand Theft Auto 5 from the shelves of Target and K-Mart stores in Australia caused quite the reaction, especially in the American gaming press.\nThe move was discussed, argued over and written about, but the act itself took place in Australia, and reflects Australian culture and history.\n\nGrand Theft Auto 5, Australian culture, and how the American press misses the point.\nWhat comes across in this article - through a number of examples - is that, in Australia, debate is not polarised, but We’re more likely to participate in public debates about [speech and art], more likely to feel heard and have more faith in judging it.\nPublic discussion of what’s OK.\n2.\nA neat flow diagram of the various publicly funded research projects that fed into the iPhone.\n3.\nGorgeous pictures of 3D fractals.\n4.\nBeautiful Instagrams through aeroplane cockpit windows, but… But taking photos, or using most any electronic device, while piloting a commercial aircraft is prohibited by American and European regulators.\nAnd:\n\nSome also appear to be flouting even stricter regulations for takeoff and landing, when not even idle conversation is allowed in the cockpit.\n\nBut my goodness the photos are beautiful.\nThat question of what’s OK… how do we decide… when do individuals break the rules and when don’t they… how do enough individuals break the rules and go “this is the sublime, this is what being human is about” and then as society we figure out that we choose the rules, and we have to find ways of making it safe to take photos from cockpit windows and share them?\nWhatever, they’re only Instagrams. But pretty ones.\nHow do we choose what’s OK? How do we, as a society, choose what we want?\n",
    link: "/home/2015/01/18/filtered",
  },
  {
    title: "Next coffee morning and how to run one",
    date: "21.37, Thursday 22 Jan 2015",
    content:
      "Let’s do coffee morning again! Next week.\nThursday 29th January, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nIt would be lovely to see you, come along! There’s a vague “making things” skew, but honestly I’ve spent a lot of time chatting about dogs and music…\nWe had way too many dudes last time. So if you’re Not A Dude or you bring a friend who is Not A Dude, I will be extra extra EXTRA pleased to see you. Please help me fix this.\nLast week’s coffee morning was bonkers… 15 people, 3 unreleased prototypes from hardware startups, an emergent theme about how to sell products. Other coffee mornings have been more low-key: Six of us talking nonsense and drinking too much caffeine. I don’t really mind what happens, it’s all good, maybe it’ll just be me and my laptop next time :)\n(What works for me)\nBut seeing as coffee morning is spreading to San Francisco I thought it might be worth writing down what works for me…\n\nSpace beats structure. Hardware-ish coffee morning is once every two weeks, same time, same place. I’ll be there, people come and go. There’s no sign-up list, no name badges, no speakers. There are a bunch of great events out there, I don’t need another place to be in an audience. Open space.\nInformality wins. It’s good to not have regular attendees… It’s like a street corner, familiar faces and surprise visitors. I try to help this by making sure there are lots of little conversations, not one big one, and by making connections if two people seem to be talking abut the same thing. Mingling is where magic happens.\nConvening not chairing. I announce a week ahead of time, and send reminders. I circulate my own perspective afterwards. If I’m having relevant meetings, I ask people to come to the coffee morning instead; that helps set a tone. I also collect names: Everyone gets added to a mailing list where they get all the updates. But at the thing itself, I just chat.\nBonfires not fireworks. For weird chats that have a chance of going deep and leading to new ideas, I suspect that 2 people is better than 20. A fine balance of familiarity and novelty. So: Slow burn. If I’m on my own one week, that’s fine. Just keep going. Telling everyone and making it too big too fast would kill it.\n\nIf I’m ever in any doubt, I go back and read what Russell did with his coffee mornings in 2007. He’s who it all comes from.\nFor email updates, join the coffee morning announce list.\n",
    link: "/home/2015/01/20/filtered",
  },
  {
    title: "Filtered for a squelchy something or other",
    date: "15.34, Saturday 24 Jan 2015",
    content:
      "1.\nWords in the 25 most common passwords of 2014:\n\npassword\nqwerty\nbaseball\ndragon\nfootball\nmonkey\nletmein\nmustang\naccess\nshadow\nmaster\nmichael\nsuperman\nbatman\ntrustno1\n\n2.\nI can’t remember when I first saw this, a segment from a BBC natural history document of a man hunting an antelope by endurance running.\nIt takes hours.\nThe hunter uses his hand to get into the mind of the antelope – there’s a moment where he has to think at it does, choose the same direction, pure animal empathy.\nYeah humans! I can’t help it, every time I see this. Go us!\nIt’s a bit of a weird reaction I know, because mostly my sense of “us” is mammals. When I think “we’re all in it together,” when I’m trying to figure out what’s ok and not ok about sacrificing dogs in the pursuit of leaving this planet to live in space, my loyalties are mammals. And my sense of “people” goes wider still. Distinguishable matter, probably. Asteroid people. A very different mode of thinking and being, sure, but a type of personhood and rights unto themselves.\n3.\nI’m completely obsessed with this extended mix of Bojack’s theme: great sounds. Deep dubstep bass, loooong sax, and some weird squelchy something or other. Can’t stop listening.\nBojack Horseman on Netflix.\n4.\nA digital clock where all the components are visible, every resistor, capacitor and all the wiring unpacked from its silicon chips, and laid out.\n",
    link: "/home/2015/01/22/coffee_morning_5",
  },
  {
    title: "Filtered for magic and legitimacy",
    date: "19.30, Monday 26 Jan 2015",
    content:
      "1.\nTypes of magician banned in ancient Rome, listed in the Codex Justinianus published in 534 AD.\n\nA haruspex is one who prognosticates from sacrificed animals and their internal organs; a mathematicus, one who reads the course of the stars; a hariolus, a soothsayer, inhaling vapors, as at Delphi; augurs, who read the future by the flight and sound of birds; a vates, an inspired person - prophet; chaldeans and magus are general names for magicians; maleficus means an enchanter or poisoner.\n\n(Source, book 9, section 18.)\nLook, you know, consultants.\n(In the context of Rome, magic is efficacious.)\nDesigners.\nAccount planning.\nCut open a goat and read the emails.\n2.\nNew system for data visualisation of London by After the flood: the London Squared Map. Squares and a pretty river wiggle.\n3.\nSitting and smiling.\n4 hour meditation sessions, recorded with Google Hangouts. Sitting and smiling.\n35 videos to date.\nUnnerving.\n2 hours and 36 mins into video #5, someone breaks into the house. Then, after presumably seeing me sitting still and smiling in front of a camera, lit from beneath by a florescent bulb, he promptly descends the stairs and exits the house.\n4.\nThree YouTube stars meet President Obama for a post-State of the Union interview: Holy Shit, I Interviewed the President, by Hank Green.\n“News” released its antibodies immediately. @rupertmurdoch: POTUS hard to follow saying no ‘available’ time for Netanyahu and then hours today with weird YouTube personalities. Strange timing.\nGreen:\n\nWalking around the White House, seeing the Press Briefing Room and all of the two-hundred-year-old chairs and decoy helicopters reminded me that the history of post-democratic power is really the history of legitimacy.\n\nAnd:\n\nThere is nothing actually legitimate about Fox News (or MSNBC for that matter) and young people know this. They don’t trust news organizations because news organizations have given them no reason to be trusting.\n\nAnd:\n\nLegacy media isn’t mocking us because we aren’t a legitimate source of information; they’re mocking us because they’re terrified.\n\nAnd here’s the fucking motherlode:\n\nThe source of our legitimacy is the very different from their coiffed, Armani institutions. It springs instead (and I’m aware that I’m abandoning any modicum of modesty here) from honesty. In new media this is often called “authenticity” because our culture is too jaded to use a big fat word like “honesty” without our gallbladders clogging up, but that’s really what it is.\nGlozell, Bethany and I don’t sit in fancy news studios surrounded by fifty thousand dollar cameras and polished metal and glass backdrops with inlayed 90-inch LCD screens. People trust us because we’ve spent years developing a relationship with them. We have been scrutinized and found not evil. Our legitimacy comes from honesty, not from cultural signals or institutions.\n\nWe have been scrutinized.\nSharpest analysis I’ve read in forever re: What Is Going On.\nThe internet means we don’t have to trust second-hand signals, and we choose not to because second-hand signals have been abused. In who we get our views from - and who we give our money to - we can scrutinize.\n",
    link: "/home/2015/01/24/filtered",
  },
  {
    title: "Comment on Internet of Things terminology",
    date: "11.22, Tuesday 27 Jan 2015",
    content:
      "Dan Hon commented: The thing - ha - about the internet-of-things is that it’s a weird descriptor.\n\nfrom a consumer point of view, for most things, why would it have wifi if it couldn’t be connected, in some way, to the internet? Which is sort of the position that all of this IoT business is a temporary blip and that instead you’ll just be looking for “doorbells” or “lightbulbs” or “locks” and you won’t really get a choice about whether they “come with internet” or not.\n\nI’ll go with that. The internet won’t stay trapped behind glass. – That was a useful encapsulation to explain what we were doing with Berg Cloud.\nOf course lightbulbs should be networked. But my hunch is that - with connectivity - we’ll find new products that means that we no longer focus on light bulbs per se. Maybe connectivity will mean that we’ll buy “lighting,” verbs not nouns.\nI guess the scale of the difference I mean is like software. Which, when networked, became social. Our global village.\n\nAnd it won’t necessarily be an “internet” and an “internet of things” but still, just, and only, the internet, at least I hope so, because the whole point of the internet - or at least, just one of the points of the internet is that things can link from one thing to another thing and that’s why the superset - the internet of networks of things - will be the one that wins. Hopefully.\n\nSo I have some very rough mental models that I use, now I’m officially exploring the Internet of Things.\n\nWords… I use titlecase “Internet of Things,” and fully capitalise “IOT” (not IoT) so it doesn’t look prissy.\nInternet of Things is an awesome rallying flag. All kinds of technologies, skills, opportunities, adjacencies, and changes are involved. We’re still building and debating it into being. I’m reminded of Web 2.0 and Tim O’Reilly’s 2005 essay, What Is Web 2.0: Design Patterns and Business Models for the Next Generation of Software. We don’t talk about Web 2.0 any more, but that’s what the deployment phase of the web was, for almost a decade.\nIt doesn’t feel to me like there is the IOT in the same way there is the Internet. There are IOT technologies and IOT experts and an IOT mindset. But it’s not a single thing. Why? Because technically it’s not fully connected, and I would argue that it doesn’t need to be. And also because it’s like that bit in The Graduate, I just want to say one word to you. Just one word. … Plastics. What? Pacemakers or wind turbines? Well, yes. All of the above.\n\nHere’s the working definition I have in my notebook: We see the internet of things wherever a physical thing is connected by some kind of data carrying link to a computer capable of running software.\nI’m casting a wide net – we’ve built a lot of infrastructure (train platform signage, building facilities) that we don’t call IOT but it is. Or it’s close to being so. Why is this good?\n\nThe physical thing is no longer closed. By adding software, features can be added and iterated in response to user needs\nThe computer end of things is easily networked, so things can be monitored and controlled remotely, data aggregated to provide extra intelligence, and the whole system incorporated into other software systems\nThe opportunity space off the Internet of Things is therefore opened up\n\nSo given my working definition, I need to refer to two types of connectivity:\n\nConnectivity is any kind of wired or radio link between the physical things and… anything else. Another physical thing, in a mesh network. A controlling computer capable of running software, such as an iPod Touch. A server.\nBackhaul is the specific connectivity that joins the thing to the internet. This doesn’t mean that the thing is routable on the open internet… it might just be networked to other things behind the same corporations firewall.\n\nI can think of lots of things that would benefit from connectivity without backhaul. I’d like to be able to orchestrate the behaviour of all the lightbulbs in my house, for example; remote control from the open internet is a bonus.\nThen back to Dan’s original point… and that’s why the superset - the internet of networks of things - will be the one that wins. Hopefully.\nHopefully. Maybe. But where my mental model takes me is to draw analogies with dumb unconnected stuff… my home. And I like that there are doors, that close, and windows that are see-through but with curtains; I can leave the phone off the hook and pull the plug on the wi-fi. There are switch by walls where my hand finds them, and those hidden at the back of the cupboard by the stove. These aren’t just security models – they’re ways of making sense of the stuff I have in my life.\nStill I go back the connected lightbulb and it’s eventual value. To discover the it might require building out the whole Internet of Things first… the World Wide Web was already 7 years old by the time Blogger.com launched and so discovered the real value of the medium.\nAnd maybe that’ll require the open internet and all that implies. I hope so too but I think we have to make that case from value, because it’s not necessary.\n",
    link: "/home/2015/01/26/filtered",
  },
  {
    title: "Hardware coffee mornings in SF and Adelaide",
    date: "08.30, Wednesday 28 Jan 2015",
    content:
      "A quick note that hardware-ish coffee morning (here’s the pattern) is spreading:\n\nSan Francisco! this Wednesday at 9:30AM at Coffee Bar on Mariposa. (That’s Wednesday as in today, the 28th.) Convener is @obra of hardware startup Keyboardio\nAdelaide! the Bean Bar on Currie Street on Friday the 29th January from 8.30am for an hour or so – that’s @andrewdotcom.\n\nGo along! Let me know how it goes!\nNext London coffee morning is tomorrow – here’s the announce list.\n",
    link: "/home/2015/01/27/comment",
  },
  {
    title: "Filtered for what’s around us",
    date: "15.24, Thursday 29 Jan 2015",
    content:
      "1.\nAmbient loops from sci-fi.\nIncluding! 12 hours of the engine noise from the ship Discovery in 2001: A Space Odyssey.\n2.\nBitter Lake by Adam Curtis available for viewing on iPlayer.\nA tone poem of the last 50 years of Afghanistan.\nCurtis’ blog post introducing it: Events come and go like waves of a fever. We - and the journalists - live in a state of continual delirium, constantly waiting for the next news event to loom out of the fog - and then disappear again, unexplained.\n3.\nPostcards from a supply chain by Dan W – It might be a photo, an anecdote, a video or a map. There will be mines and refineries and markets and ports and ships and containers. Lots of containers.\n4.\nThe Trees that Return Your Emails.\n\nDid you know that you can email every single tree in the City of Melbourne - and they’ll write back?\nRight now, you can log onto the City of Melbourne’s Urban Forest Visual map and email any tree you’d like within the council’s boundaries.\nYep, all 60,000 of them.\n\nI used the website to email a Corymbia Spotted Gum with ID 1358524.\n",
    link: "/home/2015/01/28/coffee_elsewhere",
  },
  {
    title: "Books read January 2015",
    date: "17.54, Thursday 29 Jan 2015",
    content:
      "By date finished…\n\nThe Book of Strange New Things, Michel Faber (2nd)\nAncillary Justice, Ann Leckie (11th)\nNineteen Eighty-Four, George Orwell (18th, r.)\nSoviet Space Dogs, Olesya Turkina (18th)\nThe Generation Starship in Science Fiction: A Critical History, 1934-2001,  Simone Caroti (25th)\n\nNineteen Eighty-Four is so much more horribly prescient than I remembered. History lives only in the present; feels like Wikipedia, like electronic records of all kinds? How Orwell put his finger on that I don’t know. And man, the paranoia. We swim through paranoia, it’s our ocean, we can’t see it.\nCaroti’s book on generation ships is half a history of the eras of science fiction, and half what generation ships meant in those eras. (Generation ships are starships where people live and die before it reaches its destination hundreds of years later.) \nThe Book of Strange New Things. Beautiful sentences. Meanings delicately poised. A Christian missionary, a man and wife, estrangement. And to discover this is Faber’s final novel and he wrote it while his wife Eva was dying – heartbreaking.\n",
    link: "/home/2015/01/29/filtered",
  },
  {
    title: "Drones and renders",
    date: "12.22, Friday 30 Jan 2015",
    content:
      "So the two things I got from yesterday’s hardware-ish coffee morning were:\n\nTV is dead, and the new TV is Youtube and Twitch – the live streaming video platform for video gamers to watch other video gamers play video games. Bought by Amazon for pennies shy of $1BN last year, and by February 2014, it was considered the fourth largest source of peak Internet traffic in the United States. Here’s the start-up I would do if I had some special access: Use GoPro cameras on drones with automatic follow-me functionality, and broadcast streams of climbers and surfers. Live. Put a tip jar on the side of the page.\nIn the age of renders and green screens, proving that a physical thing is real is super, super difficult. An app or website, you can share a screen grab or an animation and that’s as good as the software itself. It’s all just pixels. But physical things – I hear again and again about the lengths we go to, to drum home the point that this gadget or this printed product ACTUALLY EXISTS and YET everyone thinks it’s make-believe. So aside from sending the thing (whatever it is) to people through the post, or pointing a live webcam at it (which seems to carry some verisimilitude), ideas welcome… It’s a tough sell to get a potential customer to put down cash when, deep down, they’re sceptical about whether the product is genuine.\n\nThanks Gavin, David, Tom, Basil, Matthew, James, and Alex! Coffee again in a couple of weeks.\n",
    link: "/home/2015/01/29/books_read",
  },
  {
    title: "Consensus cosmogony",
    date: "16.39, Monday 2 Feb 2015",
    content:
      "Back in the golden age of pulp science fiction - the 1950s - there was an accepted view of what the future looked like. Wikipedia gives the run down as part of the article on Isaac Asimov’s Galactic Empire:\n\nThe initial exploration, colonization, and exploitation of the solar system\nThe first flights to the stars\nThe rise of a Galactic Empire [with optional aliens]\nThe Galactic Empire at its height\nThe Decline and Fall of the Galactic Empire\nThe Galactic Dark Ages [far future barbarism… a long time ago, in a galaxy far, far away]\nThe Galactic Renaissance\nThe Challenge To God by transcending matter and morphing into beings of pure energy, the end of time, and the investigation of the beginnings of new universes\n\nGIVEN THIS, you, a reader, could situate yourself in the future – you knew where a given story fit in.\nThe Western was not a genre – it was a consensus cosmogony.\nWhat’s special about the sci-fi future history is that the Space Race fit in: We weren’t just going into orbit and going to the Moon… we were taking the first step on Noble Eightfold Path to human occupation of the galaxy.\nSo we have all kinds of consensus understandings of what the future looks like, how we’ll get there, and what the first steps are. When consensus is strong, it’s an almighty power for coordination. For pulling in the same direction.\nOr the picture is one of doom. I grew up in the waning years of the Cold War; I knew I’d one day live in a post-apocalypse nuclear wasteland. We have a different consensus on the end of the world now: the jackpot, the changing climate: droughts, water shortages, crop failures, honeybees gone like they almost were now, collapse of other keystone species, every last alpha predator gone, antibiotics doing even less than they already did, but a world in which the oligarchs survive in a brave new world transformed by nanobots, clean energy, new drugs.\nI think Silicon Valley is a consensus cosmogony. Part of the consensus is that geography matters. My weakly-held hunch: That’s why it’s so hard to make small-s silicon small-v valleys elsewhere, ones that share that ambition and the success.\n(The Californian Ideology.)\nI’m glad I stumbled across the term cosmogony because it gives a name to what I do when I find myself in a new organisation, socio-economic network, consultancy gig, value chain, whatever. I call it mapping or orienting, but really I’m not doing that. I’m looking for something:\nWhat is the consensus cosmogony of the Internet of Things? What is its future? What does the consensus understand are the first steps?\nI’m not trying to figure out the rights and wrongs. I’m just trying to understand the grain of what we understand and what we expect.\n",
    link: "/home/2015/01/30/drones_and_renders",
  },
  {
    title: "Filtered for networks",
    date: "13.07, Wednesday 4 Feb 2015",
    content:
      "1.\nThis Ben Evans piece, The home and the mobile supply chain, points out that gadgets are easier to create now that there is a flood of small, battery-powered components coming out of the smartphone factories in China.\n\nThe smartphone boom is creating a flood of small, cheap, low power and yet very sophisticated components that would not have existed otherwise, or would have been much more expensive. The PC supply chain ultimately thought about components for $500-1000 boxes to go on your desk - the smartphone supply chain thinks about much smaller boxes that average $200 and go down to $30 or $40 and run on batteries. So you get smaller, cheaper, low power components, and you get all sorts of new types of sensors that a PC could never have used. These components are enabling everything from drones to wearables to connected home devices, ‘internet of things’, smart TVs and connected cars. And satellites. \n\nSo all those connected product startups on Kickstarter? Possible because they’re standing on the shoulders of Apple and Samsung.\n2.\nSquare is the mobile payment system targeted at small offline businesses like cabs, food carts, and boutiques. Last month it passed $100MM daily revenue, also noting that this kind of sales volume ranks it as the 13th largest U.S. retailer by annual sales.\nSmall businesses are where it’s at.\nI remember reading that the rise in Super Bowl ad prices is - weirdly - because TV advertising overall is getting less effective. So there’s a flight by adverting dollars towards the places that still work.\nHypothesis: The internet allows businesses to be smaller, and to operate in networks instead of growing the workforce. During this transition, some big companies drop away, and the biggest see less competition, so they’ll get bigger still.\n3.\nAt Sprint 15, @timoreilly stated the mantra of an organisation operating in a networked world: No undifferentiated heavy lifting.\ni.e. if you can’t add anything special by building your warehouse, use someone else’s.\nTim was discussing Amazon’s shift to becoming the operating system for web companies.\nFirst CEO Jeff Bezos broke the company up into parts that worked together in standard and documented ways. The memo that Bezos sent lays that out:\n\nAll teams will henceforth expose their data and functionality through service interfaces.\nTeams must communicate with each other through these interfaces.\nThere will be no other form of interprocess communication allowed […]\n\nAnd once the cells were defined, the skin of the company was shed and it became permeable to all the other businesses of the internet. The same protocol internal teams used to work together was made open to the world.\n4.\nThere’s a 2006 book by Alex Galloway, Protocol: How Control Exists After Decentralization.\nHere’s a summary.\nHere’s a review.\nOstensibly a critical analysis of the internet and how it became to be, actually:\nIn a networked world - where an organisation has no “head” but might be an ecosystem with values and habits (e.g. Silicon Valley; e.g. the smartphone supply chain) - where is control and governance?\nProtocol is the substrate on which we build a self-healing network of material, money, and ideas. Law is friction: It is seen as damage and routed around.\nBut protocol is hidden control.\nWhat polis are we building because of the preferences encoded in HTTP?\nHow do you measure the size - the value - of a network, and compare that against the large single nodes?\n",
    link: "/home/2015/02/02/consensus_cosmogony",
  },
  {
    title: "Filtered for tortoises and galaxies",
    date: "10.16, Thursday 5 Feb 2015",
    content:
      "1.\nIn Praise of the Flaneur, the stroller, the passionate wanderer emblematic of nineteenth-century French literary culture.\nSo CONSPICUOUS was the strolling, loitering, sauntering that around 1840 it was considered elegant to take a tortoise out walking.\nWhat is today’s equiv online?\nShowing off + self-occupation.\nBlogging?\n2.\nA lamp shade that opens and closes when the light is switched on and off.\n\nThe lampshade is comprised of polypropylene “petals” and six bi-metallic strips which are activated by the heat emitted by a bulb. Bi-metallic strips are a sandwich of copper and steel. When heated, the copper expands more than the steel causing the strip to bend.\n\nBy designer Mark Champkins, who is also responsible for telling me about tortoises on strings.\n3.\nMachine with Concrete (video), Arthur Ganson.\nA series of gears. The first spins at 200 RPM. The last turns one every two trillion years. Given the truth of this situation, it is possible to do anything at all with the final gear, even embed it in concrete.\nThis breaks my brain to look at. I can’t figure out where the causation goes.\nDomino Chain Reaction.\n4.\nOur solar system is part of the Milky Way galaxy, which is part of the Virgo cluster, which is part of the Laniakea supercluster which comprises 100,000 galaxies and half a million light years across.\nNames of some nearby superclusters:\n\nHydra-Centaurus\nPersus-Pisces\nComa\nSculptor\nHercules\nLeo\nOphiuchus: Forming the far wall of the Ophiuchus Void, it may be connected in a filament, with the Pavo-Indus-Telescopium Supercluster and the Hercules Supercluster.\nShapley\n\nThe universe is full of these galactic superclusters, and they do not themselves cluster – they are strung out into filaments - condensation on the stretched out chewing gum of dark matter between your shoe and the street - massive, thread-like formations, with a typical length of … 163 to 261 million light years, that form the boundaries between large voids in the universe.\nSome filaments are more like sheets, or walls. Here are some names:\n\nCfA2 Great Wall\nSloan Great Wall\nGrus Wall\nFornax Wall\nHercules-Corona Borealis Great Wall: The largest known structure in the universe.\n\nLastly:\n\nLarge quasar groups (LQGs) are some of the largest structures known. They are theorized to be protohyperclusters/proto-supercluster-complexes/galaxy filament precursors.\n\nThe Clowes-Campusano Large Quasar Group.\n\nLying at a distance of 9.5 billion light years away, the CCLQG is a cosmic decoupling of 34 individual quasars (highly luminous active galactic nuclei powered by supermassive black holes) spanning a region roughly 2 billion light-years in length, and about 1 billion light years wide, making it one of the largest and most exotic cosmic structures known in the observable universe.\n\nIt is the largest known structure in the universe from 1991 to 2011.\nBack, back, back, to:\nLaniakea. Our home. The name laniakea means “immeasurable heaven” in Hawaiian.\n",
    link: "/home/2015/02/04/filtered",
  },
  {
    title: "The best event I’ve ever attended",
    date: "17.16, Friday 6 Feb 2015",
    content:
      "I’ve been to a ton of events. Weekend campouts where, like Fight Club, everyone presents. Conferences which are a bundle of laughs with my friends I see once a year, and a massive mental accelerant. That one that James took me to in the basement under a shop that was all about magic and Plato and made me see the universe behind this one for like a month. Everyone in my world now knows how to make slides and give a talk; it used to be super raw and I loved that. Now talks aren’t an hour, they’re 18 minutes and everyone has the TED guidelines engraved on their soul: Black turtleneck and start with a personal story. Not bad, just different.\nBy the best event, I mean the one that has had the longest lasting effect on my thinking. And sure that’s mostly about the content and the time in my life, but also a ton about the format:\nNature, space, society at Tate Modern, London, ran across three successive Fridays in 2004. Each started at 2.30pm, and took the same format: a lecture for one hour - with few or zero slides - followed by 90 minutes of panel discussion and audience questions. Then: done, go home.\nThe videos of the three speakers are online:\n\nManuel DeLanda\nN. Katherine Hayles\nBruno Latour\n\nThe lectures are long by 2015 standards – the speakers were captivating.\nBut the format! There was something about the weekly rhythm which meant that there was time for me to digest each download of new thoughts. The session stayed with me for the week… and the ideas were then multiplied by the following lecture.\nOver the two weeks I was taken somewhere… somewhere not accessible in a dense day of short talks. An hour is time to explore and speculate, time for poetry. A week is time to discuss with friends, contemplate, see the deeper patterns. The repetition pumps the swing. But only three talks: Not a lengthy course, contained enough that it’s still a single event.\nAnd - honestly - Friday afternoons are a good time to take away from work. No getting distracted and anxious about email.\nSo over a decade later I look back, and I realise that these thinkers have guided me. Change happened in me.\nIf I was putting on an event now, this is what I’d want to do.\n",
    link: "/home/2015/02/05/filtered",
  },
  {
    title: "Filtered for TIL",
    date: "18.54, Monday 9 Feb 2015",
    content:
      "1.\nA lot of prime numbers aren’t prime if you allow for imaginary numbers.\ne.g., 13 can be factored as 2+3i x 2-3i.\nIt turns out that this can happen to a prime if and only if after dividing by 4, we get remainder 1. So 5, 13, 17, 29… can all be factored if we add sqrt(-1), but 3, 7, 11, 19, 23… won’t.\nAlso, balanced ternary notation, which is counting in base-3, except the numbers are 1, 0, and -1.\n\nThe best-known application of balanced ternary notation is in mathematical puzzles that have to do with weighing. Given a two-pan balance, you are asked to weigh a coin known to have some integral weight between 1 gram and 40 grams. How many measuring weights do you need? A hasty answer would be six weights of 1, 2, 4, 8, 16 and 32 grams. If the coin must go in one pan and all the measuring weights in the other, you can’t do better than such a powers-of-2 solution. If the weights can go in either pan, however, there’s a ternary trick that works with just four weights: 1, 3, 9 and 27 grams. For instance, a coin of 35 grams-110(-1) in signed ternary-will balance on the scale when weights of 27 grams and 9 grams are placed in the pan opposite the coin and a weight of 1 gram lies in the same pan as the coin. Every coin up to 40 grams can be weighed in this way. (So can all helium balloons weighing no less than -40 grams.)\n\nHead broke.\n2.\nHabeas corpus… ancient right to not be imprisoned except if lawfully tried.\nHabeas Corpus Act 1679, one of the most important statutes in English constitutional history. Though amended, it remains on the statute book to this day.\nIt only passed the House of Lords because one of the tellers joked that a fat lord counted as ten, and the other teller didn’t notice.\n\nLord Grey and Lord Norris were named to be the tellers: Lord Norris, being a man subject to vapours, was not at all times attentive to what he was doing: so, a very fat lord coming in, Lord Grey counted him as ten, as a jest at first: but seeing Lord Norris had not observed it, he went on with this misreckoning of ten: so it was reported that they that were for the Bill were in the majority, though indeed it went for the other side: and by this means the Bill passed.\n\nFrom r/todayilearned\nIncidentally, I like this exclamation people have nowadays, TIL, today I learned. It’s a way of passing on something that might be of curiosity, hey, TIL, [this], or a response to something surprising, well well well, TIL!\n3.\nPhotos of loads of control panels.\nI was at a big model railway exhibition a couple of years ago, which is not a hugely regular occurrence for me. But interesting, yknow. Anyway, I got pretty into looking at the control panels for the layouts. Because the model makers would ad hoc together these sheets of wood with tracks drawn on them, lovely toggle switches for the points, big fat lights for the signals, etc, etc. All custom.\nAnd I was in this massive crowd looking at this spectacular model of Liverpool Lime Street (1948), leaning over with my camera to take a picture of the control panel - which is actually in that video by the way, about 5:30 in - and behind me, one guy sees me and says to the guy next to him, “pshaw, it’s one of those control panel nerds.”\nAnd then I was all: who are YOU calling a nerd you NERD, you’re the one at a railway modelling exhibition.\nNote it’s called railway modelling, not model railways, because I don’t know why but it’s very important.\nBut actually I didn’t say anything because I AM a control panel nerd, really, in a casual sort of way, and he got me good. Nerd.\n4.\nEnglish words for mental health don’t translate.\n\nthere’s no direct translation for the word “depression” in the Cambodian Khmer language. Instead, people may say thelea tdeuk ceut, which literally means “the water in my heart has fallen.”\n\nAnd then,\n\nHinton may suggest an antidepressant that will “increase the water in the heart, so it will be like the rice fields after a storm.”\n\nBodies as land. With highlands and lowlands, and crops and weather.\n",
    link: "/home/2015/02/06/events",
  },
  {
    title: "Filtered for Muybridge and Moorcock",
    date: "10.19, Thursday 12 Feb 2015",
    content:
      "1.\nOld school smart home:\n\nYour microwave just heated a lasagna.\nRecord: You just stared out of the window for 23 minutes. [Ok] [post your score]\nYour couch likes your microwave’s status update.\nIt’s raining again. [Ok]\n\nAlso, not the same, but: Ranjit Bhatnagar says I plugged a little light sensor into an amplifier to hear invisible light modulation. One of my LED candles had a surprise. Watch the video, it plays a little tune.\nSallie Gardner at a Gallop is a series of photographs consisting of a galloping horse, the result of a photographic experiment by Eadweard Muybridge on June 15, 1878.\nBecause:\n\nThe purpose of the shoot was to determine whether a galloping horse ever lifts all four feet completely off the ground during the gait; at this speed, the human eye cannot break down the action.\n\nMuybridge used his photographic technique like a microscope on time – to see motion previously too quick to catch.\nEverything speaks.\n2.\nMichael Moorcock: How to write an adventure model in three days.\nFormula, structure, using what’s on hand: Really, it’s just looking around the room, looking at ordinary objects and turning them into what you need. A mirror: a mirror that absorbs the souls of the damned.\nMoorcock is a legend.\n3.\nDo Things That Don’t Scale, by Paul Graham.\n\nActually startups take off because the founders make them take off. There may be a handful that just grew by themselves, but usually it takes some sort of push to get them going. A good metaphor would be the cranks that car engines had before they got electric starters. Once the engine was going, it would keep going, but there was a separate and laborious process to get it going.\n\nGreat article.\nThe startup worldview. I mean: it’s effective at newness, yes, and I am pro progress. The underlying value resonates with me: The world is a do-ocracy and you can make your stamp by doing. That wasn’t always the case, authority-by-history has been dominant for so long.\nBUT (a) what can’t be reached by this worldview? A whole bunch, probably. But actually I think it would be productive to point startups at a much wider variety of problems. Case in point, Bethnal Green Ventures and “tech for good.”\nBUT (b). The mode of coordination of all these small enterprises is to share a language and share a way of being in the world. It can feel a bit paint-by-numbers sometimes, and that’s fine… except that worldviews are like the Catholic church in medieval Europe, and Silicon Valley is our Rome.\nA double-edged sword, if your native culture is not Roman.\nThen I remember Moorcock, who painted by numbers, but truly was a fucking legend for all time, who wrote books you can inhale and - by force of will and a community of like-minded geniuses - created a new and truly British science fiction, one that changed everything.\n4.\nA few weeks ago, I got the “call for talks” email from OpenTech 2015 – it’s in June, it’s the 10th edition.\nThe email said: The main thing we’re looking for are the things we don’t know to look for.\nAnd then they linked to Phil Gyford’s list, trying to imagine a tech conference that would embody an alternative viewpoint.\n\nDifferent models for start-ups. Co-operatives. Employee ownership. Normal, slowly-growing, profit-making businesses.\nRuricomp - technology for people who don’t live in cities.\n\nMakes me think: My notes on City Link and a new class of worker.\nMakes me think: indie.vc, A program, network and funding mechanism for founders looking to start and scale independent businesses with positive cash flow. A different kind of deal.\nA note\nI started writing these “filtered” posts because of Michael Sippey:\n\nI used to blog; I haven’t in a while. I miss it. So this is trying something new, without the daily pressure of a capital B Blog, or the content pressure of a the capital E Essay. Start a new draft post on Monday, dump things in it over the week, rewrite and cull along the way, what’s left gets published on Friday. Let’s see how long I keep this up.\n\nSo that’s what got me going, because I was having difficulty finding my voice. Then there’s Nat’s four short links which he does daily.\nBut let’s be clear… this is all about me: What I get out of this is that somehow, by typing, four unrelated things that have caught my eye sometimes show signs of coherence. I get glimpses of the gestalt. So that’s why I type.\n",
    link: "/home/2015/02/09/filtered",
  },
  {
    title: "Filtered for relationships",
    date: "15.41, Sunday 15 Feb 2015",
    content:
      "1.\nThe Guardian’s Watch Me Date.\n\nEach week, we’ve chosen two different people, given them two pairs of Google Glass and packed them off on a date (there is usually a lot of alcohol involved too). Filming begins the minute they meet, and that off-button is only pressed once they’ve said goodbye.\n\n2.\nHow to lose weight in 4 easy steps via @kottke who says  Step 3 is difficult but really works.\n3.\nThis quote: You are the average of the five people you spend the most time with.\nNormalisation and caring. Obesity… people are 57 percent more likely to be overweight if they had a friend who became obese. And:\n\nIf John thought that Steve was his best friend and John gained weight, Steve would gain weight too. But if John didn’t think Steve was his best friend (just a friend), John was less likely to gain weight if Steve gained weight. It seems, the more you feel connected to someone else the more his or her behaviors affect you.\n\n4.\nInvisible Boyfriend gives you real-world and social proof that you’re in a relationship - even if you’re not - so you can get back to living life on your own terms.\nIn beta at $24.99/month.\nThe back-end is interesting. Your non-existent virtual partner is a swarm of fractional micro-boyfriends. Deets:\n\nThe service’s texting operation is powered by CrowdSource, a St. Louis-based tech company that manages 200,000 remote, microtask-focused workers. When I send a text to the Ryan number saved in my phone, the message routes through Invisible Boyfriend, where it’s anonymized and assigned to some Amazon Turk or Fivrr freelancer. He (or she) gets a couple of cents to respond. […] “That rapport you feel with Ryan may actually be six or seven Ryans,” Homann explains.\n\n",
    link: "/home/2015/02/12/filtered",
  },
  {
    title: "Parish notices",
    date: "10.00, Monday 16 Feb 2015",
    content:
      "No coffee morning this week… busy busy busy. I’m Entrepreneur in Residence at Techstars London, and the Winter 2014 cohort is gearing up for its Demo Day on Friday. It’s a cross between a massive pitch (several hundred investors will be there) and a debutante ball. So all the startups are doing a ton of prep - they get 5 minutes each - I’m helping out where I can.\nNext coffee morning (what it is) will be next Thurs, Feb 26.\nGet this blog by email\nLooking at my stats, more people click through from Dan Hon’s email newsletter than any of the (high profile!) blogs or Twitter accounts that have also linked here from time to time.\nIt’s pretty clear that mobile browsing is broken for idle reading and following trails, and that - for the moment at least - people enjoy email instead.\nSo I’ve set up Interconnected-by-email. Subscribe here to get the latest posts in your inbox. Dispatches made at 11pm London time.\n",
    link: "/home/2015/02/15/filtered",
  },
  {
    title: "Filtered for SAAS",
    date: "10.01, Tuesday 17 Feb 2015",
    content:
      "1.\nSAAS = Software as a Service. History. Common biz model now: Software is no longer sold like retail, it’s sold like subscriptions.\nA good rule of thumb for SAAS startups: the 40% rule. Your annual revenue growth rate + your operating margin should equal 40%\n\nSo, if you are growing 100% year over year, you can lose money at a rate of 60% of your revenues\nIf you are growing 40% year over year, you should be breaking even\n\nThe idea being that it makes sense to spend money for growth.\nIt wasn’t always accepted that you could charge money for software. Bill Gates cemented the idea of software=property in his 1976 Open Letter to Hobbyists. Jim Warren’s response that same year:\n\nThere is a viable alternative to the problems raised by Bill Gates in his irate letter to computer hobbyists concerning “ripping off” software. When software is free, or so inexpensive that it’s easier to pay for it than to duplicate it, then it won’t be “stolen”.\n\nSAAS shows a viable alternative to that viable alternative: You don’t need to cut prices. You make duplication impossible (you don’t ship source code when you host the servers) and distribution trivial (just punch in your credit card).\n2.\nGetting going as a SAAS company is tough. Getting the first few clients is scrappy, especially because their expectations aren’t yet set. Formal work orders help nail this down.\nThe Y Combinator Sales Template Agreement is excellent – the first page is a box-filling exercise which helps you think about what you’re selling. Service fees, initial term, one-off implementation fee, pilot limitations.\nAfter the scrappy stage: what product/market fit looks like for SAAS.\nIt’s something like $100k MRR (monthly recurring revenue) and 10% month-on-month growth.\nBefore that, Do not pour on the gas at this point.\nI’m trying to remember who described Series A financing to me like this… they said: You’re Series A ready when you’ve found a lever that costs you one quid to pull and when you pull it, two quid drops out.\nThat’s when you pour on the gas!\nThe lever is product/market fit. You’ve discovered the product, you’ve found who wants it, and you’ve got the sales machine to sell it.\n3.\nSystematizing Sales With Software And Processes: How to move upmarket from a low-touch sales SaaS into a more rigorous sales process, without losing your sanity.\nFantastic insights; great resource. Medium touch.\nLightweight tools to run a sales pipeline include Close.io and Pipedrive.\nFor low-touch or a more B2C model, a good user growth pipeline is: Acquisition, Activation, Retention, Referral, Revenue.\nComprehensive resource on how to use emails for user growth.\nMore about that growth pipeline aka the pirate metrics, because the acronym is AARRR.\n4.\nSo I’m thinking about SAAS for three reasons.\n\nI didn’t do this well myself, and I didn’t know what I didn’t know. I know the consultancy model inside-out, but how a SAAS startup works? I was all at sea.\nI know a bunch of super early SAAS startups now, and this is what the world will look like when they scale up. Given that, it’s possible to make some decisions: e.g. keep the early sales pipeline short so it’s easier to iterate the process automation.\nI’m particularly interested in hardware startups, and just as SAAS was a step beyond the retail model for software, maybe there’s a recurring revenue model for hardware.\n\nOn that last point, I know the team at Winnow. Winnow is working with kitchens small and large to tackle food waste.\nIt’s a web-connected weigh-scale that sits under the bin in commercial kitchens, and a subscription to their service that has led to waste reductions of 30% to 70% by value. Easy ROI for customers.\nHardware + recurring revenue. Neat.\nSee also: In the smart home, SmartThings is introducing a premium subscription service. Samsung says the service will enable SmartThings to automatically send users or other contacts a text when it detects a problem in the house, such as a flood or fire.\nIt’s necessary…\nReid Hoffman (founder of LinkedIn) says:\n\na really great idea ends up with three innovations – product service, product distribution, and revenue model\n\nLinkedIn was a product service innovation. But it also innovated in distribution: Users invited their contacts, so it traversed the social networks and spread without ad spend. And revenue, LinkedIn made freemium work.\nIn the hardware world, I see a ton of great products from startups. BUT:\nEveryone’s still experimenting with revenue… 30% product margin won’t cut it, and that’s why Winnow is interesting. And distribution hasn’t been cracked: Physical stuff has such a tough challenge with virality compared with, say, apps… it’s hard to hear about and hard to buy. Still looking for good examples of hardware startups innovating there.\nWhat’s the SAAS flip for hardware?\n",
    link: "/home/2015/02/16/notices",
  },
  {
    title: "Birthdays",
    date: "08.49, Wednesday 18 Feb 2015",
    content:
      "One of my earliest memories is my 4th birthday, or at least I’d always thought so till about 5 minutes ago. I used to remember it vividly: We’d moved into the new family house just about a month before, we’re in the room with the heavy wooden furniture, my cake is on the big wood table and I blow the candles out. Now I can remember once having the vivid memory, but somewhere along the line the direct memory has faded.\nBut did we have furniture only a few weeks after moving in? It was imported, I know that much – there’s a story about the van carrying the cabinets and chairs and whatnot, charging off the ferry onto the land in a storm, catching the instant where the ramp is touching the jetty. So the timing doesn’t add up for me. Maybe it was my fifth birthday or my sixth.\nIt’s a happy memory, that birthday - my 4th or 5th or 6th - because I remember being delighted, and my family are there, and (maybe?) I was being picked up to blow out the candles, and (even more maybe?) my nan was there – I mean, seriously, who knows.\nSo I carry all these different types of memories all bundled up: vivid ones, emotional impressions that anchor me to family, ones that might be literally true and others that are at least true in spirit, stories about ferries that I was never there for but none-the-less there they are, memories of memories. Things that happened yesterday, this morning, ten years ago, when I was ten, a memory - maybe - and I’m reaching here - a shock-wave backwards in time of what I’ll do in 10 minutes, 10 weeks, 10 years: again, maybe true, maybe only true in spirit. All part of me.\nI find that a hopeful picture, because it gives the idea of “memory” a broad reach, and I get to include the memories and stories that probably started elsewhere: my family, my friends, my pets, my books; all together, more or less, all alive, to a greater or lesser extent, in me.\nHere’s me as a little boy.\nThat’s my school t-shirt, my guess is we’re in Kenya – so I must be 6? Do I look 6? We went to Kenya when I was 6. I’m wearing my dad’s expression, which is lovely to see.\n37 today!\nOnce more around the sun, though not closing loops because the sun itself moves. So we carve a helix on the cosmos. Lives, screwed into spacetime.\n",
    link: "/home/2015/02/17/filtered",
  },
  {
    title: "Coffee morning six",
    date: "18.51, Thursday 19 Feb 2015",
    content:
      "Hey, let’s have another hardware-ish coffee morning!\nThursday 26th February, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nDo come! Usual game… zero structure, just a few like-minded people having coffee with a vague “making things” skew. There might be two of us, there might be ten. Probably somewhere in-between.\nI think, if we’re lucky, that one person who’s going to come will bring their as-yet unreleased hardware prototype. That’s what they’ve promised me anyhow.\nAll welcome, it would be lovely to see you :)\n(For a reminder, join the coffee morning announce list.)\n",
    link: "/home/2015/02/18/birthdays",
  },
  {
    title: "Filtered for listening",
    date: "17.49, Monday 23 Feb 2015",
    content:
      "1.\nArtificial skylight that uses the same physics behind the sky being blue to create a blue sky.\nComes in a variety of models e.g. For enthusiasts of Nordic countries, CoeLux 30 is available, with a 30 degree angle beam relative to the horizon. It is a wall window and is capable of reproducing a warm, grazing light.\n2.\nArchaeoacoustics, including this playful idea:\n\n[A] trowel, like any flat plate, must vibrate in response to sound: thus, drawn over the wet surface by the singing plasterer, it must emboss a gramophone-type recording of his song in the plaster. Once the surface is dry, it may be played back.\n\nNot true, but fun to believe this: He claimed to have extracted … the word “blue” from an analysis of patch of blue color in a painting.\nAlso, reproducing the sound of drums in Stonehenge.\nAlso, extracting sounds from pictures of gramophone records in books.\nAlso, the ghost between the original recording of Suzanne Vega and an MP3.\n3.\nSci-fi books upcoming for 2015.\n\nSeveneves by Neal Stephenson (May): The world is ending, and the human race makes a desperate effort to get some survivors off the planet. Five thousand years later, the descendants of humanity are divided into seven different races, all of which decide to pay a visit to the old homeworld.\nAurora by Kim Stanley Robinson (July): A generation ship novel! Robinson returns to the future after a sojourn in the distant past, and tells the story of the first ever arduous journey to another solar system.\n\n4.\nIn the Qur’an, Solomon understands the language of the ants.\n\nUntil, when they came upon the valley of the ants, an ant said, “O ants, enter your dwellings that you not be crushed by Solomon and his soldiers while they perceive not.”\nSo [Solomon] smiled, amused at her speech, and said […]\n\n",
    link: "/home/2015/02/19/coffee_morning_6",
  },
  {
    title: "Filtered for myths and archetypes",
    date: "17.48, Tuesday 24 Feb 2015",
    content:
      "1.\nMore on archaeoacoustics:\n\nCurrently, Russian and Finnish researchers are studying “palaeoacoustic” ringing rock sites on the shores of Lake Onega in Russia. They have found that the sound these natural stone “drums” make when struck is amplified by the surface of the lake, causing it to carry for kilometres around. The features are surrounded by concentrations of rock art.\n\nSo what gets me here is that the marks - the visual human intervention - the art - is a sign that there is something here that we can’t see: In this case, a natural megaphone for rhythm.\nFrom the same article:\n\nThe Native American tribes of the Great Lake region believed that a spirit world existed behind rock surfaces, which were conceived of as being like “membranes” between that world and this. … their shamans could penetrate through cracks and crevices in the rock-face into the spirit world beyond, and also that spirits could pass through from behind it into the human world.\n\n2.\nSipapu is a Hopi word which refers to a small hole or indentation in the floor of kivas used by the ancient Pueblo peoples and modern-day Puebloans. It symbolizes the portal through which their ancient ancestors first emerged to enter the present world.\nI saw these when I visited Mesa Verde a year or two back… funny having grown up in the west and seeing crucifixes everywhere as the dominant symbol: also the x-y axes of Cartesian space, that in the west we measure and situate our [world, values, selves] inside a shared and objective universe; also in Riddley Walker the Christ figure is conflated with Adam-the-first-man and Atom-which-is-split, arms out wide, being torn apart. Then to see an alternative symbol, an indentation, sipapu.\nFor the ancient Pueblo peoples, the sipapu - the place of emergence - is somewhere near the Grand Canyon: their ancestors emerged from the Third World through a crack, into this, the Fourth World, in a place known as Sipapu.\n3.\nTales from Ovid: 24 Passages from the Metamorphoses, the magical translation by Ted Hughes.\nI mean, read this.\n\nLast comes the Age of Iron.\nAnd the day of Evil dawns.\nModesty,\nLoyalty,\nTruth,\nGo up like a mist - a morning sigh off a graveyard.  \nSnares, tricks, plots come hurrying\nOut of their dens in the atom.\nViolence is an extrapolation\nOf the cutting edge\nInto the orbit of the smile.\nNow comes the love of gain - a new god\nMade out of the shadow\nOf all the others. A god who peers\nGrinning from the roots of the eye-teeth.  \nNow sails bulged and the cordage cracked\nIn winds that still bewildered the pilots.\nAnd the long trucks of trees\nThat had never shifted in their lives\nFrom some mountain fastness\nLeapt in their coffins\nFrom wavetop to wavetop,\nThem out over the rim of the unknown.\n\nWow.\nIn Our Time episode on Metamorphosis.\nNow I am ready to tell how bodies are changed/ Into different bodies.\n4.\nLey lines and associated topics.\n\nBut why straight lines? Dobkin de Rios suspected that they derived from the entoptic patterning that occurs in the human cortex early in trance states as a result of poorly-understood neurophysiological mechanisms. These entoptic (“within vision”) images are universal to the whole human race in all periods of time, and adhere to a specific range of “form constants” - grids, dots, webs, spirals and tunnel forms, arabesques, nested curves, lines, and so on.\n\nAnd from Michael Witzel’s origins and dispersal of our first mythologies,\n\nArchetypes are those psychic contents that have not yet been submitted to conscious elaboration. Myth is the secondary elaboration of archetypes. Their images are embedded in a comprehensive system of thought that ascribes an order to the world. Common archetypes include the (great) Mother, the Father, the Hero, the Miraculous Child, the Wise woman, the Shadow. Since they are generally human, they can turn up everywhere and anytime in dreams, visions and myths.\n\nThis Laurasian approach suggests that there is a coherent mythology (with a common story line) for much of Eurasia, North Africa and the Americas.\nEncompassing:\n\nthe ultimate of origins of the universe and the world, subsequent generations of the gods, an age of semi-divine heroes, the emergence of humans, and the origins of “royal” lineages.  It frequently includes a violent end to our present world, sometimes with the hope for a new world emerging out of the ashes. Ultimately, the universe is seen as a living body, in analogy to the human one: it is born from primordial incest, grows, develops, comes of age, and has to undergo decay and death\n\nSo. Yeah.\n",
    link: "/home/2015/02/23/filtered",
  },
  {
    title: "Coffee morning 6",
    date: "20.33, Thursday 26 Feb 2015",
    content:
      "Hardware-ish coffee morning was awesome today! Thank you for coming this HUGE CROWD of people: Tom T, Kirsty, Daniel, Gavin, Karey, Siri, Anna, Maximilian, Oliver, Sam, Tom W, Basil, Utku, Grace, Matt C-W, Aly, Mark, Mike, Reetta, Alex and Ben.\nHere’s a photo.\nLots of prototypes too… Fedelis which is like a physical key for smartphone touch screens, Radio Music which is a sample player that performs like an old-school radio, Ben’s flood sensor for the Oxford Flood Network which is 1/100th the cost of existing ways of doing river sensing, and a sneak preview of Fabulous Beasts which is Alex’s new game.\nPhew! /breathes out\nI had about a trillion conversations; my notebook is a blimmin mess.\nMark asked why are people interested in hardware at all? which I thought showed a certain casualness with tact given the gathering and besides, the hardware company he himself started is now eight years old and he’s done a ton more too. Anyway, Marc Andreessen’s essay Why Software Is Eating The World is probably a decent starting point on that topic, with Internet of Things technologies making much of the physical world tractable to the same software-based transformation. Grace said that maybe it didn’t matter why, just the itch that founders have to chase hardware down is enough to make it interesting and worthwhile.\nThen a good chat with Grace on the usual challenge: Any hardware company has to lock up a bunch of capital between the factory and the consumer’s hands… inventory on shop shelves, stock, parts, pre-orders, factory tooling… and a startup has to pump prime that pipeline with cash. Working capital is a poor use of equity financing. Kickstarter’s pretty good, but my feeling is that you should cut margin to the bone with crowdfunding: Using Kickstarter to build a buying community is infinitely more valuable. So are there other pump priming financing options? Don’t know. Would like to think of some.\nOddest chat of the morning:\nKarey revealed that the portfolio on her website offers Party Mode. Click the button at the bottom of the page, and mouse over the various projects – the page becomes an instrument, it’s like a synth! And then, I swear I heard this right, when you use Party Mode, there’s an Arduino in her studio that plays the music.\nALL OF WHICH LED US TO the idea that all websites should have their live stats played like ambient electronica in offices. And that somehow got recorded in my notes as what if Brian Eno cosplayed Google Analytics.\nSo.\nOh yes, congratulations to Karey who is starting a new job with an Internet of Things company next week, bringing her funemployment to an end. And congratulations also to Sam who has just started with Little Riot who make Pillow Talk.\nNext time\nCoffee morning 7 will (probably) be three weeks from now, Thursday 19 March.\nJoin the coffee morning announce list for a reminder.\nThanks for coming everyone! Super good.\n",
    link: "/home/2015/02/24/filtered",
  },
  {
    title: "Books read February 2015",
    date: "18.15, Friday 27 Feb 2015",
    content:
      "By date finished…\n\nThe Stars My Destination, Alfred Bester (7th)\nThe Sacred Bee in Ancient Times and Folklore, Hilda M. Ransome (14th)\nBreakfast at Tiffany’s, Truman Capote (15th)\nUtopia, Thomas More (21st)\n\nSomewhere in Bee (originally published 1937) I finally twigged that, for thousands upon thousands of years in the west, bees were the source of sweetness (no beet or sugar cane in Europe); booze because mead is made from honey and was invented before beer; and, using wax, candles.\nBees: Tasty food, entertainment, artificial light. That’s quite a technology.\nIn German, animals “devour” (fressen) food, and they “perish” (crepien). Except for humans and bees, who instead eat (essen) and die (sterben).\nAnd this: [the bee] is the only creature that has come to us unchanged from Paradise.\n",
    link: "/home/2015/02/26/coffee_morning",
  },
  {
    title: "Filtered for automatic crows",
    date: "09.03, Tuesday 3 Mar 2015",
    content:
      "1.\nCrow Machine.\nThe goal of this project is to create a device that will autonomously train crows.\n\nOnce we’ve got system down for teaching coin collection we’ll move to seeing how flexibly they can learn other tasks, like collecting garbage, sorting through discarded electronics, or maybe even search and rescue.\n\nThe thing that gets me about this is that it’s automatic.\n2.\nBruce Sterling on the Convergence of Humans and Machines.\nOr not.\nYou never see a computer that is so young it cannot speak.\n3.\nVarious translations of the first sentence of Franz Kafka’s The Metamorphosis.\n\nOne morning, when Gregor Samsa woke from troubled dreams, he found himself transformed into a horrible vermin.\nWhen Gregor Samsa awoke one morning from troubled dreams, he found himself changed into an monstrous cockroach in his bed.\n\nPoor Gregor.\n4.\nJustin Long has automated Tinder using facial recognition.\n\nusing the facial recognition algorithm Eigenfaces I built a bot that learns when to swipe right (like a person) AND swipe left (dislike a person) AND start your conversations.\n\nStarting the conversation:\n\nTinderbox’s pre-programmed chats include the opening:\n“{name} are you a fan of avocados?”\nAnd, following a positive reply:\n“So if I asked you to have a guacamole party with me you’d do it?”\nOnly after all this does Tinderbox notify its human taskmaster that there’s a match ready to chat.\n\nTurns out Tinderbots are quite a thing. Here’s something not real.\n\nAt 09:07 in the morning an Uber is automatically called for the female and 3 days later she will receive a heartfelt e-card / receipt. The algorithm will also wish her happy birthday on Facebook and like the top 20% of her Instagram photos as they are posted and start getting a lot of other likes. This continues until her Facebook relationship status switches away from single.\n\nI wonder if you could automate a crow to Tinder for you.\n",
    link: "/home/2015/02/27/books_read",
  },
  {
    title: "How to swap Amazon gift cards for cash?",
    date: "18.34, Tuesday 3 Mar 2015",
    content:
      "So for one reason or another, I have several hundred dollars of Amazon.com gift cards. Accumulated over the past few years. The thing is, I don’t buy anything from Amazon.com because I live in the UK, and the gift cards aren’t transferrable between stores.\nBut now I’d like to get the cash equivalent. Somehow. There’s something I’d like to buy from a US shop which has about the same value; it’s not on Amazon.\nI’ve never redeemed the gift codes, so it’s easy to send them to someone who can use them. They’re all still valid. Online gift card exchange sites are US-only, and expensive. Maybe I can find a person could buy from the other shop for me? But that’s a big exercise in trust, so I guess I could take a dollar-sterling transaction forex hit. But even then, how will I even find someone who buys that much from Amazon.\nDunno. Any ideas? Any friends able to help?\n",
    link: "/home/2015/03/03/filtered",
  },
  {
    title: "Filtered for change",
    date: "12.38, Tuesday 10 Mar 2015",
    content:
      "1.\nWho will babysit my sourdough starter?\nDoes yeast count as domesticated? Or is it more like un-manmade nanotech?\nWe pour yeast on something, and it acts as a mutagen on sugars to CO2, carefully killing itself off afterwards. It is impenetrable: no user-servicable parts inside. It is a component, like a resistor from a factory. But it can be bred: the system that produces it can be induced to change the produced population. With yeast we would use selection; with resistors we would use market forces. And then it operates, below human scale, to affect at human scales. Sounds like nanotech to me, though it has been captured and not created. More like finding an alien technology from a crashed flying saucer. Roswell, but 6,000 years ago.\nA switchable light-input, light-output system modelled and constructed in yeast.\n2.\nThe UK has become a four-party country… between Labour, the Conservative, the Lib Dems and the Scottish National Party, the General Election in May throws up all kinds of interesting configurations for the House of Commons.\nElectoral Calculus has a coalition scenario map. Lovely, complicated fracturing. Neat graphical representation.\nThere’s a 50% chance of a hung parliament; negotiations should be fascinating.\n3.\nLook up at the Moon… hold out your arm, the Moon is about one finger across. From the Moon, the Earth is bigger: about four fingers across.\nAnd it looks pretty strange.\n\nIf you were standing on the Moon, looking up, you’d see the Earth, hanging in the sky forever\n\nThe Moon is tidally locked to the Earth, the near side always faces us.\n\nIt would go through phases, like the Moon, moving from total darkness, though quarter illumination, Full Earth, and back again. But the features on the Earth would be changing. The face of the Earth would be illuminated, and you’d see the entire planet turning throughout the day\n\n4.\nFeudal transformations and the spread of the three field system.\n\nover the eighth to tenth centuries the system of using three fields in rotation, one for sowing a winter crop to be harvested in spring, one for a summer crop to be harvested in the autumn and one lying fallow to get the next winter crop, became fairly widely established, whereas it had been largely missing before that.\n\nBut why? This series on feudal transformations looks like a fascinating exploration in what causation is, and how to see it.\n",
    link: "/home/2015/03/03/amazon",
  },
  {
    title: "A Richter scale for outages",
    date: "10.07, Thursday 12 Mar 2015",
    content:
      "I tweeted this morning:\n\nIncreasing reliance on invisible centralised software. Recent Apple outage, recent HSBC/contactless/tube outage. How long before a big one?\n\nAnd I guess what I mean is that we’re all using these same software systems. And they interact in ways that are totally emergent. So they go down in unpredictable ways. I feel like these systems are not resilient… for example, the credit card system is less resilient than a distributed payment system like cash.\nIt got brought to my attention because for, about a day, I couldn’t use my HSBC contactless card on London tubes or buses – who knows why. I had to top up my separate Oyster card, and it ended up costing me a couple quid more that day. Then, yesterday, several of Apple’s systems were down for about 12 hours: Main effect for me, I couldn’t listen to any music in iTunes. Nothing major.\nBut as software eats the world,and as the Internet of Things brings more of the physical world into that same domain, I think it would be helpful to have a language to talk about this.\nSo I made some notes on the bus.\nA Richter scale for system outage\nLike the Richter magnitude scale, each magnitude is incrementally ten times bigger. So 4.0 is 100x bigger than 2.0. But like apparent magnitude it’s subjective: The scale of the human effect is taken into account.\nHere’s what I reckon the scale might look like.\n\n\nLess than 2.0. Not distinguishable from normal network noise, like a call dropping, webpage not loading, or a computer crash.\n\n\n2.0. Facebook down, Gmail down, Apple App Store down, HSBC contactless cards not working on London transport. Duration of shorter than a day. Underlying problem is probably a single component and lack of resilience (e.g. power outage at a single cloud hosting location). Fixable.\n\n\n4.0. Minor network freeze but can be recovered with a reboot; broad human inconvenience without threat. e.g. regional ATM network down for a day, cellular network down for a day for single operator.\n\n\n6.0. Collapse of minor network requiring rebuild. e.g. recent Sony hack that meant no computers, printers, or existing network infrastructure could be re-used without manual check of each item.\n\n\n8.0. Major network freeze, can be recovered with time or reboot; major human impact. Examples include the 2008 credit crunch where bank lending gridlock precipitated the global financial crisis; power network outage major enough to require black start; the Icelandic volcano that grounded European flights for 6.5 days.\n\n\n10.0. Major network collapse, global and unrepairable. e.g. Cascading, emergent fault that wipes Internet routers and shuts down power grids, traffic and logistics, internet and non-cash payment. Can only be fixed by re-programming and re-architecting all separate components.\n\n\nSo the questions this makes me asks…\nIs there a more objective way to measure system outage magnitude? Can we also measure resilience, with a language that cuts across different systems? Is there an equivalent scale for non-software system outages, like would Gulf Stream switch-off be a 8.0? Are we really going to see more software-related black swans over the coming decades?\nHow long before the big one?\n",
    link: "/home/2015/03/10/filtered",
  },
  {
    title: "Let’s do coffee morning 7",
    date: "14.33, Friday 13 Mar 2015",
    content:
      "My dearest droogs,\nLast hardware-ish coffee morning was a ton of fun, let’s have another!\nThursday 19th March, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nDo come! Usual game… no structure, just hanging out and chatting, vague “making things” skew. Here’s what coffee morning 6 was like.\nSee if you can bunk off work, it might be fun. Or it might just be three of us checking our phones and full of painfully awkward silences. THAT’S THE RISK YOU TAKE WHEN WE HANG OUT.\nAlso – do feel free to pass this along to friends: Especially women. One of the first coffee mornings was me with a bunch of dudes. And I was sitting there, seven dudes all drinking coffee together of a Thursday morning, and it was pretty darn weird tbh. So last time was much closer to a normal mix, and I’d much prefer it if that continues.\nIt would be lovely to see you :)\nSincerely yours,\nMatt\nps. for reminders, join the coffee morning announce list.\n",
    link: "/home/2015/03/12/richter_scale_for_outages",
  },
  {
    title: "Filtered for capital",
    date: "08.35, Wednesday 18 Mar 2015",
    content:
      "1.\nAn Investor’s Guide to Hardware Startups. Super good, and long… one bit I’ll pick out:\n\nProduction cycles take time, usually 8-12 weeks. And if a company runs out of stock in between two batches, it can’t ship, so it can’t sell. The only way around it is to increase batch size. So instead of 3,000 units, the company needs to produce 15,000 of them at one time. And that takes working capital, which you, as an investor, need to provide in the initial phases.\n\nWorking capital, working capital, working capital. Working capital is a terrible use of equity financing.\n\nThe best model to take care of working capital is that investors invest into the first batch and immediately help the company get a working capital credit line from a bank. It makes little sense to finance additional batches with equity.\n\nIt’s important to get a credit line because growing organically isn’t possible – even if half your sell-in price is margin, you can only afford to grow your batch size at 50% per cycle… and whether it’s credit or re-investing the margin, all that growth incurs risk, because the items aren’t pre-sold.\nThere are double binds all over the place here. For the first batch, Kickstarter makes sense… but Kickstarter is infinitely more valuable as a buying community, so you cut margins to the bone. Which means there’s no possibility of re-investing for growing future batches. And in any case, growing batches incurs risk, which means your company has internally misaligned interests.\nThe only way I can see cutting this knot is to have a supply chain which is inside the distribution window: Where it’s possible to receive a cash order and supply it, all before the consumer gets bored and walks away.\nThe two other problems where physical units are required should be figured out and costed separately: The additional cost and risk to meet the need for immediate gratification; the marketing benefits of seeing and touching items on a shop shelf.\n2.\nCory Doctorow explains Ronald Coase.\nEver since I encountered Coase I’ve been seeing everything through a Coase lens.\nCory:\n\nOrganizing is a kind of tax on human activity. For every minute you spend doing stuff, you have to spend a few seconds making sure that you’re not getting ahead or behind or to one side of the other people you’re doing stuff with. The seconds you tithe to an organization is the CoaseCost, the tax on your work that you pay for the fact that we’re human beings and not ants or bees or some other species that manages to all march in unison by sheer instinct.\n\nCracking.\n3.\nLabyrinth by Mark Wallinger. Art across the capital.\n\nWallinger has created 270 individual artworks, one for each station on the network, each one bearing its own unique circular labyrinth, but with a graphic language common to all. Rendered in bold black, white and red graphics, the artworks are produced in vitreous enamel, a material used for signs throughout London Underground, including the Tube’s roundel logo, whose circular nature the labyrinth design also echoes.\n\nThe labyrinths are sometimes in ticket halls, sometimes on a platform, sometimes (Euston Square) tucked in the little room by the lift.\nI’ve been collecting em on Instagram as I spot them – here they are.\nYesterday I got to 50! 220 to go.\n4.\n10 extinct jobs.\nLamp lighter.\nLector Who Entertained Factory Workers.\nSwitchboard Operator.\nI have to say, I do feel slightly indignant that I have to dial phone numbers myself. I also feel indignant that I have to sort my recycling. Surely this is the thing that systems should do?\nAnd by systems, I mean organisations that might include people, where the people are paid properly.\nThe cost shouldn’t be pushed onto me - and you - and everyone else.\nSo I feel tempted to operate a kind of vanguardism – a refusal to cooperate, and an insistence on acting in a way that forces the system to improve. So: simultaneously insist on recycling being done, but deliberately putting it into the bins mixed so the problem is pushed back onto the system.\n",
    link: "/home/2015/03/13/coffee_morning",
  },
  {
    title: "Coffee morning and the business onion",
    date: "17.20, Friday 20 Mar 2015",
    content:
      "Hardware-ish coffee morning yesterday was weird… I missed a conversation about knitting. I got a short demo of Made By Many’s Hackaball - which has just blown through its Kickstarter goal CONGRATULATIONS - but missed the main discussion. Matt from Speakset was talking about their super simple videophone for old folks, but I got dragged off elsewhere halfway through that chat. Laura was talking about energy, and honestly I could have spend an hour rambling about how Apple could use their big solar farms to make a vertically integrated consumer power offering… but I got distracted about something else. And with Blaine, I think we were about to have a breakthrough moment figuring out how to put micropayments at the protocol level of the web, and what new features we could offer, but by then my head was too full.\nI hope everyone else had a good time :) Thank you for coming Alessandra, Matthew H, Matthew L,\nTom T, Blaine,\nTom A, Abby, Ben, Matt, Anna, James, Josh, Martin, Max, Laura, and Melissa!\nSo the gestalt for me is route to market.\nIt’s a bugbear of mine that we’ve ceded the future of the web to advertising. And you know, thinking about what would happen if we started to charge for content on the web… it doesn’t feel like it would work. Products on the web spread virally across social networks, producing random clicks that tease you into greater engagement. This is true for apps and articles.\nAnd paying money inhibits virality. So there always has to be a free tier, to get as many of your eyeballs to infect as many more eyeballs as possible. Or it’s totally free and there’s indirect revenue – you sell the data, or sell ads.\nThis, it turns out, is the failure mode with “the product is the marketing” philosophy: Now we don’t separate out acquisition marketing into a different effort, we need every single one of our product users to be a shill. The route to market is right through your friends list.\nThen I was looking at Hackaball which is a smart and responsive ball that children can program to invent and play games – and this is great for a bunch of reasons, but primarily (for me) because behind it is the digital agency Made by Many (where Melissa is from), and that’s terrific, that they’ve got the capabilities to design, launch, and then manufacture a Bluetooth-connected product, because that means they can bring those capabilities to all their clients. Gosh.\nBut educational products always confuse me slightly, because kids use them, but kids don’t pay for me, and so the way the product is talked about isn’t targeted at them. Like, I remember being seven. On a good day. Mostly I don’t even remember being 30. But when I do remember being seven, I remember being into fun and cool and what my friends have… not learning. The route to market is not what makes the product good.\nAnd with Speakset - which, again, is awesome - the customer is not the user. User: old people. Customer: Care providers.\nSo the way you design the product to best take it to market is not the same process to make it great for its users.\nIs this a bad thing? Of course it isn’t. Speakset will improve the lives of its users. It can only do that if it reaches lots of users. The best way to reach lots of users is via care providers.\nBut but but. One of the reasons I like Apple is that the proposition is clear. I give them money for hardware. I am the customer and the user both. They pay - separately - for marketing to tell me about the hardware. There’s no misalignment of interests where they want to push the hardware into my hands so that they can make money out of selling usage data, or something.\nNow I’m not going to claim that Apple are selfless angels, always acting in my interest. Far from it.\nBut when I’ve been sketching out business models for startups recently (which I have, a bunch), and those business models have been complicated with lots of actors having lots of different interests, I’ve been trying to draw them as a business onion. Where the core is a perfect knot of aligned interests of customer, user, and marketing, everyone acting in a way that supports revenue break-even, growth, and great product. Maybe not any profit yet. That’s the next layer of the onion: More aligned interests, but this is where the profit is. And then maybe another layer, with a more complicated ecosystem play.\nNever making a tradeoff between layers. Never saying: Well, we’ll make a loss on product sales here because we’ll make it up by selling the data over the customer lifetime. Ugh. Misaligned interests. Dirty onion.\nI’m rambling. Business onion.\nNext coffee morning\nLet’s do another coffee morning in 3 weeks… Thursday April 9th, same bat-place, same bat-channel.\nI’ll send a reminder to the announce list nearer the time – you can subscribe here.\n",
    link: "/home/2015/03/18/filtered",
  },
  {
    title: "Filtered for Monday mornings",
    date: "10.25, Monday 23 Mar 2015",
    content:
      "1.\nAn LED jacket for sausage dogs. Back Disco Dog on Kickstarter.\nIf your dog runs too far away and the connection is lost, the vest will show an automatic “LOST DOG” message\nBest video.\n2.\nThere are eleven Sikh gurus – the 11th, Final and last, eternal living guru took leadership in 1708, and is the community itself, the Khalsa:\n\nthe temporal leadership of the Sikhs was passed on to the Khalsa with the bestowed title of “Guru Panth” and spiritual leadership was passed on to the Guru Granth Sahib [the central religious text]\n\nGuru Gobind Singh the 10th guru: All the Sikhs are enjoined to accept the Granth as their Guru. Consider the Guru Granth as embodiment of the Gurus. Those who want to meet God, can find Him in its hymns.\nI wonder what this kind of metempsychosis feels like from the perspective of the guru – to awaken as a text; frozen mid-thought, only alive when in communion with other minds.\n3.\nThe brain is electric. Transcranial magnetic stimulation works by stimulating bits of your brain with a whopping great magnet.\nZap your frontal lobe, it can make you savant at drawing cats (New York Times, 2003.)\nIt’s loud too. Magnets eh.\nZap your motor cortex, your arm jumps. Quinn Norton on neuro-engineering (Wired, 2009):\n\nA few inches over my ear is the part of my brain that controls my hand and arm. Schneider holds the coil there and activates it. The muscles in my scalp contract automatically, and it stings. My hand is jumping with each loud snap from the TMS machine.\n\nI remember Quinn telling me about this experience… what stuck with me was her experience with free will. If you zap your muscles, they twitch despite yourself, but you can resist it.\nBut when you zap your neurons, you don’t resist: you change your mind.\nHold your arm down. Zap. [Arm moves.] Why did you move your arm? I wanted to.\nSo I look at all this augmented reality nonsense and it all looks quite distracting.\nAnd so I figure: What about a transcranial magnetic stimulation helmet, with Google Maps inside? That way your can check your email and Skype your mum, while the Walking-Down-The-Street Hat takes care of the tedious job of moving your legs, and collision-detecting your way around obstacles like buses and humans.\nC’mon Google, sort it out.\n4.\nI made a slo mo video of a bee yesterday – that ethereal hooting you can hear in the background - turn it up, it’s very quiet - is birdsong.\n9 Beet Stretch is Ludwig van Beethoven’s 9th symphony stretched to 24 hours, with no pitch distortions. It’s broadcast online continuously: Listen now.\nRecorded by the Huygens probe, the sound of the winds of Titan, largest moon of Saturn.\n",
    link: "/home/2015/03/20/coffee_morning",
  },
  {
    title: "Filtered for rules and otters",
    date: "10.22, Monday 30 Mar 2015",
    content:
      "1.\nSteve Coast on rules.:\n\nAnd so, with more rules we have solved most of the problems in the world. That just leaves the weird events left like disappearing 777’s, freak storms and ISIS. … Ultimately, this is why the world is getting weirder, and will continue to do so. Now with global media you get to hear about it all.\n\nAnd: everything that has ever happened has happened in the last decade or less.\n2.\nThere’s a zoo in Japan where you can shake hands with an otter.\nMore pics.\niCPooch, a video conferencing device and remote treat dispenser for pets.\nProject began at Startup Weekend (great mission – I’m a trustee of the European arm). Inventor was 14 years old.\nA dog that texts selfies.\nCharles Mingus, jazz legend, literally wrote the book on how to train your cat to use the toilet.\n3.\nWe don’t have a written constitution in the UK, but occasionally habit and precedent gets collated and scribbled down. In 2010, the operation of government was set out in the Cabinet Manual. For procedure nerds, it’s a fascinating read.\nSection 2 is about elections and The principles of government formation – especially interesting because of the upcoming general election. Also I love the writing: The tone is colloquial, plain, and straightforward. But you can tell every word is chosen with care, every “should,” every “expected.” With a thousand year history, our system of government needs to balance what works with an openness to exceptionality.\nToday we’re entering purdah, the period of self-denying ordinance from the civil service.\nSee also, Erskine May: Parliamentary Practice.\n4.\nThe Hammersmith and City line, including a picture of the 1908 White City exhibition. Gosh.\n",
    link: "/home/2015/03/23/filtered",
  },
  {
    title: "Books read March 2015",
    date: "20.00, Tuesday 31 Mar 2015",
    content:
      "By date finished…\n\nThe Jeeves Omnibus - Vol. 1, P. G. Wodehouse (5th)\nThe Past Through Tomorrow, Robert A. Heinlein (9th)\nWhy Look at Animals?, John Berger (15th)\nNeverness, David Zindell (21st)\nThe Age of Earthquakes: A Guide to the Extreme Present, Shumon Baser, Douglas Coupland, Hans Ulrich Obrist (22nd)\nEncounters with the Archdruid, John McPhee (25th)\nThe Inventions of Daedalus: A Compendium of Plausible Schemes, David E. H. Jones (31st)\n\nSome lines that stuck with me from Berger:\n\nThe animal scrutinizes him across a narrow abyss of non-comprehension.\nan animal’s life, never to be confused with a man’s, can be seen to run parallel to his. Only in death do the two parallel lines converge and after death, perhaps, cross over to become parallel again\nAs I say, I’m no scientist, but I have the impression that scientists today, when dealing with phenomena whose time or spatial scale is either immense or very small … are on the point of breaking through space-time to discover another axis on which events may be strung\n\nMore.\nSome lines that got me in McPhee, the first about the Colorado river, the second on Lake Powell:\n\nhe quoted Edith Warner: “‘This is a day when life and the world seem to be standing still – only time and the river flowing past the mesas.’“\nThe Utah canyonland had been severed halfway up by a blue geometric plane, creating a waterscape of interrupted shapes, spectacularly unnatural, spectacularly beautiful.\n\nMore.\nI can’t help myself but point my finger at these conjunctions. Narrow Abyss. Discover Another Axis. Interrupted Shapes.\n",
    link: "/home/2015/03/30/filtered",
  },
  {
    title: "Raw thoughts on Amazon Dash",
    date: "19.06, Wednesday 1 Apr 2015",
    content:
      "Amazon Dash… yup, makes sense. Give away light-weight Internet of Things gadgets to encourage purchase of fast-moving consumer goods. Tiny plastic buttons that allow for instant product ordering: Your entire house is now a shopping cart.\nWe worked on a bunch of similar stuff at Berg – such as Cloudwash where purchasing washing powder was part of the machine itself, and some secret projects where the transactions and connectivity explored different configurations. It was my colleagues who spent most time figuring out the service design and all the mini design interactions – but I was steeped in this for a year or two, so I figured I would dash out some notes…\nDash. Ho ho.\nLook, a warning. I haven’t proofread these notes so they might make no sense. And there’s nothing about how the Dash is designed, or what this means for your strategy. Feel free to get in touch for a coffee if you want to talk about either of those aspects, or if anything in what follows rings a bell for you…\nIt makes economic sense\nBy putting the Dash Button in the home, it lowers friction to purchase and shifts the distribution channel to Amazon.\nThis is good for:\n\ncustomer retention through reduced churn. You’re a loyal Tide customer, but you’ve run out. Instead of running to the nearest store and grabbing whatever brand is on sale today, you hit the button\ncustomer retention through reducing the replenishment time\nswitching to a low-cost distribution channel. Cost of sale is likely lower with Amazon or direct sales, versus physical retail that needs to cover in-store inventory and staff\n\nYou could probably make a pretty simple equation out of this, saying something like… it’s worth it when:\nrevenue from selling N buttons + N1 * channel cost saving + N2 * margin on additional sales + value of effective marketing > development cost + server cost for 1 year + cost of producing N buttons\nwhere N1 is the number of buttons used by existing customers who switch channels, and N2 is the number of buttons used to make new purchases.\nAssuming you’re giving these buttons away, and assuming you don’t have access to the marketing budget, the relevant costs become:\n\nhow much do these buttons cost to develop (not much if you’re Amazon, because you already have all the bits from your other products)\nhow much do these buttons cost to run (not much if you’re Amazon, because you already have the back-end servers and the logistics)\nhow much do these buttons cost to produce – the component cost has dropped sharply over the last year or two. Note that the Dash Buttons are small and use battery powered wi-fi… they fall out of the smartphone supply chain. Or to put it another way, these buttons are the peace dividend of the smartphone war\n\nAnd when these costs fall enough, the question becomes: Do you reckon you can make a profit on the 2% of customers who will buy 5% more a year?\nIt’s the new marketing\nI brushed over the marketing benefits above, but let’s not forget that we’re enamoured with web-connected physical things. Internet of Things gadgets are novelty; brands that launched with Amazon will be pleased with the publicity.\nThough… why not go with a Youtube video for the publicity, and not bother making the thing itself, like Evian’s fridge magnet launching their water subscription service? It’s a lot cheaper.\nI can think of a couple of marketing benefits to actually making and distributing the button itself.\nAdvertising is changing. You need Adwords and Facebook ads to fish where the fish are… but come on, they’re boring, they don’t create the emotional impact of a full-page glossy magazine ad, or a great TV spot.\nSo, for me, these buttons are the first step to a new channel. Sure, they’re utilitarian – they order more consumables. But they also tell a story that this brand is there for me, it’s in my home, it’s at hand, on-demand. Products are people too and this button has a character… it’s now up to us to create physical objects that have different characters, one that might be more suitable for high fashion, fragrance, whatever.\nYou need these different marketing channels because building awareness requires a drip-drip approach… a banner ad here, a Buzzfeed list there, a button on the fridge. A new advertising component.\nE-commerce continues to grow at the expense of physical retail, and discovery in e-commerce continues to suck. Another way to think about the Dash Button is that it’s doing the same job as a shelf-end promotion, or a BOGOF. This is a replacement for the lost world of point-of-sale discovery tricks, and it’s in-home.\nIn a way, we’re really seeing the future of marketing here. We’ve separated awareness (advertising) and distribution (stores) for so long, but it’s no longer the way. When you get a Buy Now button in a tweet you’re seeing ads and distribution merging, and the Button is the physical instantiation of this same trend.\nIn the future that Simon Wardley paints, this is a warning shot against the supermarkets, and in the future every product will carry a buy button. We’re already in this world with smartphone apps: Because App Store discovery sucks, the best mode of distribution is word of mouth. The more downloads you already have, the more downloads you’ll get. Which is why app publishers need to get their dirty mitts on your address book. Is this a future we’ll see with consumable home products, too?\nWhy Amazon?\nThe costs of making the button dropped for Amazon before anyone else – as I said above, they have the technology Lego bricks already, and the logistics available. But there are two other groups I’ve run into repeatedly who have looked seriously at the same concept\nTraditional manufacturers of either FMCG or the kit that consumes it (that is, makers of washing powder and makers of washing machines). In 90% of cases, these manufacturers don’t know how to speak with end consumers. They maybe know how to speak with consumers pre-sale… but they tend to outsource that to marketing agencies. But typically their customers are distributors and retailers, not end consumers.\nThis is a problem because the Dash Button isn’t just a button, it’s a communications channel. It’s an app. It’s push notifications. It’s the update emails. Somebody needs to write that copy, somebody needs to manage the feedback, somebody needs to choose when to do a price promotion.\nFor most manufacturers, there’s not a group in the company that knows how to do this, so making the Button isn’t an engineering challenge – it’s a difficult corporate re-org where the voice that would advocate that strategy isn’t even present in the leadership team.\nThere’s a particular problem for the device manufacturers, as opposed to the manufacturers of the consumables. Connectivity of shared objects means back-end servers, and these cost money to run. When you’re a big company, you think via the profit and loss. A connected machine which just offers neat user features (e.g. a notification when your wash cycle has finished) doesn’t make sense on the P&L: it just means you have to knock points off your margin when you first sell it, to put cash aside to keep the service running. The only way connectivity makes sense is to align the recurring costs with some kind of recurring revenue.\nIn 2015 that means creating a sales channel for consumables… which the white goods manufacturers don’t have available to them. Ink-jet printer manufacturers do. And we won’t be stuck as this stage forever. Give it 12 months, and you’ll have a microwave with in-app purchase. I’m only half kidding.\nThe marketing agencies get it. But marketing agencies are organised (have teams; do sales; are paid) around campaigns. Campaigns have a beginning and an end. In the web world, we’re used to the KPIs of ongoing services (acquisition, activation, retention, etc): we measure Monthly Active Users. That’s what you need to build a new sales channel. But it’s not how you run a successful campaign.\nAnd besides, marketing agencies need to do something different every quarter – they don’t build up a tight ops machine of technology and logistics. Building the Dash Button isn’t, for them, just the next easy thing to do.\nOn my list of startups I would do - which is way too long and honestly, mostly awful - is an agency that offers to speak with customers post-sale.\nSo the manufacturer of Break Maker X would get us in to run the communications channel with the customers… either a button on the machine or just the app. And we’d all come from the web world, so it would be all A/B testing emails, looking at the button stats, partnerships with legendary bakers to sell artisan yeast, all that nonsense. We’d run it on a retainer basis, and eventually get bought by one of the big networks for a billion quid.\nBy the way, there is one group I’ve met who do (a) know how to have a customer conversation, and (b) have an incentive to cross-sell and up-sell on that channel. And that’s the retailers, especially the retailers who already have a logistics network and run post-sales activities such as an extended warranty programme.\nIn the UK, that means John Lewis/Waitrose – I was half expecting to see this button come from them, first. But they don’t have “retail platform” in their DNA like Amazon.\nAnd there are some manufacturers who understand that the product is the channel. But I can’t say who because I’m still under NDA.\nLast thoughts\nI have to say, the Amazon Dash Button makes a ton of sense to me, as the near future of the Internet of Things, in a way the internet fridge never has.\nI’ve always said that if I was making an internet fridge, I’d just make a fridge magnet that ordered milk. Or, better, a tiny talking Fridgeezoo pet that - when tapped - would text both me and my wife “we’re out of milk!”\nIt’s that shared use that makes this button really great. Smartphones are still stuck in the Personal Computer era… but my shopping list isn’t personal. We live with flatmates, families, and friends. We can hack it – at home we use shared Reminders on iPhone for the weekly shopping. But my online grocery order is associated with a single user account. It seems dumb; the button fixes that.\nIt’s the ability for some kid in the household to say “hey, need more toothpaste” that leads to the button requiring wi-fi: Bluetooth is cheaper, but it would need a paired smartphone around.\nAnd I am curious to see how it all works. The service design is complicated… without a screen, or any feedback, maybe your order is already on the way because somebody else hit the button, but how do you know? Sure the button automagically doesn’t place a repeat order until the delivery is made, but what about more complex orders, or what if what you want is out of stock? Ultimately, this’ll do for 80% of the cases, which is more than enough.\nAnd then - for the rest - there’s the Dash Replacement Service, Amazon’s button-to-logistics technology all wrapped up, and ready to be integrated into whatever product you’re creating. I see Quirky are building this replenishment service into the device itself:\n\na new line of smart appliances including an artisanal pour-over coffee machine, a baby formula maker, and a pet food dispenser. Each appliance will measure remaining consumable supplies and place an order using DRS before running out.\n\nDRS is the best bit. Can you imagine what the life-time value is, for Amazon, if [white goods manufacturer] bake this into a washing machine, an item with an 11 year replacement cycle?\nWhere next\nWe’re seeing the various stacks line up to own the smart home ecosystem:\n\nApple… offer Homekit to chip makers and device manufacturers, make every product in the home a smartphone peripheral. We’ll make it easier to get to market, but only if you commit to us.\nGoogle… with Nest establishing a beach-head, go for a data and orchestration play, providing feature differentiation. I wouldn’t be surprised to see a Homekit-like play.\nSamsung… leading the charge for the white goods manufacturers with SmartThings and the open ecosystem it promotes.\nAmazon… end-to-end technology, combining both hardware connectivity through to back-end servers, payments, and logistics. Give it a year, then make the underlying chips available to any developer.\n\nI know the Dash Button feels utilitarian – but to my mind it’s also eminently sensible, and executed in exactly the right way. I like it. If it does well, it’ll make possible connected devices which are less utilitarian. I’ll like that even more.\n",
    link: "/home/2015/03/31/books_read",
  },
  {
    title: "Coffee morning 8",
    date: "10.04, Tuesday 7 Apr 2015",
    content:
      "It’s a bit last minute I know, but let’s have another hardware-ish coffee morning this week!\nThursday 9th April, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nWhy? It’s sunny, I’m in the mood to hang out and chat about cross-stitch and hardware startups and distribution. Zero structure though, chat about whatever you fancy – here’s how it works.\nIf you’ve been thinking about coming to coffee mornings 1 thru 7 but haven’t, bunk off work and come along to this one. It’d be lovely to see you.\n(Reminders, as always, are sent to the coffee morning list.)\n",
    link: "/home/2015/04/01/amazon_dash",
  },
  {
    title: "Filtered for doorways",
    date: "10.11, Tuesday 14 Apr 2015",
    content:
      "1.\nThe term bardo refers to the state of existence intermediate between two lives on earth.\n\nalso translated as “transitional state” or “in-between state” or “liminal state”.\n\nLiminality, from the Latin meaning “a threshold”:\n\nthe quality of ambiguity or disorientation that occurs in the middle stage of rituals, when participants no longer hold their pre-ritual status but have not yet begun the transition to the status they will hold when the ritual is complete.\n\nWhen you step through a door, the door has width – a couple of inches. For a fraction of a second, you’re not in/out but liminal.\nWalking through doorways causes forgetting.\n\n“Entering or exiting through a doorway serves as an ‘event boundary’ in the mind, which separates episodes of activity and files them away,” Radvansky explains.\n“Recalling the decision or activity that was made in a different room is difficult because it has been compartmentalized.”\n\n2.\nPhotos of sea mountains.\n3.\nTo make Lemmon Cakes, a recipe from 1670, from the cookery book The Queen-like Closet or Rich Cabinet: Stored with all manner of Rare Receipts For Preserving, Candying and Cookery. Very Pleasant and Beneficial to all Ingenious Persons of the Female Sex by Hannah Woolley.\nThe history of sugar in Europe.\nDuring the 18th century, sugar became enormously popular. Britain, for example, consumed five times as much sugar in 1770 as in 1710.\n4.\nSomething interesting is happening: Uber, the world’s largest taxi company, owns no vehicles. Facebook, the world’s most popular media owner, creates no content. Alibaba, the most valuable retailer, has no inventory. And Airbnb, the world’s largest accommodation provider, owns no real estate.\nDespite its name, I wonder whether this is the real common thread running through the sharing economy… there’s nothing on the balance sheet.\nSo look at the Bring Your Own Device trend… maybe this is the same, workplace IT with no technology. So what about facilities with no offices, menswear stores with no clothes.\nThe realisation that the heart of business is the ops machine and not the assets – orchestration not ownership. That’s a valuable insight.\nTake this trend, cross-breed it with the shift to subscription box companies (of which there are trillions because a company that takes advantage of life-term value can out-market one that doesn’t when it comes to customer acquisition), plus fluid workplaces such as holacracy… where do we get? Don’t know. On my mind. Feels like we’re on our way somewhere.\n",
    link: "/home/2015/04/07/coffee_morning",
  },
  {
    title: "Filtered for hefting",
    date: "09.04, Friday 17 Apr 2015",
    content:
      "1.\nGiant realistic cat head, with photos of it being worn (via @matlock).\n2.\nBacon by post: Cure & Simple.\nGosh there are tons of these subscriptions boxes.\nThis is the sharp end of - and this is how the Harvard Business Review puts it - why strong customer relationships trump powerful brands.\n\n[digital technologies] allow more direct interactions with customers, bypassing expensive middlemen and reducing the cost of sales and marketing; they allow firms to optimize customer lifecycle management based on detailed data and analysis of customers’ needs; they improve efficiency and quality across the value chain as a result of continuous customer feedback\n\nMeanwhile the value of a brand is declining because purchasing decisions have become more fact based, and less brand-image based.\n3.\n@herdyshepherd1, shepherd, author, and Twitter superstar. His new book on the Lake District is half autobiography, half history, and half manifesto for land and animals: The Shepherd’s Life.\nHis story and some pictures.\nHefting:\n\nHerdwick sheep are ‘hefted’; which means they hold (without fences) to a place on the fell (mountain) because they are taught a sense of belonging by their mothers in their first summer. This stretches back countless centuries and has never been broken.\n\nThis is the bit where I make some awkward analogy between hefting and brand recognition/customer lifetime value.\n4.\nTempescope, an ambient weather display for the home that looks like a glass jar with actual weather happening in it. Fog, rain, etc.\nPatch of Sky, a set of three Internet connected ambient lights, enabling you to share the sky above you in real-time with loved ones, wherever they are.\n",
    link: "/home/2015/04/14/filtered",
  },
  {
    title: "Where the wave finally broke",
    date: "11.02, Saturday 18 Apr 2015",
    content:
      "From Fear & Loathing in Las Vegas:\n\nHistory is hard to know, because of all the hired bullshit, but even without being sure of ‘history’ it seems entirely reasonable to think that every now and then the energy of a whole generation comes to a head in a long fine flash, for reasons that nobody really understands at the time—and which never explain, in retrospect, what actually happened . . . There was madness in any direction, at any hour. If not across the Bay, then up the Golden Gate or down 101 to Los Altos or La Honda . . . You could strike sparks anywhere. There was a fantastic universal sense that whatever we were doing was right, that we were winning . . . And that, I think, was the handle-that sense of inevitable victory over the forces of Old and Evil. Not in any mean or military sense; we didn’t need that. Our energy would simply prevail. There was no point in fighting-on our side or theirs. We had all the momentum; we were riding the crest of a high and beautiful wave . . . So now, less than five years later, you can go up on a steep hill in Las Vegas and look West, and with the right kind of eyes you can almost see the high-water mark-that place where the wave finally broke and rolled back.\n\n(Also, a 1997 interview with Hunter S. Thompson.)\nBen emailed me this quote the other day.\n",
    link: "/home/2015/04/17/filtered",
  },
  {
    title: "Coffee morning next week",
    date: "10.22, Tuesday 19 May 2015",
    content:
      "Seems like it’s been a while since we last had a hardware-ish coffee morning. Let’s have one next week.\nThursday 28th May, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nSame as before: Super informal, just hanging out and chatting, bring your cross-stitch or circuit boards if you have em. If nobody turns up it’ll just be me checking my email, and that’s fine too.\nSo why has it been over a month since the last coffee morning? I’ve been hiking in Colorado for one thing.\nBut also I’ve been trying something new… does the coffee morning format transfer to other situations? This term, Durrell Bishop is running a course at the Royal College and he asked me if I’d like to get involved. I suggested that we try doing weekly coffee mornings for the students: A place to chat outside the studio, something we can invite others to, but not a crit and not a talk and not unrelated to work either. So we’ve been trying that.\nIt’s risky, because the informality means no outcomes can be guaranteed. And anyway, is there any benefit to organising something like this, beyond what you get anyway from grabbing a cuppa in the canteen? Well I don’t know, which is why experimenting with Durrell and his students is so cool.\nAt the back of my head, I’m wondering whether there’s a commercial model for convening coffee mornings inside corporations. I don’t really want to do trad consultancy again. But the idea of establishing a DMZ on the edge of a company… a place where serendipity can happen, over time… no talks and no audience, but catalytic conversations, convened once every couple of weeks for several months… I’m curious about whether that could work.\nAnyway. See you a week on Thursday!\n",
    link: "/home/2015/04/18/the_wave",
  },
  {
    title: "Books read April and May 2015",
    date: "14.10, Friday 29 May 2015",
    content:
      "By date finished in April:\n\nThe Shepherd’s Life: A Tale of the Lake District, James Rebanks (4th)\nDangerous Visions, edited by Harlan Ellison (18th)\nWatermark: An Essay on Venice, Joseph Brodsky (21st)\nDesigning Miracles: Creating the Illusion of Impossibility, Darwin Ortiz (26th)\nFear and Loathing in Lad Vegas, Hunter S. Thompson (30th)\n\nBy date finished in May:\n\nWild Life, Molly Gloss (3rd)\nCount Zero, William Gibson (22nd)\nSeveneves, Neal Stephenson (28th)\nBook from the Ground: from point to point, Xu Bing (29th)\n\nLook, there are two sequences in Wild Life which the narrator Charlotte Bridger Drummond spends in silence – one in the forest and one in the company of other people. And nobody but nobody writes about silence better than Gloss. The Dazzle of the Day - her science fiction novel about starships and Quakers - puts silence (and in this case spirituality) right at the centre. You can look through silence, see what is refracted through it, and you can look around it, and it has heft and volume, and many many hues. But it’s invisible. It’s where things are born, or where you can become trapped. It’s animal, outside language. But the other way too, it’s where god speaks.\nAnyway. I’m in the library. A week or two back I was hiking in the mountains.\nBook from the Ground is a graphic novel told with emoji.\n",
    link: "/home/2015/05/19/coffee_morning",
  },
  {
    title: "Filtered for heavy dogs",
    date: "10.38, Monday 1 Jun 2015",
    content:
      "1.\nTinitell, a wristphone for kids.\nProduct video.\nVoice recognition, a battery that lasts a week, kid-to-kid comms, and GPS for the parents.\n2.\nKeecker, a video projector attached a home robot.\nSome interesting use-cases…\n\nwalk through your house skyping with a friend in Tokyo with KEECKER following you,\nor see what’s happening in real time by moving KEECKER around your house [I assume remotely]\n\nI mean, my Apple Watch means notifications follow me around by virtue of it being tied to my wrist. But another way of doing this is computation literally following me around.\nSee also the Lily drone – a drone with follow-me functionality, and 20 minutes of HD video. I love the idea that the language of film direction is coming into everyday life, that you could call out to your Lily different camera angles at it swings around you snowboarding down a mountain.\nOr walking to the shops, whatever.\n3.\nTingbot, Raspberry Pi-powered alarm-clock-form-factor box to run apps at home.\n4.\nFrom New Scientist, February 1976:\n\nA US nuclear laboratory is said to maintain a “heavy dog”–fed with heavy water and “heavy” food, and with the heavy isotope deuterium replacing normal hydrogen throughout the whole body.\n\nThe heavy dog would have some unusual properties,\n\n[it] would be invisible to a MRI scanner. The dog would still be clearly visible to the naked eye so apart from confusing the staff operating the scanner I can see no advantage to this. \n\nHeavy dog.\n",
    link: "/home/2015/05/29/books_read",
  },
  {
    title: "Filtered for radioactive cats",
    date: "11.39, Tuesday 2 Jun 2015",
    content:
      "1.\nQuestion. If you bury radioactive waste and need to warn people to stay away from the land for 10,000 years, how do you do it – basically how do you construct a message that lasts longer than humans have been living in cities?\nAnswer from 1981: cats and songs.\n\nBastide and Fabbri came to the conclusion that the most durable thing that humanity has ever made is culture: religion, folklore, belief systems. They may morph over time, but an essential message can get pulled through over millennia.  They proposed that we genetically engineer a species of cat that changes color in the presence of radiation, which would be released into the wild to serve as living Geiger counters. Then, we would create folklore and write songs and tell stories about these “ray cats,” the moral being that when you see these cats change colors, run far, far away.\n\n2.\nThe Green Man is often related to natural vegetative deities.\n\nThe Green Man appears in many forms, with the three most common types categorized as: the Foliate Head: completely covered in green leaves; the Disgorging Head: spews vegetation from its mouth; the Bloodsucker Head: sprouts vegetation from all facial orifices (e.g. tear ducts, nostrils and mouth)\n\n3.\nTraditional rhymes for counting sheep vary region by region. This is how to count to 10 in Derbyshire:\n\nYan\nTan\nTethera\nMethera\nPip\nSethera\nLethera\nHovera\nDovera\nDick\n\n4.\nGreg Egan - author of the hardest of hard sci-fi - has a particular take on science fiction:\n\nI’m interested in science as a subject in its own right, just as much as I’m interested in the effects of technology on the human condition. In many things I write the two will be combined, but even then it’s important to try to describe the science accurately. In a novel such as Incandescence, though, the entire point is understanding the science, and it really doesn’t bother me in the least that it’s not an exploration of the human condition.\nThere are times when it’s worth putting aside the endless myopic navel-gazing that occupies so much literature, in order to look out at the universe itself and value it for what it is.\n\nFuck yeah. Incandescence is a crazy novel because - although it’s set up by the short story Riding the Crocodile which is a great story in its own right - it barely has any story: It’s really about the discovery of physics and its implications from the perspective of a society living (unknowingly) close to a black hole, in the realm where General Relativity dominates over Newtonian physics.\nIt’s hard going, but it’s a book of unfolding implications. Like Neal Stephenson’s new novel Seveneves (review) which is barely a story, and more like a rigorous proof-by-deduction of what would happen if the Moon blew up.\nWhat I love about this - aside from the de-pedestaling of story, and managing to escape that particular tyranny - is the novels can walk you into a deep understanding of accurate-but-nonintuitive natural systems. It seems to me that I think by applying metaphors - by pattern recognition - this is how the world works, this is what feels familiar. Physics gives me a richer set of metaphors: I believe I’m a stronger thinker for having encountered Cooper pairs. Post Seveneves I find myself applying the metaphor of orbital mechanics to, let’s say, personal brand – just idly, not rigorously, but Stephenson’s novel has given me the beginnings of a new intuition to test out.\nAnd there’s a joy in the process of learning and encountering. So why shouldn’t science fiction be fiction about science and the scientific method itself? Egan’s bang-on, even if it’s at times difficult. Or honestly: blimmin tedious… but in a good way. More power to his elbow.\n",
    link: "/home/2015/06/01/filtered",
  },
  {
    title: "Filtered for lists",
    date: "16.48, Wednesday 10 Jun 2015",
    content:
      "1.\nPixar’s 22 rules of storytelling. e.g.:\n\nYou admire a character for trying more than for their successes.\nWhen you’re stuck, make a list of what WOULDN’T happen next. Lots of times the material to get you unstuck will show up.\n\nReminds me of Michael B. Johnson talking about Pixar’s process…\n\nMake a believable world\nCreate a character that is believable in that world\nCreate a story\nRepeat until done\n\nI seem to remember there was a precedence ordering to this. Like, the believable characters in the Toy Story world are toys, right, so they don’t have tear ducts. Which means you can’t have them cry, no matter how much the story demands it – you have to show that emotion some other way, perhaps with rain and clever camera work. World > character > story.\n2.\n16 Perfect Japanese Words You Need In Your Life.\nTsundoku. The act of buying a book and leaving it unread\nYugen. A profound awareness of the universe that triggers a deep emotional response\n3.\nGeneral Orders for Sentries.\n\nOn the surface, it’s a pretty simple thing, being a sentry. “Watch this area. Tell us if anything odd happens.”\nIn practice, there’s thousands of permeations of things that can go wrong when you’re guarding an area, and a sentry failing in his duty could lead to – literally – thousands of people getting killed.\n\nAnd so there is a list of 11 rules - short enough to memorise - that covers what to do. The Three Laws of Robotics only for soldiers.\nReading these rules, I have a picture of the military as a machine – or rather as agent-based hardware, and these rules are the software. In a sentry role? Load the General Orders for Sentries.\nIt’s the playbook.\n(I’ve been writing a playbook recently… just for a project I’m sketching out. Keeps me out of trouble. It’s interesting to think of a project or “business” as a platform of people and technology, running “software” made of actual code and of playbooks. Included in the “software” is the capacity for learning and self-healing. The playbook/software I’m sketching is made of scheduled triggers, plays which are like checklists or state machines, and pipelines. In the future, business bureaucracy will be automated – it’ll turn into software, just like everything else that doesn’t require human ingenuity or human dexterity.)\n4.\nAnimals that do not synthesise their own vitamin C:\n\nFruit bats\nGuinea pigs\nPrimate monkeys\nHumans\n\nOur word for the colour orange comes from the name of the fruit; the first recorded use was in 1512.\n",
    link: "/home/2015/06/02/filtered",
  },
  {
    title: "On conversational UIs",
    date: "17.02, Tuesday 16 Jun 2015",
    content:
      "1.\n\nWhen trumpets were mellow\nAnd every gal only had one fellow\nNo need to remember when\n‘Cause everything old is new again\n\n– Peter Allen.\nStand back folks. I’ve not spent any time editing and now I’m going out. This is stream of consciousness, and it’s long.\n2.\nThere’s that bit in the great article on Chinese mobile UI trends about how there are no websites, there’s just messaging. And not only that, some weird mish-mash of talking robots and customer service people:\n\nMany institutions that otherwise would have native apps or mobile sites have opted instead for official accounts. You can send any kind of message (text, image, voice, etc), and they’ll reply, either in an automated fashion or by routing it to a human somewhere. The interface is exactly the same as for chatting with your friends\n\nYou know, and why the hell not. I have one language to use with apps (pointing, tapping, swiping) and another with my friends (chatting). Why not chat with my apps too?\nSo as Benedict Evans - mobile and technology analyst extraordinaire - points out, messaging is the new app platform:\n\n[In WeChat, in China] You can send money, order a cab, book a restaurant or track and manage an ecommerce order, all within one social app. So, like the web, you don’t need to install new apps to access these services, but, unlike the web, they can also use push and messaging and social to spread.\n\nThe other piece of the puzzle here, Evans continues, is the smartphone notifications panel:\n\nThat pull-down panel aggregates activity from everything on your phone, and Google and Apple have made notifications actionable and given them payloads. … More and more, one’s primary interaction with any app, social messaging or otherwise, is a little pop-up with a button or two.\n\nSo I’ve long been interested in the idea that “next actions” should float away from their apps and come together in a single place… SNAP was my 2008 take on this.\nBut I guess the 2015 twist is that everything old is new again, and we’re dealing not just with actionable notifications, but robot-generated text that we can have an actual conversation with.\nWhich is Twitter’s fault.\nNowhere is it more evident that The Web is a Customer Service Medium. Just look at @AskNationwide (with replies) or @British_Airways (with replies). It’s all conversations with customers.\nThe canonical automated version of this is @andy_house (2009), aka the house that twitters, or see House of Coates for a more up-to-date take on the tweeting smart home.\nNow imagine it wasn’t just an activity feed, but you could talk back.\nA big bit of the current excitement is the rise of Slack for workplace comms and its embrace of bots. Which takes us to Ben Brown’s insanely incredible insight: What happens when you start automating workplace processes?\n\nWhat if there was a meeting runner bot that automatically sent out an agenda to all attendees before the meeting, then collected, collated and delivered updates to team members? It could make meetings shorter and more productive by reducing the time needed to bring everyone up to speed.\n\nWe’ve just been through an era where management has been regarded as the essential scarce resource of a business, and operations and technology are functions to be outsourced to fungible workers like so many cogs. But what if the core business resource is human ingenuity, and it’s management that can be turned into software… automated and optimised?\n3.\nDigit is an automated savings tool: Every few days, Digit checks your spending habits and removes a few dollars from your checking account if you can afford it.\nThe kicker: You communicate with it via text message (“Great, I’ve moved $10.00 to digit”), they have no plans for an app. And what’s interesting to me is that it has adaptive behaviour… and maybe because of the text message interface, this Digit review semi-anthropomorphises the software:\n\nAt first, Digit was really cautious with my money … But over the next couple weeks, as my balance recovered from holiday spending, it got a bit more ambitious\n\nSoftware isn’t “cautious” or “ambitious”, those are qualities of alive beings. But maybe it serves us to think so.\nWalkadoo is a walking game that encourages activity; you communicate with it by text message. Related: Autom is a robot weight-loss coach with big blue eyes. You lose more weight because you regard it as having a mind.\nRhombus is an e-commerce platform for shop to chat with customers by text message… and also accept payments, within the conversation. Related: Twitter’s in-feed Buy Now button which is a game changer if widely rolled out.\n4.\nOne of the problems with text interfaces is text entry. Keyboards suck, especially on mobile devices. Typing also introduces a discoverability question: How do you know what words are valid right now, or the right grammar to use? How do you make complex statements?\nIn the game Lifeline (iPhone/Apple Watch) you’re texting an astronaut called Taylor who is marooned on a moon. It works in real-time… when Taylor hikes to a location an hour away, you won’t hear from her till she gets there. You text back, but it’s not free text entry, you only get two options at a time. Works well on the smartwatch too.\nDespite the constrained responses, it still feels conversational. Enough that the first time I killed Taylor - by freezing to death based on advice I’d given - well, ooof.\nLifeline was prototyped in Twine, the visual programming language for writing interactive fiction. See also Inform 7 where the code-behind-the-fiction reads like a book but every word has its code-meaning too, like casting a spell in a stupid universe, like talking to a golem. e.g.:\n\nThe dark doorway is an open door. “The doorway looks ordinary enough, but it’s so difficult to be sure with the unaided eye.” The dark doorway is scenery. The dark doorway is not openable. The dark doorway is west of Longwall Street and east of Turret Roundhouse. The dark doorway is trapped.\n\nAnother take on text input:\nThe web-based game A Dark Room (also available for iPhone) is astounding. Half text adventure, half point-and-click. There’s something about clicking stoke fire and the words turning into a progress bar while the fire burns down… The communication of the element of time.\nHangkeys is a neat hack – it’s a custom iPhone keyboard that makes it super easy to play Hangman over SMS, Whatsapp, or other text message services.\nMeet by Sunrise is a custom smartphone keyboard that integrates with your calendar: Instead of typing times and locations, you tap them instead.\nMatt Galligan imagines tap-able buttons in text messages: What if instead of installing an app, we might instead allow a service to chat with us via iMessage?\nWriting code… Swift allows emoji for variable names. There’s something interesting about this. Variable names like “a” or “theCounter” or “dimensions” are meaningful… but what about underlying feelings they carry? The “ii” counter of a tight inner loop always has a zing for me, it’s the twang of high-tension power lines.\nSo can emoji carry more meaning, or meaning along a different axis? What could we use this for – instead of “houseAddress” just have a picture of a house; instead of saying errorDescription just use smiling pile of poo emoji.\n5.\nI was noodling with conversational UIs in 2002, back when AIM was a thing. What preoccupied me then - and what interests me most now - is how to make an automated conversation with a bot not boring, and (more importantly) not shit.\nSo one of the things I found before: The more the bot acts like a human, the more it will be treated like a human. And the more that happens, the more likely the bot will have to say “I don’t know what you mean”… which is lame.\nOur guiding light is The Jack Principles from the 1995 quiz show video game You Don’t Know Jack. In short, how to direct the conversation so a user will never be in a position to ask a question the machine can’t answer.\n(Tom Armitage collected a link to this and more when he ran a chatbot project at Berg back in 2010.)\nSomething else surprised me about authoring conversations, something almost contradictory…\n\nLeading a user through a conversation by the hand is great… once. It’s like a phone tree: a branching tree of questions and multiple choice answers where nothing can go wrong. But if the user wants to change their answer, compare different possibilities, or run through the conversation a second time: It’s tedious and frustrating.\nBut the alternative is a wide open space: The user can say anything, and it’s up to the bot to interpret and respond. However that introduces a discoverability problem. You can be chatting to your bot about what’s on TV tonight, completely unaware that it also knows what movies are showing nearby. Or let’s say you do ask about movies, and then you say “well how do I get to the theatre?” and suddenly it’s dumb again. Using Siri is often like that.\n\nI guess what I’m asking is how does a user have a theory of mind about a bot - a conception of its stance, intentions, domain of knowledge, etc - and how is that communicated.\nMy take back in the day was to organise knowledge into domains, within which a tree structure would be possible but avoided. To summarise how it worked:\n\nI built an AIM bot called FingertipTV. You could traverse it like a tree: “now” (reply: “a list of channels and what’s on now”), “bbc1” (reply: now and next for BBC1), “9pm” (reply: what’s on BBC1 at 9pm and the following show)\nResolution varied. “now” would result in a list of every channel but just the show titles (and you could hit a number to get the full description). Getting more precise with the channel and “9pm” would show a full show description.\nOnce you’d learnt the vocabulary, everything allowed shortcuts: The user could gradually become virtuoso. So the previous exchange could be replaced with “bbc1 9pm”\nThere was a limited amount of history. So saying “bbc1” then “later” would show what was on BBC1 later… but saying “bbc1”, “9pm”, “channel4” would show Channel 4 right now. The 9pm itself was forgotten. Use any excuse to limit the memory of the bot, because that constrains what the user has to hold in mind\nI added functionality to search movie listings… but encapsulated that in another AIM bot called Cinebot. If you asked about movies to FingertipTV, you’d get the reply “I can’t help you but my friend can,” and Cinebot would reach out and start a new conversation. Now you’d met Cinebot, and could add their name to your buddy list. Small, understandable, almost-stateless bots that talk to you and to each other\n\nMy point, I guess, is that a new medium needs a new grammar and conversational UIs are definitely a new medium.\nFor one – they’re intrinsically social. If I’m chatting with a bot in iMessage about what movies are on nearby, shouldn’t I be able to turn that into a group chat with my partner? And does the bot conduct two separate conversations, one with each of us, or assume we’re both searching for the same movie?\nWe’ll need app frameworks to help author these bots, and the frameworks will make assumptions about how conversations work in small groups.\nAnd you know what, we’re still in the PC era, the era of personal computing. We don’t really know how to use computers in small groups, how to use interfaces collaboratively.\nAnother big question for me is what happens when we have many of these bots…\nHow do traverse multiple knowledge domains, discovering features and adapting how we speak as we go? Is it going to be like FingertipTV and Cinebot, loosely coupled domains of differing knowledge and vocabulary? Or more like Siri where the same voice can tell you everything from “directions home” to “how long do dogs live” (to pick two examples that it’s giving me right now).\nMaybe it will be like Twitter, where everyone I follow is in a single stream – but I miss what they’re saying? Or like my apps on my phone, where many apps have their own activity stream… and they fight so hard to get heard that they constantly spam my notifications panel?\nMy head goes somewhere quite speculative,\nand that’s text adventures.\nDan’s story, Text Only:\n\nWhat now? >\nN.\nYou go North\nThe batteries on your Discman are almost depleted.\n\nOr Julian Dibbell’s memoire My Tiny Life, a tale of LambdaMoo, a collaboratively built text environment inhabited by objects, bots, and people.\nThere’s a strength in spatialising information – of arranging these bots - these domains of knowledge and differing patterns of interaction - into a web, or on a map. Some bots are closer to other bots.\nSo part of me wonders… what if I saw the activity feed from my smart home all together in one place, and then when I went north, say, that would be the activity feed from my social networks. Or instead, in my smart home I’d find my TV, and inside that we could have a chat about what’s being tivo’d tonight.\nI don’t want to be too literal. But maybe we need an architecture to arrange all these bots and feeds and conversations, etc. And while our experience of the conversations will vary (we’ll be friends with different bots) the architecture will be shared: Arbitrary, but shared. A cyberspace:\n\nA consensual hallucination experienced daily by billions of legitimate operators … [a] representation of data abstracted from banks of every computer in the human system. \n\n6.\n\nAnd don’t throw the past away\nYou might need it some other rainy day\nDreams can come true again\nWhen everything old is new again\nWhen everything old is new again\nI might fall in love with you again\n\nEOM\nps. More on conversational UIs.\n",
    link: "/home/2015/06/10/filtered",
  },
  {
    title: "Filtered for computers and birds",
    date: "14.12, Friday 19 Jun 2015",
    content:
      "1.\nI… look… just… this super freaky image of squirrels is a picture drawn by a computer on its own.\n\nThis squirrel has a weird amount of eyes, yeah? And seems to be made at least partially of dogs? Check out its weird rear appendage, which is composed of slug tentacles that are themselves composed of birds. A two-headed fish lurks in the foreground, and upon reexamination the background is not mere swirls, but a warped, repetitive city\n\nMore of the backstory on the Google Research Blog.\nIt’s a crazy process that works by turning up the gain on an artificial computer brain. Giving it acid…\n\nWe ask the network: “Whatever you see there, I want more of it!”” This creates a feedback loop: if a cloud looks a little bit like a bird, the network will make it look more like a bird. This in turn will make the network recognize the bird even more strongly on the next pass and so forth, until a highly detailed bird appears, seemingly out of nowhere.\n\nHere’s a gallery: Going deeper into neural networks.\nCloudscapes with hidden cities. Leaves that turn into birds and insects. Angels in the architecture.\n2.\nThere are so many things to love about Paul Ford’s epic Businessweek-takeover essay What is Code? but I’m taken with his insistence on treating the computer as a physical thing – which is of course it is, all teeny-weeny electrons and stuff…\nWhat are the steps and layers between what you’re doing and the Lilliputian mechanisms within?\nJust as the keyboard is waiting for a key to be pressed, the computer is waiting for a signal from the keyboard. When one comes down the pike, the computer interprets it and passes it farther into its own interior.\n3.\nWhat do they call turkeys in Turkey?\nAnswer: Hindi.\nIn Hindi, a turkey is called Peru, which is itself a borrowing from the Portuguese.\nThe Language of the Birds is an angelic language, a divine language which predates and supersedes human speech, used by birds, understood by the initiated.\nThere’s a funny-peculiar reference in Understanding Media (Marshall McLuhan) to Jason’s quest for the Golden Fleece, and his sowing of dragon’s teeth which grew to become the spear-tips of a new army. McLuhan enlists the legend of the dragon’s teeth as an allegory for the development of the alphabet and, at the same time, bodies of armed men.\nSaying thank you in Hindi destroys intimacy.\n4.\nData furnaces:\n\nMicrosoft has a lot of servers, mostly sitting in large data centres, producing huge amounts of heat – heat that is a massive nuisance to deal with. … Instead of finding a novel way of transferring waste heat away from the data centre, the research paper proposed that the servers themselves should be placed in homes and offices, where the waste heat could be used directly.\n\nData furnaces arrive in Europe: Free heating, if you have fibre Internet. Nerdalize is rolling out eRadiators in the Netherlands, providing 1000W of heat.\n",
    link: "/home/2015/06/16/conversational_uis",
  },
  {
    title: "More on conversational UIs",
    date: "17.51, Sunday 28 Jun 2015",
    content:
      "ICYMI, last week I dropped a ton of links + speculation on text messaging as user interface… Read it here. Alternatively catch up with:\n\nFutures of text by Jonathan Libov of Union Square Ventures is a far, far better article than the one I wrote: A survey of all the current innovation in text as a medium. Plus: animated GIFs\nWired: The future of UI design? Old-school text messages is a quicker, more readable overview, and some neat extra points… It may always feel silly to talk out loud to Apple’s virtual assistant; maybe Apple should let us text Siri instead.\n\nI wanted to add a few more links.\nLark is a weight-loss coach that communicates with you exclusively through messaging.\nHello Lamp Post (detailed project page) is a playful SMS platform, inviting people to strike up conversations with familiar street furniture using the text message function of their mobile phones. Including escalating intimacy:\n\nTo help players feel as though their relationship with objects could develop, we built in a friendship mechanic - initial conversations would be a bit small-talky, about the weather and observations on the local environment, but on repeat visits the questioning of the objects would change, to focus on opinions, memories and beliefs.\n\n(Unique qualities of text-based conversational UI… user-initiated conversations and app-initiation conversations feel the same, unlike regular apps; the element of time allows pauses and rhythms, like free-to-play games; it’s how we already talk with our friends.)\nDesigning for text-based interfaces is going to take some experimentation.\nWhat is conversation? is some decent theory… might be useful as a framework to talk about how conversations are structured and what’s they’re for. (Thanks @matt_thinkux.)\nThe word “just” creates a parent/child relationship. The article is in the context of women in the workplace, but this is an important point about language: Should a bot display deference? What should its stance be?\nI’m definitely more into how all of this feels – Alexis Lloyd (at the New York Times Research & Development group) wrote up her experiments: Our friends, the bots? I was curious to see what it would feel like to have a bot that was trying to engage as part of a social group\n\nI haven’t yet found the right words to characterize what this bot relationship feels like. It’s non-threatening, but doesn’t quite feel like a child or a pet. Yet it’s clearly not a peer either. A charming alien, perhaps? The notable aspect is that it doesn’t seem anthropomorphic or zoomorphic. It is very much a different kind of otherness, but one that has subjectivity and with which we can establish a relationship.\n\nAnd:\n\nThe conversation about how to define the bot’s relationship to us really elucidated the idea that we are moving toward one member called “non-human mental models”. We are beginning to understand machine subjectivity in a way that is in keeping with its nature rather than forcing it into other constructs, like a person or an animal.\n\nThis I love. \nIt’s not just bots. How do we speak with non-humans, on their own terms? What does a bot want? Or a penguin, or a rock, or the military-industrial complex. Do we need human translators who can hold empathy for them on our behalf? Do we need a speaker for the thermocline? See also: The Author of the Acacia Seeds, Ursula K. Le Guin.\nThere’s a hashtag used by speakers for the bots: #botALLY.\nWhat?\n\nwe are kind and gentle botmakers, allies to bots of all kinds and creeds\n\nFound via that tag, a tool to help make Twitterbots: Cheap Bots, Done Quick!\ne.g. @infinitedeserts, an infinity of deserts, each more infinite than the last.\n(I’m no stranger to twitter bots, I made a presence machine and retold 99 Secrets – both now silent.)\nMore on writing twitter bots, without code. More on writing twitter bots, with code.\nLastly:\nTelegram Bot Platform. (Telegram is a messaging app with 60+ million monthly active users; it’s growing fast.)\n\nBots are simply Telegram accounts operated by software - not people - and they’ll often have AI features. They can do anything - teach, play, search, broadcast, remind, connect, integrate with other services, or even pass commands to the Internet of Things.\n\nNeat about Telegram’s approach, #1: Bots can now provide you with custom keyboards for specialized tasks (examples are shown). Any good bot platform is going to have to do this, typing is too cumbersome otherwise.\nNeat about Telegram’s approach, #2: any message from your bot forwarded to a person or group is a messaging equivalent of a retweet - bots are viral. \nThe really unique feature about conversational UIs is that messaging is social. Introductions can be made. Bots can take part in group conversations; facts can be remembered and shared. There’s a figure and a ground.\nEnough!\n",
    link: "/home/2015/06/19/filtered",
  },
  {
    title: "Filtered for bad things",
    date: "12.05, Friday 3 Jul 2015",
    content:
      "1.\nMountains that talk about bad things.\nIt’s weird:\n\ntwo friendly mountains loudly reciting tweets from around the world. … [a tweet using the word ‘bad’] is picked up and converted by a text-to-speech engine, then loudly recited by the mountains in realtime.\nYou can also visit this world by using a smartphone to have a 360 degree VR experience as one of the villagers living below the mountains.\n\nBit shonky in that sometimes the voice of the mountains disappears for me, or the tweets doesn’t come through. Reload and retry.\n2.\nOsper is mobile banking - and a credit card - for kids. Jeez, I’d happily use this.\nThere’s a new mobile-only bank coming to the UK, called Atom.\nI’m into this. Unbundle the banks. Experiment with different interfaces for consumer banking.\n3.\nHey, so what if the dinosaurs were raptured? Like they were all good Christians and they all ascended and the mammals and birds are the Left Behind and it wasn’t a meteor after all.\nThat’s what I thought this book was about, but it turns out Rapture of the Raptor is dinosaur erotica instead.\nSee also: Taken by the T-Rex.\n4.\nCrystal shows you the best way to communicate with any coworker, prospect, or customer based on their unique personality.\nIt’s an email plug-in that tells you what phrases to change.\n\nCrystal analyzes public data to tell you how you can expect any given person to behave, how he or she wants to be spoken to, and perhaps more importantly, what you can expect your relationship to be like.\n\n",
    link: "/home/2015/06/28/more_on_conversational_uis",
  },
  {
    title: "Filtered for coherent narratives",
    date: "21.40, Monday 6 Jul 2015",
    content:
      "1.\nThe Phantom Time Hypothesis suggests that the early Middle Ages (614-911 A.D.) never happened the implication of which is that Charlemagne was a fictional character and that the year is not 2015, but actually 1718. Somebody jumped the calendar forward; documents were forged.\nMixtape of the Lost Decade: evidence is mounting that points to a ‘lost decade’ between what we now remember as the 1970s and 1980s. Art, toys and music are all rediscovered – a distinct era, the 19A0s.\nThe Internet was better during the 19A0s.\n2.\nThe city of Guntrum at OpenGeofiction, a Google Maps-style collaborative fictional world…\n\nThis world is set in modern times, so it doesn’t have orcs or elves, but rather power plants, motorways and housing projects. But also picturesque old towns, beautiful national parks and lonely beaches.\n\n(About.)\nAntarcti.ca, founded 1999, was a web search engine that mapped results to a virtual reality representation of the continent of the same name. More:\n\nThe display of search results was a 3D landscape, complete with clusters of structures (related topics) and multilevel buildings (important sites).\n\nAnd:\n\nThe impetus for the Anarcti.ca Visual Net is Mr. Bray’s long-held belief that users find a shared landscape a comfortable, intuitive way to explore various types of information … a “shared landscape” makes complex arrangements of data usable by the human mind.\n\n3.\nA timeline of events in the history of the Pokemon world.\nTransformers: A History.\n4.\n\nSurkov is one of President Putin’s advisers, and has helped him maintain his power for 15 years.\n\nAdam Curtis on Vladislav Surkov and non-linear warfare [video]:\n\n[Surkov] came originally from the avant-garde art world … what Surkov has done is to import ideas from conceptual art into the very heart of politics. His aim is to undermine peoples’ perceptions of the world, so they never know what is really happening.\n[creating a politics where] no-one was sure what was real or fake … A ceaseless shape-shifting that is unstoppable because it is undefinable\nA war where you never know what the enemy are really up to, or even who they are.\n[using] the conflict to create a constant state of destabilized perception, in order to manage and control.\nWe live with a constant vaudeville of contradictory stories that makes it impossible for any real opposition to emerge, because they can’t counter it with any coherent narrative of their own.\n\n(Transcript.)\nSurkov published a short story in 2014, just before the Russian invasion of Crimea, Without Sky, set in the future, after the ‘fifth world war.’ Review in the LRB:\n\nIt was the first non-linear war. In the primitive wars of the 19th and 20th centuries it was common for just two sides to fight. Two countries. Two groups of allies. Now four coalitions collided. Not two against two, or three against one. No. All against all.\n\nSurkov: The only things that interest me in the US are Tupac Shakur, Allen Ginsberg and Jackson Pollock. I don’t need a visa to access their work. I lose nothing.\nRussia. Pollock. Modern art was a CIA weapon – The Central Intelligence Agency used American modern art - including the works of such artists as Jackson Pollock, Robert Motherwell, Willem de Kooning and Mark Rothko - as a weapon in the Cold War. Why?\n\nBecause in the propaganda war with the Soviet Union, this new artistic movement could be held up as proof of the creativity, the intellectual freedom, and the cultural power of the US. Russian art, strapped into the communist ideological straitjacket, could not compete.\n\nPatronage:\n\nThe centrepiece of the CIA campaign became the Congress for Cultural Freedom, a vast jamboree of intellectuals, writers, historians, poets, and artists which was set up with CIA funds in 1950 and run by a CIA agent.\n\nSeveral inches were cut from Jackson Pollock’s Mural by Marcel Duchamp in 1943, so it would fit in Peggy Guggenheim’s apartment.\nThose inches of canvas have never been found.\n",
    link: "/home/2015/07/03/filtered",
  },
  {
    title: "Coffee morning next week",
    date: "09.56, Friday 17 Jul 2015",
    content:
      "It’s been super ages since the last hardware-ish coffee morning. I’ll be hanging out in Old St next week if anyone wants to join…\nThursday 23rd July, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nHere’s what happens. i.e. v informal; just chatter; it’s nice if you’re interested in the hardware world but not mandatory; it might just be me doing my email all morning or it might be a few of us.\nAnyway it would be lovely to hang out so do come along. See you next Thursday!\nTwo other things\n\nEmail. You can subscribe to get infrequent coffee morning reminders to your inbox, join the coffee morning announce list here.\nSan Francisco. I’m going to be in the Bay Area in a couple of weeks, so I’d be up for doing a hardware-ish coffee morning in San Francisco if there’s any interest… say Thursday 6 August. What do you reckon? Would you come? Where would we find coffee and a table or two?\n\n",
    link: "/home/2015/07/06/filtered",
  },
  {
    title: "Filtered for unknown lands",
    date: "09.56, Monday 20 Jul 2015",
    content:
      "1.\nTwo utterly gorgeous Twitter bots:\n\n@infinitedeserts, an infinity of deserts, each more infinite than the last. ASCII-art endless horizons and open sky. I can see the mesas, I can see the desert sun.\n@mothgenerator, every few hours a new, random, computer-generated moth, with picture and name. lepidoptera automata.\n\nThe last couple hundred years have been anomalous, historically: we’ve run out of frontiers. Now humanity is pushing on two, outer space and phase space – the space of all possibilities, explored with algorithm probes. Who can say what we’ll find.\n2.\nList of our dwarf planets, closest to the Sun first:\n\nCeres\nPluto\nHaumea\nMakemake\nEris\n\nBut Pluto shouldn’t be categorised as a dwarf planet – we’ve found out that it’s a binary planet with four chaotically orbiting moons. What do we even call that?\n3.\nAquaterra, the various lands now under the ocean previously populated by humans, roughly the size of North America.\n\n“When scientists do mention aquaterra, they often call it a ‘land bridge’ as if ancient people only used it to get from one place we know today to another place we know today. This was not just a bridge. When sea level was low, aquaterra was a vast coastal plain with population densities at least as great as those in the lands above. There were houses, roads, villages and possibly cities. It was all coastal, all flat, and mostly tropical - clearly the best place to live during the ice ages.”\n\nDoggerland:\n\nan area of land, now lying beneath the southern North Sea, that connected Great Britain to mainland Europe during and after the last Ice Age. It was then gradually flooded by rising sea levels around 6,500 or 6,200 BC. … It was probably a rich habitat with human habitation in the Mesolithic period, although rising sea levels gradually reduced it to low-lying islands before its final destruction, perhaps following a tsunami caused by the Storegga Slide.\n\n4.\nRadio Aporee, found via Warren Ellis’ newsletter Orbital Operations where he describes it as a constant stream of field recordings from all over the world.\nRain.today: More radio. Continuous synthetic rain.\n\nAt the core of Rain.today, a stochastic audio engine generates a realistic rain shower by randomly drawing sounds from different categories such as light rain, heavier rain, thunder, and water sounds.\n\nShort story. The Library of Babel, by Jorge Luis Borges.\n\nThe universe (which others call the Library) is composed of an indefinite and perhaps infinite number of hexagonal galleries, with vast air shafts between, surrounded by very low railings. From any of the hexagons one can see, interminably, the upper and lower floors.\n\nThe books in the library are infinite, and the text - of 25 letters - appears to be random - the formless and chaotic nature of almost all the books - no two identical.\n\nOne which my father saw in a hexagon on circuit fifteen ninety-four was made up of the letters MCV, perversely repeated from the first line to the last. Another (very much consulted in this area) is a mere labyrinth of letters, but the next-to-last page says Oh time thy pyramids.\n\n",
    link: "/home/2015/07/17/coffee_morning",
  },
  {
    title: "Machine Supply",
    date: "10.08, Wednesday 22 Jul 2015",
    content:
      "I read a bunch of books – here are the books I read in 2008 which was a particularly good year. Some books are comfort blankets (Red Mars, Kim Stanley Robinson), some are like the best hikes: a steady workout on the muscles accompanied by epiphany after epiphany after epiphany (Philosophy & Simulation, Manuel DeLanda). Ursula le Guin makes me forget where I am. Three Men in a Boat (Jerome K. Jerome) makes me laugh out loud, and was the first book recommended to me by Angela. We’re now married. So.\nLast week I was having a beer with Ben and Tom (literally everyone in this industry is called Ben or Tom or Matt), swapping sci-fi recommendations. It wasn’t for finding new books, or at least not exclusively – knowing what books someone loves is to know a person. I read 104 books in 2008, that was tough going. In the maybe 70 reading years I have available - mod a life-extending singularity cascading its way into reality - I could read a maximum 7,280 books. At all, ever. There are 6,000 books published every day. Knowing what books someone loves is to know their perspective and their journey, to have something special in common, to share a language.\nI heard once that geeks come in two flavours: those who read A Thousand Plateaus; those who read Godel, Escher, Bach.\nI’m ATP through and through. It changed my life. Here’s chapter 1 as a PDF, I used to keep it printed by the door to give out to Jehovah’s Witnesses. It’s a philosophy roller coaster, a call to arms. Didn’t get on with GEB.\nI’m Starship Troopers not Dune, The Beatles not the Stones.\nRecommendations\nAnyway, I like to collect book recommendations. Sometimes I even read the books. At conferences, for years, I’ve asked people for their 3 recommendations.\nNot favourites. Not the books they think I ought to read. Just 3 recommendations, whatever’s on their mind. I try to find a board and some post-its and get people to share. Here are some recommendations from Design Engaged in 2004 where I met so many friends for the first time. Here’s Matt Jones’ version of the same question from Foo in 2014 – I wasn’t there, but touchingly the board is titled “The Matt Webb question: What 3 books should I read this year?” Thank you! I’ll be at Foo in a couple of weeks, let’s do the same session.\nI love to share my recommendations with other people. Here are the books I read in April and May 2015.\nSo I made a website.\nMachine Supply\nAt Machine Supply I can make a book recommendation by pasting in an Amazon link and writing a short paragraph. Then when I share a link to that (on my blog or on Twitter), my reason comes joined together with two Amazon links… one to the US site and one to the UK site. That’s always been a niggle for me, to bundle those things together, to make a recommendation which is easy to share.\nI’m classing this as a hobby, which means I’m trying to make the kind of website that I’d use. I’m not a hugely early adopter generally. I don’t spend much time kicking the tyres of online services, I need encouragement to keep using things because I’m enormously forgetful, and I’m hugely sceptical about putting words I write into other people’s databases rather than plain text on my own laptop.\nAll of which means – that’s what I’m making. A website to make it easy for me to share book recommendations. Here’s my recommendation for The Peripheral (William Gibson), and here it is again as it appears on Twitter.\nWhat was amazing – and honestly what I hoped would happen, and what I’ll make sure the site encourages to happen, but didn’t know whether it would happen or not - what was amazing is that a few friends tried out Machine Supply when I tweeted about it yesterday.\nAnd already I’ve seen @blech recommended Spacesuit: Fashioning Apollo. (Now bought on Amazon.) And @chrbutler recommended The Book of Strange New Things - which I also love - and by the way mentioned four other books, one of which is a deeply loved favourite of mine, and the other three I hadn’t heard of. So those are now on my books-to-check-out list.\nWhat next?\nAs it says on the front page, Current status: Pre-pre-alpha, hobby. Links will break. Cities will fall.\nI’ve got a hobby! Haven’t had one of those in a while.\nHave a play. Let me know if anything breaks. My aim is to make a handy, finely-tuned little crystal. Any and all ideas welcome.\nMachine Supply is over here.\n",
    link: "/home/2015/07/20/oh_time_thy_pyramids",
  },
  {
    title: "What’s new on Machine Supply",
    date: "14.13, Thursday 23 Jul 2015",
    content:
      "Okay! So since I first tweeted about Machine Supply 48 hours ago, there have been 46 books recommended by people-who-aren’t-me! In case you missed it, here’s where I explain what Machine Supply is.\nAnd, for example, here’s my recommendation for Wild Life.\nI have also earned Amazon affiliate fees totalling - drumroll - $3.30.\n$$$\nTo celebrate I’ve added a simple way to see new recommendations – once you’re signed in, there’s a “What’s new” page which lists the 15 most recent.\ntbh I’m not totally happy with the functionality, but it’ll do as a start.\n",
    link: "/home/2015/07/22/machine_supply",
  },
  {
    title: "San Francisco hardware-ish coffee morning",
    date: "20.37, Wednesday 29 Jul 2015",
    content:
      "Last week’s coffee morning was awesome – 20 people, a bunch of demos: music-box software, razor handles (not all hardware is internet-connected), battery monitoring tech for sub-Saharan Africa. Tons of chitter chatter. I promised to send an email with a list of who was there, I’ll do that soon.\nBut first! Next week I’m in San Francisco, so I figured, well, we could have one there. Let’s try this…\nThursday 6th August, 9am-ish for a couple of hours. Sightglass Coffee, Soma district (270 7th Street, San Francisco.)\nHere’s what happens. It’s so informal, no introductions. We just find a table and talk about the weather and the cricket. It’s nice-not-compulsory to be interested in the hardware world… do bring a demo if you are, I’m always curious to see what’s going on.\nI’ve never been to Sightglass before. It might be terrible. I’ll try to make the world’s tiniest sign on a post-it.\nAnyway ALSO I’ll be at Foo Camp which is this coming weekend, so do say hi if you’ll be there too.\nIt’d be lovely to hang out. Londoners, normal service will be resumed soon. Keep your eyes on the announce list.\n",
    link: "/home/2015/07/23/whats_new",
  },
  {
    title: "Third eye",
    date: "09.36, Monday 10 Aug 2015",
    content:
      "I started The Martian on the tube – it’s survival sci-fi, told as a diary. I’m a few in-story days in. Also, because my commute is long, I started playing the text-adventure-interactive-fiction Photopia after a tweet by @tomstuart and it’s all fast cuts - cinematic really - and my train pulled into my station just as I was typing, reacting to [redacted urgent scene].\nThen two minutes later, walking on the street, my phone buzzed: It’s a notification for a fictional voicemail on the fictional phone belonging to a  fictional person from The Thick of It. @losowsky turned me onto this app, Malcolm Tucker: The Missing Phone. I thought I’d played all the way through yesterday, but it turns out I’m still inside the drama.\nSuddenly I’m intermezzo in three narratives simultaneously - all urgent in a time dimension that is moving forward only sporadically - plus IRL – I feel like an eye has opened in the back of my head and this is the feeling of looking into a dimension where I couldn’t even see blackness before, in a direction sideways to space, sideways to time.\nNow here I am, on Mars, in London, with a lost phone, in London, under the hot sun by the pool with a drowning girl, in London, on a street now in a cafe now in an office at a desk, typing\n",
    link: "/home/2015/07/29/sf_coffee_morning",
  },
  {
    title: "Tough on procrastination, tough on the causes of procrastination",
    date: "11.03, Wednesday 9 Sep 2015",
    content:
      "Between one thing and another I’ve not been posting much here recently. I’d like to say it’s because I’ve been busy, but I think that’s insufficient cause. Rather, there are three factors:\n\nToo much busyness of the wrong kind. I’ve been busy with travel, client work, formally and informally advising startups, coffee meetings, email to arrange coffee meetings, life admin… all of which feels good and helpful, and generating of opportunities. But I’ve been neglecting my own projects (I include writing here in that category). Which means I’ve both lost momentum and acclimatised to that loss of momentum. Not only have I deprived myself of the energy that comes from personal creative activity, but this is compounded by:\nProcrastination. For me, procrastination often comes from being disconnected from my feelings – it’s fine to not want to do something, the killer is not knowing whether I want to do something or not. Procrastination is an emotional strategy. My capacity to do even unrelated tasks reduces, as I slow down on the task at hand. Recently I’ve been doing a lot of figuring out what I want out of the future, and I’m not familiar with listening to that part of myself. Between busyness and procrastination, I’ve been hit by:\nThrashing, where I spend more time moving between things than doing the things themselves. Which further reduces my capacity for productive endeavour, which strengthens the conditions that lead to thrashing, which… Etc.\n\nHow to break the loop?\nI don’t know, but here’s a possible strategy: Re-build a habit of personal creative output by climbing the ladder from whatever I’m doing now. I tweet and post photos on Instagram quite happily, and the next level up is writing here.\nSo, move my fingers, attempt not to think too much about quality, the objective is to start with a blank document and end up publishing it. Repeat.\nRepeating might be difficult because I’m imminently off on my summer hols. I’ll start when I get back…\n",
    link: "/home/2015/08/10/third_eye",
  },
  {
    title: "Half-caste",
    date: "14.13, Sunday 27 Sep 2015",
    content:
      "Who Am I isn’t a question I spend much time thinking about, but it’s sufficiently complicated that when I do, I can’t quite get a handle on it.\nMy dad was from north London. My mum’s Indian, and what we’d call now a first generation economic migrant – she moved from Kenya to the UK at 18, for work. Met my dad, married, etc. She was born middle-class in Kenya, until relatively recently she’d never been to India: Technically her ethnic group is “East African Indian.”\nSo her family was part of the Indian diaspora. Her dad - my grandfather - my Nanabapa - was himself a migrant, albeit he was three years old when he was brought by his family to Mombasa from the Indian subcontinent.\nWhat does being a migrant mean to your sense of identity? To be Indian in east Africa; to be ethnically Indian in London… but not part of the larger, more cohesive British Asian community? Displaced over generations. What does it feel like? What’s passed on? Apart from the obvious empathies I mean. What subtle, secret gifts have I been given? I don’t know. Food is love. The family is Ismaili, it’s a pretty liberal branch of Islam, and I have a pretty liberal family.\nI’m mixed race, but I don’t look it. I look white. I grew up in a particularly white part of the UK, I speak only English, I’ve never set foot in a mosque. I’ve been to India on work, and to watch the cricket. Every so often white-appearing people say mildly racist things to me, or mildly Islamophobic things, expecting I’m like them. I’m not.\n(Nairobi: Sitting at the back of my grandparents’ house eating fried egg and chips and buttered chapatis. The smell of the red soil after the rain.)\nBeing half Indian and not looking it. I’m met with scepticism when I tell people, white, Indian, and mixed. It’s another kind of displacement. What I’m allowed to claim and what I’m not. It can feel like I have a tenuous grip on my background, on my ability to honour my origins.\nSometimes when I imagine my identity, I feel instead an allegiance to the people of the future – 22nd century people of tangled roots and chai skin.\nBut we were on holiday in Sicily the last couple of weeks, and we got talking to a few young Sicilians. The culture of Sicily is incredible, Greece, Carthage and Rome all on top of one another; Norman castles with Arabic interiors; halfway between Africa and Europe, a powerful centre to the Mediterranean. People there have light hair and dark hair, brown eyes and blue eyes, all shades. Italian. We were chatting to one light-haired girl and her dark boyfriend: I’m Norman, she said, He’s Arab.\nThe Normans were Vikings who settled in France. They invaded England (and won). They came to Sicily a decade or two short of a thousand years ago. A thousand. The Arabs: Twelve hundred years ago. I’m Norman, he’s Arab.\nI have a thousand hedged affiliations. Half-caste, is what we used to call ourselves when we were little, watching out for the shocked look in response when we said those crude words. I’m proud, is what I am.\nLater:\nWhenever I link to this post, a couple of people (politely! correctly!) point out that ‘half-caste’ is something that some folks now find offensive. The thing is, it is. And more than I realised than when I was a kid… the shock I saw in people’s eyes was real. But. It’s a term I can say about myself that others aren’t allowed to say about me. There’s a little shard of ownership I can hold onto there, something that I don’t really have anywhere else. It’s mine and I think that’s why I continue to use it. –Matt, June 2016\n",
    link: "/home/2015/09/09/procrastination",
  },
  {
    title: "Filtered for space",
    date: "18.41, Monday 5 Oct 2015",
    content:
      "1.\n8,400 photos of Nasa’s missions to the Moon, all in high res.\nSee some examples.\nI’m using John’s Background Switcher to automatically change my desktop background every 30 minutes to one of these photos. To do this: Create a picture set that gets its pics from Flickr and just a certain user. Use the username 136485307@N06.\nSee also: NASA Graphics Standards Manual (1976).\n2.\nTowards a Jupiter Weather Forecast which caught my eye basically because of this diagram of Jove.\n3.\nGORGEOUS geometric animations by Guy Moorhouse.\nAnd how he makes them. Process, source code, etc.\n4.\nNatural Born Cyborgs? by Andy Clarke:\n\nWe tend to think of our biological brains as the point source of the whole final content. But if we look a little more closely what we may often find is that the biological brain participated in some potent and iterated loops through the cognitive technological environment.\n\nSome old notes (on this blog) on Stewart and Cohen’s concept of extelligence, from Mike Holderness:\n\nYour extelligence, then, includes all the elements of what it is like to be you which do not reside in that unlikely grey goo in your skull.\n\nLook, I know the time even though that knowledge is on the lock screen of my phone, not in my skull.\nWhat happened to me this morning was that I had the strongest feeling I was supposed to be in a meeting this afternoon – and that I’d deleted this from my Google Calendar and forgotten it. I’ve definitely deleted something - who knows what - and given nobody has gotten in touch, I guess it was meant to be deleted. But still, the feeling.\nThis feels like a new feeling. I get that tip-of-the-tongue sensation every so often, and it feels like it’s located in my mouth. I know it’s not, it’s in my brain, but it’s tangled up with my tongue and by rehearsing syllables I can sometimes retrieve the word.\nThis feeling - this new feeling - feels like tip-of-the-tongue but located in my Google Calendar, somewhere in the aether. Super weird. The feeling of minor cognitive dysfunction in my exoself.\n",
    link: "/home/2015/09/27/half_caste",
  },
  {
    title: "Small groups and consultancy and coffee mornings",
    date: "12.05, Wednesday 7 Oct 2015",
    content:
      "There’s something in my head about small groups, and consultancy, and coffee mornings. It’s a hypothesis I’m running with to shape my own practice, and I’m darned if I can get it on paper. What’s in my head isn’t an essay, it’s more like a mini Wikipedia of articles and associations. I chat with friends about this hunch I’ve got, and the experiments I’m doing. And the person I’m talking to says: You should write that down.\nAnyway. I’ve not been able to. So I’m just going to keep typing until it’s all there, and not worry about whether it’s well structured or original.\nOr readable.\n~\nFrom the introduction to Hocus Pocus by Kurt Vonnegut:\n\nWhatever the reason, [the author] wrote this book in pencil on everything from brown wrapping paper to the backs of business cards. The unconventional lines separating passages within chapters indicate where one scrap ended and the next began. The shorter the passage, the smaller the scrap.\n\nThe story is disjointed. It appears only while you’re in motion, giving you the sensation that the story world exists not on the page but in your head – and you’ve done the work to put it together, so it’s more real for that. Like reading Markson.\nSo I wonder whether it’s possible to use that process in reverse: Write the scraps in whatever order, squint, and see what kind of logical pattern emerges. If any.\n~\nA recurring pattern in the consultancy at BERG was product invention workshops: get a good understanding of the material, the business, and the customers, all in a room together, and work through sketches. See what happens in three days.\nWorkshops had other benefits. They were a simple and relatively low-cost way to see whether the studio and the client got on. We could trial a hundred ideas and surface hidden desires and obstructions quickly. The workshop could demonstrate that design was work, not ivory tower thinking. All of this process faster because it was face to face.\nAbsolutely exhausting, but useful. Jack and I developed our workshop patterns in 2007, and they were 10x’d by Matt Jones when he joined in 2009.\n~\nOne permanent pattern in our workshop culture:\n\nBest design consultancy tip I know: Don’t criticise without offering something better. Called the Ahtisaari Manoeuvre after an early client\n\nAlways have something on the table.\nAnother: Always use fat pens.\nAnother: It’s important to have the right people in the room – representing knowledge of technical possibilities, business needs, and market insights. But at the same time, the ideal number of people to have in the room is five or six. Any more than that, you can’t continue a single conversation without it turning into a presentation.\nAnother: The one who understands the client’s business best is the client. \n~\nI’m not at BERG now - not for a year - and the consultancy as a regular component of the business ended probably a year before that. Here’s a poem about it going into hibernation.\nSo one of the things I’ve been doing is letting my own individual practice emerge. To see, without steering, what it is I want to do and how I prefer to work. It’s different to what I did at BERG, naturally, and the same in some places.\nI don’t really want to build a new consultancy business, and I’ve got enough to keep myself fed and watered between the various other gigs going on. So I can afford to experiment.\n~\nAuthor Steven Johnson on his writing process (2009).\n\nThe first stage, which is crucial, is a completely disorganized capture of every little snippet of text that seems vaguely interesting. I grab paragraphs from web pages, from digital books, and transcribe pages from printed text – and each little snippet I just drop into Devonthink with no organization other than a citation of where it came from. This goes on for months and months; I read in a completely unplanned and exploratory way\n\nAnd then:\n\nAnd so in the last stage before I actually start writing, I create a little folder in Devonthink for each of the chapters. And then I sit down and read through every single little snippet that I’ve uncovered over the past year or so of research. And as I’m reading them on the screen, I just drag them into the chapter folder where I think they will be most useful. … They feel like pieces of a puzzle that’s coming together, instead of hints or hunches.\n\n~\nCHAPTER 2\n~\nThere are a couple of things I’m investigating:\n\nThat a small group is a powerful way of thinking, and of creating action. That repetition matters, and informality.\nIt might be possible to help with strategy without providing original thought or even active facilitation: To consult without consulting. The answers and even ways of working are inherent in the group itself.\n\nMy hunch is this: To answer a business’s strategic questions, which will intrinsically involve changing that business, a more permanent solution than a visiting consultant might be to convene a small group, and spend time with it, chatting informally.\n~\nA couple of years ago I went on a weekend course to learn about group processes, run by the Institute of Group Analysis here in London. They take a psychotherapeutic approach and, well, the best way to communicate experience is through experience, so it’s done experientially.\nWe were ushered into a room and sat in a circle, ten of us. A table in the middle, door closed. And then… nothing. I felt like people were looking at me to say something, probably because earlier - when I’d arrived and gone into the main space which was half full and deathly silent - I’d said, Hey, This feels like a dentist’s waiting room or something. That had broken the ice.\nThis time I wanted to bathe in the sensation of feeling like the group needed me to speak, so I didn’t say anything. Someone else did, introducing themselves. Then a pause, then the person to their left. Then the person to their left. Now the group saw a pattern it recognised, and clung to it.\nThe next person kind of shrugged and smiled. So they were skipped and I’m not sure what happened then. Confusion. So then, the next two hours.\nIn the absence of any driving force, in the absence of anything to discuss or even decide what should be discussed or what would be the purpose of that discussion – what happens?\nThe convener (it turns out there was one, it was the person who shrugged) takes the role of a participant-observer. Following Bion, she declines any effort of the group to grant her leadership.\nThus isolated:\nThe endogenous processes of the group amplify. From within the group, they become seen and felt.\nThere were a bunch of small and large group sessions over the next two days. I felt like I’d grown a new pair of eyes, new legs.\nI don’t have a new language for groups because of this experience, but I did come away with a gut confirmation that the group transcends its individual members. And I’m a little more tuned in, than I would be otherwise, to the internal group negotiations about purpose and norms. And more curious. Mainly more curious.\n~\nGroup Psychotherapy: The Psychoanalytic Approach, Foulkes and Anthony:\nthe whole is more elementary than the parts.\n~\nCo-evolution of neocortex size, group size and language in humans by Robin Dunbar (1993).\nThis paper blew my mind when I first read it, the source of an expanding wavefront rewriting and recomplexifying everything I thought about.\nThe unexpectedly large group size that humans can maintain (150, more or less) is allowed by the fact we’ve replaced picking fleas by speech, which is many-to-many instead of one-to-one. And also a consequence of:\n\nthe intensity with which a small number of key “friendships” (the primary network) is serviced rather than to the total number of individuals in the group … groups are built up by welding together sets of smaller primary networks\n\nThe primary network is composed of approx five individuals. A psycho-physical link:\n\na nose-to-nose distance of 1.7m was the upper limit for comfortable conversation in dyadic groups; this would yield a maximum conversation group size of five individuals with a shoulder-to-shoulder spacing of 0.5m between adjacent individuals standing around the circumference of a circle.\n\n~\nThen Experiences in Groups by Wilfred Bion, which gave me a way to understand that - just as individuals fall into familiar behavioural patterns like “giddy joy” or “awe” or “mothering” - groups have their own familiar patterns they want to fall into. Perhaps as a way to avoid finding purpose, or to avoid work.\nBion calls these familiar patterns the basic assumptions, and there are three: dependency, pairing and fight-flight.\nYou know – maybe, maybe not. But the insight that a group has habits, or strange attractors, or gravities, or desires certain patterns… that the manifold of group behaviours is textured… that insight is sound, I think.\n~\nFrom a summary of Experience in Groups.\n\nQuite a lot of what happens in a Bionian group is strange, quite a lot (for the outside observer) is funny. It may begin with a long silence. Something is expected of the leader or of someone. This finally gets said, and the leader may say, ‘It appears that something is expected of me’ and revert to a silence which sorely tries the patience of the group members. A member may offer a hypothesis about what is supposed to happen, and this is likely to be contradicted by another. People who have not spoken are challenged and do or don’t speak. Some speak too soon and too often. There is often a search for something, something believed to be hidden and meant to be discovered. Members seek the approval of the leader, others seek alliances, some have strong feelings of love or hate or comradeship; others get cross or cry. Occasionally someone leaves, usually to return, sometimes not. Someone bids for the role of leader and gets sniped at. And so it goes:\n\nEtc.\nThat’s what happened at that weekend course. Hilarious.\n~\nThe first keynote I ever did, there were 700 people there, I got up there and I tried to see how long I could stand in silence, just grinning at the audience. Not long. But it felt like being charged at by a bear.\n~\nMoravec describes the conversion of the cosmos into computronium, pure thinking matter:\n\na vigorous physical affair, a wavefront that converts raw inanimate matter into mechanisms for further expansion.  It will leave in its ever-growing wake a more subtle world, with less action and more thought.\n…\nAs the cyberspace becomes more potent, its advantage over physical bodies will overwhelm even on the raw expansion frontier. The Ex wavefront of coarse physical transformation will be overtaken by a faster wave of cyberspace conversion, the whole becoming finally a bubble of Mind expanding at near lightspeed.\n\nSource. \n~\nWHAT AM I DOING?\n~\nSort of coffee mornings, sort of teaching. But neither.\nDurrell Bishop is teaching at the Royal College of Art: Running a product design platform at RCA this term. Hope it will be a functional exploration of form, behaviour, systems, language & skills.\nDurrell demonstrated the Marble Answer Machine in 1992, it’s hard to think of many physicalisations of information and behaviour earlier than that date. The group he’s running at the RCA, last term and this year too, is “Object Mediated Interactions.”\nSo Durrell asked me whether I’d like to help out, in some kind of capacity, and I said: Why don’t we do coffee mornings? And now we’ve been doing this for a term, and we’ve just started the new one.\nOnce a week we get together – a half dozen students, often Durrell, whoever is teaching the course with him which was Stuart before and Oscar now, plus a special guest.\nIt’s just for coffee somewhere or other, on Friday mornings, and we chat. It’s super casual, sharing ideas and references, talking about the brief and design in general.\nI’m curious about informality.\nThe lunchtimes at BERG, everyone around the table with such a broad range of skills and interests… and after Friday Demos - part of the weekly rhythm - the sparked conversations and the on-topic but off-topic sharing… this is where ideas happen too. Between projects but not outside them.\nAnd I think informality as part of the design process is under-communicated, at least where I’ve been listening. So much work is done like that. The students are great at speaking about their work, sure. But mainly I’m interesting in how we induct someone into a worldview, quickly; how we explain ideas and then listen carefully for feedback, accepting ideas back – all conversationally, without (and this is the purpose of the special guest) it turning into a seminar or a crit.\nI think the best way to communicate this “lunch table” work informality is to rehearse it, to experience it. Which is what the coffee mornings are about.\nI try to make sure everyone speaks, and I ask questions to see if I can encourage the removal of lazy abstraction – words that get in the way of thinking about what’s really going on. I’m a participant-observer.\nTbh I’m not sure what to call this. Visiting convener? It’s not an official role.\nI think (I hope!) everyone is getting something out of the experience, and everyone is becoming more their own kind of designer because of it, and meanwhile I get to explore and experience a small group. A roughly consistent membership, a roughly regular meeting time, an absence of purpose, or rather a purpose that the group is allowed to negotiate at a place within itself.\n~\nThese RCA coffee mornings grew out of my experiment with hardware-ish coffee mornings, a semi-irregular meetup in London having a vague “making things” skew… Internet of Things, hardware startups, knitting, the future of manufacturing and distribution, a morning off work. That sort of thing. People chat, people bring prototypes. There’s no single conversation, and only rarely do we do introductions. This invite to a meet in January also lists my principles:\n\nSpace beats structure\nInformality wins\nConvening not chairing\nBonfires not fireworks\n\nI’ve been trying to build a street corner, a place to cultivate serendipity and thoughts. Not an event with speakers, there are already several really good ones.\nIt’s been a while since the last hardware-ish coffee morning. I’ll do another one soon. Join the email announce list if you’re interested.\n~\nAnd the hardware-ish coffee mornings were shamelessly copied WHOLESALE from Russell Davies and his coffee mornings in 2007. Thank you Russell!\n~\nMatt Jones introduced me to Brian Eno’s term scenius.\n\nscenius is the intelligence of a whole… operation or group of people. And I think that’s a more useful way to think about culture, actually. I think that - let’s forget the idea of “genius” for a little while, let’s think about the whole ecology of ideas that give rise to good new thoughts and good new work.\n\n~\nI’ve tried this small group approach commercially. A friend of mine asked me to have a look at a design problem. He’s the CEO of a London startup of about 20 people, the problem seemed simple, a way of organising a single screen on their app.\n~\nTo me the fact this problem was a problem was the interesting part – why isn’t the organisation capable of thinking its way through this decision with confidence?\nI offered to act as a Visiting Strategist and convene a small group to meet a number of times, ostensibly to discuss this issue, but really I wanted to see what this group wanted to do.\nIt didn’t want to discuss the issue.\n~\nMy setup was that I believed the answer to the issue would come from the group, that they knew more about their business than me.\nWhich was true. But I also observed that the purpose of the business had recently changed, and while it could be seen by the CEO that the current approach to this design problem wasn’t satisfying, there was no way for the group to come together to think about it, and answer it together. Previously they had represented different strands of development within the startup. Now the company was moving to having a new, singular, measurable goal.\nSo I started seeing the convened discussions as rehearsing a new constellation of the team members and how they used one-another for thinking, and conscious and unconscious decision making. The group meetings would incubate a new way to think together. Do it enough, point out what works, and habits might form.\n~\nConsulting without consulting.\n~\nI don’t know whether the small group I convened as Visiting Strategist ended up working or not. I ended up participating a little more than I had hoped – I wanted never to hold the whiteboard pen. But maybe to be a good participant-observer you have to participate just as much - not more, not less - as the others. And I think the group needed more time, more repetitions.\nIn particular I felt a psychic pressure in response to trying to maintain the group as un-led.\nBut it felt like we were getting somewhere.\nI don’t think strategy can be outsourced, I think it has to emerge from a company’s nature. So when strategy evolves, there has to be organisational change. When an organisation looks outside itself (for answers that should be derived from strategy) that says to me that it’s not thinking straight, that the organisation isn’t put together quite right yet. An organisation has these informal components, and cross-team small group meetings feel like a good way to weave them in.\nAnd the CEO seemed happy.\n~\nOne of the double binds of selling anything - a product, consultancy - is that word of mouth only works when the value it provides is easy to talk about. You can’t just provide value, you have to provide noticeable, simple-to-point-at value.\nNo bad thing.\n~\nI DON’T KNOW\n~\nI’m not entirely sure where to take these experiments. I’m learning a lot from various coffee mornings, so I’ll carry on with those.\nI had some conversations earlier in the year about whether it would be possible to act as a creative director, only via regular breakfast conversations, and helping the group self-direct. Dunno. Or maybe there’s a way to build a new division in a company. Maybe what I’m actually talking about is board meetings – I’ve been a trustee to Startup Weekend Europe for a couple of years, and the quarterly meetings are light touch. But they don’t have this small group aspect, it might be that they haven’t been as effective as they could be.\nThere might be something with the street corners and serendipity pattern… When I was doing that three month gig with the government earlier this year, it felt like the people in the civil service - as a whole - had all the knowledge and skills to take advantage of Internet of Things technologies, to deliver services faster and better. But often the knowledge and opportunities weren’t meeting up. Maybe an in-person, regular space could help with that.\nAt a minimum, if I’m learning how to help companies and friends with startups in a useful way that doesn’t involve delivering more darn Powerpoint for the meat grinder: Job done.\nBut perhaps what’s happening is I’m teaching myself how to do something else entirely, and I haven’t figured out what that is yet.\n~\nSome art. Some software.\n~\nA write-only language is\n\na programming language with syntax (or semantics) sufficiently dense and bizarre that any routine of significant size is too difficult to understand by other programmers and cannot be safely edited. Likewise, write-only code is source code so arcane, complex, or ill-structured that it cannot be reliably modified or even comprehended by anyone with the possible exception of the author.\n\nThat’s three thousand words of a write-only blog post. Still, it’s all out of my head now. I’d like to use what I’m learning about small groups in some way. This should help me think about what to do.\n",
    link: "/home/2015/10/05/filtered",
  },
  {
    title: "Tomtown",
    date: "10.02, Thursday 8 Oct 2015",
    content:
      "Almost a decade ago, there was a florescence of ambient awareness. Because the web was small, we used websites to share our activity in a way that would be overwhelming now… but back then, provided social peripheral vision, creating a sense of togetherness, no matter where we were.\nSome of the tools I used:\n\nLast.fm which would share what music I had on by scrobbling tracks to a website\nJaiku which put a free/busy indicator - and message - right next to my friends in my phone address-book\nInstant messenger away messages… like a one-time-use status update. My favourite was to write 4!!! then see who messaged me to say 4 what? At which point I’d update my away message: 5!!!\nDopplr which simply said what city I was in right now and where I was planning to be next. Serendipitous meetings with friends in foreign cities, there’s nothing nicer\n(Any more I’ve forgotten?)\n\nMy own take on this was Glancing – eye-contact for small groups, only online. I reached prototype, and I’ve tried to build it again since. But never managed to get it quite right.\nAll the weird side-effects that happened! Having to turn your scrobbles off when you’re playing an embarrassing track… or not: You gotta embrace your inner midget.\nIt’s all Presentation of Self in Everyday Life and face and FoMO.\nComplex, lively, the hurly burly stuff of life.\nThere are a couple of services which have evolved.\n\nFlickr had an element of “what I’m up to right now” but it went all Pro Photography. Instagram leapt in on that low-friction, scrobble-my-view, ambient-awareness thing… but I’ve noticed in the last few months I’m beginning to miss stuff. My community there is too big.\nTwitter used to be, for me, this lovely way of having coffee with people because we both happened to be in the same part of town at the same time. And then it started acting more like old school blogging with this general awareness of what people are up to. And now it’s all about self-marketing, and so busy that unless you’re in the same timezone as someone, you’re going to lose touch.\n\nFacebook does a bunch of these things, but not well. One big room with terrible acoustics.\nHey Facebook’s new campus has the largest open plan office in the world. NO SHIT.\nCan I say something? Email used to be different. You’d spend hours crafting florid, multi-paragraph epics, full of emotion, humour, and anecdote. Imagine giving that much of a shit about an email today.\nThe web is busy now. No bad thing. But much too busy to have a single place to gather my friends around photos, another around status updates, etc. I used to have one community online, and now I’ve got a hundred. And while I can shard them by app (business on LinkedIn, family on Facebook, my global village on Twitter), it’s a lot of effort to maintain that. And it doesn’t make any sense.\nUntil:\nTom Coates invited me to join a little community of his in Slack. There are a handful of people there, some old friends, some new friends, all in this group messaging thingy.\nThere’s a space where articles written or edited by members automatically show up. I like that.\nI caught myself thinking: It’d be nice to have Last.FM here too, and Dopplr. Nothing that requires much effort. Let’s also pull in Instagram. Automatic stuff so I can see what people are doing, and people can see what I’m doing. Just for this group. Back to those original intentions. Ambient awareness, togetherness.\nNobody says very much. Sometimes there’s a flurry of chat.\nIt’s small, human-scale. Maybe it’s time to bring all these ambient awareness tools back, shared inside Slack instances this time.\nYou know what, it’s cosy. I’ve been missing this. A neighbourhood.\n",
    link: "/home/2015/10/07/small_groups_and_consultancy",
  },
  {
    title: "Filtered for flowers",
    date: "15.17, Monday 12 Oct 2015",
    content:
      "1.\nNew trend: Across China, people are sporting plastic decorations on their heads in the shape of vegetables, fruit and flowers.\ne.g. a beansprout.\n\n“Does your country have this yet?” she asked. “It will certainly spread abroad.”\n\n2.\nRelatively recent appearance in the Spanish-speaking world: The word niñ@s. Here’s a fantastic photo by Bill DeRouchey.\nA gender neutral way to say both niñas (meaning girls) and niños (meaning boys and also, historically, children generally).\n3.\nFlowers.\nThe flowers are drawn with code. When it’s written, code is built up with a series of “commits” - a self-contained block of functionality, together with a message by the developer that describes it.\nIf you read the commit messages for these flowers, there’s a poem there.\nFull code here.\n4.\nDisney princesses re-imagined as hotdogs.\n",
    link: "/home/2015/10/08/tomtown",
  },
  {
    title: "Art + tech",
    date: "19.20, Tuesday 13 Oct 2015",
    content:
      "There’s something about art + tech which is niggling at me. The process I’m interested in is when a technology organisation commissions or supports art as a way to understand itself.\nI don’t quite understand this itch or why I’ve got it, so I’ve spent a day looking at examples.\nArt as design\nThe 1951 Festival of Britain… a celebration of science, culture, and manufacturing. This public information film introduces it:\n\nSomething Britain devised … a milestone between past and future, to enrich and enliven the present. A diverse place, of serious fun, and light-hearted solemnity … That’s us. Or some of us. For we’re more than that… We are the Lion and the Unicorn. The Lion is our strength; the Unicorn our imagination.\n\n(Transcript)\nAs part of this: 28 of Britain’s leading manufacturers came together to form the Festival Pattern Group – a collaboration between designers and scientists pioneering the then-new method of x-ray crystallography.\nAll catalogued in the Wellcome Trust’s exhibition, From Atoms to Patterns. Included were table surfaces, lace, plates, carpets, wallpaper, glass, fabrics, and even ashtrays based on the atomic structures of complex molecules like insulin and haemoglobin.\nAnother collaboration between design and science:\nMark Champkins who is Inventor in Residence at London’s Science Museum. His work is sold in the museum shop and includes\n\nthis bi-metallic lampshade that opens up like a flower\na way to wrap your gifts using a vacuum cleaner\nmore\n\nAlso this bouquet of flowers for the Queen, made out of computer punch cards.\nArt as the cutting edge\nChrome Experiments is a showcase of web experiments written by the creative coding community.\nI’m not sure that Google would call this art, but there are over a thousand purposeless-but-beautiful explorations of what code can do in the browser, and you can bet the Chrome browser team is inspired and stretched by what’s contributed.\nOne such experiment: Ocean Wave Simulation.\nPoetic applications of technology…\nThese Air Penguins from 2009. Majestic, silver helium-filled robots that swim through the air like penguins through water. Makes me wonder when we’re going to see gentle acrobatic robots over Trafalgar Square, or in stadiums. Soon I hope.\nThe penguins are by Festo, a German industrial automation company. Festo’s YouTube channel. I’m sure the techniques developed (they create these animal-inspired robots every year) will fold back into the day-to-day.\nArt as revelation\nThe Bell Labs artist in residence programme in the sixties:\n\nVanDerBeek would show up describing phantasmagoric ideas that he wanted the computers to realize and that then Knowlton [the engineer] would patiently explain what the program was actually capable of. Between these poles of reality they produced some of the first computer animation ever. \n\nI look at some of the early films by Lilian Schwartz and I don’t think I’m seeing art as “something to work towards” or even (although it is this too) a kind of buttressing of human meaning to technical work… but as a way of discovering possibility? “Discovering” is too passive a word, the process is two way. The artist reveals and shapes the technology simultaneously.\nSchwartz: PIXILLATION occurred at a time when the computer system was linear in time and space; Programs did not yet control pixels as moving, malleable palettes – Pixillation was made in 1970.\nBell Labs in the 1990s, Listening Post:\n\nviewers are immersed in a sonification and visualization of thousands of simultaneous conversations happening on the internet at that moment in real-time. An arched wall of hundreds of small screens display ever-changing text in a cool glowing blue. Electronically-generated voices in both a pitched-monotone and natural-inflection sing out the text from every corner of the room singly, overlapping, or in strange harmonies.\n\nRachel Duckhouse making visible the hidden social connections between her fellow artists at Banff. Legends.\nThe Xerox PARC artist in residence programme is described here. I’m entranced by the work of Judy Malloy who in 1993 created a smart kitchen (an Internet of Things kitchen, a cybernetic kitchen, a ubiquitous computing kitchen…) as a multi-player text adventure. Her description:\n\nthe devices were a mobile, audio equipped robot, (Ralph Will Clean Up After You) a database food dispensing table, (GoodFood), a pre-narrative video device, (Barbie-Q) and two electronic books. (Sarah’s Diary and the narranoter) The social nature of LambdaMoo was also incorporated into Brown House Kitchen. Players could sit at the table, order meals, and as is usual in LambdaMOO, talk with other players.\n\nAnd there are extracts from Brown House Kitchen here:\n\nlook ralph\nRalph is an aging Will Clean Up After You Unit, manufactured in 2003 by Orlando Kitchen Thingmans. His straight white hair is combed back from his pink, wrinkled simulated skin. When you talk to him, it becomes apparent that his gossip player is stuck in some previous month.\n\nWhat strikes me about this vision of the future is that, unlike other future kitchens, it feels fully realised. This is a world we might live in.\nBut the point of Malloy’s work isn’t to be a vision of the future: It’s (in her words) narrative performance art which is a harder to grasp and much more interesting place to be.\nThere are other residencies:\nNPR discusses the programmes at Autodesk and Facebook. The residency run by Amtrak is intriguing: It was about looking outward, but from what I hear from other Amtrak writers, many used it as an opportunity to look inward.\nArt as irritant\nJohn Chamberlain’s residency at the RAND Corporation (published in 1971).\n\nChamberlain distributed a cryptic memo to all consultants at RAND … ‘I’m searching for ANSWERS. Not questions! If you have any, will you please filll in below, and send them to me in Room 1138.’\n\nSome responses:\nQuit Wasting RAND Paper and Time.\nGO TO HELL MISTER!!\nAn artist in residence is a waste of money.\nArt as marketing\nI’ve run across lots of instances of artists being commissioned for marketing – to get the word out but in a classy way. And of sponsorship of galleries and art prizes.\nYou know, Andy Warhol drawing Debbie Harry as part of the launch of the Amiga 1000. You can’t get any more art.\nBut it’s not the itch I’m feeling.\nWhen the art is outward-facing, as marketing, as communication that runs at the launch of a product and includes no feedback loop into the product’s invention… when this happens, the tech company isn’t using the art to talk to itself, to understand itself.\nThat said, you do get instances where it all comes together, technology and art and adverting and reflection: Another Science Fiction: Advertising the Space Race 1957-1962 by Megan Prelinger.\nPrelinger documents how the tech companies involved in the space race would use science fiction artists to create their adverts, briefing them on their top secret research to make nod-and-wink messages to other companies, and also - because the artists would feed ideas to sci-fi authors - subtly influencing the emerging consensus cosmogony.\nMore here.\nArt as adjacency\nI find it hard to figure out the relationship between Rackspace (a hosting company) and gapingvoid, an artist and now a consultancy. Is it patronage and a kind of “corporate social responsibility,” or access to a fresh well of ideas, or an association – a kind of cultural osmosis that Rackspace believes it needs? \nArt as decoration\nGraffiti artist David Choe accepted equity instead of cash to paint Facebook’s offices in 2005. Choe’s stock is now worth $200 million.\nArt as curation\nSometimes art is about curation, an intervention that creates maybe a binding gravity, or maybe a sense of history or manifest destiny, or maybe a landscape that produces a new language from the spaces opened up between things.\nMy examples here aren’t always from technology companies, but I find them all inspirational none-the-less.\nA Computer Perspective (1971) by the Eames Office for IBM… important milestones in the development of the electronic computer.\nTalk to Me (2011) curated by Paola Antonelli at the New York MoMA, which opened up the territory of computers and humans, talking and augmenting one another. A step away from “interface” into something, well, whatever we’re in now.\nThe New Aesthetic (2011) by James Bridle. Vanity Fair: the visible artifacts of the network, the identifiable places and moments where the digital erupts into the physical. He posted dresses patterned in pixels, camouflage that evades facial recognition, and a map of the places most densely covered by Wikipedia entries.\nCybernetic Serendipity (1968) curated by Jasia Reichardt at the ICA:\n\nthe links between the random systems employed by artists, composers and poets, and those involved with the making and the use of cybernetic devices. Cybernetic Serendipity dealt with possibilities rather than achievements, especially since in 1968 computers had not yet revolutionised music, art, or poetry, in the same way that they had revolutionised science.\n\nHere’s an unofficial archive and a short video of Reichardt opening the exhibition.\nAnd of course: Modern art was a CIA weapon, funded and nurtured to battle in the cultural front of the Cold War.\nArt as content\nEO1 by Electric Objects – a screen that leans against your wall and displays art.\nOnly… this is a TV that sits on its side emitting light. It doesn’t make sense to reproduce oil paintings on it. That’s not art, that’s a screen saver.\nWhat I like is that EO1 launched with an artist programme:\n\nArtworks can take the form of still images, animated gifs, video, generative and web-based works …\nSelected artists will be featured and promoted in Art Club, Electric Objects’s collection of new and original art for EO1, and receive an EO1 prototype plus a $500 commission fee.\n\nArt as a way to explore the form. In a way, like when Medium acquired Matter – long-form content presentation tool acquires long-form journalism organisation.\nArt as reflection\nSix Monkeys by Brendan Dawes with newsletter-sending-technology-company Mailchimp. From the intro:\n\nEmail is often thought of with negative connotations; overflowing inboxes, strategies on how to get to inbox zero … There is however another side. Email is a ubiquitous, easy to understand system, working across any platform that can deliver not just the unwanted and the unloved but often the exact opposite; messages from friends, exciting opportunities, memories of trips taken and a million other things.\n\nWhat is it?\n\nSix Monkeys is a series of six connected objects that look at how we might change our relationship to email by changing the surrounding context of how we interact with it. By placing email within our everyday physical spaces it may get us to look at the familiarity of email in a new light; we may even learn to love it again.\n\nIs this marketing? Well Mailchimp got press in the right places. But I think the key is in the phrase, email in a new light. My feeling is that Six Monkeys speaks best and loudest to Mailchimp and its community of users, keeping them alive to what email really is, not just what it is today.\nAlso this: Each object is named after a famous Chimpanzee used in linguistic research.\nAnother stand-out:\nThe Open Data Institute (co-founded by Tim Berners-Lee, led by Gavin Starks) trains companies and lobbies for open data. But since it formed in 2012, it has also commissioned and exhibited art.\nThe ODI’s Data as Culture programme:\n\nArtworks have included a knitted data discrepancy, a larger-than-life sized electronic sculpture, a semi-sentient vending machine, data collection performances, kinetic objects, and pneumatic machines.\n\nExplore some of the collection here but I know there’s more – I’m seeing if I can lay my hands on the catalogues, or find out whether there’s an online gallery.\nFinal thoughts\nSo I’m not super drawn to art-as-marketing, or even technology-as-artistic-tool – what’s grabbing me is when art is used in some kind of process by a company or organisation to think about itself. Either by commissioning, or via a residency programme, or as some kind of poetic effort or exploration. But not as design, really, or simple patronage. Something else.\nAnd while net.art is brilliant and exciting - a number of artists fizzing as they explore and define a medium - and also art as outsider critique (2005), what’s intriguing to me is the deliberate use of art, by the tech organisation itself, for… something. Whatever it is. If it even knows.\nAn instinctive urge for interpretation?\nConnection?\nHere’s a report on sound artist Bill Fortana at CERN, home of the Large Hadron Collider:\n\nFontana recorded the sounds. The popping, tapping dance beat of the protons’ regular release is underlaid with the hiss of cooling water and the heavy clang of the magnets charging and discharging. …\n[Fontana] listened to the proton source for a moment, and then handed his headphones to Detlef Kuchler, the physicist who prepares the protons and launches them on their journey. …\n“The picture on Detlef’s face was astounding,” [Koek] says. “This was his baby – and it looked as if he had just heard it crying for the first time.”\n\nThanks\nThe reason I’m looking into this is a short (and visual) report I’m writing – I lend a hand at a Large Technology Company You’ve Probably Heard Of, and my hunch is there’s some important stuff here. I’d like to understand it better and to bring to their attention.\nWhile I’m not writing up my conclusions here, I’ve posted the research because most of these projects were shared with me on Twitter and in follow-up emails by a ton of people. Thanks hugely to: @rogre, @paulpod, @hannah_redler, @amcewen, @bull, @uah, @stuartcurran, @iamdanw, @pdcawley, @inthecompanyof, @tomwhitwell, @anabjain, @designscold, @chrisboden, and @monkchips. Special thanks to @gsvoss. Not all of your contributions made it into this list, but each one has been valuable and massively appreciated. Thank you!\n",
    link: "/home/2015/10/12/filtered",
  },
  {
    title: "Why I’m bullish on Twitter",
    date: "15.36, Wednesday 14 Oct 2015",
    content:
      "My take is Twitter has three killer opportunities, invented by users and, apart from the first, ignored by the company itself.\nEveryone else seems to be chipping in on what Twitter should be doing, so this is me joining in. Those three opportunities:\n\nBreaking news. If there’s a traffic jam on my road, I find out on Twitter there’s a bus broken down a mile away. If a politician is caught out playing fast and loose with the truth, Twitter is where the story comes out, and where I find out first. It’s global and hyperlocal, it’s the latest analysis and a direct connection with the people involved. Later on, when I’m reading news, I end up going to the Guardian or Reddit – it feels bonkers given it’s Twitter where I learn about events in the first place. Twitter Moments might be the feature that creates value here, by editorialising trending topics for the mass market. It might not be, but as least the company is thinking about it.\nCustomer service. Look at any brand’s “Tweet & Replies” tab… an airline, broadband, bank, fashion. It’s brands talking to people, it’s customer service. Potential businesses abound – there’s a need for automation, artificial intelligence that divides inbound requests into easy-to-repond-to customer “intents.” Where are the China-style chatbots that talk customers through problems, account management, browsing the product range, upgrades and so on, efficiently backed up by humans only when necessary? Other companies are trying to build this, outside Twitter, but that makes no sense: Customers are already talking to brands on Twitter, and the brands are at breaking point. This is a prime use-case for Twitter when creating a new developer ecosystem, only one that allows for sustainable businesses this time around.\nTV. Watching TV alongside Twitter is amazing, it makes it worth watching a show at broadcast time again… The Great British Bake Off alongside the #gbbo timeline is hilarious. And you know, Twitter is also where I hear about new shows. If I was Twitter, I’d do something like Soundcloud’s enormously clever audio player that follows you round the site as you browse: Perhaps it would be a picture-in-picture feature, integrated with every streaming service I subscribe to. Tap the pic to see the timeline and to invite others to join you. Twitter could be modern mode of video distribution, of socialising around TV; the TV phone-in, and the electronic programme guide, all rolled into one. Or at least, it should try. It should come with a projector too.\n\nBreaking news, customer service, TV. I don’t say these because they’re places Twitter could possibly go. I point them out because users have already demonstrated that this is how Twitter works for them, and because Twitter’s competitors aren’t there. (Yet.)\nI’m bullish on Twitter because these opportunities are obvious, and Twitter Moments and the recent leadership changes hint that maybe they’re ready to take the advantage.\n",
    link: "/home/2015/10/13/art_x_tech",
  },
  {
    title: "Hardware-coffee morning next week?",
    date: "13.15, Thursday 22 Oct 2015",
    content:
      "Let’s do another hardware-ish coffee morning! Next week.\nThursday 29th October, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nWhy? Because it’s been A TRILLION YEARS. Something about summer totally knocked out my routines. Plus all that cricket on the TV. Reduced my efficiency somewhat. The last hardware-ish coffee morning was in San Francisco, I’m still due to write that up.\nAnyway here’s how it works but the short version… it might be five of us, it might be fifteen, we’re all vaguely interested in hardware startups, or making things, or knitting.\nThere’s no structure, no single conversation, it’s super super informal. Come along! And we have an alarming tendency towards the meetup group cosmic death known as TOO MANY DUDES – so if you’re NOT a dude, please take take this as an enthusiastic invitation. Don’t let me sit there with a half dozen men on a Thursday morning for two hours.\nBring a prototype if you fancy showing it round, but no pressure. Always nice to have some stuff to look at.\nSee you then!\nFor email updates, join the increasingly infrequent coffee morning announce list.\n",
    link: "/home/2015/10/14/twitter",
  },
  {
    title: "Filtered for automation",
    date: "11.56, Monday 26 Oct 2015",
    content:
      "1.\nAn autopen or signing machine is a device used for the automatic signing of a signature.\nUsed extensively by US presidents: In 2005, the U.S. Justice Department issued a legal opinion upholding the right of the U.S. President to sign bills by autopen.\nAnd:\n\nLyndon Johnson allowed photographs of his autopen to be taken while he was in office, and in 1968 the National Enquirer ran them along with the front page headline “The Robot That Sits In For The President.”\n\nHere’s the front page: The Robot That Sits In For the President\nSee also LongPen, invented by author Margaret Atwood.\n\nthe LongPen is not an Autopen, which signs your name over and over without your presence being required. Instead, the LongPen does whatever you have just done at your end, including ‘Happy Birthday Marge’ and a picture of a pussycat\n\nSaves travelling when on book tours.\nSo hold me Mom, in your long arms. In your automatic arms. In your electrical arms.\n2.\nOn finding new language for space missions that fly without humans.\n\nUnmanned? Robotic? Unpiloted? Uncrewed? Unoccupied? Unhumaned? Drone? Autonomous? Crewless?\n\nThe problem is that unmanned is sexist; robotic craft can still contain humans; unpiloted is not accurate because there’s still a pilot it’s just not human; uncrewed is not in the dictionary… and besides there is a crew, it’s just several million miles away back at mission control.\nMy feeling is that it’ll become the default to have spacecraft with no human crew, and we’ll end up distinguishing by saying when it does have human passengers, assuming not otherwise.\nJust like with robot cars. We no longer say “horseless” carriage; in the future we won’t say “driverless” car. It’ll be something to point out when there really is a human involved.\n3.\nThe iPhone 6S came out recently, and as usual there were lines overnight outside the shops. At the Apple Store in Sydney, a telepresence robot was 4th in line. Everyone seemed ok about it.\nI remember playing Mario Kart on the Nintendo DS and you could get linked up with real human players to race against – and there was a pretty good A.I. system in Mario Kart so why play against humans? You couldn’t chat. But something… the humanness shone through.\nAndy Serkis playing Gollum in the Lord of the Rings movies. You can see him, through the motion capture and the green screen and the rendered mesh. You can see him right from the back of the CGI.\nYou get that at the theatre – you go and see an opera and you’re right up there in the gods, but somehow you can tell the emotion of the lead from that tiny thumbnail of a face all the way down there on the stage, the feelings shine up and up, they’re larger than life.\nIn the future our great performers will be those who are able to project their humanity through heavy shrouds of computer mediation.\n4.\nSoylent is a food replacement beverage; you don’t need to consume anything else. I think this is part of the modern mindset, these bimodal extremes: Either you eat at Michelin star restaurants, or you go low-cost low-effort; why bother doing anything between.\nThe founder of Soylent is Rob Rhinehart. What kind of person conceives of a product like Soylent? He recently gave up alternating current.\n\nThe walls are buzzing. I know this because I have a magnet implanted in my hand and whenever I reach near an outlet I can feel them. I can feel fortresses of industry miles away burning prehistoric hydrocarbons by the megaton.\n\nAnyway, so he doesn’t have mains electricity. No kitchen, no TV. He powers his laptop and his phone from a solar cell.\nLook, this is what got me. He doesn’t own a washing machine. And so:\n\nI enjoy doing laundry about as much as doing dishes. I get my clothing custom made in China for prices you would not believe and have new ones regularly shipped to me. … I donate my used garments.\n\nUnpiloted? Uncrewed? Unoccupied? Unhumaned?\n",
    link: "/home/2015/10/22/coffee_morning_12",
  },
  {
    title: "Some ideas for banking apps",
    date: "10.55, Monday 2 Nov 2015",
    content:
      "Something interesting is happening in UK retail banking… a transformation – as far as I can tell it’s triggered by the impending (and catchily named) European PSD2 which includes new rules designed to open up access to payment account information to third parties and the UK preparation for this, commissioned by the Treasury and led by the Open Banking Working Group, defining exactly how we’ll be able to, for example, plug apps into our current accounts.\nQ. What?\nA. This:\nIf you’ve ever complained about your sucky bank mobile app, this will let third parties replace it. If you’ve ever used Transferwise because it’s a cheaper and easier way to pay for a holiday hotel, this will open up competition and make the banks get cheaper and easier too. If you’ve ever wondered why, in the UK, we don’t have apps like Acorns which automatically rounds up all your transactions to the nearest dollar, and sweeps the round-ups into your investment portfolio, this will fix that.\nNaturally the UK banks are scared they’re about to be commoditised AND responding with vast and impressive innovation efforts.\nThis is anecdotal. I have a friend who works in retail banking, I’ve had a meeting with a couple of other banks, and I’m hearing faint noises on the grapevine.\nSo I was talking to my friend, and wondering - this opening up of UK banking - which will be a cross between being able to move my mobile phone number between operators (which wasn’t originally possible) and Youtube and iTunes which democratised music production… what will happen?\nIt might be like newspapers. It turns out newspapers were an accident of distribution. They were really good at printing for cheap and getting bundles of papers into every pair of hands in the country. But then the internet emerged as a rival form of distribution, and the newspapers were unbundled – classified ads to Craigslist and then Facebook, ads to Google, breaking news to social media, expert comment to blogs. And as the readers go, so does ad value. It’s a death of a thousand cuts, and although journalism is still useful, it no longer sits catching cash at that valuable mountain pass. We’ll have to find a new way to fund it.\nYou know, no huge loss. It’s important we find a way to properly fund investigative journalism, but it doesn’t need to be these particular journalists or those particular publications.\nOr it might be like Uber.\nWhat happens when driving a car from point A to point B is no longer a specialised profession, when Google Maps can tell you what to do?\nWhat happens to retail banking when…\n\noverdrafts come from a pay-day loan company\nthe mortgage market is frictionless\ninvestments are made with an app that seamlessly integrates with your current account, gamifying savings and the stockmarket both\ngetting a new third party credit card is as easy as downloading an app, thanks to Apple Pay… this could be the golden age of American Express\nswitching your standing orders and direct debits is either automated – or unnecessary, because you take your current account number with you between banks\nand now you’ve almost forgotten who provides your underlying personal bank account, and you haven’t visited a bricks and mortar branch for years, you switch to another current account provide with a cuddly logo, some other bugger who can spend more on marketing because their operating costs are radically lower because they run all their banking with modern web tech instead of ancient and expensive mainframes\n\nGoodbye existing UK high street banks.\nAll of which means the question becomes:\nAs a retail bank, what do you do to ensure you’re not just the plumbing, that you provide enough value that (a) customers come to you and stay with you; and, (b) customers use you enough that there multiple low-friction upsell opportunities to those services that actually make a profit?\nIn short, how can my bank be a platform more like iOS (as gorgeous as Android is, I’m never going to switch because I can’t be bothered to re-download all those apps and learn new habits) and not a platform like my electricity suppler (electric potential is electric potential, switching is a phone call, and I’ll give my money to the folks who build those beautiful fields of windmills thankyouverymuch).\nI was chatting with my friend in banking (remember I said I have a friend in banking) on Friday.\nI said:\nLook, what apps can you build on the current account. Thinking about that service in the US that sweeps your small change… there’s Digit which is a text-message-only artificial intelligence that helps you save money. Clever. Catchy. And I’m sure I read about one that watches your current account and automatically donates money to charity.\nWell there’s a service like that charity one in the UK, something offered by Lloyds that handily and easily donates your spare change to charity: Save a few pennies every time you spend with your Lloyds Bank visa debit card. Problem being I’ve never heard of it.\nAnd of course I haven’t. Lloyds has a thousand products. They aren’t existentially threatened if this particular one doesn’t take off, and it’s a marketing expense anyhow so it’s barely possible to tell whether it matters. But the charity idea is a good one.\nHow about this – spitballing an idea…\nWhat if a consumer bank partnered with an online fundraising service, let’s say Just Giving which makes it super easy for charitable causes to set a goal, and allows individuals to spread the word through their social networks.\nThey partner and set up a new form of charitable giving called “sweep” – it gives your spare change to some some organisation for 3 months, say. And it’s frictionless… one-click for this particular bank if you already have an account, tap and it’s connected, enabled by the technology built to meet European PSD2.\nJust Giving (or whatever service) is crazy incentivised to market this. It’s a competitive advantage, it’s existential for them, they live or die by that KPI. And the bank… well, they do what they do best. Only now their name is out there, customers have both the warm fuzzies and a new incentive to stick with this particular account. Sure other banks will catch up, but keep building apps and get partners whose interests are exactly aligned with getting the word out and making the partnership succeed.\nMaybe the next one-click integration is Square retail payments.\nMaybe buy the Square kit in the UK, you click a button and BOOM you have a small business banking account with insert name of forward-looking UK bank here. Sure you can’t withdraw any cash yet due to European anti money laundering regs but hey the same is true with PayPal right, so come into the branch whenever you’re ready and we’ll do the paperwork. Meanwhile you can run your shop, go ahead, make sales.\nWhere does this lead?\nPerhaps, just perhaps, it leads into a form of customer relationship which is more relevant to people under 40 than in-person meetings and robot voice phone menus.\nWhy shouldn’t I be able to follow my current account on Twitter and get a direct message when my salary hits my bank? And if that same current account asked me, in that same DM, Hey, Matt, look, I can set you up an ISA, you’ve got a couple hundred a month spare to save into it, you up for this Y/N? Sure I’m going to say yes.\nThese are simple concepts to implement. But they’re also forward looking, aligned with strategic interests, and might actually get some attention.\nMy point is, for the UK consumer banks, the ideas are ten a penny. The difficulty, as ever, is going to be the organisational change to take the opportunity, and keep taking it.\n",
    link: "/home/2015/10/26/filtered",
  },
  {
    title: "Minutes of hardware-ish coffee morning, edition 12",
    date: "12.18, Monday 2 Nov 2015",
    content:
      "Hardware-ish coffee morning last week was AWESOME. Thank you for coming - in no particular order - Nathan, Nat who has just launched a new invention studio called Buckley Williams, Maximilian and Heinrich from Kazendi, Rob who is behind the Ockham Razor, creative hardware engineer Saar, Grace from manufacturer PCH International, the Tingbot massive - which is launching on Kickstarter in a matter of hours - Ben and Joe and Ken from Nord, Naomi and Nick who make biofeedback games to regulate breathing at Shift, Josh (hardware accelerator Hardware Pro), Ines (hardware investor C4V), Tony and Christiaan of the accelerating meteor Pact Coffee which recently successfully launched Nespresso-compatible speciality coffee on Kickstarter, David of Pixie Labs, No Mayo Digital‘s Izzy and Clare, shipped-hardware-product BleepBleeps founder Tom, hardware-to-software maker another Tom, Chelsea who is behind the Olly table-top robot currently in development, and OpenSensors Internet of Things platform founder Yodit. And breathe out.\nWhat an amazing group for chitter-chatter and caffeine!\nIncluding me that’s 24 people, and a quick stat – we’re down to two thirds (16) who would probably identify as dudes. Which is not perfect but better than it has been, and on the right trend. Going by my gut, it seems that female founders are a better part of the mix in hardware startups than tech at large, and I hope that goes for inclusivity of all kinds. Whether or not my gut feeling is correct, I certainly want the London hardware community to be a leading edge of London’s inclusivity, and that’s why I track the NADQ at this coffee mornings.\nNADQ = Not A Dude Quotient.\nSo if you’re a woman or not a down-the-line dude, thanks for coming! If you invited someone, thanks! I know it’s a bit weird to keep calling out my coffee morning NADQ like this, but trust me it’s weirder when I sit round a table with six other men on a Thursday morning.\nThere were a ton of new people today. That was lovely to see.\nWhat was discussed?\nHonestly who knows what was discussed.\nHardware-ish coffee morning sprawled over about five tables, with double that many conversations and people continually moving round. I have no idea what people talked about. But I had to leave just after 11 and people were still going!\nI was darting about like a headless chicken so I didn’t get to say hi to anyone and my attention was always elsewhere. BOOOOO. And sorry to everyone I know that I didn’t get to chat with!\nBUT a couple of things I did notice.\n\nTingbot is a lovely add-on for the Raspberry Pi that turns it into a hackable home gadget, a bit like an alarm clock with an app platform. Here’s a pic. What’s special is that it has a dead-simple programming environment, a bit like Arduino, that makes writing and running graphical, internet-connected apps very simple. Tingbot goes on Kickstarter this week – follow @thetingbot on Twitter to get the latest.\nOlly is a robot currently in development (in London) with all kinds of voice features. Chelsea talked about it as being table-top - which is an intriguing context because it feels like that’s where the old school kitchen radio sits - and the character-driven, emotionally-responsive robot she talked about sounds fascinating. One to watch.\n\nWhat’s also interesting to me is that we had pre, post, and intermezzo Kickstarter projects present, from both small and pretty seriously established companies, plus investors and manufacturing. A maturing scene. There’s a lot of knowledge in the room.\n…to the point that, discussing one project that is imminently adding hardware to their existing software-only offer, I can assemble the roadmap with them, 50% from my own knowledge (what the critical proof-points and bottlenecks are, what needs to happen hand-in-hand with what), and 50% simply from looking around and going: Well, first do it like company X, and then do product development like company Y, and finally you will end up speaking with someone like company Z and here are the questions to ask.\nNext time\nLet’s have one more hardware-ish coffee morning this side of the new year. I’ll take a look at my calendar and see if I can pick a Thursday which won’t be too conflicted with the holidays. Join the email announce list, I’ll send a note there to arrange it.\nUPDATE: Tingbot is now on Kickstarter! Go read more about it there. And please back it, I want a Tingbot of my own.\n",
    link: "/home/2015/11/02/bank_account_apps",
  },
  {
    title: "Filtered for reading",
    date: "09.10, Wednesday 4 Nov 2015",
    content:
      "1.\nRod McLaren’s beautiful meditation on spreadsheets, and his spreadsheet art: Sandcastles and Spreadsheets.\n\nThe spreadsheet’s unreality is dangerously doubled because, while their ordered data and formulae always comfort you that you have authored a controllable certainty, most spreadsheets are mere conjectures, provisional plans, ideas or hopes.\nSpreadsheets are dreams.\n\nRead that, next time you have a rainy day with your head buried in Excel.\nRod’s essay is part of Beeker Northam’s larger project, Hand & Brain with William Gibson and several others contributing. Something to get lost in.\n2.\nDonald Knuth helped define computer science. Since 1990, he no longer has an email address: I’d used email since about 1975, and it seems to me that 15 years of email is plenty for one lifetime.\n\nEmail is a wonderful thing for people whose role in life is to be on top of things. But not for me; my role is to be on the bottom of things. \n\nHe replies to his correspondence for 1 day every 3 months.\nJoe Nelson ran with this… Going Off-Line. I will check email once per week, on Monday.\n\nOn Twitter and Github I’ll be entirely write-only. I’ll check replies/messages/issues on Mondays along with my email. …\nI will eliminate all use of the computer that is not directly related to creating things. If I’m not coding, writing, or editing videos then there will be literally nothing to do. I am going to dissociate the computer from mindless fun, from the capacity to kill time online.\n\nI like the idea of taking a write-only sabbatical.\n(Actually, thinking about it, I reckon that’s why I’m enjoying writing on my blog so much. In the old days of blogging, a blog post was part of a conversation. Not today. Barely anybody replies, and when I do get a response it’s lovely or thoughtful and often both. But I don’t know if anyone reads these words; the links don’t get shared out so much. It’s very freeing, like having a notebook with a very slight incentive to better organise my thoughts. And my thoughts improve in that process. Write-only blogging.)\n3.\nWill Self on Stonehenge:\n\n“Don’t you worry about the monument ceasing to be real in an important sense,” I asked. “I mean, with all this messing about isn’t Stonehenge in danger of museumification?”\n\nThe balance between putting the past on a pedestal, and living in it and carrying it forwards.\n4.\nA few years ago, I transcribed and put online one of my all-time favourite short stories, The Author of the Acacia Seeds by Ursula K. Le Guin. My favourite story not just for the ideas, or for the turns of phrase and the humour. But for the gentle, determined build into a wholesale decentering of what it means to be human, and a huge widening of togetherness and empathy to the entire cosmos. Which, it turns out, is what I love science fiction for.\nBut don’t read that.\nBecause here is a video of Le Guin reading from the Acacia Seeds at a conference and oh my goodness it makes me tingle.\n",
    link: "/home/2015/11/02/coffee_morning_minutes",
  },
  {
    title: "Filtered for space and smell",
    date: "18.13, Tuesday 10 Nov 2015",
    content:
      "1.\n2.8 million years ago, a nearby supernova caused apes to come down from the trees.\n\nBased on the concentration of Fe-60 in the crust, Knie estimated that the supernova exploded at least 100 light-years from Earth - three times the distance at which it could’ve obliterated the ozone layer - but close enough to potentially alter cloud formation, and thus, climate.\n\n(You know when Carl Sagan says we are made of star stuff. Fe-60 is a type of radioactive iron that is created only in stars, and gets out only when they explode. There is a very thin layer of Fe-60 dusting our planet, 2.8 million years down in the deposited mud at the bottom of the oceans.)\nThen:\n\nAround that time, the African climate dried up, causing the forests to shrink and give way to grassy savanna. Scientists think this change may have encouraged our hominid ancestors as they descended from trees and eventually began walking on two legs.\n\nWhat an alarm clock for humanity! Where’s the snooze button, let me stay in my tree.\n3.\nVideo of the new sport of drone racing.\nFirst-person drone racing through the trees: You wear a virtual reality helmet, and race the drone along the track through the trees, seeing through a camera mounted on the front.\nThe future!\n3.\nFuture Forms is a collection of space-age electronics, primarily dating from the 1960s to the 1980s.\nGorgeous.\nSee also this gallery of Soviet PCs. Look at how much bright orange there is! Yum.\nI wonder. I wonder. Was it because these PCs were made in the heady days of the Atomic Age?\nA uranium glaze on ceramics has a wonderful glossy, bright red-orange finish. Was the orange uranium aesthetic carried over to plastic PCs?\nIt reminds me of the days in the early 2000s when all electronics had to use blue LEDs to look futuristic – the technology of blue LEDs having been commercialised just a few years before. I saw my first blue LED - hot out of the labs in Japan and brought back to Oxford - in 1998. There were probably a couple hundred of us in the room when the LED was connected to a battery and lit up, and all of us saw the purest blue we had ever seen, all for the first time, the colour of the future. Physics. There was a collective sigh of awe.\n4.\nNatural gas is used domestically for cooking and heating. A leak can explode or suffocate. So an odour of rotten eggs is added, in order that we can tell it’s there when it’s there. For safety.\nSo you wake up one morning after drunkenly playing some VR game and passing out, you forget you’re still wearing your retinal projection contact lenses and your ear plugs are still connected to the virtual world, not amplifying the real. What’s the odour we add to VR so you know you’re still in it? What should be the smell of the virtual?\nSee also, this slide and the next: Blue is the colour of hyperlinks.\n",
    link: "/home/2015/11/04/filtered",
  },
  {
    title: "Like to Continue, a fictionbot",
    date: "14.50, Wednesday 25 Nov 2015",
    content:
      "I wrote a poem on Twitter. It’s 36 tweets long, and happens entirely in your notifications panel.\nOr maybe what I made is a fictionbot. You say “hi” to it and it tells you a story. You get sent each line only when you like the last. The story is about liking, and continuing.\nSo it’s called @liketocontinue and you should just introduce yourself to start. Then watch out for what it tweets at you, and like to continue.\nIf it gets too much attention it’ll break, that’s part of the fun.\nWhys and hows\nYou can tell I’m interested in chatbots and - with my business hat on - I’m especially excited about digital coworker bots, being pioneered by the likes of Howdy which helps you run meetings (see screenshots). All the energy is around Slack which is bot-friendly group messaging for work… a great product and a great marketing strategy: They’ve figured out how to make virality work in enterprise by having a frictionless on-ramp below the expense threshold and treating the team as the viral atomic unit.\nAnd back in the day, I used to make chatbots that you used individually on AIM. For instance, googlematic let you search Google – and that got me a bunch of nice attention, and in a bunch of trouble too.\nBut I’m into Twitter. Twitter is something between these and something different too. Twitter is a place where people talk to each other and groups. It’s not quite personal, and it’s not focused on work… it’s public. I’m curious about what you can do with bots in public space. I’m in love with @mothgenerator and its gorgeous computer-generated moths. But more than that, there’s something for me about interactions that happen over time, and interactions that can start with one person and widen up to more people, sometimes deliberately and sometimes accidentally because they’re visible. It seems like there’s a lot of creative potential there. Stories! Text adventures! Collaborative poems!\nSo much potential.\nWhich is why I’m taking my own advice and exploring the potential with art. Well I say art. Amateur poetry really.\nI wanted to explore the feeling of a like and in particular waiting for a response, especially because Twitter just shifted from faves to likes. So that’s what I wrote. Made. Wrote.\nTechnically, I have a basic Python 3 app that I use to get started on any new project. It has everything I want already set up… sign in via Twitter, a database capable of storing emoji, nice web templates, email error logging, solid deployment to my webserver, and an asynchronous loop to run background tasks like listening for tweet activity. Custom for how I tend to work. It’s taken me a while to get happy with this (my coding is rusty) but it’s neat that I can get something written and live in an hour instead of a week.\nAnd I’ve learnt a ton about the tech things like Twitter limits and what you can and cannot see via the API (such as: you can see @-mentions from users you don’t follow, but you won’t get notified of their likes on your tweets). And lots of details about how to make a system where it won’t break in-progress stories when I edit the words.\nBut mainly I’ve been seeing how reading (and having to like!) tweets feels, versus lines on paper, and how that changes what I write. So I’ve spent most of my time on the words not the code, which is just as it should be.\nI want to keep digging with fictionbots. Like I said above, there’s so much potential. If you’d like to collaborate, I’d be up for chatting… it would be great to work on a little project with someone who can actually write!\nAnyway, nice to have shipped something, no matter how simple, or rather, snuck it out the door. Or rather rather - because it’s a poem - published. I hope you like it.\nUpdate August 19, 2021:\nThis bot hasn’t been online for some time, so I figured I should archive the words here.\nThe poem is read line by line as a series of tweet. The reader has to tap “like” (a heart) on each tweet before the next is delivered. The final line gives no response.\n\nLike this to continue, I’ll tweet you back\nReader, who are you? No need to reply to my questions. Just like, every time (like to continue)\nMe? I like papers with long titles. The Unreasonable Effectiveness of Mathematics in the Natural Sciences.\nThe Tyranny of Structurelessness. Summary: Power always exists. Pretending otherwise means you can’t talk about it\nAnd there are no ghosts. There are no angels. There’s no magic in the universe\nSure when a person is suddenly absent all that’s left is memories of them and what they left behind\nSuch as: The habit of a son to comb his hair to one side\nAnd this legacy has its own weight, its own agency in our lives. What else do we call that but a ghost?\nAbsences are concrete, you know? They’re there, in their own way\nAll those homophones!\nAnother homophone: Like meaning love and like meaning want and like meaning similar. Different meanings, same word\nLike this tweet.\nAlso unreasonably effective? How the Internet carries human feeling. My curiosity. Our togetherness. A miracle\nLike the air carries the smell of rain on the hot earth\nYou know that feeling when someone you love sends you a text? Hey, just thinking about you\nI wonder who you imagined, just then\nHey, if my cat could tweet, would that feel the same? Or is my love for her purely physical?\nHer helplessness and her claws, her fuzzy belly, her struggle with feline aloofness and her affection despite herself\nIs it ok to play lets-pretend on the internet? Or is that telling fibs?\nI miss fiction\nI miss my dad\nThere’s someone who, when you’re writing, you’re writing for them\nHey\nAt the beginning of a relationship, you have to take risks. It’s called turning towards. I think you’re great :)\nomg your fuzzy belly, I want to eat you up!\nWhat if they don’t like it? What if they DO\nVulnerability is scary. You wait. Then they say: Hey, I had fun today\nwith you :)\nYou dance together\nWe dance together\nAnd I’m always there for you, that’s my promise\nIf I wasn’t here it would be an amputation. Not even a ghost which at least does its hauntings.\nAt least a ghost THROWS shit off the SHELVES\nWhen all you want is to hear me say just one more time, hey I like you too :)\nbut i’m not even a ghost. and no matter what you want, there’s no continuing now\n\n",
    link: "/home/2015/11/10/filtered",
  },
  {
    title: "Filtered for air and light and war and stories",
    date: "11.48, Thursday 26 Nov 2015",
    content:
      "1.\nI was complaining out loud the other day about the distracting man I was sitting next to, hammering his keyboard, typing like a donkey falling downstairs. But then it occurred to me, I always blame external factors for ruining my focus when really I lack it for internal reasons. If I genuinely had focus, nothing could disturb me.\nEric piped up with this poem by Charles Bukowski, air and light and time and space.\n\nif you’re going to create … you’re going to create with part of your mind and your body blown away\n\nYup.\n2.\nMuji’s mission statement:\n\nMUJI’s goal is to give customers a rational satisfaction, expressed not with, “This is what I really want” but with “This will do.” “This is what I really want” expresses both faint egoism and discord, while “This will do” expresses conciliatory reasoning.\n\n3.\nMachines generating stories about images.\nHe was a shirtless man in the back of his mind, and I let out a curse as he leaned over to kiss me on the shoulder. (Looking at an image of two sumo wrestlers grappling.)\nUses a technique with the astounding beautiful name of skip-thought vectors, a machine which is able to reconstruct the surrounding sentences of a passage in a book.\nSee also: A video of the same stories-from-images trick being performed from a live webcam feed: a man is eating a hot dog in a crowd.\n4.\nFrom this explanation of Soviet Deep Battle theory, an insight into military science:\n\nWar is no longer a series of short and sharp engagements but rather a flowing affair, with larger, strategically oriented battles (‘operations’) that often encompass several smaller, shorter battles-within-battles (tactical engagements).\n\nWhich leads to approaches:\n\nDeep Battle, or Deep Operations in particular first begins to develop as a theory in the 1920s. Like most developing theories of Mobile Operations at this time, it had one, over-arching goal: Get the battlescape moving, and keep it moving\n\n“Flowing”\n“Battlescape”\nI’ve been skiing like once and my main metaphorical takeaway was that it’s easier to course correct when you’re in motion. Try to turn when you’re going forwards slowly, you’ll tumble. There’s a lesson there for company strategy, and I find myself reaching for this metaphor again and again. But now it turns out that military science understands movement, ability to adjust to circumstances, and flow, in a far richer way than me and my experience on the side of a mountain in Canada.\nWe tell stories to ourselves about what we experience, then we use those stories to approach the world. What stories we choose matters.\nWar has a vocabulary and a philosophy all of its own, and the fact I don’t know anything about it tells me I’m missing out on something valuable – as unpleasant as the subject matter is.\nSee also: Frieze magazine on the Israeli Defence Forces (from 2006) who, it turns out, are heavily influenced by contemporary philosophy:\n\nMost important was the distinction [Deleuze and Guattari in A Thousand Plateaus] have pointed out between the concepts of “smooth” and “striated” space … In the IDF we now often use the term “to smooth out space” when we want to refer to operation in a space as if it had no borders. … Palestinian areas could indeed be thought of as “striated” in the sense that they are enclosed by fences, walls, ditches, roads blocks and so on. When I asked him if moving through walls was part of it, he explained that, ‘In Nablus the IDF understood urban fighting as a spatial problem. … Travelling through walls is a simple mechanical solution that connects theory and practice.’\n\nA startling article.\n",
    link: "/home/2015/11/25/like_to_continue",
  },
  {
    title: "Hardware-ish coffee morning, edition 13",
    date: "20.35, Thursday 3 Dec 2015",
    content:
      "Hey, let’s have a hardware-ish coffee morning next week!\nThursday 10th December, 9.30am for a couple of hours, at the Book Club (100 Leonard St).\nHere’s how it works but the short version is there might be five of us, or there might be 15, and we’re vaguely interested in hardware startups, or making things with paper, or knitting, or Arduino. Or, like last time, we’re into industrial design, VC, and factories. Mainly it’s about caffeinated beverages and hanging out. There are no talks or anything like that, it’s just a coffee shop. Minutes of the previous hardware-ish coffee morning!\nADDITIONALLY. You’ll see from those links that I track our Not A Dude Quotient. If you’re a woman or basically don’t self-identify as a dude, please feel doubly welcome! Let’s be the London hardware scene we want to have.\nUh, what else. Bring a thing if you’ve got a thing to bring. Always nice to see physical stuff, whether it’s a product prototype, a new Pi Zero (I’ve not seen one yet), or your latest origami.\nSee you Thursday!\n",
    link: "/home/2015/11/26/filtered",
  },
  {
    title: "Today’s restaurant reviews",
    date: "14.37, Friday 4 Dec 2015",
    content:
      "On the eve of the activation of the Large Volition Collider, we speak with Dr. Giles Spenser about his favourite London restaurants.\n1. Nando’s\nNando’s was a favourite when I was a grad student, so I get to call myself an old timer.\n\nIt’s where we’re meeting now\n\nYes, and thanks for paying! [laughs]\nSeeing people dress up for spicy chicken burgers though… I’m not sure I’m going to get used to that.\n\nA good last supper before you find out whether your theory stands up?\n\nYes! Well, yes and no. It’ll be a while before the data is crunched. Not as long as it took the first time around.\nThe first time around we didn’t have the computation, it took a couple months for each run.\n\nThis was with Facebook?\n\nYes, with Facebook. At the time, Facebook was this incredible map of human activity. Online, of course, and what we called the Internet of Things, that was all collected into their map too. The Deep Web at the time wasn’t small, but it was statistically not significant. We wanted social interactions mainly.\nSo Facebook was this giant realtime map of enough human activity to be useful. And once a week, I would run my algorithms across it, looking for signs of actual human agency in all the changes. For most changes, you can pin down a cause. A comment is a reply to an article, a video is made because someone missed their train in the morning and had ten minutes free time to think. We can pick up that kind of thing from basic EEG and data mining. But some deltas, some changes in the map that is… some deltas appeared to have no cause at all – spontaneous action.\n\nAliens!\n\nThat was the clickbait, yes. Shortly before I published, Wow Two had been detected, so the explanation everyone reached for was that I’d built a new Seti - a new search for intelligent life - but pointing back at our own planet, our own internet.\nBut not aliens, no, although still from space. Volition. I was looking at particular patterns in social networks, where novelty comes from. There are correlations. And there’s a time element. New ideas, new actions, spontaneous human events… these spike at certain positions in the Earth’s orbit, positions that precess. The view we have now of volition is that it’s the first two dimensional particle, each a mega-scale skein originating at the central galactic black hole, orthogonal to the event horizon. Rotating around the core and rippling, like flags in the wind, trillions upon trillions of them. Where one of these volition 2-branes interacts with our own patterning, potential is raised, and new ideas form.\nThe Nando’s flagship on Regent St currently has a wait of 2 months. Dinner and wine for two, approx. £200-300.\n2. Holland\nThis is my supper club, welcome! Our franchise has been going for two years, we do a weekly dinner. All vegan.\n\nA bit soon, don’t you think?\n\nMaybe, maybe. The Netherlands evacuated Holland what, seven years ago? [Interviewer: Five years.] Five years ago, is that all. And I know a couple of families who are part of the first group moving back in. They’re very positive.\nThe name does upset some people, yes. But I think it’s okay, my friends don’t seem to mind.\n\nWhat’s the best way to get involved?\n\nI joined up without knowing anyone. Bought some suppercoins in the app, earned a few more by doing washing up duty at a few meets, and I think it took just a month or two to earn enough for supper myself.\n\nYou met your wife…?\n\nHere at Holland, yes. We have an allotment together now, so we earn coins by providing food too, and by hosting at our flat. Our group is really well balanced, actually, we’re very proud of that. Self sufficient. We don’t rent space or buy in service from outsiders at all. I think it’s been over a year since we need to use any fiat currency. And it’s a good excuse for us to all meet up, of course.\nThe question for me, obviously, is what made me sign up that first time?\nA volition skein is what made me sign up, it turns out, and when I look back at the records of my social interactions that day, my patterning was just right for resonance, and my potential was raised. So here I am.\nTo join Holland, visit holland.club to buy a starter pack of suppercoins and find a supper near you.\n3. Yo! Sushi\n\nThis was where it all started?\n\nI was watching a roll coming down the conveyor and grabbed it. Why? Because it was there. And I realised that it was there because someone else had placed it, so that action was transmitted between us.\nThat didn’t seem sufficient somehow - proximate causality but not ultimate - so I decided to check into it. To keep digging back. Which was easy then, as I said, because Facebook had mapped so much, before the Deep Web got so significant. So I was lucky, really, that it was tractable, what I wanted to test.\nSo what I’d made, at that point, was a good model of actions and feedback, and the tight knots that happens. I was double-checking, this action matched against these ultimate causes, that action matched against those ultimate causes.\nBut what I found was that I couldn’t account for some tiny proportion! That was what I named volition. Volition, I speculated - maybe only a year after that meal in Yo! Sushi - is independent from human agency. And if so, it could be isolated.\n\nAnd from there to the Large Volition Collider?\n\nThe technical work has mostly come from the community, but at its heart it’s quite simple. The pattern-network we’ve created has been evolved in software, and printing and testing it has taken almost 18 months, over an area the size of Oxford near Lake Eyre. For the flatness.\nThe activation will create a pattern complexity equivalent to, well, not genius level. But a bright 10 year old in a well-formed environment. Once we pass through a volition skein - once Earth on its orbit moves through a skein - the pattern will resonate and we should be able to see the potential rise and new ideas form. Real volition. But it’ll take a long time to sift that out from the noise of the normal pattern-network operations.\n\nThe critics say it’s expensive.\n\nYes, but what we’re looking for is fundamental particle of consciousness itself. If we can find that, what might the applications be? New ideas on demand? Finally identifying the difference between us and the artificial intelligences?\nPersonally I think we should look for ripples in the volition skein and triangulate the origin of Wow Two. See if we can say something back to those aliens.\n\nGood luck Dr. Spenser. \n\nYo! Sushi has 120 London locations. Lunch approx. £100-150. Dinner approx. £150-200.\nFollow us for live coverage of the Large Volition Collider, starting tomorrow at 02:00 UTC.\n",
    link: "/home/2015/12/03/coffee_morning",
  },
  {
    title: "Hardware-ish coffee morning goings on",
    date: "17.30, Friday 11 Dec 2015",
    content:
      "Pretty amazing hardware-ish coffee morning yesterday.\nPlenty of people present packing products or physical prototypes:\nCatlyn and Daniel from BuffaloGrid with their ruggedised battery for simultaneous charging of 20 smartphones. Carried out to communities that agents are visiting anyway (e.g. for banking or deliveries), each port activated individually and paid for by SMS. So there’s a business model and neat distribution. Currently running a trial in India.\nTempest from Science Practice and their super low-cost sensor (like, it costs pennies) for testing soil chemistry, and choosing simply what fertiliser to apply. Uses chips with microfluidics. This is actual cutting edge science. Amazing.\nMatas of Vai Kai from Berlin with wooden dolls for kids. The dolls sense and react to one another, and connect over the internet. They’re made for open play. Currently accepting pre-orders. Matas came along with Kaye and Richard from Paved With Gold, who have helped several startups market their new products.\nAmir from Flitch which is an Android phone case which is also a games controller… and it’s slightly magical: There is no battery, and no connector. It harvests energy from the NFC reader of the phone, and transmits the controller movements back over the same channel.\nPretty good for an event-which-isn’t-an-event! We did the usual – just colonised a few tables in the cafe, hung out, chatted.\nAlso we had: Avril and John who are behind the Ding Smart Doorbell which recently won the Design Council Spark innovation programme (and now they’re making the thing); Marc who organises London’s Mini Maker Faire; Tom from Autodesk who it is super great to see in the scene; Pierre, Jonathon, Lloyd, and Ezo.\nThat’s only 4 out of 16 who aren’t dudes. Not great. I’m going to use the new year to attempt a bit of a cultural reset, maybe change the location or the way I organise these things. HOWEVER – that’s my fault, not the fault of everyone who came. And so:\nThank you everyone who has come to a hardware-ish coffee morning over 2015, both here in London and our special event in San Francisco! Probably 100 or so folks? The reason it’s fun for everyone else is because you are there. It’s been brilliant eavesdropping on the connections being made and the conversations being had. Always surprises and serendipity.\nSo let’s kick off again in 2016 - join the mailing list if you want updates - and in the meantime, coffee morning gang, happy holidays.\n",
    link: "/home/2015/12/04/lvc",
  },
  {
    title: "My latest Twitter bot: @5point9billion",
    date: "13.52, Monday 14 Dec 2015",
    content:
      "Backstory! Exactly 12 years ago today, I made a little web toy called Light cone. It’s still running:\n\nFrom the moment of my birth, light (that I could have influenced) has been expanding around the Earth and light (which could influence me, from an increasing distance of origin) reaching it – this ever-growing sphere of potential causality is my light cone. Today… My light cone contains 70 stars. Zeta Doradus will be reached in in 2 months.\n\nRemember RSS for blogs? The idea was you would subscribe to a live feed of your light cone in your blog reader, and get a notification every time you reached a new star. Now RSS is no longer the new hotness, but over a decade later there are still about 500 people subscribed to that old web toy.\nI enjoyed it as a tiny, cosmic, lovely thing. I included it in the words I wrote in the intro to Mind Hacks way back in 2004, here: p Eridani, hello! It’s still great to look back, to see how far I’ve come.\nSo I figured, let’s drag this thing into the modern age, let’s move this thing to Twitter. (I’ve been making Twitter bots lately.)\nWhat it does\nMy new bot is called @5point9billion which is the number of miles that light travels in a year. The idea is that you follow it, tweet it the date of your birth (e.g. here’s my starter tweet), and then it lets you know whenever you reach Aldebaran or wherever.\nYou get tweets monthly, and then weekly, and for the last couple of days… and then you pass the star. It feels neat, don’t ask me why.\n(Aldebaran is about 66.7 light years away, so light reaching it today left Earth on 1 April, 1949, on the day Gil Scott-Heron was born. I won’t reach it for almost another three decades.)\nThe bot only tells you about bright stars – stars you could see in the night sky with the naked eye from rural areas. I figured it would be fun to hear you were reaching Tau Ceti, and then be able to look for it up there.\n(Tau Ceti is 11.9 light years from Earth, so if you’re almost 12 years old - born at the end of January 2002 - you’re touching it now. Hey and guess what, Tau Ceti has planets! I passed Tau Ceti 25 years ago.)\nSo yeah – my new Twitter bot! I’m testing it at the moment so there are rough edges in the copy, and it might break. But please do give it a go. @5point9billion is over here. You’ll need to talk to it from a public Twitter account.\nWrite-up\nI haven’t made a habit of project write-ups before, but I’m taking an increasingly “long now” approach to the tech I make and use. How will I remember what I made in a decade? By reading this post.\nIf you just want to use the bot, stop reading now :) If you want to know a bit about the underlying data, carry on.\nData\nMy original web toy was based on a list of stars I found at An Atlas of the Universe. It was a little haphazard (I’ve since discovered) but more importantly only went up to 50 light years. That felt like a lot of headroom when I made the first version of this and I was 25. Now I’m 37 and 50 doesn’t feel so far away.\nBetter data required!\nIt turns out there are dozens of astronomical catalogues, all of them doing slightly different jobs.\nIn the end I found the HYG Database which combines three sources, it contains all stars in Hipparcos, Yale Bright Star, and Gliese catalogs which is some 120,000 stars in total.\nOf particular interest to me is the data from the Yale Bright Star Catalog which concentrates on naked-eye visible stars. The HYG Database includes and tidies this up.\nThen there’s the question of filtering down this huge number of stars.\nFirst, filter by distance: There are some 4,061 stars listed within 100 light years (well, star systems but we’ll get to that). But this includes objects invisible to all but the most powerful telescopes. \nSo I picked a threshold – astronomical brightness is expressed in apparent visual magnitude, basically not how bright the star or planet or whatever actually is (we can’t know) but how bright it looks from Earth. And this is a brightness that peaks around 550nm, right in the middle of the visual range… some stars are crazy bright in the infra-red but you can’t see them.\n(550nm is yellow-green, chartreuse.)\nUsing this magnitude chart I picked +4.5 as a cut-off (lower is brighter), which is between these two descriptions:\n\n+4.0: faintest naked-eye stars visible from many smaller cities/(outer) suburbs\n+5.0: faintest naked-eye stars visible from “dark” rural areas located some 40 miles (60 km) from major cities\n\nFiltering by brightness: There are 181 objects in HYG closer than 100 light years, which are also brighter than magnitude +4.5.\nIt’s arbitrary but that’s a decent number.\nThen, data cleanup.\nOur closest star system is Toliman aka Rigel Kent aka Alpha Centauri. In my filtered-for-brightness HYG it has two entries: \nAlpha Centauri A and Alpha Centauri B. Although Alpha Centauri looks like a single star to the naked eye, these two stars can be seen separately with a 2 inch telescope, and they were first spotted in December 1689.\nBut it turns out there’s also third star – Proxima Centauri. It’s dim, small, and although 0.2 light years from the other two, it’s gravitationally part of the same system. I’ve combined these entries.\nActually I’ve gone through all 181 objects listed and:\n\ncombined them if necessary\nadded a link to the relevant Wikipedia page\ntagged them according to how many stars are in the system…  of the whole set, only about half (a little over) are solitary. Loads are binaries, some are 4 or 5 star systems\nmade a note if we reckon they have planets. That’s cool to know!\nnamed them\n\nWe’ve been naming stars for thousands of years. So most bright stars have multiple names, and because Wikipedia is a product of the west, I mainly find European or Arabic names of stars visible from the northern hemisphere. Sometimes there are Chinese names given too.\nI’ve picked my favourite names.\nMy pick is purely subjective. I’ve mainly used the expanded version of the abbreviated, disambiguated name given in HYG. For example, when HYG said 52Tau Cet, I’ve changed that to Tau Ceti.\nWith others, I’ve leaned towards traditional names. In HYG: 35Eta Oph. That’s Eta Ophiuchi, but I’m referring to it as Sabik. Of course there are multiple traditional names, and to give you an idea of what the Chinese name is like, here’s what Wikipedia says:\n\nIn Chinese, this star is considered part of … Left Wall of Heavenly Market Enclosure, which refers to an asterism (pattern of stars) representing eleven old states in China that mark the left borderline of the enclosure … Consequently, Eta Ophiuchi itself is known as Tian Shi Zuo Yuan shiyi, English: the Eleventh Star of Left Wall of Heavenly Market Enclosure, representing the state Song.\n\nI’ve played silly buggers with the character accents there but you get the idea.\nNow I have to say, the Eleventh Star of Left Wall of Heavenly Market Enclosure is possibly one of the most poetic things I’ve heard, but I’ve picked “Sadik” as the name simply because it is more likely to crop up in the books and movies I tend to encounter. As I said, subjective.\nBut you know what? Cropping up in books matters. I’m a fan of generation ship novels in science fiction – I keep a list of starship names. I also keep a list of destinations…\nIt’s super neat to think that, when I was almost 12, my light was touching Procyon, the destination of the ship Big Dog in Non-Stop by Brian Aldiss. The Dazzle of the Day by Molly Gloss – Dusty Miller is carrying a community of quakers to Epsilon Eridani. And Tau Ceti pops up all over the place.\nSo the night sky gets richer with this tapestry.\nInteractions\nOne speed bump is this bot needs to know your birthday to function – and I’m asking users to tweet their birthday publicly to start using it. I’ve been asked a few times about this, isn’t it a crazy privacy problem?\nWell I thought about having this configuration happen privately through DM, but the thing is your birthday will leak anyway… the distance of stars is public information, so when the bot says “passing Tau Ceti in 2 days,” that’s a total giveaway. The birthday at the beginning is a hurdle, true, but it makes people realise that their information will be public anyhow: It prevents that fact from being a surprise later. I can set this expectation without explaining anything, it’s implicit in the interaction.\nActually the truth is my next bot is going to be all about first pets and your mother’s maiden name, and it’s all a giant scam.\nOn the topic of setting interaction expectations implicitly:\nYou stop the messages by unfollowing the bot, and this is barely explained in the help text. It’s an unusual interaction pattern: Most Twitter bots you can use by tweeting at them, and they reply with whatever they have to say, whether you follow them or not.\nBut this bot is more like a subscription, so I need a way for users to “unsubscribe” that is intuitive enough so nobody has to guess what to do… I don’t want people to report the bot to Twitter for spamming and have account suspended.\nI’m trying to build this unconscious understanding by making the bot almost unusable unless you follow it. Everything steers the user towards following, hopefully the equation becomes very clear.\nWhat next\n@5point9billion is still in beta – on my list: a bit more copy, a couple more simple features, management tools on the back-end.\nBetween this and my previous bot (a poem called @liketocontinue) I’m gradually creating a system I can use to tell stories on Twitter. So who knows what I’ll make next - I have a bunch of ideas in my notebook - but I’d like it to be incrementally more complicated. As the complexity of what I can do with my tools grows, so my imagination grows too.\nAlways up for collaborations. Let me know if you have any ideas.\nBut at the back of my mind is this… My previous version of this project has run happily with minimal intervention for over a decade. The code that runs my blog: That’s been running in various incarnations for almost 16 years. My principle is to keep the code I write simple enough that I can rewrite it in a day or two. It’s a decent way to future-proof.\nThe time I keep code running for is longer than the popularity of most languages, of most “best practice” ways of building for the web, of the platforms I use – RSS, say. Will Twitter be around in a decade? How about the web itself? Is this bot simple enough that I could re-write it in a day or two? No, it’s not. Not yet. It would be cool if it was.\nI don’t know where I’m going with this.\nCrossing the river by feeling the stones.\nHey, @auchmill tweeted something lovely: Funny, isn’t it? I’ve never been so aware of my age, or made to feel so okay about it\nYou can follow @5point9billion over here. 198 people are already using it as I write these words. If any of you are reading, hello!\n",
    link: "/home/2015/12/11/coffee_morning_minutes",
  },
  {
    title: "Hamlet and Star Wars and what fiction is",
    date: "18.23, Wednesday 16 Dec 2015",
    content:
      "Look, Hamlet. Hamlet is such a non-nonsensical story. All rational, makes sense, about feelings, betrayal, etc. I must have written a dozen essays on Oedipal blahblahblah. Yet the play opens with them meeting a ghost! What is that?? What gets me is I’ve never questioned this, it fits with the narrative so well. So what are we seeing – is the ghost some manifestation of the group unconsciousness, the reaction of the court to the actions of the king and queen so totally repressed that the only way it can come out is as a thing with its own body and agency, independent from any individual? And why have I overlooked this so far? Is it because when I read about the ghost in Hamlet I accept it because honestly that’s just how things are: The world is inhabited by us and also by these forces that emerge from us all, but are claimed by no-one… and so we treat them as if they are real even though they aren’t? I don’t know. But the ghost isn’t a chorus… it’s not part of the staging. The guards meet the ghost! Hamlet meets the ghost!\nOh gosh now here’s a thing: the Ghost was originally played by Shakespeare himself.\n… which reminds me of 2001: A Space Odyssey and the way the Monolith is the shape of the cinema screen itself, and most of the shots seems practically built to remind you that (a) the screen has edges where we are and so via the Monolith we intrude, and (b) that the director is behind the camera and has a viewpoint somethingsomething \n… and I’m reminded of the astounding stage adaption of His Dark Materials in which black-clad puppeteers controlled the character’s omnipresent animal familiars - fading from our notice during the first 3 hour part of the play - and then in the second segment, they visit the underworld, and are told that we are followed around the whole time by our own death, always there, always invisible, at which point the puppeteers remove their masks. Tingles.\nsomethingsomething a crack between our world and the fiction world\n(I have an assumption that authors and directors are all always talking about the weird timelessness of fiction and the roles of the author and spectator/reader, because that’s the world THEY inhabit. Even, I don’t know, Greg Egan with Schild’s Ladder which is the hardest of hard sci-fi, could he be any more preoccupied with the nature of crafting a story and how it gets in and out of the page? The entire thing is a metaphor down to the new bubble universe being like the solid pages of a book, and the spaceships weaving themselves like story being constructed letter by letter.)\n… and somethingsomething I’m reminded of this 2005 piece about Star Wars and what The Force really is. Being:\n\nthe characters come to understand that there is another agent, external to themselves, that is dictating the action. Within the films’ fiction, that force is called … er, “the Force.” It’s the Force that makes Anakin win the pod race so that he can get off Tatooine and become a Jedi and set all the other events in all of the other films in motion. We learn that Anakin’s birth, fall, redemption, and death are required to “bring balance to the Force” and, not coincidentally, to give the story its dramatic shape.\n\nAnd so, yes:\nThe Force is, in other words, a metaphor for, or figuration of, the demands of narrative. The Force is the power of plot.\nThere’s a ghost in Hamlet! The ghost was played by Shakespeare! Dunno, good grief, I’m broken, draw your own conclusions.\n",
    link: "/home/2015/12/14/5point9billion",
  },
  {
    title: "New interview",
    date: "18.34, Wednesday 16 Dec 2015",
    content:
      "John Pavlus interviewed me about code… how I got into it, what I think it does to and for society, etc. The result is this article, For Designers, Learning To Code Isn’t A Yes-No Question featured at Fast Company Design.\nIncluded! My early spiritual experience with transistors. Ted Nelson’s amazingly prescient observation that Whatever it may do in the real world, to the computer program, it’s just another device and the dehumanising effect technology can have. The steamroller approach of the coding mindset on the world’s problems… and it’s power too.\nI’m delighted with this. For some reason, conversations with John always lead to interesting places - places I don’t think either of us (well, me definitely) would have reached without talking together - and it’s neat to have some of those endpoints written down.\nGo read!\n",
    link: "/home/2015/12/16/hamlet",
  },
  {
    title: "Next",
    date: "10.15, Thursday 17 Dec 2015",
    content:
      "I’m on the lookout for new gigs. 2015 has been a good and exploratory year – the highlights: I’ve mentored startups as Entrepreneur in Residence at Techstars and continue to spend quality time with many especially in the pre-series A and hardware spaces, including being an advisor at Tech Will Save Us and making a small investment in Unmade. I’ve developed Internet of Things policy with the government; built a regular hardware-focused London meet-up; taught design students and explored small group dynamics; got a speaking agent (!) and done talks about the Internet of Things and business models; made a return to coding and built Twitter bots. I still work closely with Samsung on corporate innovation, and have a few more personal projects bubbling away…\n2016?\nI want to build on 2015 with new gigs, drop me a line if you’d like to chat. I’m open to longer engagements… full or part-time for 3-6 months, that kind of thing. Email is matt@interconnected.org.\n",
    link: "/home/2015/12/16/fastcompany",
  },
  {
    title: "Ulysses and other apps for writing",
    date: "12.49, Tuesday 22 Dec 2015",
    content:
      "A quick plug for the Mac app Ulysses which has totally upended my writing workflow in the last few months. Brilliant – the first tool I’ve found that fits the way I work.\nMy previous writing workflow in a nutshell:\n\nI capture super-quick notes in Simplenote on my phone, or nvALT 2 (an updated version of Notational Velocity) on my laptop. They’re synced together. Perfect for ideas, recipes, records of when I last called the electricity company to give a meter reading, etc. These apps are optimised for search… type a word or two, and all matching notes instantly appear.  Over the past two decades I’ve seen the benefits of serendipitously running across my own forgotten scribbles, these apps are ideal for that.\nFor longer documents, I move to Textmate which really is a text editor for writing code, and it’s dated too. I use a plugin I wrote in 2007 called Plain Text Wiki. This lets me write longer, structured documents of multiple linked pages, all as plain text. Seems like a bunch of trouble to go to.  But I’m a purist: Since losing a bunch of data in the 1990s, I’m distrustful of other people’s file formats. Plain text is the way to go, no Word docs. I want formats that I can extract words from, even when I’m down at the level of reading bytes retrieved from broken hard drive platters. It’s happened. That was the first time. The second time a drive failed on me, I ran the server with the drive sitting on an ice tray direct from the freezer – any warmer and it would seize. I do backups now.\n\nThis blog uses Markdown for formatting posts, and I wrote my own blog engine. The engine has changed multiple times, but the data - my posts - remain the same. For quick presentations I use Deckset which lets me make + present great looking slides fast, also using Markdown from plain text files.\nSo I’m pretty choosey, and my flow is pretty well established.\nEvery so often, I try a more grownup app for writing. Textmate is ok but it’s made for coding. And more importantly, I can’t get to the docs I’m working on from my iPad or my phone.\nBut the Mac apps I’ve found… they’re all about focus. Full screen writing. Dark backgrounds. I don’t focus when I write, I’m all over the place. I like to have multiple documents on the go, and often multiple projects.\nEnter Ulysses.\nUlysses is plain-text first, with Markdown for formatting. There’s a learning curve, and then it’s simple: All my text sits in a single library that I’ve organised into projects. Within each project, there are notes both short and long. There’s a prominent search field, and when I look at the Ulysses library on disk, I can find the text files.\nI’ve added my blog as an “external folder” – to publish, I drag a file from my main library onto it, and sync.\nBut importantly, it just feels right. I open it and continue writing. I don’t have to think about what to call this file and where to save it, but equally I don’t need to be concerned about mixing up my work projects and my personal projects.\nWhat’s convinced me to make this a permanent part of my workflow is that I’m on the Ulysses for iOS beta and it’s great. The library syncs automatically. Being able to access my longer docs while I’m on the bus (which, it turns out, is where I do most of my thinking) and add notes directly to those projects… fantastic. Drafting blog posts while I’m on the tube, in a familiar text editor? So good.\nSo yeah – an enthusiastic plug for Ulysses. Thanks!\nAll of that said: I don’t think I would have looked outside my current workflow except that I sat down with Dinah Sanders and she generously showed me how she uses Scrivener, which is the go-to app for authors of proper books.\nWhile I’m not using Scrivener (Ulysses is similar and I’m too committed to my text files…), Dinah opened my eyes to using process and organisation as part of writing. Currently I’m constrained by my own working memory. Every time I try to write a single piece of more than a couple thousand words - fiction or non-fiction - I get in the swamp. This feels like it’s helping.\n",
    link: "/home/2015/12/17/next",
  },
  {
    title: "@5point9billion news",
    date: "17.24, Monday 28 Dec 2015",
    content:
      "Some updates for that space+birthdays Twitter bot I launched a couple weeks ago…\n\nThe bot now picks up the timezone of the user – notifications are sent out at 12 noon local time.\nThere’s a website! I’ve made Electron Farm as the home for my various Twitter bots. Use 5point9billion’s homepage to set your birthday without tweeting it publicly, and also see which stars you’ve already reached.\n\nThe bot just passed 300 active users, which is not bad!\nAnd here’s a pretty visualisation of all bright star systems closer than 100 light years. It was a bit quick+dirty to make, but a neat way to get to learn about drawing 3D graphics. I like the way it looks, so I’m thinking about how to use these kind of animations for the bot.\n",
    link: "/home/2015/12/22/ulysses",
  },
  {
    title: "Favourite books, 2015",
    date: "15.40, Wednesday 30 Dec 2015",
    content:
      "Favourite books read this year:\n\nThe Book of Strange New Things, Michel Faber\nWild Life, Molly Gloss\nEncounters with the Archdruid, John McPhee\nGroup Psychotherapy: The Psychoanalytic Approach, S. H. Foulkes and E. J. Anthony\n\nNew Things is so undramatic – the story of a wife at home, and a husband who is a Christian missionary taking the word to people who are hard to understand. Communication and distance runs through this book: Between the couple; between the missionary and his community; between what’s really happening and the reader.\nIt’s a delicate book. Half-told shadows of truths, understated language that circumnavigates huge black holes of feelings where light doesn’t go.\nI found out after reading it that Michel Faber intends this to be his final novel – he wrote it while his wife was dying. Heartbreaking. You can tell.\nWild Life is by Molly Gloss who wrote The Dazzle of the Day, a novel about a village of Quakers who travel to another star system on a generation ship. They treat repairing the solar sails like farming the fields. And it talks about something that can’t be talked about from the inside: Silence.\nSo Wild Life isn’t sci-fi, but - like Strange New Things (did I mention the Christian missionary visits aliens on another planet?) - it’s speculative fiction: A woman gets lost in the woods, I don’t want to say much more than that.\nExcept this. There’s a memorable period of silence in the woods. For me it highlights what happens in silence… you become detached from what words do. Words, somehow, add our expected reality onto our perceptions. Silence, by removing words, simultaneously creates dissociation - a dreamlike state - but also brings you closer to reality itself, requires you to become embedded.\nThe beginning, middle, and end of the silence is sensitively and insightfully told.\nArchdruid is nonfiction. It’s John McPhee’s portrait of David Brower, founder of Friends of the Earth, told in three parts, each part a fight with another individual, an opponent, over an environmental issue: Mining, property development, the damming of rivers.\nThe third part grabbed me especially – David Brower rafts down the Colorado River with Floyd Dominy, through sites where Dominy has won and Brower has lost. McPhee is there too, a participant observer. This isn’t journalism, it’s telling a story through describing what happens between the three of them.\nIt strikes me that what these books by Faber, Gloss and McPhee have in common is they all describe character enormously well.\nBrower is speaking on behalf of wilderness. Rocks, trees, these things are silent, at least in our human conversations. So we need people to speak for them. Maybe. It’s a fuzzy domain. On the one hand, that which doesn’t speak sometimes needs a voice, so perhaps we need speakers who will hold its viewpoint inside. Essential if the rest of us aren’t going to destroy it by trampling. But the risk is that when you speak for a thing that holds its own counsel, you undermine its subjectivity and its sovereignty – its right to be understood on its own terms.\nMcPhee describes the land in words that speak to me: The Utah canyonland had been severed halfway up by a blue geometric plane, creating a waterscape of interrupted shapes. He is also the author of Annals of the Former World.\nWhat happens between people:\nI have been having my mind slowly transformed by Group Psychotherapy by Foulkes and Anthony. I’ve had a long-standing interest in small group dynamics that I’m really beginning to indulge this year, and along with Wilfred Bion’s Experiences in Groups, this is the best eye-opener I’ve found.\nGroups (social interactions, company) are the water in which we swim. Having common group phenomena pointed out, or to be shown details of a group’s evolution and its impact on individual behaviour, makes me feel like I’m finally seeing something that was in-front of me all along.\nThis is also the book that introduced me to the role of the “participant observer”… in these psychoanalytic situations, the person who attempts to speak for the group, but is also part of it. Tricky. Enlightening.\nWhen you can see something, well, that lets you ask questions like, why couldn’t this be otherwise? And, what about the groups I haven’t looked at yet, the ones with trees and rocks and other non-humans?\nGroup Psychotherapy includes an analysis of the three person closed group in No Exit, the play by Jean Paul Sartre in which he says Hell is other people. I hadn’t clicked what a tight description of the group this is. Now seeing how real it is, there’s more there for me to read.\nI guess that’s what brings together all of my favourites this year. There’s a reality to the characters, and their interactions, and their behaviours and evolution, and their situations; and so they tell me more - by speaking and by not speaking - and they live longer in my imagination.\n",
    link: "/home/2015/12/28/5p9b_news",
  },
  {
    title: "My recipe for chicken pilau",
    date: "16.03, Sunday 2 Mar 2014",
    content:
      "The following was originally posted on Medium and has since been moved here.\nIngredients\n\nChicken (500g or 1 lb)\nOnions (2)\nTomatoes (2)\nPotatoes (6 medium-sized)\nBasmati rice (3 cups)\nGreek yoghurt (150–170g or 1 cup)\nVegetable stock (5 cups)\nFrozen peas (1 cup)\n\nSpices\nGreen chillies (4), cinnamon bark, black peppercorns, cloves, green cardamon pods, cumin seeds, garlic paste, ginger paste, turmeric, chilli powder, mustard seeds, fresh coriander.\nMethod\nWash 3 cups of rice and leave to soak.\nIn a half cup of water, put\n\n1 big tbsp broken-up cinnamon sticks\n1 tsp black peppercorns\n1 small tsp cloves\n1 tsp green cardamon pods\n2 big tsp cumin seeds\n\nThis is the whole garam masala. Leave it to soak.\nA pilau is a spiced rice-based dish where the rice is cooked in the stock and the flavours of the other ingredients, as opposed to a biryani where the rice is pre-cooked. This pilau is made with chicken, rice and potatoes.\nThis recipe is a combination of two recipes from A taste of our cooking by the Ismaili Women’s Organisation. I’ve added notes of my own, primarily details about cooking spiced food that would be taken for granted by almost everyone reading the book, but that I’ve picked up along the way.\nIt’s not a particularly complicated recipe. It’s the one I use.\nFor me, when I think of pilaus I think of family gatherings where dozens of people are eating and there are chapattis and vegetable curries and all kinds of things. I think of one of my aunts cooking.\nA pilau is an easy comfort food. This quantity will last a week, tasting better every day.\nIn a saucepan:\n\n150–175g Greek yoghurt\n1 big tbsp garlic paste\n1 big tbsp ginger paste\n2 fat green chillies, kept whole, stabbed on both sides\n\nGet the yoghurt mixture good and hot, then add 3 large chicken breasts (about 500g or 1 lb) chopped into about 10 pieces.\nCook, boiling, until tender (that is, until the chicken is pretty much done).\nLeave in the saucepan, and put to the side.\nPeel 6 medium potatoes, cut them into 1 inch cubes. Parboil. Drain and put to the side.\nA few years ago I was on the tube to work and I had one of those scent memories that is so strong it’s an interruption. The olfactory bulb, the part of the nose that does the smelling, isn’t separate from the brain like the eyes or the ears: It’s part of the brain itself, wired deep into the ancient vaults that deal with emotion and memory.\nAnd so it was, I was right back in my grandparents’ house in Nairobi, where we’d visit when I was a kid, and there were all the smells and memories, all the family and old stories, all the people, some now gone, and me still on the tube.\nI looked around for whoever it was who smelt like that, whatever had triggered the memory, thinking someone nearby smelt like that back room in Nairobi, then realised — I had cooked the chicken pilau on my own, as an adult, for the first time the evening before — the ginger, garlic, and spices were coming out of my skin, and it was me.\nA happy connection to my roots.\nBy this point in the recipe, my house already smells pretty good. It keeps getting better.\nMake the following in the pot you’ll be leaving the pilau in for the rest of the week, so all the flavour stays. This should be the largest pot you own.\nToast the following until it all smells great but nowhere near burnt. Toasting means cooking on the dry pan bottom, moving the spices around a little.\n\n1 tbsp coriander powder\n1 tbsp cumin powder\n1 tsp turmeric\nHalf tsp hot chilli powder\nHalf tsp mustard seeds\n\nAdd 2–4 tbsp vegetable oil, make a paste and get it good and hot.\nFry onions until light brown… they should be only just done.\nAdd the whole garam masala and boil away the water.\nSpoon the chicken and chillies out of the yoghurt. Fry until the chicken\nis fully coated and done. It should be moist, and coloured but not going brown. Make sure the ingredients are fully mixed and not stuck to the bottom of the pan.\n(Drain the rice.)\n(Prepare 5 cups of vegetable stock (6 heaped tsp of powder) in boiling water,\nand throw in a cup or two frozen peas. Give a minute for the peas to\ncook.)\n(Preheat the oven to 160C/320F.)\nTo the pot: Add the remaining yoghurt from the chicken saucepan, 2 more green chillies (prepared as before), and 2 tomatoes chopped into eighths. Mix and cook briefly.\nAdd the potatoes and vegetable stock. Stir thoroughly.\nBring to the boil, salt to taste.\nAdd the drained rice, stir once, bring back to the boil, then cover and simmer for 15–20 minutes or until the rice is cooked.\nUncover, and steam dry by placing in the oven for 30 minutes.\nThe pilau will be rich with some chilli heat, not too hot. When I eat it, the spices fill me, my skin tingles, I’m full of memories; Suddenly I’m three dimensional and completely solid, the internal ballast of history and family.\nEat with yoghurt and fresh coriander.\nVariation\nI usually make this chicken pilau with fresh curry leaves. I love the taste of curry leaves so I use them liberally: A couple crumpled then dropped in whole whenever chillies are added, and a couple more chopped and cooked up when the spices are toasted.\n",
    link: "/home/2015/12/30/four_books_read_in_2015",
  },
  {
    title: "Tap tap",
    date: "15.28, Wednesday 5 Nov 2014",
    content:
      "Hello. Hello? Is this thing on?\nI was at a conference last week and the closing speaker, Tobias, ended his presentation by saying I’m Sorry instead of Thank You.\nI liked that. I’m sorry. Hello.\n",
    link: "/home/2014/03/02/chicken_pilau",
  },
  {
    title: "Filtered",
    date: "10.22, Wednesday 12 Nov 2014",
    content:
      "1.\nMaybe I should be adopting Michael Sippey’s low-pressure philosophy for ‘filtered’: I used to blog; I haven’t in a while. I miss it. So this is trying something new, without the daily pressure of a capital B Blog, or the content pressure of a the capital E Essay. Start a new draft post on Monday, dump things in it over the week, rewrite and cull along the way, what’s left gets published on Friday. Let’s see how long I keep this up.\nLow-pressure filtering? Cold brew blogging.\nIt’s a philosophy that seems to be working.\n2.\nLong read on The Knowledge from the New York Times Style magazine. the Knowledge is the examination taken by black cab drivers in London… deep knowledge of 25,000 streets and everything on them.\nFascinating how revision works and how the test works. Revision: A series of 320 runs across central London that you rehearse by crossing on a motorbike and taking notes. The test: Verbal, over many months, increasing in complexity and frequency. There is no such thing as “failing” the Knowledge. You can either quit, or persevere and pass.\n3.\nAn Interview with Stanley Kubrick by Joseph Gelmis, 1969. I referenced Kubrick and 2001 a ton at my Web Directions talk (video online soon apparently). Two favourite quotes:\nActually, film operates on a level much closer to music and to painting than to the printed word, and, of course, movies present the opportunity to convey complex concepts and abstractions without the traditional reliance on words. I think that 2001, like music, succeeds in short-circuiting the rigid surface cultural blocks that shackle our consciousness to narrowly limited areas of experience and is able to cut directly through to areas of emotional comprehension.\nAnd:\nOne of the things we were trying to convey in this part of the film is the reality of a world populated – as ours soon will be – by machine entities who have as much, or more, intelligence as human beings, and who have the same emotional potentialities in their personalities as human beings. We wanted to stimulate people to think what it would be like to share a planet with such creatures.\n4.\nA Ranking of All 118 Sweaters Seen on Twin Peaks.\nDiligent.\nSlideshow here.\n",
    link: "/home/2014/11/05/hello",
  },
  {
    title: "Filtered on 14 November",
    date: "12.32, Friday 14 Nov 2014",
    content:
      "1\nAll Cameras are Police Cameras by James Bridle, the first of a series of reports from The Nor, an investigation into paranoia, electromagnetism, and infrastructure.\nAll about the Third London Wall, one made not out of stone or checkpoints but bits, electrons and radio waves.\nFull of good meaty stuff like this: Surveillance images are all “before” images, in the sense of “before and after”. The “after” might be anything […]\nBut - I don’t know - something about power and whatever-comes-after-matter. Paranoia too, that’s a fucking massive looming ocean that we can’t even tell we’re in. I’m glad James is looking, I hope he can see it and tell us.\n2\nTwo images on Twitter I liked.\nSecond most common languages in the 30-something London boroughs, being: Punjabi, Gujurati, Polish, Turkish, Urdu, Spanish, Portugeuse, Arabic, Bengali, French, Tamil, Nepalese, and Lithuanian. Why I love London.\nThat comet we [humanity] just landed on, 30 light minutes away, called either comet 67P or Churyumov-Gerasimenko… here’s the comet comped over a city. It’s either really big or really small, I’m not sure which.\nI was just trying to describe why I liked this so much. Frontiers. Because we should be mining the Moon and populating the Asteroid Belt.\nThe Little Prince.\nChina called its Moon rover Jade Rabbit which sadly didn’t rove as much as hoped. When its battery died, the announcement was made in the voice of Jade Rabbit itself: Although I should’ve gone to bed this morning, my masters discovered something abnormal with my mechanical control system … Nevertheless, I’m aware that I might not survive this lunar night.\n3\nI’m thinking a bunch about how to best help startups. Paul Miller and Jessica Stacey wrote Good Incubation, a report on how to incubate specifically social ventures. (Paul runs Bethnal Green Ventures, a London startup accelerator that focuses on social good and has done everything from 3D printed prosthetics for kids, to a smartphone with an ethical supply chain.)\nConventionally a startup’s progress is measured by revenue, traction, funding, etc.\nPart II of the report puts forward a way of seeing startups by their primary challenge, and therefore how they can be most helpfully supported.\nThere are five archetypes:\n\nTeam Formers\nProposition Seekers\nCustomer Hunters\nModel Clarifiers\nScalers\n\nFor each, the report points out its needs and common pitfalls.\n4\nToba Boca, genius makers of smartphone toys for kids, have released a gentle, gorgeous woodland snowglobe called Toca Nature.\nIt doesn’t persist, you re-make your world each time you play. You don’t raise and lower the land, you make lakes for beavers and mountains for wolves. You make little discoveries. You don’t look up at the sky, you look into the forest.\nI’ve always been taken by the Wood Between the Worlds in the Narnia books. A transitional forest outside time and space, in the gaps between the eleven worlds. A quiet woodland pond for each world, step into it and–\n",
    link: "/home/2014/11/12/filtered",
  },
  {
    title: "Hardware coffee morning",
    date: "12.18, Monday 17 Nov 2014",
    content:
      "tl;dr let’s hang out this Thurs. and chat hardware\nI think it was the week before last, I had just got back from holiday, and I had three meetings with hardware startups, all wanting to talk through what they were doing, and each at a different stage. Some of what we were talking about was startup stuff - like, what to do first - and some was technical (what code should run where?) - and most of it was, you know, let’s just chat through this.\nIt was fun for me for a couple of reasons. First because there is a hardware boom in London and that’s exciting. There are some great hardware-focused meetups, and some good semi-private communities, but I find the chitter-chatter especially enjoyable. The second reason is that, with Berg gradually taking less of my time, I find myself (a) wanting to lend a hand, even in a small way, to people getting going with products and hardware etc; and (b) missing hanging round smart people with that particular bent and learning from them.\nI guess that’s one of the things I love about hardware and the Internet of Things and all that nonsense. You can go from embedded software to supply chain via character design in a single conversation, and that appeals to my Attention Gadabout Disorder.\nSo what I’m saying is, we should see more of each other.\nCoffee mornings\nI’m inspired by Russell Davies’ coffee mornings that he did for a year or two back in 2006/7. A regular spot, an open door, and a good crowd. Let’s do it!\n9.30am till whenever, Thursday 20th, The Book Club.\n(3 days from now.)\nI’m a bit of a morning person, sorry about that.\nNo agenda except coffee and hanging out. But if you’re into hardware (making or manufacture), Internet of Things, knitting, shops, China, sending stuff through the post, so on and so forth, please feel particularly welcome. Tom’s coming along, it’d be lovely to see you too. If it’s fun we’ll do it again.\n",
    link: "/home/2014/11/14/filtered",
  },
  {
    title: "Filtered on 19 November",
    date: "16.05, Wednesday 19 Nov 2014",
    content:
      "1.\nNew to me: It turns out cricket standardised on six balls per over relatively recently. Test cricket used to use four balls, eight per over was used in the 1974 Ashes… it’s been six since 1979/80.\nI’m always curious about the things and institutions we take for granted now, and how they started.\nThe Football Association was founded in 1863. The Scout movement in 1907.\nOr the Psychoanalytic Society in 1902 and the Macy conference (cybernetics) in 1954. Different trajectories.\nThe Civil Service - the 447,000 strong organisation of apolitical bureaucrats instilled with public service values that runs the UK - the Civil Service was originally created for a private company, East India Company, that trained its previously-amateur adminstrators to run its operations in India and prevent its leaders from running amok.\nAnd somehow the East Indian Company didn’t disappear but in the process of becoming Empire, flipped inside-out and now it is the state?\nThe founding report in 1853 gave the service its core values of integrity, propriety, objectivity and appointment on merit, able to transfer its loyalty and expertise from one elected government to the next – and took its inspiration from what had already been done by the Chinese.\nThe Northcote-Trevelyan Report!\n2.\nWildcard is a new iPhone app that embodies an emerging user interface: Cards.\nCards are single units of content or functionality, presented in a concise visual format that resembles a real world playing card or postcard.\nTwitter is made out of cards, once tweets become actionable (perhaps with a ‘Buy Now’ button).\nMost of my inbox is cards, or notifications of changes to cards. Accept a Linkedin invitation. Add a recommended book to a basket. Take a meeting.\nI’ve got some history with this, so I buy the cards paradigm.\n3.\nDenim Breaker Club, from the always-interesting Hiut.\nJeans.\nSo there’s this:\nYou are going to break our selvedge jeans in for our customers. You will have to agree to not wash them for 6 months. You will have to agree to update what you get up to in them on HistoryTag. And before you get them sent to you have pay a small deposit, which we will refund on their safe return. When we get them back, we will expertly wash them. And then we will sell these beautiful jeans. You will have 20% of the sale.\nAnd there’s this:\nWill this reduce the carbon footprint of a jean? What will ownership look like in the future? Does trust still matter?\nGood grief these folks are good. I’m watching closely, what an incredible petri dish for the future of products.\n4.\nI’ve always thought of GPS as being like a bunch of satellites that broadcasts the grid of very fine graph paper across the whole world. Then we can see the grid and count our way across it.\nAndrei Derevianko is mining 15 years of historic GPS data to look for anomalies.\nIt turns out the universe might have fracture lines across it, folds along which the mass of an electron is different from the norm. If these lines exist, the solar system would pass over them as it orbits round the galactic core; it would take 170 seconds for the anomaly to move across the GPS network.\nThat’s what Derevianko is looking for.\n",
    link: "/home/2014/11/17/hardware_coffee_morning",
  },
  {
    title: "Filtered on 23 November",
    date: "14.21, Sunday 23 Nov 2014",
    content:
      "1.\nGet Your Kicks on the Route G6.\nThe Economist (from 2012) on China’s growing network of expressways, and the culture of driving it’s kicking off. Everything from service stations with rubbish shops, to the Beijing-Tibet Expressway: several thousand kilometers from Beijing, across China, then a climb up onto the Tibetian plateau itself.\nYou need oxygen cannisters for the altitude sickness on the drive.\n2.\nPiccolo is a pocket-sized, open source drawing robot. Attach a pen and make it draw.\nSee also Mirobot, which is bigger and Wi-Fi connected too.\n3.\nChristmas in Yiwu by Dan W. Over the summer, Dan travelled across China and by container ship following the electronics supply chain… this piece is about his visit to a vast commodity market.\nI expected to find bizarre oddities but the products were all familiar. I’d seen them in pound shops and market stalls already.\nAnd:\nIn the bridges between Districts I would sometimes see counterfeit money in various currencies being sold off a blanket on the floor.\nIncredible. Where shit comes from. It all reads like something Bruce Sterling might write.\n4.\nI currently have my nose deep in Mike Brearley’s The Art of Captaincy which is ostensibly about how to captain a cricket team, but is really all about the psychology of groups (Brearley became a psychoanalyst after retiring from cricket).\nBut also in the book is the concisest description of what class means in Britain.\nUntil 1954, every captain of England was an amateur; that is, he was not paid to play cricket. (The Latin root imples that amateurs played because of love of the game, rather than for anything so base as money.) Before the War, and for some time afterwards, the distinction was secure. Amateurs had different changing-rooms, stayed in better hotels, and emerged on to the playing area through separate gates. They stated when they were able to play, which explans why a cricketer of G.O. Allen’s stature played only 146 matches for Middlesex in a career spanning twenty-six seasons. Their names were represented differently on score-cards, either as ‘Mr’ or with ‘Esq.’, or with the initials before rather than after their surnames. In 1950 Fred Titmus played his first game at Lord’s. It was a fine Saturday, with a good crowd. An announcement came over the loudspeaker: ‘Ladies and gentlemen, a correction to your scorecards: For “F.J. Titmus” read “Titmus, F.J.”.’\n[…] By no means all the amateurs in cricket were High Tories in background or style. They had simply gone on from school to Oxbridge, been good at cricket, and followed a natural route into the first-class game. (Indeed, until 1981 the Wisden ‘Births and Deaths’ list marked out those of us who played for Oxford or Cambridge as ‘Mr’.)\nThat’s a lot of what you need to know about this country, right there.\n",
    link: "/home/2014/11/19/filtered",
  },
  {
    title: "Hardware coffee morning one",
    date: "20.20, Tuesday 25 Nov 2014",
    content:
      "Last Thursday’s hardware-ish coffee morning was fun. Lovely to spend time with Tom, Charles and David, Daniel, Alex, Dan, Basil, and Ben. Thank you for coming!\nAlthough… Too Many Dudes. Something to fix for next time.\nHere’s a pic of our sign to alert people that this was a Coffee Morning With Intent.\nAnd Ben is part of Knyttan which does on-demand knitted jumpers on industrial knitting machines. Here he is wearing the test pattern, which had a lot of fans.\nSo, what happened? We sat round a table and people chatted with people. Zero structure, except for 5 minutes for everyone to say their names and what they’re doing at moment (arcade machines, newspapers, jumpers, just interested). Plus coffee. I think everyone left at about 11. I’m not sure what everyone else discussed but I had a chat about telescopes and another about what a “minimum viable product” is in hardware, and also I found out about a hardware/making cluster at Somerset House, all of which was very enjoyable.\nConclusions. I like coffee and I like mornings and I liked chatting with everyone. There will be another! Probably next week. I’ll let you know.\n",
    link: "/home/2014/11/23/filtered",
  },
  {
    title: "Filtered for minimal art and mind hacks",
    date: "10.45, Thursday 27 Nov 2014",
    content:
      "1.\nThis technique of video magnification is stuck in my head a bit. Amplify colour to see heart beat. Amplify movement to see breathing or instability in a mechanical device.\nI dunno, I dunno. I’m not sure why I keep thinking about this. What else can it be used for? My imagination goes to Ekman’s microexpressions, in 1969 he theorized that facial muscles that expressed seven human emotions also created ‘microexpressions’ that could reveal concealment, despite the fact that these microexpressions last just 0.04 second.\nMost people pick these up intuitively. But could you pipe the video of people’s faces through facial recognition software, and magnify deviations from the norm in realtime, and use that to exagerate the face? Augmented reality glasses as a prosthetic for people with low EQ? Is insensitivity to the feelings of others a pathology? This opens a can of worms. The only proper vehicle to explore this is science fiction.\n2.\nLook, if you’re not playing Crossy Road on your iPhone already, you should be. Infinite road-crossing tap-tap game.\nWhen I was a kid, I used to love playing Frogger on whatever home computer I had at the time, I forget which.\nOne day my little sister took the joystick and just jammed it forwards. No hopping right or left, no pausing for a gap in the traffic or for the log to drift. Just FORWARDS. And of course her little frog went right through the traffic right across the river and right into its home at the top of the screen.\nWhich ruined Frogger for me. Because then I would start the game and jam the joystick forwards, to see if I could make my frog to do too. Which it wouldn’t, it was a fluke, it would die. But I would try, again and again and again.\nCrossy Road is great, play Crossy Road. I’m genmon on Game Center.\n3.\nI’ve been enjoying @rarabro on Instagram and her minimal photographs with vivid backgrounds. Beautiful colours!\nIn the comments of this seagull over a blue/purple gradient, @rarabro explains her method… which apps she uses and what she looks for. Interesting! Something to copy.\n4.\nA quick shout out to the Mind Hacks blog… Mind Hacks was a book I wrote with Tom Stafford back in 2004. Since then, the blog has taken a life of its own.\nVaughan Bell was a lead contributor to the book, but has become the powerhouse of the blog. Between Vaughan and Tom, they’ve written 2.2 million words and just celebrated the blog’s 10th birthday. On its most popular day, the blog had 100,000 unique readers – two times the sales of the book ever, in a single day.\nLast week, Vaughan and Tom received the British Pyschological Society’s Public Engagement and Media Award, the first time a blog has won this.\nI’m in awe of what they’ve achieved.\nLast week I went to Mind Hacks - Live! that the guys put together to celebrate the blog’s birthday. I think my highlight was Vaughan’s and Neuroskeptic’s live dramatic reading of the love scene from Susan Greenfield’s 2121 which is - as Vaughan described it - a dark future where there is too much internet.\nYou should follow Vaughan on Twitter.\n",
    link: "/home/2014/11/25/hardware_coffee_morning",
  },
  {
    title: "Coffee morning two",
    date: "10.12, Friday 28 Nov 2014",
    content:
      "tl;dr next hardware coffee morning is Thurs. 4 Dec\nSo the first coffee morning was fun. That was last week. Who’s up for doing it again?\n9.30 for a couple hours, Thursday 4th December, the Book Club in Old St.\nSame as before… zero structure, people talking to people about products or hardware or burgers or hobbies. Ok so I’m saying that because I want to talk about hobbies.\nI’ve sort of vaguely been saying to people I’ve met over the last week or so that there’s coffee happening, so there might be a few people coming and going.\nOr it might be me doing my email on my own and getting steadily over-caffeinated, which I happily do too, and if you see that happening then do come join me.\nIt would be lovely to see you! Don’t be shy.\n",
    link: "/home/2014/11/27/filtered",
  },
  {
    title: "Stars Wars as a new genre",
    date: "18.33, Sunday 30 Nov 2014",
    content:
      "There’s a new teaser trailer for next year’s Star Wars movie, which reminds me: There was an opportunity Disney had when they acquired the Star Wars frachise from George Lucas…\nA few years back I read Riders of the Purple Sage by Zane Grey. It’s a western, and I love westerns as movies (Once Upon a Time in the West has, I reckon, the all time best set-piece of any movie, ever), but I’d never read westerns as books.\nAnd it turns out that Purple Sage is the ur-western. It’s all there. The cowboy with the thousand yard stare; the widow in need with an inner strength; the violence; the land. It came out in 1912 and has sold over 100 million copies since. Its popularity defined the genre.\nOkay so 1912. The first wagon trail along the Oregon Trail was 1836, the Gold Rush was 1849, the American Civil war was the 1860s, Billy the Kid was born in 1861 and died in 1881, the “cowboy” era of the Wild West was done by the mid 1880s.\nI think once of the things that I love about westerns is that they turn the same mythology over and over again. The same characters - Billy the Kid, Pat Garrett, Butch Cassidy - with the same biographies, the same geography and the same timeline - this well-known canon provides a background or structure which means that every film and every book adds depth and commentary on everything that has come before.\nIt amazes me that the time between the end of the era-as-fact and the beginning of the era-as-myth was maybe only 25 or 30 years… one generation.\nThat’s what I was hoping Disney would do with Star Wars. Return of the Jedi came out in 1983; it’s been about the same amount of time.\nImagine, imagine if Disney had said: Star Wars isn’t a franchise, it’s a genre.\nThe legendary galaxy, a long time ago, far far away, is well understood: What’s true is what’s in the Holocron continuity database.\nOpen the Holocron. Show everyone what’s in it. Let it become history.\nThen let anyone make movies and books that share the Star Wars world. Not like all those other franchises that argue about what’s canon and what’s not… rise above it, become a new shared set of conventions, formulas, history and myth, just like the western but for the 21st century.\nSo that’s what I wished would happen, but we’re getting Episode VII instead and a bunch more movies coming soon, set in a fictional universe the cultural ownership of which will be policed and its geology mined for the untold riches of merchandise, which is how our world works in 2014 so I can’t feel disappointed, and I guess that’s okay too.\n",
    link: "/home/2014/11/28/coffee_morning_two",
  },
  {
    title: "Filtered for tampons and structurelessness",
    date: "16.46, Tuesday 2 Dec 2014",
    content:
      "1.\nThe first post I read was from James Darling about buying milk. His story: People at his work were being proprietorial about their milk in the fridge, so he bought a big bottle and put up a sign that said Everything with DSD5 written on is free to anyone. Contributions welcome. And now all the milk is for public consumption and people contribute.\nIt turned out James had been inspired by Alice Bartlett doing something similar with tampons. This is what she said:\nAfter sitting around for six months trying to work out how to get my secret stash of tampons into the toilet in a way that would stop them from being tidied away by the cleaning staff, I realised the solution. Put tampons and sanitary towels in the toilet for everyone. Put them in a posh container so it would be obvious that they were supposed to be there. Ask women to contribute if they found it useful.\nAnd now that’s become Tampon Club which btw has the best logo, and they say how to set one up, for example what kind of container to use, and how to get it started, and what kind of message works well. Who is behind this? A shadowy cabal of menstruating women, natch.\nI could say there are lessons here about culture hacking, or that I’m super pleased that people I know are actively building new commons. Or that this is a good and right way of Being In The World, and I hope that I can contribute stuff like this too.\nBut the main thing is that I hope everyone hears about this and helps Tampon Club happen more. So tell your friends! Here’s Tampon Club at IBM Hursley.\n2.\nApropos my post on Sunday about Star Wars being the new Western (or not), @gnat pointed me at this In Our Time episode about the American West. 45 minutes, worth a listen. A race through a history of the west and the frontier, with some great anecdotes and some astute observations about American politics and how various presidents have enrolled the frontier mythology… one point that sticks in mind: Lincoln grew up in a log cabin; Roosevelt went to Harvard and wrote a history of the frontier; Reagan acted in westerns; W Bush referenced the shows about the west he saw on TV growing up.\nThat’s not saying anything bad about Reagan or Bush. Just that the western frontier was so defining for the United States… but so recent, so every generation we get further away from it is a huge difference in what it means.\n3.\nI’m into this Japanese notebook hack which introduces a third dimension into your un-indexed notes. Tag each page with a keyword, and list that keyword on the last page of the book. To match up with that tag, make a mark on the edge of each corresponding page. Then you can get a view over what’s where. Neat.\n4.\nThe Tyranny of Structurelessness (1970) came up in conversation the other day and I feel like it’s worth a re-read.\nAll groups have structure, even if they try not to. Hidden structure means hidden power which is impossible to critique. There are two negative consequences…\nThe first is that the informal structure of decision-making will be like a sorority: one in which people listen to others because they like them, not because they say significant things.\nAnd,\nThe second is that informal structures have no obligation to be responsible to the group at large. Their power was not given to them; it cannot be taken away. Their influence is not based on what they do for the group; therefore they cannot be directly influenced by the group.\nBut there’s hope. Once the movement no longer clings tenaciously to the ideology of ‘structurelessness’, it will be free to develop those forms of organisation best suited to its healthy functioning.\n…and that organisation should keep in mind a number of principles which are then listed and explained: Delegation of authority; Responsibility of individuals to the group; Distribution of authority; Rotation of tasks; Allocation of tasks along rational criterial; Diffusion of information; Equal access to resources.\nWorth a read for new organisations of all kinds.\nLastly.\nDo people read this blog? If you do, feel free to comment on Twitter like @gnat did when he pointed out that In Our Time episode, or just say Hi which is always appreciated. You can find me at @genmon and, if you want to get automatic notifications about new posts, follow @intrcnnctd.\n",
    link: "/home/2014/11/30/star_wars",
  },
  {
    title: "Filtered for spaaaace",
    date: "20.23, Wednesday 3 Dec 2014",
    content:
      "1.\nPlanet Labs! They’ve already got 28 satellites in orbit and they’re making available Earth imagery for… anything. Developers will be able to get access to the pictures and do stuff with it. Do crops about to become ready change in the infra-red? Probably. Valuable.\nThey have a gallery of recent pics. Something a bit incredible about the images being so fresh. “2 days ago.”\nThey’ve raised $65MM so far. A fleet of satellites in orbit for only that. Space eh.\nThanks @ukglo for the pointer over brunch.\n2.\nSpacelog! Original transcripts of early space exploration, online.\nHouston, Tranquility Base here.\nLater:\nAnd the–the surface is fine and powdery. I can–\n3.\nAs part of the Google Lunar XPRIZE there are four private companies going to the Moon in 2015. To get the prize they have to land a robot and make it go 500m.\nSpaceX isn’t going to the Moon, but they are a private company doing launches and whatnot, gearing up for taking crew too. They’re hiring a farmer.\nThis is probably because they incidentally own a farm.\nBut I prefer to imagine it’s because the future is farmers in space, like in  The Dazzle of Day by Molly Gloss, in which Quakers travel in a world-ship called the Dusty Miller to a planet called Reiradi on a journey thats last several generations. The book is mainly about farming and the nature of silence in which the voice of God may be heard. It’s beautiful.\nIn my notes, I have a list of names of generation ships in science fiction I’ve read. Here is the list:\n\nDiscovery\nDusty Miller\nMagellan\nNew York\nPeerless\nAmerica\nLeonora Christine\n\n4.\nIn Transformers: The Movie (1986) - which I understand was the final movie role for Orson Welles - there’s a Universal Greeting which expresses Hello even when you don’t share a language.\nThis is it:\nBa weep gra na weep ninny bong.\nHere’s a video. Try it out, let me know how it goes.\n",
    link: "/home/2014/12/02/filtered",
  },
  {
    title: "What happened at coffee morning two",
    date: "13.58, Thursday 4 Dec 2014",
    content:
      "Coffee morning two was this morning – great to see Bethany, Mark, Matt, Pierre, David, and Tom. Thanks for coming!\nAgain… Too Many Dudes. I totally need to work on this.\nWhat was it like? It turns out that both Bethany and I showed up early to do some email, so tap tap tap. Then Mark joined (Mark has just made an organically opening lamp shade at the Science Museum) so we shut our laptops and started chatting. Pierre I didn’t know, so I’m really pleased he showed up, and Matt was told about the coffee morning by Mark so I’m also pleased he came.\nMatt is from Bare Conductive which makes conductive ink and electronics that integrates with it. He told us this morning that in our studio, the light switches are painted on. You touch the wall and the light turns on.\nAlso their electronics board tells you how it works. Like, with a voice. The first time you turn it on, you plug in some headphones, touch a button, and it speaks to you – instructions, setup, etc. This anecdote came up while we were discussing creativity and R&D in a product company: What’s the right balance between exploring new ideas, and refining the product?\nDavid from Winnow gave another example… their internet-connected scales help commercial kitchens avoid food waste. The beta version of their software uses realtime weather forecasts to tell chefs if it’s going to be raining at lunchtime (if they know it’s going to be raining, they’ll prepare less food). Wonderful feature, totally in line with the mission. How do you make time to discover these new ideas, when you’re also working on scaling the product?\nAlso discussed was the news that it looks like the flagship Maker Faire in London, planned for 2015, is no longer happening. Sad news if they can’t find a new venue and the right support.\nThoughts\nI liked today, and I think what I like is that there can be many conversations all at once; a coffee morning is resolutely informal.\nThere’s also, for me, a hint that these coffee mornings could be a place where paths cross - not a “community” or group - gossip rather than knowledge, a street rather than a salon. That feels like the kind of thing I’d like to foster right now.\nSo I’ll keep doing it I think.\nNext coffee morning\nPencil in Thursday December 18th, 9.30 till whenever, at the Book Club again. I’ll confirm nearer the time, but that’s 90% certain as of today. Hopefully see you there.\n",
    link: "/home/2014/12/03/filtered",
  },
  {
    title: "Filtered for top-notch long reads",
    date: "11.22, Friday 5 Dec 2014",
    content:
      "1.\nThis well-illustrated piece on Chinese Mobile UI trends is full of great nuggets.\nMy favourite is that companies have adopted automated “chat” as their official public face. Each brand is a bot that runs inside one of the several apps that users in China have instead of Facebook, Twitter, WhatsApp, etc. How it works:\nYou can send any kind of message (text, image, voice, etc), and [the bot will] reply, either in an automated fashion or by routing it to a human somewhere. The interface is exactly the same as for chatting with your friends, save for one difference: it has menus at the bottom with shortcuts to the main features of the account.\nA couple more features:\nOther than that, every feature you can use in a normal chat is available here. WeChat even auto-transcribes the voice messages (mentioned before) into text before passing them to the third-party server running the account. Official accounts can also push news updates to their subscribers. Every media outlet operates one …\nI’m into this, I’m into this. Our western way for interacting with companies (assuming the shitty voice menu things are wildly out-dated) is websites, which we browse. But instead of browsing, a conversation?\nSo… cultural difference between China and the west, or just one of those forks in the road? Or a glimpse of the future?\n2.\nHooked on Labs (thanks Iain) draws a line between the practice of Robert Hooke in the 1660s and the modern trend for companies to have “labs.”\nLabs are places where people conduct experiments to test out theories. The new labs proliferating outside the hard sciences are a symptom of the spread of experimentalism as an ideology for how we should shape the future. Curiosity is at the core of experimentalist culture: it holds that knowledge should develop by being testable and therefore provisional …\nI like that the answer to “how should we invent?” can be not a process but a location. Other answers might be “a studio,” and “the field,” both of which suggest a variety of processes and practices without being pinned down.\nI guess my recent preoccupation with coffee mornings is about the same thing. Can the “coffee morning” as a place, with all its informality (which I am desperate to preserve), be a way to dowse the scenius, to allow invention to occur without process?\nAlso coffee.\nAnd this bit:\nOne vital source of this conversational approach to science was Copenhagen and the culture that Niels Bohr created around his institute for theoretical physics and his nearby home.\n…which reminds me of this terrific story about the development of the theory of electron spin and how it came together as Bohr travelled across Europe by train.\nAt the beginning of the trip:\nBohr’s train to Leiden made a stop in Hamburg, where he was met by Pauli and Stern who had come to the station to ask him what he thought about spin. Bohr must have said that it was very very interesting (his favorite way of expressing that something was wrong), but he could not see how an electron moving in the electric field of the nucleus could experience the magnetic field necessary for producing fine structure.\nAnd as Bohr travels from town to town, he meets scientists, hears arguments, develops his view, and carries information. Great story.\nI think of the interactions between scientists as the hidden particles that don’t show up in the traces of a cloud chamber. They’re there, busy - multiple - far denser and richer and messier than the clean interactions of the citations in scientific papers or at conferences - the invisible trillions of forks that are left out of Feynman diagrams. Those interactions are what really matter, and their stories are the most interesting of all.\n3.\nI mentioned a radio show on the American West the other day… that show mentioned a paper given in 1893 by one Frederick J Turner: The Significance of the Frontier in American History (chapter 1 only in the linked book).\nThree years earlier, the western frontier had been officially declared closed. In his paper, Turner argued that as “European germs” moved west from the Atlantic coast, America was created:\nMoving westward, the frontier became more and more American. As successive terminal moraines result from successive glaciations, so each frontier leaves its traces behind it, and when it becomes a settled area the region still partakes of the frontier characteristics. Thus the advance of the frontier has meant a steady movement away from the influence of Europe, a steady growth of independence on American lines. And to study this advance, the men who grew up under these conditions, and the political, economic, and social results of it, is to study the really American part of our history.\nIt’s both a wonderful history and a great point of view.\nBut this chapter is worth reading purely for the language and the metaphors. The variation of sentence length. The rhythms.\ncolonial settlement is for economic science what the mountain is for geology, bringing to light primitive stratifications.\nEvery river valley and Indian trail became a fissure in Indian society, and so that society became honeycombed.\nComplex society is precipitated by the wilderness into a kind of primitive organization based on the family.\nFor a moment, at the frontier, the bonds of custom are broken and unrestraint is triumphant.\nAnd now, four centuries from the discovery of America, at the end of a hundred years of life under the Constitution, the frontier has gone, and with its going has closed the first period of American history.\nBoom!\nThis is a paper written to be read aloud.\n",
    link: "/home/2014/12/04/coffee_morning_two",
  },
  {
    title: "Filtered for art and other intangibles",
    date: "18.03, Monday 8 Dec 2014",
    content:
      "1.\nAlgorithmically extended art.\nAlways wanted to see more of the night sky in Van Gogh’s Starry Night? Well now you can.\nMy. Mind. Is. Blown.\nThis is now a built-in function in the Wolfram Language so you can try it yourself.\nSee also Shapeme which can evolve images e.g. the Mona Lisa out of overlapping triangles, using a technique called simulated annealing.\nI don’t know what this means. It feels like all these new image-manipulation techniques and tools - Microsoft Hyperlapse which reconstructs 3D scenes from photographs then flies through them, seam carving, Kinect - will one day be bound together in a new kind of Photoshop, a realtime reality manipulator. We have all the bits.\n2.\nIn the UK, government websites are gradually being taken over by the Government Digital Service. The Design Principles are a work of art; the department has so far saved the taxpayer about a half a billion quid, and it won Designs of the Year in 2013. \nThe guide to Plain English is worth a read. Avoid using metaphors! For example\n\ngoing forward (unlikely we are giving travel directions)\none-stop shop (we are government, not a retail outlet)\n\n3.\nThe Internet Engineering Task Force is the group of people that makes the Internet work. I ran across this quote in The Tao of the IETF, one of their “founding beliefs”:\nWe reject kings, presidents and voting. We believe in rough consensus and running code.\nWhich reminds me of do-ocracy as an way to run an organisation: Doing a task is in itself justification for you being the person who does that job.\nWhich reminds me of the San Francisco hackerspace Noisebridge - which is do-ocratic to the extreme - and what happened when a monk moved in and erected a shrine With Hilarious Consequences:\n5) The shrine was erected and re-activated, and I believe Church cleared\nonce again, before Tuesday meeting. Crutcher, as the minutes show, said\nthat if it remained so prominent, ‘it is my personal plan to do-acrat that\nshrine to pieces with powertools tonight.’\n4.\nOnce a year, UNESCO adds nominated practices and expressions to the Representative List of the Intangible Cultural Heritage of Humanity.\nSome examples from the 300-or-so entries…\n\nTsiattista poetic duelling\nMongolian knuckle-bone shooting\nPractices and expressions of joking relationships in Niger\nMediterranean diet\nShrimp fishing on horseback in Oostduinkerke\nTurkish coffee culture and tradition\n\nWhen the aliens land and set up shop and they’re like, Guys, so what have you got? And we’re all… Uh, lasers? We’ll trade you lasers for a starship drive. And the aliens will be: Nope, what else?\nThen we’ll say: Tsiattista poetic duelling. Turkish coffee. Jazz.\nBingo.\nKudos to UNESCO for prepping our inventory ahead of time.\n",
    link: "/home/2014/12/05/filtered",
  },
  {
    title: "Filtered for making and alienation",
    date: "14.38, Wednesday 10 Dec 2014",
    content:
      "1.\nGifpop! Turn animated GIFs into actual physical prints using the magic of lenticular printing.\nLenticular stuff is brilliant. It reminds me of when I went to my 10 year school reunion and I was meeting all these people that I knew then but hadn’t seen since, and I would see them as how I saw them then - with all of those old preconceptions and outdated understanding - then suddenly see them instead with total unfamiliarity as a completely new and unique person, and then it would flip back and forth. And the reverb when that happens as you see two people at once, overlaid, displaced in time but both there in the present, flipping between the two, it builds like a loud buzz in your ears and fills your head. I haven’t used Gifpop! yet; maybe I should try to make that. Also they partner with artists and make limited edition gifpops. Super cool!\n2.\nKnyttan make on-demand, customised pullovers and scarfs. If you’re in London, you can go see your pullover being made on their knitting machines in Somerset House (they have a pop-up there).\nThe designs are gorgeous… they’ve teamed up with a bunch of designers to make generative art designs, you use the website to build on the patterning - herding the houndstooth flock around a scarf, or overlaying interference patterns - then select colours and size to suit you.\nThey have some pretty special animated GIFs.\nI’m currently based out of Techstars London and Knyttan is one of the startups in the programme, so I’ve got to spend a bit of time with them. (Incidentally, my mentoring experience at Techstars has totally convinced me about the value of accelerators for startups.)\nWhat excites me most in this area of “on-demand manufacture” is the potential for collapsing the supply chain. You design, you see your item being made. You don’t transport the item across the world. When - for cost reasons - you manufacture massive runs, it brings its own pressures: massive shipping containers, long lead times; the logic of marketing, credit, capital and mass consumption. “On-demand” (3D printing, computerised knitting machines) releases the chokehold of mass production.\nShorter supply chains means being closer to the means of production and to the people who work in the factories – a kind of de-alienation. It means geographically distributed manufacture, less pressure on having to make and then advertise and sell huge production runs. A different kind of world.\nSo that’s what I see. Plus beautiful knitwear, which is after all what really matters. \n3.\nPi-Top is a laptop built around the ubiquitous Raspberry Pi single board computer. If you want, you can 3D print your own chassis. There’s a lovely transparent window so you can see the electronics inside.\nWhich - you know what - cars should do too. I’d love a little window in my car (not that I have a car) so I can see it working. There’s something about electronics (which cars seem to be now) as opposed to mechanics (which they used to be) which makes it inhuman. Electronics are teeny weeny. You can’t see it. So I’m alienated from how my car works. Not, as I said, that I have a car. But I do have a microwave, and I’m alienated from how that works… whereas my grill, I can figure that out.\nIf I hadn’t had a spiritual experience involving transistors when I was 19, I’d be alienated from computers too. (That’s a story for another day.)\nSo when it comes to banks, or government, or policing, it’s very easy for me to be alienated from those things too - patted on my head and told not to worry myself about it - because I’m alienated from the stuff in my everyday life already, and I’ve become acclimated to that feeling. And that’s sad. And dangerous.\nMore Windows In Things.\n4.\nDo artifacts have ethics?\nWhen we ask whether technology is “moral” or not, is the only relevant question what can be done with it?\nA hammer may indeed be used to either build a house or bash someones head in. On this view, technology is morally neutral and the only morally relevant question is this: What will I do with this tool?\nMaybe there are more questions:\n… might I not also ask how having the hammer in hand encourages me to perceive the world around me? Or, what feelings having a hammer in hand arouses?\nAnd there follows a list of 41 questions that you might ask of a thing - a product, an object - as a start, to understand better what kind of role it has in our moral world.\nHere are some favourites of mine:\n\nDoes the use of this technology arouse anxiety?\nHow does this technology empower me? At whose expense?\nWhat feelings does the use of this technology generate in me toward others?\nCan I imagine living without this technology? Why, or why not?\n\nAnd,\n\nDoes my use of this technology make it easier to live as if I had no responsibilities toward my neighbor?\n\nI love this list.\nBlimey I’m banging on today aren’t I. Time to wrap up.\n",
    link: "/home/2014/12/08/filtered",
  },
  {
    title: "We Didn’t Start the Fire Pedia",
    date: "12.17, Friday 12 Dec 2014",
    content:
      "Here’s a list of all the things in We Didn’t Start the Fire by Billy Joel, ordered by Wikipedia article popularity (page visits in the month of November 2014).\nMost popular at the top. Page visits in parentheses.\n\nBerlin (1,080,805)\nEinstein (352,130)\nJ.F.K. blown away (325,980)\nKennedy (281,883)\nElvis Presley (245,866)\nSouth Korea (233,906)\nMarilyn Monroe (218,501)\nReagan (214,539)\nJoseph Stalin (209,276)\nDylan (187,512)\nNorth Korea (177,425)\nAIDS (157,598)\nRichard Nixon (153,397)\nRichard Nixon back again (153,397)\nHemingway (151,655)\nMalcolm X (147,612)\nEisenhower (125,292)\nBrando (123,981)\nLebanon (123,688)\nMoonshot (115,290)\nCastro (112,343)\nPrincess Grace (103,783)\nHarry Truman (97,320)\nTelevision (96,978)\nWatergate (96,187)\nJames Dean (95,731)\nPalestine (83,086)\nKhrushchev (79,498)\nPsycho (73,061)\nThe Catcher In The Rye (72,372)\nChildren of Thalidomide (70,547)\nWoodstock (68,833)\nPunk rock (65,845)\nRussians in Afghanistan (62,203)\nDoris Day (61,926)\nBuddy Holly (60,534)\nBay of Pigs invasion (59,399)\nKerouac (57,135)\nCharles de Gaulle (55,524)\nDisneyland (54,682)\nRed China (54,198)\nDacron (53,648)\nJoe McCarthy (49,314)\nEichmann (49,203)\nJoe DiMaggio (48,507)\nHo Chi Minh (46,511)\nBardot (46,293)\nAyatollah’s in Iran (44,963)\nMarciano (44,101)\nMafia (43,957)\nTrouble in the Suez (43,446)\nSputnik (40,023)\nLiberace (39,491)\nCrack (39,256)\nLawrence of Arabia (38,190)\nU-2 (37,172)\nBen-Hur (36,544)\nNasser (36,001)\nAlabama (34,247)\nCommunist Bloc (33,882)\nSugar Ray (32,193)\nJohn Glenn (31,611)\nLittle Rock (30,717)\nRosenbergs (28,928)\nForeign debts (28,810)\nVaccine (27,660)\nWheel of Fortune (27,337)\nBudapest (25,983)\nH-Bomb (24,831)\nBridge On The River Kwai (23,994)\nProkofiev (23,294)\nCalifornia baseball (23,170)\nListon beats Patterson (21,290)\nPope Paul (21,015)\nSally Ride (20,840)\nJuan Peron (20,776)\nThe King And I (19,836)\nTerror on the airline (18,693)\nBirth control (18,027)\nPeter Pan (17,142)\nDien Bien Phu Falls (16,703)\nMickey Mantle (16,278)\nSouth Pacific (15,976)\nStudebaker (15,908)\nSantayana (15,903)\nChou En-Lai (15,744)\nBegin (15,424)\nStranger in a Strange Land (15,086)\nBernie Goetz (14,452)\nStarkweather Homicide (14,130)\nEdsel is a no-go (13,418)\nBelgians in the Congo (13,165)\nChubby Checker (12,051)\npayola (11,996)\nRock and roller cola wars (11,936)\nRoy Cohn (11,566)\nPasternak (11,113)\nHeavy metal suicide (11,069)\nSyngman Rhee (9,726)\nEngland’s got a new queen (9,696)\nBritish politician sex (9,446)\nJohnnie Ray (9,013)\nRock Around the Clock (8,655)\nMalenkov (8,234)\nHula hoops (7,999)\nHomeless vets (7,809)\nSpace monkey (7,796)\nBritish Beatlemania (7,141)\nToscanini (6,212)\nRockefeller (5,902)\nBrooklyn’s got a winning team (5,268)\nPanmunjom (4,842)\nWalter Winchell (4,680)\nCampanella (4,657)\nPeyton Place (4,071)\nOle Miss (3,945)\nDavy Crockett (3,745)\nChina’s under martial law (2,342)\nHypodermics on the shores (753)\n\nList of pages mostly taken from the Wikipedia entry for We Didn’t Start the Fire, and page view count from the Wikipedia article traffic statistics service.\n",
    link: "/home/2014/12/10/filtered",
  },
  {
    title: "Filtered for storytelling",
    date: "19.52, Sunday 14 Dec 2014",
    content:
      "1.\nCracking profile of Billy Joel in the New Yorker from October, Thirty-three hit wonder.\nLong. Full of good word nuggets.\nThe saxophone is the radiocarbon.\nI seem to be reading a lot of New Yorker articles recently. My current magazine subscriptions are The Economist and the London Review of Books which is max capacity. Maybe time to change it up.\n2.\nThere’s a new place in Shoreditch that only sells breakfast cereal. It’s called Cereal Killer Cafe. There’s a portrait of Hannibal Lector made out of Cheerios on the wall.\nRob Manuel visited, expecting to hate it, and didn’t. Lovely story, good luck to them.\n3.\nI’ve been totally immersed this weekend in the iPhone game A Dark Room – minimalist, just text and tapping, and what a picture it paints.\nDon’t read any reviews, just play it with no preconceptions. Absolutely top fucking notch, best game I’ve played all year.\nOnce you have played, here’s the development blog.\nAlso on my iPhone:\n\nWorkflow which lets you link together actions (“take a photo”, “make a GIF”, “tweet it”) and create custom, automated workflows that you can run from the home screen or wherever there’s a Share button. Official site. The app has tons of examples.\nPocket Storm plays a thunderstorm from crickets to deluge to fading out again, you choose how long it lasts from 5 minutes to an hour. Different each time.\n\n4.\nVery excited – Adam Curtis has a new film out in January: Bitter Lake.\nPoliticians used to have the confidence to tell us stories that made sense of the chaos of world events. But now there are no big stories and politicians react randomly to every new crisis - leaving us bewildered and disorientated. And journalism - that used to tell a grand, unfurling narrative - now also just relays disjointed and often wildly contradictory fragments of information.\nHere’s the trailer. (Down at the bottom of the blog post.) So good.\nCurtis’ style is distinctive – a collage of archive footage and music with CAPS stamped over it, and the essay in his own voice. This new film is about the stories that politicians tell - and Afghanistan and all the usual politics - but also looks like it’ll be about journalism and his own technique:\nIt tells a big story about why the stories we are told today have stopped making sense. But it is also an experiment in a new way of reporting the world. To do this I’ve used techniques that you wouldn’t normally associate with TV journalism. My aim is to make something more emotional and involving - so it reconnects and feels more real.\nLooking forward to this enormously.\nCurtis’ The Century of the Self (2002) is on Vimeo – part 1 here.\nBooks\nI recently finished The Art of Captaincy by Mike Brearley. Brearley was England cricket captain in the late 1970s, and one of the most successful in recent decades. Then later, President of the British Psychoanalytical Society. The book is exactly as excellent as you can imagine – and has a tendency to illustrate points with detailed anecdotes about moisture on the wicket and fielding positions.\nAnd also The Cyberiad by Stanislav Lem, funny short stories about robots who invent weird things in a galactic civilisation of robots. Here’s how it opens: One day Trurl the constructor put together a machine that could create anything starting with n. – read How the World Was Saved.\n",
    link: "/home/2014/12/12/billy_joel",
  },
  {
    title: "Coffee morning three",
    date: "12.25, Monday 15 Dec 2014",
    content:
      "Pop the date in your calendar! Coffee morning three is this week. Sort-of-hardware-ish.\nThursday 18 December, 9.30am till whenever, the Book Club in Old St.\nCoffee morning two was fun. This will be the same… Zero structure, many conversations all about nonsense maybe with a slight hardware bent, a half dozen or so people, open to anyone!\nI’ve been thinking about why I’m organising this coffee mornings, beyond the whole “there isn’t enough time in the day to meet all the interesting people I’d like to, so meet everyone on Thursday mornings” thing, and because I really enjoy introducing people to other people and having that work. I think it’s because there’s a mode of thinking which I miss now I’m no longer working in a studio, and that’s informality. It’s the tea-in-the-kitchen chats that make me laugh and spark new thoughts. And that sort of informal serendipity comes from a weird mix of rhythm and randomness. Which means I like having a regular time but not regular attendees. It’s just whoever fancies coming that day… I don’t want to build a community! But maybe a street corner. I think I’ll carry on these coffee mornings into 2015, every couple of weeks probably.\nSo, next coffee morning is this Thursday, hopefully see you there, and let’s chat! If you see someone you don’t know, say hello, and if you think two people should talk then make that happen! Recreational catalysis.\nThere may be crackers containing festive hats. It depends on how organised I am.\nCome along!\n",
    link: "/home/2014/12/14/filtered",
  },
  {
    title: "Red, yellow, green, bice, plunket, plaid",
    date: "09.35, Tuesday 16 Dec 2014",
    content:
      "Opening lines of Wikipedia articles on various colours:\n\nRed. Red is the color at the end of the visible spectrum next to orange and at the opposite end from violet. The wavelength of red light is approximately 620–740 nm on the electromagnetic spectrum. Red is the color of blood …\nYellow. Yellow /[phonetic]/ is the color of gold, butter, and ripe lemons. In the spectrum of visible light, and in the traditional color wheel used by painters, yellow is found between green and orange. It is a primary color in subtractive color. Yellow is commonly associated with gold …\nGreen. Green is a color on the spectrum of visible light, located between blue and yellow. It is evoked by light with a predominant wavelength of roughly 495-570 nm. In the subtractive color system, used in painting and color printing, it is created by a combination of yellow and blue, or yellow and cyan …\nBlue. Blue is the colour of the clear sky and the deep sea. It is located between violet and green on the optical spectrum. Surveys in the U.S. and Europe show that blue is the colour most commonly associated with harmony, faithfulness, confidence, distance, infinity, the imagination, cold, and sometimes with sadness.\n\nDo nanometers help?\np215-218: Table 33, Color words in Samuel Johnson’s Dictionary (1755).\n(I found a file on my computer with the above title. Pages 215-218 of what? The notes are probably from when I was researching Making Senses back in 2006… but the actual source? Possibly Folk Taxonomies in Early English (Anderson). Dunno. Anyway, here are my favourites.)\nBlack\n\nbistre “A colour made of chimney soot boiled, and then diluted with water, used by painters in washing their designs.”\nlutarious “Of the colour of mud.”\n\nWhite\n\ngrisly Defined as “Dreadful; horrible; hideous; frightful; terrible,” but several citations make it clear that grisly is a color word.\nhoar “1. White. 2. Grey with age. 3. White with frost.”\n\nRed\n\nlake “A middle colour, betwixt ultramarine and vermilion, yet it is rather sweet than harsh. It is made of cochineal”\nroan Citation: “Roan horse is a horse of a bay, sorrel, or black colour, with grey or white spots interspersed very thick.”\nrubican “Rubican colour of a horse is one that is bay, sorrel, or black, with a light, gray, or white upon the flanks, but so that this grey or white is not predominant there.”\n\nGreen\n\nbice “The name of a colour using in painting. It is either green or blue.”\n\nBlue\n\nceruleous, cerulean “Blue, sky coloured.”\nplunket “A kind of blue colour.”\nwelkin “sky-coloured”\n\nAlso\nAlso, hyper-red.\nSynaesthesia is when you, for example, “see” the printed number 5 as green, and 2 as green. Or hear C-sharp as blue. I swear I remember reading about an experiment where - when a synaesthesiac sees the number 5 as red - the number 5 is also printed in red. And the resulting colour: HYPER-RED.\nBut I’ve been combing The Phenomenology of Synaesthesia (Ramachandran and Hubbard) which is the go-to paper on such questions (for example, Does it matter whether the letters are upper or lower case? Yes it does)… and I can’t find anything. Am I mis-remembering?\nFinally: A list of fictional colours. Plaid is one of the colors outside of the natural human spectrum visible to large intelligent arachnids in Vernor Vinge’s novel A Deepness in the Sky. Cracking book that.\n",
    link: "/home/2014/12/15/coffee_morning_three",
  },
  {
    title: "Filtered for nematodes and Uniqlo",
    date: "15.25, Wednesday 17 Dec 2014",
    content:
      "1.\nThe nematode worm Caenorhabditis elegans (C. elegans) is tiny and only has 302 neurons. These have been completely mapped and the OpenWorm project is working to build a complete simulation of the worm in software. A neuron map is called a connectome.\n(In May, OpenWorm achieved a successful Kickstarter to run the worm’s brain in a web browser.)\nOne of the OpenWorm founders has hooked up the software connectome to sensors and wheels in a Lego robot body: A Worm’s Mind In A Lego Body.\nIt’s a funny threshold to cross without much fanfare, the first brain upload.\nIs this Artificial Intelligence? What’s A. about this A.I.?\nRelated: The four-colour theorem which was the first to rely on Proof By Computer. Instead of being solved mathematically, every single of the vast number of cases was checked by a computer program. Does this count as a proof? Controversial at the time, more common now.\nRelated: Slime mold robot. Related: Cyborg cockroaches.\nCaenorhabditis elegans. C. elegans.\nIs the uploaded nematode a new species? If so, what do we call it?\n2.\nBooks are back in the UK. E-book sales have peaked at 30%; Waterstones (major but recently troubled chain bookshop) is beginning to open new branches.\nOld books undergo acid hydrolosis – lignin, which binds the fibres, oxidises into acids which break down the cellulose. The organic compounds released smell of vanilla and almonds.\n3.\nI mentioned the Cereal Killer cafe the other day… here’s another perspective:\nCereal Killer Cafe, the London Review of Breakfasts.\nA wave of nausea suddenly hits me. I’m staring at my notes and the room feels like it’s breathing. Then the rest just pours out. ‘Is your cafe ironic? Do you really like ADHD kids food? Or just jokingly like it? Is there really anything to celebrate here beyond a profound efficiency in the delivery of deadly consumption habit forming food to minors? Or is that the point?’\nMust read.\n4.\nI get a few specific items from particular brands. For the basics, I love Uniqlo. Great clothes.\n…maybe a little bit because I’m in love with their slogans, which every employee must memorise, as related in this GQ article on Uniqlo.\nUniqlo is clothes that suit your values.\nUniqlo is how the future dresses.\nCHANGE OR DIE\nFast Company on Uniqlo: We are not a fashion company, … We are a technology company.\nAt the factory, a technician hands me a packet of small white pellets that look like albino peppercorns. These are the seeds of HeatTech.\nUniqlo is beauty in hyperpracticality.\nUniqlo is clothing in the absolute.\nIn Snacks for a Fat Planet (New Yorker, 2011), it turns out that PepsiCo have invented a new kind of salt. So we wondered, was there a different kind of salt crystal that would produce the same taste curve but with less salt?\nYes: ‘We don’t know the molecular structure of the salt receptors, and we don’t really understand the mechanism by which salt works,’ Khan went on. Nevertheless, collaborating with crystal technologists in Munich, PepsiCo was able to develop ‘15 micron salt,’ a new kind of salt that produces the same taste curve as the salt the company has been using - a pyramid-shaped crystal known as Alberger salt - but contains twenty-five to forty per cent less sodium. PepsiCo first used the new salt on its Walker brand of chips, which it sells in the U.K. By the end of 2012, 15 micron salt will be flavoring many of the Lay’s plain chips made in the U.S.\nIce-nine.\nA.I. elegans.\nTHEY INVENTED A NEW MOLECULE JUST FOR CRISPS.\n",
    link: "/home/2014/12/16/colours",
  },
  {
    title: "Connected products trip up the incumbents",
    date: "13.12, Friday 19 Dec 2014",
    content:
      "Coffee morning three! Six of us this time: Josh, Gavin, Alex, Raph, and Daniel. Thanks for coming!\nI kept some notes…\nSomething about commissioning a sit-com pilot about open data?\nSexy turducken. Don’t ask.\nFridgeezoo fridge pets. Which are SO CUTE.\nAnd a long, rambling conversation that had no conclusion but - to my mind - is the most interesting consequence of web-connected products and the new hardware startups.\nWhich is that manufacturers never spoke to consumers before. They spoke with distributors and retailers. But now products are connected to the internet, manufacturers suddenly have a relationship with the consumer. And they literally don’t know what to do. Should marketing look after this? Or product development? Or customer service? Or should it be outsourced to an agency, like advertising?\nFor instance… the “Tips” application on the iPhone. Who looks after that? Who makes sure the content is good? Apple is an exceptional company, and they care about customer experience at every level. But could Bosch do this? Or Magimix?\nIf companies don’t get this right, their products won’t be any good. But to get it right, they need to restructure. I saw this challenge multiple times while we were consulting on new connected products.\nBut the incumbents will find it hard to adapt. Which leaves the door open for new hardware companies who behave more like companies that run websites: In touch with their community, selling direct, a product group that cares about the product in-use not only until the moment it leaves the factory.\nAlso.\nAlso we had crackers and festive hats. Proof.\nNext coffee morning\nI’m loving this different mix of people each time thing. I was fully expecting to sit on my own doing email, and ended up having a brilliant and funny bunch of conversations. A proper little street corner!\nNext coffee morning: Thursday 15 January, 9.30am till whenever, the Book Club again.\nPop it in your calendar, it’d be lovely to see you.\n",
    link: "/home/2014/12/17/filtered",
  },
  {
    title: "Filtered for washing machines",
    date: "14.22, Friday 19 Dec 2014",
    content:
      "1.\nThe Kindly Brontosaurus, The amazing, prehistoric posture that will get you whatever you want, whenever you want it.\nIt works like this:\nYou must stand quietly and lean forward slightly, hands loosely clasped in a faintly prayerful arrangement. You will be in the gate agent’s peripheral vision-close enough that he can’t escape your presence, not so close that you’re crowding him - but you must keep your eyes fixed placidly on the agent’s face at all times. Assemble your features in an understanding, even beatific expression. Do not speak unless asked a question. Whenever the gate agent says anything, whether to you or other would-be passengers, you must nod empathically.\nI vaguely remember reading an article about holding eye contact for one beat longer - four rather than three seconds - and how persuasive that is. But I can’t find the article now, Google just returns a ton of blog posts about flirting.\n2.\nContent, Forever starts with whatever Wikipedia page you want, then gives you an auto-generated article (for however many minutes read you want), rambling through paragraphs of interconnected articles.\nRelated: Nieman Lab predictions for the future, generated with a Markov chain generator.\nComputational social scientists are already working on wearable technology, however, they are tackling interesting problems, and I personally look forward to reading the email lists where she asks her question about how to be able to quickly iterate and push ideas to market, all while empowering culture changes along the way for customers who advertise with media companies with giant databases of information that makes up articles.\nFewer and fewer shut-off valves.\n3.\nThe Studio D End of Year Report led me to their custom-design zero branding duffle bag: D3 Traveller.\nWhich I now want to own, of course. Ultragibson.\n4.\nShirts wash part 1, on YouTube. Via @philgyford who said Brilliant (if shaky) mundanity: … A boy’s multi-part commentaries of washing machine cycles.\nIt’s like we’re see this boy before he’s been infected with society’s idea of what constitutes news. The sacred and the profane. Don’t take the piss, this is good.\nMalden level crossing.\nSomething brilliant about seeing through somebody else’s eyes, the ambient sound and everything.\n",
    link: "/home/2014/12/19/coffee_morning",
  },
  {
    title: "Rambling nonsense about Bitcoin, more",
    date: "15.23, Monday 22 Dec 2014",
    content:
      "reddit closed $50MM funding last September (175 million monthly active users. Massively multiplayer topic-based pub banter.) They promised to give 10% of the shares to the community, and they’ve just said how:\nAnnouncing reddit notes. To celebrate all of you and your contributions, we plan to give away reddit notes in a random lottery. As of this point, it looks like we’re going to have approximately 950,000 reddit notes to divide among active user accounts.\nreddit notes will be a digital currency, used for tipping good comments and other in-community transactions, backed by approx. $5MM in shares. You’ll be able to buy and sell them for dollars. As reddit-the-company gets more valuable and approaches IPO, reddit notes will grow in value because - hopefully, one day - the shares will be worth actual money on the primary market.\nSee also Storj which is cloud storage - like Dropbox - except that in addition to paying for online storage, you can rent out spare space on your hard drives for other people to use, and get paid for that. Behind the scenes it’s based on Bitcoin, the cryptocurrency and distributed secure ledger.\nWhat’s significant about reddit notes is that they’re tied to the success of the company. If you have notes, you share in the upside as the value grows. If you contribute to the success of the company by being popular in the community, you’ll accumulate more notes via tips from others.\nBitcoin will be the underlying technology for reddit notes too.\nRemember when Instagram sold? The value of the company is the value of the community. I finished that post by writing More interesting to me is the question of what happens when the workers organise, and demand a wage that is transferrable between the island economies of the internet. I’ve absolutely no idea what that would even look like, a transferrable store of labour but one in which the act and value of labour is contextually variable according to its position in a social network. But I can’t imagine money itself looked entirely obvious before it was invented either.\nSo what if every company had its own currency used for shares in the company, for resource allocation by the company and community (e.g. balance of online storage used and provided, or - say, with Uber - to replace surge pricing and balance the number of drivers and customers), and to reward the community? And if that currency could be exchanged for dollars?\nDisclosure: I’m current an Entrepreneur in Residence at Techstars London. One of the companies in the cohort is Swarm and this is what they call crypto-equity.\nBitcoin\nI’m interested in Bitcoin because it can be used as the underlying technology for applications like reddit notes and crypto-equity.\nBitcoin is technical and has lots of new concepts all at once, but it’s not that complicated. How the Bitcoin protocol actually works.\nThe article that really nails it: Bitcoin isn’t Money – it’s the Internet of Money.\nThe internet: Core Internet protocols, such as TCP, part of the ‘transport layer,’ shuffle packets of data around, but they don’t define how the exchange of packets is then used to create meaningful communication. Internet applications, such as email and the World Wide Web, are defined in protocols implemented on devices at the edges of the network, like servers and home computers, not in the guts of the network: routers, switches, hubs, and exchange points.\nWhich means: The Internet model improves upon the traditional telephone model by making possible what Vint Cerf calls ‘permissionless innovation.’ Tim Berners-Lee was able to launch the World Wide Web without waiting for Internet service providers to support it.\nPermissionless innovation is the key. Plus the distributed nature of the internet… lots of applications can work together without the people who make them needing to be in the same team. And also the layers! The bits and bytes of the internet keep moving around, even while a particular webpage might render badly.\nAs the internet is for data, Bitcoin is for money.\nLook at the banks… they’re horribly inefficient when it comes to technology. Vertically integrated stacks of slow moving, expensive code. There’s no incentive to upgrade this technology because it’s a protective moat against smaller, more agile competitors who can’t afford to enter. So the banks end up being these giant bundles of all the services they provide… foreign exchange, letters of credit for international trade, investment, mortgages and overdrafts, merchant accounts, online balance checking. Why should the same organisation provide all of these things?\nWell, if you did try to make interoperating technology for all these services, it probably wouldn’t work. It would be insecure and error-prone. Translating between data and currency the whole time would make things inefficient. Hackable. But base it all on Bitcoin? Treat Bitcoin and the blockchain as the architecture for interop between all the different bits of a bank’s technology?\nMaybe, in the future, these monolithic banks will provide infrastructural and corporate applications only, all the other services fulfilled by an ecosystem of small and medium businesses.\nMaybe there will be a business that just does overdrafts. A business that just does real-time credit risk. A business that just sweeps your spare change into investments.\nUnbundle the banks!\nDeep value chain sectors\nThere are these industry sectors that are dominated by huge, monolithic, vertically integrated companies.\nFor example, the toy industry has history been able to prevent competitors entering using a combination of: difficulty accessing distributors and retailers; the economics of mass production demanding mass consumption and therefore mass media. This is being undermined by direct sales (e-commerce) and marketing via social media.\nOr newspapers and magazines. Being unbundled under the pressure of the internet.\nThese get broken up in a death of a thousand cuts.\nAnd then there are new technologies which are coming in that demand a whole ecosystem of new businesses to really take advantage of them, and force existing businesses to restructure to avoid being left behind.\nFor example, as I said the other day, to take advantage of the Internet of Things, existing manufacturers will need new teams and new departments to figure out how to speak directly with consumers.\nThe Internet of Things (IoT) is a proper deep value chain sector. I can’t think of a single business that could do everything from the product manufacturing, the wireless chip design and fabrication, the back-end web services, the community management, and the design, marketing and customer service. There are a dozen decent size businesses at every step of that.\nWhen I think of IoT, I think of that bit in The Graduate, I wanna say one word to you. Just one word. Are you listening? Plastics.\nPlastics? Like, pacemakers or wind turbines? Putting it out the ground or selling it in shops?\nAnd one of the things that preoccupies me (working with startups, and having been immersed in the Internet of Things for a decade) is: what do you do, as a business early into these deep value chain sectors? You have to throw a line across the canyon to ship any product at all, but you’ll get out-competed by people who wait for the ecosystem to appear.\nTwo other areas I’m keeping my eye on:\n\nArtificial intelligence. Algorithms, robots, computer vision, futures markets as information processing, neural networks for toys. The applications of these technologies are a long way from their first implementations. Bringing A.I. to market will be a long process.\nLet’s call it 3D printing. But really what I mean is the telescoping collapse of the supply chain. We manufacture right now in Shenzhen and other clusters because of economies of scale, and because of the network effects between factories. But alienation from the supply chain is beginning to bother us (finding horse meat in our lasagne as one example), and new technologies are beginning to undermine the pressures that lead to mass production. What will happen when a local factory can keep a catalogue of everything they want to provide, and re-stock the shops overnight? The thing is, these new technologies of manufacture bring with them their own aesthetic. So part of productising 3D printing is to make it desirable. But when this really takes off? When e-commerce and pick-up points are properly built out, when commerce and awareness can travel along the vertices of the social graph, when manufacturing is small scale and local? What then?\n\nAlso-watching-but-less-informed-about: Space.\nEnough already\nI’m rambling I know. And I haven’t edited these notes so they’re a blimmin mess stream of consciousness.\nBut the meta I’m trying to figure out is: when you spot that one of these deep value chains is at the beginning of a big reconfiguration, what do you do? How do you enter it as a small business? How, as a national economy, do you help it along and make sure the transition happens healthily?\nUpdate: Good grief, I wrote a lot more.\n",
    link: "/home/2014/12/19/filtered",
  },
  {
    title: "Filtered for the future of the firm",
    date: "17.57, Tuesday 23 Dec 2014",
    content:
      "1.\nThere are these cars around London that seem a bit like Zipcar - the car sharing service - but you can leave them anywhere. Or at least, in most parking bays. So they kind of float around. The app tells you where the nearest car is.\nWhich is like Uber with no drivers?\nHow far could this go?\nNo parking bays. I know Zipcar give you credit for getting the car cleaned. Or at least they used to. Could that be included… and gradually raise the credit you get until somebody is motivated to do the cleaning?\nAnd to get them repaired? What if you get credit for car maintenance?\nThis is why I’m into the idea that companies are resource allocation markets.\nWhat if the company doesn’t even supply any cars, just the marketplace. You get credit if you supply cars. Or rather, you get car-marketplace-currency, which is itself a fraction of the ownership of the marketplace, and the value of your share goes up as the entire system is utilised.\nWhat else could this be applied to?\nI’m playing with a startup idea at the moment that involves inventory and many concession stands, each of which need to be staffed. So I treated this as a toy… what if Bitcoin was used for resource allocation, what then? If someone supplied a concession stand, they would get paid in credit. If some staffed a stand, they would receive a wage in credit. If someone repairs a stand: credit.\nCredit is backed by a certain number of shares in the company, so they’re worth something. When somebody purchases some of the inventory, that’s profit for the company; when that dividend is paid out, it is paid in proportion to the shares, and so the credit can be exchanged for dollars.\nThis would be simple, using Bitcoin.\nThen I asked myself: What would be the benefits of running the business like this?\nTwofold:\nCurrently, a business like this would track its assets, liabilities, etc, using double-entry book-keeping. The prepared accounts are used to manage the business and allow it to invest in more assets and achieve more income. But the accounts are a model. They’re a map of the territory, not the territory itself. They’re hard to maintain, and they don’t integrate well with the business.\nBut use Bitcoin? There is no book-keeping because your activities in running the business are the same as recording it.\nMore importantly for a startup business: The job of finding the right prices can be thought of like game balancing… like finding the right cost of wheat in the economy of Farmville. We know how to do that.\nThe accounts - and the business model itself - become something that can be iterated in code to achieve financial growth, just like A/B testing the code of a website to get user growth.\nOkay, this is a long way off. The costs of setting up this system would be prohibitive. But when someone makes the tools…\n2.\nSo here’s a classic long read for the holidays: A Brief History of the Corporation: 1600 to 2100.\n(…which was last in my head when I used to write weeknotes at Berg, back in week 315.)\nThe piece ends by speculating what happens after the traditional corporation is a spent force…\nAnd when that shift happens, the Schumpeterian corporation, the oil rig of human attention, will start to decline at an accelerating rate. Lifestyle businesses and other oddball contraptions — the solar panels and wind farms of attention economics — will start to take over.\nAnd:\nWithout realizing it, the hundreds of entrepreneurs, startup-studios and incubators, 4-hour-work-weekers and lifestyle designers around the world, experimenting with novel business structures and the attention mining technologies of social media, are collectively triggering the age of Coasean growth.\nCoasean growth? Coasean growth is fundamentally not measured in aggregate terms at all. It is measured in individual terms. An individual’s income and productivity may both actually decline, with net growth in a Coasean sense.\nI don’t know what this means. But it makes me wonder.\nThe author names “Coasean growth” after the Nobel prize-winning economist Ronald Coase: He is best known for his work on transaction costs, social costs and the nature of the firm.\n3.\nWhy do companies exist? In The Nature of the Firm (1937), Ronald Coase put it down to transaction costs. In short, companies exist because it’s cheaper to have an organisation that does the necessary activity internally than to use the free market outside it. Why? Because using the market - the price mechanism - itself has costs.\nHere’s a summary of Coase’s paper:\nThere are costs to using the price mechanism for coordinating economic activity. ‘transaction costs’ or ‘marketing costs’\nFor example, if you want someone to carry your goods from the warehouse to your shop, first you have to find someone. That’s tough. It’s easier when lots of people who need carriage and lots of people who provide carriage come together – on a website or in the Yellow Pages. That’s a marketplace. But at a certain threshold, it’s easier still to just employ those people.\nFirms exist to economize on the cost of coordinating economic activity.\nFirms are characterized by the absence of the price mechanism.\nThis insight is old, but it makes my head spin.\nBecause it has two implications.\nFirst is that the internet has made much easier both forming marketplaces and negotiating prices. Amazon is a marketplace where buyers and sellers are brought together, and prices change fluidly. Uber has a bottled marketplace: It doesn’t employ its drivers, but they transact via Uber. And pricing is dealt with half by algorithm (increase the price till there are enough drivers) and branding (passengers never negotiate).\nSo as markets and pricing get easier still, firms can get much smaller – ad hoc value chains assembled out of code and culture, barely anyone working at the company at all.\n(Though we have to ask: If online marketplaces are so efficient, how can Amazon afford to buy the third party book sellers on their platform? There must be some efficiencies to being inside the firewall of the firm.)\nThe second implication is that the firm, no matter how small, can have a kind of hinterland of value providers - a community of users who post pictures, drivers who transport passengers - who, although technically not inside the firm, are as part of it as a spider’s web is part of the spider, or a beaver’s artificial lake is part of the colony.\nIf the firm is thought of as contouring transaction costs, and these costs are radically lowered…\nAnd if…\nNot only are we realising that functions that used to be part of a firm are now outside it,\nbut also that functions that have always been outside of the firm should actually be thought of as being part of it - for instance, realising that the community of a website should be rewarded like workers or owners, such as when reddit is giving partial ownership of its company to its users - then we need a new understanding of what a firm is.\n4.\nThere’s some kind of fight online about some kind of technology something something. Dunno.\nBut in a smart piece asking people maybe to just chillax, Quinn said something that caught my eye:\nThis age has put a group of maladjusted geeks, of which I would happily count myself one, into an historical role of giving input into what human agency will mean long after we’re all dead.\nYup.\nWe should take that seriously.\nSo, y’know, the idea that a corporation - an organisation for orchestrating human endeavour to deliberate ends - an entity invented in the 1600s, and entity which BY ITS INESCAPABLE LOGIC forces us into mass production, mass consumption, mass media, alienation and the loss of individuality, and all kinds of ugly inhuman shit… the idea that we can re-invent the corporation, and create new forms of it: That’s interesting.\nThe idea that we might create a type of organisation which is empowering, has local value which doesn’t mean everything gets coerced into the value of giant companies, is smaller, can be interrogated and critiqued because it’s just code, that avoids the priesthoods of capital and law.\nThat a company might be a fuzzy-edged thing, where consumers are owners too…\nBack in the 1960s, the US Department of Defense funded the development of ARPANET which became the internet, a made-out-of-whole-cloth dropped-into-history collection of protocols, practices, computers and networks, which I reckon probably had to be created all at once, because it couldn’t evolve, incubated just like that.\nAnd if DARPA came along now and said, Hey Matt, What Next?\nI’d say: Make a little bottle-city company that embodies all of this. Consumer-owners, internal currencies for resource allocation, corporate governance as executable code, doing an actual interesting tractable not-too-ambitious thing. Half co-op, half lifestyle business, half startup. Show what happens when we use capital, instead of capital using us. Do it simply and elegantly. Make a little nest of these companies.\nThen sit back and see what happens.\n",
    link: "/home/2014/12/22/ramble_about_bitcoin",
  },
  {
    title: "Filtered for elephants and apocalypse",
    date: "10.29, Wednesday 24 Dec 2014",
    content:
      "1.\nThis elephant can speak Korean. It puts its trunk in its mouth to make the sounds.\nVocabulary:\n\nhello\nno\nsit down\ngood\napparently one or two other words but these are not disclosed by the article\n\nThe elephant’s name is Koshik.\nSee also: Cat barking like a dog and getting caught.\nSee also: Fictional speculation that the English word “hawk” is from crow-language.\nSee also: The Author of the Acacia Seeds.\n2.\nHow Frozen took over the world, in the New Yorker.\n(Yes, I just cancelled my subscriptions to the London Review of Books and the Economist, and started one to the New Yorker.)\nWhat an awesome movie. I saw it for the first time last night.\nThe first act is perfection. Zero narrative slack. Wall-E is the only other animated picture that does that so well.\nThen the lack of villains… the sisters… I totally understand why this movie is so popular.\nPlus, girls. Aren’t most of Pixar’s movies most appealing for boys-and-dads?\n3.\nHere’s one of my favourite stories.\nAn aquarium in Fushun, China, has dolphins. In 2006, two dolphins swallowed some plastic and the vets couldn’t get it out.\nBut they realised that China being China - a billion plus humans - they also had the world’s tallest man. And the world’s tallest man has the world’s longest arms. And the world’s longest arms could reach down the dolphins’ throats and pull the plastic out.\nSo they called him up - Bao Xishun, Mongolian herdsman, world’s tallest man - and he came along and saved the dolphins.\nOne of his arms is 1.06m long.\n4.\nEngineer Joshua Pearce explains how to feed 7 billion people after a global catastrophe.\nAll the trees would be dead, for lack of light. And so we would need to significantly ramp up our rate of cutting trees down. Plus, temperatures would drop. We looked at a 10-degree and a 20-degree scenario. In the 20-degree scenario, you start having things like say, all of the wood in Canada freezes. That type of problem. Even if we want to do things like chop the wood down and get fields of mushrooms and that kind of thing, frozen wood is much more difficult to deal with. … We’re probably the first to ever calculate how many chain saws there are in the world and what their duty cycles were and how fast we can manufacture them in order to make sure that we had enough cutting power.\nDidn’t see any of that in Frozen.\nBooks\nI just finished reading The Three-Body Problem by Cixin Liu (translated by Ken Liu). Intriguing because there’s an explicit parallel to the Cultural Revolution that runs through the whole book, and it’s a challenging idea (this is the first of a trilogy which is currently bonkers popular in China). Also there are some hard sci-fi ideas in the back third of the book that I’ve never seen anywhere else. No spoilers, but:\nan important mark of a civilization’s technological advancement is its ability to control and make use of micro dimensions. Making use of fundamental particles without taking advantage of the micro dimensions is something that our naked, hairy ancestors already began when they lit bonfires within caves. … From the perspective of a more advanced civilization in the universe, bonfires and computers and nanomaterials are not fundamental different.\nThere are some narrative quirks that I’m not sure I like or not… odd shifts in point of view, and flourishes that remind of mid-century American sci-fi. Unimportant in the scheme of things. Solid read, give it a go.\nMerry Christmas if that’s a thing you celebrate! I do, it’s going to be a cracker.\n",
    link: "/home/2014/12/23/corporations",
  },
  {
    title: "Filtered for four easy pieces",
    date: "11.30, Saturday 27 Dec 2014",
    content:
      "1.\nThe different euro banknotes are illustrated with bridges. To avoid favouring any particular member state, the bridges are fictional.\nExcept that a new housing development in the Netherlands has gone and built them all. Classic.\n2.\nFrom before Google, questions received by the New York Public Library.\n\nIs it possible to keep an octopus in a private home?\nWhat does it mean when you dream of being chased by an elephant?\nHow do you put up wallpaper?\n\nIn the early 1900s, physics was regarded as a solved problem. It was all figured all, all just a matter of cranking the handle, bar one or two loose threads. One loose thread - the ultraviolet catastrophe - is solved by quantum theory, which unpacks into the story of physics over the 20th century.\nGotta pull those threads.\n\nCan mice throw up?\n\n3.\nWritten in 1983, and released last year under the 30-year rule, the Queen’s speech in the event of a nuclear war.\n4.\nLegendary physicist Richard Feynman on magnets (video) – and the power of asking why something happens.\n\nBut I really can’t do a good job, any job, of explaining magnetic force in terms of something else you’re more familiar with, because I don’t understand it in terms of anything else that you’re more familiar with.\n\nTranscript.\n",
    link: "/home/2014/12/24/filtered",
  },
  {
    title: "City Link, co-determination, and destiny",
    date: "14.30, Tuesday 30 Dec 2014",
    content:
      "The courier firm City Link went into administration on Christmas Eve. We were waiting for some gifts to be delivered, so we went to the Swindon depot a few days later to pick up the packages.\nPretty bleak as you can imagine. Workers milling around, finding out whether they’re being officially laid off or not. Staff will get redundancy, but the deliveries were mostly subcontracted and those folks are at the bottom of the heap. One guy we met found out about City Link going under just after he finished his turkey on Christmas Day - when the unions broke the news - watching the BBC. He’s owed £25k or so, he said he might-as-well have put all that money he paid for fuel into a big heap and burned it. We heard about another guy inside, owed £125k for the deliveries he’s done in the 2 or 3 weeks over December, unlikely to see any of it.\nIt was the RMT union who went public with the City Link news – they had been informed and asked to keep it quiet. But they also have members in the various subcontracted companies and they felt it was wrong for those people not to know.\nMy first reaction was that the UK should adopt the German system of co-determination, worker representatives hold seats on the boards of all companies employing over 500 people.\nBut although I like Mitbestimmung, thinking a bit more, I’m not so sure it does what I think we need.\nEarly signs of the Coasian flip\nSee, City Link actively encouraged a community of Owner Drivers.\n\nDo you have enthusiasm, determination and ambition? If you would like the flexibility of being self employed, with the support of a large established company, choosing to become a Service Delivery Partner with City Link offers the perfect partnership.\n\nThe subcontracting companies weren’t delivery companies that happened to work for City Link, amongst others –\nthey were individuals encouraged to start companies with City Link as primary client… the City Link website says how much they will earn, that they get training, a uniform… they sound like employees, right?\nBut then, as an Owner Driver, you lease your van - in City Link livery - under your own credit; you insure it, you provide safety equipment.\nHow could you work for anyone else, with a van painted like this?\nIt makes me see that City Link was run by externalising their risk onto others – primarily with credit (they receive money for deliveries up-front, Owner Drivers pay for fuel up-front, but City Link pay later under the terms of the invoice), and capital expenditure (Owner Drivers lease their own vans and equipment).\nLots of companies run like this:\n\nUber’s drivers are independent contractors – but feel more like staff paying for the privilege, given the leasing schemes of Uber and their partners\nLyft drivers were encouraged to buy a particular SUV… but then the marketing scheme changed, They pulled the plug, leaving us high and dry. Lyft gave drivers a payout to cover the difference, which is good for some and not for othrs.\nTaskRabbit has pivoted from eBay-for-jobs to a kind of temping agency… in a way that radically changes working conditions: Anyone left working for TR is an indentured servant. Now a company changing its business model is fine and good and necessary, and some of the community of “Taskers” will no longer fit in. But the cost of - effectively - laying these people off has been handed to the workers, instead of being a cost borne by the company as part of their pivot\nAirbnb turns apartments into hotel rooms, an external cost for other residents: There are the regular incivilities like the cigarette ends and the constant parties. But more than that, it is destroying the sense we used to have of the building being a shared space where we all knew and respected each other.\nWhen Instagram sold to Facebook for $1BN, the community of users had done all the value-creating work of posting photos and recruiting more users, but they saw none of the reward.\n\nAlthough I’m picking out the downsides, I do not believe that running companies like this is bad or wrong.\nOn the contrary, I like that City Link, Uber, Airbnb and the rest are networks of companies big and small, sharing risk across the whole network.\nIt breaks down the producer/consumer divide – it’s a kind of Mitbestimmung or co-determination in its own way. It allows small, agile companies to push back against the incumbents who use their position to treat us badly. It puts people closer to their own destiny, it’s a de-alienating force.\nThis funny mix of heavily meshed companies is what I was getting at the other day in that ramble about Ronald Coase and the future of the firm. As the internet cuts transaction costs, firms will get smaller, and we’ll see a lot more of this:\n\nSo as markets and pricing get easier still, firms can get much smaller – ad hoc value chains assembled out of code and culture, barely anyone working at the company at all.\n…\nThe second implication is that the firm, no matter how small, can have a kind of hinterland of value providers - a community of users who post pictures, drivers who transport passengers - who, although technically not inside the firm, are as part of it as a spider’s web is part of the spider, or a beaver’s artificial lake is part of the colony.\n\nHowever.\nAs software eats the world, and companies get smaller and we enter a networked economy - as the Coasean flip takes place - there’s a sharp end:\nTaskRabbit workers paying the cost of the company pivot. Neighbours of Airbnb hosts soaking the externality of strangers in their space without choosing to accept it. Drivers who used to be employees being encouraged to be independent Owner Drivers - still in City Link livery - bearing the risk of the company’s capital expenditure and future success… without seeing any of the potential upside.\nAnd then that risk being cashed in, on Christmas Day after the turkey, invoices unpaid.\nSo what can be done?\nA new class of worker\nThe commonality here is there is a new class of worker.\nThey’re not inside the company - not benefiting from job security or healthcare - but their livelihoods in large part are dependent on it, the transaction cost of moving to a competitor deliberately kept high.\nOr the worker is, without seeing any of the upside of success, taking on the risk or bearing the cost of the company’s expansion and operation.\nThese aren’t just subcontractors or employees-by-another-name, they feel like something new.\nSo I’m looking for a mechanism to govern the relationship between the company and its worker-community. Something that fulfils these goals:\n\nReduces friction for people to work with well run, well cash-flowing companies, and vice versa\nKeeps workers and the company on the same side of the table with interests aligned, not making them adversarial\nProtects the worker\n\nThe premise is that it’s fine to share the risk, otherwise small companies could never do weird ambitious things – but it needs to be equitable.\nreddit’s scheme to give company equity to the community is good. So something like that? It’s interesting, maybe similar to what the Guardian are reaching for with mutualisation…\nbut maybe a bit hard to implement, until the right toolkit exists? I don’t like regulation. Regulation increases friction. I don’t want to inhibit something that - on the whole - feels like it’s going in the right direction: I’m pro the Coasean flip to a networked working world. I’d prefer to reduce friction along the vector of Doing The Right Thing.\nWhat about, simply, inventing a proper word for this “worker community” and making a code of conduct that companies can sign up for, to make it clear that this genuinely is a community of Worker Owners who share in the risk and upside both, not virtual residents of a virtual company town, buying goods from the company store with company scrip.\nThe code of conduct could start small: Payments could be made using escrow, instead of 30 day invoicing terms like regular suppliers. Stock options could be traded one-for-one between the company and the Worker Owner’s company. Working for competitors could be explicitly allowed.\nI don’t know.\nBut it would be a fascinating thought experiment, to draft a code of conduct that would be equally applicable to Uber, City Link, and Airbnb. The test would be whether their worker communities would grow faster because of it, without unduly slowing the company’s expansion.\nA metric for financial destiny\nMeasure first.\nIf you don’t have some kind of measurement - some kind of metric or indicator - you can’t see what effect you’re having. So there’s no feedback and you can’t improve what you’re doing.\nThe right kind of metric will provoke interesting forward conversations, and reveal interesting experiments. Even if, to begin with, the metric is inadequate.\nFor every person, I’d love a measure of how many other people’s financial destiny they control.\nSo… let’s say a company pays 100 people, and none of those people have any other income. The company has four equal shareholders, so each shareholder has 25% each. The shareholders have no other shares in other companies, and receive no other income.\nIn this case, each shareholder controls 25 peoples-worth financial destiny.\nLet’s say I pay three freelancers. For each of them, I am responsible for a tenth of their annual income. This year, I control 0.3 peoples-worth financial destiny.\nThat’s how it would work. You would work it out using invoices, income or revenue, payroll, and shares.\nWhat would it mean, to have this balance sheet for financial destiny?\nWhat if we said it should be capped at 1,000? Nobody should be allowed to have that much control other other humans. That means, for a 10,000 person company, no single shareholder should have more than 10% of the shares.\nWhat if it was capped at 100?\nWhat if we based taxes on it… what would a progressive destiny tax look like?\nWhat does too-big-to-fail look like, for destiny? Does the measure need to be moderated where there are barriers to switching jobs? If we made visible such a destiny network, could we test trickle-down? Could we identify geographic economies and see if local currencies work?\nRegulation and governance are not about stopping things happening or slowing things down. Governance is also the system of eyes and senses that we build, as a society, so we can see ourselves as in a mirror – and work to accelerate what we endorse.\nWe’re entering a new, networked world where the old categories of companies and consumers no longer apply. We need to find new frames of reference or we’re flying blind.\n",
    link: "/home/2014/12/27/filtered",
  },
  {
    title: "Garam masala recipe",
    date: "12.41, Wednesday 31 Dec 2014",
    content:
      "I spent 30 minutes yesterday making up a fresh batch of garam masala. It’s a curry staple so I use it a bunch – but usually I buy it pre-blended. That’s a problem because the flavour is not consistent between brands… everyone has their favourite blend and personally I don’t like my garam masala too peppery.\nSo here’s a recipe I like, from Curry (DK Publishing).\nIngredients\n\n50g coriander seeds\n50g cumin seeds\n20 green cardamom pods\n10 cinnamon sticks each 2.5cm/1 inch long\n2 tbsp cloves\n10 blades mace\n10 black cardamom pods\nHalf a nutmeg\n1 tbsp black peppercorns\n4 cinnamon leaves or bay leaves\n1 tbsp dried rose petals\n1 tbsp fennel seeds\n\nMethod\nFrom the book…\n\nHeat a dry frying pan and add all the spices. Stir them and shake the pan as they start to crackle. When they smell roasted and aromatic, remove the pan from the heat and tip the spices on to a plate. Allow to cool.\nTo grind the spices, use a mortar and pestle or a spice mill (or a clean coffee grinder).\n\nI used ground black pepper instead of peppercorns, and bay leaves rather than cinnamon leaves. I doubled up on all the quantities, and broke up the pods, sticks, and leaves before toasting: it looked pretty colourful.\nWe have an electric coffee grinder that’s only used for spices.\nIt smells and tastes fantastic.\nOther recipes\nThis tandoori chicken recipe is the best I’ve found, and it includes a recipe for a blend called tandoori masala which I now keep in a jar on the shelf. It also requires yet another blend, a tangy one called chaat masala which has dried powdered mango in it. I found that in a store on Drummond St near Euston.\nStill on the lookout for a better recipe though. Tandoori chicken and naan is one of those Platonic solids of food, apparently dead simple but actually an ur-food where it’s worth sweating the details because when it’s perfect it’s perfect.\nCheese on toast is like that too.\nAnd here’s my chicken pilau which includes a recipe for whole garam masala. You soak the spices to bring the flavours out, rather than toasting, and add at the beginning rather than the end. All these methods!\nHappy new year. I hope you have a great 2015 lined up.\n",
    link: "/home/2014/12/30/city_link",
  },
  {
    title: "Testing",
    date: "09.51, Thursday 2 May 2013",
    content:
      "The good thing about rolling your own blogging system is that you’re in control of your data and your destiny.\nThe bad thing is that you have to live with all the ridiculous choices made by you-with-13-fewer-years-experience.\nSo every time I have anything to say, there’s a several hour (day, week, month) long throat clearing process where I have to check what the syntax for the blog posts is, see whether the rendering and publishing code still works, and get the whole thing working on my laptop again.\nYou’d think that this barrier to entry would result in me only posting when I had something really, really worthwhile to say. Where my desire for public exposition was so strong that it would carry me through all the pain and hurdles.\nNo. I write posts when I’m procrastinating, or when I’m at an airport. Today I’m procrastinating.\nUpdate: Why on earth does my blog template put a little dot after “May” in the date?? Apparently me-some-years-ago is a lazy coder who can’t be bothered to truncate correctly. This is lazy: strftime(“%b. %Y”)\n",
    link: "/home/2014/12/31/garam_masala",
  },
  {
    title: "BERG Cloud press",
    date: "16.15, Saturday 4 May 2013",
    content:
      "Recent press on BERG Cloud, the new Dev Kits and Little Printer:\n\nTwitter Tests a Toolkit That Puts the Internet in Things: Platforms that combine networking with user interfaces will help companies test post-PC ideas: But according to Berg CEO Matt Webb, the basic engineering challenges of connecting physical objects to the Internet are still too daunting to encourage rapid innovation. ‘Our ambition is to let you go from zero to your first connected product in a day,’ says Webb. ‘We all cut our teeth developing for the Web, and we wanted to create a way to experiment with hardware that’s just as agile.’ - John Pavlus, MIT Technology Review (3 May)\nTicker tape, circa 2013: New York Times breaking news alerts come to Little Printer: It’s easy to imagine all sorts of ways that Little Printer could make push notifications a little more personal and tangible; for instance, Berg has already field-tested instant ‘welcome’ printouts triggered by patrons checking in to a cafe using Foursquare. Fortunately, Little Printer is pretty hacker-friendly, so it shouldn’t be too tough to whip up your own alerts using IFTTT, Twine, or otherwise. - Ellis Hamburger, The Verge (3 May)\nLittle Printer: Meet the palm-sized, werewolf-spotting, cheeky face of the internet of things: The company envisions a future where, much as the advent  of the web enabled smaller companies and start-ups to start online businesses without needing a huge corporation behind them, connected objects will allow them to get into the hardware game too. - Jo Best, ZDNet (2 May)\nTwitter UK’s #Flock cuckoo clock shares time and tweets alike: Twitter UK has teamed up with Berg to produce #Flock, a smarter-than-average clock that both marks time and pops out a bird whenever there are new followers, replies and retweets. It’s comparatively simple underneath the wood, as a Berg Cloud developer kit links an arm mechanism to the owner’s Twitter account. - Jon Fingas, Engadget (19 April)\nFrom Berg, A Birdhouse Powered By Your Twitter Stream: Sadly, the project isn’t for sale. Instead, this extremely limited batch was produced as a proof of concept for the studio’s new Berg Cloud Dev Kit, which is basically a hardware bridge to connect the Internet to Arduinos, enabling your bespoke physical projects to speak with the voice of cloud data. - Mark Wilson, Fast Company Co.Design (18 April)\nTwitter UK shows off #Flock, a cuckoo clock powered by tweets: Twitter built the clocks in partnership with BERG, a London design consultancy that specializes in forward-thinking, quirky, and sometimes unclassifiable objects. - Casey Newton, The Verge (18 April)\nProduct Design Agency BERG To Become BERG Cloud, An Internet Of Things Startup: BERG Cloud aims to be an ‘operating system for connected products’. What we saw, cofounder and CEO Matt Webb told me in an exclusive interview, is the emergence of a platform that could control everything from the Little Printer to the signage in a city, to home electronics and automation inside businesses. - Mike Butcher, Techcrunch (18 April)\n\nAnd one slightly older piece:\n\nThe Virtual Haircut That Could Change the World: On or about the 14th of February, 2013, the hair on Little Printers’ faces began to grow. Stick with us. This is about the future of the Internet of Things. - Tim Maly, Wired Design (20 February)\n\n",
    link: "/home/2013/05/02/i_have_no_idea_what_im_doing",
  },
  {
    title: "Orbits and hardware",
    date: "15.19, Thursday 9 May 2013",
    content:
      "Open in my browser right now:\n\n\nPlanar Choerographies. We’re all familiar with stable orbits in a two body system: it’s how the earth goes round the sun. The earth describes a big circle, the sun a little one, and both are centred on their mutual centre of gravity. It turns out there are stable orbits for n-bodies too, and they’re lovely. I wonder what it would be like to live on a planet in a seven on a butterfly solar system.\n\n\nWired interview with Bill Gates. Saved 5 million lives, and he’s funny? Dammit.\n\n\nThe pitch deck Buffer used to raise $500,000. Great pitch deck. A simple story, well told.\n\n\nChris Dixon on hardware startups. A big factor in why hardware is possible now? The peace dividend of the smartphone war. (Chris Anderson.) Chris Dixon lists a few points to keep in mind: Manufacturing (no Amazon Web Services for production); defensibility (no network effects); planning (it’s not agile); B2C vs B2B (attention vs margins).\nI’m gonna add four other points of differentiation from software. One is distribution, both attention and fixing shipping things. Is hard. Incumbents win. Second is funding: margins are lower, you have working capital tied up in stock, the pipeline is slower. Third is complexity. Connected products (and that’s my concern) have mechanical parts, embedded software, connectivity/protocols, and cloud software. These need to move in sync, and it’s hard to tell what takes the lead. The fourth point is business model – the business model of products is already moving into flux. It’s about to go chaotic.\nFurther reading: Indiepocalypse (Andy Biao): For hundreds of years, publishers across every industry - book publishers, record labels, film studios, videogame publishers - solved problems for artists in four major ways: being, Funding, Production, Marketing, Distribution. And the internet is disrupting all four of these simultaneously.\nThe way I think about this is the “fat middle.” In each industry - say, news - we’ve had the dominant head (New York Times) and long tail (round robin newsletters). In music? Dominant head of stadium tours and U2, and the long tail of bar gigs. The internet’s flattened the curve, and a fat middle has arisen. In news, major blogs: Engadget, the Verge, etc. Music: see all of YouTube.\nSo… a fat middle of hardware? Yup. It’s happening. Cool.\n\n\nNow I can close my tabs.\n",
    link: "/home/2013/05/04/berg_cloud_press",
  },
  {
    title: "Pricing hardware and changing business models",
    date: "14.25, Tuesday 14 May 2013",
    content:
      "How To Price Your Hardware Product, Marc Barros:\n\nThe mistake most hardware startups make is they don’t charge enough because they don’t think of the problems they will encounter at scale. They don’t calculate the real cost to deliver their product to a customer’s door, they leave no margin to sell through retail down the road when opportunities arise, and they can’t easily raise the price after it has been set.\n\nCovers some good points that you need to take into account, beyond your profit margin:\n\nRetail margin, and sales rep commission\nThe cost of fulfilment: Shipping, and the credit card fee\nReturn allowance\nThat the product cost is the landed cost: It needs to be fully packaged, in the warehouse\n\nAll points that are easy to forget when you’re looking at the bill of materials for whatever the core component is.\nHere’s one of Barros’ examples using top-down pricing: $200 retail means you get $101.80 from your customer. A product cost of $58.10 means you have a margin of $43.70, or 42.9%. He recommends shooting for a margin of 50%. All reasonable, sensible, I like his summary for this: Don’t be afraid to charge more. Long term, your loyal customers will thank you for staying in business. You’re not thanking your customers in any way if your low margins mean you have to skimp on customer service, or developing improvements to the product they’ve invested in.\nTo my mind, there are two disruptions that make this take on pricing difficult.\nKickstarter\nI think about Kickstarter hardware projects in two categories. There are those made for love not money. (And that’s cool – hardware products, like any creative act, can be made for 1,000 true fans with the potential - but not requirement - to break through into the mainstream. I love it.) Then there are those where Kickstarter is about getting mindshare, learnings, and the infrastructure to build the products that come after this one – there’s no profit requirement. That’s cool too: In an established company, products sit underwater for a long time before they break even.\nThese projects are low margin, funded by love and future expectations, and - because Kickstarter is also a great distribution platform - they don’t need to build in retail margin. Consequently the prices are lower than equivalent non-Kickstarter projects.\nAmazon\nI use Amazon as a proxy for the shifting sands of new business models. The Kindle is sold at cost, or below: It’s all touchscreen, PCBs, and battery. Where do Amazon make their money? Well, nowhere yet… they’re a notoriously low margin, long term view company. But once they make $3/month additional sales, the Kindle Fire moves into profit. But think about this… if the $159 was sold with the same markup suggested by Barros, we’d see a RRP of $547. Insane.\nThis isn’t new. Cellphones have been subsidised by carriers for years, their high up-front offset against monthly bills. Car financing is common. DFS functions more like a credit company then a sofa store.\nBut it’s becoming more common in the hardware world as subscription relationships become more accepted – and more necessary. When products connect to the cloud, the cost structure changes once again. On the one hand, there are ongoing network costs which have to be paid by someone. You can do that with a cut of transactions on the platform, by absorbing the network cost upfront in the RRP, or with user-pays subscription.\nWe’re finding product categories dominated by one business model or another. It’s hard to enter a subscription-dominated category with a straight-forward retail model. Your product will look too expensive.\nIt’s not as easy as it once was.\nEnough product companies are operating at zero margin, or on some alternate business model, that pricing hardware is no longer as simple as making sure you have the right margin.\n",
    link: "/home/2013/05/09/orbits_and_hardware",
  },
  {
    title: "How any of the Big 3 could own connected products",
    date: "20.23, Wednesday 15 May 2013",
    content:
      "I’ve been doing some competitive landscape analysis around connected products/Internet of Things platforms – I’ll write up my thoughts soon. During research I touched on Bluetooth 4, which seems like it could be the connective tissue of a peripheral ecosystem around smartphones just as USB was for peripherals around the PC.\nAnd in this section, I hadn’t included Apple’s MFi Program in the list (MFi is hardware and certification for iPod, iPhone and iPad.) Greg asked me why. Well, I said, they don’t do enough UX integration, and besides, I don’t want to give them any ideas. If they did what I think they should do, they would totally own connected products.\nBut hell! The Big 3 are full of the smartest technologists on the planet!\nIt’s not for lack of ideas that they aren’t doing this.\nSo here’s how Apple, or Amazon, or Google could totally become the platform for the future world of connected products, and - with a connected products platform of my own - the thought that one of them might make a move like this is what keeps me up at night.\nAmazon\nStarting point: With the Kindle, Amazon have an amazing chip that has global connectivity via 3G. They also have a billing model where the content provider pays for delivery (currently $0.15/MB for Amazon.com deliveries to the US, which explains why you don’t get many graphics-heavy books on the Kindle). This kind of billing infrastructure is hard.\nWhat happens: Amazon apply their genius for service oriented architecture (SOA) to Kindle’s Whispernet functionality, take advantage of their economies of scale, and provide wireless chips that any developer can use. Just as they SOA’d their storage requirements into S3, and their server farms into EC2 - now both services that are the tarmac of the modern web - they couple this SOA’d hardware connectivity with Amazon Web Services, and create the perfect platform for connected products. Of course Amazon also own an identity system with associated credit cards/payments platform. Plus they really get APIs.\nAmazon would own connected products. You wouldn’t build on anything else.\nApple\nStarting point: The emerging smartphone peripheral ecosystem (appcessories and whatnot) is built around Bluetooth 4, the low power wireless standard that Apple have been including in their products since 2011.\nWhat happens: Right now dealing with appcessories on the iPhone sucks (claiming and syncing), so Apple add some minor UX support, adding hardware products to the homescreen with a parallel to Newstand called Nightstand – a virtual table for physical things. You associate each product with your Apple ID. Then, to solve the problem that connected products need to talk to the web without a smartphone present, they activate the Bluetooth 4 already present in the Apple TV (and maybe add one to the Airport Express), and make it so that any product that can connect via your smartphone can also connect via any Apple TV you’ve signed in on using the same Apple ID. For bonus points, iCloud is used for the messaging layer, so any data sent via the Apple TV also shows up on your iPhone. Of course Apple owns an identity system with associated credit cards, fully capable of micro-payments and subscriptions.\nApple would own connected products. You wouldn’t build on anything else.\nGoogle\nStarting point: Android. Motorola.\nWhat happens: Google take cheap cellphone guts - the peace dividend of the smartphone war -and use Motorola to release a development platform that runs Android, rebooting the Android @Home program that was launched back in 2011 with smartphone-controlled lightbulbs. In this new 2013 world of Arduino and Raspberry Pi, hardware is way more accepted… but loads of people already know how to develop for Android. So developers flock to this new platform. You’re not locked into Google’s hardware, because Android hardware is commoditised down to the CPU, unlike similar offerings from Amazon or Amazon. The UX is provided by Android apps, of course. Google Cloud Messaging is used to link the connected hardware to regular ol’ websites that developers build themselves. Websites are easy, and Google trusts the web. The platform is a great combination of open and familiar. Google also owns an identity system, and a payments platform.\n(A note: I don’t think Google could pull off the Apple model of a peripheral ecosystem built around Bluetooth 4. Google doesn’t have enough non-smartphone presence in the home, and Android fragmentation would be a major problem – especially Samsung’s ownership of the front room via the Smart TV platform, which would put the two companies at odds.)\nGoogle would own connected products. You wouldn’t build on anything else.\nWho I’d back\nI wouldn’t back any of ‘em.\nIt’s true, if any of the Big 3 made a move like this, you’d be dumb to use anything else for your Kickstarter project or new hardware company. It would be great. So many common problems would be solved.\nBut I’d be sad. We’d be stuck with a platform that met our imaginations only of today. It wouldn’t evolve; big companies are too slow.\nWe’re only going to discover the weird and wonderful opportunities of connected products once we’ve rolled our sleeves up and got our hands dirty. How are connected products going to change our homes, our offices, our cities, our social lives? Who knows. It’ll take years to find out. And at that point, maybe we can have a dominant platform. That’ll be fine. Until then there’s BERG Cloud and a dozen others to help figure it out. There will be more. Let a thousand flowers bloom!\n",
    link: "/home/2013/05/14/pricing_hardware",
  },
  {
    title: "Cricket and pixel cityscapes",
    date: "15.58, Wednesday 5 Jun 2013",
    content:
      "Okay I’ve been blocked on a bit of writing for about two weeks. And since it appears I can’t think my way out of a paper bag, how about we have some random links from my open tabs.\n\nShane Warne’s Ball of the Century – there’s a video, way down the page, of Warne bowling Gatting out with a leg spin back in 1993. Amazing.\nStartup advice, 95 stanzas. All good. I like this: A lot of the best ideas seem silly or bad initially–you want an idea at the intersection of ‘seems like bad idea’ and ‘is good idea’. (It’s important to note you need to be contrarian and right, not simply contrarian.)\nPixel City home screens for the Sony Ericsson XPERIA X2, by us two. Lovely pixel art panoramic cityscape on your phone, and: As a user pans through the cityscape, all the different elements link to the functionality of the user’s phone. Text messages appear playfully on billboards, calendar events arrive by train, a passing airplane shows your call history and much more. 2009! Wonder and joy. Facebook Home is po-faced by comparison. Nintendo are cowards for not making a smartphone with Animal Crossing as the interface.\nWikipedia’s list of shibboleths. A shibboleth is a word, sound, or custom that a person unfamiliar with its significance may not pronounce or perform correctly relative to those who are familiar with it. It is used to identify foreigners or those who do not belong to a particular class or group of people. I’ve seen these referred to as “class markers” and green beards (which is unconscious), but I think the password/admission/in-group associations of “shibboleth” make it a useful term.\n\nFingers crossed, now unblocked.\n",
    link: "/home/2013/05/15/what_keeps_me_up_at_night",
  },
  {
    title: "",
    date: "19.06, Sunday 1 Jan 2012",
    content:
      "\nThere's a nice turn of phrase in Borges' short story Tlön, Uqbar, Orbis Tertius:\n\n\nHe and my father had entered into one of those close (the adjective is excessive) English friendships that begin by excluding confidences and very soon dispense with dialog. They used to carry out an exchange of books and newspapers and engage in taciturn chess games... I remember him in the hotel corridor, with a mathematics book in his hand, sometimes looking at the irrecoverable colors of the sky.\n\n\nIn the Mars trilogy, Kim Stanley Robinson has his characters also watch the colours of the sky. In one of his fictions (it might be the Mars trilogy, it might be a short story, it could be both), Robinson has theatre become a resurgent art form: irrecoverable experiences in an age of on-demand media. I can see that.\n\n\nBorges approaches the uniqueness of experience from another angle in this footnote of the same story:\n\n\nAll men, in the vertiginous moment of coitus, are the same man. All men who repeat a line of Shakespeare are William Shakespeare.\n\n\nThere's something appealing about this. At birth, as tabula rasa, we are as one. A single entity, instantiated in billions of brains across time and space. And symmetry breaks and breaks again, and we become our separate selves. But this loneliness can be reversed: at certain singular moments, we exist in transcendent communion with other individuals who have taken the same journey as ourselves, and for an instant we are identical, one, the same thoughts and the same concerns, before time drags us on and we become individual once again.\n\n\nBut you know, exiting that moment of communion, you could have taken a different turn. You know, and that's comforting.\n\n",
    link: "/home/2013/06/05/some_links",
  },
  {
    title: "Buy commodities, sell brands",
    date: "14.38, Wednesday 29 Feb 2012",
    content:
      "Warren Buffet, in his latest annual letter to the shareholders of Berkshire Hathaway: ‘Buy commodities, sell brands’ has long been a formula for business success. It has produced enormous and sustained profits for Coca-Cola since 1886 and Wrigley since 1891. …\nBuy commodities, sell brands. I like it.\n",
    link: "/home/2012/01/01/irrecoverable",
  },
  {
    title: "Wolfe+585",
    date: "09.10, Friday 2 Mar 2012",
    content:
      "Every so often at work, we invite everyone we know to the pub and have a night of drinks. Each BERG Drinks has a theme on the invite: this most recent one was to celebrate the birthday of Wolfe+585, Senior, so called because he has the longest personal name ever used. It’s in German, you can go read it if you like.\nBut if you dig around, you can find a translation of Wolfe+585’s full name into English, which is:\nAdolph Blaine Charles David Earl Frederick Gerald Hubert Irvin John Kenneth Lloyd Martin Nero Oliver Paul Quincy Randolph Sherman Thomas Uncas Victor William Xerxes Yancy Zeus Wolfe Schlegel Steinhausen-Bergedorf who before ages were conscientious shepherds whose sheep were well tended and diligently protected against attackers who by their rapacity were enemies who 12,000 years ago appeared from the stars to the humans by spaceships with light as an origin of power, started a long voyage within starlike space in search for the star which has habitable planets orbiting and whither the new race of reasonable humanity could thrive and enjoy lifelong happiness and tranquility without fear of attack from other intelligent creatures from within starlike space Senior.\nSo there you go.\n",
    link: "/home/2012/02/29/buy_commodities",
  },
  {
    title: "A proposal for making a Moon city",
    date: "18.09, Monday 5 Mar 2012",
    content:
      "Here’s a fact about the Moon and space exploration that somebody told me a couple years back: If it costs $X to get to Earth orbit, it costs $10X to get to the Moon, and it costs $100X to bring something back.\nOne of the games I like to play is “there from here.” For example, I would love for humanity to have cities in the Asteroid Belt. In this age of peak everything I have a preference to do belt tightening. The solution to not having enough resources on Earth is to not be constrained to Earth. Let’s go mining in space. Cities in the Asteroid Belt then – how do we get there from here?\nThe challenge being that technology develops stepwise. It happens in increments, and the reach of each increment is dependent on the incentive and the amount available to be invested. Sometimes a leap is made. So maybe the incentive is big. The Space Race between the USA and the USSR was one such incentive. Or the promise of finding a cheap route to the lucrative spices in the Indies spurred the Europeans to send ships west across the Atlantic. Or you can keep the investment required low. Citizen science projects use the coordinating technology of the internet to allow many low investments to make big progress. In order to develop technology towards cities in the Asteroid Belt, we need to find the steps to get there. We’d have to have cities on the Moon first. And for that, at the very least, we need to be able to easily get to and return from the Moon.\nBut why go to the Moon in the first place? There’s nothing there. And space technology is so expensive. It would be a massive investment to develop cheaper space technology. No incentive.\nOkay, so here’s a thing. Technology evolves from where we are now. What are some things we’re getting great at right now? Robot factories. Mining. Thank you Foxconn. Thank you rapacious appetite of the consumer society for hard to find rare earth minerals.\nAnd to review: It’s much cheaper to get to the Moon than to come back, so make it a one-way journey. And it’s peak everything, so the value of mineral resources is only going to go up.\nTwo other thoughts: the X Prize (Revolution through Competition), and USA Homestead Act of 1862, whereby a system to grant land rights to individuals was set up, by which a person living on and improving the land was granted property.\nHere’s my proposal:\nWe build robot mining factories and send them to the Moon.\nOnce there, they extract and purify valuable resources, packaging it in an automated fashion to be picked up. Time passes. The piles of nicely packaged and purified minerals grow and grow on the lunar surface. Meanwhile commodity prices on Earth also rise. The piles steadily grow in value. And grow, and grow. A prize that increases in value the longer you wait. CEOs of manufacturing companies look lustfully through their telescopes. The CEOs eye one-another suspiciously.\nUntil suddenly it becomes worthwhile to develop technology to get to the Moon and bring it all back. Whoever gets to the pile first is allowed to keep it. There is a race! Mining companies make the leap to the next generation of space technology.\nAnd as a spin-off we have a sustainable Moon-Earth shuttle service. Stick a few people on the shuttle, establish a permanent settlement, ta da, Moon city. Next step Ceres.\n",
    link: "/home/2012/03/02/wolfe_585",
  },
  {
    title: "Gobstoppers",
    date: "11.34, Tuesday 6 Mar 2012",
    content:
      "I’m a fan of gobstoppers. (I don’t know if you get these outside the UK: solid sugar sweet for sucking, no gum, brightly coloured.)\nTo manufacture a one inch gobstopper takes two weeks!\nIt probably takes seven minutes to eat one. Every minute you suck that’s two days. An hour a second!\n",
    link: "/home/2012/03/05/moon_city_proposal",
  },
  {
    title: "Trying to understand credit",
    date: "18.19, Tuesday 6 Mar 2012",
    content:
      "I just visited the bank and had an impromptu tutorial in international trade – good stuff. Recently they told me they’d lost a payment we were supposed to receive, and two weeks later it turns out they hadn’t lost it at all. It was a mess, and I have to admit there was a bit of shouting in the meantime. The shouting resulted in me being handed up to a more senior “relationship manager” and this is the chap who ran me through the basics of how banks can help orchestrate aforementioned international trade. So all’s well that ends well.\nI have models in my head of how things work. In my model of how the business of BERG works, I model cash, attention, and risk. My model of credit encompasses things like overdrafts, 30 day payment terms, loans and whatnot, and my understanding of it comes from two sources: my personal experience of debt (my advances on pocket money, the slow repayment of my student loan, credit cards) and macro-economics, on which topic Ray Dalio’s paper A Template for Understanding What is Going on is an astoundingly good explanation of the current global credit crisis. Dalio explains:\n\nthe difference between credit and money: credit is the promise to deliver money, and credit spends just like money. While credit and money spend just as easily, when you pay with money the transaction is settled; but if you pay with credit, the payment has yet to be made. \nthat while money exists, credit is created and disappears simply by belief: most of what people think is money is really credit, and it does disappear. For example, when you buy something in a store on a credit card, you essentially do so by saying, ‘I promise to pay.’ Together you created a credit asset and a credit liability. So where did you take the money from? Nowhere. You created credit. It goes away in the same way. Suppose the store owner justifiably believes that you and others might not pay the credit card company and that the credit card company might not pay him if that happens. Then he correctly believes that the ‘asset’ he has isn’t really there. It didn’t go somewhere else.\nand finally, in two paragraphs so deft that they have to be read to be believed, a description of the game of Monopoly firstly in terms of property vs cash, and secondly a version modified to allow the bank to create credit, in which case the game starts exhibiting the same credit cycles as our actual economy.\n\nHe frames the credit crisis as a “deleveraging” - a kind of global disarmament of credit - and the essay is simultaneously illuminating and bleak, bleak stuff. So I get that.\nOn the other hand I have very little deep understanding of what my mortgage means. Is it good or bad to have this credit? What if I rent out my mortgaged house and rent somewhere else? Too confusing.\nCredit\nI used to understand credit as the swap of risk and cash, i.e. I promise to pay the bank some cash in the future in order for them to take a risk now. For example: they front me cash as a loan (or, more informally, an overdraft) and I pay it back plus some percentage. The fee I pay covers them not having the money in the meantime, plus the risk they take on me not returning the cash.\nAfter my meeting with the bank I understand credit a little differently.\nI now understand credit as transferring no risk. The bank may front me cash now, but I give them security in the form of my house or something else. I retain all risk, nothing is transferred. There is no risk to the bank in issuing the credit. What I’m paying the bank for is access to their proprietary marketplace to exchange forms of capital - in the case I mentioned, cash and houses - together with a promise that the exchange won’t be finalised so long as certain conditions are met. So credit is possible not because the bank is able to absorb risk, but because:\n\nthe bank has an internal marketplace in which it is able to hold open many capital exchanges; and,\nthe bank is able to enforce - using the legal system itself - the fungibility of capital and obligation: if it gives me cash, it can get my house in return.\n\nYes, the bank does have risk here, but it’s not the same risk as my risk. It’s new risk.\nInterestingly what this leaves available is a system in which risk and cash are exchanged, where risk is transferred. This is what investment is, and this is what Kickstarter does.\nAnyway this seems obvious now I write it down, but I thought I’d share.\nUltimately where it leads me is to start looking for a relationship between risk and credit as if they are the same thing but one observed as static in time and the other in motion, in the same way that magnetism and electricity are the same thing separated by the speed of light.\nUpdate: On a little reflection, a bank isn’t quite a marketplace because the transaction types are highly limited. Cash flows in and out, and cash flows out transacted for security (a promise on other capital). It would be worth diagramming the systems of banks, individual lending, and investments in order to see where the thing called credit emerges.\n",
    link: "/home/2012/03/06/gobstoppers",
  },
  {
    title: "Versus",
    date: "22.41, Wednesday 7 Mar 2012",
    content:
      "Tantek’s 2012 SxSW Packing and Check List versus A list of every example actant mentioned in the first half of Prince of Networks by Graham Harman.\n",
    link: "/home/2012/03/06/credit",
  },
  {
    title: "Belief and desire",
    date: "09.32, Thursday 8 Mar 2012",
    content:
      "At the bottom of internal phenomena, whatever they are, the analysis pushed to the limit will never discover more than three irreducible notions: belief, desire, and their point of pure application, pure sense. - La croyance et le desire, Tarde (1880).\n(Found in Mind that abides: panpsychism in the new millennium, David Skrbina, after a mention by Bruno Latour in last night’s lecture.)\nBelief and desire! As tempted as I am to reduce these to vectors - simple forces of the internal self, dual forces of the consolidating shady yin and the bright exuberant yang - I will resist, and instead attempt to retain an understanding of belief and desire as the lively, messy, complicated, massive things they are.\n",
    link: "/home/2012/03/07/versus",
  },
  {
    title: "Air quotes, product",
    date: "12.42, Thursday 8 Mar 2012",
    content:
      "Bruce Lee: Before I studied the art, a punch to me was just like a punch, a kick just like a kick. After I learned the art, a punch was no longer a punch, a kick no longer a kick. Now that I’ve understood the art, a punch is just like a punch, a kick just like a kick.\nBack when I was a whippersnapper, back when my business was a consultancy named “Schulze & Webb” with a skull and bones cellphone on the homepage, we used to write strategy and do interaction design for web and mobile companies.\nA product is just like a product\nWe visited a bit of IDEO where they invent toys, and they told us about products. Products they told us have to be “shelf demonstrable” (an alternate term I heard later is “shelf evident” which you have to say like Sean Connery saying “self evident”). This is the idea that regardless of what your toy - your product - does, you have 15 seconds for it to tell its story to the customer, before they even touch it. This doesn’t need to be every feature of the product, and it doesn’t even need to be accurate. But in 15 seconds, you need to communicate that combination of usefulness and desire that makes a potential customer walk to the shelf, pick up the product, handle it, and put it in their basket.\nThis was an approach to product design that had never really occurred to me before. I’d thought about “form follows function,” and even concentrating on designing an experience rather than the aesthetics. But the idea that you should be concerned with not just the product but how the product is understood was enormously powerful for me.\nThat last phrase is from a talk I saw last year by Jonathan Ive at Apple.\nAs it happens I once related the 15 seconds anecdote to someone else from Apple, and they looked at me then said (I paraphase): HA! 15? One! You’ve got one second! Maybe two!\nSo there you go.\nA product was no longer a product\nThe concept of “product” felt like a really good metaphor for the at-the-time new world of websites, mobile services, etc. It’s not just how products are understood easily by individual customers, but also how people can talk about products easily to their friends, and how products attract focus inside teams and organisations.\nSo we would suggest, in our consultancy, that websites could learn from these qualities of products:\n\nproducts have to be shelf demonstrable – they can tell their story in 15 seconds, with no interaction beyond looking.\na good product is explainable in a sentence. We’ve since refined this: we ask ourselves how whatever we’re designing can be described in 140 characters or less. This is how ideas spread, but also - in big companies - it’s an important component of getting organisational buy-in. You can rally behind a short description.\na product knows its audience. You’d be surprised how often, in design work, a product doesn’t know its audience. We’ll start off imagining a website or film or prototype is going to be shown to customers… but really the audience is senior management, or the investors.\nproducts are measurable! Regular physical products are sold for money. You can talk about units shipped, margin, profit, returns, love and so on. Given these metrics, a product can be improved. A mobile website is way more abstract: these metrics need to be decided and built in to give the team direction.\na product is predictable. This is more abstract, but I think it’s critical. People get really upset if a website or app violates expectations, such as when (say) private information is shared when the tone of the brand is that it’s like a buddy. That’s because our expectation of buddies are that friends aren’t gossipy blabbermouths. Predictability is easy when you have a non-networked, physical product: it obeys mechanical rules and gravity. But these metaphorical products? Predictability is a risk.\n\nThe idea of “product” ended up feeling like a really good filter for design work.\nThe most laissez faire measure for how good design work is is the market itself.\nAnd one of the challenges in consultancy is making the consequences and “next steps” of the work and strategy relevant to unseen audiences. By framing strategic recommendations as products, we implicitly introduce the market, and the market brings with it its own natural evolutions and desires. The next steps for a product, as opposed to a design thought piece, are obvious: you scale it, you platformise it, you make it more desireable, you grow it, etc.\nSo our workshops turned into product invention workshops in which strategic recommendations are expressed as briefs for new products, making the strategy (a) understandable, and (b) testable.\nI’m still a believer in the metaphor of “product” in design.\nBut meanwhile!\nWhile we were using good old fashioned solid products as a metaphor for these weird ephemeral fuzzy website things, the nature of products was shifting. Products got smart.\nIt’s so significant that physical things now have computation inside them, and access to the network. It’s insane what this means. Bruce Sterling’s Shaping Things has one approach to this – spimes: objects that have knowledge and history of their place in space and time. In Smart Things, Mike Kuniavsky catalogues ways of designing products infused with computation and networks. But my main understanding of this has been working on Little Printer and my proximity to client work in the studio on other connected product prototypes.\nRecently I noted down some places in which traditional products have changed:\n\nthe product/service mix! The iPod (rest its precious little soul) wasn’t anything without the service of iTunes and the iTunes Music Store. And the Nike Fuelband is half display of a fitness tracking service and half a conduit between the physical and the virtual. Kuniavsky calls these service avatars, products that aren’t just better with a well-designed service around them, but entirely to do with the service. I think about Little Printer: is it a product? Well yes, it’s a gorgeous object and we’re sweating the industrial design. But the industrial design and the brand creates a space in which publications - part of the service layer - can really shine, and the value of Little Printer rests almost entirely on the quality of these publications! So it is a product or a service? I don’t think it’s possible to make that distinction, you wouldn’t separate the two.\nthe object/interface separation! The user interface is an interface because it’s the surface of the thing, the interface between the thing and the world. The controls of a physical thing used to be on the interface, the surface. The design cue for a control surface was the idea of affordances. No longer. I control Little Printer through a portable screen, separate from the object itself: my smartphone. To control a thing, you no longer necessarily look at the thing. Weird.\nlittle brain/big brain! This is an idea that cropped up in the studio - I can’t remember who said it first, sorry - but it’s found a regular spot in my notebook. When a product is connected to the network it has two brains. A little local one that can perform cheap calculation, and a big one in the network that can do potentially anything at all: massive facial recognition, searching all of Amazon, advanced artificial neural networks, whatever. Think of Siri on iPhone: iPhone’s little brain records and compresses the voice, and does simple matching with local data. Siri also talks to the network, and that’s where the speech recognition happens. And the Wolfram|Alpha facts and calculations. And anything else Apple adds to Siri’s big brain in the future. So how do you do product design when the physical shape of the product no longer bounds what its functionality, and the behaviour of a product can be side-loaded from the network, entirely changing what it does without the product physical altering at all? \nthe product/brand/experience singularity! Not so much a change as a realisation this one. Some time ago I became interested in the idea that products were also designed experiences, and that they could be understood less as passive lumps of matter and more like nonhuman actors, companions with personality traits and quirks. You can read more about this in my talk Products are people too. It was also being generally understood that the experience of a product was a key determinant of the brand. And because knowledge of a product is increased when people tell their friends, a product becomes its own marketing too. Products, brands and experiences all fold into one another, to such a point where you have to consider them holistically.\n\nLet’s not even get into my and the studio’s general preoccupation with products with “fractional artificial intelligence” and a world with robots in it, of all shapes and sizes.\nThrough all of this mish-mash, “product” thinking (I’m quoting “product” diligently) continued and continues to be important in our consultancy and design work! “Product” is a powerful idea.\nA product is just like a product\nWhile “product” is a powerful idea, product (no quotes) is an increasingly useful term - in its original sense - and one I now need to personally reclaim.\nAs we’re working on Little Printer, I need a way to refer to the object itself – the thing that the tooling is for, that contains the electronics, that will sit inside the packaging, that has painfully long lead times on the PSUs. Yes, it’s fuzzy with service-thinking because it’s nothing without the behaviours controlled by the network such as deliveries and publications. And it’s separate from the interface which sits on the smartphone. And it has a face which is part of the brand, and to make things more complicated the face is printed so is it part of the network and the service, or is it part of the product design?\nMetaphorically of course, according to all my “product” thinking, the entire thing - publications, marketing, brand, smartphone interface, plastic and silicon all - is the “product,” because it’s the entire “product” by which the market will judge our success.\nBut still I need a word to refer to the physical thing. And with all that nuance, and with all that muddy complexity, with all of that, I’m taking back the word. Taking it back from myself! Product. A product is just like a product.\nWhich leaves me having to find a new way to refer to the metaphor of “product”… but that’s fine, challenges are good.\n",
    link: "/home/2012/03/08/belief_and_desire",
  },
  {
    title: "The user interface of Seldon’s Plan",
    date: "13.58, Tuesday 13 Mar 2012",
    content:
      "Seldon’s plan is a future map of humanity, from the collapse of the first galactic empire to the establishment of the second, a thousand years in the future. It is developed according to psychohistory, and named after the father of this new science and of the plan itself: Hari Seldon. Psychohistory is a kind of statistical mechanics to predict the behaviour of large populations, and using the plan a secret organisation shapes the destiny of the galaxy towards this Second Empire. The seed of the future empire is a society named the Foundation, on a planet named Terminus, and the secret organisation - tasked to improve the plan and from its hidden vantage point manipulate humanity - is called the Second Foundation, unknown by the first and established by Seldon himself.\nThis story is told in the science fiction books of the Foundation series by Isaac Asimov, a space opera classic.\nWhat fascinates me is the user interface by which the Plan is read and explored by “Speakers” – the secret members/academics/bureaucrats of the Second Foundation. It is projected on the wall as a network of dense, interlocking equations by a device named the “Prime Radiant,” and manipulated using a combination of gestural interface and thought control. Black equations were part of the original Seldon plan; red is used for those added by Speakers; blue is where unanticipated deviations from the plan have occurred.\nI’ve taken two extracts which describe the Prime Radiant and the visualisation of the Plan from the books Second Foundation and Foundation’s Edge. Read the extracts here.\n",
    link: "/home/2012/03/08/air_quotes_product",
  },
  {
    title: "Two org charts",
    date: "17.36, Wednesday 14 Mar 2012",
    content:
      "Apple’s org chart under Steve Jobs can be seen in Adam Lashinsky’s Fortune article Inside Apple (as Kindle Single), and in low resolution here. Lashinsky’s book version of Inside Apple includes an updated org chart centred on the new CEO, Tim Cook.\nI won’t pretend to understand how large companies work, but in my understanding an org chart is a part map and part blueprint of a large variety of connections:\n\nhierarchic responsibility for areas of the business\nsensibility. I mean both a grouping of people in similar disciplines (“design”, “engineering”, “finance”) and similar rhythms or mindsets: launch focused, continuous development focused, hackers, bureaucrats, and so on\nease of influence, for example when a CEO and a product design group are directly connected, we can assume that there is a flow of values and insight that goes both ways. It might be more appropriate to call this “close coupling”\n\nWhat interests when I look at such charts is trying to find “the tail that wags the dog.”\nLet me explain. I am curious as to how products are invented – how is the genuinely original incepted into an organisation, and how does this idea because real? I look for two clues in the structure of the org chart:\n\na flow downstream - a path of least resistance - from a concept toward a machine that manufactures, sells, and improves a product. The concept has to be in a form which has a tendency towards improving and not eroding as it moves down the gradient.\nsince the flow downstream takes most of the company (I believe), I look for a tail that wags the dog: a source of uniqueness; a harnessed singularity producing negentropy; a small enough group that invention can truly occur, but large enough that a sizeable number of information/possibility streams can be collided, and close enough to business strategy that the whole business can orient around the new ideas. Some parts of the company are intended just to feed this small group.\n\nThe group in Apple’s case is said to be Jonathan Ive’s product design group – a dozen or so people who invent new products. The gradient from this group spelt out in a playbook called the ANPP. From the book Inside Apple:\nOnce the design is under way, the rest of the company kicks into gear. The two organizations that will be responsible for the product are the supply-chain team and the engineering corps. Thus begins the Apple New Product Process, or ANPP. The ANPP is the step-by-step playbook spelling out everything that needs to get done to make the product. The ANPP wasn’t always unique to Apple. Xerox, HP, and others used a similar playbook in the late 1970s and early 1980s. A former Apple engineer described Apple’s process, which began as a manufacturing aid aid for the Macintosh, as part art, part science. The goal of the ANPP “is to automate the science part so you can focus on the art,” said this engineer. The process elaborately maps out the stages a products creation will follow, who touches it, how responsibilities will be assigned across functions, and when assignments will be completed.\n(The passage that follows this gives more details from the ANPP. Two managers take over the product: one from supply chain, and the other from engineering. I don’t know where software comes in, but I understand - from reading around - is that it’s when the hardware features are more-or-less finalised. What little of the process that is public is fascinating, and I recommend the book.)\nYou could, I suspect, draw the ANPP atop the org chart - perpendicular to many of the lines of responsibility - and map out the gradient a product moves along on its route to market.\nNow I don’t completely buy Lashinsky’s description. The iPod had a very different origin, where the market opportunity was spotted by one party, the project left dormant until another party spotted a technological opportunity in a new miniaturised hard drive appearing in the supply chain, the novel UI was spotted by marketing, and the person bringing the project at least halfway from invention to reality didn’t join the project until many of these seeds were in place. The organisation which Apple has become isn’t the organisation that created the iPod: there is no guarantee that its current form will be a true codification of previous success.\nBut still, interesting food for thought.\nDisney’s 1943 org chart is also fascinating, primarily because it maps out exactly the gradient: Walt, to story, to direction which coordinates a network of parties - the direction of flow here is wonderfully mapped - and finally the production flow narrows and the picture goes to market.\nIt’s a lovely diagram and again, who knows how it well it describes the “at play” network of Walk Disney Studios. In particular the roles of marketing and technology are not well described – but maybe this was unnecessary: perhaps innovation in the technology of animation was done in a sideways fashion, by running particular innovation pictures (such as Fantastia) that would introduce novel processes into these departments; and maybe product-market fit was part of Walt’s genius and so it didn’t need to be introduced elsewhere in the machine.\nBut to see the gradient by which an idea can be “plussed” and not corrupted as it moves towards market, well that’s fascinating.\n",
    link: "/home/2012/03/13/user_interface_of_seldons_plan",
  },
  {
    title: "Banksy, invention, and the six steps",
    date: "20.02, Wednesday 14 Mar 2012",
    content:
      "Banksy does all that outdoor stencil art. He started work between 1990-1994, and switched to stencilling in 2000. That his style has become so imitated is a signal to me that what he started was something new, if not in the medium (stencilling isn’t new, and nor is graffiti), but in the binding between his medium and his message.\nThere’s a story Banksy tells about discovering stencils as related in his book Wall And Piece and repeated in this article:\nI spent one night trying to paint LATE AGAIN in big silver bubble letters on the side of a passenger train. British Transport Police showed up and I got ripped to shreds running away through a thorny bush. The rest of my mates made it to the car and disappeared so I spent over an hour hidden under a dumper truck with engine oil leaking all over me.\nAs I lay there listening to the cops on the tracks, I realised I had to cut my painting time in half or give up altogether. I was staring straight up at the stencilled plate on the bottom of a fuel tank when I realised I could just copy that style and make each letter 3ft high.\nI got home at last and crawled into bed next to my girlfriend. I told her I’d had an epiphany that night and she told me to stop taking that drug ‘cos it’s bad for your heart.\nIn Scott McCloud’s Understanding Comics - which is excellent, go read it - McCloud puts forward a theory of artistic creation consisting of six steps, steps he likens to an apple. Surface is the skin. Idea/Purpose is the core.\nHere are McCloud’s steps:\n\nIdea/Purpose. The impulses, the ideas, the emotions, the philosophies, the purposes of the work… the work’s ‘content’.\nForm. The form it will take… will it be a book? A chalk drawing? A chair? A song? A sculpture? A pot holder? A comic book?\nIdiom. The ‘school’ of art, the vocabulary of styles or gestures or subject matter, the genre that the work belongs to… maybe a genre of its own.\nStructure. Putting it all together… what to include, what to leave out… how to arrange, how to compose the work.\nCraft. Constructing the work, applying skills, practical knowledge, invention, problem-solving, getting the ‘job’ done.\nSurface. Production values, finishing, the aspects most apparent on first superficial exposure to the work.\n\n(cf. Duffy/Brand’s shearing layers of change, for buildings: site; structure; skin; services; space plan; stuff.)\nIn the subsequent pages McCloud tells the story of an artist learning by starting at step 6, and working their way back - with effort - to step 3. Beyond step 3, there is a choice: does the artist want to say something about life through his art or does he want to say something about art itself. Choosing the second route, step 2, the artist becomes an “explorer.” Choosing the first, step 1, the artist uses art as a tool.\nBanksy, I think, invented at step 3. The proof is in the train epiphany anecdote: the story he wanted to tell forced him to do something different. Stencils leapt from somewhere else into graffiti, and the electric arc went via the kite-in-the-thunderstorm of Banksy’s eyes. Subsequent stencil artists may or may not have better structure, craft or surface, but they didn’t invent at step 3.\nI’m not going make a judgement whether doing what Banksy did is “better” or not. I don’t believe which steps an artist (or creator) operate in has much relation to “better” or value. But maybe the six steps are one way into to talking about all of this stuff. The breakdown provokes interesting questions: when and where should invention occur, in multiple places or one at a time; what is the interaction between invention and culture and time; how these steps would look when distributed across an organisation including all kinds of people.\n",
    link: "/home/2012/03/14/two_org_charts",
  },
  {
    title: "The Plague",
    date: "15.13, Sunday 18 Mar 2012",
    content:
      "I can say I know the world inside out, as you may see – that each of us has the plague within him; no one, no one on earth is free from it. And I know, too, that we must keep endless watch on ourselves lest in a careless moment we breathe in somebody’s face and fasten the infection on him. What’s natural is the microbe. All the rest – health, integrity, purity (if you like) – is a product of the human will, of a vigilance that must never falter. The good man, the man who infects hardly anyone, is the man who has the fewest lapses. Yes, Rieux, it’s a wearying business, being plague-stricken. But it’s still more wearying to refuse to be it. That’s why everybody in the world today looks so tired; everyone is more or less sick of plague. But that is also why some of us, those who want to get the plague out of their systems, feel such desperate weariness, a weariness from which nothing remains to set us free except death.\n– Albert Camus, The Plague (1947).\nIt says a lot, that quote.\nI’ve been in bed sick the past three days. I wasn’t reading The Plague, but in the odd hours I was awake I did finish reading Robison Crusoe.\nSpeaking of which, this article: Robinson Crusoe and the ethnic sidekick. The same archetype: Men in Black, Independence Day, Jerry Maguire, Crimson Tide, 48 Hrs., Pulp Fiction, even Field of Dreams. … battling an alien economic system in order to save the Protestant Work Ethic.\nLater: One of the crucial elements of that story that rewrote the world is how one acquires wealth. Until Crusoe, wealth was a dream peasants might have, but one they had little expectation of ever coming true. Most stories about acquiring wealth before Robinson Crusoe were stories like Ali Baba and the Forty Thieves, or some variant of the Purse That Never Empties, or the story of Aladdin, where wealth comes from rubbing a magic lamp.\nRobinson Crusoe acquired his money the hard way. He earned it! Or at least that’s how we perceive it. In truth, Crusoe got rich by entering a natural paradise and being the sole proprietor. He does not begin from scratch. The island is rich, has no owners, and needs improvement.\nIt goes from there. Gordon Gecko as Robinson Crusoe? Man Friday as apprentice white man, a new paradigm of racism? A cracking read.\n",
    link: "/home/2012/03/14/banksy_and_the_six_steps",
  },
  {
    title: "A description of metabolism",
    date: "08.55, Tuesday 20 Mar 2012",
    content:
      "This is the most straightforward description of metabolism I’ve read. I’m just going to quote it all. I look at what I might highlight, and there’s not a wasted word.\n\nOne property of living things above all makes them seem almost miraculously different from nonliving matter: they create and maintain order, in a universe that is tending always to greater disorder. To create this order, the cells in a living organism must perform a never-ending stream of chemical reactions. In some of these reactions, small organic molecules–amino acids, sugars, nucleotides, and lipids–are being taken apart or modified to supply the many other small molecules that the cell requires. In other reactions, these small molecules are being used to construct an enormously diverse range of proteins, nucleic acids, and other macromolecules that endow living systems with all of their most distinctive properties. Each cell can be viewed as a tiny chemical factory, performing many millions of reactions every second.\nThe chemical reactions that a cell carries out would normally occur only at temperatures that are much higher than those existing inside cells. For this reason, each reaction requires a specific boost in chemical reactivity. This requirement is crucial, because it allows each reaction to be controlled by the cell. The control is exerted through the specialized proteins called enzymes, each of which accelerates, or catalyzes, just one of the many possible kinds of reactions that a particular molecule might undergo. Enzyme-catalyzed reactions are usually connected in series, so that the product of one reaction becomes the starting material, or substrate, for the next. These long linear reaction pathways are in turn linked to one another, forming a maze of interconnected reactions that enable the cell to survive, grow, and reproduce.\nTwo opposing streams of chemical reactions occur in cells: (1) the catabolic pathways break down foodstuffs into smaller molecules, thereby generating both a useful form of energy for the cell and some of the small molecules that the cell needs as building blocks, and (2) the anabolic, or biosynthetic, pathways use the energy harnessed by catabolism to drive the synthesis of the many other molecules that form the cell. Together these two sets of reactions constitute the metabolism of the cell.\nFrom the chapter Catalysis and the Use of Energy by Cells in Molecular Biology of the Cell. 4th edition.\n\n",
    link: "/home/2012/03/18/the_plague",
  },
  {
    title: "Lucky meat",
    date: "14.56, Monday 26 Mar 2012",
    content:
      "A concept for a vending machine for tea (or coffee).\nI’m totally into the idea that witnessing is a key part of the experience of vending, maybe even that there’s a fairytale world inside the machine.\nBut in particular I think that vending machines can be about experiences and stories.\nSo tea. Or coffee. Caffeinated beverages are about waking you up.\nWhat you do is you make the entire front face of the vending machine glass, but it’s a giant glass “V” shape that inclines into itself, so that at the top of the machine it’s very wide, and lower down at waist height the “V” shape both narrows and pulls back into itself, tilting back into the machine.\nThen when you choose your tea (or coffee), the liquid is shot as if through the barrel of a gun BANG directly at your face. We use facial recognition computer chips or something for this. It blasts, and splashes, as hard and fierce as possible. And then the tea (or coffee) is runs down the inside slope of the “V” and is channeled in and falls eventually into a cup at the bottom apex where it finally drips in. Then you have your drink. (But you don’t need it, because you’re already awake.)\nThe pretence that we tell people is that tea (or coffee) is better aerated, and the fire-hose of piping hot beverage straight between the eyes is integral to the process of making it taste awesome. Really it’s about the experience of it and telling your friends. This is the vending machine I would like to make.\nAlso I have an idea for a restaurant.\nLucky meat.\nTake 64 steaks, or better: 64 cows.\nDivide the cows into two groups, 32 each, and name one heads and the other tails.\nFlip a coin.\nWhichever group of cows loses is butchered and the produce destroyed, rendered inedible.\nNow take the winning group of 32 cows. Divide them in two. Flip a coin. 16 win, 16 are destroyed.\nRepeat, repeat, repeat, you have 2 cows. Flip a coin, one wins, destroy the loser, make steaks out of the winner.\nThese steaks are from a lucky cow: it has won 6 times in a row, a winning steak from a winning streak.\nBy the magic of tapu - or, to put it another way, the Law of Association from the laws of magic - the lucky meat will carry with it the luck of the animal. By eating the lucky meat, the eater too becomes lucky. Imagine yourself being presented with, and eating, lucky meat, knowing that the meat has somehow been chosen, somehow won the lottery and ended up on your plate! Of course this is also a commentary on the wasteful nature of agro-industry, or maybe it’s a commentary on what makes luxury items or the nature of scarcity and the tenuous non-existence of value, etc. Honestly it’s about meat, when it comes down to it.\nI think you could charge a lot more for lucky meat.\nSome might argue that none of the cows are lucky.\n",
    link: "/home/2012/03/20/description_of_metabolism",
  },
  {
    title: "Marx at 193",
    date: "11.52, Monday 2 Apr 2012",
    content:
      "Some choice quotes from Marx at 193 by John Lanchester.\n\nEmpiricism, because it takes its evidence from the existing order of things, is inherently prone to accepting as realities things that are merely evidence of underlying biases and ideological pressures. Empiricism, for Marx, will always confirm the status quo. He would have particularly disliked the modern tendency to argue from ‘facts’, as if those facts were neutral chunks of reality, free of the watermarks of history and interpretation and ideological bias and of the circumstances of their own production.\n\nOn the origin of value, In Marx’s judgment surplus value is the entire basis of capitalism: all value in capitalism is the surplus value created by labour. And so Marx creates a model which allows us to see deeply into the structure of the world, and see the labour hidden in the things all around us. He makes labour legible in objects and relationships.\nLanchester digs into Facebook and into airport check-in:\n\nThis idea of labour being hidden in things, and the value of things arising from the labour congealed inside them, is an unexpectedly powerful explanatory tool in the digital world. … When you start looking for this mechanism at work in the contemporary world you see it everywhere, often in the form of surplus value being created by you, the customer or client of a company. Online check-in and bag drop at airports, for example. … They’re transferring their inefficiency to the customer, but what they’re also doing is transferring the labour to you and accumulating the surplus value themselves. It happens over and over again. Every time you deal with a phone menu or interactive voicemail service, you’re donating your surplus value to the people you’re dealing with. Marx’s model is constantly asking us to see the labour encoded in the things and transactions all around us.\n\nSidenote: I have an objection to the Dyson Airblade in that previous generations of hand-driers encouraged me to move and play with my hands, attempting to find for myself some kind of expertise or intelligence in drying, but the Airblade, in order to achieve its own efficiency forces all of its users to adopt identical movements, removing autonomy from millions to save money for the owners of the establishments in which it is installed. I have been roboticised.\nBack to Lanchester: the rest of Marx at 193 covers the variety of capitalisms developed since his work, the limits of natural resources, China and Mass Group Incidents, basically anti-authority riots which occur regularly all over China and seem never to be reported in the Western mainstream media, and this nugget about life expectancy:\n\nUK life expectancy is now over eighty and rising so sharply that buried in the statistics is a truly strange fact: a woman who is eighty today has a 9.2 per cent chance of living to be a hundred, whereas a woman of twenty has a 26.6 per cent chance. It may seem weird that the person sixty years younger has a three times better chance of making it to a century, but what it shows is just how fast progress is being made.\n\nRead the whole thing.\nLanchester’s article is in the current issue of the London Review of Books which is a total treat. Another joy is Thomas Jones’ review of two biographies of David Bowie/Ziggy Stardust, So Ordinary, So Glamorous, which is a must-read for the whole story but also for this simultaneous smack-down and correction: Trynka doesn’t often go into details about the music, which is perhaps just as well. In his discussion of ‘Starman’ he talks about its ‘opening minor chords’ when they’re nothing of the kind, and says that ‘the key changes from minor to major’ at the chorus. But there’s no key change, and it’s important that there isn’t: the effect Trynka’s hearing, the sense of ‘release’ and ‘climax’ he gets when the chorus kicks in, would be lost if there were. What happens is that for the first time, the melody hits the tonic; Bowie gets through 15 bars in F major without singing an F, and then on the word ‘starman’ he hits two of them, an octave apart. BANG!\nHere’s Starman, live in 1972, and listen out for that avoidance of the F and then suddenly when you hear it. Wow.\n",
    link: "/home/2012/03/26/lucky_meat",
  },
  {
    title: "Peak Attention and the DuPont Equation",
    date: "18.08, Tuesday 3 Apr 2012",
    content:
      "I keep coming back to this article A Brief History of the Corporation: 1600 to 2100 (which I first read back in Week 315), in particular the section Schumpeterian Growth and the Industrial Economy (1800-2000) which is about (and I quote) THE COLONIZATION OF TIME which I have written in caps and underlined because it is meant to be said out loud like this:\nThe COLON IIZ AAAATION OF TIIIIIME.\n\nPer capita productivity is about efficient use of human time. But time, unlike space, is not a collective and objective dimension of human experience. It is a private and subjective one. Two people cannot own the same piece of land, but they can own the same piece of time.  To own space, you control it by force of arms. To own time is to own attention. To own attention, it must first be freed up, one individual stream of consciousness at a time.\nThe Schumpeterian corporation was about colonizing individual minds. Ideas powered by essentially limitless fossil-fuel energy allowed it to actually pull it off.\n\nAaaaand:\n\nThe equation was simple: energy and ideas turned into products and services could be used to buy time. Specifically, energy and ideas could be used to shrink autonomously-owned individual time and grow a space of corporate-owned time, to be divided between production and consumption. Two phrases were invented to name the phenomenon: productivity meant shrinking autonomously-owned time. Increased standard of living through time-saving devices became code for the fact that the “freed up” time through “labor saving” devices was actually the de facto property of corporations.\n\nGosh, feels like the internet doesn’t it.\n\nFor the same two centuries it seemed like time/attention reserves could be endlessly mined. New pockets of attention could always be discovered, colonized and turned into wealth.\nThen the Internet happened, and we discovered the ability to mine time as fast as it could be discovered in hidden pockets of attention. And we discovered limits.\nAnd suddenly a new peak started to loom: Peak Attention.\n\nSidebar: There’s something I faintly remember reading in Lefebvre, Love & Struggle: Spatial Dialectics by Rob Shields. It’s so faint I’m not sure I’m remembering it correctly. But I think it was something about Henri Lefebvre writing in post-war France about home automation - washing machines and the like - and seeing it as a turning inwards of the forces of colonisation: France was no longer colonising other countries and instead was eating itself in a colonisation of everyday life. Which gives me an image of a country-body made from rapacious corporations, starved after being cut off from their food of the various European empires, digesting its own body of workers and consumers, burning the healthy fat pockets of attention and boredom and creating the jittery, never at rest, meth-addled population we have today.\nOne final thing from A Brief History of the Corporation (READ IT), this line: I am not sure who first came up with the term Peak Attention, but the analogy to Peak Oil is surprisingly precise. It has its critics, but I think the model is basically correct. I think I might have said it first, here and here. But who knows, it probably wasn’t me.\nReturn on Equity\nAnd the thing for me is I like to trace the paths between abstraction and acts. For example, at work we’ve recently been doing some consultancy with a company on new product development, and part of the work (I encourage it to be part of the work) is to consider not just new concepts, but how to ensure new concepts are adopted. That means understanding the business, the audience, route to market, etc, but also the personality of the organisation: what will work well in the organisation, and what will the organisation resist?\nThe personality of an organisation is embodied in its structure (which encodes both who socialises with who, which is my best model for how understanding and influence is transmitted, and the values and worldview of its management), and also its myths: what is its origin (this will be held up as a triumph to mimic); what examples does it use as patterns to mimic or run away from?\nSo I like to be able to simultaneously speak about the personality of an organisation (the abstraction) and how that abstraction manifests in action – that is, the behaviours of individuals and much smaller groups. This is my route to figuring out how to change an organisation… and honestly, getting an organisation to produce a new product or support a new concept is always going to involve change, because if the organisation didn’t need to change then it would already be doing whatever we’ve been brought in to help with.\nOne of the things that has intrigued me is how the pursuit of profit by a corporation - the concept of which is bizarre, by the way, that “pursuit” is a something that can be done by a “corporation,” a thing/idea partially comprising but also transcendent from the humans who can actually pursue - anyway, how the pursuit of profit by a corporation leads to the very many (but not all) frankly shitty organisations that exist in the world today, organisations which\n\nneither make the people in them happy;\nnor make the people who interact with them happy;\nare none-the-less profitable!\nbut dealing with them feels a bit like dealing with a person whose memory is sub 3 seconds, and whose left hand and right hand are controlled by separate bodies who fell out once over a silly and probably avoidable situation and a decade later now won’t even go to the same parties, the misunderstanding having calcified and cooled into a mutual avoidance which is no longer seething - it would show up as dark blue on one of those thermal imaging cameras - but is utterly fixed.\n\nIntrigued that is until I read End the Religion of Return on Equity in the Harvard Business Review which puts the blame firmly at the feet of a human named Donaldson Brown, of the company DuPont, in 1917:\n\nA hundred years ago, the focus on squeezing every drop of return out of equity capital made great sense. …\nThe ability to do that rose to a new level in 1917, when General Motors was in financial difficulty and DuPont took a major position in the company. (GM represented an important channel for Dupont’s lacquer, artificial leather, and other products, and Pierre du Pont was on GM’s Board.) DuPont sent Donaldson Brown, a promising engineer-turned-finance staffer, to Detroit to sort things out, and sort them out he did.\nBrown noted a simple fact: Return on equity can be broken down into a three-part equation. It is logically the product of return on sales times the ratio of sales to assets times the ratio of assets to equity. By parsing ROE into the DuPont Equation (very rapidly to become a business school mainstay), he provided the basis for organizations divided into functions with their own objectives. He reasoned that if marketers worked on maximizing return on sales, production managers were rewarded for the sales they squeezed out of their physical plant, and finance managers focused on minimizing the amount of equity capital they needed, ROE would take care of itself.\nThus Brown not only sowed the seeds of the today’s hated silos, he also set three “runaways” in motion. That is to say, he created objectives with such strong feedback loops that they were pursued single-mindedly, even to unhealthy excess.\n\nThe DuPont Equation.\nBang! Read that again. Each of the three components of the equation is a top-level division of the company, as separately run as it is possible to do, with different goals, requiring a different mentality from the people in the divisions.\nAgain: Each ratio in an equation written by a man named Donaldson Brown in 1917 has become separated into different divisions in org charts of corporations almost 100 years later.\nNo wonder some corporations can feel so schizophrenic.\nThe article makes it clear…\n\nIn their pursuit of margin, marketers sought market power even to the point of monopoly, requiring antitrust laws to cry stop at the last moment of the end game. Similarly, production engineers treated their factories royally and their labor as expendable, until unions and labor laws intervened. Financial managers, supported by their bankers, increased their debt-to-equity ratios until capital requirements were imposed-oops, we mean until there was a catastrophic financial crash and a depression.\n\n…and then it continues into speculating about a new formation for the DuPont Equation. It’s worth your time.\nHow these ideas of Peak Attention and the DuPont Equation are linked\nDon’t know, still thinking about that.\n",
    link: "/home/2012/04/02/marx_at_193",
  },
  {
    title: "A slow savings account",
    date: "13.57, Wednesday 4 Apr 2012",
    content:
      "Pensions have a very particular schedule. You pay in to the same plan - at a rate of 10% or more over a large chunk of your career - and it starts paying out at a fixed point: at age 55, or 60, or whatever.\nIt seems to me that a pension’s particular schedule should instead be one end of a spectrum, the other end of which is credit cards and savings accounts. And then we should fill in that spectrum.\nSee, savings accounts are a way of putting a little bit of money aside for a big future purchase or a “rainy day.” Unemployment insurance does the same job, but it has a fixed pay-out trigger.\nSavings accounts, unemployment insurance, and pensions are all ways to smooth out spikes in income over time.\nA credit card provides for smoothness too, only it smooths out income spikes into the past whereas a savings account or a pension smooths out income spikes into the future. There are also fixed term investment vehicles with tax benefits. \nI wonder whether there’s another kind of income smoothness service, one possible only with modern computerised record-keeping?\nI’ve been using Twitshift, which lets me follow myself from a year ago on Twitter. I get to see all the things I was doing and thinking from 365 days in the past. Timehop does a similar job, but across lots of social media. I like the continuous, day-by-day nature of it.\nAlso I think a little about Bob Shaw’s concept of slow glass which is glass that is so opaque that light takes as long as ten years to pass through it. From a practical standpoint, then, if you looked through a window made of slow glass, you’d see events that took place outside that window ten years ago.\nI would like a slow savings account.\nA slow savings account would work exactly like a regular account – I could pay money into it, and transfer money out. The difference would be: when I pay money in to a slow savings account, it appears in the available balance exactly one year later.\nAdditional slow savings models might include:\n\nContinuous partial pension. A pension doesn’t start at a fixed date, but is paid continuously over my entire life. I pay into it, and it pays me a very small amount every month (which, of course, I could use to pay back into my pension, deciding to feed the present to the future). This would give me a direct and visceral sense of the strength of my income as a 65 year old - having income of just 10 bucks a month from my continuous partial pension would certainly make me want to contribute more to it - and also gradually raise my safety line, the minimum level of income to which I am able to fall. A higher safety line lets me take more risks to find happiness and/or wealth, which is the advantage had by people from rich backgrounds.\nSpike smoothing. Whenever my current account balance spikes above a certain threshold, the surplus is taken and distributed evening over the next year. This achieves one of the functions of a regular savings account, in an automatic fashion.\n\nA slow savings account would be the exact opposite of a credit card: it distributes present income into the future, instead of borrowing from the future; it deals with assets instead of liabilities; it encourages smooth spending instead of enabling large spike purchases; it raises the level of the safety net instead of raising the level of indebtedness.\n",
    link: "/home/2012/04/03/peak_attention_and_the_dupont_equation",
  },
  {
    title: "Instagram as an island economy",
    date: "03.53, Wednesday 11 Apr 2012",
    content:
      "Facebook bought Instagram for a billion dollars.\nIf you don’t know:\n\nFacebook is a corporation with a database in which they would like to record every act that every person makes, annotated with the place and time, and another database that lists every social relationship each person has. They are persuading people to do this by being the world’s second virtual society, the first being the internet itself, the difference with Facebook being that everything in the society is recorded in a form that makes cross-indexing simple.\nInstagram is a corporation with a smartphone app that lots of people use to take and share photos. Instagram makes it easy to take pretty photos, and to see the pretty photos of your friends. The photos are used to (a) represent yourself to your friends, and (b) act as condensation seeds for social interactions of the type (i) grooming and (ii) conversation.\nA billion dollars is a lot of money.\n\nNot users but producers/consumers\nThe other day I picked some choice quotes from ‘Marx at 193’ (an article by John Lanchester). Here’s one: This idea of labour being hidden in things, and the value of things arising from the labour congealed inside them, is an unexpectedly powerful explanatory tool in the digital world.\nWhat is the labour encoded in Instagram? It’s easy to see. Every “user” of Instagram is a worker. There are some people who produce photos – this is valuable, it means there is something for people to look it. There are some people who only produce comments or “likes,” the virtual society equivalent of apes picking lice off other apes. This is valuable, because people like recognition and are more likely to produce photos. All workers are also marketers – some highly effective and some not at all. And there’s a general intellect which has been developed, a kind of community expertise and teaching of this expertise to produce photographs which are good at producing the valuable, attractive likes and comments (i.e., photographs which are especially pretty and provocative), and a somewhat competitive culture to become a better marketer.\nThere are also the workers who build the factory – the behaviour-structuring instrument/forum which is Instagram itself, both its infrastructure and it’s “interface:” the production lines on the factory floor, and the factory store. However these workers are only playing a role. Really they are owners.\nAll of those workers (the factory workers) receive a wage. They have not organised, so the wage is low, but it’s there. It’s invisible.\nLike all good producers, the workers are also consumers. They immediately spend their entire wage, and their wages is only good in Instagram-town. What they buy is the likes and comments of the photos they produce (what? You think it’s free? Of course it’s not free, it feels good so you have to pay for it. And you did, by being a producer), and access to the public spaces of Instagram-town to communicate with other consumers (access to these spaces is so valuable to me that it keeps me using the iPhone, a model of smartphone which can run Instagram, rather than Windows Phone 7 which I have used and enjoyed, but cannot).\nIt’s not the first time that factory workers have been housed in factory homes and spent their money in factory stores.\nImplications:\n\nThere is a way of identifying the various value exchanges, which means there should be a way to calculate the aggregate value.\nHowever, Instagram is more-or-less a closed economy: producers are paid in Instagram-dollars and consumers pay with Instagram-dollars. The loop is so tight that the Instagram-dollars are invisible. So how is the aggregate value to be calculated? Instagram-town is barely connected to the US dollar so we don’t know what the value is.\n\nI will say that it’s simple to make money out of Instagram. People are already producing and consuming, so it’s a small step to introduce the dollar into this.\nThe question is: what will the exchange rate be?\nIsland economies and colonisation\nThe situation of Instagram is that of an isolated island economy, separate from the outside world, being linked to the global economy. How do we figure out what it’s worth to the global economy? How do you value a closed system?\nI can think of three examples: Japan’s period as an autarky (self-sufficient economy) in the 1850s; China’s transition from a closed to a linked economy over the past decade; a Pacific island such as Naura, in the middle of nowhere, being colonised.\nThe third makes me think that the business of these virtual society companies (there are lots) is to isolate some settlement on an island, allow it to develop for a small amount of time, and then colonise it. This is the story of empire, but it’s also the story of expansion. Think of the Wild West: first the people, then the railways, the banks, the law, and government.\nBut the Wild West ended up okay, part of it we call California. Both Instagram and Facebook are based there.\nMaybe Instagram is worth a billion dollars, there’s certainly a lot of labour encoded in the objects of its production. More valuable, I think, for Facebook is the general intellect I have not mentioned: that developed by the factory owners. They’re highly accomplished at paying their workers very little (i.e., since there is no money changing hands, we measure this by observing that the workers are highly productive) and, out of their workers, training good marketers. Facebook needs that in order to complete their database.\nMoney; users\nMore interesting to me is the question of what happens when the workers organise, and demand a wage that is transferrable between the island economies of the internet. I’ve absolutely no idea what that would even look like, a transferrable store of labour but one in which the act and value of labour is contextually variable according to its position in a social network. But I can’t imagine money itself looked entirely obvious before it was invented either.\nThe second interesting point is that the word “user,” as in a user of Instagram or Facebook, is dangerous, because it hides all of this.\n",
    link: "/home/2012/04/04/slow_savings_account",
  },
  {
    title: "Decision fatigue",
    date: "18.25, Sunday 15 Apr 2012",
    content:
      "Decision fatigue: When you make a lot of choices in a short period of time, you find it harder to exert self-control.\n\nWikipedia’s examples of decision fatigue include: how decision fatigue can leave a person vulnerable to sales and marketing strategies designed to time the sale [such as the hard to turn down] dealer’s offer to rustproof their new car; and this: George Loewenstein has suggested that the disastrous failure of men in high office to control impulses in their private lives may at times be attributed to decision fatigue stemming from the burden of day-to-day decision making. Similarly, Tierney notes that ‘C.F.O.’s [are] prone to disastrous dalliances late in the evening’, after a long day of decision-making. Decision paralysis is another form: given the choice between too many things, a person might choose instead to walk away.\nInequality of the will (via @tomstafford) which, in a discussion about willpower and poverty, puts forward Baumeister’s conceptualisation of willpower as a muscle: Put simply, willpower gets tired by using it. For example, if you place cookies in front of someone and tell them not to eat them, then they will give up more easily on a difficult task that follows – such as choosing which job offer to accept. (The article makes clear that it is not certain how far the muscle metaphor goes.)\nScientific American’s article Tough Choices, reporting on the paper Making choices impairs subsequent self-control: a limited-resource account of decision making, self-regulation, and active initiative, gets into the science: Why is making a determination so taxing? Evidence implicates two important components: commitment and tradeoff resolution. The first is predicated on the notion that committing to a given course requires switching from a state of deliberation to one of implementation. In other words, you have to make a transition from thinking about options to actually following through on a decision. … Yale University professor Nathan Novemsky and his colleagues suggest that the mere act of resolving tradeoffs may be depleting. For example, in one study, the scientists show that people who had to rate the attractiveness of different options were much less depleted than those who had to actually make choices between the very same options.\n\nI was in Las Vegas last week, and seeing the women in short skirts serving at the resort facilities and in the casino bars, remembering also the booth babes at CES, it got me thinking why casinos and trade shows bother doing this. What game are they playing? (You can tell I’m a lot of fun at parties.)\nI wonder whether it might be to fatigue the superego. You’re working hard not to behave in an inappropriate fashion around this show, so your self-control becomes inhibited in subsequent situations such as whether to place a big bet or let yourself be guided along a path by a salesperson about a purchase or checking out a product. “Inappropriate fashion” varies for straight men, straight women and gay women. Gay men and people who don’t bother censoring their behaviour would seem to be at an advantage here.\nLast thoughts:\nPeople seem to enjoy the large number of choices involved in getting coffee at Starbucks. Does this warm up your decision muscle every morning? And television is the epitome of decision-free consumption - one choice every 30+ minutes - so is this why it belongs so neatly in the evening, when decision fatigue has really kicked in?\nShould you ration the decisions you make, wearing the same clothes every day to retain your limited choosy vital fluids for the major stuff? Or does your choice muscle get pumped over the months: the more decisions you make, the better you get?\nI mentioned the superego just now, Freud’s concept of the personality’s guiding sense of right and wrong. I find it interesting that decision making and self-control are linked, in that activity in one will fatigue the other. It would be interesting to explore the entire space of functions associated with the superego and find - via mutual fatigue effects - which are, in this functional view, part of the same muscle.\n",
    link: "/home/2012/04/11/instagram_as_an_island_economy",
  },
  {
    title: "After I die",
    date: "12.51, Sunday 22 Apr 2012",
    content:
      "This is a bit morbid I suppose but I’ve been thinking about what I’d like done with me after I die (which won’t be for a good long time, touch wood).\nWhen I imagine the brain, I think that “me” is its structure, and its electrical and chemical signalling. “Me” is also my brain as embodied in my meat, and I can imagine the structure and the dynamics of that too. My structure - of my body and my brain - changes continuously, as I grow and change, and as I learn and have experiences.\nWhen I imagine the dead me, I imagine a body with a brain which is thinking really, really slowly. As my body and my brain decompose, these are simply changes in the structure – so decomposition would feel like learning and developing, in some sort of way. And as adjacent neurons break down and affect one-another, or as a worm burrows its way through my dead brain, maybe these would feel like occasional thoughts.\nAnd so, during this time, the pattern which is my consciousness becomes absorbed into the pattern which is the world, and mingles with structures already there, new connections are made and others broken, just as thinking already is, and the changing me-pattern I experience as slow thoughts and slow developments of the self, and I become part of a wide, slow, thinking earth.\nThat’s option one, to be buried and to decompose gently.\nOption two:\nI would like to be cremated, my ashes made into bread, and the bread shared out and eaten by all my friends. I think that would be wonderful.\n",
    link: "/home/2012/04/15/decision_fatigue",
  },
  {
    title: "Belief and desire",
    date: "15.08, Monday 30 Apr 2012",
    content:
      "On the sociology of Gabriel Tarde:\n\nTarde denies the existence of higher-level entities (like “society” according to Durkheim). This is an atomism not just of composition, but of organization. There is no such thing as social laws and regulations, social norms, social impositions. There are only power relations among individuals. Certain individuals impose on others; certain individuals are imitated by others. Social coherence is merely the result of imitation on a mass scale, together with raw power impositions.\nHowever, Tarde is not advocating the sort of “individualism” one sees in traditional liberalism, from Adam Smith to the free-market fanatics of today. … Individuals, no less than human societies, are composed of multiple elements that overpower and/or imitate one another. You can’t call Newton the author of the laws of motion any more than you could call 17th Century British society, or King Charles as its representative, the author of those laws. The author is more properly one particular atomistic thought in Newton’s brain, a thought that overpowered the other thoughts in his brain, compelled them to obey it, or seduced them to imitate it.\nBy a similar argument, it cannot possibly be the case that all hydrogen atoms are uniform and interchangeable. The only explanation for the apparent uniformity of nature is that one particular hydrogen atom dominated the others, forced them to obey it, or induced them to imitate it.\n\nAnd:\n\nThe ultimate motivating forces that move all of the world, whether human beings in society, thoughts in a single brain, or hydrogen atoms in a gas, are according to Tarde belief and desire. There’s nothing else. Rocks and stars, indeed atoms themselves, believe and desire just as we do. At the other extreme, things like ideologies and customs and social classes and bureaucracies can be explained merely as statistical aggregations of particular beliefs and desires, amplified by mass imitation.\n\nBelief and desire!\n",
    link: "/home/2012/04/22/after_i_die",
  },
  {
    title: "Science questions",
    date: "10.26, Monday 14 May 2012",
    content:
      "SCIENCE QUESTIONS\n\nIs it true the human ear never stops growing?\nIf the universe is infinite then why is so much of the night sky black?\nHow come the biggest corn flakes are on the top of the pack and don’t sink?\nWhy do people imitate birds by whistling when birds don’t have lips?\nIs it true that dogs see in black and white?\nIs it true that dogs die from eating chocolate?\nIs it true that dogs can see ghosts?\nWas there a dog jesus?\nIf there wasn’t a dog jesus, if a dog dies from eating chocolate, does a dog go to heaven?\nOr does the dead dog become a dog ghost?\nIs this why dogs can see ghosts?\nBecause ghosts are dogs?\nAnd dogs are ghosts?\nMountains, are they small or far away?\n\n",
    link: "/home/2012/04/30/belief_and_desire",
  },
  {
    title: "FuelBand for alpha waves",
    date: "09.54, Wednesday 16 May 2012",
    content:
      "I was waiting for a bus the other day, and had a pretty good time stand there, wool gathering, contemplating the world, thinking about the various things I needed to do, etc.\nAnd on the bus after I thought: I don’t give myself enough time to stop and think.\nAnd then I thought: I don’t give myself enough time to exercise either, and what I did in that case was buy a Nike+ FuelBand and monitor how many steps I take each day. (There was a surprise there: Factoring out exercise, there’s a huge variation in my regular everyday activity, a four-times difference between quiet days and active days although they feel much the same.)\nSo I bought a MindWave from Neurosky which is a portable electroencephalography (EEG) headset with dry sensors. That is, it measures faint electrical activity on my head to read my brainwaves, and it’s “dry” so I don’t need to soak the sensors in saline or anything like that.\nIn theory it should be able to measure when I’m concentrating, when I’m excited/agitated, and when I’m relaxed.\nIt comes with a dongle to plug into my Mac so I can read the data from it using the MindWave developer tools. (In retrospect I should have bought the MindWave Mobile which uses Bluetooth and can also connect to the iPhone.)\nIt’s a shame the MindWave doesn’t store data itself – if I want to get long-term readings then I will have to keep it paired with my Mac and store and analyse the data there.\nWhy? Because I’d like to wear this the whole time, and become more mindful of how much time - and for how long - I’m concentrating, reflecting, etc. And over time, being mindful of this, could I see whether I’m happier/more productive/more creative when I spend (say) regular time each day reflecting, or long periods of time on a single day concentrating, and so on.\nCompanies I would start if I wasn’t doing this one:\nThe models currently in this space are exemplified by two companies, both based on Neurosky’s technology:\n\nHome of Attention, which caters to managers for trainers and managers for education and self-improvement. In their literature there are phrases like : You learn to relax at any time, You learn how to use your concentration to access any required performance at an instant. Other companies focus brain training on different sectors, and adjust their branding accordingly.\nToys and games, of which my favourite is the Necomini cat ears headset. These ears perk up when you see something interesting (food, a pretty boy), and fall when you relax. A neat toy… and done right it would be entertaining to see these in bars, although I have a feeling they’re really a Hypercolor for checking people out.\n\nNeurosky themselves have an app store.\nBut I think these companies are missing a trick. I’d like to introduce focus, good design, and vertical integration, and take lessons from successes like Nike+ and Foursquare.\nI would love to take the Neurosky MindWave technology, have it store data for later syncing as a Bluetooth Smart Device, make it look great, wrap a FuelBand self-awareness and goals iPhone app around it, build in a mood tracking feature for feedback - maybe correlate it with email and calendar/todo list activity, Twitter/Facebook updates (for another mood datapoint), and Foursquare (for location) - and sell it as a headband.\nYou would share the time you’d spent reflecting each day on Facebook. There would be challenges, and self-awareness. I might bootstrap a distributed network of gym instructors for meditation (we’d have a marketplace for subscription yogis).\nKind of a cross between Brain Age (or Brain Training depending on your territory), FuelBand, product sales plus subscription services, quantified self, and mental well-being.\nThe really interesting stuff would happen when we start using machine learning across vast amounts of data from tens of thousands of individuals, all submitting brain wave and activity/mood data. We’d data-mine like crazy. What would we learn? It would be a little like 23andme, the data-mining + pathologies + gene sequencing company, and a little like Knewton with their personalised, adaptive learning. Maybe we would end up saying things like:\n\nYou know you need to be on top form in 5 days? We know from past behaviour and by looking at people like you that you need to spent 30 minutes more per day in uninterrupted quiet reflection in order to achieve this. Here’s your goal. Go!\n\nThere’s not quite a business here, not at launch… but after you find out what combinations of which mental states over a day promote what kind of behaviours, and you can help people be mindful of that? There’s something really big there, I’m sure.\nI wish I had more hours in the day.\nRight now\nI am using my MindWave and playing Blink/zone to explode fireworks whenever I blink. When I don’t blink they don’t explode, when I do blink they do. It works surprisingly well. It’s a weird experience to have something I regard as so interior picked up by a computer.\n",
    link: "/home/2012/05/14/science_questions",
  },
  {
    title: "Ze Frank on ugly",
    date: "09.43, Tuesday 22 May 2012",
    content:
      "Ze Frank’s 2006 defence of ugly MySpace pages as markers of mass experimentation and the democratisation of design:\n\nFor a very long time, taste and artistic training have been things that only a small number of people have been able to develop. Only a few people could afford to participate in the production of many types of media. Raw materials like pigments were expensive; same with tools like printing presses; even as late as 1963 it cost Charles Peignot over $600,000 to create and cut a single font family.\nThe small number of people who had access to these tools and resources created rules about what was good taste or bad taste. These designers started giving each other awards and the rules they followed became even more specific. All sorts of stuff about grids and sizes and color combinations - lots of stuff that the consumers of this media never consciously noticed. Over the last 20 years, however, the cost of tools related to the authorship of media has plummeted. For very little money, anyone can create and distribute things like newsletters, or videos, or bad-ass tunes about “ugly.”\nSuddenly consumers are learning the language of these authorship tools. The fact that tons of people know names of fonts like Helvetica is weird! And when people start learning something new, they perceive the world around them differently. If you start learning how to play the guitar, suddenly the guitar stands out in all the music you listen to. For example, throughout most of the history of movies, the audience didn’t really understand what a craft editing was. Now, as more and more people have access to things like iMovie, they begin to understand the manipulative power of editing. Watching reality TV almost becomes like a game as you try to second-guess how the editor is trying to manipulate you.\nAs people start learning and experimenting with these languages authorship, they don’t necessarily follow the rules of good taste. This scares the shit out of designers.\nIn Myspace, millions of people have opted out of pre-made templates that “work” in exchange for ugly. Ugly when compared to pre-existing notions of taste is a bummer. But ugly as a representation of mass experimentation and learning is pretty damn cool.\nRegardless of what you might think, the actions you take to make your Myspace page ugly are pretty sophisticated. Over time as consumer-created media engulfs the other kind, it’s possible that completely new norms develop around the notions of talent and artistic ability.\n\nHere’s the video.\n",
    link: "/home/2012/05/16/fuelband_for_alpha_waves",
  },
  {
    title: "Instagram for webpages",
    date: "18.14, Tuesday 22 May 2012",
    content:
      "Companies I would start if only I had the time, #2 in a series. (Previously, FuelBand for alpha waves.)\nInstagram for webpages.\nHear me out:\nInstagram has proven there is a mass appetite for creativity and personal expression. Look at the popular photos on Instagram: girls, pets, and sunsets; well-shot and quirky. Facebook, by comparison, is a desert – a gridded Excel spreadsheet of relationship changes and status updates. When at last they added the possibility of creativity - of beauty and of ugliness - in the shape of Facebook Timeline banners, people leapt at it.\n(Note: I’m obsessed with Instagram. I think it’s brilliant. A demonstration that people in a social group when left together and given the right tools develop deep skills and a rich culture.)\nThe mass creativity is what I really miss about MySpace. Check out Ze Frank talking about MySpace in 2006: sure the ugly pages were a joke, but ugliness was also a sign of a huge amount of experimentation, of personal expression, of wit and one-upmanship, of tribes and remixing. Culture in action!\nThe granddaddy of mass creative expression online was GeoCities, started in 1994 and now dead but archived. A giant metropolis of people speaking in HTML - the bricks and cement of the Web - learning from one-another, improving their skills to speak better – having conversations by creating and sharing. GeoCities is the roots of present-day maker culture. And it was enabled by the very thing that makers are right now injecting into the manufacturing world with open source hardware: view source. View source! See how any webpage is constructed, then copy-and-paste parts of HTML and use it yourself! What a great way to learn.\nThere’s no “view source” on the iPad.\nThat smells like a gap in the market.\nProductizing “view source”\nWe’ll start with an Instagram clone for the iPhone and iPad. Instead of photos, users would share webpages written in the app itself. There’s view source, of course.\nWhat we’ll do…\n\nAll webpages are hosted in the app, there’s no separate browser. Users make them, and you see what your friends have published recently in a big list of square pages. Webpages can be viewed outside the app too\nNo links, no browsing. It’s a reverse chronological list of new, fixed size webpages made by your friends\nBuilt-in HTML editor, with a deliberately limited feature set (e.g., XHTML, no sound and no music)\nDraft mode: Before a you publish a page, you can show the source to your friends to ask for hints\nTurn the phone sideways to read the source for any page\nCSS animations and 3D (but no Javascript)\nLots of fonts and glyphs\nAbility to upload small pictures, and filters to apply to them\n\nPages would be a fixed width and height, and there would be a file-size limit.\nWe’ll also have a few features to invite expression:\n\nA visual editor: when you view source from anyone, you can copy a “style” and keep it in your toolbox for later. Applying the style to text is a drag-and-drop operation (although you’re still using the HTML text editor so you see how it happens). Likewise you can save snippets from pages for later, ditto glyphs, ditto little pictures\nTagging, so a user can make a blog by tagging all their posts “blog” (then you can link to all your pages tagged blog from your profile)\nNo credits – this is an environment where copying is okay, so nobody should get care too much about credits. It’s all share-and-share-alike.\nTemplating: users would be encouraged to make a default set of templates for showing off quotes, pictures, word art, links, and chat. It’d be like Tumblr with post-by-post variety.\n\nThere’s Facebook integration for sharing. The hope is that people make little webpages with poems or aphorisms in place of writing status updates, and share those each day instead.\nWhile I was writing this, Panic launched Coda 2, their code, HTML and CSS editor. It’s remarkable for its UI – do watch the tour, and look out for the smart styling menus: it doesn’t just help you type the syntax to specify a colour, it presents you with a colour picker. So yeah, we’d try and license some of the Coda technology.\nInstagram for webpages\nThis is Instagram meets GeoCities meets Diet Coda meets Twitter art meets About.me meets Tumblr meets social scrapbooking.\nWe’ll know we’re doing it right when half of the pages are ugly.\nMoney: Initially we’ll find revenue from brands because people follow the brands they like.\nThe long-term plan is that this service invents, popularises and owns a new media type, in the same way that Twitter “owns” 140 character updates and Instagram “owns” square photos. You end up with a generation of people highly literate in HTML authorship and this new media type, and they associate this literacy - this superpower - with this particular service.\nA year down the road we’ll add form inputs, a super simple programming language for back-end processing only (not mixed with the HTML), and a custom micropayments widget. This is possible because it’s a controlled viewing/authoring system. Bingo, we have an economy. I’m sure we can think of something to do with that.\n",
    link: "/home/2012/05/22/ze_frank_on_ugly",
  },
  {
    title: "Facebook should make a camera",
    date: "14.32, Tuesday 3 Jul 2012",
    content:
      "Companies I would start if only I had the time, #3 in a series (previously, previously):\nI would make a Facebook Camera for the explicit purpose of getting acquired by Facebook.\nFacebook have announced they’re going mobile first. They need to: half Facebook’s traffic comes from mobile rather than PC, but mobile traffic does not currently directly generate any meaningful revenue.\nThere are lots of rumours about Facebook working on a phone.\nThey shouldn’t make a phone. They should make a camera.\nFeatures the Facebook Camera should have\nThe Facebook Camera should be a better pocket camera, with native Facebook and re-imagined for sharing, plus core communications functionality. It should have wifi and optionally 3G.\nThe camera is a “second device” which lives alongside the phone and doesn’t compete with it. This sidesteps Facebook around the highly competitive (and increasingly locked-in) space of iPhone and Android, and avoids the need to launch with a full app store.\nFacebook are interested in camera apps (they have two: their own, and Instagram). They should make the hardware.\nA better pocket camera:\n\nBetter photos than the iPhone, i.e. a proper lens and sensor\nInstagram filters, and tilt shift. Of course!\nImages and short video.\nFace detection for identity, blinks, and smiles.\n\nThe viewfinder screen should be front-facing, on the same face of the camera as the lens.\nSocial photos aren’t like what I’ll call “posterity” photos. They’re not portraits and landscapes. Social photos include the photographer in the picture – you hold the camera out, and point it back at you and your friends. Or you point it at the view behind you and include yourself in the frame, to prove you’re there. A front-facing viewfinder would be perfect for this, and it would also make the physical product visually distinctive when shown in adverts and magazines (“self-evident” product design is essential for marketing).\nNative sharing:\n\nFace detection for auto-tagging of your friends, driven by Facebook’s recent acquisition of face.com, the facial recognition technology firm.\nLike Instagram, invisible upload and share. Make it seamless, and remove the save to memory card, upload to computer, upload to Facebook, tag and share dance.\nComments and notifications of comments, plus a dedicated share button.\nBrowsing of your own and your friend’s photostreams (I can’t count the number of times people have shown me photos from one of their friends’ Facebook albums, as the easiest way to illustrate a conversation).\n\nSharing happens in real life too. One usage of digital cameras I saw - before the iPhone came along - was that a few photos would be kept, undeleted, on the memory card, usually of cats, kids and significant others. These photos are for showing off.\nThere should be a dedicated “photo wallet” Facebook album, and the front-facing screen should be used for a dedicated showing off function.\nA “core communications” device:\nAlthough I see the Facebook Camera as a second device, alongside the phone, this networked device should support all core communications:\n\nEmail, chat, and text. Note that Facebook Messages supports all three of these, and also that group chat is the killer feature that RIM used to get BlackBerry out of its business niche and into the hands of teens (Apple attacked BlackBerry’s group chat, BBM, with its iMessage app).\nMaps, to find and meet friends, with venue information and events (possibly joined to a basic calendar, for events and birthdays only).\nAwesome Web browser, capable of running iPhone-optimised mobile sites.\nFacebook social games.\nCloud sync for photos, address book, and so on, for easy on-boarding. This is Facebook itself.\n\nGiven this list, I suspect the Facebook Camera would undermine many of the reasons to carry a full-featured app phone.\nMusic isn’t required. Wearing your headphones is anti-social when you’re hanging out with your friends.\nIf you want the killer feature… Facebook should build on Facebook Chat to support video, and make this camera a video chat device. Hangouts (easy, social video chat) is the stand-out amazing feature in Google+, and Facebook should be looking to compete.\nProduct design:\nThe Facebook Camera should have accessible product design which is cool without being weird (the Nokia Lumia does this well), mass market without being tacky (the Kindle does this well), and distinctive without being bizarre (think of the original iPod). It’s got to look like a camera crossed with an iPod Touch with your friends inside.\nReasons Facebook should make a mobile device\nIt makes sense to make hardware, because physical products are high engagement.\nFacebook’s model (as I understand it) is to record every single action every person takes, with metadata of time, place, and location in the social graph. This substrate, and the tools to manipulate it, has a good chance of being the underlying foundation of whatever it is comes after the Web. The Web started as a document repository, it’s all about nouns. Facebook has the potential to be as big, but all about verbs. The “social network” aspect of Facebook is part of its bootstrap: the way Facebook gets into the position that it’s natural that all verbs run through it. The next step in the bootstrap, to move down into the foundations, is that Facebook will become a platform for other social networks. Instagram is the first major one.\nAny drop in engagement in the social network (for example what happened to Digg or MySpace) risks this entire future.\nAs a defensive play, a mobile device is essential. Facebook’s mobile usage is increasing, but they can’t make any money out of ads on mobile. So they’re in a desparate double bind: So long as Facebook on mobile is popular but not commercially useful, it’s good for mobile operators and OS providers because it boosts service usage, but it’s bad for Facebook because it cannabalises desktop usage.\nBut when their mobile service is popular and becomes commercially viable, the mobile operators and OS providers become conflicted gatekeepers who will either undermine the ad experience or get a piece of it themselves by undermining Facebook as a whole. We’re seeing signs of this already. Half of the mobile market is owned by Android, made by Google, who also make Google+, which means Android will threaten Facebook.\nThe way to escape this trap is for Facebook to make a mobile device.\nReasons Facebook shouldn’t make a phone\nThe phone market is really, really contested, and really, really hard. Phones are the centrepiece of Apple, the most valuable and most inventive company on the planet. Phones are the focus of Google, the Web’s most inventive company, and a fierce and increasingly motivated competitor. Both Apple and Google have been working hard on lock-in for one or more OS generations. Phones are the one of the points of both attack and defence from the previous generation’s largest technology firm, Microsoft. Phones are where one of the largest technology companies there is - Samsung - can just about keep up. Phones are the rocks on which the biggest of the big technology players have come unstuck: Nokia and RIM.\nTo have a phone now, you need the phone, a sufficiently incredible offer to get customers to break with phones they love (most of those people are in 18-24 month contracts), a whole app and developer ecosystem, hardware manufacturing and distribution, access to the network, access to a media content system, access to a physical media playback system, and to be butressed by a multi-device ecosystem like tablets or music players.\nFacebook could enter this market, sure, but why bet the business on winning in such a competitive space?\nHere’s the thing: You don’t need to make a phone to make it in mobile.\nReasons Facebook should make a camera\nFive years ago, the iPhone was released into a world of desktop PCs and bulky laptops. Laptops were never truly mobile devices, and the iPhone (and Android) made a lot of sense in that world, over the previous generation of smartphones from Nokia and RIM. “App phones” were more like mini computers.\nThe product landscape has changed. The iPad is phenomonally successful, and other tablets look pretty neat too. The trend with laptops is towards ultrabooks, where the MacBook Air is setting the pace – the Air is almost instant on, super light, and has an incredible battery life. It’s way more mobile than any previous laptop. Alongside these product shifts, the cloud has emerged as the home of data. When I lost my laptop recently, configuring a new laptop was as simple as signing into iTunes, Dropbox, and GMail.\nIn this world of iPads and (hopefully) upcoming tablets, does the bells-and-whistles approach of iPhone and Android make as much sense? I don’t think so. I think a new, simple category of pocket devices opens up. It’s not going to be another music device, those have vacated the pocket. It might be a gaming device, but the iPhone has grabbed that niche. \nBut it could be a camera.\nA camera that also dealt with core communications (email, chat, maps, Facebook) would  meet some of the same needs as a phone without competing with phones directly.\nCameras are both highly personal and highly popular, like music players were when Apple launched the iPod. That’s a good place to be. It’s full of love.\nAnd cameras fit right in with Facebook’s position at the world biggest online photo service (in 2010, Facebook had 2.5 billion photos uploaded every month), just as the iPod fit with Apple’s position in the music sector with iTunes.\nLast, the camera sector is ripe for re-invention and new features.\nThe bottom end of the market has been softened up: the iPhone has replaced the compact camera as most people’s camera of choice. But it doesn’t take great photos, and it’s okay but not particularly good at letting you share and socialise around photos. So the iPhone has not protected its position as a compact. And although the former compact sector has been adding features like crazy - smile detection, wifi uploads - none of the device manufactures really get software or social networks.\nOn the high end, the professional cameras have turned into excellent prosumer models – which is neat, but they’re definitely not social: they’re portrait and landscape cameras. You can see a few manufacturers attempting to innovate: Nokia have their 41 megapixel camera, Polaroid have launched a digital camera, Sony have their compact DSCL, there’s Lytro and their lightfield camera, and Samsung have actually launched cameras with front-facing screens, etc. But nothing has traction.\nEvidence Facebook is working on something mobile, maybe even what I’m suggesting\nFacebook is breaking up their mobile app into lots of different apps for particular functions, which is what I’d expect if they were going to launch their own device: they’d want Facebook features to be top-level features on whatever that new device was, and creating them in HTML (the language of the Web) on iPhones means they can re-use these apps still in HTML on whatever their hypothetical new device is.\nThey obviously care about cameras: the single app that doesn’t parallel a feature on the Web is a dedicated camera app. And then there’s Instagram, which is Facebook’s second camera app.\nHow I’d make this business work\nIf I was Facebook, I’d be getting ready for a hypothetical future device by preparing all my functionality to make the jump. Currently Facebook are breaking up their single iPhone app into lots of little microapps. Makes sense. Then I’d talk to Sony for the manufacturing.\nBut I’m not Facebook. So I’d either do a start-up with a hardware accelerator (equity is exchanged for contract manufacturing), or I’d prototype and then pitch to joint venture with Facebook itself.\nThe thing is, the nature of products is changing. It doesn’t make sense to think of cameras as straight-up-and-down products – you have you consider what a camera is as a service, and what it is as media. That is: how does the camera meet the service offering of “taking and sharing photos” as easily and wonderfully as possible? And how does the camera let photos take their place as objects in the communication and entertainment media of social networks? The industrial design is almost secondary.\nAnd traditional product companies - even Apple to an extent - don’t think like this. Web companies do, but so far hardware has been out of their reach. Until Web companies figure out how to do hardware, there’s going to be an interesting gap to fill.\n",
    link: "/home/2012/05/22/instagram_for_webpages",
  },
  {
    title: "",
    date: "19.51, Saturday 1 Jan 2011",
    content:
      "I didn't keep a comprehensive list of books I read in 2010 (as I did in 2007 and 2008), and I didn't make much time for reading. But here are the ones I can remember, in roughly chronological order.\n\n\nThe Red Men, Matthew de Abaitua\nLocas II: Maggie, Hopey & Ray, Jaime Hernandez\nFounders at Work: Stories of Startups' Early Days, Jessica Livingstone\nHow to Build a Career, International University Society (1950)\nThe Medium is the Massage, Marshall McLuhan and Quentin Fiore\nThe Art of the Start, Guy Kawasaki\nMen Without Women, Ernest Hemingway\nAcross the River and into the Trees, Earnest Hemingway\nZendegi, Greg Egan\nPermutation City, Greg Egan\nWhere the Suckers Moon: The Life and Death of an Advertising Campaign, Randall Rothenberg\nFor Whom the Bell Tolls, Ernest Hemingway\nThe New Space Opera, Gardner Dozois and Jonathan Strahan (editors)\nGetting to Plan B: Breaking Through to a Better Business Model, John Mullins and Randy Komisar\nAnathem, Neal Stephenson\nExcession, Iain M. Banks\nThe Star Fraction, Ken MacLeod\nThe Stone Canal, Ken MacLeod\nThe Cassini Division, Ken MacLeod\nThe Sky Road, Ken MacLeod\nImaginary Magnitude, Stanislaw Lem\nThe Life and Times of Martha Washington in the Twenty-First Century, Frank Miller and Dave Gibbons\nThe Unusual Life of Tristan Smith, Peter Carey\nThe Embedding, Ian Watson\nExperiences in Groups, and Other Papers, W. R. Bion\nDictionary of Minor Planet Names, Addendum to Fifth Edition: 2003-2005, Lutz D. Schmadel\nWhat To Do When You Become The Boss: How new managers become successful managers, Bob Selden\nSurface Detail, Iain M. Banks\nBreakfast of Champions, Kurt Vonnegut\nDarwinia, Robert Charles Wilson\nThe Lifecycle of Software Objects, Ted Chiang\nThe Illuminatus! Trilogy, Robert Shea and Robert Anton Wilson\nVurt, Jeff Noon\nPollen, Jeff Noon\nGateway, Frederik Pohl\nBlue Event Horizon, Frederik Pohl\nSurely You're Joking, Mr. Feynman!, Richard Feynman\nHeechee Rendezvous, Frederik Pohl\nGetting to Yes: Negotiating Agreement Without Giving In, Roger Fisher and William L. Ury\n\n\nThere's a bunch of Hemingway in there. At the beginning of 2009, I read a couple of books about how to write: On Writing (Stephen King), and Steering the Craft (Ursula K. Le Guin). Le Guin includes passages that she encourages you to read out loud, so I'd take a hot bath and listen to myself speaking. Reading out loud is surprisingly tough. One or two of the passages were Hemmingway, and the beauty and many overlapping rhythms of his straightforward prose amazed me. So I read Fiesta (aka The Sun Also Rises) which blew me away, and then The Old Man and the Sea, which didn't so much. Then I rationed out several of his other novels and stories over 2010.\n\n\nMen Without Women is rare: stories about men as men, not exploring the human condition, but the male condition: pride, legacy, obligation, competition, camaraderie, the inability to connect. Deep masculine preoccupations.\n\n\nAnyway, Across the River and into the Trees and For Whom the Bell Tolls are two of the best books I've read, ever ever ever. So very real, deeply touching, frank. I don't know how to say this, but I don't want to read each word but eat it, savour it and consume it and never let it out. Across the River is heartstoppingly, achingly beautiful and mournful, every letter and every dot of it, and I swear on my life that I truly have to stop breathing after every chapter for a week until I'm able to digest it and hold it inside me.\n\n\nI read a bunch of business books too. Business occupies a lot of mind right now because I'd like for the studio to achieve our lofty ambitions profitably and happily. So I think about how to do that, and read about it too, and it's good to see how other people approach marketing, or appraisals, or pitch presentations. I'd recommend pretty much all of the ones in the list (and one from 2009 too: The Pixar Touch: the Making of a Company, David Price). Getting to Yes is the best. I'm terrible at negotiation, even the first few pages of the book made me feel sick through nervous tension by association. But the book takes the sting out of it with a common-sense approach, so that's cool.\n\n\nThere's a lot of sci-fi. I use it to wind down, and to think. Anathem is a delight, so convincing, the weaving into reality of a whole world and a whole new physics (just as Illuminatus is I suppose). And you should check out Golem XIV, the novella at the end of Lem's Imaginary Magnitude. It's about two massive artificial intelligences, straddling the singularity, and how their concerns are not human concerns. Lem, as he showed in his collection The Cyberiad, is the Jean-Baptiste Lamarck of revealing and taxonomising and understanding this brand new kingdom of life, the non-human artificial intelligences.\n\n\nFnord.\n\n\nThe highlight of 2010 was Experiences in Groups (W. R. Bion). I made a piece of software called Glancing back in 2003 (read the conference presentation and more notes). It was simple desktop software with a glanceable interface, allowing non-verbal communication for small groups of close friends. Since then I've been convinced that a better understanding of small groups is key to good design of technology and services (for instance, and again), but research is hard to come by. Group Dynamics (Donselson Forsyth) is decent, but a little structural for my taste. Bion, on the other hand, is hot, spilly and wet.\n\n\nBion's approach to groups is psychiatric in origin, and he develops a theory of the various modes of behaviour groups adopt, and how they interplay. Personally I cross-breed Bion with what little I've picked up from Latour - that you should ascribe agency to non-human actors too - and so I regard products as part of a social group just as much as people, and that throws up interesting questions: when we design products, what modes are they introducing into the group mentality? Will they tip the balance towards a dependency mode, rather than promoting sophisticated creativity?\n\n\nLike all good books, I've found Bion useful in my work, and insightful in my personal and professional lives. I won't say any more right now because I'm sure I'll come back to it.\n\n\nAlso you should read the Red Men, because it's about mirror worlds (whoa) and artificial intelligence and robots, and that's what 2011 is going to be all about.\n\n",
    link: "/home/2012/07/03/facebook_should_make_a_camera",
  },
  {
    title: "",
    date: "18.18, Sunday 2 Jan 2011",
    content:
      "\nTed Chiang makes a neat distinction between science and magic in this interview:\n\n\nScience fiction and fantasy are very closely related genres, and a lot of people say that the genres are so close that there's actually no meaningful distinction to be made between the two. But I think that there does exist an useful distinction to be made between magic and science. One way to look at it is in terms of whether a given phenomenon can be mass-produced. [...] I think magic is an indication that the universe recognizes certain people as individuals, as having special properties as an individual, whereas a story in which turning lead into gold is an industrial process is describing a completely impersonal universe. That type of impersonal universe is how science views the universe; it's how we currently understand our universe to work. The difference between magic and science is at some level a difference between the universe responding to you in a personal way, and the universe being entirely impersonal.\n\n\nChiang's short story collection, Stories of Your Life and Others, is top-notch. The title story is available online: Story of Your Life. It's told by a woman to her daughter, about her life and an alien language that works kinda sideways to time. Definitely put aside a half hour to read this.\n\n",
    link: "/home/2011/01/01/books_read_in_2010",
  },
  {
    title: "",
    date: "17.58, Monday 3 Jan 2011",
    content:
      "\nThere's been a lot about WikiLeaks recently: the leaked diplomatic cables, the discussion of the cables, the discussion of the ethics of releasing the cables, and news about the editor-in-chief Julian Assange and his way with women.\n\n\nBruce Sterling on WikiLeaks and Assange is a must-read: The Blast Shack. Not just because he digs into the sources of power, and not just because he always sees the human in the systemic (the fact Assange is a geek is not separable from the behaviour of his organisation) and vice-versa, but because Sterling's metaphor and language is incisive and heady, and reading it creates a feeling like eating too much monosodium glutamate. Get more of Sterling on his blog.\n\n\nAssange's politics are themselves interesting. Aaron Bady unpacks them in Julian Assange and the Computer Conspiracy: he describes the state as authoritarian, and says that this necessarily produces conspiracy, a network of people who need to operate in secret. Then by attacking the internal information flows of the conspiracy (ie, releasing confidential diplomatic cables), you can provoke the conspiracy to act against itself.\n\n",
    link: "/home/2011/01/02/ted_chiang_makes_a_neat_distinction",
  },
  {
    title: "",
    date: "20.36, Monday 3 Jan 2011",
    content:
      "\nSpeaking of group dynamics (as I did, briefly), the Group dynamics page on Wikipedia has a really good References section that mentions Bion and Forsyth amongst others.\n\n\nAnd on that topic, I didn't remember that Clay Shirky's (now classic) essay A Group Is Its Own Worst Enemy references Bion's ideas so heavily. In particular, he runs through Bion's three patterns that groups enter when avoiding a more sophisticated purpose: sex talk; identification and vilification of external enemies; and religious veneration. (These are archetypes of more complex behaviours that you'll definitely recognise.)\n\n\nSays Shirky: So these are human patterns that have shown up on the Internet, not because of the software, but because it's being used by humans.\n\n\nIn A Group Is, Shirky defines \"social software,\" examines it, and sets out what to design for. This essay is nearly 8 years old and I'd forgotten how detailed and foundational it is.\n\n",
    link: "/home/2011/01/03/theres_been_a_lot",
  },
  {
    title: "",
    date: "14.58, Tuesday 4 Jan 2011",
    content:
      "\nRory Hyde interviewed me last year, after I spoke at Thrilling Wonder Stories, and he's put the result online: Know No Boundaries.\n\n\nI like interviews with people carrying voice recorders. I say things that I don't expect to say, but I also force myself to pause and think how to say it before I speak. And then somebody else turns it into proper English and asks another good question. So I surprise myself. A handful of decent things came out:\n\n\nOn products:\n\n\nI think the idea of products is really important. I have these things I look for in our work; one is hope, I think our things should be hopeful, and not just functional. Another is that it should be beautiful, inventive and mainstream. I think mainstream is important because otherwise you're just affecting a few people. A product is a good gate because you start to ask 'how is this going to be consumed by the market?' We don't have many ways of judging whether something is really good, and money is one of them. And that's kind of what products do.\n\n\nI will say something about why to invent as well. Because you could see our work as experimental, or science-fiction, or futuristic; but I would say - and others in the studio may not agree with me - that our design is essentially a political act. We design 'normative' products, normative being that you design for the world as it should be. Invention is always for the world as it should be, and not for the world you are in. By designing it, it's a bit like the way the Earth attracts the moon, and the moon attracts the Earth just a tiny bit. Design these products and you'll move the world just slightly in that direction.\n\n\nOn Fractional A.I.:\n\n\nAbout 'fractional AI', I reference two things there, one is artificial intelligence as it is seen in movies of the mid twentieth century; human scale or larger intelligences as seen in books by Arthur C. Clarke or Isaac Asimov for instance. But then there's this idea which emerged in the early 1900s of fractional horsepower. Horsepower used to be the thing that we measured factories by, but fractional horsepower says that instead of motors that are as big as buildings, we could have motors that were as big as fists. So we could take the fruits of these factories, make them really really tiny, and put them in our homes. Fractional horsepower enabled genuine improvements in quality of life, through appliances like washing machines, refrigerators and hairdryers. And we had half a million fractional horsepower motors in the US by the 1920s, it was an incredible explosion that made domestic life better.\n\n\nMy belief is that we're going to have the same explosion with artificial intelligence. And we won't see it as was depicted in films as controlling nuclear weapons (War Games), or controlling space ships (2001). Fractional AI means that the tiny things around us will be smarter. And the very first place you see this in a very tiny way is in children's toys. It used to be that children played with Meccano or Lego, now they play The Sims. The Sims is a representation of a world in which everything is intelligent in really tiny ways, and we'll be seeing more of that I think in conventional products. What does an intelligent car look like? It maybe only will be as intelligent as a puppy, so what does that mean?\n\n\nOn the shift from the industrial to the domestic:\n\n\nWe've experienced a shift in the last fifty years, in that the bleeding edge of technology used to be industry, so the objects we got in our homes were the off-cuts of industry; look at computers, or the mobile phone, or the internet; those came from industrial mainframes, or battlefield communications, or decentralised information systems. We've experienced a flip now, the technology we have starts on the desktop, in games consoles, or from texting your mates. That is the bleeding edge of technology, and it is leading the way. And it's quite unsurprising that the world we were trained to be in - the industrial one - was one that's a bit soulless, where you had to follow orders, be a cog in the machine. So maybe we're not quite trained right for the things we're being asked to design now, which start from the domestic sphere. Now that's incredibly exciting, because we get to look at other disciplines for where we should learn our craft, and maybe that's character animators, child psychologists, cartoonists, or architects of intimate domestic spaces instead of office buildings.\n\n\nThanks Rory!\n\n",
    link: "/home/2011/01/03/speaking_of_group_dynamics",
  },
  {
    title: "",
    date: "22.10, Wednesday 5 Jan 2011",
    content:
      "\nKinect-Like Gesture System for iPad to Be Demoed at CES (includes video). The product is Mimesign from Elipticllabs: When interacting with a toy or a gadget, the user shouldn’t have to change her state of mind. Rather than entering a mindset where high precision is required to locate the right button or icon, Mimesign seeks to create a different and more natural bond between the user and the device.\n\n\nIn the future we will interact with all our devices by doing tiny techno dancing at them.\n\n",
    link: "/home/2011/01/04/rory_hyde",
  },
  {
    title: "",
    date: "22.15, Wednesday 5 Jan 2011",
    content:
      "\nProcessing monsters is a collection of little interactive monsters made with Processing, the computer language for easily making images and animations.\n\n\nThe monsters are super cute. The scratchy black and white aesthetic is weirdly alive in this age of smooth gradients and drop-shadows. I like the grit.\n\n",
    link: "/home/2011/01/05/kinect_like_gesture",
  },
  {
    title: "",
    date: "10.33, Thursday 6 Jan 2011",
    content:
      "\nOne year in one image, by Eirik Solheim [thanks Timo]. This is a gorgeous, a time lapse pixel sliced photograph of a forest. It's funny to see how fast the seasons transition. It's like winter, winter, winter, winter, then boom, spring. Then spring is like watching something catch fire. It imperceptibly greens, a raising of temperature, a growing veriditas or orenda that suddenly ignites. I wonder how much this varying rate of change influences my own perception of time passing: January to July 2010 lasted ten centuries, but the second half of the year flashed by in a second.\n\n",
    link: "/home/2011/01/05/processing_monsters",
  },
  {
    title: "",
    date: "15.16, Thursday 6 Jan 2011",
    content:
      "\nThe Year of Practical Thinking, by Giles Turnbull: They say you learn something every day. TIL that every day in 2010, Giles wrote that thing down. Brilliant; funny; read 'em all.\n\n\nSee also: read more wikipedia, random stuff from Wikipedia, approximately daily.\t\n\n",
    link: "/home/2011/01/06/one_year_in_one_image",
  },
  {
    title: "",
    date: "16.19, Thursday 6 Jan 2011",
    content:
      "\nBack in, shit, 1997, three bubbles ago, sixteen years ago, when \"liberal\" had just stopped being a dirty word on its way to being a good word before it was dirty again, I got into computer games for the second time. I'm now on my fifth: the first was the BBC Microcomputer Model B, which I liked at school, and the third through fifth were and are: Animal Crossing on Nintendo; iPhone casual games; Xbox after I got really hung-over last year, after my sister's wedding. I was into a game called Riven which was like walking around a beautiful place of trees and water and cliffs and cable-cars, with atmospheric music and puzzles. You would click around lush, rendered images, with occasional movies. Playing Riven is like PowerPoint meets Alice in Wonderland. It was as great a piece of world-building as I've ever seen in a video game. The sprawling world of Riven has an alternate history and an alternate physics (I'm not kidding: water has bizarre physical properties). You don't so much solve puzzles as wander around looking at the scenery and poking things until you intuitively understand the new world, and then you're not solving puzzles, you're just doing what comes naturally. I would spend time in Riven in the dark with headphones and scotch. In retrospective I could have spent more time with my friends in the college bar that term.\n\n\nAnd now Riven is on iPhone! It's very pretty.\n\n\nOh happy day!\n\n\nI feel old.\n\n",
    link: "/home/2011/01/06/the_year_of_practical_thinking",
  },
  {
    title: "",
    date: "18.24, Friday 7 Jan 2011",
    content:
      "\nThe Road Not Taken, by Robert Frost. I heard this over the Christmas break. (Do me a favour: instead of reading this yourself, have someone read it to you.)\n\n",
    link: "/home/2011/01/06/riven_for_iphone",
  },
  {
    title: "",
    date: "22.39, Friday 7 Jan 2011",
    content:
      "\nFrom The Annals of the Heechee by Frederik Pohl, in which the consciousness of Robinette Broadhead (who has been \"vastened\" to live after death as a machine-stored personality) is asking the simulation of Albert Einstein about his continuity of being: You see 'me' in the sense that you see a waterfall. If you look at the Niagara Falls today, and come back a week later and look at it again, you will think you're seeing the same waterfall. In fact, not one atom of the waterfall is the same. The waterfall exists only because it is constrained to do so by the laws of hydraulics, and surface tension, and Newton's laws as they bear on the fact that one body of water is at a higher elevation than another. ... The water molecules are not Niagara Falls. They are only what Niagara Falls is made of.\n\n\nThe universe is the phenotype of physics.\n\n",
    link: "/home/2011/01/07/the_road_not_taken",
  },
  {
    title: "",
    date: "21.06, Saturday 8 Jan 2011",
    content:
      "\nA review of the best robots of 2010: balance, telepresence (it would be seriously creepy to replace Skype with a squirming robot fetus, but that's the future), robot cars, flying things (sadly nothing as beautiful as the robot air penguins), puzzle solving robot hands, and tree climbers.\n\n",
    link: "/home/2011/01/07/niagara_falls",
  },
  {
    title: "",
    date: "21.20, Saturday 8 Jan 2011",
    content:
      "\nThe AI Revolution is On, by Steven Levy at Wired: The Kiva bots may not seem very smart. They don’t possess anything like human intelligence and certainly couldn’t pass a Turing test. But they represent a new forefront in the field of artificial intelligence. Today’s AI doesn’t try to re-create the brain. Instead, it uses machine learning, massive data sets, sophisticated sensors, and clever algorithms to master discrete tasks. Examples can be found everywhere: The Google global machine uses AI to interpret cryptic human queries. Credit card companies use it to track fraud. Netflix uses it to recommend movies to subscribers. And the financial system uses it to handle billions of trades (with only the occasional meltdown).\n\n\nLevy's point is that old school AI - human-equivalent computer intelligences - has been replaced by a new kind of AI: one that doesn't try to replicate the human mind. Lots of examples in his article.\n\n\nFractional AI\n\n\nI've been calling this \"fractional AI,\" a kind of domesticated, not-very-intelligent artificial intelligence, and you can find it in toys and in the algorithms in the tools that we use everyday. What I find interesting is that it's no longer high-end. Just as, in the early 1900s, the fractional horsepower engine took the power of factories into every home, and led to the washing machine, the hairdryer, the dishwasher -- fractional AI will put intelligence in our everyday products. And what then?\n\n\nI've touched on the topic a couple of times in two very similar talks recently:\n\n\nWhat comes after mobile, video from Mobile Monday Amsterdam\nFractional AI, video from the Do Lectures\n\n\n...but I'm not yet happy with how I'm stating the trend, or its opportunities. I have another talk in a month that I'm going to use for a deeper exploration, and that's the one I'll publish more widely.\n\n",
    link: "/home/2011/01/08/best_robots_of_2010",
  },
  {
    title: "",
    date: "16.12, Sunday 9 Jan 2011",
    content:
      "\nMarcel Mauss on magic: In practice, magic differs from religion in desired outcome. Religion seeks to satisfy moral and metaphysical ends, while magic is a functional art which often seeks to accomplish tangible results. In this respect magic resembles technology and science. Belief in each is diffuse, universal, and removed from the origin of the practice. Yet, the similarity between these social phenomena is limited, as science is based in experimentation and development, while magic is an \"a priori belief.\" Mauss concludes that though magical beliefs and rites are most analogous to religion, magic remains a social phenomenon distinct from religion and science with its own characteristic rules, acts and aims.\n\n\nMauss provides, in A General Theory of Magic, a look and explanation of the rituals, actors, and lines of power (mana) involved, and magic's place as a collective phenomenon. I find myself particularly attracted to the systems of representation: there is a persistent relationship between a murderer and their victim, for example; there is a spooky action-at-a-distance between a flame and a fire; there are laws of similarity and so on.\n\n\nThere seems to be something really human about these magical associations, something that I share. Like: a stolen object carries bad luck. Or: an object dropped into a clean toilet (to be crude about things!) will always be dirty, dirtier even then a piece of food dropped onto an uncleaned kitchen floor. Or, try this: draw a picture of a friend, then burn the paper. It's difficult to do so, the paper has become sacred.\n\n\nThere are words that Mauss has picked up used to talk about these magical qualities and lines of power. Words like mana and orenda. The cultures in which these words are used understand the concepts completely. There are proscribed ways that mana flows and accumulates, the forms it can take, and the ways in which it interacts.\n\n\nMana is as abstract and real as momentum, kinetic energy, and magnetic flux density. These terms from physics aren't important because they let us make predictions about the behaviour of the universe (that's the job of technology), but because they reveal the structure of the universe we inhabit. We observe first and do not judge, and that's science, that's how the deep structure is revealed. Physicists are bloodhounds; Newton's Laws and all the rest are hidden lines of scent. And as with physics, so with magic. Mana is a thing to be observed, felt, not judged -- and then the hidden currents of humans and our place in the universe can be seen. The rich possibility of it all makes me giddy!\n\n",
    link: "/home/2011/01/08/ai_revolution",
  },
  {
    title: "",
    date: "21.39, Monday 10 Jan 2011",
    content:
      "\nI'm currently in the middle of reading Journey into Space by Toby Litt, which is about a generation ship and includes some breathtakingly beautiful descriptions of meteorology and the Lake District.\n\n\nAnd, like a perfect idiot, I went and started reading this review by Ursula Le Guin of the same, and of course, not many paragraphs in, ran into massive spoilers. So I'll go back and read that properly once I've finished the novel.\n\n\nIf you can't go faster that the speed of light and you're going somewhere far away, it's going to take more than a human lifetime to get there. People will have to be born (and die) on the same spaceship. Hence: generation ship. I like generation ships (and there are lots listed at that link). The concept raises some interesting issues: how do you maintain knowledge? Particular social values? Do people get bored? Does the 6th generation still care about landing? Do wars happens; do they care about Earth? Is it all just a metaphor for growing up and getting old?\n\n\nHere are several more generation ship novels.\n\n\nMy favourite is Paradises Lost, a novella in Le Guin's collection Birthday of the World. Early on, she gets across the lack of danger (and variety) on-ship: The smaller-order world revealed here is an austere one. No amoeba oozing along, or graceful paisley-paramecium, or vacuum-cleaning rotifer; no creature larger than bacteria, juddering endlessly under the impacts of molecules.\n\n\nAnd only certain bacteria. No molds, no wild yeasts. No virus (down another order). Nothing that causes disease in human beings or in plants. Nothing but the necessary bacteria, the house-cleaners, the digesters, the makers of dirt -- clean dirt. There is no gangrene in the world, no blood poisoning. No colds in the head, no flu, no measles, no plague, no typhus or typhoid or tuberculosis or AIDS or dengue or cholera or yellow fever or ebola or syphilis or poliomyelitis or leprosy or bilharzia or herpes, no chickenpox, no cold sores, no shingles. No Lyme disease. No ticks. No malaria. No mosquitoes. No fleas or flies, no roaches or spiders, no weevils or worms. Nothing in the world has more or less than two legs. Nothing has wings. Nothing sucks blood. Nothing hides in tiny crevices, waves tendrils, scuttles into shadows, lays eggs, washes its fur, clicks its mandibles, or turns around three times before it lies down with its nose on its tail. Nothing has a tail. Nothing in the world has tentacles or fins or paws or claws. Nothing in the world soars. Nothing swims. Nothing purrs, barks, growls, roars, chitters, trills, or cries repeatedly two notes, a descending fourth, for three months of the year. There are no months of the year. There is no moon. There is no year. There is no sun. Time is divided into lightcycles, darkcycles, and and tendays. Every 365.25 cycles there is a celebration and a number called The Year is changed. This Year is 141. It says so on the schoolroom clock.\n\n\nLovely words!\n\n",
    link: "/home/2011/01/09/a_general_theory_of_magic",
  },
  {
    title: "",
    date: "17.20, Tuesday 11 Jan 2011",
    content:
      "\nThe Experimental Nonlinear Physics Groups (University of Toronto) have made a spiral defect knitting pattern. This is the swirling chaotic pattern that arises with a heat difference across pressurised carbon dioxide. It's pretty when it moves.\n\n\n(Apropos of nothing, a video of a baby monkey riding backwards on a pig.)\n\n",
    link: "/home/2011/01/10/generation_ships",
  },
  {
    title: "",
    date: "17.58, Tuesday 11 Jan 2011",
    content:
      "\nIf someone doesn't think you're hot, the next best thing for them to think is that you're ugly. -- OKCupid (the dating site) did some awesome research into the mathematics of beauty, by looking at hotness ratings and number of messages received. They looked at consensus over cuteness. You get more approaches if some people think you're hot and some people think you're ugly, compared to everyone thinking you're merely cute.\n\n\nThis is the conclusion: We now have mathematical evidence that minimizing your \"flaws\" is the opposite of what you should do. If you're a little chubby, play it up. If you have a big nose, play it up. If you have a weird snaggletooth, play it up: statistically, the guys who don't like it can only help you, and the ones who do like it will be all the more excited.\n\n\nI used to draw the yay/nay/meh triangle when talking about people's reactions to brands. You can choose to be on one side of the triangle. And - my opinion - it's better to be a yay/nay brand than to be a yay/meh one. Yay/nay at least means everyone is passionate. But yay/meh? There's not much you can do with indifference.\n\n",
    link: "/home/2011/01/11/patterns_in_nonlinear_physics",
  },
  {
    title: "",
    date: "13.47, Wednesday 12 Jan 2011",
    content:
      "\nIn the UK, a public performance of hypnotism requires a government permit, as set out in the Hypnotism Act 1952. Which only makes you think: what public fear or media frenzy occurred in 1951 that the then-government leapt in to control mesmerism?\n\n\nUpdate\n\n\nPhil points out the history of hypnotism in the '50s and '60s: As far as the 1950's and 60's went there was only one interest in hypnosis by the general public. That was the practise of hypnosis for entertainment purposes, stage hypnotism. In 1952, the practise of stage hypnosis came under parliamentary scrutiny, in the form of a court case Rains-Bath v Slater. (Waxman 1989)\n\n\nRalph Slater was an American Hypnotist who performed in Brighton in 1948. During this performance, a lady accused Slater of assault and professional negligence. The case allowed for the professional negligence but did not find that an assault occurred. (Singleton, Lord Justice 1952). This incident led to a private member's bill to be passed in parliament. In August 1952, the Hypnotism Act was placed on the statute book. The Act conferred power to any local authority which granted licenses for the regulation of places used for public entertainment, to attach conditions to that license in relation to the demonstration or performance of hypnosis. (HMSO 1952).\n\n\nAnd here's a very pertinent question to the Secretary of State, in Parliament in 1951! (Thanks Chris!)\n\n\nIt's weird to think that hypnotism was so serious and feared - a real power, a potential terrorism - that it had to be regulated. Which (of course) reminds me of the UN Weather Weapon Treaty (1976) which bans military use of 'environmental modification techniques' ... the deliberate manipulation of natural processes--the dynamics, composition or structure of the Earth, including its biota, lithosphere, hydrosphere and atmosphere, or of outer space -- ie, artificial rain, hurricanes and earthquakes. Imagine attacking New York with an artificial earthquake. Or a hyper-thunderstorm. Shiiiit.\n\n\nGeoengineering was quite a topic in the 1970s (Kurt Vonnegut's brother invented the modern process of cloud seeding, dropping silver iodide into the sky to produce rain), and there was a fear that there would be an arms-race as there had been with atomic weapons. So: a treaty to ban military geoengineering. And, I'm guessing, given no military investment, that's why we didn't get the spin-off benefits in farming and domestic use. Who knows what 35 years of investment in geoengineering would have got us! Tabletop volcanos! Genetically modified tomatoes that create their own microclimate! Super-local sunny days to always have blue sky for picnics! Pocket clouds! And instead, we got the internet. If I sound disappointed it's because I am.\n\n",
    link: "/home/2011/01/11/mathematics_of_beauty",
  },
  {
    title: "",
    date: "15.39, Wednesday 12 Jan 2011",
    content:
      "\nFor those who enjoy such things, you can now be notified on Twitter whenever there's a new post on this blog: follow @intrcnnctd.\n\n",
    link: "/home/2011/01/12/hypnotism_act",
  },
  {
    title: "",
    date: "17.16, Wednesday 12 Jan 2011",
    content:
      "\nBack in 2003, Mike Kuniavsky gave a talk called The Coming Age of Magic in which he speculated about how to design for ubicomp.\n\n\nUbicomp? Ubicomp is ubiquitous computing, and it's the quick way of talking about what happens when computers are so small and so cheap that we put them in all kinds of products and environments. Like toys, and toilets, and clothing, and desks and buildings. Why? Because it can be handy and fun. In 2003 this was future. In 2011 it's everyday (just flick through a copy of the Argos catalogue), or at least getting that way. I mean everything from iPhones to digital photo frames to the Magic Wand TV remote control (swish zap) to Zhu Zhu Hamsters (artificially intelligent!).\n\n\nMike talked about animism and enchanted objects, which is where we interact with things like they have lives of their own. It's the difference between a screwdriver (a tool) and a puppy (a fuzzy autonomous being). Once products start behaving in ways that aren't totally predictable, maybe we need to start designing them to show off their magic.\n\n\nAlong the way he cited some research that stuck in my head: Folk Biology and the Anthropology of Science: Cognitive Universals and Cultural Particulars (S. Atran, 1998). Mike summarises, Most world cultures classify all entities into one of four general classifications. ... Humans; nonhuman animals; plants; nonliving things.\n\n\nIt's a lovely little insight. And it's interesting because it happens across a bunch of cultures! The paper puts it pithily: Such taxonomies are not as arbitrary in structure and content, nor as variable across cultures, as the assembly of entities into cosmologies, materials or social groups. These structures are routine products of our 'habits of mind,' which may be in part naturally selected to grasp relevant and recurrent 'habits of the world.'\n\n\nAtran goes on to look at this folk biology in some detail. (\"Folk\" is the prefix given to pre-theoretic understanding of a bunch of different disciplines. For instance, folk physics says that we believe, like Aristotle, that objects fly through the air then drop suddenly when thrown, like Coyote charging off a cliff then falling only as he realises where he is, rather than falling with the smooth parabola that actually occurs in ballistics, and you can observe this innate belief when studying the reactions of babies. There is also folk psychology, which I don't know much about, and more.)\n\n\nIt turns out we treat plants and animals somewhat specially: we're really good at classifying and grouping them, and - as humans - we tend to all do it roughly the same way. This grouping ability doesn't carry across to things that aren't animals or plants. There's a neat bit of evidence for this that made me laugh: comparing constellations in the cosmologies of Ancient China, Greece and the Aztec Empire shows little commonality. By contrast, herbals like the Ancient Chinese ERH YA, Theophrastus's Peri Puton Istorias, and the Aztec Badianus Codex, share important features, such as the classification of generic species into tree and herb life forms.\n\n\nAnyway, my question is this: as humans, we'll treat animals and not-animals differently. There are qualities of animals we'd be surprised to see in not-animals, like autonomous behaviour and memory, and maybe we're more inclined to learn from animals or treat them ethically? So how do we distinguish between the two? Would it be enough to put a smiley face on a doll? Or would it need to be a doll that said random things? Or a doll that wasn't random but reacted to you in some way?\n\n\nHow much spirit of life is enough spirit of life to make the difference?\n\n",
    link: "/home/2011/01/12/intrcnnctd",
  },
  {
    title: "",
    date: "12.50, Thursday 13 Jan 2011",
    content:
      "\nDan Hill's firsthand report of the Brisbane flood weaves a personal story with excursions into history and politics. His vignettes are plainly told. A wonderful piece of journalism, easy to read, and something that's brought me closer to these Australian floods (from halfway around the planet) than anything else. Worth devoting your lunch hour to. (And it reminds me of nothing so much as John McPhee's Annals of the Former World, of which you can read an excerpt here, a telling of ancient geology via road-trips and stories.)\n\n\nAlso: a gallery of photos of the Australian flooding. It seems to me not so much a flood as a tiny but universal shift, as if the world declared a new reality where the water table is now here, thank you very much, a new matter of fact.\n\n",
    link: "/home/2011/01/12/animals_and_not_animals",
  },
  {
    title: "",
    date: "13.35, Thursday 13 Jan 2011",
    content:
      "\nAutom is a robot weight-loss coach: Autom has a short conversation with you every day to help you keep track of your eating and exercise quickly and simply. She provides feedback, advice, and encouragement to keep you motivated.\n\n\nLet's be blunt. It's a touchscreen interface to answer multiple choice questions about whether you've exercised or not, and for how long, and it adapts day by day to encourage you to lose weight. Only the screen is in the belly of a tiny robot with robot speech, and massive blue eyes which blink and wink slightly too slowly.\n\n\nIt's remarkable the difference the face makes. If Autom were an iPhone app, it would have to be like filling in a little form every day. But because it's a little robot, there's license for the interface to be conversational. It can ask you questions in a different order, request you to return the next day (and you'll feel bad if you don't!). A conversational interface can make suggestions where a conventional one can't.\n\n\n(Healthcare's an interesting space. GlowCaps are medicine bottle tops that light up and play a tune when it's time to take your pills. Because they're connected to the internet, they can join up to larger services: you can have a cash incentive to complete your prescription, or work to achieve challenges in a game, or just an email to a family member if you forget. The market is insurance companies, not pill-takers. They'll pay for it because it's in their interest to keep you healthy. Autom and GlowCaps are \"ubicomp\" - ubiquitous computing - without being computing. They're helpful coaches first, and only secondarily technology/robots/magically connected devices.)\n\n",
    link: "/home/2011/01/13/flood",
  },
  {
    title: "",
    date: "14.46, Friday 14 Jan 2011",
    content:
      "\nVideo visualisations of DNA, at the molecular level. See: DNA coiling into chromosomes, DNA replication, transcription into RNA, the reading of RNA instructions to assemble amino acid building blocks into a protein. Decently explained. I get a buzzy sense of vertigo to see how we go from the information of the genetic code all the way to proteins. (Proteins are the building blocks of life. They're transformers and logical signal processors: they react chemicals to make other chemicals, and can be switched on and off. So in that sense they're super smart transistors, networking together to make an information processing system that also channels flows of matter and energy. And proteins are also mechanical. They can provide rigidity, and actuation in muscles. It's as if the metal surface of your computer was made the same stuff as the silicon chip, and it could ripple itself to move around your desk.)\n\n",
    link: "/home/2011/01/13/autom",
  },
  {
    title: "",
    date: "17.33, Friday 14 Jan 2011",
    content:
      "\nI've got the latest Google iPhone app. Using it, I took a photo of a Sudoku puzzle. Google recognised the puzzle. I tapped again, and it gave me the solution. See a video here.\n\n\nThe first time I saw a phone solve Sudoko was an app called Sudoko Grab which uses a artificial neural network. Wha? Given a picture of the puzzle, the app turns it into black and white and finds the grid (computer vision) then overlays the identified numbers over the live video feed (augmented reality). Then, to solve the puzzle, it uses a toy model of how the brain works (this is the artificial neural network bit). Just a simple one - it only needs to do some maths - but it figures out what numbers should go where so they all obey the rules of the game. A toy model of the brain (the artificial neural network bit) is used to identify the numbers, and the puzzle is solved with yer more regular code. (Thanks Christian N for the correction!)\n\n\nThese's some hard math going on here. Cutting edge technology interests me only so-so when it's in high-end military tech. And then a little bit more when it shows up in games and toys (games and toys are automatically incentivised to pursue new shit, so they're good signals). But it gets super interesting when it's used for trivial things, but it means that it has become a commodity that large numbers of people can deploy, and that everyday platforms are powerful enough to run it. The interesting thing about Sudoku Grab is that the app is about puzzle solving, not showing off the algorithms, and that the iPhone - a regular, everyday device, widely deployed (ahem, in a certain social milieu) - is capable enough to do it. Hard math for trivial things.\n\n",
    link: "/home/2011/01/14/dna_visualisations",
  },
  {
    title: "",
    date: "18.30, Friday 14 Jan 2011",
    content:
      "\nThe last time I wrote on my blog with any kind of regularity was early 2008. January 2008 was pretty good. I had an easy fluidity.\n\n\nI've tried to write since. It's not come. I was finding myself over-thinking my words. They'd seem to me try-hard poetic, and I prefer to write the way I speak. Or I didn't have anything to say. Anything I said was obvious. Or I'd over-explain. Everything I tried to say, I'd step back and back and back, and suddenly I'd have written a wall of backstory without getting to any kind of point. Mainly, I was scared of being boring.\n\n\nI've not been writing anywhere else much. I've kept a few notes, written a few letters to myself as ways to structure strategy or life decisions, and I don't believe I've written many emails of any substance. I've also not been reading much, or browsing much new on the web. These things are possibly connected.\n\n\nSo far in 2011, I've written consecutively for 14 days. That's the most I've done for three years. What happened? I'm trying to not care about being boring.\n\n\nFor me, writing seems to be a muscle. Without doing it regularly, I feel I've lost my ability to express cogently complex ideas in interesting ways.\n\n\nAnd, because I haven't been regularly talking about the ideas that interest me, I've not given myself the time to reduce down those ideas into pithy, understandable statements.\n\n\nWriting seems to be associated with my sense of pattern recognition. I'm missing the structures of abstraction it gives me, and the room for wiggly play I get while I do it.\n\n\nSo I'm trying to start writing regularly again. It's frustrating and a bloody pain. I feel incapable of expressing what I mean to say. There's no glitter to my words, and I have to force them out. I can see everything that's wrong with what I write. I don't like the structure, but improving it doesn't come naturally because I don't know what to do. I can't figure out how to vary the sentence length or increase variety and rhythm without it sounding like I'm doing rubbish teenage spoken word poetry. There are no insights. I can't start or end things. I don't even sound like me. I'm boring. Okay, fine, do it anyway.\n\n",
    link: "/home/2011/01/14/sudoku_solver",
  },
  {
    title: "",
    date: "18.46, Saturday 15 Jan 2011",
    content:
      "\nRoll up your sleeves and do the following: starting at the main door and moving clockwise, clap strongly into each corner of your house. Clap from the lowest level to as high as you can reach to the ceiling. You will feel a huge difference in the quality of energy as the sound of clapping will be different depending on the accumulated energy. Be sure not to omit any corners in your house, and be sure to clap as much as necessary; some house corners will require more time. (This is a technique called space clearing.)\n\n\nCity\n\n\nThe Situationists adopted the technique of the dérive, to drift through the city without a goal and notice the way in which certain areas, streets, or buildings resonate with states of mind, inclinations, and desires, and to seek out reasons for movement other than those for which an environment was designed.\n\n\nI used to spend my lunch breaks in London taking constrained walks following simple algorithms: first right, first left, repeat. (Or: second left, second left, first right, repeat.) I found myself on familiar roads, turning down side-streets I'd never noticed before. Thinking about why, I found that the architecture of the city, when I stood at a particular spot or walked in a particular way, would bend my attention towards some places and away from others. All it takes is a gentle curve to the right and a busy junction at the end, and the street in shadow to my left is unobserved and never taken. Every day. And then the habit is formed, and so, to me, it's as if the side-street never existed. And if everyone who walks down the street has the same experience, then the side-street is ignored and the main street is bustling and new shops open, and so positive feedback occurs that locks the city into this form. The psychogeography reinforces itself.\n\n\nConstrained walks and the dérive both reveal the city's psychogeography, and force the city to give up more of itself. It's funny to find, right on my doorstep, the streets I didn't know that I didn't know, the ones I'd got the unknown habit of avoiding. The city grows.\n\n\nHome\n\n\nSpace clearing makes visible and disrupts the psychogeography of my home. By standing in far corners, I find new perspectives. I strengthen rarely visited spots in my own mental map. Later, I find myself noticing the corners more. My house looks larger. The changed shape of my rooms encourages me to walk differently about the space. I stand in slightly unfamiliar spots, look at my bookshelves with a new-found unfamiliarity, and this prompts new combinations of titles to come to my attention, and new ideas.\n\n\nI wonder if I could make something to do this for me? Maybe a robot vacuum cleaner programmed to find rarely visited corners and play an attention-grabbing sample, hey, over here, over here.\n\n",
    link: "/home/2011/01/14/being_boring",
  },
  {
    title: "",
    date: "15.33, Sunday 16 Jan 2011",
    content:
      "\n3D facemaking machine for dolls. It prints photographs onto tiny moulded doll faces. As Alice says, Beautifully specific and weird. Brilliant pictures.\n\n\nIt comes from (where else?) Zhejiang, China's captured warp core of industrial capitalism.\n\n\nBruce Sterling, in Taklamakan, has a vision of how products could be not invented but generated. Why not evolve them in virtual worlds then print them out: you could just set up a giant high-powered virtuality with a bunch  of virtual cans  inside it. Then you  make  some can-opener simulations, that are basically blobs of goo. They're simulated goo, but they're also  programs, and those programs trade data and evolve. Whenever they pierce a can, you reward them by  making more copies of them. You're running, like, a million generations of a million different possible can-openers, all day every day, in a simulated space. [...]\n\n\nFinally, you evolve this super weird, super can-opener that no  human being could  ever have invented. Something that no human being  could  even imagine. Because it grew like a mushroom in an entire alternate physics. But you  have all  the specs  for its shape  and proportions, right there in the supercomputer. So to make one inside the real world, you just print it  out like a  photograph. And it works! It runs! See? Instant cheap consumer goods.\n\n\nAnd then you see the 3D doll face machine, and browse Alibaba, where everything's cheap so long as you buy a thousand of it, and think maybe our way of inventing things isn't that different.\n\n",
    link: "/home/2011/01/15/space_clearing",
  },
  {
    title: "",
    date: "16.04, Sunday 16 Jan 2011",
    content:
      "\nVideo of cats in zero gravity. It has the rigour of a scientific experiment. First, take two surprisingly good natured cats and drop them upside-down in regular gravity to prove they land on their feet. Next, remove gravity and observe.\n\n",
    link: "/home/2011/01/16/warp_cores_and_doll_faces",
  },
  {
    title: "",
    date: "17.13, Monday 17 Jan 2011",
    content:
      "\nTen rules for writing fiction, from many authors (and here's part two). I met Gareth W. this morning who recommended these, and he's picked out some favourites. Worth a read! In particular, he pointed me at this one: Write every day. That way, the book you're working on is never out of your awareness for long. It will always be percolating in the back of your mind, growing on its own. No part of writing is as hard as getting the engine warmed up, so try not to let it cool down. Amen.\n\n",
    link: "/home/2011/01/16/cats_in_zero_gravity",
  },
  {
    title: "",
    date: "17.23, Monday 17 Jan 2011",
    content:
      "\nMusic for shuffle mode, by Matthew Irvine Brown: a series of short, interlocking phrases (each formatted as an individual MP3) that can be played in any order and still (sort of) make musical sense. There's a video of it playing in iTunes. Genius. (Disclosure: I have the pleasure of working with Matt Brown.)\n\n",
    link: "/home/2011/01/17/rules_for_writing",
  },
  {
    title: "",
    date: "17.04, Tuesday 18 Jan 2011",
    content:
      "\nKurt Vonnegut's eight rules for writing a short story:\n\n\nUse the time of a total stranger in such a way that he or she will not feel the time was wasted.\nGive the reader at least one character he or she can root for.\nEvery character should want something, even if it is only a glass of water.\nEvery sentence must do one of two things—reveal character or advance the action.\nStart as close to the end as possible.\nBe a Sadist. No matter how sweet and innocent your leading characters, make awful things happen to them—in order that the reader may see what they are made of.\nWrite to please just one person. If you open a window and make love to the world, so to speak, your story will get pneumonia.\nGive your readers as much information as possible as soon as possible. To hell with suspense. Readers should have such complete understanding of what is going on, where and why, that they could finish the story themselves, should cockroaches eat the last few pages.\n\n\n(Found on the A Whole New You blog.)\n\n",
    link: "/home/2011/01/17/music_for_shuffle",
  },
  {
    title: "",
    date: "17.11, Tuesday 18 Jan 2011",
    content:
      "\nEvan Williams' Ten Rules for Web Startups:\n\n\nBe Narrow\nBe Different\nBe Casual\nBe Picky\nBe User-Centric\nBe Self-Centred\nBe Greedy\nBe Tiny\nBe Agile\nBe Balanced\nBe Wary\n\n\nEach is unpacked, read it. The list is from 2005 -- Ev's big success then was Blogger. Since then, his new thing is Twitter. Not bad!\n\n",
    link: "/home/2011/01/18/vonneguts_eight_rules",
  },
  {
    title: "",
    date: "13.35, Wednesday 19 Jan 2011",
    content:
      "\nImagine a robot you can control from 1,000 miles away. You feel like you're there. People  near the robot treat it like it's actually you in the room -- they include you in conversations. You can speak back, see, maybe point at things, and move around. This is a telepresence robot. There are a bunch on the market.\n\n\nQB from Anybots (tagline: Your Personal Avatar) looks like a broom standing up on wheels. At the top of the broom handle is a head which contains: a microphone and speaker; a webcam; a screen (that shows a video feed of you); a laser to point at things. On the back of the head is a web address. You visit that website to drive the robot around, and: The robots eyes go dark to indicate to that you are no longer logged in.\n\n\nAVA from iRobot (tagline: Robots that Make a Difference) has three wheels and is between 3 and 5 feet tall. It has laser and sonar sensors and is semi-autonomous: it can explore a room on its own and build a map. An iPad plugs into the neck and can run different applications. One app might be telepresence. iRobot's first run at telepresence robotics was the ConnectR, (Virtual Visiting Robot) back in 2008. This was a robot vacuum cleaner the shape of a dustbin lid that travelling businessmen would dial into from their hotel rooms to spend quality time with their ignored children. Like this.\n\n\nThe Giraffe video conferencing robot (strap: robots that let you be in two places at once) looks like a mirror on a tall, sturdy, plastic, purple stand with wheels. Uses include remote team management, teletourism and elder care. The Giraffe is not on sale in the USA.\n\n\nTilr from RoboDynamics (no tagline) is a flatscreen monitor held aloft a sleek, red, industrial stand. The wheels are concealed under an angular base with black rubber bumpers. A video camera is slung under the monitor. The robot appears to wear a backpack. It is made for factories. It wants to be Iron Man.\n\n\nFrom InTouch Health (extending your reach) comes the RP-7, an oversized iron built up to human height, with a TV screen and double video camera on top. \"RP\" stands for Remote Presence. In the photo, the screen shows a video portrait of the operator - their entire head - which makes it look rather like a laughing doctor is stuck inside the body of the robot. Surely the screen should show just the face of the person?\n\n\nThere's a quote attributed to Albert Einstein: The wireless telegraph is not difficult to understand. The ordinary telegraph is like a very long cat. You pull the tail in New York, and it meows in Los Angeles. The wireless is the same, only without the cat. I'm unable to describe telepresence robots in such terms.\n\n",
    link: "/home/2011/01/18/ten_rules_for_web_startups",
  },
  {
    title: "",
    date: "15.58, Wednesday 19 Jan 2011",
    content:
      "\nGorgeous mechanism: Japanese tea-serving automaton from the 19th century (photo).\n\n\nThe Digesting Duck was created in France in 1739. It would eat and defecate grain.\n\n\nAround 450 BC, the ancient Greek island of Rhodes was so well known for its robots that the poet Pindar wrote of it:\n\n\nThe animated figures stand\nAdorning every public street\nAnd seem to breathe in stone, or\nmove their marble feet.\n\n",
    link: "/home/2011/01/19/telepresence_robots",
  },
  {
    title: "",
    date: "14.50, Friday 21 Jan 2011",
    content:
      "\nFrom this list of 6 Tiny Things That Have Mind-Blowing Global Impacts I discover that every living thing in the ocean combines to move enough water to stir things up as much as the moon and wind. More info at this article: Jellyfish Are the Dark Energy of the Oceans. Basic story goes like this: scientists were trying to figure out where ripples and movements of the ocean come from. The moon is an obvious one, as is the wind. And they assumed that all the movements of fish and krill and whatnot would cancel out. But no -- the effects of all these tiny living things add up to about the same as the pull of gravity of the one great big moon. That's a lovely metaphor for something, I'm sure.\n\n\nAnother good fact: most of the ocean - excepting the top 300 feet or so - is so placid that a couple hand-held kitchen mixers could stir a cubic mile of it.\n\n",
    link: "/home/2011/01/19/ancient_robots",
  },
  {
    title: "",
    date: "17.22, Friday 21 Jan 2011",
    content:
      "\nBruce Sterling's essay The Last Viridian Note is only partly the final message from a design movement -- although it is that: the Viridian movement is an approach to sustainability that eschews the hair shirt and belt-tightening. Viridian is bright green environmentalism. Sustainability through technology and design. No, the Last Viridian is a manifesto for a way of living.\n\n\nSterling identifies four categories of products to allow into your life:\n\n\nBeautiful things. Beautiful things he says are important. They should be on display, he says. He says this: Your pride in these things should enhance your life, your sense of taste and perhaps your social standing.\nEmotionally important things. Sterling says there are sentimental keepsakes that you want to pass to your grandchildren. Hang onto these.\nTools, devices, and appliances that efficiently perform a useful function. Tools that aren't beautiful or emotionally important should be held to exacting standards. Collecting semi-functional gadgets because they are shiny-shiny is a vice. So: perfectly functional.\nEverything else. Everything else, says Sterling, you should throw away.\n\n\n(I spoke at the Luxury Briefing conference yesterday about the stories that products tell, and about illusionary faces and little robots. Everyone was well dressed and wonderfully friendly. It was interesting to see how closely many \"luxury\" products align with the Last Viridian manifesto. Of course, many don't. My key takeaways: there exist online artificial personality constructs for the purposes of market research; there is a drug in the Amazon that makes you see god, and another that lets you see camouflaged animals, and yet another that heals your mouth; the future of retail is charm. The idea of charm has stuck with me.)\n\n",
    link: "/home/2011/01/21/jellyfish_and_the_moon",
  },
  {
    title: "",
    date: "11.21, Saturday 22 Jan 2011",
    content:
      "\nGoogle appears to have a problem with its search results this month. They're filled with rubbish, and people are beginning to notice. Google acknowledge the problem. What I hadn't realised is that many of the rubbish results come from a small group of companies. Each of these companies is a \"content farm\" -- they identify what people are searching for online (eg, \"winter tires\") and then write articles relevant to that topic (eg, how to put snow tires on your car). Then they sell ads around those articles, and collect money. The biggest of these content farms is Demand Media.\n\n\nThis is the future of journalism!\n\n\nIt's so incredibly responsive. Imagine if Hollywood could turn out emo horror romance films immediately the vampire craze started. Or that, leafing through the Times or the Guardian or the Economist, the newspaper could magically sense your interests and create analysis and reportage dedicated just to you.\n\n\nWhat's lame (of course) is that Demand Media's articles are no good. Here's their low-down on buying snow tires: Invest some time in comparison shopping. Prices for snow tires differ by retailer as well as region. Make use of the Internet, clubs and department stores in addition to tire dealerships. Well no shit. There's technically nothing wrong with what these articles say, but you get a vague sense of wrongness when reading them, like when you're talking to a super articulate idiot and you can't quite put your finger on why they're an idiot. But you know.\n\n\nGoogle's search technology uses 200 signals to rank one result above another. Signals like \"page rank\" (how many important web pages link to this page) and title text are important. But these signals evidently aren't enough to weed out the dross.\n\n\nOne big new Google innovation is Social Search. This is the idea that your friends will have more relevant answers for you than the average of the entire rest of the web. Social is big! It's why Facebook is so exciting.\n\n\nBut there's another signal Google need: taste. The difference between a good article and a sophisticated spam article is no longer anything simple like number of linking, or quality of spelling. It's something weird and human. It's the quality that editors of newspapers have, and that every single person has very strongly in very individual areas, and some of it is personal and some of it is universal.\n\n\nAnd I've no idea how they'll do it, but it's required. Search engines need to acquire a sense of taste.\n\n",
    link: "/home/2011/01/21/last_viridian",
  },
  {
    title: "",
    date: "16.03, Monday 24 Jan 2011",
    content:
      "\nI buy my home glassware from a French company called Duralex. In particular the Duralex Picardie tumblers. The Picardie is a design classic, good for wine, coffee, scotch and water. They remind me of holidays to the south of France, and of primary school. The company has been in and out of receivership these past few years so I have a couple boxes spare I bought on eBay. I'm pleased to hear that Duralex is in safe hands once again. Not mine though. The glass is toughened, the tumblers are supposed to be almost unbreakable. But I smashed one into ten thousand tiny pieces over the weekend. Whoops!\n\n",
    link: "/home/2011/01/22/google_and_taste",
  },
  {
    title: "",
    date: "16.11, Monday 24 Jan 2011",
    content:
      "\nIf a tree falls in the forest and no-one hears it, does it make a sound? Answer: Everyone should agree that in such a case there will be acoustic vibrations but no auditory experience, and be done with it. The facts have all been laid out, after all. Bosh! Done.\n\n",
    link: "/home/2011/01/24/duralex",
  },
  {
    title: "",
    date: "18.15, Tuesday 25 Jan 2011",
    content:
      "\nA few links today.\n\n\nSurface detail, a video of a computer-generated 3D fractal surface, like an animated Romanesque broccoli.\n\n\nA wonderfully targeted shop this, tiny things are cute, an emporium of little lovelies and wily whatnots. For example, tiny things you never knew you wanted.\n\n\nPinoko's collection of inspiring artwork. Generally, sort-of computer generated but existing in a physical way. Butterflies, a toy car racing track with astounding complexity, and heavy metal shovels cut in lace patterns.\n\n\nShoaling and schooling are different things: any group of fish that stay together for social reasons are said to be shoaling, and if, in addition, the group is swimming in the same direction in a coordinated manner, they are said to be schooling. (If the fish are together but not for social reasons, for example because of a common food source, this is called an aggregation.) It's interesting to think of communities of people in these terms, as they move from a gathering, to a group which has its own identity, to a work group with some kind of common purpose. \n\n",
    link: "/home/2011/01/24/zen",
  },
  {
    title: "",
    date: "21.27, Tuesday 25 Jan 2011",
    content:
      "\nTen Obscure Factoids Concerning Albert Einstein: Fond of animals, Einstein kept a housecat which tended to get depressed whenever it rained. Ernst Straus recalls him saying to the melancholy cat: 'I know what's wrong, dear fellow, but I don't know how to turn it off.'\n\n",
    link: "/home/2011/01/25/four_links",
  },
  {
    title: "",
    date: "15.40, Wednesday 26 Jan 2011",
    content:
      "\nTwo provoking ideas:\n\n\nPeople with 1 million dedicated 'can contact them at any time' followers simply weren't around two years ago, -- from this article about Kevin Smith trying a new film distribution technique: he's taking his movie round just one city at a time, and charging $70 a ticket. This feels like a new kind of money. The pub game used to be imagining what you'd do if you had a million bucks. Now it's: imagine if you had a million people who had decided to pay you attention. What the hell do you do with that? Are you a philanthropist, or a social currency entrepreneur; do you invest it for your pension?\n\n\nFish are the only acceptable animal in the world of interior design, but, and here's the awesome bit: I want to see steakhouse- and fried-chicken-joint-variants, where you dine amidst cows ambling up Guggenheim-like ramps and chickens wriggling through Habitrails.\n\n",
    link: "/home/2011/01/25/einstein_and_his_cat",
  },
  {
    title: "",
    date: "16.22, Wednesday 26 Jan 2011",
    content:
      "\nUFO on Tape has become - in seconds - the iPhone game I want to show everyone. It's simple (you're trying to follow a UFO around the sky with a video camera), it's photorealistic (it looks like UFO videos ought to look), it's X Files (the aesthetic is grainy, darting), it's sort-of augmented reality (you have to literally move around to keep the UFO on camera, which makes it totally physically immersive), it never breaks frame and it's simple to understand (like Nick says, it's Steadicam Canabalt). Play it now!\n\n\nAll of which reminds me of Dance Central for my XBox Kinect. Mostly it takes a while for me to reach flow state, that mode what you're immersed and there could be a brass band in the same room and you wouldn't notice. It sometimes happens after a couple hours coding. It takes about 20 minutes reading, and about 5 minutes to get into it when dancing (if the music's right). But the UFO on Tape and the game Dance Central both get me into flow in seconds, like snapping your fingers and bam I'm under. Five minutes later the game ends and I'm like, hey where did the time go. It's maybe something to do with the physical involvement that the Kinect demands, something that I've previously called body thinking. The Kinect is this freaky device that stares into your front room with its infra red eyes, and snares your body into an equivalent virtual representation on the screen. You can't help but tumble into cyberspace. (It helps that my screen is a 4 foot tall projection on the wall.)\n\n\nSwords to ploughshares\n\n\nAnd so I conclude with two thoughts. First, that the Kinect is magical technology. As WW2 and ballistics gave us digital computers, and Cold War decentralisation produced the Internet, the technologies of mass surveillance and anti-terrorism gave us Kinect. It's swords to ploughshares for the 21st century. (src)\n\n\n(Though let's attempt to forget Operation Plowshare from the 1960s, which proposed the re-use of nuclear warheads to create canals and make road-cuts.)\n\n\nAn interface can be a sandy beach, not a cliff\n\n\nSecond, this mode of interacting with technology - call it tangible or augmented reality or whatever you like - is worth watching now because it's low key and everywhere, and only likely to become more significant.\n\n\nIt's talking to your XBox to play a DVD. It's nudging your laptop to skip to the next tune. It's pinch-zooming photos on your iPhone to look closer and rotate them. It's spinning in your chair to point a pretend camera at a pretend UFO. It's a bit like acting. And it's a bit like playing Let's Pretend and being 6 years old. And it's restrained, non-superfluous, sensitive and attentive. And it makes a gentler edge between the world of computers and the world of my front room, less like a cliff between worlds and more like a sandy beach. And it's a lot of fun.\n\n\nBut it's not super high tech or dramatic or woo-woo-flashy like the Minority Report interface. I don't know what to call it. But it's nice and humble and human, and I like it.\n\n",
    link: "/home/2011/01/26/two_provoking_ideas",
  },
  {
    title: "",
    date: "19.15, Thursday 27 Jan 2011",
    content:
      "\n@rstevens says: Dogs with thumbs would make you coffee, cats with thumbs would steal your car.\n\n\nIt feels true! But I wonder. Every so often I think about whether cats are Good or Evil. And last time I gave it much thought, I concluded that they don't have original sin. There is no eternal stain on the soul of cats, and therefore nothing against which they can be measured. They are without Heaven or Hell, they can be neither Good nor Evil (it is only we who interpret their actions one way or the other). Anyway, cats.\n\n",
    link: "/home/2011/01/26/ufo_on_tape",
  },
  {
    title: "",
    date: "15.41, Friday 28 Jan 2011",
    content:
      "\nVintage Future collects wonderful old images of futures that never happened. It's all fins and jets and space. (via)\n\n\nAnd maybe it's something about the treatment or the promise of something wonderful that comes across in both sets of images, but the World of Soviet Groceries (via) gives me a little tingle too.\n\n",
    link: "/home/2011/01/27/cats_with_thumbs",
  },
  {
    title: "",
    date: "16.44, Friday 28 Jan 2011",
    content:
      "\nDomestic robots\n\n\nWikipedia maintains a list of domestic robots. I knew of the Roomba, the autonomous vacuum cleaner, but I hadn't realised quite how many autonomous vacuums there are. I guess vacuum cleaners are the Hello World of robots.\n\n\nThere's a beautiful comparison of their patterns of movement that Russell Davies references in his post on 'designing behaviour': the top shot shows the pattern the Roomba used. The second one down shows the Neato. The Roomba pattern may be more efficient, but it just doesn't look right to a human brain. It's not how a human would do it. The Neato pattern looks more like how I would clean. The Roomba pattern is organic, but an alien organic. The Neato cleaner's pattern is rectilinear.\n\n\nRussell continues: That's going to be a thing - not just designing efficient, effective behaviour - but designing behaviour that's emotionally satisfying to the owner and appropriate to the character of the object.\n\n\nFurby\n\n\nWikipedia claims that the first successful attempt to produce and sell a domestically-aimed robot was the Furby, launched in 1998. It was a toy - a plush owl with aesthetics that frankly creep me out, now I look back from the safety of this side of the millennium - and it had the illusion of intelligence. Get this:\n\n\n\tFurby has sensors for day and night, tummy tickles, back rubs, noises, and motion. No buttons. To wake Furby up, you pick it up. Also Furbys can move to express emotion with their faces, and a little with their bodies. But, HELPFUL TIP: Furby is a state-of-the-art electro-mechanical robotic toy. The mechanical sound you hear when Furby moves is normal.\n\tFurby speaks a special language called Furbish: For example, when I wake up, often I’ll say Da a-loh u-tye which means Big light up. This is how a Furby says Good Morning! But as Furby grows up (there are four stages of development), English words and phrases come in. There's a simple kind of reinforcement learning: if you pet a Furby while it says a new phrase, it will say that phrase more often. Ditto tricks. Furby learns!\n\tFurbys communicate with other Furbys (via an infrared port located between the eyes). Put several together and they'll dance and chatter.\n\n\nFurby was crazy popular. (1.8 million units in 1998, 14m in 1999; 40m over the first 3 years.)\n\n\nThere's so much going on here. Furby's language of interaction is human and physical (light and movement). It responds to the environment. It develops. It learns and can be taught. It communicates with humans and its own kind. It doesn't do anything of these things in a hugely sophisticated way, but it does everything just enough and it never, never breaks frame.\n\n\nThere's a checklist of the bare minimum you need to make something feel sentient, even if it's just in a fractional way, puppy-smart, and that checklist may have been discovered by Furby.\n\n\nThere's something that happens to your relationship with an object once that threshold is crossed, and that's why we use the word robots instead of saying products or objects.\n\n\n(A short thought experiment: a kettle product that doesn't boil properly needs to be replaced. A kettle robot that doesn't boil properly will piss you off, or will need to be made redundant, or otherwise elicit an emotional reaction.)\n\n\nRobots aren't merely artifacts that move. They're the fourth kingdom of nature.\n\n\nThe several kingdoms of nature\n\n\nHere, by the way, is my personal list of kingdoms of nature:\n\n\nRocks. Rocks are slow life. When Ursula Le Guin mused on the language of ants, penguins and plants in her (beautiful) short story The Author of the Acacia Seeds, she speculated about how rocks would talk: the first geolinguist, who, ignoring the delicate, transient lyrics of the lichen, will read beneath it the still less communicative, still more passive, wholly atemporal, cold, volcanic poetry of the rocks: each one a word spoken, how long ago, by the earth itself, in the immense solitude, the immenser community, of space.\n\n\nBy rocks I mean all kinds of matter, from clay to stars. And I don't entirely mean that stellar nebulae are sentient but I do mean there's a universe of interacting, unfolding things that can be understood only on their own terms -- like all of these kingdoms I have in my list. The rules of this kingdom we call physics.\n\n\nOrganic life! DNA-based, RNA-based, carbon based. Plants and animals and lichen. This is a kingdom of stuff which is able to control probability: the metabolic pathways are highways of catalysed, otherwise-unlikely chemical reactions. And it is able to alternate between the two worlds of information and matter, from protein machines encoded in the letters of DNA, to the fizzing chemical mushy flesh that the protein machines build.\n\n\nThe third kingdom is corporations. The philosopher Manual DeLanda, in A New Philosophy of Society, diagrams societies at multiple levels: social networks, organisations and governments, cities and nations. His book is a zoo of these inhuman macro buckyballs. Such massive animals have flows of money, power, and people instead of blood and nerves. In Platform for Change, Stafford Beer outlined the intrinsic behaviour of corporations: that they have a desire to continue their existence, and this dominates their response to stimuli. At the very smallest, cellular level, organisations are small groups of people, and their actions are dominated by group psychology -- at a national and planetary scale, economics. But cities and corporations cannot be understood in the same terms as dumb matter or organic life, so that's why they're the third of my kingdoms of nature.\n\n\nRobots are the fourth kingdom. By robots I mean everything from inorganic information processing to smart matter. But I contend that, because of the following two qualities, it's not possible to understand robots in terms of any of the three other kingdoms:\n\n\nThese are sentiences - simple like Furby or extraordinary artificial intelligences like Joshua in the movie War Games - that we can relate to as animals, but that are not rooted in organic life. They will have different motivations for survival, different priorities, and different psychologies.\nThese are creatures that live natively in cyberspace. Pragmatically, they talk through the Internet. A world made out of information, not atoms, where we don't have regular things like momentum, distance, heaviness, conservation of matter. Other rules apply, rules of which we have only indirect experience.\n\n\nAnd between those two qualities, it means we can't treat robots as artificial people, or magical moving puppets. They are, and will develop, their own new nature, which we - as members of the second kingdom of nature - have to explore, discover and understand fresh, on its own terms.\n\n\nBack to Furby\n\n\nWhich brings me back Furby, the electronic talking owl.\n\n\nFurby has a spin-off called Shelby. Shelby is a grumpy electronic talking clam: When I placed one of my Shelby's in a group with 5 furbys, greetings were exchanged and then, for no reason I could discern, my Shelby started babbling at the furbys, then slammed its shell shut and stayed closed up. As if somehow it had been offended? The furbys ALL stopped talking at once when this happened and remained silent.\n\n\nNattie has a Shelby and tells her story: Shelby doesn't stop talking unless it doesn't get any response for five minutes or something... and ignoring it is agonizing, because it's being cute, and you just feel so awful when it says it loves you, or it tries to tell you a knock knock joke, and you know you can't respond. He'll outright say things like, \"I want to PLAY!\" and you feel like the worst person in the world.\n\n\nNattie named her Roomba 'Ricky.' They had a more loving relationship: When Ricky got stuck in a corner and started furiously backing up and rotating, backing up and rotating, we'd frown and stand watch over him, concerned: \"What are you doing, Ricky?\" When he couldn't get himself unstuck, we'd sigh, pick him up -- \"Oh, calm down\" we'd say when we whirred in the air -- and put him back down, like he was a toddler learning to walk. And when he finished cleaning the room and sang that -- er, emitted that triumphant little chime, his joy was our joy.\n\n\nAnd then of course, one day Ricky will die and then where do you put your feelings? Robots, man. They're nothing but heartbreak. Robots ain't shit.\n\n\nThe question is, as it always is, how do we live together?\n\n\nIt's something to consider. A different bit of the brain activates when we're dealing with sentiences -- or, as it turns out, even when we imagine we're dealing with sentiences (I use sentiences to mean \"intelligence things,\" of varying levels of intelligence, but not necessarily human or animal). It doesn't take much: just a human-like appearance or even, as in The Media Equation (Reeves and Nass, 1996), painting the computer the same colour as its user's t-shirt.\n\n\nWhen we imagine something is intelligent, we simulate its mind inside our own, in order to anticipate it. We begin to think a bit like it, in some small way. We socialise with it, takes cues from it.\n\n\nOn the one hand, this is very clever. Robots don't need their own brains: they can parasite on ours. Be intelligent simply by appearing to be intelligent.\n\n\nOn the other, do we want to relate to robots in this way? Sherry Turkle points out the risks of sociable machines: If convenience and control continue to be the values we hold uppermost, we will be tempted by sociable robots which, just as slot machines attract a gambler, promise us excitement programmed in, just enough to keep us in the game. ... We come to a point where we are so smitten by the idea of conversation with computers that we forget what human conversation about human problems is about: human meaning through the first-hand knowledge of the human life cycle, something of which robots will be forever innocent, no matter how \"expressive\" we make their faces or voices.\n\n\nWe don't get to choose what personality robots have\n\n\nWhen Ben Bashford writes about Emoticomp he talks about objects with behaviours and personalities - robots - but questions how we should design those personalities. What is the watch-word we're after? He proposes politeness. A polite thing... is interested in me; is deferential to me; is forthcoming; has common sense; ... Etc.\n\n\n...which is a great way to approach it. Polite robots would be the best! But I don't think we get to choose. Polite robots would be lovely. But the nature of the fourth kingdom - their equivalent of evolution - is that they reproduce in the sales figures of technology corporations and the womb-factories of China. The testes of robots are the shelves of Toys-R-Us. Humans don't get to choose the personality of robots, the market does.\n\n\nAnd judging by Furby and Shelby, our robots won't be polite but will be needy and paranoia-inducing, resembling helpless infants.\n\n\nThe half-breed children of robots and humans\n\n\nI'll wrap on a final weird-future slippiness between kingdoms two and four, and the story starts with a phenomenon called Hello Little Fella, which is the human habit of recognising illusionary faces in objects and the environment. Here's a favourite.\n\n\nIt's not just faces. There's a widespread habit of believing things having feelings, and, because we're human and because this is the 21st century, there's a community of people who fantasise about having sex with these inanimate things, then write stories about it, and it's called anthropomorfic.\n\n\nAll of which, finally, brings us to an iPhone game in which you have a virtual girlfriend to woo. Each girlfriend comes from a barcode. This is Barcode Kanojo: I'm currently dating a can of Heinz tomato soup in Barcode Kanojo, but it wasn’t my first choice. I wanted Heinz Beanz or a box of Shreddies, but both have already been taken by faster scanners.\n\n\nIt's an offensively brilliant idea. Barcode Kanojo's free iPhone app will scan any product you have knocking around your house and turn it into a delicate anime girl over whom you can obsess, masturbate, and fight. The game in Barcode Kanojo's game comes when another player scans the same bottle of bleach you just scanned ... In a sad parody of real life sexual politics, Kanojos will date only their creator until someone else who scanned the same tin of beans gives them more money and attention. Mostly money. (via)\n\n\nAll hail our weird new robot overlords indeed. Welcome to the fourth kingdom of nature, folks.\n\n",
    link: "/home/2011/01/28/retro_art",
  },
  {
    title: "",
    date: "18.28, Saturday 29 Jan 2011",
    content:
      "\nIn defense of machines, by George Boas: We are first told that though man invented [machines] to be his servants he has become theirs. ... This argument is a gross exaggeration. Man is no more a slave of his machines than he has ever been, or than he is to his body ...\n\n\nWe must each establish a system of values for ourselves or absorb that of our social group, and judge machines by it as we do everything else. There is no other way of evaluating anything.\n\n\n(Found in Visions of Technology, edited by Richard Rhodes.)\n\n",
    link: "/home/2011/01/28/furby_and_the_fourth_kingdom",
  },
  {
    title: "",
    date: "09.13, Tuesday 1 Feb 2011",
    content:
      "\nOn my way into work this morning (a seven minute walk), I saw two contractors painting the yellow lines on the side of the road. I hadn't realised they did it like this: they have a big roll of what looks like yellow ribbon. They cut long strips of ribbon and place it on the road. The ribbon looks like rubberised paint. Then they melt it with a flame torch, and it becomes road marking! Simple straight lines and no spilled paint. Easier all round I guess.\n\n\nAlso on my way into work, I let someone know their bag was dripping. Sucky for them, but for me it means my good deed for the day is done by 8.30 am, so I can really stick the boot in for the rest of Tuesday. Reading around about good deeds, it turns out that, yes, people who did one good deed were less likely to do another good deed in the near future. They had, quite literally, done their good deed for the day. -- from this article about good deeds and psychology.\n\n\nThere are a few nice tit-bits in the piece, including the anecdote that people having lunch after church tend to abuse the waitstaff and tip poorly, and this observation on the finding that one good deed means you needn't bother about another:\n\n\nThis meshes nicely with a self-signalling conception of morality. If part of the point of behaving morally is to convince yourself that you're a good person, then once you're convinced, behaving morally loses a lot of its value.\n\n\nSelf-signalling! I wonder how much behaviour is driven by the satisfaction you get when your observations of self match up with your desired positive traits. Yes, I suppose I am the kind of person that gives to charity. Yes, I suppose I am the kind of person that keeps a tidy house. Etc. And how dangerous that feedback loop is when you're reinforcing negative behaviour. Sigh, I suppose I am the kind of person who has no willpower.\n\n\nWhich, in a really prosaic way, makes me think about keeping a to-do list. Saying you'll do something, and then doing it! That's a good feeling alright.\n\n",
    link: "/home/2011/01/29/evaluating_machines",
  },
  {
    title: "",
    date: "18.46, Tuesday 1 Feb 2011",
    content:
      "\nTsukumogami ('artifact spirit') are a type of Japanese spirit. ... tsukumogami originate from items or artifacts that have reached their 100th birthday and thus become alive and aware. Any object of this age, from swords to toys, can become a tsukumogami. Tsukumogami are considered spirits and supernatural beings, as opposed to enchanted items. (Thanks Tom!)\n\n\nAlso #1: Tsukumogami vary radically in appearance, depending on the type of item they originated from as well as the condition that item was in. Some, such as tsukumogami originating from paper lanterns or broken sandals, can have tears which become eyes and sharp teeth, thus giving a horrifying visage. Others, such as worn prayer beads or teacups, may merely manifest faces and appendages, giving a warm and friendly appearance. Related to this, see the dream parade from the movie Paprika (more). The mailbox and the refrigerator will lead the way! The happy and mundane world will vent their anger.\n\n\nAlso #2: Though by and large tsukumogami are harmless and at most tend to play occasional pranks on unsuspecting victims, as shown in the Otogizōshi they do have the capacity for anger and will band together to take revenge on those who are wasteful or throw them away thoughtlessly. Related to this, the Japanese water sprite Kappa is a humanoid turtle that lives in ponds and rivers, and leaps out to harass passers-by. If you are accosted by one, remember that kappas are extremely polite, and insist that you bow before you fight. On bowing, the kappa's brain (which is kept in an indentation on the top of the head, and is made of water) will slosh out, and they will be defeated.\n\n\nI mention this because the kappa is also a prankster: Their pranks range from the relatively innocent, such as loudly passing gas or looking up women's kimonos, to the more troublesome, such as drowning people and animals, kidnapping children, and raping women. \"Troublesome\" is certainly the word for it.\n\n\n(Why does the kappa abduct people? For this: the purpose of eating their livers or their shirikodama, a mythical ball inside the anus.\n\n\nRemember that. Shirikodama. It will be useful one day.)\n\n\nAlso #3: It is said that modern items cannot become tsukumogami; the reason for this is that tsukumogami are said to be repelled by electricity. Additionally, few modern items are used for the 100-year-span that it takes for an artifact to gain a soul.\n\n\nRelated to this, see the New Delhi Monkey Man. In 2001, a monkey man terrorised India. It was stronger than a man; it had metal claws; it was covered in thick hair with buttons on its chest. But the monkey man was scared by water, light and electricity. Appearance of the monkey caused mob terror... but turned the (at the time, rationed) electricity back on would calm the neighbourhood. Monkey man was a modern, physical manifestation of the desires of the group mentality.\n\n\nI wonder what the lack of souls for modern objects signifies, to the group mentality.\n\n\nI finish on Sokushinbutsu, the rare Japanese practice of self-mummification by Buddhist monks: For 1,000 days (a little less than three years) the priests would eat a special diet consisting only of nuts and seeds, while taking part in a regimen of rigorous physical activity that stripped them of their body fat. They then ate only bark and roots for another thousand days and began drinking a poisonous tea made from the sap of the Urushi tree, normally used to lacquer bowls.\n\n\nAnd then: This caused vomiting and a rapid loss of bodily fluids, and most importantly, it made the body too poisonous to be eaten by maggots. Finally, a self-mummifying monk would lock himself in a stone tomb barely larger than his body, where he would not move from the lotus position. His only connection to the outside world was an air tube and a bell. Each day he rang a bell to let those outside know that he was still alive. When the bell stopped ringing, the tube was removed and the tomb sealed. After the tomb was sealed, the other monks in the temple would wait another 1,000 days, and open the tomb to see if the mummification was successful.\n\n\nSometimes this would work. Usually, not.\n\n\nDong!\n\n",
    link: "/home/2011/02/01/yellow_lines_and_self_signalling",
  },
  {
    title: "",
    date: "20.08, Tuesday 1 Feb 2011",
    content:
      "\nBooks read January 2011, by date finished:\n\n\nNymphomation, Jeff Noon (3rd)\nThe Annals of the Heechee, Frederik Pohl (8th)\nJourney into Space, Toby Litt (11th)\nSmart Things: Ubiquitous Computing User Experience Design, Mike Kuniavsky (22nd)\n\n\nThe first third of Journey into Space is wonderful and poetic.\n\n\nKuniavsky's Smart Things is a comprehensive, bullet-proof, accessible guide and compendium of approaches to the entire ubiquitous computing sector. If you're designing smart things, it's a must-read. If you're theorising in the area, it's a must-cite.\n\n",
    link: "/home/2011/02/01/100_year_artifact_spirits",
  },
  {
    title: "",
    date: "13.09, Thursday 3 Feb 2011",
    content:
      "\nOkay, this is wrestling, and then two of the dudes (who are dressed as Egyptian gods?) hypnotise the other two dudes, by doing a weird snake move, and make them breakdance themselves into being knocked out. That is the most illegal thing I've seen in the history of wrestling! (Thank you Schulze, that is utterly remarkable.)\n\n",
    link: "/home/2011/02/01/books_read_in_jan_2011",
  },
  {
    title: "",
    date: "10.27, Friday 4 Feb 2011",
    content:
      "\nHere are some Japanese fighting robots on television (remote controlled; two arms and two legs each). My favourite is the one with the balloon for the head and his special move.\n\n\n(I found that via this essay On the Potential for Branded Robots, which is a big question! I wonder about the ethics. Robots don't have sentient feelings (yet), so it's fine to treat them as slaves. But they appear to be sentient, and humans interact with them as if they are sentient. So what does it do to us as people, if we accustom ourselves to not having to care about other sentient beings? Is that okay? Might we start treating the non-robot sentiences around us callously too -- the human working in the train station, the human making us coffee, the human in the call-centre, the cat we meet on the street? Should we, for our own sakes, make robots tender and fragile so that we don't accidentally train ourselves into being heartless?)\n\n",
    link: "/home/2011/02/03/hypnosis_wrestling",
  },
  {
    title: "",
    date: "12.13, Friday 4 Feb 2011",
    content:
      "\nNeal Stephenson writes about why space rockets won't go away in Space Stasis: What the strange persistence of rockets can teach us about innovation.\n\n\nHis point: using rockets to get into space works decently enough. But it's expensive, limited, and it's never going to get better. Rockets are an example of lock-in. There is no shortage of alternative, innovative ideas for how to get into space - ones that might have much more promising futures - but we'll never see them because there are too many factors that prevent change.\n\n\nOne fascinating contributor to lock-in is insurance. Start from the fact that satellites are super expensive to build, and generate lots of money once in orbit. A satellite is a big investment with a big pay-off! Which means you want insurance... Rockets of the old school aren't perfect—they have their share of failures—but they have enough of a track record that it's possible to buy launch insurance. The importance of this fact cannot be overestimated. Every space entrepreneur who dreams of constructing a better mousetrap sooner or later crunches into the sickening realization that, even if the new invention achieved perfect technical success, it would fail as a business proposition simply because the customers wouldn't be able to purchase launch insurance.\n\n\nAnother factor is regulation. It's hard to get the permits to fly a rocket over other countries' cities. You could operate in a country with looser regulation... but then you wouldn't get access to the expertise and the technology to build the rocket in the first place.\n\n\nIt's weird, says Stephensen, that we even have rockets in the first place. They grew out of a bizarre battle that arose in rare circumstances. But what investment that war caused: Richard Rhodes estimates the cost of the nuclear weapons and missile programs at $4 trillion in the United States and the USSR each.\n\n\nGreat article.\n\n",
    link: "/home/2011/02/04/japanese_fighting_robots",
  },
  {
    title: "",
    date: "13.37, Friday 4 Feb 2011",
    content:
      "\nThere's a lovely collection of numbers from Jeff Dean at Google, about how long common computer processor and network operations take. Data on the same chip takes, at its quickest, only 0.5ns to look up (half a billionth of one second). Data in computer memory takes 100ns (200 times as long) to pull onto the chip. Data in the same building takes a million times as long; data across the Atlantic will take 300 millions times as long. Here are the numbers.\n\n\nWhat makes this more human is this comparison, which reveals a little bit about computer time: your equivalent to a computer looking up data from a chip is remembering a fact from your own brain. Your equivalent to a computer looking up data from a disk is fetching that fact from Pluto. Computers live in a world of commonplace interactions not the size of a house, like us, but the Solar System. On their own terms, they are long, long lived, and vast.\n\n",
    link: "/home/2011/02/04/why_rockets_wont_go_away",
  },
  {
    title: "",
    date: "20.40, Sunday 6 Feb 2011",
    content:
      "\nWhen we make the breakthrough that means humans can speak with dolphins, what should our first 20 questions be? Here's a list. It's an interesting thought experiment!\n\n\nThe United Nations Office for Outer Space Affairs is the forum for developing principles on the use of space. I wonder if they have a list of first questions in the event that an alien species turn up.\n\n\n(Related: a huge list of questions to ask the girl you're dating to promote a deeper level of disclosure.)\n\n\nI'd like to be able to speak to pets and farm animals. Dolphin and squid might be our aquatic doppels, but it's a fascinating and terrifying idea that we might have to develop a sociology of cattle or sheep, and negotiate with them (and ourselves) their lives, comfort, and death. To be fair, we probably already communicate with them enough for that particular conversation.\n\n",
    link: "/home/2011/02/04/computer_time",
  },
  {
    title: "",
    date: "12.32, Monday 7 Feb 2011",
    content:
      "\nTheo Janson makes massive mechanical animal skeletons that walk, with dozens of legs, along the beach, powered by the wind: Strandbeest (there are videos).\n\n\nOn a smaller scale, here is a video of a hamster/mechanical walker hybrid. A tabletop walking skeleton, with a hectic hamster racing in a ball as a mechanical battery.\n\n\n(Related: a dog in a man suit.)\n\n\nI like the idea of exoskeletons or hybrids. The parasite Dicrocoelium dendriticum has the ability to control the habits of ants to make them climb blades of grass (to be eaten by sheep).\n\n\nThere's a virtual reality system called CAVE. It's a room you go into, and video is projected on the walls, the ceiling, and floor. Computers monitor how you move, and so the video can respond to your movements. You could feel like you were standing in a ballroom, or a forest, or a computer-generated architecture. I heard about this application of it: the CAVE would monitor your head rotation, but move the video twice as much. So if you turned your head 10 degrees to the right, it would whizz the video round 20 degrees. If you looked directly right, over your shoulder, it would turn the video so it was as if you were looking directly behind you. Apparently you get used to it really fast.\n\n\nSo I wonder: could you make a helmet like this? It would have cameras on top, and you would look at a screen inside, but it would use gyroscopes to move the cameras twice as fast as you moved your head, so it would feel like you could turn your head all the way round. Owl helmet!\n\n\nSuperpowers for animals\n\n\nHorseshoes give the superpower of walking on hard surfaces to horses. But what if you gave neutral buoyancy in air to sheep, or the magical sensation of magnetic north to cattle, or gecko shoes to dogs? What if dogs could stick to walls and ceilings?\n\n\n(Naturally related: Chris Woebken's series of prosthetics to give animal abilities to humans. Lovely photos. Lovely objects.)\n\n",
    link: "/home/2011/02/06/questions_for_dolphins",
  },
  {
    title: "",
    date: "18.10, Monday 7 Feb 2011",
    content:
      "\nI've been exploring themes around artificial intelligence, telepresence robots, and Furbys recently. In a sort of fun, figuring-it-out, what do we need to know, how to design for it and live in it kind of way. I'm enjoying myself.\n\n\nAnd... I'm giving an evening lecture about it all on Wednesday 16th February, at 7pm. The title:\n\n\nBotworld: Designing for the new world of domestic A.I.\n\n\nIt's at the Royal Institution in London.\n\n\nYou should come! But you'll need to book. Read more about it.\n\n",
    link: "/home/2011/02/07/hamster_exoskeleton",
  },
  {
    title: "",
    date: "20.07, Tuesday 8 Feb 2011",
    content:
      "\nThere's a neat video demo of a 3D road generator. The user clicks on a landscape where they want the road to run, and the system generates architecturally sound roads, road cuts, tunnels, bridges, and suspension bridges. I assume there's some kind of civil engineering rules built-in. While you watch, the user shows how hills and valleys can be introduced and automatically compensated for.\n\n\nA road runs from A to B. You choose the A and the B. The system follows engineering rules to make it work.\n\n\nThen there are city generators. I don't know what rules this is following. Not engineering constraints, but the observed laws of cities: that high residential land value tends to happen where there are good views; that high commercial land value tends to have tall buildings; that cities are organised into hubs with major roads for spokes; and so on. (I'm guessing on the rules.)\n\n\nAnother city generator: Suicidator City Generator screenshots.\n\n\nAlso, in a funny kind of way, this retro city which is also a mobile phone interface: the panel is a living, breathing portal to help the user fully interact with their mobile phone handset. As a user pans through the cityscape, all the different elements link to the functionality of the user’s phone. Text messages appear playfully on billboards, calendar events arrive by train, a passing airplane shows your call history and much more.\n\n\nI don't know what appeals to me. Some combination of these three things: autonomous simulation; toy to fiddle with; randomness but realness.\n\n\nVirtual pets and virtual people\n\n\nI get a similar feeling with virtual pets - that is, toys like Tamagotchi - and computer games like Animal Crossing (a virtual life in a little town with artificially intelligence animal friends) and Little Computer People (a virtual fellow who lives in a house inside your computer, from 1985).\n\n\nIt's that feeling again -- the feeling that there's another world just beyond the looking glass, something alive, but simple enough that it doesn't feel entirely independent from me. What is this, some kind of mix of separateness but ownership, a god complex?\n\n\nA couple of appearances in fiction: Superman's miniature city-in-a-bottle, Kandor; Philip K. Dick's hobby build-an-earth-in-a-bubble Worldcraft.\n\n\nThe space trading computing game Elite would simulate entire galaxies... and on computers from 1982, what's more. Get this: Their first idea had been to furnish the machine with the details of (say) 10 solar systems they'd lovingly handcrafted in advance: elegant stars, advantageously distributed, orbited by nice planets in salubrious locations, inhabited by contrasting aliens with varied governments and interesting commodities to trade. But it quickly became clear that the wodge of data involved was going to make an impossible demand on memory. ... What if, they asked themselves, they got the machine to invent the map as well? To avoid the storage problem, it would need to build solar systems on the fly; that is, it would have to come up with names and distances and dimensions right when they were called for, that instant, rather than pulling them out of memory. Yet these unstored, instantaneous inventions also needed to be solid and dependable. Stars and planets needed to stay where they were put. And so that's what they did.\n\n\nSim social network\n\n\nWhich brings me to something I once wanted: an artificial, generated social network, where I am the only real person. I wrote about it in 2006, in a story called They follow each other on the wind. A device called MyPeopleGalaxy. Here's a bit of it:\n\n\nIt is a shiny blue pocket-sized $20 blogging device with artificial intelligence and a whopping big hard drive. All I did was start blogging into it. It took my words, and the clever stuff the fella did wove those words, and manipulated them and whatever else, and over time it learned English. And after a while more, it started simulating more bloggers who moved in one by one by one. Fake ones. 2 million bloggers in my pocket.\n\n\nA little bit more: In MyPeopleGalaxy, your blog posts are shaken into words and recombine into comments to your posts, and other blogs are inspired by yours. You can see echoes of your vocabulary and ideas in the blogs that surround you. This is the best of artificial prose pioneered by the spam email people, taken and used to generate fake journal posts for 14 year-olds. Good grief. I couldn’t put it down.\n\n\nAnd you know what? I still want it. Simulations of people, all with individual names, personalities and interests, tens of thousands of them, all generated. It shouldn't be too hard: there's already a record of each of us in some marketing database somewhere. Just roll the dice on that and invent people who don't exist.\n\n\nAnd all of them with their own Facebook pages, and their own status updates, and their own friends lists, and their own blogs. All in their own big social network. That shouldn't be too hard either -- I can barely tell the difference between generated spam and real websites and email nowadays, so the technology must exist.\n\n\nAnd I want them all making friends, falling out, going through the whole lifecycle of relationships, copying jokes and links off each other, getting obsessed with virals, watching YouTube, reading the news, all the rest, all of it, every single bit of it. All generated, all artificial, a colossal baroque folly. I reckon it'd be pretty easy to do.\n\n\nAn ant farm that I can watch. A soap opera with 10,000 computer-controlled software actors.\n\n\nAnd I want to have a profile right there too, on Fakebook, the only real person of the lot of them. Single player socialising. It's horrible, I get that, a kind of pornography but of friendship and attachment. But I reckon it'd be fun to play, crazy addictive, and I have a hunch there would be some interesting spin-off applications. Toy mirror worlds.\n\n",
    link: "/home/2011/02/07/speaking_about_robots_feb_16",
  },
  {
    title: "",
    date: "12.07, Wednesday 9 Feb 2011",
    content:
      "\nMy favourite alternate Twitter interface is isparade.jp. Put in your Twitter name, and your friends come marching across the screen as stick figures with square heads, speaking their statuses, like this, all parading after a bigger figure which is me. Also, there's music. Super weird, super awesome. (Thanks Matt!)\n\n\n(By the way, if you're on Twitter: follow @genmon for my personal updates, and follow @intrcnnctd to get notified when there's an update to this blog.)\n\n",
    link: "/home/2011/02/08/sim_social_network",
  },
  {
    title: "",
    date: "12.20, Wednesday 9 Feb 2011",
    content:
      '\nEdward Mordrake was reportedly the 19th century heir to an English peerage. He supposedly had an extra face on the back of his head, which could neither eat nor speak, although it could laugh or cry. Edward begged doctors to have his "demon head" removed, because, supposedly, it whispered horrible things to him at night, but no doctor would attempt it. He committed suicide at the age of 23. (Via read more wikipedia.)\n\n',
    link: "/home/2011/02/09/twitter_parade",
  },
  {
    title: "",
    date: "18.37, Friday 11 Feb 2011",
    content:
      "\nMy Life Portable Console Virtual Life Simulator: it's pink, it looks like a rubbish Gameboy, it's an isometric first-person simulation of the life of a teenage girl. You can chat with boys and argue with your dad.\n\n\nAccording to the massive stats crunching of the dating site OKCupid, the best question to ask to figure out whether a girl will sleep with you on the first date is \"Do you like the taste of beer?\" (By best, I mean \"most predictive.\")\n\n\nAnd: No matter their gender or orientation, beer-lovers are 60% more likely to be okay with sleeping with someone they've just met. Sadly, this is the only question with a meaningful correlation for women. For men there are a few others: Q: In a certain light, wouldn't nuclear war be exciting?\n\n\nFinally: videos of waiters who are monkeys wearing doll masks.\n\n",
    link: "/home/2011/02/09/tiny_nasty_extra_face",
  },
  {
    title: "",
    date: "11.26, Tuesday 15 Feb 2011",
    content:
      "\nA reminder: I'm giving a public talk about domestic artificial intelligence, at 7pm tomorrow (Wednesday 16th), at the Royal Institution in London.\n\n\nBotworld: Designing for the new world of domestic A.I.\n\n\nBack in the 1960s, we thought the 21st century was going to be about talking robots, and artificial intelligences we could chat with and play chess with like people. It didn't happen, and we thought the artificial intelligence dream was dead.\n\n\nBut somehow, a different kind of future snuck up on us. One of robot vacuum cleaners, virtual pets that chat amongst themselves, and web search engines so clever that we might-as-well call them intelligent. So we got our robots, and the world is full of them. Not with human intelligence, but with something simpler and different. And not as colleagues, but as pets and toys.\n\n\nMatt looks at life in this Botworld. We'll encounter a zoo of beasts: telepresence robots, big maths, mirror worlds, and fractional A.I. We'll look at signals from the future, and try to figure out where it's going.\n\n\nWe'll look at questions like: what does it mean to relate emotionally to a silicon thing that pretends to be alive? How do we deal with this shift from 'Meccano' to 'The Sims'? And what are the consequences, when it's not just our toys and gadgets that have fractional intelligence... but every product and website?\n\n\nMatt digs into history and sci-fi to find lessons on how to think about and recognise Botworld, how to design for it, and how to live in it.\n\n\nBook your ticket now! (More regular blogging will resume on Thursday.)\n\n",
    link: "/home/2011/02/11/first_dates_and_monkeys",
  },
  {
    title: "",
    date: "15.42, Tuesday 15 Feb 2011",
    content:
      "\nMajesty 2, the Fantasy Kingdom Sim: In the world of Majesty, you are the ruler of the kingdom Ardania. At your service are your loyal and somewhat obnoxious subordinates, who have their own minds about how things should be done. In fact, Majesty is the only game where your heroes decide on their own what should be done and when, leaving you to try to control them through monetary incentives.\n\n\nSee also Godville, available for iPhone, in which your hero collects items, has fights, embarks on quests, advances through levels, and keeps a diary... and you do nothing but watch (and occasionally give encouragement.)\n\n",
    link: "/home/2011/02/15/speaking_tomorrow_in_london",
  },
  {
    title: "",
    date: "18.49, Monday 21 Feb 2011",
    content:
      "\nThe current wave of Arab revolutions reminds me that the series of Colour Revolutions in the Balkans and ex-Soviet states (in the early 2000s) was not an unassisted wave. Rather, it might have been the work of revolution consultants from Belgrade known as the Centre for Non-Violent Resistance (see also the full article).\n\n",
    link: "/home/2011/02/15/games_where_you_dont_do_anything",
  },
  {
    title: "",
    date: "18.48, Wednesday 23 Feb 2011",
    content:
      "\nToday is the anniversary of the final day of the life of Laura Palmer. When I was young, I was crazy for Twin Peaks. Laura Palmer was found dead, wrapped in plastic, on 24 February, 1989. Also: you can read her secret diary.\n\n",
    link: "/home/2011/02/21/revolution_consultants",
  },
  {
    title: "",
    date: "18.08, Thursday 24 Feb 2011",
    content:
      "\nHere is a brilliant isometric map of Hong Kong.\n\n\nA topographic map of Venus.\n\n\nA gallery of the new London 2012 Olympic velodrome. It's vast and modernist, but warm: cathedral caverns and concrete angles, both dull and glossy, with highly textured detail from wood and punched brushed metal. Unafraid of repetition. Oranges, browns, greys and dull blues. Matt Brown at work calls it a New British Modern, and I see that. It's definitely not New York art vinyl or Japanese pop. There are elements of Scandinavian design, but just as much of British municipality and of functional authenticity. Barbican but 21st century. Anyway, good pics. There's mileage in this NBM I think.\n\n\nFive emotions invented by the internet, including: The state of being 'installed' at a computer or laptop for an extended period of time without purpose, characterized by a blurry, formless anxiety undercut with something hard like desperation, and The sense of fatigue and disconnect one experiences after emitting a massive stream of content only to hit some kind of ‘wall’ and forget and/or abandon the entire thing. Yeah. It's funny because it's true.\n\n\nI wonder: I can fatigue very particular muscles. Climbing stairs, those muscles get tired. Weights, etc. It's possible to have very tired biceps but find it easy to run. Tiredness is a bodily located phenomenon. And so: is it possible to fatigue bits of my mind? Does my super-ego get worn out from filtering my behaviour? Can I run out of the neurotransmitter responsible for saying three syllable words? Or whatever. Does my hypothalamus get out of puff? Does my visual cortex get worn out identifying horizontal edges?\n\n\nToday my linearity gland is pooped.\n\n\nFirst watch Such Great Heights, the Postal Service. Pretty electronica. And now Ben Fold's live percussion version. Is lovely.\n\n",
    link: "/home/2011/02/23/laura_palmer",
  },
  {
    title: "",
    date: "14.14, Saturday 26 Feb 2011",
    content:
      "\nThis morning I've been watching the cricket world cup, playing the lovely, simple iPhone game Tiny Wings, doing some basic scenario planning for work, and a little tidying, during which I ran across some UK coins designed by Matthew Dent, which I must have collected when they were released.\n\n\nWork is brilliantly odd and fun (and busy with a trajectory to becoming crazy busy) at the moment. Lots of pots on the bubble. Just today, on the BERG blog, there's a sneak peek at the art of SVK, the comic we're working on with Warren Ellis and Matt Brooker. I should make a list of everything that contributes to my general feeling of living in the Absurd.\n\n\nBut not right now, as I'm off to an exhibition about Isotype.\n\n\nLast thing: blue eyes are blue not because of pigment, but because of the Tyndall effect: light scattering by particles in a colloid or particles in a fine suspension. ... It is similar to Rayleigh scattering, in that the intensity of the scattered light depends on the fourth power of the frequency, so blue light is scattered much more strongly than red light. An example in everyday life is the blue colour sometimes seen in the smoke emitted by motorcycles. Rayleigh scattering has slightly different physics, but is the reason the sky is blue. Neat.\n\n",
    link: "/home/2011/02/24/not_linear_today",
  },
  {
    title: "",
    date: "15.36, Monday 28 Feb 2011",
    content:
      "\nRentAFriend.com has Friends from around the world available for hire. Rent a Friend to attend a social event, wedding, or party with you. Hire someone to introduce you to new people, or someone to go to a movie or a restaurant with. Hire a Friend to show you around an unfamiliar town, teach you a new skill or hobby, or just someone for companionship. You can view all of the profiles & photos on RentAFriend.com right now for free!\n\n\nI have a hunch that television is really bad for us. When we can speak about social psychology with the same degree of accuracy as we can liver function, we'll find that TV has been poisoning the social body. Future generations will look back and say, What?? You used to train your children into believing the environment and other people were non-responsive to their moods and expressions? Are you insane?\n\n\nFacebook is better. At least it's not passive. Although I'd like to test this. Let's find two remote Canadian towns, cut off physically from the rest of the world by winter. One we'll accidentally-on-purpose break television. The other we'll accidentally-on-purpose break the web. Then: observe.\n\n\nThere's something dangerous, still, I'm sure, with Facebook. I don't know what it does to a person to have social interaction without proximity of bodies. It's weird to do talking without smelling. I can feel my Jacobson's organ shrivelling up like a walnut.\n\n\nFacebook is a technology of disembedding: social relations are no longer confined to the 'local context.' Rather, the location of individuals and the time frame in which they interact has become indefinite. It is hard to say when this began, but the development of a postal service is a good example. With mail, social relations could be conducted across broad geographic areas (no longer limited to the local context) and within indefinite time spans (due to the time lag in mail delivery).\n\n\nMoney is also a technology of disembedding. In barter, the goods to be exchanged need to come together in time and space. With money - the crystalline form of trust - there's no need.\n\n\nDisembedding isn't bad. A community of one hundred people couldn't support - and wouldn't need to support - a cartographer, but a community of a hundred thousand has just the niche for such an abstract role. And I'm glad, because I like maps. Big communities are supported by disembedding.\n\n\nBut now we have a trade-off. Currency to disembed exchange of goods from markets in town squares is, well, handy. Social currency to disembed exchange of friend interactions from the fuggy physical world of smells and touches is... well, handy - in that I get cartographers - but a teeny bit inhuman. Possibly. Facebook (and the like) also means eventually smelling and touching people you'd otherwise have never met. And television gives you things in common with a billion people you'll probably never meet, although you might.\n\n\nI don't have a conclusion. And I'm not planning on renting any friends.\n\n",
    link: "/home/2011/02/26/saturday_rambling",
  },
  {
    title: "",
    date: "17.26, Monday 28 Feb 2011",
    content:
      "\nFits.me (strap: \"Virtual Fitting Room for Online Clothes Retailers\") has a shape-changing robot mannequin hooked up to a webcam. Deets: Customers shopping at a participating site enter their body measurements online (height, chest, arm length, torso, type, and so on), then see photos of a mannequin shaped just like them 'trying on' the item they're eyeing in different sizes and styles.\n\n\nGreat photos here. And also, this quote from the CEO: Now, we have a robot that can be any shape at the push of a button. I wish I had a button like that. WHOA.\n\n\nSuperpowers suddenly seem more of-our-world if they have buttons. What if Mr. Fantastic had to press a button before he stretched? What if Superman had one button to fly, one button to use his heat rays, and another button to fly or use his super speed? Villains would try to press them! He would fumble for them in a rush! What if the Iron Man suit ran on Windows 3.1, and the mouse ball kept sticking? What if Superman lost his user-defined preferences file and his only back-up was at the back of a drawer in the Fortress of Solitude?\n\n",
    link: "/home/2011/02/28/rent_a_friend",
  },
  {
    title: "",
    date: "17.40, Thursday 3 Mar 2011",
    content:
      "\nConviviality:\n\n\nPeople need not only to obtain things, they need above all the freedom to make things among which they can live, to give shape to them according to their own tastes, and to put them to use in caring for and about others. Prisoners in rich countries often have access to more things and services than members of their families, but they have no say in how things are to be made and cannot decide what to do with them. Their punishment consists in being deprived of what I shall call 'conviviality.' They are degraded to the status of mere consumers.\n\n\nI choose the term 'conviviality' to designate the opposite of industrial productivity. I intend it to mean autonomous and creative intercourse among persons, and the intercourse of persons with their environment; and this in contrast with the conditioned response of persons to the demands made upon them by others, and by a man-made environment. I consider conviviality to be individual freedom realized in personal interdependence and, as such, an intrinsic ethical value. I believe that, in any society, as conviviality is reduced below a certain level, no amount of industrial productivity can effectively satisfy the needs it creates among society's members.\n\n\nAnd so: To formulate a theory about a future society both very modern and not dominated by industry, it will be necessary to recognize natural scales and limits. We must come to admit that only within limits can machines take the place of slaves; beyond these limits they lead to a new kind of serfdom. Only within limits can education fit people into a man-made environment: beyond these limits lies the universal schoolhouse, hospital ward, or prison. Only within limits ought politics to be concerned with the distribution of maximum industrial outputs, rather than with equal inputs of either energy or information. Once these limits are recognized, it becomes possible to articulate the triadic relationship between persons, tools, and a new collectivity. Such a society, in which modern technologies serve politically interrelated individuals rather than managers, I will call 'convivial.'\n\n\n-- Tools for Conviviality, Ivan Illich (1972).\n\n",
    link: "/home/2011/02/28/shape_changing_robot",
  },
  {
    title: "",
    date: "18.13, Friday 4 Mar 2011",
    content:
      '\nGoogle\n\n\nOrigin of the name "Google": Sean and Larry were in their office, using the whiteboard, trying to think up a good name - something that related to the indexing of an immense amount of data. Sean verbally suggested the word "googolplex," and Larry responded verbally with the shortened form, "googol" (both words refer to specific large numbers). Sean was seated at his computer terminal, so he executed a search of the Internet domain name registry database to see if the newly suggested name was still available for registration and use. Sean is not an infallible speller, and he made the mistake of searching for the name spelled as "google.com," which he found to be available. Larry liked the name, and within hours he took the step of registering the name "google.com" for himself and Sergey (the domain name registration record dates from September 15, 1997).\n\n\nBaidu\n\n\nBaidu is Google\'s competitor in China, and is the 6th most popular site in the world.\n\n\nOrigin of the name "Baidu": \'Baidu\' was inspired by a poem written more than 800 years ago during the Song Dynasty. The poem compares the search for a retreating beauty amid chaotic glamour with the search for one\'s dream while confronted by life\'s many obstacles. \'...hundreds and thousands of times, for her I searched in chaos, suddenly, I turned by chance, to where the lights were waning, and there she stood.\' Baidu, whose literal meaning is hundreds of times, represents persistent search for the ideal.\n\n\nBeautiful.\n\n\nIncidentally, Baidu\'s city maps in China are all super-cute pixelated 3D cartoons of themselves. Here\'s one place I found: a miniature Eiffel Tower, next to a dense urban city hive. [Huh, my link stopped working.] It\'s like browsing the future dressed up as a children\'s game.\n\n',
    link: "/home/2011/03/03/conviviality",
  },
  {
    title: "",
    date: "16.04, Friday 11 Mar 2011",
    content:
      "\nList of quotes from Ayn Rand.\n\n\nRand developed the philosophy of Objectivism, in which the pursuit of one's individual happiness and productive achievement is the highest moral purpose.\n\n\nOne should not depend on nor sway to others.\n\n\nRand: The question isn't who is going to let me; it's who is going to stop me.\n\n\nAnyway, I've been thinking about an email app built on a principle of Objectivism. At the moment, my email client defaults to doing nothing, and I must intervene to create action (ie, write a reply).\n\n\nBut if I had an Objectivist email app, it would automatically respond to all emails with stock enabling and forceful replies after a period of (say) 15 minutes, and I would have to intervene if I wanted it to not do that.\n\n",
    link: "/home/2011/03/04/google_and_baidu",
  },
  {
    title: "",
    date: "09.07, Tuesday 15 Mar 2011",
    content:
      "\nEvery morning I wake up to continuing news from the Fukushima nuclear plant in Japan, which engineers are fighting to control. The problems - fires, explosions, venting of radioactive gases, a fire in the spent fuel area, the risk of fuel rods melting and releasing highly toxic substances into the environment - are the result of broken cooling systems damaged by a tsunami, itself the result of an earthquake, natural disasters in which large numbers of people died, in highly local but massively multiple tragedies.\n\n\nI write as if you didn't already know, mainly to wrap my own head around what's going on. From the other side of the globe, I really can't grasp what's been happening on the western Pacific Rim these last few months. The floods in Australia, earthquakes in New Zealand and Japan, Japan's continuing crisis. I don't have the imagination, it's a struggle to put myself there.\n\n\nBut Fukushima:\n\n\nThere are a few dozen engineers, and they're fighting, warring really against this problem, this overheating. And there's little or no electricity, and everything they're doing is outside operational parameters. It's become chaotic. I can just about get a little-finger hold on what that's like. They said on the radio this morning (or maybe overnight) that the current attempts to cool the overheating fuel rods are all improvised now. The engineers are using fire engines to pump sea water in through internal sprinklers. It's rumoured that one of the fires started when a fire engine ran out of fuel and could no longer pump. I can almost grasp that, the scrambling, the constant brainstorming and the constant new emergencies. I can't quite get the rest. The danger of death from radioactivity, the hundreds of thousands of people evacuated from the local area. That's the size of the whole city where I went to school!\n\n\nThe nuclear aspect touches old fears. I was born and grew up in the Cold War. I was almost 12 years old in December 1989, at the time of the Malta Summit, when the corner was turned, detente found, and the end of the War declared. I'd had a childhood talking about atom bombs with my friends, and having nightmares about mushroom clouds and fallout. The fiction we read in class was often enough about nuclear apocalypse. A sudden escalation was not off the cards. I remember the first day, in the early 1990s, that I realised that the weight of possibility of nuclear war had lifted. I felt like I could breathe for the first time.\n\n\n1991-2001 were blessed years in the West. The Cold War had ended, and the effects of foreign policy and a callousness to the rest of the world had not yet cross-multiplied with psychopaths and boomeranged into terrorism. There was crazy growth and there were easy recessions. India and China were off the radar, changing slowly, but not the obvious inheritors of global cultural leadership. The West was it.\n\n\nI feel no guilt. That was the most carefree decade I'll have.\n\n\nSo the events in Fukushima touch an old terror for me.\n\n\nThey'll never read this, but I wish the very best of luck to all those fighting to bring the reactors under control. You're in my thoughts.\n\n\nI want to end on something more abstract.\n\n\nMatt Jones and I were talking in the studio yesterday and he mentioned the Holocene -- the geological period lasting from 12,000 years ago, the end of the most recent glacial period, until now. All of recorded human history is within the Holocene. But now, maybe (the story goes), we're in the Anthropocene: the epoch in which human activities that have had a significant global impact on the Earth's ecosystems.\n\n\nIt's the era of human-altered climate and of artificial islands. When archeologists in a million years dig deep down and take a core sample through 2011 AD, they'll look at the thin, white, compressed layer of undecomposed plastic waste and iridium traces - a geological layer 100% due to human civilisation - and they'll point to it and say \"Ah, the Anthropocene,\" before turning it into shimmering jewellery and what-have-you.\n\n\nThe thing we have to realise is that this isn't an era of control. Our attempts to control the world have multiplied so much that they themselves have become part of the system, part of the world, and the entire thing has once again become chaotic, unpredictable, and uncontrollable. We live in a world in which we must constantly adapt, improvise, and take care. We must show it respect (the world is not a resource: it is as big as us); we have to swim through it, not walk over it. Engineering is not only problem solving, and not only a way to manage risk, but an improvisational skill. We're going to need that.\n\n\nIt's all very grim in Fukushima. And I'm really feeling that grimness this morning, apologies for passing it on.\n\n",
    link: "/home/2011/03/11/inbox_hero",
  },
  {
    title: "",
    date: "18.55, Thursday 17 Mar 2011",
    content:
      "\nThe Long Now Foundation was established in 01996 to creatively foster long-term thinking and responsibility in the framework of the next 10,000 years.\n\n\nSticking a zero at the beginning of the year is ace. They're building a clock that'll last those 10,000 years. Two lovely interventions in culture! Yum.\n\n\nThey recently asked on their blog, Peak Science? First they point out a trend, identified by Samuel Arbesman (Harvard Medical School): By measuring the average size of discovered asteroids, mammalian species and chemical elements, he was able to show that, over the last few hundred years, these three very different scientific fields have been obeying the exact same trend: the size of what they discover has been getting smaller.\n\n\nAnd follow it with this speculation: we've basically picked all the low-hanging fruit of scientific discovery -- all Galileo had to do was be the first person to look at Jupiter through a telescope and he discovered four moons. But, we've found all the moons now, and without those easy to reach facts, we’re now forced to pool more effort and resources into learning new things.\n\n\nInteresting! But I disagree.\n\n\nThe kinds of science mentioned are what Deleuze and Guattari call \"royal science\" -- it's the science you get taught at school where the discipline is given capital letters: Physics, Chemistry, Computer Science. It's the science where there are institutions, journals, funding, prizes, PhDs, and a division between those who are Scientists and the rest of society. It's the science you can get a qualification in, and the science you can fail in.\n\n\nIt happens that sciences start their lives somewhat differently -- biology emerged from hobbyist Victorian men and women first collecting, and then taxonomising animals and plants. Electricity was a hobbyist's occupation before it was formalised: the same journal would speak about a lecture, a new patent, an experiment with lightbulbs, and who had been hit by lightning that month. Sciences don't look like sciences to begin with. You can't \"fail\" in collecting examples of finches.\n\n\nSo, my first question: (1) where are the hobbies?\n\n\nOf course, the Large Hadron Collider at CERN, that particle accelerator loop 27 kilometres around, can't be a hobby -- it's too big and too expensive. But it's at the final \"white dwarf\" end  of scientific evolution. It's way past its lively period of heady, explosive growth and illumination. Science goes through stages: first you collect (write down many examples), then you have a period of making taxonomies and hypotheses (a period of crazy invention and fights and predictions), and then you settle on a reductionist model and (a) the science turns into technology (lasers and CD players), and (b) you look for experiments to disrupt the model to start over again (CERN).\n\n\nI simplify. But, y'know.\n\n\nCollecting is easy. But it's not really seen as science (though it's essential). It's a an incidental activity, or a hobby, often by people who are fans of science, or philosophy, or some other similar discipline preoccupied with causality and structure (where it is also accompanied by cataloging and rule-making).\n\n\nSo my second question is (2) where are people collecting?\n\n\nAnswer my two questions, and we'll find new proto-sciences, science nurseries full of low-hanging fruit.\n\n\nAnd here are some examples that pop immediately to mind:\n\n\nPageRank, by Google, their form of analysing the web, is right at the beginning of a new science. As a way of understanding networks, it was ripe for the picking - Page and Brin just had to do it! - and we've still not looked at the higher-level molecules in the structure of the web. Links and pages are the fundamental particles. But imagine if the attention given to string theory was given to networks in the web: what evolving manifolds might we find? What 11-dimensional rules?\nStephen Wolfram's work with cellular automata. Algorithms are not expensive, and don't have to be examined by experts. So many of us could examine simple sets of rules that evolve, and find new interesting creatures in Conway's Game of Life. It's not hard, there's just a lot to territory to explore. So be explorers!\n\"Phenethylamines I Have Known And Loved\" by Shulgin. An exploration of psychedelic compounds. They act so differently. #125: QUALITATIVE COMMENTS: (with 35 mg) There was a vague awareness of something all afternoon, something that might be called a thinness. There is a universe of internal life to catalogue before we can start drawing architectures, that super-complex muddy hinterland between consciousness and wet chemicals.\nMandelbrot and the world of fractals. There are shapes and rules in fractals which are as wide-ranging and fundamental as circles and rectangles. We see the networks of neurons in the brain reflected in the super-filaments of galactic superclusters that braid the known universe, and reflected again in the patterns that emerge at the end of a game of Go. Why are these similar? Can looking inward at one educate us about looking up at another? Perhaps. But we need to collect and taxonomise first, to learn how to describe new shapes. We're maybe 50 years off a breakthrough here, I guess, and Mandelbrot is our Galileo: Clouds are not spheres, mountains are not cones, coastlines are not circles, and bark is not smooth, nor does lightning travel in a straight line.\nSmall group dynamics and psychiatry. The experiments made on subjective experience, the social world, and the brain are easy (there are home brain imaging kits), and depend more on constructing a language for discussion (as Freud did) and data than slicing the brain up into tiny slices. There is a cosmos, a natural philosophy, of subjective experience to be described, and we'll need to make a lot of mistakes and try all kinds of alchemy before we attain the chemistry - or its equivalent - to speak about it, even to the level of literacy we have speaking about, say, modern art.\nKevin Kelly's Computational X -- Computational Medicine, Computational Linguistics, Computational Architecture, and more: Inventing materials, forms, structures that cannot be made with concrete and glass. Generate endless varieties of one form, with ease. There must be a commonality between these areas, if they are tractable to investigation with the same techniques. So how do we describe it? First, we need the stuff to describe. We all have computers. As hobbyists, let's apply computation to everything! Ah, we are doing that. So carry on, and look for abstract bridges and common shapes! It's a proto-science. A proto proto-science.\n\n\nThere are a billion low hanging fruits. We don't recognise these worlds as capital-S Science because they're not what we've been taught to see. Get out your telescope that you don't recognise as a telescope, and you'll see moons and Jupiters that have never before been spied.\n\n",
    link: "/home/2011/03/15/fukushima_and_engineering",
  },
  {
    title: "",
    date: "17.43, Saturday 7 May 2011",
    content:
      "\nBooks read February to April 2011, by date finished:\n\n\nBluebeard, Kurt Vonnegut (4 Feb)\nMy Name is Legion, Roger Zelazny (7 Feb)\nThe Boy Who Would Live Forever, Frederik Pohl (20 Feb)\nGeneration X, Douglas Coupland (12 Mar)\nNeuromancer, William Gibson (24 Mar)\nThe Cybernetic Brain: Sketches of Another Future, Andrew Pickering (7 April)\nAscents of Wonder, David Gerrold (editor) (8 Apr)\nGlasshouse, Charles Stross (9 Apr)\nIn the Bone: the best science fiction of Gordon R Dickson, Gordon R Dickson (15 Apr)\nIncident on Ath: Dumarest Saga 18, E C Tubb (17 Apr)\nThe Explorers, C M Kornbluth (22 Apr)\nTaurus Four, Rena Vale (24 Apr)\nOnly the Paranoid Survive, Andrew S Grove (24 Apr)\nThe Checklist Manifesto, Atul Gawande (30 Apr)\n\n\nIt's rare to find a second-hand bookshop in London with a good cache of science fiction nowadays. People buy up the books and sell them online. But I ran across one, way out of the way, and picked up a half dozen books and collections of short stories from the 1940s-1970s. The short stories are the best: Ascents of Wonders, In the Bone, The Explorers, and The Complete Venus Equilatoral (not on this list as I only finished it today) are all worth picking up. It's weird reading old stories -- some of the ideas were copied so many times they've become bored tropes. But others ideas never made it into the mainstream and are as fresh as the day they were written. And then of course there's the pleasure of the history diving of it all: the 1940s were all engineering-led, the 1970s all psychology. From outer space to inner space.\n\n\nBluebeard is probably my favourite Vonnegut. It's a great story, brilliantly told, and without the familiar Vonnegut tricks of paragraph-by-paragraph cut-up or surreality. So it gets a little deeper inside me I guess. The protagonist is Rabo Karabekian (SPOILERS), one of the founders of the (fictionalised) American modern art movement Abstract Expressionism. Karabekian also appears in Vonnegut's earlier novel Breakfast of Champions, in which he is attacked for the emptiness of his art: Well, we don't think much of your painting. I've seen better pictures done by a five-year old. The painting in question is called The Temptation of Saint Anthony, and is green with a single, solid, vertical line of yellow tape.\n\n\nAnyway, at this moment Vonnegut puts into Karabekian's mouth a defence of this fictional art as fine as I have ever read:\n\n\nI now give you my word of honor that the picture your city owns show everything about life which truly matters, with nothing left out. It is a picture of the awareness of every animals--the 'I am' to which all messages are sent. It is all that is alive in any of us--in a mouse, in a deer, in a cocktail waitress. It is unwavering and pure, no matter what preposterous adventure may befall us. A sacred picture of Saint Antony alone is one vertical, unwavering band of light. If a cockroach were near him, or a cocktail waitress, the picture would show two such bands of light. Our awareness is all that is alive and maybe sacred in any of us. Everything else about us is dead machinery.\n\n\nAmen!\n\n\nLet me finish on The Cybernetic Brain, which is hands down the most remarkable book I have read for months and months. On the face of it, Pickering has written a biography-of-ideas of several key players in cybernetics (specifically British cybernetics) from the 1950s to the 1970s: Grey Walter, Ross Ashby, Gregory Bateson, R. D. Laing, Stafford Beer, and Gordon Pask. And he goes deep. There are sketches of Laing's grand alternative to psychiatry (fully integrated cooperative community houses); Beer's attempts to use the rich ecology of woodland ponds as the brains of factories, hooking sensors up to production lines and pond weed; the influences on Brian Eno and others; electronic circuits for both Walter and Ashby's proto-robot experimental probes into learning machines; more.\n\n\nBut what Pickering really does is put forward that these cyberneticians (in particular, as opposed to American crowd more occupied with control systems) saw \"intelligence\" as something not representational (ie, the brain encodes or contains knowledge) but essentially performative. He opens with Walter's Tortoise, a toy robot that can avoid obstacles, and is attracted by moderate light (and repelled by bright light). A community of Tortoises would have unexpected emergent behaviour. Pickering: The tortoise is our first instantiation of the performative perspective on the brain ... the view of the brain as an 'acting machine' rather than a 'thinking machine.'\n\n\nPickering comes to present cybernetics as holding a view of intelligence as something that only thinks by doing; something that, even when it follows rules, is not unpredictable so much but can only be calculated or predicted by actually doing its thing. It's a wonderfully optimistic, re-humanising, uncontrolled, lively, meaty way of seeing and being, which runs so counter to the statistical, predictable, crowd behaviour, goal directed, success/failure and \"psychohistorical\" perspective we usually take on the world.\n\n\nThis is also intrinsically a view on design, as Pickering says: a distinctly cybernetic notion of design, very different from that more familiar in modern science and engineering. If our usual notion of design entails the formulation of a plan which is then imposed upon matter, the cybernetic approach entailed instead a continuing interaction with materials, human and nonhuman, to explore what might be achieved--what one might call an evolutionary approach to design, that necessarily entailed a degree of respect for the other.\n\n\nThe Cybernetic Brain is academic, large and grainy; it is skittish and the anecdotes flock and tumble. It's terribly easy to read, like a month of late night conversations with a brilliant friend. It is not fair of me to say that it boils down to a single worldview or puts forward just one perspective. But it does pass on the torch of that perspective. It is not a perspective which can be learned from reading papers, only kindled by experiencing experiments vicariously, and above all Pickering's book does just that: it is inspiring. Recommended.\n\n",
    link: "/home/2011/03/17/finding_baby_sciences_and_new_moons",
  },
  {
    title: "",
    date: "17.42, Sunday 3 Jan 2010",
    content:
      "\nWhen Richard Feynman refuses to explain how magnets work he fidgets and bounces and puffs in a way I recognise from a friend with long-term mental illness, who does this when he gets excited and gets really into explaining a topic. There are six such tunnels under the English Channel and the North Sea. There is a homunculus in your head and when you push your tongue up on the back of your mouth it tastes of lemon. Valve computers as crates of milk bottles. Electricity pylons as totem poles, across the United Kingdom.\n\n\nThe repulsion of magnets is the same as the repulsion you get when you push your hand against the sofa and it pushes back.\n\n\nFeynman concludes, I really can't do a good job, any job, of explaining magnetic force in terms of something else you're more familiar with, because I don't understand it in terms of anything else you're more familiar with.\n\n",
    link: "/home/2011/05/07/books_read_feb_to_apr_2011",
  },
  {
    title: "",
    date: "17.50, Friday 31 Dec 2010",
    content: "\nIs this thing on?\n\n",
    link: "/home/2010/01/03/when_richard_feynman",
  },
  {
    title: "",
    date: "10.55, Saturday 14 Feb 2009",
    content:
      "\nMy new theory is that I've lost some strength in my glutes and outer thighs, and that's letting my legs twist inwards, which means my knee isn't hinging on a clean line, which is why it's swollen now.\n\n\nI've been putting stress under my shoulder blades for as long as I remember. A couple months back, the knot had compressed into a diamond that wouldn't shift, and every time I slept on a plane my two smallest fingers on my left hand would go numb. Clare traced these back first to my neck, then to my right shoulder where I'd lost a great deal of mobility some two years ago showing off in a pub arm wrestling. She fixed me and now my shoulders are level for the first time in all that time: when I stepped out of her house it felt like I was standing on a hill, I'd got that used to pulling one side of my body taut.\n\n\nBut during that two years I'd increased my fitness considerably, and lop-sidedly too it turns out. Levelling my shoulders means I'm now resolving that asymmetry all down my body in a cascade of little problems that bubble up every time I discover an imbalance. I twinged my neck for a week putting together furniture, and when I tilted left to nod at a coffee shop the pain made me put my head between my legs standing near the Angel, and I felt that kind of deep-down bone sick I've only felt before wading through a river of snow-melt so freezing to the ankles it visits your marrow.\n\n\nThen this knee thing, which I brought on by running in the snow that morning. The sky was bruised and luminous, running through the flurries let me play at being a sentient super nebula charging through a galaxy of stars, and my feet - and the curbs - disappeared under the fresh white. But I should have warmed up more and taken it slower. I thought it was hamstrings and hip flexors that day: your knee is a floppy hinge held in balance by so many muscles, and if any is a little off the bend will grate and it'll swell, which is what's happened to me. One muscle at its limit already must have been finished off by the brittle morning. Stretching has helped.\n\n\nBut really this is the effect of no longer going to the gym and I never realised how much those squats were enabling my runs. Time to get those into the routine, build up my left leg again and get that knee problem sorted, and chase this asymmetry right out the soles of my feet; let it go to ground like a static charge.\n\n",
    link: "/home/2010/12/31/is_this_thing_on",
  },
  {
    title: "",
    date: "15.18, Wednesday 18 Feb 2009",
    content:
      "\nCarl Steadman opened my eyes to the possibility of narrative in new media with two pieces: Two Solitudes (1995), in which you would eavesdrop by email on a conversation between two lovers?, friends? becoming distant, over 30 days, and 99 Secrets which I first encountered in 2000.\n\n\nYou can read Two Solitudes online, though without the slow delivery and intimacy of the inbox, it loses much of its poignancy and involvement.\n\n\n99 Secrets has similarly decayed. 99secrets.com, where you could click through 99 short snippets of conversation between an anonymous he and she, has been snagged by a domain squatter and is consequently no longer available in the Wayback Machine. (I've attempted to buy the domain to enable access to the cache again, but haven't had a response to my emails.) It's sad.\n\n\nRecently I found miss bunnyhead darling kept the 99 secrets and posted them back in 2006. I am super, super grateful. As ephemeral as the secrets maybe should be, I think they still deserve an audience.\n\n\nWhat I've done is taken that list - which I'm not going to link to directly here  - and I'm posting Carl Steadman's 99 Secrets to Twitter instead, randomly, roughly once a day: follow @to_no_one.\n\n\nThank you miss bunnyhead darling, for your act of care! Thank you Carl, for showing us what could be done and how we can be touched! I hope I don't offend anyone by re-performing the words.\n\n\nThe name I've used on Twitter is from the final secret:\n\n\n99. i still love you, he said, to no one.\n\n",
    link: "/home/2009/02/14/my_new_theory_is",
  },
  {
    title: "",
    date: "18.46, Tuesday 1 Jan 2008",
    content:
      "\nBlogs were a different kind of conversational before permalinks were invented. This was also before categories, and titles, and topic-specific blogs, and professional bloggers. Permalinks and titles encourage us to face outward, to package our ideas in chunks for easy consumption by the reading machine (um, that's you). But I'm sure permalinks weren't that, to begin with. They were more like putting a timestamp in whenever the virtual carriage return lever was pulled.\n\n\nHere's an Orangina Naturally Juicy commercial, which is aimed at furries. Speaking of which, I learned about a new fetish: financial domination. A financial dominatrix is like a camgirl who hurts you via your wallet. She won't take her clothes off, or answer your questions, but you can pay her $100 because you're a spineless worm with deep pockets. Seems like a good racket. And there's something hilarious about Goddess Hannah's Amazon Wish List.\n\n\nA related note: the sex singularity is when machines surpass humans in hotness.\n\n\nVikram Chandra, The Cult of Authenticity: when an Indian author puts a cow or mentions dharma, are they doing it to exoticize the Indian landscape to signal their Indianness to the West, in the context of the Western market? Authenticity, as Chandra tells it, is one of those gods that people speak on behalf of constantly, but never speaks for itself. The trinity of these gods that looms largest in the UK is: anti-discrimination; health & safety; security. Is there a word for this general type? And what is the larger system of words that discrimination and its evil twin, political correctness fit into?\n\n\nMatt Jones wants to scamper between beautiful extremes of pored-over and glanceable information design.\n\n\nGoogle have introduced instant messaging chat bots that translate languages. I wonder what the conversational UI is like for these, in group chats?\n\n\nIn Alan Moore and Dave Gibbon's Watchman (spoilers: cracking interview from March 1988), Ozymandias sits in his Antarctic base and watches dozens of television broadcasts simultaneously, letting patterns float up and predicting the future from the gestalt. ''Just me and the world.' \"Browsing\" the Web is like \"reading\" a David Markson novel.\n\n\nThere is both a great tune and a car blowing up in slow motion in the video to Kojak, You Can't Stop It.\n\n\nAll of that aside, I thought I'd switch the design of this weblog to one with more purple, orange and old people in it, based on a design I made for Tom Coates, some 7 years ago.\n\n",
    link: "/home/2009/02/18/carl_steadman_opened",
  },
  {
    title: "",
    date: "17.52, Wednesday 2 Jan 2008",
    content:
      "\nWhat I like most about the Fit Song video by Cornelius [thanks] is the sugar cube stop motion animation near the beginning, because it's not just that the sugar cubes are being added to the chain one by one: there's a signal travelling down the chain, which means the entire scene iterates frame-by-frame. This reminds me of Yatima and Paolo, in Greg Egan's Diaspora, attempting to catch up with the Transducer civilisation by chasing successive subtly varying Transducer-made artifacts through nested 5 dimensional universes, where each universe is contained within a Planck-sized singularity hidden in the last. Each artifact looks like a totally non-moving solid, and it's only after they've passed to the 267,904,176,383,054th universe (with no way of getting back) that they realise the artifacts were successive iterations in time of the Transducer civilisation itself, uploaded to a computer, each of the Transducer's moments stretched to eternity in a given universe, existing only as a dynamic entity when skipping across them. Imagine living parallel to time, like that. A stop-motion city: a trillion Londons, side by side in a great circle around the Earth, iterating by a second each time, so you can walk from 1pm Oxford Circus to 2pm Covent Garden by crossing the M25 7,200 times.\n\n(Actually you'd only get 1,460 Londons side by side before you ran out of planet and got back to where you came from. At a second per iteration, that's a little over 24 minutes.)\n\n\nHere are multiple stencils of a figure, all over a city, that when seen in a certain order become a stop motion animation of someone walking towards you.\n\n\nThe Fit Song video is by the artist Tsujikawa Koichiro, currently showing at Tokyo's Mori art museum.\n\n\nHow about making a stop motion watch. 86,400 watches, side by side. It'd save on moving parts. Or perhaps a clock that only changes when you look at it.\n\n",
    link: "/home/2008/01/01/blogs_were_a",
  },
  {
    title: "",
    date: "19.03, Thursday 3 Jan 2008",
    content:
      "\nWith reference to that music video yesterday, I come to a familiar complaint: there should exist an iTunes music visualiser that looks exactly like Michel Gondry's Star Guitar. If someone offered to make that for me, I would find a way to bring it into the world. In this Making Of video, Gondry prototypes Star Guitar using oranges and VHS video cassettes.\n\n\nAudiosurf allows you to experience the intensity and emotion of your songs in real time, in full color, and in 3D. Songs that give you an adrenaline rush are converted into wild roller coaster rides full of color and motion. Songs that calm you down appear as cool colors against a relaxing sky. (Releases February 2008.)\n\n",
    link: "/home/2008/01/02/what_i_like_most",
  },
  {
    title: "",
    date: "20.05, Thursday 3 Jan 2008",
    content:
      "\nThai personal names include given and family names, honorifics and nicknames, all of which have different cultural meanings than how they're used in the UK.\n\n\nThere's also an alternative way to count your age in China, Korea and Japan, although this is becoming less popular.\n\n",
    link: "/home/2008/01/03/with_reference_to",
  },
  {
    title: "",
    date: "21.34, Thursday 3 Jan 2008",
    content:
      "\nBenoit Mandelbrot Fractal Art Contest 2007, winners. Next year I'm going to enter a photo of a rainforest and claim I just hit on the correct l-system parameters.\n\n\nA random tree.\n\n\nSpeedTree is a software component to procedurally generate, light and render vast forests of trees in real-time. What I would give for a slowly panning, generative, Mac desktop background of the Trees of Pangaea, the species mix of which would respond to my shifting continuous partial attention.\n\n\nDynamic traffic simulator. Click 'Zufahrt' and see the pressure wave propagate backwards through the traffic jam from the on-ramp. I could watch these simulations for hours. See also the shortcut.\n\n\nVATSIM networks people all over the world to simulate air traffic control together. This is a service provided to people using flight simulator software, via plug-ins. TerraNova have a good thread on this. When Wired covered sim ATC in 2003, they mentioned a curious failure mode: O'Hare was having four emergencies a night, and they don't get four a month in the real world. They'd call the tower and say, 'Emergency! Engines out.' I know what people are doing: Maybe they need to go eat dinner, so they call in an emergency so they don't have to wait in a holding pattern to land.\n\n\nAgeing superheroes. Who was I talking about this with? An old folks home for superheroes would need to be stocked with the equivalents of incontinence pants for the special forms of excretions these people have. Like Superman would have leaky heat ray vision the whole time, and everything in-front of him would get mildly toasted. And Green Lantern would have little accidents where the power ring would make manifest glowing greens pairs of slippers and cups of tea. Or I suppose he could just take it off.\n\n\nOmar Elsayed's website, dessalles.com, is utterly gorgeous: a Google Maps satellite view drifts in the background. I left the window open all day, and it wound up over a handsome desert somewhere. Like being in a hot air balloon, lost and rapt in the baking heat. He also gives a smart response to my question, how to design a sign-in system for a group, switching the focus from authentication to permissions. I like this approach, for a TV that tracks usage for multiple users: let anyone can use any profile they wish and instead protect the ability to remove content from a specific profile.\n\n\nInterrupter 1.0 is a preliminary prototype of a device that interrupts you while you move through the city. I have an ongoing problem with presence - sometimes unable to feel fully in the world for days at a time - and I value highly the moments of coming to or surfacing this device would provoke. So, inspired by Interrupter I've made a presence machine on Twitter: follow it, then every 5 minutes there's a small chance the machine will say 'Look around you.' It should work out as once every 12 hours, more or less [update], and being in the world twice a day ought to be enough for anyone.\n\n",
    link: "/home/2008/01/03/thai_personal_names",
  },
  {
    title: "",
    date: "22.32, Friday 4 Jan 2008",
    content:
      "\nMy Muesli [via]: custom-mixed cereal. See also, Coco Pops Creations.\n\n\nSnuzNLuz [via]: an alarm clock that donates money to a charity with which you ideologically disagree whenever you hit the snooze button.\n\n\n765 traces a tale of trees and branching, with stepping stones of celtic art, fractals and territories. The ultimate composition is breathtaking in how many systems [thanks] it resembles.\n\n\nFollowing on, there's a link to Rod's piece, Abbey Among Oak Trees (Northern Line), 2006, a composite image using, in the place of brushstrokes, long random drawings created on tube trains. The brushstrokes tangle together and tug at one another in a way that it's easy to forget elements always do in any composition (image or text, or code for that matter). Where that tangling is usually a property of something aside what the medium is really about (as colour and texture is for paint, meaning and poetry is for words), Rod's brushstrokes have that as their core and almost only nature.\n\n",
    link: "/home/2008/01/03/benoit_mandelbrot",
  },
  {
    title: "",
    date: "12.41, Sunday 6 Jan 2008",
    content:
      "\nThe presence machine I put together the other day stubbornly refused to randomly pick its magic number for 2 and a half days (it runs every 5 minutes, and flips a 144 sided coin. If the 100th heads comes up, it uses Twitter to remind you to have a look around). The odds of that are small--less than a penny in the pound. Overnight, however, it did fire, twice. But Twitter appears to reject identical status updates, and so the messages didn't get through.\n\n\nI've made an update: to keep the messages different, the presence machine will now send out a first line from Lao Tzu's Tao Te Ching, translated by Ursula Le Guin. Sometimes it's not the first line; I'm fickle.\n\n\nHere's the presence machine. Maybe something will happen soon. Maybe not.\n\n",
    link: "/home/2008/01/04/my_muesli_via",
  },
  {
    title: "",
    date: "18.27, Tuesday 8 Jan 2008",
    content:
      "\nRude words from 1811.\n\n\nA game in which you have to cooperate with your past selves.\n\n\nContinuing from last year's rambling on the Second Second Law of Thermodynamics, I don't mean that entropy doesn't increase. But somehow, as it increases - as disorder increases - it releases some another measure, a measure which can either be thrown away or harnessed and turned into life. You know what I mean? As you shake a packet of cornflakes, it settles down. Think of the decreasing height of the cornflakes in the box as entropy increasing, and that's a decent enough analogy because the level will never spontaneously increase again. But in the process of the height shaking down, the larger cornflakes float to the top! A size sorted gradient of cereal emerges! That's the magic of percolation. Where does that order come from? Perhaps you pay for it with increasing entropy. What if, while you were shaking it, multi cornflake autocatalytic networks evolved that optimised their chance of getting to the top? What do we call this second-order order?\n\n\nAnyway I was thinking that if my dishes and cutlery were made out of diamond, or something like it but harder, I'd be able to just throw them into the dishwasher instead of having to stack them, because they couldn't break. And then I'd have the washer agitate its contents really vigourously, because then the casserole dishes would float to the top, and the forks to the bottom, and putting stuff away would be an ordered process.\n\n\nThe disadvantage of diamond plates, of course, is that diamond conducts heat too well. If you were holding an ashtray in your hand and you stubbed out a cigarette on it, you'd burn your palm. And you'd be contributing to your chances of getting emphysema and a number of other unpleasant conditions.\n\n\nI find that certain mental states are good for certain tasks. No caffeine is good for doing my taxes, running and washing up. Walking with no music and being in the shower is good for insights into problems. Coding then beer is good for questions like 'how could this become the case?' and 'what are the implications of it, were it to be the case?' Being hung-over and tired is good for creative writing. Being cross, elated, care-free or cocky is good for new ideas.\n\n",
    link: "/home/2008/01/06/the_presence_machine",
  },
  {
    title: "",
    date: "10.06, Wednesday 9 Jan 2008",
    content:
      "\nNew software pricing models are always worth looking out for. More and more cleanly defined things are sliding towards plain ol' data (not just media. Home fabbing and local, short run manufacture are turning home electricals and clothes into free data plus effort). And because the concept of commercial software is so new (only since Bill Gates invented software-as-property 30 years ago), its business models aren't as entrenched as, say, music, so it'll blaze the way in finding new ways to be sold. Also software has an inherent lightness, which means it's suitable as a testbed for ideas that'll eventually inform how businesses work around open hardware and other forms of data (though of course it won't be directly translated, just as the Web is a testbed for including social ideas in mobile phones and televisions without direct translation). Software pricing models are try-outs for the future, just like social software on the Web.\n\n\nI ran across the Celtx script editing/collaboration application [thanks]. It's free, with the money coming from web services built into the interface.\n\n\nThis follows the model of applications like iPhoto, which has integrated photo book publishing, and of course iTunes with its music store. Linotype FontExplorer X follows the iTunes model but is more interesting in that it gives away superb font management software (something that used to be expensive) and, as its commercial play, bundles access to an online store font (and buying fonts was always somewhat tedious).\n\n\nUntil recently Eudora had a paid and ad-supported mode, and Twitterific can be used free of charge, supported by in-line advertising.\n\n\nCeltx, though, seems to represent something newer than these, something much more mature, considered and integrated as a model:\n\n\n\nfor one, the desktop software doesn't act merely as an enabler or gateway to the extra services; the extra services are there to make the core activity (writing a script) richer.\n\n\nSecond, the software has a pleasant gradient toward commercial use: while I can't find any pay-for services yet, my reward for starting a user account (from within the application) was free access to private, off-site back-ups; collaboration and sharing; and PDF generation. \n\n\nAnd by joining the software with a community website for collaboration and as the home for other Web services, the software has fuzzy edges which gives it room to grow in the direction of user interest--something more like a web application rather than desktop software. Actually, I'll be intrigued to see where Celtx takes this: integration with Lulu for quick+easy self publishing, or the ability to send your script to the sub-editor equivalent of Lazymask? (Lazymask is an in-betweener.)\n\n\n\nBut what a turnabout! Social software where the software's the commodity and the social comes at a premium!\n\n\nWhere Celtx differs from end-user webapps is that web applications haven't made a great showing with various levels of features for different levels of paying. Flickr offer stats to pro users (and bandwidth), and blogging software has had a tradition of pricing tiers (before Wordpress--who remembers Blogger Pro?), but these are exceptions: in the main webapps are (a) ad supported, and (b) networked: additional pay-for services are offered via non-exclusive affiliate links, with the end provider providing the functionality instead of integrating into the original webapp.\n\n\nAuthenticity and going with the grain:\n\n\nThere's something else that rings true about Celtx, and that's its authenticity. The internet has helped reduce the variable unit price of software close to zero (mod marketing and sales). In part due to improved SDKs, IDEs, and APIs, open source, and the sharing of knowledge on the internet, the barrier to entry and the cost of software development is astoundingly low. It's possible - I don't have figures to back this up - that the cost of developing (or licensing) a web front-end to manage sales, registration and lost licenses for a piece of software like Celtx would exceed its original development costs.\n\n\nThe authenticity comes in because they will charge for what actually costs money per unit, unlike the reproduction of software-as-data: collaboration necessarily involves servers, which somebody has to host, and that costs money. PDF generation involves expertise and money to install, host and scale. And so on.\n\n\nOn top of authenticity is a sense of going with the grain: whereas software is simple to pirate without hard-to-code countermeasures, the use of a service online is just not pirateable. This is the way physical property and consultancy has always been sold, of course - in non-pirateable forms - and paying only for the hard bit is not new. Two interesting twists elsewhere: CentOS is a free Linux distribution, built by the community from Red Hat Enterprise Linux. It's identical but free; with RHEL you pay for support. Perfect for the difference between development and production servers. And with Mint web stats, what you get for purchasing is the latest plug-ins and access to the forum.\n\n\nSo while I agree that the qualities a software pricing methodology must have are, as identified by ASG [pdf], budget predictability, controllability, technological independence, value, flexibility, and simplicity, I'd want to add to that those two above: authenticity (because that provides simplicity and a sense of fairness), and going with the grain (because it's easier, and automatically doesn't promote piracy).\n\n\nFurther questions:\n\n\nFor all this discussion, where do new software pricing models get us? There are a number of areas ripe for a further look.\n\n\n\nWhat these new models feel most like is open source hardware: the replicable-for-low-unit-cost part is free (with hardware, that's the design once it's drawn on), and what costs money is where costs are actually incurred--in the manufacture, whether you buy it from the same people hosting the community effort, or produce it yourself. Charge for the plastic, throw open the APIs. Ponoko is intriguing in a similar regard: you, as a designer, upload a specification for laser-cut wood/other material furniture and objects. Then, as a customer, you pay Ponoko - or a local laser cutter who has joined their network - to product the object for you. The designer gets a royalty. Yesterday I was talking with Schulze about publishing the designs for the furniture he makes in the workshop, in a form that anyone could take down to their local builders merchant and get cut for home assembly (D.I.Y.kea, he called it). Same deal. And Tim O'Reilly has talked about the significance of Threadless.com too. Same again. What happens when software fragments along the cost faultlines across its entire life-cycle? What divisions are there?\n\n\nTechnology offers new simplicities. Mobile phones tariffs, insurance and mortgages have all become more complex in the name of - let's be generous - giving the consumer a closer fit to their actual usage. But in the case of mobile phones, the tariff ends up altering your behaviour, which in a social situation really isn't great. For a business, new technology (primarily the ability to price adaptively) has the double advantages of easier to understand pricing models, and not having to build the expensive measurement infrastructure demanded by over-complex pricing systems. Car insurance per mile, for example, is more complex to develop as a business (otherwise we'd have seen it before) yet way simpler to understand and as an experience. What new simplicities could there be with software... in a way that the user doesn't feel they're being nickle and dimed, with \"pay for me\" nags next to every menu item?\n\n\nStart-ups run on the Amazon Elastic Computing Cloud. Amazon S3 is used for Web-accessible storage of user profile images by Twitter, and accessible as a desktop drive through companies like Jungle Disk. Dave Winer has asked whether S3 could be an end-user product: As a developer who has to pay for his users' storage needs I would very much like to see users learn how to use S3 to store their stuff, so I can focus on writing software and fixing bugs instead of paying to store your stuff. I'm inclined to agree! We already pay for our bandwidth separately, so what if we also paid for our computing resources independently from the webapp, and paid webapps for the service they offered rather than for their infrastructure?\n\n\nThe Mint web stats package, mentioned earlier, asks for money from people who want to be involved in the community (or ask for support, and there's a quid pro quo there). In the comments threads about the soon-to-be-updated Super Duper Mac backup software, people are offering to pay for a free upgrade because they value the developer so highly. What if this behaviour was taken further:  only the keen are asked to pay, for services only the keen value. Could this fund the entire software development? Okay, that's the shareware model, and it doesn't work too well... but what about novel differences? What if some upgrades were flagged as optional? Perhaps only businesses would pay for Microsoft Word, because they want the budget stability, and everyone else gets it for free? To be honest, I'm more interesting in exploring concepts like yield management for variable pricing in a software context. What if I priced my software so that it was a $1,000 per copy for the first 10 copies, $100 each for the next 1,000 and free thereafter? Or if I sold hours of support at some extremely high rate, and let any other company sell as many copies of my software as they felt they profitably could while having to purchase support hours from me (amortised across their whole user base)?\n\n\nWhat other pay-for services are there, if all software worked like Celtx? What if Adobe had built out Lazymask, and included it in Photoshop... and Photoshop had become a platform like a Wii or an iPod that encouraged a huge secondary market around it? Or rather, what if Photoshop was a platform more like Dubai where taxes are non-existent to encourage growth, and the government makes its money in the same way everyone else does: on real estate and running hotels. What if Adobe sold Photoshop at cost... then distributed plug-ins to its services, competing with everyone else who also makes plug-ins to their services, offering everything from online collaboration tools and source control for images, to integration with local print shops? \n\n\n\nMy first job was at the Saturday boy in the local ironmongers and once, cleaning the top storage shelves, I found a price label that'd been there decades. Eric, my boss and one of the best men I have ever had the honour to meet, told me about the way products were priced when he was younger. The iron lawn roller he'd sold had the price cast into the body of the machine itself, because the price was as durable as the manufacturing process used to make it. It's not so simple now.\n\n",
    link: "/home/2008/01/08/rude_words_from_1811",
  },
  {
    title: "",
    date: "22.25, Thursday 10 Jan 2008",
    content:
      '\nI am the Noah of hyperlinks.\n\n\nProducts or services that include mental well-being as a feature:\n\n\nSeamless Relocation is at its heart a London-based personal relocation consultancy. But their USP is framed in the language of well-being: moving is "emotional," "overwhelming," and "stressful." Their goal is to make this transition as positive and smooth as possible for all concerned.\nThe StressEraser is an iPod-like biofeedback and training device to induce meditative states.\n\n\nThe World Stress Map shows the boundaries of the tectonic plates. The Pacific plate is large, and the western Pacific a whole load more textured than I expected. All those drowned continents.\n\n\nGames about something that are actually about something else:\n\n\nAudiosurf (mentioned previously) sent over a demo. Techno car racing tetris. It\'s fun like dancing, which is fun because moving at the same rhythm you\'re hearing kind of doublepluses the sensation.\nOver a decade ago, Endorfun kept you occupied with a simple cube-rolling game while you got a buzz from subliminal affirmations flashed on the screen.\n\n\n(I love the world and the world loves me.)\n\n\nI\'ve called this "body-thinking" before: the kind of reading of the world we do non-mentally. Everything we do taps into different motivations, of course (the joy of watching things happen; the joy of putting things away neatly; plain old needing to), but Audiosurf and Endorfun seem different somehow: the ostensible aim of the game is really just an excuse to keep you busy while the real mental pay-off happens.\n\n\n(I create joyous relationships.)\n\n\nOn the study of the natural laws of exceptions, \'pataphysics:\n\n\nFrom A survey of imaginary musical technologies: For some composers, the imagining and realisation of a new and unfamiliar music technology is integral to their music. I also like the Tubaharp.\nCollections and exhibitions of the Museum of Jurassic Technology, Culver City.\n\n\nAnd:\n\n\nQuotes from Tyler Durden.\nSpiritual messages printed on tea bags.\n\n\nTwo by two! Two by two!\n\n',
    link: "/home/2008/01/09/new_software_pricing_models",
  },
  {
    title: "",
    date: "18.38, Monday 14 Jan 2008",
    content:
      "\nThe fancy-legged fellow isn't allowed in the Olympics, as his disadvantaged compensator unfairly advantages him. Huh. Tiger Woods has surgically upgraded his vision to 20/15. There exist Nike Vision contact lenses which selectively enhance colours so golfers can see the ball better on the putting green. In answer to the question how much is too much?, we should let the market decide: all modifications should be allowed until betting exchanges refuse to take wagers on the athlete. The athlete must declare all prosthetics and performance enhancers ahead of time.\n\n\nAlongside graphics cards, we'll soon have quantum computing chips which will take certain calculations, handed off to them by the CPU, and rifle through parallel universes looking for the answer, super quick. In addition we'll have prediction market co-processors: a petri dish of bacteria specially bred to exhibit the supply/demand curves of perfectly rational economic agents, tucked just behind the battery to the side of the hard-drive. (I wrote a story that mentioned something similar.)\n\n\n2008 is the year we hit Peak Attention. You can either carry on encountering as much as you do now, giving every input less and less attention every year, or you can start managing it, keeping some back to take long-haul attention flights. What are the consequences of living post-Peak Attention? Nobody will be able to understand anything hard unless they make sacrifices.\n\n\nThe xkcd IRC channel will hit Peak Unique Sentences in 2010 after which being funny is hard because all the good sentences are used up. But just like domain names, this will cause a fluorescence in amusingly spelled cuss words.\n\n\nActually having single people who are delegated to understand hard things while other people process trivialities is fine. Thought and understanding are networked, social activities: cognition is distributed [pdf]. For a mass of people to make a decision, they form a decision making organ, which is a particular body formed to that job. It purifies group opinion as the liver purifies blood.\n\n\nEvery time I mention an idea, I'm giving it attention cycles from all you readers. Attention is the bile of the public thinking stomach organ, breaking it down and digesting it, distributing it to the rest of the body public in recombinant forms.\n\n\nThe entities in a group of people aren't only the humans, but the organs made of sub-groups. Like Conway's Life parts that perform different functions. Like Standard Biological Parts stitched end to end. Organisations should be thought of as organs that specialise to think, co-ordinate, propel, introduce novelty, gather food, defend or fight, in a way that self-reinforces: a body.\n\n",
    link: "/home/2008/01/10/i_am_the_noah_of_hyperlinks",
  },
  {
    title: "",
    date: "11.56, Tuesday 15 Jan 2008",
    content:
      "\nOver at Mind Hacks, Vaughan has been posting some remarkable brain-related news. Some top picks:\n\n\nA brain-computer interface to compose music, home made, using EEG.\nThe origins of the word 'stress.'\nRegarding how ideas spread through social networks, it's the masses, not the 'opinion formers', who matter.\nSteven Pinker, moral judgements, and how shifting a topic from a personal to moral issue brings a specific, difference reasoning framework into play.\nChristian Nold's biomaps.\n\n\nMy favourite is the ambient panic video, overlaying dreamy suburban visuals on this radio documentary about panic (All In The Mind). It's Adam Curtis meets Lucid Dreams. Watch.\n\n",
    link: "/home/2008/01/14/the_fancy_legged_man",
  },
  {
    title: "",
    date: "18.27, Wednesday 16 Jan 2008",
    content:
      "\nThe sound of Jupiter space. Reminiscent of 9 Beet Stretch (before). As 9 Beet Stretch is slowed down, I wonder what the voice of Jupiter would be sped up.\n\n\n\"Heeeelllllllllloooooooo wooooorrrrrllllldddddd.\"\n\n\n\"Jupiter Space,\" eh. 2001: A Space Odyssey (1968) culminates in what is called Jupiter space (the original screenplay has Discovery head for Saturn). This of course means there's also Earth space and Moon space, with all the bits in-between being \"outer space.\" The idea that planets have space hanging off them - different spaces, like different territorial waters - seems quaintly planetcentric now. The viewpoint has shifted such that all the planets are within the very same space, located by Cartesian coordinates on a map of the galaxy. There is just Space. I suppose this is like the university computer network and the military computer network and Ford's computer network all coming together to make a single \"the internet.\"\n\n\nPerhaps, back in the 1960s, we all used to have our own lives too, but now we're each living the same life but with different parameters. It's a shame. As a metaphor it makes the idea of trying out someone else's life - of judging them - of being in their shoes - seem possible. But it's not, not always. Our individual lives are separated by the desert vacuum of Outer Life. I need rocket-ships, time and bravery to visit your life, to understand you inside your own space. And vice-versa. But it's worth it.\n\n\n2001 movies. Check out 20'01 and 2001x1: every frame of it, in glorious colourfields.\n\n",
    link: "/home/2008/01/15/over_at_mind_hacks",
  },
  {
    title: "",
    date: "18.56, Thursday 17 Jan 2008",
    content:
      "\nA new TV channel, BBC2+219000. As C4+1 shows Channel 4 but one hour later, BBC2+219000 shows BBC2 but 25 years after t.x., which means a heady mix of golden age Open University programming and cultural insights into 1983.\n\n",
    link: "/home/2008/01/16/the_sound_of_jupiter_space",
  },
  {
    title: "",
    date: "21.53, Sunday 20 Jan 2008",
    content:
      "\nKevan's zombie simulation reminds me of nothing so much as the formation of galaxies. As the sim starts, the universe is hot and young. The survivors get infected and condense into slower moving matter, which then itself clumps into larger, even slower moving massive objects. Galaxies are zombie hordes of stars, shuffling round the universe converting the free interstellar medium into brainless eating machines.\n\n",
    link: "/home/2008/01/17/a_new_tv_channel",
  },
  {
    title: "",
    date: "22.50, Sunday 20 Jan 2008",
    content:
      "\nMovement. I'll be speaking at Web Directions North at the end of the month, and taking the opportunity to expand on some of notes in last year's wrap-up.\n\n\nToday I met up with Tom Armitage to see what he's created for a prototype we've been working on together. It shows off a simple pattern I think should (and will be) part of every web app. But before Tom made the proof of concept, I didn't know if it'd work. It does, it's better than I imagined, and I'm totally psyched. There'll be a demo in my talk.\n\n\nThe abstract, for Movement:\n\n\nWe've always had metaphors to understand and design for the Web.\n\n\nThe original conception of the Web was as a library of documents. Our building blocks were derived from spatial ideas: \"breadcrumbs,\" \"visits\" and \"homepages\" were used to understand the medium.\n\n\nWebsite-as-application was a new and novel metaphor in the late 1990s. The spatial concept of navigation was replaced by concepts derived from tools: buttons performed actions on data.\n\n\nThese metaphors inspire separate but complementary models of the Web. But the Web in 2008 has some entirely new qualities: more than ever it's an ecology of separate but highly interconnected services. Its fiercely competitive, rapid development means differentiating innovations are quickly copied and spread. Attention from users is scarce. The fittest websites survive. In this world, what metaphors can be most successfully wielded?\n\n\nMatt takes as a starting point interaction and product design, with ideas from cybernetics and Getting Things Done. He offers as a metaphor the concept of the Web as experience. That is, treating a website as a dynamic entity - a flowchart of motivations that both provides a continuously satisfying experience for the user... and helps the website grow.\n\n\nFrom seeing what kind of websites this model provokes, we'll see whether it also helps illuminate some of the Web's coming design challenges: the blending of the Web with desktop software and physical devices; the particular concerns of small groups; and what the next movement might bring.\n\n",
    link: "/home/2008/01/20/kevans_zombie_simulation",
  },
  {
    title: "",
    date: "21.58, Tuesday 22 Jan 2008",
    content:
      "\nChinese mathematics, an overview: a person gains knowledge by analogy, that is, after understanding a particular line of argument they can infer various kinds of similar reasoning ... Whoever can draw inferences about other cases from one instance can generalise ... really knows how to calculate... . To be able to deduce and then generalise.. is the mark of an intelligent person.\n\n\nIf English was written like Chinese: The yingzi that use a particular radical will form a class of their own--a sort of meaning class. We can consider the entire English language to be divided into 214 meaning categories. For instance, every yingzi that uses the bug radical will have something to do (at least etymologically) with insects or reptiles. However, since the number of radicals is so limited, and because the choice of radical is sometimes quirky, the resulting sets will be rather vague and eccentric.\n\n\nHumans have 347 different smell receptors. 347 orthogonal odours.\n\n\nAdam Greenfield's Minimal Compact applies the model of different-yet-compatible Linux distributions to the simplest surface needed for states to live side-by-side. cf. coexistentialism.\n\n\nThe Molecule of the Month presents short accounts on selected molecules from the Protein Data Bank. Each installment includes an introduction to the structure and function of the molecule, a discussion of the relevance of the molecule to human health and welfare, and suggestions for how visitors might view these structures and access further details. Plus each is super pretty.\n\n",
    link: "/home/2008/01/20/movement",
  },
  {
    title: "",
    date: "21.47, Thursday 24 Jan 2008",
    content:
      '\nAnonymous has declared war on the Church of Scientology (more news). I just read this on the internet: WE SHALL NEVER ASK FOR RANSOM. WE SHALL NEVER YIELD FOR NEGOTIATIONS. THERE ARE NO DEMANDS. THERE ARE NO DESIRES. THERE IS NO FUNDING, NO LEADERSHIP, NO MEMBERSHIP, NO POLITICAL GOAL. ANONYMOUS WISHES TO SEE SCIENTOLOGY FALL, FOR NO OTHER REASON THAN IT WOULD BE AWESOME. PEOPLE DO NOT PROPERLY UNDERSTAND THIS. YET.\n\n\nOn Slashdot, a comment explains: Memetic warfare. Walk down the street and ask random people "What\'s the first thing you think of when you hear the word \'$cientology\'"? If it\'s "Tom Cruise", the person could still be sucked into the cult. ... When it\'s "Xenu!", "Scam", "Money", ... the person will never be sucked into the cult. ... At some point - 20%? 50%? 90%? - herd immunity develops.\n\n\nAnonymous is not an organisation but an ideology that exists as a population. It can\'t do or think anything itself except metaphorically. Individuals who act in the same way as Anonymous but who have never heard of it can\'t be described as being part of it. This is an entity that exists as an auto-catalytic set in the social network. There is no leader who can give orders because identity cannot be verified from one instant to the next; there is perhaps a leadership organ. Whereas our society of capitalism and marketing is a control society which attempts to manipulate the network while keeping it computable (that is, conforming to a model held by the control system), Anonymous is a non-computable part of the network. That\'s what makes it dangerous. A part of the network outside the control structure which is developing self-awareness.\n\n\n(What strikes me most about the anti-Scientology videos is that individuals are using the same techniques of manipulation and persuasion that Hollywood, advertising and the state have used on the general population. I find this heartening.)\n\n',
    link: "/home/2008/01/22/chinese_mathematics",
  },
  {
    title: "",
    date: "22.28, Monday 28 Jan 2008",
    content:
      "\nThe chloroplast organelle, which performs photosynthesis in plants, is more complex, structurally, than the mitochondria which use oxygen to turn food molecules into ATP (energy-carrying chemical; an abstract interface) in most eucaryotes. Eucaryotes are cells with a nucleus--cells without a nucleus are procaryotes, which come as eubacteria and archaea.\n\n\nMitochondria, themselves, appear to be bacteria captured by procaryotes very early in the evolution of cells with nuclei, and now the two live symbiotically.\n\n\nTwo crazy things:\n\n\n\nWe - and I identify with the procharyotes-mod-mitochondria for some reason - live stacked on a substrate of captured energy transformers. We can't live in the world raw. We wear an internal space-suit that permeates every cell.\n\n\nIt's possible that plants are more advanced than animals, at a cellular level, but us animals - because we took the 'worse is better' approach - have had more time to do the bounded random walk into intelligence. Give it a billion years, and maybe the underlying smarter engineering of plants will win out in the end.\n\n\n\nLife: amazing. (Current reading is ECB2. Lots to learn.)\n\n",
    link: "/home/2008/01/24/anonymous",
  },
  {
    title: "",
    date: "09.20, Tuesday 29 Jan 2008",
    content:
      "\nSimCity on the OLPC, letting kids dig around with the dynamic system rules. Download Micropolis (its screenname in the open source world), and read more. I'd like this hooked into my todo list to have different districts as different projects, with the attention I give each manifesting as land value.\n\n\nVisit Deyemon, my mini city which runs online like a simplified SimCity. The more referrer traffic it gets, the higher the population. I can encourage you to visit other URLs to improve its industry, transport network, and so on.\n\n\nA viral loop is the steps a user goes through between entering the site to inviting the next set of new users (more). The viral loop leads to: motivated users; growth; mutuality between websites in the ecosystem. By happy coincidence, I'll be speaking on a similar topic at the end of the week.\n\n\nThe OLPC Human Interface Guidelines concentrates not on applications but activities. (Run OLPC without an XO laptop.) cf. Human Interface Guidelines for Mac OS X 10.5 Leopard.\n\n\nRumoured gestures for inclusion in Windows Mobile 7.\n\n\nThe Internet of 1996 shows just how much is dependent not on the technology, but on the people making stuff figuring out where the grain is. Once upon a time, the entire Web was mapped in 3D to the continent of antarcti.ca. \n\n\nMaintain eye contact to feel powerful. Keith Johnstone in Impro has a different view: breaking eye contact can be high status so long as you don't immediately glance back for a fraction of a second. ... status is established not by staring, but by the reaction to staring. Thus dark glasses raise status because we can't see the submission of the eyes.\n\n\nJohnstone also says the best ideas are often psychotic, obscene and unoriginal--it's in adulthood that we're trained to suppress these. Go for it, he says. Right on.\n\n\nCopy someone else staring at the camera and making a gesture, then post it to YouTube [via]. Now get a tentacle arm.\n\n\nThree thoughts:\n\n\nSatellites are very tall towers used for telecommunications. Are there any other profitable uses of space, or is that it?\nBurglars should be given objects of value to make them complicit with the aim of the state to preserve the concept of property.\nWe used to chase horses off cliffs for food. Then we carried spears. A portable cliff!\n\n\nRight. I'm off to Canada.\n\n",
    link: "/home/2008/01/28/the_chloroplast_organelle",
  },
  {
    title: "",
    date: "11.00, Tuesday 29 Jan 2008",
    content:
      "\nMy super power would be to know the resonant frequency of a thing as soon as look at it, and have the range of movement in my hands such that I could match those frequencies.\n\n\n(Other super powers I would like.)\n\n\nFor example I would place my hands on the trunk of a cedar and vibrate my palms at resonance. It would swing wildly, only gradually at first. At the opportune time: shove--down it would come. Except that I wouldn't want to.\n\n\nBees buzz on the turbulent flow of the air. Fish bumble too, pushing against and off the whorls emergent in the fluid dynamics of the ocean. They slip slide in the low pressure gaps the physics leaves.\n\n\nPerhaps if I could shiver the surface of my body correctly and variously, I could create micro currents and micro vacuums in the air just touching me, every skin cell tacking into the wind. Then I would swim through them and on them, like stepping stones, like pinball, like progress and careers and love and life, like falling upwards.\n\n",
    link: "/home/2008/01/29/simcity_on_the_olpc",
  },
  {
    title: "",
    date: "18.00, Thursday 31 Jan 2008",
    content:
      "\nBooks read January 2008, with date finished:\n\n\nConfessions of a Crap Artist, Philip K. Dick (4th)\nGod Bless You, Dr. Kevorkian, Kurt Vonnegut (11th)\nVirtual History: Alternatives and Counterfactuals, Niall Ferguson (editor) (12th, r.)\nThe Cloudspotter's Guide, Gavin Pretor-Pinney (16th)\nFinite and Infinite Games: A Vision of Life as Play and Possibility, James P. Carse (20th)\nThe Secret of Scent: Adventures in Perfume and the Science of Smell, Luca Turin (22nd)\nCat Confidential, Vicky Halls (26th)\nImpro: Improvisation and the Theatre, Keith Johnstone (27th)\nWhite Night, Jim Butcher (29th)\n\n\nIf I had to pick just one to recommend, it'd be Impro.\n\n",
    link: "/home/2008/01/29/my_super_power",
  },
  {
    title: "",
    date: "17.40, Monday 4 Feb 2008",
    content:
      "\nBest conference ever! I have been to some excellent conferences: ETech 2002, Design Engaged 2004, eurofoo 2004, reboot 2005, 2006 and 2007... maybe one or two more. Here's another for the list: I've just returned from Vancouver, where I was giving the closing keynote at Web Directions North 2008.\n\n\nAll of those conferences were good in different ways. ETech blew my mind; I met so many new friends at Design Engaged; reboot specialises in variety and friendliness; eurofoo, well, many reasons, but the eurodance foam party is a factor. And of course it's personal preference. Sometimes your brain is ready to be melted, or by coincidence you're stepping into a new community.\n\n\nWhat WDN08 did, for me, was hit the sweet-spot:\n\n\n\nTalks: I went to every talk I could (I had to skip one to do my run-through) and they were all top notch. I'm more excited about the Web now than I have been for a long time: it's going through a period of transformation, both in terms of platform and the kinds of people using it. And it's clear now that the Web is on the trail of certain issues - adaptive, service and experience design - and is probably better placed to offer approaches than most other media and design. It's great to see the Web come into its own.\n\n\nOrganisation: the conference organisation was tight. Seriously, it makes such a difference--well done to the team and helpers. Aside from general organisation, I personally felt welcomed and generously looked after. I think I can only call it care and consideration, and it's much appreciated--it made the trip a pleasure.\n\n\nSponsors: it feels odd to mention the sponsors, but having them participate instead of just slapping logos on things was a good difference. No vendor pitches, but general attention and being there. Microsoft deserve a special mention for their hosting of the two day party at Whistler. What made their sponsorship work was that Microsoft people were present and chatting. I'd like to see the culture of the Web assimilate MS instead of letting the historic divide calcify into two types on online experience: this kind of activity helps.\n\n\nWhistler: ah, the Whistler trip. Unique. It's great that the mental workout of the first couple of days is balanced with a physical one in the next two. I'd not skied before. Man, what an opportunity. If this trip has hooked me - it might well have done - this might turn out to be the most expensive conference I've been to. And group bonding is certainly facilitated by the alcohol and exhilaration. Lots of socialising in the bar and on the buses.\n\n\n\nI want to thank the organising team: Maxine Sherrin, Dave Shea, Derek Featherstone and John Allsopp. Thanks for being so welcoming, and it was so good to meet and hang out with all of you.\n\n\nBut mainly it's been the people--it's the crowd at a conference that makes the difference between good and great. (This particular crowd is mostly new to me too.) I can't count the number of people who showed me intriguing connections on topics I brought up in my talk, or the number of incredibly illuminating and hilarious conversations I had. What a joy. And then the easy conversations with folks I knew and folks I'd just met... I hope I've left Vancouver having made a few new friends. Thank you all of you who read this (I lost track of the group on the last night and didn't get to say goodbye to bunch of people), and please let's stay in touch.\n\n\nAn all round brilliant week.\n\n\nSlides and transcript of Movement will be up in the next couple of days.\n\n",
    link: "/home/2008/01/31/books_read_january_2008",
  },
  {
    title: "",
    date: "12.18, Wednesday 6 Feb 2008",
    content:
      "\nNew presentation online. I've put up the slides and notes for Movement (from my WDN08 trip). Read Movement here.\n\n\nA key introduction in the talk is Snap, a pattern for syndicating interactions. I've been working on this with Tom Armitage, and he's built the proof of concept. For more on that, and a longer essay about Snap outside the presentation itself, read about Snap on the company weblog.\n\n",
    link: "/home/2008/02/04/best_conference_ever",
  },
  {
    title: "",
    date: "22.24, Saturday 9 Feb 2008",
    content:
      "\nImpro (Keith Johnstone) has four chapters: Status; Spontaneity; Narrative Skills; Masks and Trance. The following are excerpts from the final chapter, Masks and Trance.\n\n\nOn what a Mask is:\n\n\nIt's true that an actor can wear a Mask casually, and just pretend to be another person, but Gaskill and myself were absolutely clear that we were trying to induce trance states. The reason why one automatically talks and writes of Masks with a capital 'M' is that one really feels that the genuine Mask actor is inhabited by a spirit. Nonsense perhaps, but that's what the experience is like, and has always been like.\n\n\nA Mask is a device for driving the personality out of the body and allowing the spirit to take possession of it.\n\n\nThe feeling of wearing a Mask:\n\n\nMany actors report 'split' states of consciousness, or amnesias; they speak of their body acting automatically, or as being inhabited by the character they are playing.\n\n\nOnce students begin to observe for themselves the way that Masks compel certain sorts of behaviour, then they really begin to feel the presence of spirits.\n\n\nAt the moments when a Mask 'works' the student feels a decisionlessness, and an inevitability. The teacher sees a sudden 'naturalness', and that the student is no longer 'acting'. At first the Mask may flash on for just a couple of seconds. I have to see and explain exactly when the change occurs. The two states are actually very different, but most students are insensitive to changes in consciousness.\n\n\nOn how to put on a Mask:\n\n\nOnce the student has found a comfortable Mask, one that doesn't dig into his eyes, I arrange his hair so that it covers the elastic and the top of the forehead of the Mask. I then say: 'Relax. Don't think of anything. When I show you the mirror, make your mouth fit the Mask and hold it so that the mouth and the Mask make one face. You'll know all about the creature in the mirror, so you don't have to think about that. Become the thing that you see, turn away from the mirror, and go to the table. There'll be something that it wants. Let it find it. Disobey anything I'm saying if it wants to, but if I say \"Take the Mask off\", then you must take it off.'\n\n\nWhat a Mask can do:\n\n\nA new Mask is like a baby that knows nothing about the world. Everything looks astounding to it, and it has little access to its wearer's skills. ... They don't know how to take the lids off jars; they don't understand the idea of wrapping things ... When objects fall to the floor it's as if they've ceased to exist.\n\n\nthe inability to speak is almost a sign of good Mask work. Actors are amazed to find that it's necessary to give the Masks 'speech lessons'. ... Speech lessons sound silly, but remember Chaplin, who never really found the right voice for his Tramp. He made many experiments and finally made him sing in gibberish (Modern Times).\n\n\nThe personality of Masks:\n\n\nMy suspicion is that the number of 'personality types' that emerge in Mask work is pretty limited. ... just as myths from all over the world show similar structures, so I believe that wherever there is a 'Pantalone-type' Mask there will be Pantalones.\n\n\n'It's like you get the freedom to explore all the personalities that any human being may develop into--all the shapes and feelings that could have been Ingrid but aren't. Some Masks don't trigger any response ... maybe these are spirits outside Ingrid's repertoire, that is any one person may have a limited number of possibilities when he develops his personality.'\n\n\nBeing analytical (the Waif is a particular Mask Johnstone uses regularly, which has its own childlike personality):\n\n\nWe have instinctive responses to faces. Parental feelings seem to be triggered by flat faces and big foreheads. We try and be rational and asset that 'people can't help their appearance', yet we feel we know all about Snow White and the Witch, or Laurel and Hardy, just by the look of them. The truth is that we learn to hold characteristic expressions as a way of maintaining our personalities, and we're far more influenced by faces than we realise. ... Sometimes in acting class a student will break out of his habitual facial expression and you won't know who he is until you look at his clothes.\n\n\nIf we wanted to be analytical we could say that the flatness of the Mask, and its high forehead, are likely to trigger parental feelings. The eyes are very wide apart as if looking into the distance, and helping to give it its wondering look. Where the bottom of the Mask covers the wearer's top lip, a faint orange lip is painted on to the Mask. Everyone who has created a 'Waif' character with the Mask has lined their lip up with the Mask's, and then held it frozen. ... It was only when she froze her top lip in this way that she suddenly found the character. The eyes of the Mask aren't level, which gives a lopsided feeling, and is probably the cause of the characteristic twisting movements that the Waif always has.\n\n\nI've never worn a Mask, but I have held an African tribal mask over my face and it feels like freedom.\n\nWe use our face as storage for emotions, so why not use appearance, poise, habitual personal space, and the expectations of others as storage for personalities? Change any of those, and those are your personality parameters you're playing with.\n\n\nThe idea there are a limited number - or at least stable set, or basic vectors - of personalities I find intriguing. It doesn't seem unlikely that there are certain personalities which are with the grain of however the 'model of the other' is represented in neurons. And people will end up snapping to grid and becoming those personalities because everyone else imposes it on them.\n\n\nTrance state and spontaneity: when I write a talk, I write long hand first, and I write as if I'm speaking. When delivering, I half read and half speak--the words always need adjusting according to the feel of the room. But when everything is perfect, I feel I'm aloft. I start reading from my notes, then improvise... only to, paragraphs later, look down and found I've improvised what I wrote before, word for word.\n\n\nThe experience of predestined free will is magical.\n\n",
    link: "/home/2008/02/06/new_presentation_online",
  },
  {
    title: "",
    date: "00.06, Sunday 10 Feb 2008",
    content:
      "\nThe visual cortex of developing ferrets has more territory containing neurons selective for vertical or horizontal orientations than oblique angles. We preferentially see up-downs and left-rights.\n\n\nYou drop a population of finches on an island: they speciate, populations diverging from one another as they find niches. But each incipient species has as part of its environment every other incipient species. It's complex. The eventual set of species are not only determined by the size of nuts, the type of trees and the local predators, but through an iterative solution to the force-directed graph of the species, overlaid on the peaks and contours of the fitness landscape.\n\n\nMaybe with a slightly different composition of the initial population, and we'd have six eventual species, not eight.\n\n\nCould we regard the fundamental forces of physics as species? Could they have speciated differently, at the end of the GUT Era?\n\n\nThere is general agreement that human personalities may more-or-less be plotted in a five-dimensional space, where the five trait-dimensions are: openness; conscientiousness; extraversion; agreeableness; neuroticism.\n\n\nWithin that space, are there attractors of personality, semi-stable or wandering fitness peaks? Just as our visual cortex is tuned to particular orientations of line, is our internal 'model of the other' tuned to particular personalities? Are there maybe only a few dozen personality archetypes which can mutually co-exist in a connected population? These archetypes emerge sometimes, perhaps.\n\n\nAnd perhaps there are particular stories, too, that are easier to understand and easier to remember because they align with the grain of thought; narrative archetypes like cause-and-effect, the Fall, the Hero's Journey.\n\n\nMaybe the root of narrative compulsion is that we see something occur, and the story that pops into our head is the 'cause-and-effect' one, we mistake the ease and fluidity of that story in our head for truth. We're fooled because \"it slips into place because the explanation fits reality\" is indistinguishable from \"it slips into place because the explanation is easy to understand with my brain.\"\n\n\nCognitive therapy works because it helps patients re-narrate their lives (quote source). Cybernetics was a cognitive therapy for science. We need help re-narrating the whole time, because the problem is this: obvious looks like true.\n\n\nJust as tricking a woman into unknowingly blushing fools her into thinking she's attracted to you.\n\n\nJust as you misread movie close-ups for your paying attention, and tension from loud noises as suspense.\n\n\nHere's one that happens a lot: the misidentification of understanding for original thinking.\n\n\nAnd another: the relief, the release of tension at the end of a story, the knowledge that phew it was actually going somewhere, and when it all wraps up and there's an indicator - a nod, a rhythm change, - that we're done... that release of narrative tension being misidentified as funny.\n\n\nHere's what my new hero, Steve Martin, has to say about being funny: What if there were no punch lines? What if there were no indicators? What if I created tension and never released it? What if I headed for a climax, but all I delivered was an anticlimax? What would the audience do with all that tension? Theoretically, it would have to come out sometime. But if I kept denying them the formality of a punch line, the audience would eventually pick their own place to laugh, essentially out of desperation.\n\n",
    link: "/home/2008/02/09/impro",
  },
  {
    title: "",
    date: "16.31, Monday 11 Feb 2008",
    content:
      "\nNext up: I've been to O'Reilly ETech since ETech 2002, and was planning to have 2008 off. But then I saw the sessions: tangible internet objects, the brain and society, activity-based interaction, crowds, social networks and warfare, PMOG, botnets, sex, Asian media, body hacking, Cuba, and more sex.\n\n\nSo I'm going, it looks to awesome to skip. See you in San Diego! Drop me a line if you fancy a beer.\n\n\nI'm canyoning first for a few days in Arizona.\n\n\nAlso coming up: I'm keynoting at GUADEC, the GNOME Users' And Developers' European Conference, in Istanbul in July. Not my usual turf I have to admit, but the brief grabbed me--I've been asked to speak about what you see the future of software being - desktop vs web app vs hybrid - and of course the kinds of things that you have on your mind which led to Mind Hacks. And how could I turn that down? I'm a sucker for a good topic.\n\n",
    link: "/home/2008/02/10/the_visual_cortex_of_developing_ferrets",
  },
  {
    title: "",
    date: "12.49, Friday 15 Feb 2008",
    content:
      "\nSome pictures:\n\n\nPhotos of 1960s London.\nIllustrations of the human body, illustrating conceptions from different cultures through history.\n1975: And the Changes to Come (1962), scanned.\n\n\nTorrentFreedom have built their service to never store any data which could be used for identification. In a pleasant turn of phrase, they call it structural anonymity: We built the system from day one so that there's no correlation between an IP+timestamp and a username - this means we can't hand over logs of 'who was on what IP at what time' ... Our payment system is fully abstracted from the operational environment - billing events are passed to the VPN engine via temporary 'tokens' that are one-way-factors ... we don't have 'server logs' like everyone else does ... all of our operational VMs run in fully-encrypted partitions.\n\n\nSpace smells metallic.\n\n\nThe law of unintended consequences is what happens when a simple system tries to regulate a complex system. See also, from cybernetics, the Law of Requisite Variety.\n\n\nJason Kottke has collected videos showing multiple time periods at once. He pulls a quote: But, we can kind of think of the multi-playthrough Kaizo Mario World video as a silly, sci-fi style demonstration of the Quantum Suicide experiment. At each moment of the playthrough there's a lot of different things Mario could have done, and almost all of them lead to horrible death. The anthropic principle, in the form of the emulator's save/restore feature, postselects for the possibilities where Mario actually survives and ensures that although a lot of possible paths have to get discarded, the camera remains fixed on the one path where after one minute and fifty-six seconds some observer still exists.\n\n\nI think of it somewhat like ray-tracing an interactive space. Each player is a ray of light fired into the black box of the game world, bouncing off interaction possibilities differently each time. The integral of all the consequences gives the shape of the interaction surface. Then perhaps a diagram can be produced. (It's only be looking at parallel universes side-by-side that the contingency of a particular event or counterfactual can be ascertained. That is, you can't know from a single game whether a move was 'hard' or 'lucky'.)\n\n\nAs video games get trickier to learn - because learning is fun - they'll hit a point where it's as fast to get good at real-life skateboarding than it is to get good in-game. What an odd singularity. The choice for the player then becomes, where can I find the best teacher?\n\n\nWhat would Richard Feynman do?\n\n",
    link: "/home/2008/02/11/next_up",
  },
  {
    title: "",
    date: "17.04, Monday 18 Feb 2008",
    content:
      "\nGetting older. From this to that and now here, I'm 30. In addition, my lightcone is two weeks away from Gamma Pavonis and some weeks ago enveloped its 45th star, Kappa-1 Ceti. Down to the forest where I grew up to celebrate, knotting off loop after loop.\n\n\nYou don't talk about the ingredients getting old when you make soup, you wait for the complexity to emerge. Two ingredient combine, and then there are three flavours. And they themselves recombine in all permutations and you have six plus three is nine flavours. And then they combine, and so on. Not getting older but simmering. Thirty years cooked.\n\n\nWhat have I learned? That I get a long way by assuming the other person is right and knows more than I do, and that I should always try to understand--I too often don't listen well enough. That everyone has something fascinating about them, and I'll never be bored so long as I'm trying to find the stories. But that some people are idiots; that took a lot of time to figure out. Always create. How I learn--that was a big one, and it's opened many doors. That hard work with my body is fun just like hard work with my head, and that both are better in combination. I wish I'd worked that out sooner. How to not be precious about what I write and how to collaborate.\n\n\nAnd then there are general, often contradictory life principles I've run on for years, and they're doing me very well thank you: be less tolerant; care more; care less; speak and do without thinking first, but consider afterwards; do what I want and if it's toxic, move on; don't avoid being wrong or foolish, and it's possible to be wilfully obscure, absurd and fib while simultaneously meaning every single word; everything is interesting.\n\n\nThe first chapter of Deleuze and Guattari's A Thousand Plateaus is Rhizome [pdf], and it includes this advice:\n\n\nWhere are you going? Where are you coming from? What are you heading for? These are totally useless questions. Making a clean slate, starting or beginning again from ground zero, seeking a beginning or a foundation-all imply a false conception of voyage and movement (a conception that is methodical, pedagogical, initiatory, symbolic...). ... move between things, establish a logic of the AND, overthrow ontology, do away with foundations, nullify endings and beginnings. ... The middle is by no means an average; on the contrary, it is where things pick up speed. Between things does not designate a localizable relation going from one thing to the other and back again, but a perpendicular direction, a transversal movement that sweeps one and the other away, a stream without beginning or end that undermines its banks and picks up speed in the middle.\n\n\nWrite to the nth power, the n - 1 power, write with slogans: Make rhizomes, not roots, never plant! Don't sow, grow offshoots! Don't be one or multiple, be multiplicities! Run lines, never plot a point! Speed turns the point into a line! Be quick, even when standing still! Line of chance, line of hips, line of flight. Don't bring out the General in you! Don't have just ideas, just have an idea (Godard). Have short-term ideas. Make maps, not photos or drawings. Be the Pink Panther and your loves will be like the wasp and the orchid, the cat and the baboon. As they say about old man river:\n\n\nHe don't plant 'tatos/ Don't plant cotton/ Them that plants them is soon forgotten/ But old man river he just keeps rollin' along\n\n",
    link: "/home/2008/02/15/some_pictures",
  },
  {
    title: "",
    date: "19.32, Monday 25 Feb 2008",
    content:
      "\nQuiet. Preparations for my upcoming trip have meant a race to the finish on several tasks, with the consequence that everything nonessential is being dropped to the wayside. This has led me to notice a third way I get things done:\n\n\nThe marathon: start doing a thing and continue doggedly doing it until it's done. I do this with books.\nThe leap: take a small step which forms an unbreakable commitment to doing the rest. This is how I started doing talks: once the abstract's published there's no way to not make a decent presentation without letting down a lot of people.\nPace: if an activity gets boring, switch immediately to something else. It doesn't matter what the activity is, so long as expressing it produces useful output. This is what I'm doing now.\n\n\nOne of my activities is reading Essential Cell Biology. (Yes, I regard reading which is not related to work as essential. And if I don't finish it before I go, I'll lose the tenuous understanding I need to complete it.) Reading about cell biology is reading the best whodunnit: we start with the cell working downwards - to proteins, metabolism, meiosis, ATP - and working up, to people. I'm beginning to hit the magical moments of the loop closing, where the top and bottom link up: oh, so that's why I eat!; oh, so that's what breathing's all about! The Krebs citric acid cycle, with the lead pipe, in the ballroom! And the denouement is life itself, there in-front and inside of me, while I'm reading on the Tube.\n\n",
    link: "/home/2008/02/18/getting_older",
  },
  {
    title: "",
    date: "02.24, Friday 29 Feb 2008",
    content:
      "\nBooks read February 2008, with date finished:\n\n\n\n\n\tAphrodite, Isabel Allende (4th)\n\n\n\tChristie Malry's Own Double-Entry, B. S. Johnson (9th)\n\n\n\tBreak Through: From the Death of Environmentalism to the Politics of Possibility, Ted Nordhaus and Michael Shellenberger (10th)\n\n\n\tThe Terminal Beach, J. G. Ballard (12th, r.)\n\n\n\tIn the Beginning was the Command Line, Neal Stephenson (13th)\n\n\n\tScience in Action, Bruno Latour (16th)\n\n\n\tt zero, Italo Calvino (19th, r.)\n\n\n\tThe Rituals of Infinity, Michael Moorcock (19th, r.)\n\n\n\tEssential Cell Biology, Alberts, Bray, Hopkin, Johnson, Lewis, Raff, Roberts, and Walter (26th)\n\n\n\tReading the Everyday, Joe Moran (27th)\n\n\n\tMatter, Iain M. Banks (28th)\n\n\n\nThere's been a smell, biochemistry and science theme: scent last month, then Aphrodite, Latour, Calvino and Essential Cell Biology. It's all felt a bit Powers of 10... not just from seeing the proteins behind the experience of taste and food, but reading straight-forward textbooks and simultaneously being aware the colossal energy and practice of science that went into producing facts.\n\n\nScience in Action is the stand-out book this month. I studied physics at college, and have had heated debates both with those who regard science as entirely a social construction and those who believe in big-s Science (as a process and as outcomes. Mainly people without a science background curiously). Latour is the first I've read to describe science as I've seen it, and to show in a single breath the complex interplay of humans and nonhumans. Superb.\n\n",
    link: "/home/2008/02/25/quiet",
  },
  {
    title: "",
    date: "17.50, Tuesday 4 Mar 2008",
    content:
      "\nSpeaking at ETech. I've snagged a last minute speaking spot today (Tuesday) at 16h55, in the Mission Hills room--I'll be rambling through ideas from science fiction and vaguely relating it to design (a toned version of this talk). Come along. (I gave a 5 minute science fictional tour of the Solar System yesterday, as part of the Ignite session. This will be similar.)\n\n",
    link: "/home/2008/02/29/books_read_february_2008",
  },
  {
    title: "",
    date: "18.11, Sunday 30 Mar 2008",
    content:
      "\nBooks read March 2008, with date finished:\n\n\nA Science Fiction Omnibus, Brian Aldiss (editor) (13th)\nThe Rubaiyyat of Omar Khayaam, Robert Graves and Omar Ali-Shah (translators) (13th, r.)\nThe Purple Cloud, M. P. Shiel (13th)\nA Lover's Discourse, Roland Barthes (15th)\nThe Worst Journey in the World, Apsley Cherry-Garrard (20th)\nThe Cognitive Style of PowerPoint: Pitching Out Corrupts Within, Edward R. Tufte (21st)\nRosencrantz and Guildenstern Are Dead, Tom Stoppard (22nd, r.)\nAntarctica, Kim Stanley Robinson (23rd, r.)\nWhat is History?, E. H. Carr (26th)\n253, Geoff Ryman (30th)\n\n\nGraves' fraudulent Rubaiyyat is breath-taking, as always. Cherry-Garrard, Carr, Stoppard and Ryman are also happy additions to this month's reading. But Barthes' Lover's Discourse is an observed and poignant pattern language of love. Recommended.\n\n",
    link: "/home/2008/03/04/speaking_at_etech",
  },
  {
    title: "",
    date: "13.41, Tuesday 1 Apr 2008",
    content:
      "\nThings are not good. Staying undercover for a bit, back later perhaps.\n\n",
    link: "/home/2008/03/30/books_read_march_2008",
  },
  {
    title: "",
    date: "13.41, Thursday 1 May 2008",
    content:
      "\nBooks read April 2008, with date finished:\n\n\nArcadia, Tom Stoppard (1st)\nAdventures in Pataphysics, Alfred Jarry (3rd)\nHarmonograph: A Visual Guide to the Mathematics of Music, Anthony Ashton (6th)\nSocial Intelligence: The New Science of Human Relationships, Daniel Goleman (11th)\nExploits & Opinions of Dr. Faustroll, Pataphysician, Alfred Jarry (13th)\nThe Child Garden, Geoff Ryman (15th)\nMichael Rosen's Sad Book, Michael Rosen and Quentin Blake (15th)\nThe Lathe of Heaven, Ursula K. Le Guin (18th)\nWorld War Z: An Oral History of the Zombie War, Max Brooks (20th)\nCybernetics, Second Edition: or the Control and Communication in the Animal and the Machine, Norbert Wiener (22nd)\n\n\nArcadia's deeper than I remember. Wow. Harmonograph has taken me on a journey. Jarry's books, I have no idea what's going on - I don't even know if I enjoyed reading them - but they've wriggled deep inside my brain and changed me more than most other books I've read in the last couple years. Valuable ammunition in the assault on cause and effect. World War Z is very close to the stand-out book this month. A great zombie novel didn't need to be told as a retrospective oral history from multiple perspectives, but Brooks did it, and my goodness I haven't encountered a book so impossible to put down for a long time. I'm not kidding: I couldn't sleep with that book unfinished on the floor, and picked it up and held my eyelids open until it was done.\n\n\nBut I try to recommend only one book a month. Read Rosen's Sad Book. Sigh.\n\n",
    link: "/home/2008/04/01/things_are_not_good",
  },
  {
    title: "",
    date: "16.03, Monday 26 May 2008",
    content:
      "\nThe Geometry of Music: the cosmos of chords consists of weird, multidimensional spaces, known as orbifolds, that turn back on themselves with a twist.\n\n\nDmitri Tymoczko has created several movies of orbifolds. It's impossible, watching Chopin visualised on a Mobius strip, not to anthropomorphise the chord components, ballroom dancing around one another, the tension in the music building and held as the partners move apart, and harmonious closure achieved when they move together.\n\n\nThen, watching Chopin in 4-dimensional space, I get confused with melody making in Super Mario Galaxy, where the level-select screen responds to the cursor with changes in the ambient music, and so you can use it as an instrument.\n\n\nCause and effect are confused. Which comes first, the visualisation or the music? If Tymoczko watched a partner and I dancing, could he interpret the plan view of the ballroom as an orbifold, run his algorithms backwards, and play generated Chopin that was magically in sync with our improvisation?\n\n\nMichel Gondry's video for Around the World (Daft Punk) is the greatest ever made. The dancers move into and out of the video as the parts of the music they represent. The circular stage allows loops in the music to show up in the choreography.\n\n\nGondry's commentary; the making of Around the World.\n\n\nAnd just as, finally, the blurring of music and representation Gondry further explored with Star Guitar seem to be making their way into generated music visualisations, in five years time we'll see 3d avatars auto-generating visualisations as complex as the 1997 Around the World video.\n\n\nAnd five years after that, our dancing in clubs will alter the music which will alter our dancing, and the music and the visualisation/dancing will be translations of one another, and no way to tell which is first, because none is.\n\n\nThe Super Mario Galaxy orchestra recording Gusty Garden level soundtrack.\n\n\nSo let's let go of cause and effect as an explanatory framework. It never existed anyway, it was just easy. Let's demonise people who believe in it.\n\n\nCausist people think things happen for a reason. If you make a causist, dirty causist, encounter some phenomenon, they'll point at some proceeding event or circumstance as if a. that caused the thing, or b. that explains it.\n\n\nExplaining can't be done by looking at the past. The past is dead, filthy causist. If you try, the past retroactively becomes a series of events that were occurring towards a goal which, at the time, they are not. Explanations are to exist solely and entirely in the present, or not at all.\n\n\nWell then, explanations are now no longer causes but networks of mutual contingencies. We can look at explanations not as predictions, but as chords that have reached closure. Seeing an explanation, we can feel relief that the world is at one.\n\n\nTo explain a thing is to tell the story of a lattice of things and events. To narrate a crystal.\n\n\nSometimes. Explanations dance around one another. Closure is never reached entirely, and that's why phenomena unfold like music. So mostly explanations are not complete, in which case almost every event - every note - is an exception.\n\n\nCausists, dirty causists, filthy causists, are unable to see that the world is almost entirely exceptional.\n\n",
    link: "/home/2008/05/01/books_read_april_2008",
  },
  {
    title: "",
    date: "16.57, Sunday 1 Jun 2008",
    content:
      "\nBooks read May 2008, with date finished:\n\n\n\tIslamic Design: a Genius for Geometry, Daud Sutton (3rd)\n\tFoucault's Pendulum, Umberto Eco (5th, r.)\n\tWild Palms, Bruce Wagner and Julian Allen (7th, r.)\n\tPatterns, Drusilla Cole (9th)\n\tUnder the Skin, Michael Faber (10th)\n\tEarth Abides, George R. Stewart (11th)\n\tPsychogeography, Merlin Coverley (11th)\n\tThe Wild Palms Reader, Roger Trilling and Stuart Swezey (13th, r.)\n\tIncandescence, Greg Egan (17th)\n\tFrom Atoms to Patterns, Lesley Jackson (17th)\n\tUnderstanding Material Culture, Ian Woodward (30th)\n\tAnnals of the Former World, John McPhee (31st)\n\n\nThe books on patterns have been inspirational, as was Woodward which has opened up new ways of thinking for me. But I unreservedly recommend Annals of the Former World which is geological in topic, size, and narrative form. Astounding and volumetric.\n\n",
    link: "/home/2008/05/26/the_geometry_of_music",
  },
  {
    title: "",
    date: "17.48, Monday 2 Jun 2008",
    content:
      "\nLet me speak seriously for a moment. As my parents die and my grandparents die, I feel progressively cut adrift. They precede me. They tethered me to the past, to the bedrock behind. We see the world in fives: two generations back, our children, and our children's children, and ourselves. Time is a little planet with close horizons. I find myself in the middle generation, almost cut loose with a single rope now. Let go. And it's my job to carry the torch and god help me if I stumble, because I'm it now, those towering experiences behind me have passed the baton on, and that's the burden of the middle. I don't have children and until I do it's a marathon to the far shore, a hard march every step hard won, to clasp hands finally with the next generation who will clasp hands with the next, and they'll steady me, I'll have done my job and I'll be pulled along to the future.\n\n\nI know a fellow who met a fellow whose mother makes garden gnomes, and when his father died, his mother made a gnome out of the ashes and she keeps it in the front garden of the family home.\n\n",
    link: "/home/2008/06/01/books_read_may_2008",
  },
  {
    title: "",
    date: "07.46, Tuesday 10 Jun 2008",
    content:
      '\n"The source of a diamond is a kimberlite pipe, a form of diatreme--a relatively small hole bored through the crust of the earth by an expanding combination of carbon dioxide and water which rises from within the earth\'s mantle and moves so fast driving magma to the surface that is breaks into the atmosphere at supersonic speeds. Such events have occurred at random through the history of the earth, and a kimberlite pipe could explode in any number of places next year.\n\n\n"...\n\n\n"There is a layer in the mantle, averaging about sixty miles below the earth\'s surface, through which seismic tremors pass slowly. The softer the rock, the slower the tremor--so it is inferred that the low-velocity zone, as it is called, is close to its melting point. In the otherwise rigid mantle, it is a level of lubricity upon which the plates of the earth can slide, interacting at their borders to produce the effects known as plate tectonics. The so-termed lithospheric plates, in other words, consist of crust and uppermost mantle and can be as much as ninety miles thick. Diamond pipes are believed to originate a good deal deeper than that--and in a manner which, as most geologists would put it, "is not well understood." After drawing fuel from surrounding mantle rock--compressed water from mica, in all likelihood, and carbon dioxide from other minerals--the material is thought to work slowly upward into the overlying plate. Slow it may be at the start, but a hundred and twenty miles later is comes out of the ground at Mach 2. The result is a modest crater, like a bullet hole between the eyes."\n\n\n--Annals of the Former World, John McPhee.\n\n',
    link: "/home/2008/06/02/let_me_speak_seriously",
  },
  {
    title: "",
    date: "21.14, Thursday 26 Jun 2008",
    content:
      "\nInteresting08, last weekend, was seriously tremendous. I spoke for a little bit, and my slides are now online.\n\n",
    link: "/home/2008/06/10/the_source_of_a_diamond",
  },
  {
    title: "",
    date: "15.50, Wednesday 2 Jul 2008",
    content:
      "\nBooks read June 2008, with date finished:\n\n\nWhen the Body Becomes All Eyes, Phillip B. Zarrilli (4th)\nFrom Counterculture to Cyberculture, Fred Turner (20th)\nStars in My Pocket Like Grains of Sand, Samuel R. Delany (22nd)\nA New Philosophy of Society, Manual DeLanda (26th)\nThe Periodic Table, Primo Levi (29th)\n\n\nI'm a huge fan of DeLanda. I find his language and the concepts useful operators in thinking about work and life in general. But this is my second run at A New Philosophy and while assemblage theory hits home hard, I sense that he plays fast and loose with his examples without moderating his language to compensate. That makes it hard for me to take as seriously as I'd like.\n\n\nFrom Counterculture to Cyberculture tracks Stewart Brand's rather Count de Saint-Germain existence through the significant events of the latter half of the 20th century. I enjoy this kind of history, and in particular I have a hobby interest in the central role of cybernetics over the last 60 years in the making of the modern world; Turner did not disappoint.\n\n\nThis month my single recommendation is Levi, if only because he tells personal, far-reaching stories, and then drops in lines like man is a centaur, a tangle of flesh and mind, divine inspiration and dust.\n\n\nCertainly, I am a centaur.\n\n",
    link: "/home/2008/06/26/interesting08",
  },
  {
    title: "",
    date: "22.54, Wednesday 2 Jul 2008",
    content:
      "\n#3books. I asked people on Twitter, earlier today, to share the 3 most recent books they've read. Here are mine; you can join in by adding '#3books' to your message. The responses are brilliant: you can read them at both at Summize and at Twemes (neither site gets the full collection unfortunately). Thanks all for playing! That's my reading list for the next 6 months sorted out.\n\n",
    link: "/home/2008/07/02/books_read_june_2008",
  },
  {
    title: "",
    date: "09.43, Thursday 3 Jul 2008",
    content:
      "\nTwo kinds of training: respondent conditioning is when you perform two events simultaneously so the subject confuses cause and effect. So think of Pavlov and his dogs: the dogs salivate when he gives them food, and then he rings a bell whenever he gives them food and the dogs get used to that. Or rather, they get conditioned to that. Then they confuse cause and effect and end up salivating whenever the bell rings, whether the food comes or not.\n\n\n(Pavlov cut the dogs' throats to find this out. His theory of conditional reflexes dominated institutional Soviet thinking for decades, in part leading to both the Soviet rejection of cybernetics and their late development of computers, and also to Lysenko rejecting Mendelian genetics. Lysenko directed farm policy under Stalin, and his misguided theory of agrobiology led to mass crop failure and starvation.)\n\n\nAnother kind is operant conditioning. It relies on consequences after the event to produce conditioning, and it's more suitable for voluntary behaviour. It's what they use on dolphins.\n\n\nThere are a few types: you can give a reward for good behaviour; you can remove pain for good behaviour; you can actively punish bad behaviour; you can remove a pleasant stimulus when bad behaviour occurs.\n\n\nIf you give me a biscuit every time I make you tea, I'll likely make you more tea.\n\n\nThe most powerful form is variable-interval reinforcement. That's when the reward doesn't happen every time, and you end up working harder to get it. It's as if you're trying to figure out the pattern, to get the reward to come more often. It's why email is addictive: you hit that 'get mail' button and get your reward, but not always, just sometimes, and that conditions you into checking more and more.\n\n\nOne weird thing that happens, in operant conditioning, is the extinction burst. There's a nice example I read, I don't recall where, about elevators. Imagine you live on the 10th floor and you take the elevator up there. One day it stops working, but for a couple of weeks you enter the elevator, hit the button, wait a minute, and only then take the stairs. After a while, you'll stop bothering to check whether the elevator's working again--you'll go straight for the stairs. That's called extinction.\n\n\nHere's the thing. Just before you give up entirely, you'll go through an extinction burst. You'll walk into the elevator and mash all the buttons, hold them down, press them harder or repeatedly, just anything to see whether it works. If it doesn't work, hey, you're not going to try the elevator again.\n\n\nBut if it does work! If it does work then bang, you're conditioned for life. That behaviour is burnt in.\n\n\nOr a baby, crying to get attention, will have one last huge attempt to get attention before learning that tactic isn't going to work.\n\n\nI have a friend - again I can't remember who - who saw a talk from a fellow who trained dolphins - and I don't remember why or where - and he mentioned this extinction burst. You trail off the fish rewards for leaping through the hoop, and let extinction occur, and then when the extinction burst happens - you know, the dolphin is trying everything it knows, going crazy trying to get you to notice it and feed it fish - bang, that's when you get in with the big reward and there you go, the dolphin's hooked.\n\n\nAnyhow.\n\n\nIt strikes me that dating, when successful, may produce operant conditioning.\n\n\nIt also strikes me that some people may have personalities that naturally produce operant conditioning to certain behaviours in the people around them, simply by acting with exactly the right balance of predictable/erratic or aloof/intimate.\n\n\nBack to dating. It would naturally be most successful if a couple condition one another reciprocally. And it makes me wonder: could this be routinized? Or rather, could this be a pattern followed deliberately? And if so, could that be a product, for sale?\n\n\nI don't believe that knowing the conditioning was occurring would interfere - my muscles still develop at the gym even though I'm working them artificially - but it would have to be done carefully.\n\n\nHow could you produce this artificially? I'm not sure how. Maybe a pattern of dates where one partner or the other is instructed not to show, almost at random? A system which means all communication is mediated through something which is unreliable, so it occasionally drops calls--and then that system is manipulated in order to produce the extinction, the extinction burst, and eventual pay-off?\n\n\nThat is: a couple dating should have available manufactured, reciprocal, variable-interval operant conditioning, with a pay-off timed to the artificially produced extinction burst, to trigger mutual addition, and they should be able to buy this in a shop.\n\n\nIt's an interesting design challenge. Here are my criteria: it has to be adopted knowingly by both parties (so no Rules of Seduction games); it has to be reciprocal and involve as little technology as possible; it has to be productisable--that is, it can't be the side-effect of another system: it has to be able to be actually or virtually packaged up and sold. And the usual product rules also apply: how are people going to understand and discover it; does it fit with natural flows (like, if the communication is mediated, won't they just swap phone numbers and use those instead, because it's easier); do all the halting states have ways out; how does use of this product act to expand the market for this product. Other than that, it's all open.\n\n\nI am aware that talking like this makes me sound like a sociopath.\n\n",
    link: "/home/2008/07/02/3books",
  },
  {
    title: "",
    date: "08.51, Thursday 7 Aug 2008",
    content:
      "\nBooks read July 2008, with date finished:\n\n\nThe Possibility of an Island, Michel Houellebecq (4th, r.)\nOn Deep History and the Brain, Daniel Lord Smail (10th)\nStand on Zanzibar, John Brunner (26th)\nCity of Quartz, Mike Davis (31st)\n101 Things I Learned in Architecture School, Matthew Frederick (31st)\n\n\nIf, like 2007, I want to read 104 books this year, I should've hit 61 by the end of July. I made 62, but I'm not making so much time for it right now so we'll see what happens.\n\n\n101 Things got my brain fizzing and has given me language for ideas I've not been able to articulate before. But this month (I like to recommend one book a month), Stand on Zanzibar is well worth your time: it's a collage of quotes and narrative, out of which a story about an over-populated world slowly emerges. It's like watching a cloud form, or walking past Quantum Cloud.\n\n",
    link: "/home/2008/07/03/two_kinds_of_training",
  },
  {
    title: "",
    date: "10.20, Tuesday 19 Aug 2008",
    content:
      "\nLightning turns the sky into graph paper. L-- shouts 'this way,' and his bright eyes target me with reflected horizontals and verticals. The thunder plays four/four in my gut. We trip on curbs and scrape along walls, running - ricocheting - down narrow city lanes. There's a deeper sound, God making a plosive, the opening of whale song, and then light, and I realise it's another negentropy bomb, on the next street. Nothing for a second. In the gloom the city looks identical but raised to a higher octave. Potential. 4. 3. 2. 1. Then the world exhales and drops into regularity. A creak as the building next to us attempts to adjust to the sudden order imposed on its far side. The crystal structure spreads, architecture aligning, physics gentrifying, roads straightening, square paving slabs unfolding from one another. Another creak and a slump this time, L-- is caught in dust and rubble. I crouch over him; there's blood on my hands as I hold his head and the lightning is the same shape as his body. 'They're homogenising us out of existence,' he says. His teeth are red. 'Find the Deterritorial Army. Tell them the layers of emergence are becoming too tightly coupled. Tell them objects are no longer sufficiently mobile on the substrate. Don't wait.' It smells of wet brick; mysteriously I think of ferns. L--'s blood is thickening into hexagons. I turn and run.\n\n",
    link: "/home/2008/08/07/books_read_july_2008",
  },
  {
    title: "",
    date: "10.04, Saturday 30 Aug 2008",
    content:
      "\nBooks read August 2008, with date finished:\n\n\nMidnight's Children, Salmon Rushdie (9th, r.)\nEnder's Game, Orson Scott Card (14th, r.)\nThe Black Swan, Nassim Nicholas Taleb (15th)\nBody of Glass, Marge Piercy (16th)\nThen We Came to the End, Joshua Ferris (17th)\nWays of Seeing, John Berger (20th)\nEnvisioning Emotional Epistemological Information, David Byrne (23rd)\nThe Compass Rose, Ursula K. Le Guin (23rd, r.)\nHow Buildings Learn, Stewart Brand (26th)\nAn Introduction to Cybernetics, W. Ross Ashby (27th)\nEssays in Love, Alain de Botton (27th, r.)\nSubspace Explorers, E. E. 'Doc' Smith (30 August, r.)\n\n\nI read a lot or a little when I'm feeling glum, and this month I read a whole bunch plus there was some travelling. (For those of you keeping count, this means I need to average 7.5 books/mo. for the rest of the year. So if I'm lagging behind in November, look for me to instigate a personal crisis or two to get the reading rate up. You have been warned.)\n\n\nThe Black Swan points out that big, rare events dominate continuous trending (50 years of stockmarket movement is mostly accounted for by 10 days), and that you should put yourself in positions where black swans - when they do occur - will be positive. A good framework. Ashby's 1956 Introduction to Cybernetics is a straight-forward argument from one end of cybernetics to the other: enough to see why it was believed to hold so much promise. There are foreshadowings of both the inevitability of order (autocatalytic loops) and selfish gene ideas in there, which shows how much was nascent in that early crystal seed.\n\n\nI've had David Byrne on my to-read list since the book came out, and I can't believe I waited. Intelligent art and wise words: the cake results as least as much from the shape of the pan, the cooking and the timing than from its ingredients. Ways of Seeing is also enlightening and brilliantly designed.\n\n\nThere's nothing in this month's reading I'd shy away from recommending if it took your fancy--we'd be able to have a good chat about it whatever you picked up. Le Guin's short stories are actually better than I remember; both Piercy and Ferris I couldn't put down; Doc Smith's space opera is pacier even than his subspace drives; and although Essays in Love seems a little childish now, and the protagonist is a dick, love is childish, and we are all dicks. Well, I am.\n\n\nOkay, but I need to recommend one book and it's between Byrne and Berger. I'm going to say Berger's Ways of Seeing because it's rescued art for me and given me a way into a new world.\n\n",
    link: "/home/2008/08/19/lightning",
  },
  {
    title: "",
    date: "17.02, Wednesday 3 Sep 2008",
    content:
      "\nIn the Sweat-Shop: I ran across this excerpt in Heim's biography of John von Neumann and Norbert Wiener. It's the first stanza \"In the Sweat-Shop,\" from Leo Wiener's translation of the Yiddish poems of Morris Rosenfeld.\n\n\n\nThe machines in the shop roar so wildly that \noften I forget in the roar that I am; I am \nlost in the terrible tumult, my ego disappears, I \nam a machine. I work, and work, and work with- \nout end; I am busy, and busy, and busy at all time. \nFor what? and for whom? I know not, I ask not! \nHow should a machine ever come to think? \n\n\n\nIt reminds me how the processes that surround us drown and re-cut us.\n\n\nThe collection is online: Songs from the ghetto (1898).\n\n",
    link: "/home/2008/08/30/books_read_august_2008",
  },
  {
    title: "",
    date: "17.02, Saturday 6 Sep 2008",
    content:
      "\nHyperlinks are blue which is the colour of sky, of potential. The @ symbol looks like a whirlpool, the mouth of a wormhole. A rabbit hole we fall through. This is the internet.\n\n",
    link: "/home/2008/09/03/in_the_sweat_shop",
  },
  {
    title: "",
    date: "13.00, Saturday 13 Sep 2008",
    content:
      "\nVolition\n\n\nWhen I was young my family included Indigo, a golden retriever with his own towel and a wide smile. I would sit and watch him as he lay sprawled with his chin on one leg, staring into the middle distance. Suddenly he would leap to his feet and trot, tail wagging, a few paces before hurling himself at the carpet, twisting as he did so to roll and throw himself around and generally have a good old time right there in the hall. What was it Indigo, hey? What did you see, did you see a ghost who said -Come play? Why that moment, hey boy? Just as quickly he would stand and shake himself down, and come back to his spot near the kitchen where I could see him and he could see me, and I'd be laughing. Where did it come from, that abrupt desire for play? How come that exact second for decanting some of the internal flywheel into rolling about with his belly in the air and legs waving? It reassured me that I couldn't see any cause, that it was something inside. It meant Indigo had his own internal life, and so I could love him more.\n\n\nNewly single I sit at the table in my flat, shuffling papers, wondering how I'll know what to do next, and wishing I could be like Indigo. I drink water because I'm thirsty; I pack because tomorrow I fly to Oslo.\n\n\nI was 10 years, 9 months, 3 weeks and 3 days old the day they activated the Large Hadron Collider. I was at college in a lecture the day I found out they'd found the Higgs boson, which gives particles mass. Mass gives momentum, and momentum is what keeps you moving. The Higgs is where it comes from:\n\n\nthe universe is a house, and you're a particle - let's say a proton - and the house is packed full of ghosts, from wall to wall like a carpet, and from foundations to rafters like roaches. You're dancing in the ballroom - there's a ballroom in this house - and as you dance the ghosts tap at your arm and tug at your collar and rest their hands on your shoulder. You turn for a second to see who it is, but the face of the ghost is hard to make out, and besides the ghosts are restless so it has already mixed back into the crowd, and perhaps there aren't any ghosts anyway - you've had a few glasses of wine after all, maybe you're imagining things - but that aside, it means that your otherwise smooth dance is slowed and shaped by the constant contact of a million touches.\n\n\nThe ghosts are Higgs bosons, which fill the universe so they slosh over the sides, and the contact they have with particles - like you and me - as they pass by is what we see as mass.\n\n\nThe lecture that day was one on particle physics, and Dr L-- came into the hall with a grin and bright eyes.\n\n\n-Gentlemen! he said. He always called us gentlemen, whatever the mix.\n\n\n-Gentlemen, your notes are out of date! My colleagues at Cern let me know this morning. On slide, uh, 20 from last week, where we declared the existence of the Higgs boson was unknown, well that's no longer the case. We have it.\n\n\nIt shouldn't have hit me so hard. We assumed the existence of the Higgs, or something like it, in most of our mathematical models. But to have it confirmed! It didn't need to have come out this way: there could have been a field that created mass, like an electromagnetic field, covering the universe. Or each particle could carry within itself mass, just like charge or spin.\n\n\nBut to have it confirmed... it wasn't right that mass was an external quality, I was thinking, it belonged inside. I felt violated, like someone had knocked me to the ground and emptied my pockets. I walked up the Banbury Road with my head in turmoil, each iron bar on each iron fence looked empty to me, each paving slab on the ground looked hollow, and I eyed the so-called empty air with suspicion for hoarding mass to itself, for withholding the Higgs from me.\n\n\nIt's funny how these things hit you.\n\n\nThe way you show the existence of just one of these ghosts is you stop dancing and you barrel across the dance floor as hard as you can, shouting and roaring, barging ghosts and dancers alike hither and thither, scattering them and knocking them flying. If you get it just right, you splash a clearing in the ghosts, and if you're luckier still there's a moment before they get to their feet where you can grab one, sit on his chest and hold him down by his neck and grab his chin so you can wrench his dirty face round to look straight at yours and lean in real, real close and, panting, whisper straight at him through your gritted teeth: you little fucker: gotcha.\n\n\nPost-doc I studied the origins of volition.\n\n\nIt's not enough to know that Higgs makes things slow down. What makes 'em move to begin with? Okay, so this proton dances with that proton and that's why that one moves... but why was the one before that moving? And the one before that? And the one before that?\n\n\n-You're obsessed with work, you said, the day my paper outlining the experimental procedure for isolating volition was published. -Why do we never do anything?  (That was the first time. I was at my computer, watching comments and cross-linkings appear on arXiv as my ideas rippled across the community. Physics changes fast when it wants to.)\n\n\nWith hindsight I see you were right. I didn't know how to do anything but work, anything but respond to comments and questions. But it was also unfair: we were as active as any other couple, popular round the faculty and taking full enjoyment from the art and music that sticks to any town with a population of students. We scoured the event sheets for unusual plays and exhibitions in new gallery spaces.\n\n\nMaybe that slipped. The questions to field more than filled the day, as the detector moved closer and closer to coming online.\n\n\nThe ghosts that fill my head can be scattered and isolated, briefly and with much effort, and I can hold one down and recognise his face: my father, say. My very own Higgs; these are the things that join me to the world.\n\n\nVolition strings, if they exist, are the faintest of the faint to see. We have to look for the ragged ends of the superstrings that comprise the real substance of the universe. Most strings exist in knotted loops, which are particles. Some strings, after the Big Bang, had their loops severed and the ends of these thrash around like the end of a hose with the water turned full on. They whip, their ends moving at light speed and their middles faster still, although it's impossible to ever detect those except indirectly.\n\n\nThe open ends of volition strings, when they touch a particle - which is rare and fleeting - impart it some unpredictable shove. They push it into a new orbit. And so: movement.\n\n\nSeeing this in action is what the detector is for. The detector is lined up such that the cut-off end of the volition string will pass through the distant star σ Octantis, which is dense and should slow it just a little, and then through the Earth, which should slow it just a little more and focus it, and then we have our detector placed flat, facing down, in the Arctic Circle of Norway looking through the rock and the mantle and through the core, and we use the entire planet as a kind of lens, and we look close, and we hope we see a twitch in the fabric of the cosmos. Volition.\n\n\n-You're inert, you said, there's been a year of trying, and we agreed it was best if we parted, and as to whether this decision was right - it has to be said - I numbly say it was. That was three months back.\n\n\nBut you're going to be there in Tromsø, in the calibration and operations team, as the detector is activated, and in three days we'll see one another again.\n\n\nI'm here because I first suggested a form of this experiment in a paper years ago, a kind of honoured guest except that the details have been refined and revised by hundreds of physicists and mathematicians since. We crowd round the screens, and although really there's no need for personal presence these days, it's a happy moment to be in, with my fellow hunters. I think of Indigo and my father and Dr L-- and you and I see my life as a careering country dance, passed from one hand to another, swung from person to person, kept moving in do-ci-dos up and down and round and round. Somehow I'm standing behind you and, as the lens cap comes off - the culmination of my work - I find myself unable to think of anything so much as the nape of your neck just ahead of me, and it would be the work of a second to rest two fingertips gently on its soft concave curve; and I fancy that the end of a volition string passes right through me, skewers me from my head through my soul itself, or maybe volition is inside me all along and I just need to grasp it, to fan its spark to life, and I understand that what I'm facing now is a decision: to connect or to not connect, that there is no default choice, there is no momentum or inertia or carrying on as you were before; that every millisecond is a choice, an opinion, an act, and it can't be avoided because volition fills us, floods us, drowns the ghosts: and I look at your neck, and my hand, and I have a choice to make.\n\n",
    link: "/home/2008/09/06/hyperlinks_are_blue",
  },
  {
    title: "",
    date: "11.17, Tuesday 30 Sep 2008",
    content:
      "\nBooks read September 2008, with date finished:\n\n\nThe Very Slow Time Machine (1979), Ian Watson (7th)\nThree Men in a Boat (1889), Jerome K. Jerome (10th)\nThe Non-Statistical Man (1965), Raymond F. Jones (13th)\nSignal to Noise (1992), Neil Gaiman and Dave McKean (15th, r.)\nJohn von Neumann and Norbert Wiener: From Mathematics to the Technologies of Life and Death (1980), Steve J. Heims (18th)\nRiders of the Purple Sage (1912), Zane Grey (22nd)\nThe Haunted Stars (1960), Edmond Hamilton (23rd)\nSpacehounds of IPC (1947), E. E. 'Doc' Smith (24th, r.)\nThe Futurological Congress (1971), Stanislaw Lem (25th)\nDiaspora, Greg Egan (28th, r.)\n\n\nThis month I've also picked up an original 1955 printing of the Rand Corporation's A Million Random Digits with 100,000 Normal Deviates (which will go with my copy of Ulysses - with the words rearranged in alphabetical order - from Simon Popper's Borromean), and a reprint of 507 Mechanical Movements, but neither of those I'll read so they won't be included here.\n\n\nIt's been a month of sci-fi and Westerns (I've been watching a bunch of films too), which has left me dreaming of clear blue skies, long clear vistas, desert scrub, C beams glittering in the dark near the Tannhauser gate... I'm not kidding, this is manifesting as a heart-breaking yearning, a pining for frontiers and wide-open scale. I really don't know how to deal with it.\n\n\nSo Zane Grey was magical, and it's incredible to see the Western being written for the first time--the seed that turns into a genre. Egan's Diaspora was as poignant as the first time I read it: the hardest of hard sci-fi that delves into what it means to be human and opens it way, way up. The universe is a lot bigger after I finish reading that book. Ian Watson I'm pleased to have discovered as a sci-fi author: his stories have ideas I've read nowhere else, and I'm happy to find he has a large back catalogue to work through.\n\n\nLem was hilarious (oh and, like the best satire, true. Or was it the mascons telling me the book was good?); Jerome was also hilarious--it had me laughing out loud, so rare.\n\n\nHeims' double bibliography of Wiener and Neumann paints the characters and context of early cybernetics, and in that way sits as a great companion piece to his later book Constructing a Social Science for Postwar America: The Cybernetics Group, 1946-1953. But here's the thing: you also get a picture of Wiener's humanity (and the surprising humanity in cybernetics), and the horrendous contingency of the Cold War and the arms race, which appears to have rested heavily on one of the quickest and most convincing minds of the the 20th century - Neumann - understanding people like machines, refusing to have faith in humanity, and being a warmonger. Heims makes a powerful case for a science better embedded in society, and produces this marvellous quote from Paul Goodman:\n\n\nWhether or not it draws on new scientific research, technology is a branch of moral philosophy, not of science.\n\n\nRecommended.\n\n",
    link: "/home/2008/09/13/volition",
  },
  {
    title: "",
    date: "10.16, Tuesday 4 Nov 2008",
    content:
      "\nTwo days ago, Sunday, I joined the Tate as a member to get access to their Members Room to have somewhere to sit to read my book and have a coffee. The cheesecake there is pretty good. I was looking out onto the river. I rarely see London from the side, and it was strange being six storeys up to not see the buildings looming up or from above, as from a plane, and not closing in on me but, as I say, from the side and set back from me somewhat, across the water.\n\n\nI think it's good for the soul of a city to be able to take itself in, and that's something that Brighton can do, looking back on itself from the beach and the pier, and that San Francisco does very well, from above and across, but London cannot and in consequence often feels like an ant hill, with all of us the ants. When I am in London, I am inside it, in its belly. I cannot take it in. From the side I am not high up enough to look down on the city as a map, so I see London as a collection of buildings and cars and people, at a human scale, and with a little distance I am able to appreciate it, to study it. To apprehend London. It's a rare view, the one from the side.\n\n\nThe water and the sky and the buildings had, because of the lowness of the sun and the overcastness of the clouds, the same flatness of illumination and the same quality of colour, blue brown green. The Thames itself was highly reflective and it was possible to see the dark blue tint of the sky, but look through that and beyond it had no translucency, not even a little, so it looked like oil and moved like oil too: not just choppy (which it was) but rippling too so between every wave was another wave, and so on. The Thames was over-full, brimming, and the waves moving slowly as if the water was heavier today, or the air was thick, or gravity different in some way.\n\n\nI understand that young people have translucent skin and so, in the light, they appear to glow, light reflecting from multiple depths of the skin simultaneously so their outer shell appears to fluoresce. The skin of adults is opaque, like old plastic.\n\n\nPiercing through these three, the water, sky and city, was the reflection of the setting sun on a building, a blinding orange light smeared out and organised into a grid by the window. And on the river was an upright mirror the size of a billboard, on a raft and tethered, bobbing, glinting white then black, the waves speaking in Morse.\n\n\nIt reminds me of the last time I sat watching the Thames, waiting for a friend near the Oxo Tower, and again seeing London from the side. This time the river was flowing fast, and the clouds were moving fast, and the distances involved in both were such that I could see continuous parallax: those parts nearest to me moving quickest, and those furthest moving slow. And birds flew past me, and people walking and cycled past me in both directions, and boats went along the river, and overall there was a sense that everything in my visual field was horizontal; that everything was moving sideways today; that I might be on a conveyor belt.\n\n\nRed on Maroon Mural, Section 2\n\n\nAfter the Members Room I went to the Rothko exhibition, which runs until 1 February 2009.\n\n\nThere's something about Rothko's painting, especially a few of those in room 3, which means they operate somewhere different from other art. The interventions Rothko makes on the fields of colour are of the same order as the interventions my perception system makes, the way my subjectivity changes my perception, and the way the light and quality of the canvas changes as I move my eyes, my head and my body around the room. It becomes impossible to disentangle these influences, to know whether it is me or Rothko responsible for what I am perceiving and thinking. My reactions to the pieces in room 9 were of looking over a landscape: the heavy blacks at the top drew my head up, and the level of the horizon made me feel as though I was looking from a hill over a large plain abundant with life, or lying flat on the ground, or up at heaven. I was elated or deeply depressed. From where did this come? It humbles me. When David Markson writes, he's not writing the words, but writing instructions to author the thing that appears between the paper and my brain, which is brought into being and constructed by the act of reading. I cannot author on this level. Rothko was not painting canvases, but a structure held halfway between us: a delicate structure constructed by him and me both, where the art insists on me a certain context or emotion, causing me to feel the room around me he wants me to feel and to think thoughts felt as my own; simultaneously mirroring and leading me, like dancing, like speaking with a highly charismatic person, or really good sex when you can't tell whether it's you or your partner anticipating or actually something that is mutual and happening between you and outside you. Rothko's art is transcendent. I was enraptured. There were fireworks in my soul.\n\n",
    link: "/home/2008/09/30/books_read_september_2008",
  },
  {
    title: "",
    date: "11.09, Tuesday 4 Nov 2008",
    content:
      "\nBooks read October 2008, with date finished:\n\n\nOn the Road, Jack Kerouac (1st)\nThe Embedding, Ian Watson (7th)\nThe Mightiest Machine, John Campbell (11th)\nThe Three Stigmata of Palmer Eldritch, Philip K. Dick (17th)\nThe Collapse of Complex Societies, Joseph Tainter (20th, r.)\nThe Cyberiad, Stanislaw Lem (23rd)\nA comprehensive review of the extraordinary new technology of Information, Scientific American (29th)\nTales of the Night, Peter Høeg (30th, r.)\n\n\nIt's to be noted that 63% of the books I read this month have titles that begin with \"The\" compared to only 29% for 2008 as a whole (26% if you exclude October). The run of five is unprecedented, although back in March there were two groups of two separated by an indefinite article.\n\n\nHøeg: Seismology is the study of surface tremors caused by the tension built up below the earth's crust. The study of love represents the seismology of the individual and of togetherness. This is one point of view: Høeg's characters are all have deeply different approaches, and I am arrested by how he is able to see love in such a variety of profound ways: \n\n\nInformation, a collection of essays from 1962, has a delightful turn of phrase: computers are referred to as \"workers\" and timesharing a computer installation is a way to keep them \"gainfully employed.\" It makes me wonder when the word \"working\" changed from meaning productively labouring towards a goal to simply not broken. There's also this quote: They are called computers simply because computation is the only significant job that has so far been given to them. (Ridenour, 1952)\n\n\nI've read Tainter's review of collapse before. He comes to a view that complexity has diminishing returns, and a change in circumstances can mean it makes economic sense for the population to decomplexify their society. It's a must read. An op-ed in the New York Times pointed out that Although banks perform an essential economic function — bringing together investors and savers — they are not the only institutions that can do this. It's true. Just as the internet reduces our dependence on high street shops and advertising to choose the products we encounter, and big entertainment verticals to choose what media we consume to unwind, it also reduces the importance of banks as a problem solving mechanism for how capital and entrepreneurs meet. But the financial sector, as an organ of complex society, must be paid for. If its complexity is no longer required, perhaps we are all better off to see it simplified.\n\n\nMy recommendation this month is for On the Road. To mix pace and narrative and meaning like that. I was carried away. Poetry!\n\n",
    link: "/home/2008/11/04/two_days_ago",
  },
  {
    title: "",
    date: "16.59, Thursday 6 Nov 2008",
    content:
      "\nI like small plastic cows. I don't know why. I haven't owned any until today. For many years I have wanted a herd for my home, and 100 would do nicely. But there is no way I can justify spending that much money on plastic animals. I could however justify giving that same amount to charity. So how about 100 people buy me 1 cow each, and then I give £500 to the charity they vote for? It's a win-win. It's Matt Webb's 100 Head Cattle Drive 2008! Pass it on, buy a cow, round 'em up and roll 'em out.\n\n",
    link: "/home/2008/11/04/books_read_october_2008",
  },
  {
    title: "",
    date: "11.00, Monday 17 Nov 2008",
    content:
      "\nIn contrast to the structures that I talked about the other day - the ones that Rothko and Markson set up halfway between your mind and what is ostensibly their art (but their art is actually these collaboratively unfolded mental sculptures) - I want to take a minute to talk about an alternative category of artistic expression, which is the transportation into the extended present.\n\n\nThere's something that happens when you listen to the music of Steve Reich which is that the pattern is at least short term predictable, and so you hear not only the presently-playing music but also you hear the previous 10 seconds (by memory) and the next 10 seconds (by expectation). And here I have to modify my argument with two points:\n\n\nOne: your expectations of music are not completely intellectualised. Your pattern recognition systems have their own particular grooves or lines of flight and so even when you know exactly what is coming up, your internal expectation might be different, like a corner on a known road which is always out of character. Two: this is of course true for all music, only it's easier to discern with the music of Steve Reich.\n\n\nSo what happens when your expectations are violated is a gap opens up between reality and your counterfactual present, a bridge over a chasm which suspended only because it is held at either end by the memory of the past and the predictability of the future. What's important here is not the bridge itself but the height of it, which manifests as either a tension - a kind of predictive vertigo - or a tickling. To me this tickling is the most enjoyable quality of this kind of art, arising from the joyful violation of expectations, and is only possible where the art allows the long present.\n\n\nAnother way the present can be extended is to make time smooth so that you slip over it and forget what the past is and what the future is. This I experience when I'm using the iPhone app RjDj, which takes the noise from around you and plays it back to you through your headphones, sliced and processed and echoed, so I'm not sure whether I'm hearing something live or a slice of it that is repeated a second later and incorporated into this generative soundscape. RjDj ends up being a world mindfulness enhancer because whereas I might not notice a sound because I am momentarily distracted by dodging a person on the pavement or reading a road-sign, here I have multiple opportunities in a several second window to listen. RjDj is especially enhancing when reading, because it turns out - at least for me - that my sense of linearity when reading down a page is anchored on time's arrow as it presents itself in sensory data from the world around me. Isolated from the moment-by-momentness of the world and having my sense of now extended by RjDj results in me reading the book page by page instead of sentence by sentence, having awareness of the page behind me and - because I am so aware of this larger context and the longer curve of narrative - an expectation of the page ahead. It dissolves the experience of reading.\n\n\nThere's a curious shift here in the focal distance of time. Marshall McLuhan, in Understanding Media, makes a comment that European men rest their eyes on an object so that they touch the surface, as if they are reading it, because of their history reading books; American men, by contrast, are from a televisual culture, and rest their eyes an inch or two ahead of the object, in order to take in a wider surface simultaneously. American women, says McLuhan, are disconcerted by Europeans because the men appear to be examining them closer, really penetrating them with the focal distance of the gaze, and this is felt as intimate and erotic. RjDj helps me move my focal appreciation of the present back a couple inches, a non-European connection with now, so that I can apprehend it; regard it; look at it from the side.\n\n\n9 Beet Stretch, Beethoven's Ninth time-stretched over twenty-four hours, does this. Long hikes or drives through the desert - undifferentiated scenery - does this. Repetitive beat music does this; dancing does this; being in the flow does this. The communication of highly complex ideas relies on using rhetoric to construct a long present as a kind of carrier wave on which a subtle and highly structured object can be authored in the listener's mind: an example is the I Ching.\n\n\nBut to me it's this tickling quality that is what makes the production of the long present worthwhile. To have a constructed artwork that exists over time and mirrors your thoughts so completely as to mesh with your expectations, fooling you into thinking it's of your own origin, using repetition and rhythm to construct a smooth space over which you can slip between the past and the now and the easily expected future, and then to make a surprise key change, to demonstrate the autonomy of the artwork, well that tickles me and it's why A Thousand Plateaus makes me laugh out loud, and this is simultaneously the experience of flirting when you can find the flow, and of wrestling with a dog, and familiar music, and if you're lucky even your own body and your own mind, which are really one, and are yourself too actually, with their own grooves and own lines of flight, but still you reflexively look inward and predict yourself, incorporating that too, recursively, making a kind of extended present of self, which is what we call identity, and you make actions and create thoughts which are consistent with your sense of self, but sometimes, as I say, if you are lucky, your body and your mind can jump the groove and prove that they too, in the context of the long self, still have the capacity to surprise, and this, I conclude, making a comment on a feeling that makes me happy and how to achieve this, is how one is able to tickle oneself.\n\n",
    link: "/home/2008/11/06/i_like_small_plastic_cows",
  },
  {
    title: "",
    date: "15.30, Sunday 30 Nov 2008",
    content:
      "\nBooks read November 2008, with date finished:\n\n\nZen and the Art of Motorcycle Maintenance, Robert M. Pirsig (11th, r.)\nChanging Planes, Ursula K. Le Guin (17th, r.)\nLegends from the End of Time, Michael Moorcock (17th, r.)\nProduct as Landscape, Sam Hecht & Kim Collin (19th)\nOne Night @ the Call Center, Chetan Bhagat (22nd)\nPale Fire, Vladimir Nakokov (27th)\nAmerican Psycho, Bret Easton Ellis (30th, r.)\n\n\nI read Pirsig first when I was maybe 17, a copy from the year the book was published (1974) in fact, my parents' copy, and this was a period of time when books would mean a lot to me, this one especially, and so when I lent it to a friend I was disappointed that circumstances (I don't recall, just missed chances and then the moving away of everyone and the drifting apart of that group) meant I didn't get it back. Earlier this year or maybe last year at a birthday party that I, in a somewhat unlikely fashion, attended, my long-time-ago friend also - and in even more unlikely a fashion - appeared, and it turned out she had brought Pirsig along with her, just in case I was there, and so after 13 years I have the book back. It's pretty good, and presents a number of neat approaches and vocabulary, but I feel differently about Pirsig now and so I feel distant from the ideas despite having the physical thing in my hands.\n\n\nBhagat was also a little disappointing: I love the lyrical quality of Indian English, and enjoy reading the Times of India online, but the story didn't transport me. Le Guin is a favourite but I've maybe read it a little too recently; Moorcock is amusing but that's it; the design work and discussion in Product as Landscape is thought provoking and again shows some neat approaches, but didn't inspire in me any cascade of epiphanies.\n\n\nAmerican Psycho is disturbing. It's another book I first read at 17, I think, and I re-read out of curiousity. Ellis is a masterful storyteller. The tone is hypnotic and the chapters - it's a sequence of long photographs, I guess, a story told under strobe lighting - vivid and lucid. Humanity, when you see it once maybe twice, is a glass of fresh water. Compelling and horrible.\n\n\nI'm beginning to feel about Nabokov how I feel about Vonnegut: an author I wish I'd found much earlier, both holding a level of control over their writing that means everything you want to read into the story is there and more besides. That quality lets the words burrow into you much deeper. Pale Fire is a poem by one author followed by detailed commentary by his friend and the story emerges, as in several books I've read this year, only in motion, slowly and from the coming together of many small and hidden parts. The story is steganographically encoded, unpacked by the act of reading. These stories cannot be summarised. Highly enjoyable; recommended.\n\n\nSo far in 2008 I have read 99 books (not counting online stories or graphic novels) and so my target for December is to finish another 5. These I have in hand although life details (moving flat, which is both time consuming and will eliminate my commute, which is where I read most; a different pattern of going out; energy devoted to reading; the holidays) may prove to make this challenging.\n\n",
    link: "/home/2008/11/17/in_contrast",
  },
  {
    title: "",
    date: "18.12, Tuesday 9 Dec 2008",
    content:
      "\nWhat I remember is walking unhurried down an unsurfaced road, all bright white pebbles and patches of dirt and grass in a strip running down the middle, and the trees - which I can smell too, that is vivid - curving over the road so that the sun comes through in tiny pieces between the overlapping leaves and branches, shingling the shingles, and the road curving around to the left and slightly downhill passing through woods filled with bluebells while there is a gate on the right that I do not use, and then the trees thin and I step into a patch where I can see the clear, clear azure sky, and the sun amazes me, and I take a deep slow breath, drinking the beauty, and what I remember then is the whole history of the photon hitting my retina and so my consciousness stretches out, back across time, back through space to the surface of the sun where once upon a time I fought in the goblin wars, our feet hooked in magnetic loops to avoid falling off and spinning into the heliosphere, wading through heaps of putrefying corpses tens and hundreds of kilometers deep, mulching and over millennia decomposing and recombining and autocatalytic loops of goblin proteins arising which we would harness, picking and restitching the cycles and matter flows of their autopoiesis with the tips of our swords such that over ten thousand years spaceships would evolve, the tips of our swords that were so sharp they were the resolution of superstrings and we would carve our names into the fabric of the cosmos itself whenever we made a kill, so the surface of the sun, our sun, is a trillion billion names, and it glows with these inscribed names, the interaction of the light and the power of the nuclear reactions of the sun combining with the semiotic density to make the currents on which our ships would ride, which would arc and tumble and dogfight like whales in heat, whales dancing in tangos, but multidimensional dances with a complexity never imagined on Earth; and from that vantage point, diving into the heart, I see the birth of my photon and its siblings, the ones that were nursed together in the heart of the star and I ride these brother and sister particles of light out to all their destinations simultaneously: and my consciousness becomes a ball of awareness expanding at the speed of light, now wider than the orbit of Jupiter, now passing the wavefront where the matter of the solar system collides with the matter of the galaxy and when I hit that I take the entire galactic disc in instantly, a giant deep breath that fills my lungs, a giant gulp that fills my stomach for I am a giant, and the Milky Way turns into a colossal eye, my eye, the black hole in the centre my new retina that absorbs light released at the beginning of the universe and so I am witness to the very first moments of time and also, therefore, the entire map of history which is laid out in-front of me... into which map I dive and follow paths and alleyways and circuit traces of consequences and rivulets of chance back to this moment, this path, these trees, this exact same blue sky, this intake of breath, this moment, this very moment, which I hold; and then I breath out because here I have all the universe inside of me and I hold the power to transcend and all it needs is for me to choose the right time and just for the moment I want to stand here, on this road, near the shelter of these green trees, in the brightness, in the brightness, in the brightness, in the brightness, in the brightness under our sun.\n\n",
    link: "/home/2008/11/30/books_read_november_2008",
  },
  {
    title: "",
    date: "10.20, Friday 12 Dec 2008",
    content:
      "\nSo here's what happened today fourteen years ago (now twenty years, two-thirds of a lifetime away). Let's add the other parenthesis: my first memory is about brown cows. Between those two dates I am strung taut like a string on a violin, and my original note played; my harmonics and tones since then emerging, recombining, gaining texture, depth and power; resonating and causing resonance, folding in and over, unique rhythms and vibrations arising and overlaying, until now when I have become a full, rich, individual note. But the pure, simple first harmonic is present still and - the entire stretch of my memory of him - those seven years are deep inside me, my spine, valuable, and appreciated.\n\n",
    link: "/home/2008/12/09/what_i_remember_is",
  },
  {
    title: "",
    date: "13.04, Wednesday 31 Dec 2008",
    content:
      "\nBooks read December 2008, with date finished:\n\n\nWatchmen, Alan Moore and Dave Gibbons (1st, r.)\nWhen Species Meet, Donna J. Harroway (8th)\nWelcome to Mars, Fantasies of Science in the American Century: 1947-1959, Ken Hollings (18th)\nThe Holocene: An Environmental History, Neil Roberts (30th)\nA Humument: A Treated Victorian Novel, Tom Phillips (31st)\n\n\nI've also read a few sci-fi novellas using Stanza on my phone (One-Shot, James Blish; Invaders from the Infinite, John Campbell; The Colors of Space, Marion Zimmer Bradley) but for some reason, being texts and not books made out of paper, I don't feel they belong here. I am capricious with my list of books read.\n\n\nI'm not feeling too wordy today, so let's keep it brief.\n\n\nThe Holocene: scale, the big picture like Annals of the Former World (read May this year), nature and culture as a single thing, the tortuous paths of cause and contingency, the planets and its natureculture and geological structures and histories as metaphor mines: the planet as self.\n\n\nHollings: a collage mixing facts and facts of fiction, a portrait of post-war America (it's my favourite period), the back-drop to cybernetics, flying saucers and suburbia.\n\n\nA Humument: a text found in the pages of the novel A Human Document, each page a painting, a play between text where we are trained to silently ignore everything but the encoded information, and the visual surface where every position, colour, reference, juxtaposition, quality is important, and to ricochet between these two. Poetry.\n\n\nYou should read Welcome to Mars, def.\n\n",
    link: "/home/2008/12/12/so_heres_what_happened",
  },
  {
    title: "",
    date: "13.50, Wednesday 31 Dec 2008",
    content:
      "\nI completed reading 104 books in 2008 (I also completed 104 in 2007). There are individual monthly lists: January; February; March; April; May; June; July; August; September; October; November; and December.\n\n\nThose lists have links too. Here I just want to pull out my favourites. I made it a rule to recommend one book a month--I've highlighted those in bold, and put together those 12 make an incredible package.\n\n\nImpro: Improvisation and the Theatre, Keith Johnstone (27 Jan.)\nScience in Action, Bruno Latour (16 Feb.)\nt zero, Italo Calvino (19 Feb., r.)\nEssential Cell Biology, Alberts, Bray, Hopkin, Johnson, Lewis, Raff, Roberts, and Walter (26 Feb.)\nThe Rubaiyyat of Omar Khayaam, Robert Graves and Omar Ali-Shah (translators) (13 March, r.)\nA Lover's Discourse, Roland Barthes (15 March)\nThe Worst Journey in the World, Apsley Cherry-Garrard (20 March)\n253, Geoff Ryman (30 March)\nArcadia, Tom Stoppard (1 April)\nExploits & Opinions of Dr. Faustroll, Pataphysician, Alfred Jarry (13 April)\nMichael Rosen's Sad Book, Michael Rosen and Quentin Blake (15 April)\nWorld War Z: An Oral History of the Zombie War, Max Brooks (20 April)\nFoucault's Pendulum, Umberto Eco (5 May, r.)\nWild Palms, Bruce Wagner and Julian Allen (7 May, r.)\nFrom Atoms to Patterns, Lesley Jackson (17 May)\nUnderstanding Material Culture, Ian Woodward (30 May)\nAnnals of the Former World, John McPhee (31 May)\nFrom Counterculture to Cyberculture, Fred Turner (20 June)\nStars in My Pocket Like Grains of Sand, Samuel R. Delany (22 June)\nThe Periodic Table, Primo Levi (29 June)\nStand on Zanzibar, John Brunner (26 July)\n101 Things I Learned in Architecture School, Matthew Frederick (31 July)\nWays of Seeing, John Berger (20 Aug.)\nEnvisioning Emotional Epistemological Information, David Byrne (23 Aug.)\nThe Compass Rose, Ursula K. Le Guin (23 Aug., r.)\nHow Buildings Learn, Stewart Brand (26 Aug.)\nThree Men in a Boat, Jerome K. Jerome (10 Sept.)\nJohn von Neumann and Norbert Wiener: From Mathematics to the Technologies of Life and Death, Steve J. Heims (18 Sept.)\nRiders of the Purple Sage, Zane Grey (22 Sept.)\nOn the Road, Jack Kerouac (1 Oct.)\nThe Collapse of Complex Societies, Joseph Tainter (20 Oct., r.)\nPale Fire, Vladimir Nakokov (27 Nov.)\nWelcome to Mars, Fantasies of Science in the American Century: 1947-1959, Ken Hollings (18 Dec.)\nA Humument: A Treated Victorian Novel, Tom Phillips (31 Dec.)\n\n\nSome common themes: last man on earth and journeys; stories that emerge only through the motion of the reader through the book; post-war history; alternatives to the cause and effect model; frontiers and open vistas; the big picture.\n\n\nI'm not reading to a target next year. I don't have such a long commute any longer and I'd like to watch more films. I don't mind saying that a good deal of 2008 has been pretty eventful, and between that and some of the excellent books I've encountered, I'm slowly developing new ways of thinking and talking about myself, the world and how things happen in it. I'd like to take time to explore those ideas in 2009, and shape and fold them myself.\n\n\nAs a final curious constraint, I'm going to recommend three books from my 2008 reading, ones that I hadn't read before and now I think you definitely should if you haven't already (though really I would choose a different three from those highlighted 12 each time I picked): Impro, Keith Johnstone; Annals of the Former World, John McPhee; On the Road, Jack Kerouac.\n\n",
    link: "/home/2008/12/31/books_read_december_2008",
  },
  {
    title: "",
    date: "15.51, Saturday 20 Jan 2007",
    content:
      "\nBut there is another aspect of love, which some may also have experienced, and which is likewise illustrated in a Persian text. This one is from an ancient Zoroastrian legend of the first parents of the human race, where they are pictured as having sprung from the earth in the form of a single reed, so closely joined that they could not have been told apart. However, in time they separated; and again in time they united, and there were born to them two children, who they loved so tenderly and irresistibly that they ate them up. The mother ate one; the father ate the other; and God, to protect the human race, then reduced the force of man's capacity for love by some ninety-nine per cent. Those first parents thereafter had seven more pairs of children, every one of which, however--thank God!--survived.\n\n\n--p149, Myths to Live By, Joseph Campbell\n\n",
    link: "/home/2008/12/31/i_completed_reading",
  },
  {
    title: "",
    date: "09.46, Monday 12 Feb 2007",
    content:
      "\n30 year prediction:\n\n\nBy 2037, China, by virtue of their ability to see and manage environment impact on a larger scale than other countries, will have invented cheap renewables to reduce their dependancy on fossil fuels, and will be working on fixing the atmosphere (perhaps they'll also have genetically engineered rafts of algae on the Pacific, excreting plastics). The West will rely on Chinese innovation to dig us out of our ecological mess.\n\n\nJust as the West will be a secondary market for Chinese consumer goods, BRIC being central, our prime-time TV entertainment will be dubbed Indian television which will be written and produced better than anything we can make domestically, yet - like our clothes that are always 12 months behind the global styles, and our cooking utensils that aren't really optimised for the kind of food we eat - will leave us feeling strangely culturally decentred.\n\n",
    link: "/home/2007/01/20/but_there_is_another",
  },
  {
    title: "",
    date: "17.54, Thursday 22 Feb 2007",
    content:
      "\nJust to get super abstract with the purpose of existence for a moment, the purpose of existence is this: To occupy time and space. In short, things which don't occupy time or space, aren't.\n\n\nHere are some different ways to occupy time and space: Be big; be multiple; be long lived. Planets are big, so are stars. Grass is multiple. Rocks are long lived. So are trees.\n\n\nOne cheap way to occupy more time and space without being more materially robust is to avoid the termination of the occupation. Animals are smart and get out of the way of being terminated. Movement and intelligence are both good strategies.\n\n\nOccupation isn't measured in metres or seconds but by witnesses. A dinosaur, being big, occupies space as far as it can be seen. To maximise its witnesses, it moves. There's a kind of persistence of existence which means it occupies a sausage shape in space as it walks along.\n\n\nI have a theory that dinosaurs were silent, and they were replaced by birds because birds had a technological secret weapon that let them occupy more efficiently: Noise.\n\n\nBirdsong occupies more space with less meat than dinosaurs.\n\n\nIf this is correct then, on average, birdsong in the late Mesozoic can be heard from a marginally greater distance from that which dinosaurs can be seen.\n\n",
    link: "/home/2007/02/12/30_year_prediction",
  },
  {
    title: "",
    date: "13.30, Saturday 24 Feb 2007",
    content:
      "\nI've been travelling a bunch recently. Jet lag is a funny beast. I used to let myself adjust slowly, returning east, but now I go cold turkey: Up at 7am every day, from the first day I get back. It makes sure I sleep through the night. Not making concessions to my body throws into relief what my body really wants to do.\n\n\nFor instance:\n\n\nWhen my body wants to go to sleep, the taste of sleep comes on. I get heavy and my head lolls.\n\n\nDuring the period I would usually be fast asleep, I'm kinda okay, but it's like walking through treacle. I'm also cold.\n\n\nJust before my body expects to be waking up - what is, local time, early afternoon - I get that taste in my mouth again, I feel super tired, and my bladder fills up. Give it another hour or so, as I come out of the slump, and my feet get really hot.\n\n\nWhat's going on here? I've no idea. But I can guess.\n\n\nFirst, my body helps me go to sleep. Even when I'm tired, I'm not necessarily sleepy (I hope you see the distinction). My body must be releasing something to make me sleepy. That lasts an hour or so, enough to knock me out.\n\n\nThat taste in my mouth? While I'm asleep, my body is doing its maintenance tasks. It's dumping out the nasty chemicals, metabolising stuff which it didn't during the day, taking the opportunity to check all my cells and digest the old ones, and whatever. The taste of sleep and crusty eyes, that's my body excreting through my face.\n\n\nSecond, when I'm waking up, that's my body doing its clean-up tasks from the overnight work. There's stuff it kept back because it couldn't excrete them earlier, so when it knows I'll be up and about soon, it flushes liquids to my bladder and the last batch of stuff to my mouth.\n\n\nMy temperature regulation goes to daytime mode last, usually just after I've woken up. My body heats up, and this is felt most in my feet which go cold/hot and clammy (I think this is because my body makes assumptions about whether I'm standing or lying down). I get this same thing if I stay in bed too long on weekends.\n\n\nWhat this all feels like gives me a new theory.\n\n\nI feel like I'm operating my body with levers and buttons, when I get up, I'm jet-lagged, and my body expects to be in deep sleep. I have to operate my legs with levers, and remember to reel my shoulders in, out of the way of door frames. Making breakfast isn't automatic, it's a sequence I have to assemble then follow: Get cereal, get bowl, open cereal, pour cereal into bowl, put down box...\n\n\nThis subjective sensation does not - does not one little bit - correspond with the idea that my body is resting.\n\n\nWhat it corresponds with is lag. If I operate my body when it wants to be asleep, my body is thrashing to keep up. I'm overloading it. When I'm asleep, it's because my body is simply too loaded to sustain consciousness.\n\n\nThose overnight maintenance tasks must be a dog to run. Saving my memory out to long-term storage, running over recent experiences to figure out what to pre-emptively put in the cache, monitoring cell division, allocating resources, doing integrity checks, figuring out how to digest the worst bits of that agro-industry food, shuttling chemicals round my body. That takes work! My body is a busy bee!\n\n\nConsciousness - being awake - is what my body throws me as a sop when it doesn't need the resources for anything else.\n\n\n(Apologies for the ugly mind/body division I've been making here. For mind, read 'the self-aware bit of the mind+body me' and for body read 'me.')\n\n",
    link: "/home/2007/02/22/just_to_get_super",
  },
  {
    title: "",
    date: "10.57, Thursday 8 Mar 2007",
    content:
      "\nSkype Prime is included in the new Skype 3.1 beta on Windows. Skype Prime allows you to charge a one-off or per-minute fee for people to call you. Perfect for premium rate voice services. But what else does it enable? I've talked about Skype as a platform before. What automated voice services could be built--perhaps, simply, a voicemail system as a front-end to a dictation service? It could work like this: You call a number, which happens to be running on Skype. You pay a per-minute charge, and dictate a message. The call is recorded and when you hang up, the mp3 is pushed to Mechanical Turk for transcription. The text is emailed back to you. Of course there's no reason this couldn't be done with Asterisk or some other transcription service, but the advantages here are: Skype has micropayments built in; you can run it from a desktop machine; the technology makes it easier to prototype so you can concentrate on the experience.\n\n\nWhat else? The one-off payment means Skype Prime could be used for software distribution. You pay your money, you get a file in return. Granted, it doesn't scale well and software distribution can happen in many ways... but for an individual selling home-made ebooks or movies, a simple plug-in to allow this could be easier than setting up online.\n\n\nGiven all this, if I was Skype I'd be working on a server-side Skype component. I'd want to allow, for example, Ruby on Rails apps to run dynamic voice menus, call in and out, and offer premium services.\n\n",
    link: "/home/2007/02/24/ive_been_travelling",
  },
  {
    title: "",
    date: "14.38, Thursday 8 Mar 2007",
    content:
      "\nMy favourite short story is The Author of the Acacia Seeds and Other Extracts from the Journal of the Association of Therolinguistics by Ursula K. Le Guin. It's a story of language, translation, and understanding things in terms of themselves, and - like all of Le Guin's best - progressively takes me so far outside myself that I can glimpse what it would be like to live non-sequentially, sideways to time, or without action and with only response. Le Guin helps me understand how historically contingent I am (personally and socially) , which helps me accept the points of views of others, human and non-human. Anyway, it's a story which can be read into endlessly, and also beautiful: It helps me see meaning in broader scales and configurations than those to which I am accustomed. (Le Guin's Always Coming Home is in my top 5 books.)\n\n\nI've wanted to share it with friends, but short stories are inconvenient to pass round because you have to lend the whole book. So I've transcribed the story and put it online. I hope many more people read Le Guin because of it. Read The Author of the Acacia Seeds.\n\n",
    link: "/home/2007/03/08/skype_prime_is",
  },
  {
    title: "",
    date: "09.05, Friday 9 Mar 2007",
    content:
      "\nA new question to catch blog comments spam bots, building on xkcd's new captcha approach.\n\n",
    link: "/home/2007/03/08/my_favourite_short",
  },
  {
    title: "",
    date: "15.15, Sunday 20 May 2007",
    content:
      "\nPlain text wiki:\n\n\nI'm a big fan of VoodooPad, the Mac desktop wiki application. It presents you with a good text editor, and a bunch of formatted text documents linked together in the UsualWikiWay (also some really innovative scripting hooks). I like wikis because my problem is not noting down loads of associated ideas (so I don't need mind mapping software)--my problem is linearising, and wikis really help me with putting down everything I'm thinking about, and massaging it into a talk, or project presentation, or whatever.\n\n\nHere's my one problem with VoodooPad: The data is in a proprietary format. I've had computers long enough to know that I want my data in a format used by many, many applications over many, many years. So I use VoodooPad for arranging and notes I don't need to keep, and make sure my final presentation notes also exist as text files.\n\n\nTo be honest, the most important part of a wiki for me is the wiki--I'm not bothered about formatting or pictures. How about a plain text wiki? So that's what I've made.\n\n\nThe plain text wiki is implemented as a bundle inside TextMate, the (highly extensible) Mac text editor. To use it, I do this:\n\n\nMake a new text file, and save it in a new, empty directory as 'IndexPage.txt'. It's easiest to use this directory as a project--close the text file, and drag the directory icon onto TextMate.\nIn the project window, open IndexPage.txt and make notes as normal (set the language to 'Wiki' in the bottom bar, if it's not that already). WikiWords appear underlined. With a cursor over it or at the end, hit enter to open this page in the project window. If it doesn't exist, it's created as WikiWords.txt in the project directory.\nHit shift+ctrl+i to return to IndexPage.\n\n\nThis is exactly what I need: A bunch of text documents that I'll be able to read at any point in the future, in a wiki structure that will be simple to implement in most extensible text editors. There are a bunch of things still to do (some helper command to create a new wiki folder would be great, and also to give different formatting to the words if the wiki page doesn't exist yet), but this is my first TextMate bundle and I'm not sure how to do those yet.\n\n\nAnyway, there's barely anything there... but if you want it, feel free to download. Grab the Plain Text Wiki bundle (get the zip; it's unpacked there too so you can browse) and double click to install. Patches welcome!\n\n\nUpdate: Hey, I want to clarify something here. I love VoodooPad and won't stop using it. I like it even more now Gus Mueller has pointed out how to make it save in plain text. There's also room in my life for this super simple, plain text wiki directory thing, because I know its wikiness can be easily implemented again in the future. But 'proprietary,' as a word, is a strong one, making things appear black and white, and I used it recklessly. I'm sorry about how I put together the blog post above.\n\n",
    link: "/home/2007/03/09/a_new_question_to",
  },
  {
    title: "",
    date: "13.03, Friday 25 May 2007",
    content:
      "\nPlain text wiki update: I've updated the plain text wiki TextMate bundle (background) with a few new features:\n\n\nWiki links can now be made [[like this]] in addition to the CamelCase form (thanks Mark Fowler for implementing this)\nThere's now an 'Export Wiki to HTML' command. This will make a directory of linked HTML files, and assumes you're using Markdown for formatting (and because Markdown is so excellently unobtrusive, you'll never notice this change if you don't use the export function). A few people asked for this, so I hope it helps. Thanks Fabrice Luraine for showing me how to inherit from the Markdown language.\nThere's a 'Create New Wiki' command which simply prompts for a directory and makes an IndexPage.txt file there. It seemed easier somehow.\n\n\nDownload here. I'm new to both Ruby and TextMate bundles... so, as ever, patches welcome!\n\n",
    link: "/home/2007/05/20/plain_text_wiki",
  },
  {
    title: "",
    date: "19.38, Monday 25 Jun 2007",
    content:
      "\nSome Foo Camp personal highlights:\n\n\nSeparate conversations with Marc Hedlund and Kevin Slavin, both direct to the heart of the Sun advice and sharing on big business decisions that have been occupying me fully the past week.\nWaking at 6am under canvas (read: space-age super plastic) on the O'Reilly campus, taking early morning walks and drinking the birdsong. Note for O'Reilly employees: Listen out for the bird that goes 'tee tee, tee tee; tee-woot, tee-woot, t-t-t-t, t-t-t-t; tooooow, tooooow.' It's mimicking the car alarm warning cycle that goes off next door, which I heard at 7.30-ish.\nA selfish highlight this one. My session included the first talk I've done for a year that wasn't written long hand, and I'm pleaseder than I imagine you imagine about that, as I've not been able to happily speak off-the-cuff all that time. Also I got to reveal the summer project to a whole bunch of smart folks who gave great feedback and asked exactly the right kind of probing questions.\n\n\nAside from that, too numerous to mention: Hilarious events; meeting a ton of people including several I've wanted to meet for some time; general hanging out and learning and conversing and thinking and eating carrots.\n\n",
    link: "/home/2007/05/25/plain_text_wiki_update",
  },
  {
    title: "",
    date: "09.59, Saturday 30 Jun 2007",
    content:
      "\nThis isn't a story I tell too many people.\n\n\nA couple years back, I was hanging out with a A. in the flat we shared, playing Tiger Woods PGA Tour and having a beer or something. S. popped his head in - another flatmate - and a great deal of time later, returned from wherever he'd been and asked us why we were still listening to Dire Straits. Whoops, caught out.\n\n\nAnyway, we looked closer at the CD player and it turned out that it wasn't the album that'd been on repeat, it was a single song. We'd been listening to the single track Brothers in Arms, Dire Straits, solid for four hours. It's a pretty awesome album, obv., and a pretty great track, but I'm not going to admit that to a soul.\n\n\nThere was a post at Overheard in New York the other day:\n\n\nShort man: So, my therapist told me to take off my clothes and look into the mirror.\n\nTall woman: Why?\n\nShort man: To confront my inner midget.\n\n\nI'm shy of services like last.fm because I have a certain public image and letting people know I listen to Dire Straits isn't exactly in keeping with that. Ambient drone and Balearic house on the other hand, I'm happy for people to hear about.\n\n\nBut how absurd! This is who I am! I got over identity issues and pretending to be someone I'm not in my early teens, like pretty much everyone. Hiding my musical preferences is like wearing a mask, right. I should just let it all hang out. Well, kinda.\n\n\nPresentation of self is a complex dance. My personality is far too curious and, uh, on occasion abrupt, but I mute that in public (well, I try). I wear a particular expression when I know I'm being photographed for Flickr.  I wear t-shirts to the office and suits to conferences. That's half the story.\n\n\nThe other half the story is what you do. You will never publicly call me out on not being my real self. You will never datamine my music listening habits and publish the stupidest songs I listen to, whenever I say I like some fancy orchestral stuff. I mean, you could... but you would look stupider than me for being petty and breaking that social understanding that we all manage our presentation of self, all the time.\n\n\nThis is why I don't believe these are privacy's end of days.\n\n\nAlong with new visibilities comes social understanding of those new visibilities. We agree to look the other way, just as Finns hold a hand in-front of their face while they have a phone call in a public place, and you can slip on your swimsuit on the beach and no-one looks. Just as you will see my predilection for Dire Straits, Genesis and Talking Heads (it turns out, every band mentioned in American Psycho. Why is that?), laugh at me, and then move on: I'll be proud of what I listen to, but I'll simultaneously not mention it next time I'm visiting old colleagues in BBC Audio & Music, and you won't call me on it because that's how the world turns.\n\n\nA caveat: We can cope with the shifting boundaries of privacy and social understanding if the social accommodations are given time to emerge. It's all to easy to read this shift and encode the lack of privacy technologically: You can't hold a social contract with a database which is tracking your office movements via your RFID identity card and holding the data for 6 months. You don't have any human understanding with the algorithms harvesting your web browsing behaviour and identifying your product affinities.\n\n\nIf the end of privacy comes about, it's because we misunderstand the current changes as the end of privacy, and make the mistake of encoding this misunderstanding into technology. It's not the end of privacy because of these new visibilities, but it may be the end of privacy because it looks like the end of privacy because of these new visibilities*. Uh, if you see what I mean.\n\n\nLong story short, I decided to expose my music listening on last.fm to the world. I looked in the mirror, embraced my inner midget and said, hey, I listen to Dire Straits. And you know what? No-one cares. And it's great.\n\n\nThe Bad album, Michael Jackson, too. Ssh.\n\n",
    link: "/home/2007/06/25/some_foo_camp",
  },
  {
    title: "",
    date: "11.08, Friday 13 Jul 2007",
    content:
      "\nTwo years ago today, Matt Jones took this photo of me and Jack. Shortly after, we bought Z.V.B. Ltd. off the shelf and renamed it Schulze & Webb Ltd. I had a terrible haircut, rectified only days later.\n\n\nOne year ago (the portrait on our about page is from that month): Jack had finished college. I was billing through the company but effectively acting as a sole consultant. I wrapped up my projects that July; aside from odd jobs, we didn't issue another invoice till 1 November. Those were some lean months.\n\n\nWhat happened in that time is we became a company.\n\n\nOur starting point was that we wanted to work together, on exciting work for good clients. And we also knew that you get what you do. So we started turning down any work which meant we'd operate separately or as freelancers.\n\n\nThat led us to marketing, and market positioning, business plans, and quarterly targets. In my notebook from last year, there's a matrix of short/medium/long-term with the kind of work we'd like, for what kind of clients, and how we'll get the work. We're still following it.\n\n\nI put money into the company. We introspected a lot, tried to figure out what our model would be for balancing consultancy and our own projects. We got the lay of the land and positioned the troops.\n\n\nOne week in late October 2006, we received two phone calls and two briefs: One three month user experience project, and one design strategy intensive project for what turned out to be a recurring client. That was our first profitable quarter, and we've been booked out since.\n\n\nBut those were lean, lean months. It's tough on the wallet and on your sleep too. We were forged then.\n\n\nIt's been a funny two years. I feel like I'm on my third company. The first was leaving the BBC (after writing Mind Hacks part-time) to freelance and work with Jack. Second was starting the limited company with Jack officially, pitching in together. Third was last year, turning down the freelance work.\n\n\n(The story of last year's jump is in the Daily Telegraph, incidentally.)\n\n\nHey, so will there be a jump number four? We've reached stage three of last year's business plan, and I never wrote a stage four. All the pieces are in place now, and it's a question of whether we want to put everything back into play. I suspect, yes, there will be a jump. And I don't want to promise any news soon because these roads are long, but there have been some interesting recent developments and we're feeling hungry.\n\n\nI just wanted to bookmark this moment, and that photograph. Two years!\n\n",
    link: "/home/2007/06/30/this_isnt_a_story_i",
  },
  {
    title: "",
    date: "07.50, Tuesday 18 Sep 2007",
    content:
      "\nA bunch of texts about computing:\n\n\nMy friend David Smith has ferried to me a first edition of Ted Nelson's Computer Lib/Dream Machines (1974). This is extremely good. Computer Lib established the computer as something with which people could be creative; something with which people could create art (oh, and make their lives better).\n\n\nI also have Doug Engelbart's Mother of All Demos (1968) on DVD. He had it at a conference I was at, and was copying it for a friend... I was nearby and happened to have a DVD burner... I asked if I could snag a copy. It's pretty good quality; I'm very pleased.\n\n\nBoth Engelbart and Nelson read Vannevar Bush's 1945 essay in the Atlantic Monthly, As We May Think. Now that'd be an issue to own. Bush put the US scientists on a war footing, and in this article gave something back in the form of the memex: a kind of hypertext, knowledge-management device for linking and sharing articles and pictures, based on microfiche and cameras. Engelbart read this article as a radar technician in the Philippines, put the ideas together with the radar screen he used, and realised that computers didn't need to be used just as calculators to figure out ballistics--they could be used as personal helpers, in collaboration with people in an interactive way. The 1968 demo included co-working, hypertext, links, outlines, cursors, video conferencing, and the mouse.\n\n\nAnother book I have is Lion's Commentary on Unix 6th Edition (1996 reprint). It circulated illegally for some time, only being published 20 years after it was written. The whole operating system is short - less than 9,000 lines - and it rewards reading. Want to know what a process is? Here you go. And a file? It's in there. Magical.\n\n\nAnd so three questions:\n\n\nWhat other seminal texts are there?\nWhat should I investigate further? I should take time to look into Lettvin's What the frog's eye tells the frog's brain (1959) with with Maturana, McCulloch, and Pitts. The latter two mathematically modelled the neuron, and fed substantially into cybernetics. Cybernetics was heavily influenced by anthropology, and also by the feedback mechanisms in anti-aircraft guns in World War II (itself modelled on brains, perhaps?). The theoretical structure of the brain inspired the earliest computer architectures. It's all tangled up.\nWhat is there, from the last 10 years or so, that will have this impact? Ben Russell's Headmap Manifesto (1999) is on my hard drive.\n\n\nRecommendations?\n\n",
    link: "/home/2007/07/13/two_years_ago_today",
  },
  {
    title: "",
    date: "13.22, Thursday 20 Sep 2007",
    content:
      "\nI had some recommendations for more seminal texts in computing:\n\n\n\nRod McLaren pointed me at Tracy Kidder's The Soul of a New Machine, on the creation of a new computer at Data General in the 1970s. It appears to be a story of how objects are not invented but argued, cajoled and bullied into life. This very human account reminds me of Constructing a Social Science for Postwar America (Steve Joshua Heims) on the collaborative construction of cybernetics and what it influenced.\n\n\nrobertogreco sent me Jason Kottke's review of Glut: Mastering Information Through the Ages (Alex Wright), in which he highlights Paul Otlet's 1934 description of the radiated library: Over there, in an immense edifice, are all the books and information. From there, the page to be read, in order to know the answer to the question asked by telephone, is made to appear on the screen. The screen could be divided in half, by four, or even ten if multiple texts and documents had to be consulted simultaneously. Sounds like a good reference to chase down. And I don't know why I haven't read Glut yet.\n\n\nAndrew Otwell mentioned two books: ESR's The Art of Unix Programming (1/2 programming and 1/2 cultural history) and The Pattern on the Stone by Danny Hillis. The latter I have been recommended so many times I need to go order it right now.\n\n\nDanny O'Brien said simply: HAKMEM? It's a 1972 \"memo\" (technical report) of the MIT AI Lab that describes a wide variety of hacks, primarily useful and clever algorithms for mathematical computation. There are also some schematic diagrams for hardware. Aha! But it's odd--it feels like extracts from lab books and answers, and I don't know enough of its history to feel its exciting newness. More research required.\n\n\nMichael Dewar brought up Stafford Beer, inventor of the 1970s pre-internet socialist cybernetic economy system Cybersyn. Now I've previously looked at Cybersyn, but didn't realise (as Michael told me) that Beer's book Platform for Change has an essay on it. That's definitely one for the book pile.\n\n\n\nThanks all; loads of reading there. Now I can't find the email - maybe it was IM - but Tom Armitage mentioned The Essential Turing to me. Man, that looks like it's right to the heart of the matter. Maybe I should read it to warm up to Feynmann's Lectures on Physics.\n\n",
    link: "/home/2007/09/18/a_bunch_of_texts",
  },
  {
    title: "",
    date: "12.50, Thursday 25 Oct 2007",
    content:
      "\nOne of Niven's Laws states that F×S=k or, to put it another way, the product of freedom and security is a constant (so the greater the security of a society, the lower the freedom within it).\n\n\nI'm not sure I agree. By Ashby's Law of Requisite Variety, the control system must have sufficient states to absorb the number of possible states of the system being controlled. In more concrete language: a more complex control system (police, legal system and so on) allows more freedom of the society, in terms of allowed states, not less.\n\n\nNote that this is discussing states of society as a whole, which doesn't correspond with individual freedom. For example: consider a society with 2 citizens. The first citizen has the freedom to occupy the states black/white, and the second to occupy red/green. There are 4 possible society states. But if both citizens have the freedom to occupy black/white, there are degenerate states at the society level: there are only 3 distinguishable society states.\n\n\n(Also note that I'm equating security with having a more developed system of control, said system allowing feedback (such as locating and disarming a bomb) to occur.)\n\n\nWhat this means, for freedom and control, is that increased control can buy us two different types of freedom: greater individual freedom, and greater freedom to be different from other people. Control (and decreasing personal freedom of the first type) allows us to have a more heterogeneous society.\n\n\n(Implications? Individuals in a factory are freer than individuals in a conglomerate because they're all free in the same way and the factory-society can afford more of that for the same level of control. And a society comprised of a large number of similar villages can also afford more individual freedom than a society in which some individuals are allowed to express global freedom, via fame.)\n\n",
    link: "/home/2007/09/20/i_had_some",
  },
  {
    title: "",
    date: "20.30, Sunday 11 Nov 2007",
    content:
      "\nI read The Space Merchants by Pohl and Kornbluth in September. I guess it stuck in my head.\n\nThe advertising industry is the pinnacle of this society. In the book, an ad fellow has a job to convince people to colonise Venus. There is also a pro-environment, anti-consumerism terrorist organisation named 'the Consies.'\n\n\nSee, this makes sense. Environmentalism as it stands is conservatism - the refusal to see there might be another, better system - by another name. I say 'as it stands' because I don't see any signs that the movement has escaped being one side of this spectrum: on the one hand we can conserve our resources, and on the other we can use and risk them.\n\n\nThere is a third way, and that is to identify the system which generates this opposition and work to change that. For example we may see that the environmentalism debate would be rendered moot having a billion humans orbiting Jupiter and a trillion nano-scale Londons seeded and replicated over the Tharsis Bulge using solar energy and reversible computing. So we would make a risk assessment to figure out whether we want to achieve that. Maybe the polar bears and Bangladesh are worth that. You tell me.\n\n\nThe current dichotomy is not sustainable (ha!), and nor is the system which generates it. Environmentalism prolongs the existence of this system.\n\n\nWe've seen how this should be resolved with capitalism: Marx told us. The revolution must come, and indeed must be provoked by encouraging conflict (in the case of capitalism, between labour and capital by making peaceful strikes violent and so on). The sooner the revolution comes, the sooner we can get on.\n\n\nNow I'm not advocating a Marxist approach to trees. But what emerged from this conflict was a world in which labour was treated differently. Granted it's one in which conglomerate control is more insidious and labour has transformed into automatic consumers, but at least it's different. At least it proves the point that just the possibility of revolution can bring about a synthesis--and, goodness, given that's happened once then maybe if it happens twice we'll be able to put the dots together and have continuous revolution instead.\n\n\nSo what I'm advocating is a game-changing, post-revolution environmentalism. Don't waste resources, sure. But if we're spending resources to shift the status quo - feeding pandas into a wood-chipper to send a colony to the Moon, if that's the kind of engine that we invent and that's what it takes - then I'm behind it. Otherwise we're slowly painting ourselves into a corner.\n\n\nAlso secretly I'm behind anything that forces the issue too, which is why I burn tyres on the roof.\n\n\n(There are two hidden assumptions here: that profligate use of resources will generate proportionately greater technological advance; that happiness does not matter. I could argue that deliberately making people unhappy is what will trigger the happiness revolution which will save us all - and I do use a form of this defence to be impolite to charity beggars - but really it needs more thought.)\n\n",
    link: "/home/2007/10/25/one_of_nivens_laws",
  },
  {
    title: "",
    date: "21.12, Sunday 25 Nov 2007",
    content:
      "\nSo I think they should genetically engineer trees with branch and leaf fractal sizes such that they act as perfect frequency filters for the noise spectrum of traffic and plant them alongside roads, because that would be prettier than the walls that are used. Also genetically engineered grass with serrated edges and designed cilia so when the wind blows the grass sings in a deep, filling harmonic tone, like this: llllllllllllllllllllllllllllllllllllll.\n\n",
    link: "/home/2007/11/11/i_read_the_space",
  },
  {
    title: "",
    date: "15.09, Friday 30 Nov 2007",
    content:
      "\nI'd like to finish reading another 12 books before the end of 2007, as this would take me to 2/week over the year. I'm a few pages from the end of The Art of Innovation (Tom Kelley), and the following 5 books are in the queue: The Great Gatsby (F. Scott Fitzgerald); The Fabric of Reality (David Deutsch); The Catcher in the Rye (J. D. Salinger); Programming Collective Intelligence (Toby Segaran); Pedagogical Sketchbook (Paul Klee). A possible is The Nature and Art of Workmanship (David Pye).\n\n\nI need to find another 5 books.\n\n\nThere are two constraints: I'm reading at 50% above my usual pace in order to reach the target, so I need to avoid the books that take me a while longer than usual to get through (Consuming Life (Zygmunt Bauman), I'm looking at you). However I don't want to cheat by reading pulp sci-fi, so I would like a few more non-fiction books in there, especially because my fiction consumption has been pretty high these last couple of months.\n\n\nAny suggestions?\n\n\n(More data: my quest for seminal computing texts led to me reading The Pattern on the Stone (W Daniel Hillis) and Platform for Change (Stafford Beer). And this is what I said about books in 2005... which reminds me that I haven't read The Rubaiyyat (Omar Khayaam) recently, so that may also have to drop onto the stack.)\n\n",
    link: "/home/2007/11/25/so_i_think_they",
  },
  {
    title: "",
    date: "18.41, Wednesday 26 Dec 2007",
    content:
      "\nI completed reading 104 books in 2007 (as mentioned last month). Though I'm starting more books this year, for the sake of hitting that magical 2 per week, I won't be finishing any.\n\n\nI've not kept a record like this before. I have this picture of myself that the books that really change me are all squashed into the last 12 months. But when I look at my bookshelf, it turns out that's not true: I didn't read Catch 22 this year, nor Lolita, nor Black Swan Green (even the Compass Rose, source of The Author of the Acacia Seeds, I picked up last year). Most of my cybernetics and modernism reading was last year (or the year before, even). Some books - like Computer Lib and art catalogues - I consult and dip into but never read cover to cover, so they don't appear in my list. And some, like Le Guin's translation of the Tao Te Ching and Robert Graves' of the Rubaiyat (Omar Khayyam), are so vivid for me I swear I must have read them recently but never made a note.\n\n\nAnyway. I like books that make me say Ha! a lot. Good ideas are like tickles. In the list below, along with the date I finished the book, I've added a '*' if the book tickled me. If it was a re-read then there's an 'r.'\n\n\nThe reason I've put any stars in December is because I can only tell if a book was awesome for me after some time has past, and at this point it feels as if I've had a 100% awesome reading month. Actually, this month has felt a bit like reading only one or two books: The Catcher in the Rye, The Gum Thief and the Fall and Rise of Reginald Perrin are all about the urge to disappear, just in different societies. And the Fabric of Reality and Complexity were similar enough that I wanted to bang their heads together and go 'look! You're talking about a physics which is fine-grained and organic in just the way you other folks talk about economics and cellular automata. Discuss!' Complexity, of course, bounced off the duffers of the generation before... said duffers being the revolutionary stars of From Newspeak to Cyberspeak and Platform for Change, both of which I'd read a couple of months earlier. Super bizarre.\n\n\nHere's the list.\n\n\nJanuary:\n\n\n\n\tCities, John Reader (5th, *)\n\n\n\tPredator's Gold, Philip Reeve (6th)\n\n\n\tRight Ho, Jeeves, P. G. Wodehouse (8th)\n\n\n\tJeeves in the Offing (13th)\n\n\n\tInfernal Devices, Philip Reeve (14th)\n\n\n\tMyths to Live By, Joseph Campbell (18th, *)\n\n\n\tThe Inimitable Jeeves, P. G. Wodehouse (18th)\n\n\n\tVisions of Technology, Richard Rhodes (21st, *)\n\n\n\tPandora's Star, Peter F Hamilton (26th)\n\n\n\tPushing Ice, Alastair Reynolds (28th)\n\n\n\nFebruary:\n\n\n\n\tA Darkling Plain, Philip Reeve (4th)\n\n\n\tAda or Ardor, Vladimir Nabokov (10th, *)\n\n\n\tUnderstanding Comics, Scott Mc Cloud (11th, *)\n\n\n\tJudas Unchained, Peter F Hamilton (15th)\n\n\n\tRing for Jeeves, P. G. Wodehouse (25th)\n\n\n\tA General Theory of Magic, Marcel Mauss (28th, *)\n\n\n\nMarch:\n\n\n\n\tThe Outsider, Albert Camus (2nd, *)\n\n\n\tThe Stainless Steel Rat Saves the World, Harry Harrison (4th)\n\n\n\tAunts Aren't Gentlemen, P. G. Wodehouse (4th)\n\n\n\tThe Man in the High Castle, Philip K Dick (9th, *)\n\n\n\tChanging Planes, Ursula K. Le Guin (25th, r., *)\n\n\n\nApril:\n\n\n\n\tThe Plague, Albert Camus (2nd)\n\n\n\tFrom Russia With Love, Ian Fleming (8th)\n\n\n\tTimequake, Kurt Vonnegut (14th, r., *)\n\n\n\tThe Reality Dysfunction, Peter F Hamilton (16th)\n\n\n\tUnderstanding Radio, Andrew Crisell (20th)\n\n\n\tThe Forever War, Joe Haldeman (22nd, *)\n\n\n\nMay:\n\n\n\n\tThe Neutronium Alchemist, Peter F Hamilton (5th)\n\n\n\tDesign for the Real World, Victor Papanek (8th, r., *)\n\n\n\tThe Pinhoe Egg, Diana Wynne Jones (11th)\n\n\n\tCosmicomics, Italo Calvino (12th, r., *)\n\n\n\tThe Stainless Steel Rat for President, Harry Harrison (13th)\n\n\n\tThe Myths of Innovation, Scott Berkun (18th)\n\n\n\tStorm Front, Jim Butcher (20th)\n\n\n\tFool Moon, Jim Butcher (27th)\n\n\n\nJune:\n\n\n\n\tNever Let Me Go, Kazuo Ishiguro (2nd, *)\n\n\n\tStories of Your Life and Others, Ted Chiang (2nd, r.)\n\n\n\tBlade Runner, Scot Bukatman (6th)\n\n\n\tGrave Peril, Jim Butcher (6th)\n\n\n\tStarship Troopers, Robert Heinlein (15th, r.)\n\n\n\tRed Mars, Kim Stanley Robinson (20th, r.)\n\n\n\nJuly:\n\n\n\n\tThe Naked God, Peter F Hamilton (2nd)\n\n\n\tThe Cult of the Amateur, Andrew Keen (8th)\n\n\n\tGreen Mars, Kim Stanley Robinson (8th, r.)\n\n\n\tThe Real Toy Story: Inside the Battle for Britain's Youngest Consumers, Eric Clark (10th, *)\n\n\n\tBlue Mars, Kim Stanley Robinson (16th, r.)\n\n\n\tMisreadings, Umberto Eco (17th, r.)\n\n\n\tVisual Function: An Introduction to Information Design, Paul Mijksenaar (17th)\n\n\n\tThe Martians, Kim Stanley Robinson (21st, r.)\n\n\n\tHarry Potter and the Deathly Hallows, J K Rowling (21st)\n\n\n\tDeath Masks, Jim Butcher (24st)\n\n\n\tBlood Rites, Jim Butcher (26th)\n\n\n\tInformal, Cecil Balmond (30th, *)\n\n\n\nAugust:\n\n\n\n\tStill Life with Woodpecker, Tom Robbins (3rd, r.)\n\n\n\tProven Guilty, Jim Butcher (4th)\n\n\n\t84 Charing Cross Road, Helene Hanff (5th)\n\n\n\tA Theory of Fun, Raph Koster (5th, *)\n\n\n\tThe Player of Games, Iain M. Banks (8th, r.)\n\n\n\tThe Adventure of English, Melvyn Bragg (15th, r.)\n\n\n\tJpod, Douglas Coupland (22nd)\n\n\n\tLook to Windward, Iain M. Banks (24th, r.)\n\n\n\tThe E-Myth Revisited, Michael E. Gerber (31st)\n\n\n\nSeptember:\n\n\n\n\tDistress, Greg Egan (1st, r.)\n\n\n\tSix Memos for the Next Millennium, Italo Calvino (3rd, *)\n\n\n\tSpares, Michael Marshall Smith (9th, r.)\n\n\n\tSamarkand, Amin Maalouf (12th, r.)\n\n\n\tSchild's Ladder, Greg Egan (18th, r.)\n\n\n\tThe Space Merchants, Frederik Pohl and C. M. Kornbluth (21st)\n\n\n\tDead Beat, Jim Butcher (23rd)\n\n\n\tThe Pattern on the Stone, W Daniel Hillis (24th)\n\n\n\tQuarantine, Greg Egan (28th, r.)\n\n\n\tWest with the Night, Beryl Markham (29th)\n\n\n\nOctober:\n\n\n\n\tAltered Carbon, Richard Morgan (5th)\n\n\n\tGateway, Frederik Pohl (6th)\n\n\n\tPlatform for Change, Stafford Beer (8th, *)\n\n\n\tGod Knows, Joseph Heller (13th, *)\n\n\n\tBroken Angels, Richard Morgan (16th)\n\n\n\tNew Musical Resources, Henry Cowell (16th)\n\n\n\tBlue Monday: Stories of Absurd Realities and Natural Philosophies, AUDC (Robert Sumrell and Kazys Varnelis) (18th, *)\n\n\n\tAtlas of Novel Tectonics, Reiser and Umemoto (22nd)\n\n\n\tLarklight, Philip Reeve (22nd)\n\n\n\tThe Game, Diana Wynne Jones (27th)\n\n\n\tFrom Newspeak to Cyberspeak: A History of Soviet Cybernetics, Slava Gerovitch (31st, *)\n\n\n\tReflections on the Name of the Rose, Umberto Eco (31st)\n\n\n\nNovember:\n\n\n\n\tThe Meaning of it All, Richard Feynmann (1st, r.)\n\n\n\tPacific Edge, Kim Stanley Robinson (4th, r.)\n\n\n\tWoken Furies, Richard Morgan (9th)\n\n\n\tThe Sirens of Titan, Kurt Vonnegut (13th, r.)\n\n\n\tThe Gold Coast, Kim Stanley Robinson (19th, r.)\n\n\n\tMiss Wyoming, Douglas Coupland (26th, r.)\n\n\n\tConsuming Life, Zygmunt Bauman (27th, *)\n\n\n\tThe Day of the Triffids, John Wyndham (28th)\n\n\n\tThe Art of Innovation, Tom Kelley and Jonathan Littman (30th)\n\n\n\nDecember:\n\n\n\n\tThe Great Gatsby, F. Scott Fitzgerald (1st)\n\n\n\tThe Fabric of Reality, David Deutsch (7th)\n\n\n\tThe Catcher in the Rye, J. D. Salinger (7th)\n\n\n\tThe Gum Thief, Douglas Coupland (8th)\n\n\n\tThe Fall and Rise of Reginald Perrin, David Nobbs (9th, r.)\n\n\n\tComplexity, M. Mitchell Waldrop (12th)\n\n\n\tThe Raw Shark Texts, Steven Hall (14th)\n\n\n\tA Fool's Alphabet, Sebastian Faulks (16th, r.)\n\n\n\tLet your words be few: symbolism of speaking and silence among seventeenth-century Quakers, Richard Bauman (18th)\n\n\n\tThe Fountainhead, Ayn Rand (22nd)\n\n\n\tI Seem To Be a Verb, R. Buckminster Fuller, Jerome Agel and Quentin Fiore (24th)\n\n\n\tPedagogical Sketchbook, Paul Klee (25th)\n\n\n\nI could say a whole bunch about pretty much any book on this list, and I would love to but time prevents it. But if there's one you'd like to hear more about, drop me a mail and I'll post a story about it here.\n\n",
    link: "/home/2007/11/30/id_like_to_finish",
  },
  {
    title: "",
    date: "11.23, Friday 28 Dec 2007",
    content:
      "\nWrapping up 2007: As Borges wrote reviews of non-existent books, I have notes for essays I'll never write. Here I've collected what's been on my mind the last couple of months.\n\n\n1 #\n\n\nThe common theme of Web 2.0 Expo Berlin was surfaces, which I picked up primarily from a talk on microformats as nanotech by Jeremy Keith and a conversation with Terry Jones.\n\n\nIn short: the surface of the Web is currently pages - these are the atoms - which are interlinked (Tom Coates talks about how to be native to the Web of data). Search engines index the text, and our browsers make local deductions from the raw source to show rendered pages.\n\n\nWhat microformats and other forms of structure do is increase the resolution of the Web: each page becomes a complex surface of many kinds of wrinkles, and by looking at many pages next to each other it becomes apparent that certain of these wrinkles are repeated patterns. These are microformats, lists, blog archives, and any other repeating elements. Now this reminds me of proteins, which have surfaces, part of which have characteristics shared between proteins. And that in turn takes me back to Jaron Lanier and phenotropics, which is his approach to programming based on pattern recognition (I've looked into this before).\n\n\nSo what does phenotropics mean for the Web? Firstly it means that our browsers should become pattern recognition machines. They should look at the structure of every page they render, and develop artificial proteins to bind to common features. Once features are found (say, an hCalendar microformat), scripting can occur. And other features will be deduced: plain text dates 'upgraded' to microformats on the fly. By giving the browser better senses - say, a copy of WordNet and the capability of term extraction - other structures can be detected and bound to (I've talked about what kind of structures before).\n\n\nWhile browsers look for patterns inside pages, search engines would look for inter-page, structural features: the research search engine companies should be doing now is into what kind of linking goes on. Just as there is a zoology of traffic, and the exploration into the world of cellular automata resembles a biologist's hacking into a rainforest rather than the scientific method, I want a typology of the fine structure of the Web: dense pockets that persist over time; starbursts; ping-pong conversations with a slowly changing list of references. What animals are these and how do I search them? Here's an example of the kind of search I want to do: 'conversations that have arisen in a small, pre-existing group of friends that converge on referencing projects identified by the wider Web as physical computing.' Or the same search but for conferences, and then have my browser scoot over the pages, and deduce event microformats from them.\n\n\nThe technological future of the Web is in micro and macro structure. The approach to the micro is akin to proteins and surface binding--or, to put it another way, phenotropics and pattern matching. Massively parallel agents need to be evolved to discover how to bind onto something that looks like a blog post; a crumb-trail; a right-hand nav; a top 10 list; a review; an event description; search boxes. Functionality can be bound to the pattern matchers: Technorati becomes a text search over everything that has a blog post matcher bound to it; a site with a search matcher bound to it can have extra functionality offered in the browser, for site-wide search offered in a consistent way for every site on the Web (ditto crumb-trails and site maps).\n\n\nThe macro investigation is like chemistry. If pages are atoms, what are the molecules to which they belong? What kind of molecules are there? How do they interact over time? We need a recombinant chemistry of web pages, where we can see multiple conversation molecules, with chemical bonds via their blog post pattern matchers, stringing together into larger scale filaments. What are the long-chain hydrocarbons of the Web? I want Google, Yahoo and Microsoft to be mining the Web for these molecules, discovering and name them.\n\n\nThe most important thing I think we've learned about the Web in the last 10 years is this: there is not infinite variety. That means the problem of finding the patterns in pages and inter-page structure is a tractable one. It might be large and difficult, but it can be done: you make a first approximation that finds patterns in most of the Web, and then another to find patterns in most of the rest, then most of the rest, then most of the rest, and then special case it. Then you'll be done. It'll take years. Whatever.\n\n\nMicro/macro structure is the first of the challenges that faces the Web.\n\n\n2 #\n\n\nIncidentally, I'm flicking through my notebook looking for more notes on this topic and I've run across a reminder to look into the three ways ultrastable institutions adapt to changing circumstances in order to continue being \"machines for surviving,\" as identified by Stafford Beer in his book Platform for Change. Beer talks about social institutions such as 'schooling,' 'the general practice of medicine' and 'penal establishments' (his examples). These are self-organising and self-regulating systems. As their environment changes, how do they not collapse? How are they not sensitive to shock?\n\n\nBeer says that an ultrastable social institution will do one of three things in response to change:\n\n\nIt will change internally and still survive (I guess this is like scouting or soccer, both institutions that have changed minimally).\nThe institution's internal form will change, but its relationships to other institutions will remain. Perhaps this is like prisons, which have the same relationship to the population, police, courts and government... but operate internally very differently.\nDramatic change occurs. This makes me think of the Church: it has changed enormously internally and in its external relations over the last millennium, yet it's still the Church.\n\n\nAs simple as this typology is, I like it because it's a springboard to start discussing how things change. The metaphor that's all to often used for how things change is the Uncertainty Principle from quantum mechanics: when you look at (make a measurement of) one parameter of a system, another parameter flips so you know less. If you know where it is, you can't know how fast it's moving. And yes, it's true, measuring something changes it. But using this metaphor denies us more knowledge: it stops us asking how it changes, and how much, and why.\n\n\nThe metaphor Beer uses, and the one I remember my friend Andrew using, is Le Chatelier's principle. This is from chemistry. It says that a system in equilibrium which is given a prod will change internally to counteract that prod and move into a new equilibrium. So let's say we're attempting to measure domestic violence by putting cameras in houses. Of course this method will change the nature and frequency of the violence, but rather than stopping at \"it changes,\" Le Chatelier leaves open the possibility of figuring out what sort of change has occurred. What happens in other situations where we've used cameras?, we would ask. How have reports changed over time, to reach this new equilibrium? By acting on the system and looking at the responses, we can learn about its internal mechanics, which is a form of science I'm much happier with than the very Zen but not particularly helpful Uncertainty Principle.\n\n\n3 #\n\n\nThis in turn makes me think of Tainter's Collapse of Complex Societies (which I've talked about before, in the context of New Puritans). States form for several reasons, one of which is external conflict or pressure; another is internal management. Fundamentally, though, Tainter casts the continued existence (or not) of a complex society as a economic decision by the population (or a privileged elite who can exert the necessary power): it is cheaper to have centralised complexity than have multiple simpler villages. The whole system essentially 'rolls downhill' into increasing order. (This is similar to how I rationalise takeoff of aeroplanes to myself: the wings are structured such that, at a certain speed, the system of plane and wings and air finds it easier and more stable to fall upwards, carried in a basket of potential energy.)\n\n\nCollapse, in Tainter's view, only looks like collapse because we privilege the institutions of complexity: collapse is a sensible economic decision on the part of the people in the society, to refactor complexity into simple units, and do away with the cost of the managerial organisation. If building of monuments - capacitors of work capacity, essentially - stops, everyone is a little bit richer (though: no more pyramids).\n\n\nBut marry this with Beer and ultrastable social institutions. The ultrastable in this case is the state itself, which contains the whole population. It will change internally, and change its relationship with ultrastables around it, in order to survive. Tainter is reductionist to not regard institutions as actors in their own right. From this perspective, we could see the complexity of the USA as the outcome of a sensible economic decision (paying for safety at the cost of simplicity) during the Cold War period of the 1950s to 1980s. As the threat of nuclear war receded, the complexity of the US (the West in general, really) could also have reduced. It is insupportable without external pressure, like a sandcastle moat on the beach where the walls are thinning. So, being ultrastable, the US state survival machine generates new threats to keep it's own continued existence being a sensible economic decision. It adjusts internally and externally to create ground force to loft itself upwards, to keep itself in the air. That's how I read the War on Terror, anyhow.\n\n\n4 #\n\n\nI mentioned refactoring earlier, so an additional point on that: I have a feeling that refactoring code is not a good thing. I am not in favour of deleting code. If there are problems with code the way it is written, there should be mechanisms to code over it gradually, and leave the old code there. If it becomes too complicated, we need more convenience functions and not less. A codebase should be its own source repository: seeing what the code was like a year ago shouldn't be a check-out from source control, but archeology.\n\n\nI'm not entirely sure why I believe this, but here's a tangential reason. The reason code is refactored is because when code gets complicated, it's hard to understand and maintain. But keeping code simple limits the type of problems we can tackle to ones which have solutions comprehensible to the human brain. Yes, breaking problems down into nuggets that are human brain sizes is one strategy that works. But I think we'll find it's as small a part of the problem space as linear equations model only a small part of all dynamic systems. This may mean we need new ways of approaching programming. Instead of simplicity, we need better tools and languages. Maybe a string class will have to be a gigabyte of raw code. Who cares. Maybe HTML parsing libraries evolve inside themselves and compete. Maybe what my code does, instead of calling a method on an object, is give a list of examples of the kind of responses I know I'd like, and use that to dynamically select from a huge number of pattern matching code libraries that live in the cloud. And maybe if it doesn't work quite right, we don't call that a bug but we call it an inadequate model and write yet more code to make it work better.\n\n\nRefactoring code means we say there are certain behaviours that are important, which are those to be kept, and other there aren't. I say, who are we to say what's important. The days we can ignore side-effects are gone.\n\n\n5 #\n\n\nIf we were a rich world, we'd innovate our way out of this environmental crisis. We'd breed algae that piss petrol, and albatross that inhale hydrocarbons and then soar upwards to breach into the stratosphere, exhaling ozone. But we aren't a rich world, so we're tightening our belts and hoping something will turn up. Nothing will turn up though, because we're all there is to do the turning up. Don't be a Consie.\n\n\nRefactoring our code to accommodate the width of brain passed by a human female's pelvis is similarly stupid. We need to wallow in code, and have the wings to fly in it, to navigate it and garden it to make it self organise.\n\n\nBeer's ultrastables, Tainter's societies that loft themselves into order (falling upwards), and my recent reading about complexity (including Waldrop's Complexity) makes me think of the Second Second Law of Thermodynamics. The (first) Second Law of Thermodynamics is the one that says that a room tends towards untidyness, and scrambled eggs will never spontaneously un-. The Second Second Law of Thermodynamics knows that this view is reductionist, because - with scale - small ultrastable units might emerge in the entropic soup: call them autocatalytic loops or machines for surviving. And these loops might grow, and do whatever they need to turn into ultrastables which can persist over time - a dynamic system that never converges or diverges - perhaps even developing ways of predicting the future or seeing over a distance: people, in other words. Given enough untidy rooms, life will inevitably occur, and a person will evolve who will tidy that room.\n\n\nYou know, seeing is just like predicting the future. Seeing is predicting the far away, because we can never know for sure.\n\n\nAll intelligence must have models of what it needs to predict: aspects of the external world refactored into mini replicas that preserve the behaviour we care about. If you cut open my brain, there is a model of my house in it. Evolution refactored reality into the brain at the beginning of the Holocene, and the favoured behaviours to preserve then aren't the same ones we need now.\n\n\nDavid Deutsch, in The Fabric of Reality, brings up the Second Second Law of Thermodynamics in the context of astrophysics. The Sun will be dying in some billion years. If humans are still around, we'll have to fix it then or before then. Therefore the presence of life cannot be discounted in stellar evolution. Said stellar evolution can be modelled, in physics, and compared to the observed universe using the Hertzsprung-Russell diagram. If there is a divergence, either there's something wrong with the astrophysics or life - as predicted by the Second Second Law of Thermodynamics - has played a part and must be included in the equations. Or all life dies or moves beyond the physical universe before it gets to a point where it wants or needs to manipulate stars. Side effects are important. They mount up. Then survival machines emerge.\n\n\n6 #\n\n\nI was wondering how to model traffic, once we have flocking cars.\n\n\nFlocking cars will come, first for motorways. Cats eyes are being replaced by solar powered LEDs--it won't be long before they have RFIDs in them, initially for inventory management, but then as a handy augmentation to GPS. So that'll be lane position sorted.\n\n\nAnd cars already have systems to make sure the brake is being applied enough, and I don't think it'll be long until the steering wheel starts providing resistance is the cars senses another car behind and to the side. Just a little helping hand, you know. There's already automatic parking. I heard about a VR system which only has a screen ahead and to the sides of the user, but simulates being about to look all the way around: the scene it projects moves twice as fast as the head. So when you look 90 degrees to your right, the scene shifts 180 degrees. You get used to it really quickly, apparently. I think we'll have something like that for cars, too, to deal with the information overload.\n\n\nThen cars will begin to help out with driving a little more: a toggle switch to flick left and right between lanes, just as easily as changing gear. Think of it as an automatic clutch for changing lanes on freeways. Then cruise control will use the cars ahead and behind as cues, and by that time we'll have mesh networks everywhere so the cars will share information too. And then the insurance companies will lower the premiums if you opt not to drive manually on main roads, and that'll be that.\n\n\nSo what are the emergent properties of flocking cars? I think we'll need a certain kind of maths to model it, and that is what I was thinking about. It'll be a bit like signal processing: we'll look at the distances between successive cars, and monitor the pressure waves that move along that pipe. There will be standing waves causes by junctions, and the police will introduce special cars to act as signal dampers or oscillation providers, used to break up clots of cars. Having all the cars on the same rule system worries me, because the failure modes of homogeneous populations are nasty. We'll need a way of parameterising the rules so that different cars all behave slightly differently, so that traffic itself becomes an ultrastable system, responding to an accident by simply shifting the internal population of rules to change the equilibrium and flock around the grit instead of locking up entirely. That'll mean we'll have a statistical mechanics of traffic instead, and next to the weather reports in the newspaper we'll have pressure- and temperature-equivalent forecasts being reported for the road system. Heat is just the aggregate of the vibrations of a mass of particles, after all; the analogy works.\n\n\nWe'll use the same reports to buy and sell futures in car insurance, hedging the additional commute risk by promising to take a safe trip to the grocery store in the evening.\n\n\n7 #\n\n\nI look forward to the day of flocking cars, because change is good. The more change there is, the more likely it is that some of the changes will be positive and form survival machines that persist. One way to bring forward that day is to deliberately drive badly. The more effort we put into driving well manually, the less need there is for robots. So we don't get flocking cars and we have to work harder. That's the story of the 20th century, if you ask me.\n\n\nThe communists were dangerous for two reasons: firstly they were internationalists, valuing actors whose behaviour they admired highly even if the actors were not in the local nation state. At any moment their motivations were potentially treasonous. Secondly they knew class revolution was inevitable, but attempted to bring it forward by promoting conflict, making riots out of protests, attacking the police and so on.\n\n\nDriving badly, burning tyres on the roof and refusing to delete code are all aspects of bringing forward the revolution by promoting conflict. I am an internationalist of progress.\n\n\n8 #\n\n\nI was going to talk about groups and motivations on the Web, but first I want to briefly mention the Magna Carta.\n\n\nMonarchy used to be a force of nature. It wasn't something you'd notice. Yes there were limits of the power of monarchy, but they were like gravity: since the king couldn't fly, he wouldn't try. He can't vaporise the barons with his mind, so why should he want to? The monarch has the power that a queen bee has in the hive: in dynamic equilibrium with the population. But equally the monarch isn't totally defined by the relationships to the population around it: if the monarchy was so defined, the person wouldn't be required because the shape of the hole would do.\n\n\nNecessarily, the monarch is sometimes unpredictable (if it's known what the king would say in any given situation, the monarch wouldn't be required). So in the situations where the king is predictable, the situation unfolds without the monarch needing to be present as an actor: the king is like gravity. And when the opinion isn't known, the monarch is the final answer--the answer of the king can't be deduced without asking the king. There are no shortcuts.\n\n\nNote that this is like the present day legal system. In most situations between two companies, a contract will exist but never be used: because each company can see what a contract says about a decision, the contract will inflect that decision without being run. In some situations a contract is ambiguous, and the legal system will compile and run it. In that case it cannot be known ahead of time what the result will be, otherwise there would be no point in running the legal system over the problem.\n\n\nIt is not possible to know what the king will say without asking the king; the king is only asked for a decision in cases where the answer cannot be known ahead of time. The king is the only source of unknowns in the society. In our world, it is the free market which is the only source of unknowns.\n\n\nWhat the Magna Carta did - or rather, what the process that the Magna Carta was part of did - was turn the king into a thing. The thing-king is the king revealed. The important feature of the document isn't the constraints put on the king, but rather the fact that it is possible to bind to the king at all. It's like suddenly leaping above the ocean and realising that the ocean is there at all... and therefore tides! and therefore currents! and therefore the possibility of other bodies of water that aren't this ocean! Or it's like the way that air pollution revealed the atmosphere as something that could have varying parameters over its volume. Once the king is a thing, it is possible to bring the king into society, and constrain and rule him. That was the big deal.\n\n\nSo when I look at the economic imperatives of the free market, and the way the invisible hand is swiping us into situations that are frankly fucked up, I wonder: is it possible to make the free market a thing? Rather than complain about it and make laws about it (which of course won't work, because they're inside a system in which the only source of 'truth' is the free market (and by 'truth' I mean those facts which can't be known without computing them)), is it possible to describe the market to such a degree that the next steps will naturally be to internalise and constrain it?\n\n\nBecause whenever we describe something, we consume it. Look at the universe and physics. Or people, and psychology and mental hygiene. Or Africa.\n\n\nTo promote the end of the free market, if that's what you hate, discuss it--that's my advice. Discuss it and find the whorls and jetstreams of it. Find the laws of thermodynamics of it. Categorise the behaviours, without making the models that economists do. Taxonomy first, models next. Turn the market into a surface ripe for binding. As thermodynamics described steam and brought about the Industrial Revolution, describe the market.\n\n\nThis means we'll have metamarkets, in the end. Mini free markets captured and tuned to perform particular tasks, inside a society we can't currently grasp, just as China held Hong Kong in a bubble to propel it into orbit, and the Large Hadron Collider intends to create new zones of particular kinds of physics in order to perform scientific experiments.\n\n\n9 #\n\n\nAnother thing the Web needs to do better is groups. A lot of social software takes non-social, individual activities and puts them into a social context: bookmarking, photos, even accountancy. Then what we've done is ported in existing social concepts (used by people to model and interact with other people in social settings) like identity, reputation and sharing, and created a substrate in which social patterns that emerge in the meat world can come about online too: groups, factions, and power relationships (I would say these exist more independently from people than the earlier concepts).\n\n\nI want to think about social software in reverse. Can we take activities that are already group-based and irreducibly social in the real world, and make software that is good for them? I suspect that software for a running group or book club would not succeed by merely introducing ideas like friends lists and social sharing: these \"features\" were never absent. Instead new kinds of social functionality will need to be created. To be honest, I've no idea what this social functionality will be.\n\n\nBut to begin with, I do know that making social software for a pre-existing group activity is so different from the \"individuals socialising\" model we have at the moment that our usual references (Goffman's presentation of self, and human motivations from psychology) will fall down, and our normal feature set (signing in, and messaging with inboxes) won't apply.\n\n\nThe challenge I was thinking about was this: how would you design a sign-in system for a book club? Having them share a username and password doesn't seem elegant somehow: although the information they keep online they want to keep in common, in the meat world telling one person a username and password doesn't guarantee that knowledge passes to others in the group. So is there knowledge they do hold in common?\n\n\nPerhaps the login system could be based around questions: 'what is a name of a blonde person in your group?' And let's say, to sign in, you answer three questions: two which are known by the system and one which isn't. The one which isn't known is asked several times and the answers correlated. This becomes another known fact the system can use in the official part of the sign-in process. The problem I see here is that people from outside the group could also sign in, and this is also the problem with traditional passwords: with my weblog, it's not the random stranger I want to prevent logging in--it's the potentially malicious people I might meet, who are the people most likely to guess my password (except that I use a strong password, but you get my drift). Somehow the group sign-in system has got to make use of the fact that a solid group exists out there in the world, and make use of a trivia that only an official group member would know: 'did you have red or white wine at the last birthday dinner you went out for?' I don't know. I do know that it's a challenge to develop a group sign-in pattern, and once developed that pattern will encourage a thousand websites to bloom, just as a known login/registration pattern helped along both developers and users of the current batch of websites.\n\n\n10 #\n\n\nIt also makes me wonder what analogues groups have to individuals. There is still the concept of forgetting: multiple members of a group might leave, and some of the group memory will be lost. And there will still be a need to change the identification method on demand.\n\n\nIn terms of what functionality we'd offer to groups, I was thinking about what an analogue to a blogging system would be to a small group of people. I don't think it's just a blog with multiple authors. Wikis are better, but they don't leave a contrail through time like blogs do. There's no publication.\n\n\nMaybe a wiki for a making a zine would be better. On the wiki, which you'd be able to edit by answering the group login questions. There would be a certain amount of structure: page numbers, sidebars, links and a contents page. There would be different page formats: long form, big pictures, and intro material (there would be templates for these). There would also be a big clock at the top right: 'going to press in 30 days!' it'd say. And it'd gradually count down. On the final day, the wiki would freeze its content, and allow only small changes for a further day or two, at which point the entire thing would be automatically compiled into a zine, and a PDF of the entire thing generated and published. Old-schoolers will recognise this as what Organizine could have become but never did.\n\n\n11 #\n\n\nSince \"Incidentally, I'm flicking through my notebook,\" I've been writing whatever seemed to follow on. That was page 6 of my notebook, and this notebook started in October 2007. I've just thought about looking down at my notebook again and come to page 7, which - happily - is another comment about the Web and interactive systems more generally.\n\n\nFlickr is playful, and it is structured to bend the trajectory of users back into it. In a way, it's a true massively multiplayer game: with most games and ARGs the player is basically playing against the game developers and designers, who are the ones generating the rulespace. With Flickr you get the feeling that you are playing in partnership with the developers, both of you playing together in the foam of the nature of the Web and photos and social systems at large. You have different abilities, that's all.\n\n\nTo generalise Flickr's attributes, successful interactive systems will bend users back towards them, whether by play or not. A tool like a screwdriver doesn't need to do anything to bend people back towards it because it's driven by necessity: every time you need to deal with a screw, you'll pick up the screwdriver. But websites are abundant. The Web is crusted with functionality. In an ocean of passive particles, the ones that dominate are the ones that learn how to autocatalyse and reproduce (another expression of the Second Second Law of Thermodynamics, or just natural selection).\n\n\nIn order to keep going, the path of a user through a website must be designed to never end. In order for the website to grow, the path of the user must be designed to bring in more users, as in a nuclear chain reaction.\n\n\n12 #\n\n\nComputer programmes are something else that have to not halt unintentionally. The way this is done is to model the application as a collection of finite-state machines. Each machine can exist in a number of different states, and for each state there are a number of conditions to pass to one or another of the other states. Each time the clock ticks, the machines sees which conditions are matched, and updates the state accordingly. It is the job of the programmer to make sure the machine never gets into a state out of which there is no exit, or faces a condition for which there is no handling state. There are also more complex failure modes.\n\n\nGetting Things Done, David Allen, describes a finite-state machine for dealing with tasks. Each task has a state ('in,' 'do it,' 'delegate it,' 'defer it,' 'trash' and more) and actions to perform and conditions to be met to move between the states. The human operator is the clock in this case, providing the ticks. This machine does have exit points, where tasks stop circulating and fall off.\n\n\nThe cleverness of Getting Things Done is to wrap this finite-state machine in another finite-state machine which instead of running on the tasks, runs on the human operator itself, the same operator who provides the ticks. The book is set up to define and launch the state machine which will keep the human in the mode of running the task machine. If they run out of tasks, the GTD machine has a way of looping them back in with tickle files and starting again the next day. If they get into a overwhelmed state, the GTD machine has a way of pruning the tasks. If they get demotivated and stop running the task machine, the GTD machine has ways of dealing with that. Alcoholics Anonymous has to deal with this state too, and it's called getting back on the wagon. The GTD machine even has a machine wrapped around it, one comprising a community to provide external pressure. Getting Things Done is a finite-state machine that runs on people; a network of states connected by motivations, rationale and excuses, comprising a programme whose job it is to run the task machine.\n\n\n13 #\n\n\nWebsites can also be seen as finite-state machines that run on people. Successful websites must be well-designed machines that run on people, that don't crash, don't halt, and have the side-effect of bringing more people in. Websites that don't do this will disappear.\n\n\nInstead of a finite-state machine, think of a website as a flowchart of motivations. For every state the user is in, there are motivations: it's fun; it's the next action; it saves money; it's intriguing; I'm in flow; I need to crop the photo and I remember there's a tool to do it on that other page; it's pretty.\n\n\nIf you think about iPhoto as its flowchart of motivations, the diagram has to include cameras, sharing, printers, Flickr, using pictures in documents, pictures online and so on. Apple are pretty good at including iPhoto all over Mac OS X, to fill out the flowchart. But it'd make more sense if I could also see Flickr as a mounted drive on my computer, or in iPhoto as a source library just as I can listen to other people's music on the same LAN in iTunes. This is an experience approach to service design.\n\n\nUsers should always know their next state, how they can reach it, and why they should want to.\n\n\nIf I were to build a radio in this way, it would not have an 'off' button. It would have only a 'mute for X hours' button because it always has to be in a state that will eventually provoke more interaction.\n\n\nDesigning like this means we need new metrics drawn from ecology design. Measurements like closure ratio become important. We'll talk about growth patterns, and how much fertiliser should be applied. We'll look at entropy and population dynamics.\n\n\nMaybe we'll look at marketing too. Alex Jacobson told me about someone from old-school marketing he met who told him there are four reasons people buy your product: hope, fear, despair and greed. Hope is when your meal out at the restaurant is because it's going to be awesome. Fear is because you'll get flu and lose your job unless you take the pills every day. Despair is needs not wants: buying a doormat, or toilet paper, or a ready-meal for one. Greed gets you more options to do any of the above, like investing. Yeah, perhaps. Typologies aren't true, but they're as true as words, which also aren't true but give us handholds on the world and can springboard us to greater understanding. We can kick the words away from underneath ourselves once we reach enlightenment.\n\n\n14 #\n\n\nThe lack of suitable motivations is also why we don't have drugs that make us superheroes, and this is also a failure of the free market because obviously these drugs would be cool. It's not like there hasn't been a search for interesting drugs (drugs for something other than pure pleasure or utility). The second half of Phenethylamines I Have Known And Loved documents the Shulgins' subjective experiences with 179 compounds that act like the neurotransmitter, phenethylamine.\n\n\n\"There was a vague awareness of something all afternoon, something that might be called a thinness.\" (#125)\n\n\n\"I easily crushed a rose, although it had been a thing of beauty.\" (#157)\n\n\nPiHKAL was written in 1991. Viagra wasn't patented till 1996. Why hasn't the last 16 years been spent on substitute phenethylamines doing for consciousness doing what Viagra does for penises?\n\n\nIn The Player of Games, Iain M. Banks talks about Sharp Blue, a drug which is \"good for games. What seemed complicated became simple; what appeared insoluble became soluble; what had been unknowable became obvious. A utility drug; an abstraction-modifier; not a sensory enhancer or a sexual stimulant or a physiological booster.\"\n\n\nI was talking about this with Tom and Alex and some Matts in the pub a few months ago. Why don't we have abstraction modifier drugs now? Why are there no drugs to help me think in hierarchies, or with models, or to make cross connections? Or rather, since drugs exist that do this in a coarse and illegal way now, why haven't these been tuned? I had been busy all day coding highly interlocking finite-state machines.\n\n\nIf I wanted to make such drugs, it would be a waste of my time to develop them myself. My best way forward would be to manipulate the market and society to want the drugs, and leave the rest up to pharma industry. Products are often invented (or revealed) to mediate a risk. The particular risk is chosen (from many) to make a particular product: there is no cause and effect here; it is choreographed between the risk and mediation. For example, the AIDS risk has been revealed as HIV, as there is money to be made in designing drugs to combat this particular molecule. However the AIDS risk is part of the risk of epidemic death and the cause of this is more properly revealed as poverty, not a virus. The product to mitigate and manage AIDS-as-poverty is not as palatable to the world or as tractable for the market: it is expensive and hard and has rewards which are hard to quantify (I'm badly misrepresenting Risk and Technological Culture, Joost van Loon, I'm sure).\n\n\nRisks are deliberately revealed in small ways too. Dove invented, in advertising, the concept of the un-pretty underarm (no 'armpit' here). Fortunately they have launched products to mitigate this problem.\n\n\nSo first the problem of abstraction difficulty must be revealed as a risk. This can be done in a traditional marketing way, with press releases and spurious research. Then various ways must be tested to mitigate this risk: these need to be simultaneously difficult and expensive, and vastly popular. The intention here is to demonstrate that there is a market for any company who creates a better method, which is profitable enough that some expensive research can be done up-front. For this, imagine popularising a method like Getting Things Done crossed with the creation and value of the diamond industry and the accessibility and mind-share of omega-3 in fish oil. I'm sure the alternative therapy industry would be unwitting, happy partners in this.\n\n\nOnce the risk is revealed and the market visible, it's a matter of providing to the pharma industry the material they need to persuade governments to make this legal. That is, the facts that the ability to abstract is essential to business, and that it's a matter which is outside the scope of government.\n\n\nFrom there the invisible hand will take care of everything. A technician will be reading some lab reports and realise that some of the test subjects exhibited the qualities discussed as necessary to the country in a newspaper article they read last week. A research programme will be suggested. The business people will assess the market size, based on published research and the number of people buying games like Brain Training. The government will turn a blind eye because business needs to be competitive. We could have an abstraction drug inside a decade.\n\n\nOne day people will look back on the above paragraphs and see that what was suggested was what happened. It will be my L. Ron Hubbard moment.\n\n\n15 #\n\n\nEarlier this year I met a biochemist who is part of a research group that has created an artificial store of energy which is as small and energy-dense as fats, and as quick release as sugars--those being the two ways cells in the body store and retrieve energy. Because every cell uses energy, rats eating food with this new compound are tested to be smarter and have better endurance. Holy shit. The same fellow was wearing a hearing aid with a switch that made him hear better at parties than I do.\n\n\nI would like to meet more people like him. I am currently working on an idea which may turn into a small product which I am prepared to underwrite, and it requires I meet with people who are decent-ish writers (who would like to write more and are probably teachers) who are interested in the world and typologies, and understand one of these areas at a 16 year-old to first-year undergraduate level: geography and city models; meteorology; the Austro-Hungarian Empire; soil; tectonics; the metabolic cycle; proteins and enzymes; U.S. highway design; dendritic patterns; closed-system ecology like Biosphere 2; farm management.\n\n\nThe kind of person I have in mind is Dr Vaughan Bell, who was introduced to me by a friend to write a hack or two for Mind Hacks. He wrote a whole bunch (he was already a pretty serious Wikipedia contributor, among other public understanding of science activities), communicates incredibly, and has turned the Mind Hacks blog into one of the top 5,000 weblogs globally, increasing general knowledge and interest in psychology and cognitive science immeasurably. Please let me know of anyone of whom you're reminded by these two paragraphs.\n\n\n16 #\n\n\nVending machines on the street sell mixed smoothies. Each machine is populated with a selection of 8 from dozens of base fruit smoothies. There are 10 options on the machine, representing different mixes of the 8 fruit flavours. Genetic algorithms are used to evolve the smoothies towards the optimum flavours for that neighbourhood, based on what sells. Variety is introduced by having wild-card base flavours in that 8th slot. Sometimes you take a detour on the way to work to help out training a machine to produce your favourite cocktail.\n\n\nAdditionally: 'Coke Continuous Change' is a variety of Coca Cola that is different every time you buy it. The company manufactures batches of varying recipes and ships out crates of unique mixes. Each can has a code on it that also represents the recipe. Using feedback from drinkers, Coke can optimise the level of variety and serendipity on a hyperlocal level. The only constant is there is no constant. If you hate the one you're drinking, buy another.\n\n\nThat'll do.\n\n",
    link: "/home/2007/12/26/i_completed_reading",
  },
];
